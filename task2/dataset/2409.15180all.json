{
    "2006.04558": {
        "title": "FastSpeech 2: Fast and High-Quality End-to-End Text to Speech",
        "abstract": "Non-autoregressive text to speech (TTS) models such as FastSpeech can\nsynthesize speech significantly faster than previous autoregressive models with\ncomparable quality. The training of FastSpeech model relies on an\nautoregressive teacher model for duration prediction (to provide more\ninformation as input) and knowledge distillation (to simplify the data\ndistribution in output), which can ease the one-to-many mapping problem (i.e.,\nmultiple speech variations correspond to the same text) in TTS. However,\nFastSpeech has several disadvantages: 1) the teacher-student distillation\npipeline is complicated and time-consuming, 2) the duration extracted from the\nteacher model is not accurate enough, and the target mel-spectrograms distilled\nfrom teacher model suffer from information loss due to data simplification,\nboth of which limit the voice quality. In this paper, we propose FastSpeech 2,\nwhich addresses the issues in FastSpeech and better solves the one-to-many\nmapping problem in TTS by 1) directly training the model with ground-truth\ntarget instead of the simplified output from teacher, and 2) introducing more\nvariation information of speech (e.g., pitch, energy and more accurate\nduration) as conditional inputs. Specifically, we extract duration, pitch and\nenergy from speech waveform and directly take them as conditional inputs in\ntraining and use predicted values in inference. We further design FastSpeech\n2s, which is the first attempt to directly generate speech waveform from text\nin parallel, enjoying the benefit of fully end-to-end inference. Experimental\nresults show that 1) FastSpeech 2 achieves a 3x training speed-up over\nFastSpeech, and FastSpeech 2s enjoys even faster inference speed; 2) FastSpeech\n2 and 2s outperform FastSpeech in voice quality, and FastSpeech 2 can even\nsurpass autoregressive models. Audio samples are available at\nhttps://speechresearch.github.io/fastspeech2/.",
        "date": "2020-06-08T13:05:40+00:00",
        "label": 1
    },
    "1710.03090": {
        "title": "Theoretical Computer Science for the Working Category Theorist",
        "abstract": "Theoretical computer science discusses foundational issues about\ncomputations. It asks and answers questions such as \"What is a computation?\",\n\"What is computable?\", \"What is efficiently computable?\",\"What is\ninformation?\", \"What is random?\", \"What is an algorithm?\", etc. We will present\nmany of the major themes and theorems with the basic language of category\ntheory. Surprisingly, many interesting theorems and concepts of theoretical\ncomputer science are easy consequences of functoriality and composition when\nyou look at the right categories and functors connecting them.",
        "date": "2017-10-04T19:19:00+00:00",
        "label": 0
    },
    "2012.12144": {
        "title": "Integrating computing in the statistics and data science curriculum: Creative structures, novel skills and habits, and ways to teach computational thinking",
        "abstract": "Nolan and Temple Lang (2010) argued for the fundamental role of computing in\nthe statistics curriculum. In the intervening decade the statistics education\ncommunity has acknowledged that computational skills are as important to\nstatistics and data science practice as mathematics. There remains a notable\ngap, however, between our intentions and our actions. In this special issue of\nthe *Journal of Statistics and Data Science Education* we have assembled a\ncollection of papers that (1) suggest creative structures to integrate\ncomputing, (2) describe novel data science skills and habits, and (3) propose\nways to teach computational thinking. We believe that it is critical for the\ncommunity to redouble our efforts to embrace sophisticated computing in the\nstatistics and data science curriculum. We hope that these papers provide\nuseful guidance for the community to move these efforts forward.",
        "date": "2020-12-22T16:28:18+00:00",
        "label": 0
    },
    "2404.13914": {
        "title": "Audio Anti-Spoofing Detection: A Survey",
        "abstract": "The availability of smart devices leads to an exponential increase in\nmultimedia content. However, the rapid advancements in deep learning have given\nrise to sophisticated algorithms capable of manipulating or creating multimedia\nfake content, known as Deepfake. Audio Deepfakes pose a significant threat by\nproducing highly realistic voices, thus facilitating the spread of\nmisinformation. To address this issue, numerous audio anti-spoofing detection\nchallenges have been organized to foster the development of anti-spoofing\ncountermeasures. This survey paper presents a comprehensive review of every\ncomponent within the detection pipeline, including algorithm architectures,\noptimization techniques, application generalizability, evaluation metrics,\nperformance comparisons, available datasets, and open-source availability. For\neach aspect, we conduct a systematic evaluation of the recent advancements,\nalong with discussions on existing challenges. Additionally, we also explore\nemerging research topics on audio anti-spoofing, including partial spoofing\ndetection, cross-dataset evaluation, and adversarial attack defence, while\nproposing some promising research directions for future work. This survey paper\nnot only identifies the current state-of-the-art to establish strong baselines\nfor future experiments but also guides future researchers on a clear path for\nunderstanding and enhancing the audio anti-spoofing detection mechanisms.",
        "date": "2024-04-22T06:52:12+00:00",
        "label": 1
    },
    "2103.10489": {
        "title": "Addressing Hate Speech with Data Science: An Overview from Computer Science Perspective",
        "abstract": "From a computer science perspective, addressing on-line hate speech is a\nchallenging task that is attracting the attention of both industry (mainly\nsocial media platform owners) and academia. In this chapter, we provide an\noverview of state-of-the-art data-science approaches - how they define hate\nspeech, which tasks they solve to mitigate the phenomenon, and how they address\nthese tasks. We limit our investigation mostly to (semi-)automatic detection of\nhate speech, which is the task that the majority of existing computer science\nworks focus on. Finally, we summarize the challenges and the open problems in\nthe current data-science research and the future directions in this field. Our\naim is to prepare an easily understandable report, capable to promote the\nmultidisciplinary character of hate speech research. Researchers from other\ndomains (e.g., psychology and sociology) can thus take advantage of the\nknowledge achieved in the computer science domain but also contribute back and\nhelp improve how computer science is addressing that urgent and socially\nrelevant issue which is the prevalence of hate speech in social media.",
        "date": "2021-03-18T19:19:44+00:00",
        "label": 0
    },
    "2201.05852": {
        "title": "Data Science in Perspective",
        "abstract": "Data and Science has stood out in the generation of results, whether in the\nprojects of the scientific domain or business domain. CERN Project, Scientific\nInstitutes, companies like Walmart, Google, Apple, among others, need data to\npresent their results and make predictions in the competitive data world. Data\nand Science are words that together culminated in a globally recognized term\ncalled Data Science. Data Science is in its initial phase, possibly being part\nof formal sciences and also being presented as part of applied sciences,\ncapable of generating value and supporting decision making. Data Science\nconsiders science and, consequently, the scientific method to promote decision\nmaking through data intelligence. In many cases, the application of the method\n(or part of it) is considered in Data Science projects in scientific domain\n(social sciences, bioinformatics, geospatial projects) or business domain\n(finance, logistic, retail), among others. In this sense, this article\naddresses the perspectives of Data Science as a multidisciplinary area,\nconsidering science and the scientific method, and its formal structure which\nintegrate Statistics, Computer Science, and Business Science, also taking into\naccount Artificial Intelligence, emphasizing Machine Learning, among others.\nThe article also deals with the perspective of applied Data Science, since Data\nScience is used for generating value through scientific and business projects.\nData Science persona is also discussed in the article, concerning the education\nof Data Science professionals and its corresponding profiles, since its\nprojection changes the field of data in the world.",
        "date": "2022-01-15T13:51:12+00:00",
        "label": 0
    },
    "2404.13146": {
        "title": "DeepFake-O-Meter v2.0: An Open Platform for DeepFake Detection",
        "abstract": "Deepfakes, as AI-generated media, have increasingly threatened media\nintegrity and personal privacy with realistic yet fake digital content. In this\nwork, we introduce an open-source and user-friendly online platform,\nDeepFake-O-Meter v2.0, that integrates state-of-the-art methods for detecting\nDeepfake images, videos, and audio. Built upon DeepFake-O-Meter v1.0, we have\nmade significant upgrades and improvements in platform architecture design,\nincluding user interaction, detector integration, job balancing, and security\nmanagement. The platform aims to offer everyday users a convenient service for\nanalyzing DeepFake media using multiple state-of-the-art detection algorithms.\nIt ensures secure and private delivery of the analysis results. Furthermore, it\nserves as an evaluation and benchmarking platform for researchers in digital\nmedia forensics to compare the performance of multiple algorithms on the same\ninput. We have also conducted detailed usage analysis based on the collected\ndata to gain deeper insights into our platform's statistics. This involves\nanalyzing two-month trends in user activity and evaluating the processing\nefficiency of each detector.",
        "date": "2024-04-19T19:24:20+00:00",
        "label": 1
    },
    "1612.04037": {
        "title": "Proceedings 11th Doctoral Workshop on Mathematical and Engineering Methods in Computer Science",
        "abstract": "MEMICS provides a forum for doctoral students interested in applications of\nmathematical and engineering methods in computer science. Besides a rich\ntechnical programme (including invited talks, regular papers, and\npresentations), MEMICS also offers friendly social activities and exciting\nopportunities for meeting like-minded people. MEMICS submissions traditionally\ncover all areas of computer science (such as parallel and distributed\ncomputing, computer networks, modern hardware and its design, non-traditional\ncomputing architectures, information systems and databases, multimedia and\ngraphics, verification and testing, computer security, as well as all related\nareas of theoretical computer science).",
        "date": "2016-12-13T05:47:19+00:00",
        "label": 0
    },
    "2007.03606": {
        "title": "Data Science: A Comprehensive Overview",
        "abstract": "The twenty-first century has ushered in the age of big data and data economy,\nin which data DNA, which carries important knowledge, insights and potential,\nhas become an intrinsic constituent of all data-based organisms. An appropriate\nunderstanding of data DNA and its organisms relies on the new field of data\nscience and its keystone, analytics. Although it is widely debated whether big\ndata is only hype and buzz, and data science is still in a very early phase,\nsignificant challenges and opportunities are emerging or have been inspired by\nthe research, innovation, business, profession, and education of data science.\nThis paper provides a comprehensive survey and tutorial of the fundamental\naspects of data science: the evolution from data analysis to data science, the\ndata science concepts, a big picture of the era of data science, the major\nchallenges and directions in data innovation, the nature of data analytics, new\nindustrialization and service opportunities in the data economy, the profession\nand competency of data education, and the future of data science. This article\nis the first in the field to draw a comprehensive big picture, in addition to\noffering rich observations, lessons and thinking about data science and\nanalytics.",
        "date": "2020-07-01T02:33:58+00:00",
        "label": 0
    },
    "1106.2769": {
        "title": "Co-c.e. spheres and cells in computable metric spaces",
        "abstract": "We investigate conditions under which a co-computably enumerable set in a\ncomputable metric space is computable. Using higher-dimensional chains and\nspherical chains we prove that in each computable metric space which is locally\ncomputable each co-computably enumerable sphere is computable and each co-c.e.\ncell with co-c.e. boundary sphere is computable.",
        "date": "2011-06-14T17:46:06+00:00",
        "label": 0
    },
    "2006.07397": {
        "title": "The DeepFake Detection Challenge (DFDC) Dataset",
        "abstract": "Deepfakes are a recent off-the-shelf manipulation technique that allows\nanyone to swap two identities in a single video. In addition to Deepfakes, a\nvariety of GAN-based face swapping methods have also been published with\naccompanying code. To counter this emerging threat, we have constructed an\nextremely large face swap video dataset to enable the training of detection\nmodels, and organized the accompanying DeepFake Detection Challenge (DFDC)\nKaggle competition. Importantly, all recorded subjects agreed to participate in\nand have their likenesses modified during the construction of the face-swapped\ndataset. The DFDC dataset is by far the largest currently and publicly\navailable face swap video dataset, with over 100,000 total clips sourced from\n3,426 paid actors, produced with several Deepfake, GAN-based, and non-learned\nmethods. In addition to describing the methods used to construct the dataset,\nwe provide a detailed analysis of the top submissions from the Kaggle contest.\nWe show although Deepfake detection is extremely difficult and still an\nunsolved problem, a Deepfake detection model trained only on the DFDC can\ngeneralize to real \"in-the-wild\" Deepfake videos, and such a model can be a\nvaluable analysis tool when analyzing potentially Deepfaked videos. Training,\nvalidation and testing corpuses can be downloaded from\nhttps://ai.facebook.com/datasets/dfdc.",
        "date": "2020-06-12T18:15:55+00:00",
        "label": 1
    },
    "2002.10137": {
        "title": "Audio-driven Talking Face Video Generation with Learning-based Personalized Head Pose",
        "abstract": "Real-world talking faces often accompany with natural head movement. However,\nmost existing talking face video generation methods only consider facial\nanimation with fixed head pose. In this paper, we address this problem by\nproposing a deep neural network model that takes an audio signal A of a source\nperson and a very short video V of a target person as input, and outputs a\nsynthesized high-quality talking face video with personalized head pose (making\nuse of the visual information in V), expression and lip synchronization (by\nconsidering both A and V). The most challenging issue in our work is that\nnatural poses often cause in-plane and out-of-plane head rotations, which makes\nsynthesized talking face video far from realistic. To address this challenge,\nwe reconstruct 3D face animation and re-render it into synthesized frames. To\nfine tune these frames into realistic ones with smooth background transition,\nwe propose a novel memory-augmented GAN module. By first training a general\nmapping based on a publicly available dataset and fine-tuning the mapping using\nthe input short video of target person, we develop an effective strategy that\nonly requires a small number of frames (about 300 frames) to learn personalized\ntalking behavior including head pose. Extensive experiments and two user\nstudies show that our method can generate high-quality (i.e., personalized head\nmovements, expressions and good lip synchronization) talking face videos, which\nare naturally looking with more distinguishing head movement effects than the\nstate-of-the-art methods.",
        "date": "2020-02-24T10:02:10+00:00",
        "label": 1
    },
    "2106.15561": {
        "title": "A Survey on Neural Speech Synthesis",
        "abstract": "Text to speech (TTS), or speech synthesis, which aims to synthesize\nintelligible and natural speech given text, is a hot research topic in speech,\nlanguage, and machine learning communities and has broad applications in the\nindustry. As the development of deep learning and artificial intelligence,\nneural network-based TTS has significantly improved the quality of synthesized\nspeech in recent years. In this paper, we conduct a comprehensive survey on\nneural TTS, aiming to provide a good understanding of current research and\nfuture trends. We focus on the key components in neural TTS, including text\nanalysis, acoustic models and vocoders, and several advanced topics, including\nfast TTS, low-resource TTS, robust TTS, expressive TTS, and adaptive TTS, etc.\nWe further summarize resources related to TTS (e.g., datasets, opensource\nimplementations) and discuss future research directions. This survey can serve\nboth academic researchers and industry practitioners working on TTS.",
        "date": "2021-06-29T16:50:51+00:00",
        "label": 1
    },
    "1401.4507": {
        "title": "Using Quantum Computers to Learn Physics",
        "abstract": "Since its inception at the beginning of the twentieth century, quantum\nmechanics has challenged our conceptions of how the universe ought to work;\nhowever, the equations of quantum mechanics can be too computationally\ndifficult to solve using existing computers for even modestly large systems.\nHere I will show that quantum computers can sometimes be used to address such\nproblems and that quantum computer science can assign formal complexities to\nlearning facts about nature. Hence, computer science should not only be\nregarded as an applied science; it is also of central importance to the\nfoundations of science.",
        "date": "2014-01-18T01:46:52+00:00",
        "label": 0
    },
    "2002.05658": {
        "title": "Ten Research Challenge Areas in Data Science",
        "abstract": "Although data science builds on knowledge from computer science, mathematics,\nstatistics, and other disciplines, data science is a unique field with many\nmysteries to unlock: challenging scientific questions and pressing questions of\nsocietal importance. This article starts with meta-questions about data science\nas a discipline and then elaborates on ten ideas for the basis of a research\nagenda for data science.",
        "date": "2020-01-27T21:39:57+00:00",
        "label": 0
    },
    "2007.08087": {
        "title": "Starting with data: advancing spatial data science by building and sharing high-quality datasets",
        "abstract": "Spatial data science has emerged in recent years as an interdisciplinary\nfield. This position paper discusses the importance of building and sharing\nhigh-quality datasets for spatial data science.",
        "date": "2020-07-16T03:15:56+00:00",
        "label": 0
    },
    "2205.01553": {
        "title": "Why The Trans Programmer?",
        "abstract": "Through online anecdotal evidence and online communities, there is an\nin-group idea of trans people (specifically trans-feminine individuals)\ndisproportionately entering computer science education & fields. Existing data\nsuggests this is a plausible trend, yet no research has been done into exactly\nwhy. As computer science education (traditional schooling or self-taught\nmethods) is integral to working in computer science fields, a simple research\nsurvey was conducted to gather data on 138 trans people's experiences with\ncomputer science & computer science education. This article's purpose is to\nshed insight on the motivations for trans individuals choosing computer science\npaths, while acting as a basis and call to action for further research.",
        "date": "2022-05-03T15:06:23+00:00",
        "label": 0
    },
    "1407.7360": {
        "title": "A Taxonomy and Survey on eScience as a Service in the Cloud",
        "abstract": "Cloud computing has recently evolved as a popular computing infrastructure\nfor many applications. Scientific computing, which was mainly hosted in private\nclusters and grids, has started to migrate development and deployment to the\npublic cloud environment. eScience as a service becomes an emerging and\npromising direction for science computing. We review recent efforts in\ndeveloping and deploying scientific computing applications in the cloud. In\nparticular, we introduce a taxonomy specifically designed for scientific\ncomputing in the cloud, and further review the taxonomy with four major kinds\nof science applications, including life sciences, physics sciences, social and\nhumanities sciences, and climate and earth sciences. Our major finding is that,\ndespite existing efforts in developing cloud-based eScience, eScience still has\na long way to go to fully unlock the power of cloud computing paradigm.\nTherefore, we present the challenges and opportunities in the future\ndevelopment of cloud-based eScience services, and call for collaborations and\ninnovations from both the scientific and computer system communities to address\nthose challenges.",
        "date": "2014-07-28T09:14:35+00:00",
        "label": 0
    },
    "2304.06632": {
        "title": "AI-Generated Content (AIGC): A Survey",
        "abstract": "To address the challenges of digital intelligence in the digital economy,\nartificial intelligence-generated content (AIGC) has emerged. AIGC uses\nartificial intelligence to assist or replace manual content generation by\ngenerating content based on user-inputted keywords or requirements. The\ndevelopment of large model algorithms has significantly strengthened the\ncapabilities of AIGC, which makes AIGC products a promising generative tool and\nadds convenience to our lives. As an upstream technology, AIGC has unlimited\npotential to support different downstream applications. It is important to\nanalyze AIGC's current capabilities and shortcomings to understand how it can\nbe best utilized in future applications. Therefore, this paper provides an\nextensive overview of AIGC, covering its definition, essential conditions,\ncutting-edge capabilities, and advanced features. Moreover, it discusses the\nbenefits of large-scale pre-trained models and the industrial chain of AIGC.\nFurthermore, the article explores the distinctions between auxiliary generation\nand automatic generation within AIGC, providing examples of text generation.\nThe paper also examines the potential integration of AIGC with the Metaverse.\nLastly, the article highlights existing issues and suggests some future\ndirections for application.",
        "date": "2023-03-26T02:22:12+00:00",
        "label": 1
    },
    "1610.07365": {
        "title": "Introduction: Cognitive Issues in Natural Language Processing",
        "abstract": "This special issue is dedicated to get a better picture of the relationships\nbetween computational linguistics and cognitive science. It specifically raises\ntwo questions: \"what is the potential contribution of computational language\nmodeling to cognitive science?\" and conversely: \"what is the influence of\ncognitive science in contemporary computational linguistics?\"",
        "date": "2016-10-24T11:30:22+00:00",
        "label": 0
    },
    "2304.10778": {
        "title": "Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT",
        "abstract": "Context: AI-assisted code generation tools have become increasingly prevalent\nin software engineering, offering the ability to generate code from natural\nlanguage prompts or partial code inputs. Notable examples of these tools\ninclude GitHub Copilot, Amazon CodeWhisperer, and OpenAI's ChatGPT.\n  Objective: This study aims to compare the performance of these prominent code\ngeneration tools in terms of code quality metrics, such as Code Validity, Code\nCorrectness, Code Security, Code Reliability, and Code Maintainability, to\nidentify their strengths and shortcomings.\n  Method: We assess the code generation capabilities of GitHub Copilot, Amazon\nCodeWhisperer, and ChatGPT using the benchmark HumanEval Dataset. The generated\ncode is then evaluated based on the proposed code quality metrics.\n  Results: Our analysis reveals that the latest versions of ChatGPT, GitHub\nCopilot, and Amazon CodeWhisperer generate correct code 65.2%, 46.3%, and 31.1%\nof the time, respectively. In comparison, the newer versions of GitHub CoPilot\nand Amazon CodeWhisperer showed improvement rates of 18% for GitHub Copilot and\n7% for Amazon CodeWhisperer. The average technical debt, considering code\nsmells, was found to be 8.9 minutes for ChatGPT, 9.1 minutes for GitHub\nCopilot, and 5.6 minutes for Amazon CodeWhisperer.\n  Conclusions: This study highlights the strengths and weaknesses of some of\nthe most popular code generation tools, providing valuable insights for\npractitioners. By comparing these generators, our results may assist\npractitioners in selecting the optimal tool for specific tasks, enhancing their\ndecision-making process.",
        "date": "2023-04-21T07:08:26+00:00",
        "label": 1
    },
    "1310.7911": {
        "title": "Compact manifolds with computable boundaries",
        "abstract": "We investigate conditions under which a co-computably enumerable closed set\nin a computable metric space is computable and prove that in each locally\ncomputable computable metric space each co-computably enumerable compact\nmanifold with computable boundary is computable. In fact, we examine the notion\nof a semi-computable compact set and we prove a more general result: in any\ncomputable metric space each semi-computable compact manifold with computable\nboundary is computable. In particular, each semi-computable compact\n(boundaryless) manifold is computable.",
        "date": "2013-10-29T18:29:13+00:00",
        "label": 0
    },
    "2407.18517": {
        "title": "SLIM: Style-Linguistics Mismatch Model for Generalized Audio Deepfake Detection",
        "abstract": "Audio deepfake detection (ADD) is crucial to combat the misuse of speech\nsynthesized from generative AI models. Existing ADD models suffer from\ngeneralization issues, with a large performance discrepancy between in-domain\nand out-of-domain data. Moreover, the black-box nature of existing models\nlimits their use in real-world scenarios, where explanations are required for\nmodel decisions. To alleviate these issues, we introduce a new ADD model that\nexplicitly uses the StyleLInguistics Mismatch (SLIM) in fake speech to separate\nthem from real speech. SLIM first employs self-supervised pretraining on only\nreal samples to learn the style-linguistics dependency in the real class. The\nlearned features are then used in complement with standard pretrained acoustic\nfeatures (e.g., Wav2vec) to learn a classifier on the real and fake classes.\nWhen the feature encoders are frozen, SLIM outperforms benchmark methods on\nout-of-domain datasets while achieving competitive results on in-domain data.\nThe features learned by SLIM allow us to quantify the (mis)match between style\nand linguistic content in a sample, hence facilitating an explanation of the\nmodel decision.",
        "date": "2024-07-26T05:23:41+00:00",
        "label": 1
    },
    "1711.00354": {
        "title": "JSUT corpus: free large-scale Japanese speech corpus for end-to-end speech synthesis",
        "abstract": "Thanks to improvements in machine learning techniques including deep\nlearning, a free large-scale speech corpus that can be shared between academic\ninstitutions and commercial companies has an important role. However, such a\ncorpus for Japanese speech synthesis does not exist. In this paper, we designed\na novel Japanese speech corpus, named the \"JSUT corpus,\" that is aimed at\nachieving end-to-end speech synthesis. The corpus consists of 10 hours of\nreading-style speech data and its transcription and covers all of the main\npronunciations of daily-use Japanese characters. In this paper, we describe how\nwe designed and analyzed the corpus. The corpus is freely available online.",
        "date": "2017-10-28T05:28:01+00:00",
        "label": 1
    },
    "2111.14203": {
        "title": "How Deep Are the Fakes? Focusing on Audio Deepfake: A Survey",
        "abstract": "Deepfake is content or material that is synthetically generated or\nmanipulated using artificial intelligence (AI) methods, to be passed off as\nreal and can include audio, video, image, and text synthesis. This survey has\nbeen conducted with a different perspective compared to existing survey papers,\nthat mostly focus on just video and image deepfakes. This survey not only\nevaluates generation and detection methods in the different deepfake\ncategories, but mainly focuses on audio deepfakes that are overlooked in most\nof the existing surveys. This paper critically analyzes and provides a unique\nsource of audio deepfake research, mostly ranging from 2016 to 2020. To the\nbest of our knowledge, this is the first survey focusing on audio deepfakes in\nEnglish. This survey provides readers with a summary of 1) different deepfake\ncategories 2) how they could be created and detected 3) the most recent trends\nin this domain and shortcomings in detection methods 4) audio deepfakes, how\nthey are created and detected in more detail which is the main focus of this\npaper. We found that Generative Adversarial Networks(GAN), Convolutional Neural\nNetworks (CNN), and Deep Neural Networks (DNN) are common ways of creating and\ndetecting deepfakes. In our evaluation of over 140 methods we found that the\nmajority of the focus is on video deepfakes and in particular in the generation\nof video deepfakes. We found that for text deepfakes there are more generation\nmethods but very few robust methods for detection, including fake news\ndetection, which has become a controversial area of research because of the\npotential of heavy overlaps with human generation of fake content. This paper\nis an abbreviated version of the full survey and reveals a clear need to\nresearch audio deepfakes and particularly detection of audio deepfakes.",
        "date": "2021-11-28T18:28:30+00:00",
        "label": 1
    },
    "2408.09300": {
        "title": "Malacopula: adversarial automatic speaker verification attacks using a neural-based generalised Hammerstein model",
        "abstract": "We present Malacopula, a neural-based generalised Hammerstein model designed\nto introduce adversarial perturbations to spoofed speech utterances so that\nthey better deceive automatic speaker verification (ASV) systems. Using\nnon-linear processes to modify speech utterances, Malacopula enhances the\neffectiveness of spoofing attacks. The model comprises parallel branches of\npolynomial functions followed by linear time-invariant filters. The adversarial\noptimisation procedure acts to minimise the cosine distance between speaker\nembeddings extracted from spoofed and bona fide utterances. Experiments,\nperformed using three recent ASV systems and the ASVspoof 2019 dataset, show\nthat Malacopula increases vulnerabilities by a substantial margin. However,\nspeech quality is reduced and attacks can be detected effectively under\ncontrolled conditions. The findings emphasise the need to identify new\nvulnerabilities and design defences to protect ASV systems from adversarial\nattacks in the wild.",
        "date": "2024-08-17T21:58:11+00:00",
        "label": 1
    },
    "1904.02892": {
        "title": "WaveCycleGAN2: Time-domain Neural Post-filter for Speech Waveform Generation",
        "abstract": "WaveCycleGAN has recently been proposed to bridge the gap between natural and\nsynthesized speech waveforms in statistical parametric speech synthesis and\nprovides fast inference with a moving average model rather than an\nautoregressive model and high-quality speech synthesis with the adversarial\ntraining. However, the human ear can still distinguish the processed speech\nwaveforms from natural ones. One possible cause of this distinguishability is\nthe aliasing observed in the processed speech waveform via down/up-sampling\nmodules. To solve the aliasing and provide higher quality speech synthesis, we\npropose WaveCycleGAN2, which 1) uses generators without down/up-sampling\nmodules and 2) combines discriminators of the waveform domain and acoustic\nparameter domain. The results show that the proposed method 1) alleviates the\naliasing well, 2) is useful for both speech waveforms generated by\nanalysis-and-synthesis and statistical parametric speech synthesis, and 3)\nachieves a mean opinion score comparable to those of natural speech and speech\nsynthesized by WaveNet (open WaveNet) and WaveGlow while processing speech\nsamples at a rate of more than 150 kHz on an NVIDIA Tesla P100.",
        "date": "2019-04-05T06:53:37+00:00",
        "label": 1
    },
    "2408.16132": {
        "title": "SVDD 2024: The Inaugural Singing Voice Deepfake Detection Challenge",
        "abstract": "With the advancements in singing voice generation and the growing presence of\nAI singers on media platforms, the inaugural Singing Voice Deepfake Detection\n(SVDD) Challenge aims to advance research in identifying AI-generated singing\nvoices from authentic singers. This challenge features two tracks: a controlled\nsetting track (CtrSVDD) and an in-the-wild scenario track (WildSVDD). The\nCtrSVDD track utilizes publicly available singing vocal data to generate\ndeepfakes using state-of-the-art singing voice synthesis and conversion\nsystems. Meanwhile, the WildSVDD track expands upon the existing SingFake\ndataset, which includes data sourced from popular user-generated content\nwebsites. For the CtrSVDD track, we received submissions from 47 teams, with 37\nsurpassing our baselines and the top team achieving a 1.65% equal error rate.\nFor the WildSVDD track, we benchmarked the baselines. This paper reviews these\nresults, discusses key findings, and outlines future directions for SVDD\nresearch.",
        "date": "2024-08-28T20:48:04+00:00",
        "label": 1
    },
    "2403.11778": {
        "title": "Towards the Development of a Real-Time Deepfake Audio Detection System in Communication Platforms",
        "abstract": "Deepfake audio poses a rising threat in communication platforms,\nnecessitating real-time detection for audio stream integrity. Unlike\ntraditional non-real-time approaches, this study assesses the viability of\nemploying static deepfake audio detection models in real-time communication\nplatforms. An executable software is developed for cross-platform\ncompatibility, enabling real-time execution. Two deepfake audio detection\nmodels based on Resnet and LCNN architectures are implemented using the\nASVspoof 2019 dataset, achieving benchmark performances compared to ASVspoof\n2019 challenge baselines. The study proposes strategies and frameworks for\nenhancing these models, paving the way for real-time deepfake audio detection\nin communication platforms. This work contributes to the advancement of audio\nstream security, ensuring robust detection capabilities in dynamic, real-time\ncommunication scenarios.",
        "date": "2024-03-18T13:35:10+00:00",
        "label": 1
    },
    "2308.14970": {
        "title": "Audio Deepfake Detection: A Survey",
        "abstract": "Audio deepfake detection is an emerging active topic. A growing number of\nliteratures have aimed to study deepfake detection algorithms and achieved\neffective performance, the problem of which is far from being solved. Although\nthere are some review literatures, there has been no comprehensive survey that\nprovides researchers with a systematic overview of these developments with a\nunified evaluation. Accordingly, in this survey paper, we first highlight the\nkey differences across various types of deepfake audio, then outline and\nanalyse competitions, datasets, features, classifications, and evaluation of\nstate-of-the-art approaches. For each aspect, the basic techniques, advanced\ndevelopments and major challenges are discussed. In addition, we perform a\nunified comparison of representative features and classifiers on ASVspoof 2021,\nADD 2023 and In-the-Wild datasets for audio deepfake detection, respectively.\nThe survey shows that future research should address the lack of large scale\ndatasets in the wild, poor generalization of existing detection methods to\nunknown fake attacks, as well as interpretability of detection results.",
        "date": "2023-08-29T01:50:01+00:00",
        "label": 1
    },
    "2202.01291": {
        "title": "Computer sciences and synthesis: retrospective and perspective",
        "abstract": "The problem of synthesis in computer sciences, including cybernetics,\nartificial intelligence and system analysis, is analyzed. Main methods of\nrealization this problem are discussed. Ways of search universal method of\ncreation universal synthetic science are represented. As example of such\nuniversal method polymetric analysis is given. Perspective of further\ndevelopment of this research, including application polymetric method for the\nresolution main problems of computer sciences, is analyzed too.",
        "date": "2022-01-26T04:42:45+00:00",
        "label": 0
    },
    "2106.04624": {
        "title": "SpeechBrain: A General-Purpose Speech Toolkit",
        "abstract": "SpeechBrain is an open-source and all-in-one speech toolkit. It is designed\nto facilitate the research and development of neural speech processing\ntechnologies by being simple, flexible, user-friendly, and well-documented.\nThis paper describes the core architecture designed to support several tasks of\ncommon interest, allowing users to naturally conceive, compare and share novel\nspeech processing pipelines. SpeechBrain achieves competitive or\nstate-of-the-art performance in a wide range of speech benchmarks. It also\nprovides training recipes, pretrained models, and inference scripts for popular\nspeech datasets, as well as tutorials which allow anyone with basic Python\nproficiency to familiarize themselves with speech technologies.",
        "date": "2021-06-08T18:22:56+00:00",
        "label": 1
    },
    "2311.15308": {
        "title": "AV-Deepfake1M: A Large-Scale LLM-Driven Audio-Visual Deepfake Dataset",
        "abstract": "The detection and localization of highly realistic deepfake audio-visual\ncontent are challenging even for the most advanced state-of-the-art methods.\nWhile most of the research efforts in this domain are focused on detecting\nhigh-quality deepfake images and videos, only a few works address the problem\nof the localization of small segments of audio-visual manipulations embedded in\nreal videos. In this research, we emulate the process of such content\ngeneration and propose the AV-Deepfake1M dataset. The dataset contains\ncontent-driven (i) video manipulations, (ii) audio manipulations, and (iii)\naudio-visual manipulations for more than 2K subjects resulting in a total of\nmore than 1M videos. The paper provides a thorough description of the proposed\ndata generation pipeline accompanied by a rigorous analysis of the quality of\nthe generated data. The comprehensive benchmark of the proposed dataset\nutilizing state-of-the-art deepfake detection and localization methods\nindicates a significant drop in performance compared to previous datasets. The\nproposed dataset will play a vital role in building the next-generation\ndeepfake localization methods. The dataset and associated code are available at\nhttps://github.com/ControlNet/AV-Deepfake1M .",
        "date": "2023-11-26T14:17:51+00:00",
        "label": 1
    },
    "1512.00407": {
        "title": "Science of Cyber Security as a System of Models and Problems",
        "abstract": "Terms like \"Science of Cyber\" or \"Cyber Science\" have been appearing in\nliterature with growing frequency, and influential organizations initiated\nresearch initiatives toward developing such a science even though it is not\nclearly defined. We propose to define the domain of the science of cyber\nsecurity by noting the most salient artifact within cyber security -- malicious\nsoftware -- and defining the domain as comprised of phenomena that involve\nmalicious software (as well as legitimate software and protocols used\nmaliciously) used to compel a computing device or a network of computing\ndevices to perform actions desired by the perpetrator of malicious software\n(the attacker) and generally contrary to the intent (the policy) of the\nlegitimate owner or operator (the defender) of the computing device(s). We\nfurther define the science of cyber security as the study of relations --\npreferably expressed as theoretically-grounded models -- between attributes,\nstructures and dynamics of: violations of cyber security policy; the network of\ncomputing devices under attack; the defenders' tools and techniques; and the\nattackers' tools and techniques where malicious software plays the central\nrole. We offer a simple formalism of these key objects within cyber science and\nsystematically derive a classification of primary problem classes within cyber\nscience.",
        "date": "2015-11-29T23:54:03+00:00",
        "label": 0
    },
    "2209.10377": {
        "title": "Complexity through Translations for Modal Logic with Recursion",
        "abstract": "This paper studies the complexity of classical modal logics and of their\nextension with fixed-point operators, using translations to transfer results\nacross logics. In particular, we show several complexity results for\nmulti-agent logics via translations to and from the mu-calculus and modal\nlogic, which allow us to transfer known upper and lower bounds. We also use\nthese translations to introduce a terminating tableau system for the logics we\nstudy, based on Kozen's tableau for the mu-calculus, and the one of Fitting and\nMassacci for modal logic.",
        "date": "2022-09-21T14:14:46+00:00",
        "label": 0
    },
    "1111.4755": {
        "title": "Saying Hello World with MOLA - A Solution to the TTC 2011 Instructive Case",
        "abstract": "This paper describes the solution of Hello World transformations in MOLA\ntransformation language. Transformations implementing the task are relatively\nstraightforward and easily inferable from the task specification. The required\nadditional steps related to model import and export are also described.",
        "date": "2011-11-21T05:26:57+00:00",
        "label": 0
    },
    "2312.05187": {
        "title": "Seamless: Multilingual Expressive and Streaming Speech Translation",
        "abstract": "Large-scale automatic speech translation systems today lack key features that\nhelp machine-mediated communication feel seamless when compared to\nhuman-to-human dialogue. In this work, we introduce a family of models that\nenable end-to-end expressive and multilingual translations in a streaming\nfashion. First, we contribute an improved version of the massively multilingual\nand multimodal SeamlessM4T model-SeamlessM4T v2. This newer model,\nincorporating an updated UnitY2 framework, was trained on more low-resource\nlanguage data. SeamlessM4T v2 provides the foundation on which our next two\nmodels are initiated. SeamlessExpressive enables translation that preserves\nvocal styles and prosody. Compared to previous efforts in expressive speech\nresearch, our work addresses certain underexplored aspects of prosody, such as\nspeech rate and pauses, while also preserving the style of one's voice. As for\nSeamlessStreaming, our model leverages the Efficient Monotonic Multihead\nAttention mechanism to generate low-latency target translations without waiting\nfor complete source utterances. As the first of its kind, SeamlessStreaming\nenables simultaneous speech-to-speech/text translation for multiple source and\ntarget languages. To ensure that our models can be used safely and responsibly,\nwe implemented the first known red-teaming effort for multimodal machine\ntranslation, a system for the detection and mitigation of added toxicity, a\nsystematic evaluation of gender bias, and an inaudible localized watermarking\nmechanism designed to dampen the impact of deepfakes. Consequently, we bring\nmajor components from SeamlessExpressive and SeamlessStreaming together to form\nSeamless, the first publicly available system that unlocks expressive\ncross-lingual communication in real-time. The contributions to this work are\npublicly released and accessible at\nhttps://github.com/facebookresearch/seamless_communication",
        "date": "2023-12-08T17:18:42+00:00",
        "label": 1
    },
    "1103.1386": {
        "title": "Physics and computer science: quantum computation and other approaches",
        "abstract": "This is a position paper written as an introduction to the special volume on\nquantum algorithms I edited for the journal Mathematical Structures in Computer\nScience (Volume 20 - Special Issue 06 (Quantum Algorithms), 2010).",
        "date": "2011-03-07T21:00:29+00:00",
        "label": 0
    },
    "2207.01934": {
        "title": "How sustainable is \"common\" data science in terms of power consumption?",
        "abstract": "Continuous developments in data science have brought forth an exponential\nincrease in complexity of machine learning models. Additionally, data\nscientists have become ubiquitous in the private market, academic environments\nand even as a hobby. All of these trends are on a steady rise, and are\nassociated with an increase in power consumption and associated carbon\nfootprint. The increasing carbon footprint of large-scale advanced data science\nhas already received attention, but the latter trend has not. This work aims to\nestimate the contribution of the increasingly popular \"common\" data science to\nthe global carbon footprint. To this end, the power consumption of several\ntypical tasks in the aforementioned common data science tasks will be measured\nand compared to: large-scale \"advanced\" data science, common computer-related\ntasks, and everyday non-computer related tasks. This is done by converting the\nmeasurements to the equivalent unit of \"km driven by car\". Our main findings\nare: \"common\" data science consumes $2.57$ more power than regular computer\nusage, but less than some common everyday power-consuming tasks such as\nlighting or heating; large-scale data science consumes substantially more power\nthan common data science.",
        "date": "2022-07-05T10:15:22+00:00",
        "label": 0
    },
    "2308.12734": {
        "title": "Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion",
        "abstract": "There are growing implications surrounding generative AI in the speech domain\nthat enable voice cloning and real-time voice conversion from one individual to\nanother. This technology poses a significant ethical threat and could lead to\nbreaches of privacy and misrepresentation, thus there is an urgent need for\nreal-time detection of AI-generated speech for DeepFake Voice Conversion. To\naddress the above emerging issues, the DEEP-VOICE dataset is generated in this\nstudy, comprised of real human speech from eight well-known figures and their\nspeech converted to one another using Retrieval-based Voice Conversion.\nPresenting as a binary classification problem of whether the speech is real or\nAI-generated, statistical analysis of temporal audio features through t-testing\nreveals that there are significantly different distributions. Hyperparameter\noptimisation is implemented for machine learning models to identify the source\nof speech. Following the training of 208 individual machine learning models\nover 10-fold cross validation, it is found that the Extreme Gradient Boosting\nmodel can achieve an average classification accuracy of 99.3% and can classify\nspeech in real-time, at around 0.004 milliseconds given one second of speech.\nAll data generated for this study is released publicly for future research on\nAI speech detection.",
        "date": "2023-08-24T12:26:15+00:00",
        "label": 1
    },
    "1706.03825": {
        "title": "SmoothGrad: removing noise by adding noise",
        "abstract": "Explaining the output of a deep network remains a challenge. In the case of\nan image classifier, one type of explanation is to identify pixels that\nstrongly influence the final decision. A starting point for this strategy is\nthe gradient of the class score function with respect to the input image. This\ngradient can be interpreted as a sensitivity map, and there are several\ntechniques that elaborate on this basic idea. This paper makes two\ncontributions: it introduces SmoothGrad, a simple method that can help visually\nsharpen gradient-based sensitivity maps, and it discusses lessons in the\nvisualization of these maps. We publish the code for our experiments and a\nwebsite with our results.",
        "date": "2017-06-12T19:53:30+00:00",
        "label": 1
    },
    "1108.3558": {
        "title": "Proceedings of the 5th Workshop on Membrane Computing and Biologically Inspired Process Calculi (MeCBIC 2011)",
        "abstract": "This volume represents the proceedings of the 5th Workshop on Membrane\nComputing and Biologically Inspired Process Calculi (MeCBIC 2011), held\ntogether with the 12th International Conference on Membrane Computing on 23rd\nAugust 2011 in Fontainebleau, France.",
        "date": "2011-08-17T19:41:29+00:00",
        "label": 0
    }
}