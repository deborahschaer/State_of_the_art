{
    "2308.12950": {
        "title": "Code Llama: Open Foundation Models for Code",
        "abstract": "We release Code Llama, a family of large language models for code based on\nLlama 2 providing state-of-the-art performance among open models, infilling\ncapabilities, support for large input contexts, and zero-shot instruction\nfollowing ability for programming tasks. We provide multiple flavors to cover a\nwide range of applications: foundation models (Code Llama), Python\nspecializations (Code Llama - Python), and instruction-following models (Code\nLlama - Instruct) with 7B, 13B, 34B and 70B parameters each. All models are\ntrained on sequences of 16k tokens and show improvements on inputs with up to\n100k tokens. 7B, 13B and 70B Code Llama and Code Llama - Instruct variants\nsupport infilling based on surrounding content. Code Llama reaches\nstate-of-the-art performance among open models on several code benchmarks, with\nscores of up to 67% and 65% on HumanEval and MBPP, respectively. Notably, Code\nLlama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our\nmodels outperform every other publicly available model on MultiPL-E. We release\nCode Llama under a permissive license that allows for both research and\ncommercial use.",
        "date": "2023-08-24T17:39:13+00:00",
        "label": 1
    },
    "2309.05519": {
        "title": "NExT-GPT: Any-to-Any Multimodal LLM",
        "abstract": "While recently Multimodal Large Language Models (MM-LLMs) have made exciting\nstrides, they mostly fall prey to the limitation of only input-side multimodal\nunderstanding, without the ability to produce content in multiple modalities.\nAs we humans always perceive the world and communicate with people through\nvarious modalities, developing any-to-any MM-LLMs capable of accepting and\ndelivering content in any modality becomes essential to human-level AI. To fill\nthe gap, we present an end-to-end general-purpose any-to-any MM-LLM system,\nNExT-GPT. We connect an LLM with multimodal adaptors and different diffusion\ndecoders, enabling NExT-GPT to perceive inputs and generate outputs in\narbitrary combinations of text, images, videos, and audio. By leveraging the\nexisting well-trained highly-performing encoders and decoders, NExT-GPT is\ntuned with only a small amount of parameter (1%) of certain projection layers,\nwhich not only benefits low-cost training and also facilitates convenient\nexpansion to more potential modalities. Moreover, we introduce a\nmodality-switching instruction tuning (MosIT) and manually curate a\nhigh-quality dataset for MosIT, based on which NExT-GPT is empowered with\ncomplex cross-modal semantic understanding and content generation. Overall, our\nresearch showcases the promising possibility of building an AI agent capable of\nmodeling universal modalities, paving the way for more human-like AI research\nin the community. Project page: https://next-gpt.github.io/",
        "date": "2023-09-11T15:02:25+00:00",
        "label": 1
    },
    "2105.01707": {
        "title": "ABET Accreditation: A Way Forward for PDC Education",
        "abstract": "With parallel and distributed computing (PDC) now wide-spread, modern\ncomputing programs must incorporate PDC within the curriculum. ACM and IEEE\nComputer Society's Computer Science curricular guidelines have recommended\nexposure to PDC concepts since 2013. More recently, a variety of initiatives\nhave made PDC curricular content, lectures, and labs freely available for\nundergraduate computer science programs. Despite these efforts, progress in\nensuring computer science students graduate with sufficient PDC exposure has\nbeen uneven.\n  This paper discusses the impact of ABET's revised criteria that have required\nexposure to PDC to achieve accreditation for computer science programs since\n2018. The authors reviewed 20 top ABET-accredited computer science programs and\nanalyzed how they covered the required PDC components in their curricula. Using\ntheir own institutions as case studies, the authors examine in detail how three\ndifferent ABET-accredited computer science programs covered PDC using different\napproaches, yet meeting the PDC requirements of these ABET criteria. The paper\nalso shows how ACM/IEEE Computer Society curricular guidelines for computer\nengineering and software engineering programs, along with ABET accreditation\ncriteria, can cover PDC.",
        "date": "2021-05-04T18:58:18+00:00",
        "label": 0
    },
    "2207.01934": {
        "title": "How sustainable is \"common\" data science in terms of power consumption?",
        "abstract": "Continuous developments in data science have brought forth an exponential\nincrease in complexity of machine learning models. Additionally, data\nscientists have become ubiquitous in the private market, academic environments\nand even as a hobby. All of these trends are on a steady rise, and are\nassociated with an increase in power consumption and associated carbon\nfootprint. The increasing carbon footprint of large-scale advanced data science\nhas already received attention, but the latter trend has not. This work aims to\nestimate the contribution of the increasingly popular \"common\" data science to\nthe global carbon footprint. To this end, the power consumption of several\ntypical tasks in the aforementioned common data science tasks will be measured\nand compared to: large-scale \"advanced\" data science, common computer-related\ntasks, and everyday non-computer related tasks. This is done by converting the\nmeasurements to the equivalent unit of \"km driven by car\". Our main findings\nare: \"common\" data science consumes $2.57$ more power than regular computer\nusage, but less than some common everyday power-consuming tasks such as\nlighting or heating; large-scale data science consumes substantially more power\nthan common data science.",
        "date": "2022-07-05T10:15:22+00:00",
        "label": 0
    },
    "1610.04276": {
        "title": "Perspectives on Surgical Data Science",
        "abstract": "The availability of large amounts of data together with advances in\nanalytical techniques afford an opportunity to address difficult challenges in\nensuring that healthcare is safe, effective, efficient, patient-centered,\nequitable, and timely. Surgical care and training stand to tremendously gain\nthrough surgical data science. Herein, we discuss a few perspectives on the\nscope and objectives for surgical data science.",
        "date": "2016-10-13T22:06:46+00:00",
        "label": 0
    },
    "2209.14375": {
        "title": "Improving alignment of dialogue agents via targeted human judgements",
        "abstract": "We present Sparrow, an information-seeking dialogue agent trained to be more\nhelpful, correct, and harmless compared to prompted language model baselines.\nWe use reinforcement learning from human feedback to train our models with two\nnew additions to help human raters judge agent behaviour. First, to make our\nagent more helpful and harmless, we break down the requirements for good\ndialogue into natural language rules the agent should follow, and ask raters\nabout each rule separately. We demonstrate that this breakdown enables us to\ncollect more targeted human judgements of agent behaviour and allows for more\nefficient rule-conditional reward models. Second, our agent provides evidence\nfrom sources supporting factual claims when collecting preference judgements\nover model statements. For factual questions, evidence provided by Sparrow\nsupports the sampled response 78% of the time. Sparrow is preferred more often\nthan baselines while being more resilient to adversarial probing by humans,\nviolating our rules only 8% of the time when probed. Finally, we conduct\nextensive analyses showing that though our model learns to follow our rules it\ncan exhibit distributional biases.",
        "date": "2022-09-28T19:04:43+00:00",
        "label": 1
    },
    "2302.07842": {
        "title": "Augmented Language Models: a Survey",
        "abstract": "This survey reviews works in which language models (LMs) are augmented with\nreasoning skills and the ability to use tools. The former is defined as\ndecomposing a potentially complex task into simpler subtasks while the latter\nconsists in calling external modules such as a code interpreter. LMs can\nleverage these augmentations separately or in combination via heuristics, or\nlearn to do so from demonstrations. While adhering to a standard missing tokens\nprediction objective, such augmented LMs can use various, possibly\nnon-parametric external modules to expand their context processing ability,\nthus departing from the pure language modeling paradigm. We therefore refer to\nthem as Augmented Language Models (ALMs). The missing token objective allows\nALMs to learn to reason, use tools, and even act, while still performing\nstandard natural language tasks and even outperforming most regular LMs on\nseveral benchmarks. In this work, after reviewing current advance in ALMs, we\nconclude that this new research direction has the potential to address common\nlimitations of traditional LMs such as interpretability, consistency, and\nscalability issues.",
        "date": "2023-02-15T18:25:52+00:00",
        "label": 1
    },
    "1506.00555": {
        "title": "Writing and Publishing Scientific Articles in Computer Science",
        "abstract": "Over 15 years of teaching, advising students and coordinating scientific\nresearch activities and projects in computer science, we have observed the\ndifficulties of students to write scientific papers to present the results of\ntheir research practices. In addition, they repeatedly have doubts about the\npublishing process. In this article we propose a conceptual framework to\nsupport the writing and publishing of scientific papers in computer science,\nproviding a kind of guide for computer science students to effectively present\nthe results of their research practices, particularly for experimental\nresearch.",
        "date": "2015-06-01T16:09:53+00:00",
        "label": 0
    },
    "2206.03276": {
        "title": "Oxford-style Debates in Telecommunication and Computer Science Education",
        "abstract": "Oxford-style debating is a well-known tool in social sciences. Such formal\ndiscussions on particular topics are widely used by historians and\nsociologists. However, when we try to go beyond standard thinking, it turns out\nthat Oxford-style debating can be a great educational tool in telecommunication\nand computer science. This article presents this unusual method of education at\ntechnical universities and in the IT industry, and describes its features and\nchallenges. Best practices and examples of debating are provided, taking into\naccount emerging topics in telecommunications and computer science, such as\ncybersecurity. The article also contains feedback from IT engineers who\nparticipated in Oxford-style debates. All this aims to encourage this form of\neducation in telecommunication and computer science.",
        "date": "2022-06-03T10:42:31+00:00",
        "label": 0
    },
    "1706.01538": {
        "title": "On Computation of Matrix Mittag-Leffler Function",
        "abstract": "A method for computation of the matrix Mittag-Leffler function is presented.\nThe method is based on Jordan canonical form and implemented as a Matlab\nroutine.",
        "date": "2017-06-05T20:48:07+00:00",
        "label": 0
    },
    "1311.5006": {
        "title": "Indagini in Deep Inference",
        "abstract": "Italian master's thesis in Computer Science. It is an overview of the\nstandard tecniques developed in the field of Proof Theory, ending with some\nresults in the new field of Deep Inference, plus an original contribution\ntrying to relate Deep Inference and Process Algebras.",
        "date": "2013-11-20T10:46:35+00:00",
        "label": 0
    },
    "1909.04486": {
        "title": "Data Science in Biomedicine",
        "abstract": "We highlight the role of Data Science in Biomedicine. Our manuscript goes\nfrom the general to the particular, presenting a global definition of Data\nScience and showing the trend for this discipline together with the terms of\ncloud computing and big data. In addition, since Data Science is mostly related\nto areas like economy or business, we describe its importance in biomedicine.\nBiomedical Data Science (BDS) presents the challenge of dealing with data\ncoming from a range of biological and medical research, focusing on\nmethodologies to advance the biomedical science discoveries, in an\ninterdisciplinary context.",
        "date": "2019-09-09T11:31:40+00:00",
        "label": 0
    },
    "1106.2769": {
        "title": "Co-c.e. spheres and cells in computable metric spaces",
        "abstract": "We investigate conditions under which a co-computably enumerable set in a\ncomputable metric space is computable. Using higher-dimensional chains and\nspherical chains we prove that in each computable metric space which is locally\ncomputable each co-computably enumerable sphere is computable and each co-c.e.\ncell with co-c.e. boundary sphere is computable.",
        "date": "2011-06-14T17:46:06+00:00",
        "label": 0
    },
    "1907.02860": {
        "title": "Truly Concurrent Bisimilarities are Game Equivalent",
        "abstract": "We design games for truly concurrent bisimilarities, including strongly truly\nconcurrent bisimilarities and branching truly concurrent bisimilarities, such\nas pomset bisimilarities, step bisimilarities, history-preserving\nbisimilarities and hereditary history-preserving bisimilarities.",
        "date": "2019-06-27T05:56:54+00:00",
        "label": 0
    },
    "0609110": {
        "title": "Algebraic recognizability of languages",
        "abstract": "Recognizable languages of finite words are part of every computer science\ncursus, and they are routinely described as a cornerstone for applications and\nfor theory. We would like to briefly explore why that is, and how this\nword-related notion extends to more complex models, such as those developed for\nmodeling distributed or timed behaviors.",
        "date": "2006-09-19T15:21:08+00:00",
        "label": 0
    },
    "2308.11432": {
        "title": "A Survey on Large Language Model based Autonomous Agents",
        "abstract": "Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.",
        "date": "2023-08-22T13:30:37+00:00",
        "label": 1
    },
    "1710.03090": {
        "title": "Theoretical Computer Science for the Working Category Theorist",
        "abstract": "Theoretical computer science discusses foundational issues about\ncomputations. It asks and answers questions such as \"What is a computation?\",\n\"What is computable?\", \"What is efficiently computable?\",\"What is\ninformation?\", \"What is random?\", \"What is an algorithm?\", etc. We will present\nmany of the major themes and theorems with the basic language of category\ntheory. Surprisingly, many interesting theorems and concepts of theoretical\ncomputer science are easy consequences of functoriality and composition when\nyou look at the right categories and functors connecting them.",
        "date": "2017-10-04T19:19:00+00:00",
        "label": 0
    },
    "1610.07365": {
        "title": "Introduction: Cognitive Issues in Natural Language Processing",
        "abstract": "This special issue is dedicated to get a better picture of the relationships\nbetween computational linguistics and cognitive science. It specifically raises\ntwo questions: \"what is the potential contribution of computational language\nmodeling to cognitive science?\" and conversely: \"what is the influence of\ncognitive science in contemporary computational linguistics?\"",
        "date": "2016-10-24T11:30:22+00:00",
        "label": 0
    },
    "2401.03568": {
        "title": "Agent AI: Surveying the Horizons of Multimodal Interaction",
        "abstract": "Multi-modal AI systems will likely become a ubiquitous presence in our\neveryday lives. A promising approach to making these systems more interactive\nis to embody them as agents within physical and virtual environments. At\npresent, systems leverage existing foundation models as the basic building\nblocks for the creation of embodied agents. Embedding agents within such\nenvironments facilitates the ability of models to process and interpret visual\nand contextual data, which is critical for the creation of more sophisticated\nand context-aware AI systems. For example, a system that can perceive user\nactions, human behavior, environmental objects, audio expressions, and the\ncollective sentiment of a scene can be used to inform and direct agent\nresponses within the given environment. To accelerate research on agent-based\nmultimodal intelligence, we define \"Agent AI\" as a class of interactive systems\nthat can perceive visual stimuli, language inputs, and other\nenvironmentally-grounded data, and can produce meaningful embodied actions. In\nparticular, we explore systems that aim to improve agents based on\nnext-embodied action prediction by incorporating external knowledge,\nmulti-sensory inputs, and human feedback. We argue that by developing agentic\nAI systems in grounded environments, one can also mitigate the hallucinations\nof large foundation models and their tendency to generate environmentally\nincorrect outputs. The emerging field of Agent AI subsumes the broader embodied\nand agentic aspects of multimodal interactions. Beyond agents acting and\ninteracting in the physical world, we envision a future where people can easily\ncreate any virtual reality or simulated scene and interact with agents embodied\nwithin the virtual environment.",
        "date": "2024-01-07T19:11:18+00:00",
        "label": 1
    },
    "1003.5716": {
        "title": "Proceedings First International Workshop on Linearity",
        "abstract": "This volume contains the proceedings of LINEARITY 2009: the first\nInternational Workshop on Linearity, which took place 12th September 2009 in\nCoimbra, Portugal. The workshop was a satellite event of CSL 2009, the 18th\nEACSL Annual Conference on Computer Science Logic.",
        "date": "2010-03-30T01:48:23+00:00",
        "label": 0
    },
    "2108.12409": {
        "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation",
        "abstract": "Since the introduction of the transformer model by Vaswani et al. (2017), a\nfundamental question has yet to be answered: how does a model achieve\nextrapolation at inference time for sequences that are longer than it saw\nduring training? We first show that extrapolation can be enabled by simply\nchanging the position representation method, though we find that current\nmethods do not allow for efficient extrapolation. We therefore introduce a\nsimpler and more efficient position method, Attention with Linear Biases\n(ALiBi). ALiBi does not add positional embeddings to word embeddings; instead,\nit biases query-key attention scores with a penalty that is proportional to\ntheir distance. We show that this method trains a 1.3 billion parameter model\non input sequences of length 1024 that extrapolates to input sequences of\nlength 2048, achieving the same perplexity as a sinusoidal position embedding\nmodel trained on inputs of length 2048 but training 11% faster and using 11%\nless memory. ALiBi's inductive bias towards recency also leads it to outperform\nmultiple strong position methods on the WikiText-103 benchmark.",
        "date": "2021-08-27T17:35:06+00:00",
        "label": 1
    },
    "2302.12813": {
        "title": "Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback",
        "abstract": "Large language models (LLMs), such as ChatGPT, are able to generate\nhuman-like, fluent responses for many downstream tasks, e.g., task-oriented\ndialog and question answering. However, applying LLMs to real-world,\nmission-critical applications remains challenging mainly due to their tendency\nto generate hallucinations and their inability to use external knowledge. This\npaper proposes a LLM-Augmenter system, which augments a black-box LLM with a\nset of plug-and-play modules. Our system makes the LLM generate responses\ngrounded in external knowledge, e.g., stored in task-specific databases. It\nalso iteratively revises LLM prompts to improve model responses using feedback\ngenerated by utility functions, e.g., the factuality score of a LLM-generated\nresponse. The effectiveness of LLM-Augmenter is empirically validated on two\ntypes of scenarios, task-oriented dialog and open-domain question answering.\nLLM-Augmenter significantly reduces ChatGPT's hallucinations without\nsacrificing the fluency and informativeness of its responses. We make the\nsource code and models publicly available.",
        "date": "2023-02-24T18:48:43+00:00",
        "label": 1
    },
    "1809.02789": {
        "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering",
        "abstract": "We present a new kind of question answering dataset, OpenBookQA, modeled\nafter open book exams for assessing human understanding of a subject. The open\nbook that comes with our questions is a set of 1329 elementary level science\nfacts. Roughly 6000 questions probe an understanding of these facts and their\napplication to novel situations. This requires combining an open book fact\n(e.g., metals conduct electricity) with broad common knowledge (e.g., a suit of\narmor is made of metal) obtained from other sources. While existing QA datasets\nover documents or knowledge bases, being generally self-contained, focus on\nlinguistic understanding, OpenBookQA probes a deeper understanding of both the\ntopic---in the context of common knowledge---and the language it is expressed\nin. Human performance on OpenBookQA is close to 92%, but many state-of-the-art\npre-trained QA methods perform surprisingly poorly, worse than several simple\nneural baselines we develop. Our oracle experiments designed to circumvent the\nknowledge retrieval bottleneck demonstrate the value of both the open book and\nadditional facts. We leave it as a challenge to solve the retrieval problem in\nthis multi-hop setting and to close the large gap to human performance.",
        "date": "2018-09-08T11:47:16+00:00",
        "label": 1
    },
    "1709.00103": {
        "title": "Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning",
        "abstract": "A significant amount of the world's knowledge is stored in relational\ndatabases. However, the ability for users to retrieve facts from a database is\nlimited due to a lack of understanding of query languages such as SQL. We\npropose Seq2SQL, a deep neural network for translating natural language\nquestions to corresponding SQL queries. Our model leverages the structure of\nSQL queries to significantly reduce the output space of generated queries.\nMoreover, we use rewards from in-the-loop query execution over the database to\nlearn a policy to generate unordered parts of the query, which we show are less\nsuitable for optimization via cross entropy loss. In addition, we will publish\nWikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL\nqueries distributed across 24241 tables from Wikipedia. This dataset is\nrequired to train our model and is an order of magnitude larger than comparable\ndatasets. By applying policy-based reinforcement learning with a query\nexecution environment to WikiSQL, our model Seq2SQL outperforms attentional\nsequence to sequence models, improving execution accuracy from 35.9% to 59.4%\nand logical form accuracy from 23.4% to 48.3%.",
        "date": "2017-08-31T23:12:15+00:00",
        "label": 1
    },
    "2305.00347": {
        "title": "Positionality of mean-payoff games on infinite graphs",
        "abstract": "This short note establishes positionality of mean-payoff games over infinite\ngame graphs by constructing a well-founded monotone universal graph.",
        "date": "2023-04-29T21:43:31+00:00",
        "label": 0
    },
    "2306.13304": {
        "title": "ToolQA: A Dataset for LLM Question Answering with External Tools",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in\nvarious NLP tasks, but they still suffer from challenges such as hallucination\nand weak numerical reasoning. To overcome these challenges, external tools can\nbe used to enhance LLMs' question-answering abilities. However, current\nevaluation methods do not distinguish between questions that can be answered\nusing LLMs' internal knowledge and those that require external information\nthrough tool use. To address this issue, we introduce a new dataset called\nToolQA, which is designed to faithfully evaluate LLMs' ability to use external\ntools for question answering. Our development of ToolQA involved a scalable,\nautomated process for dataset curation, along with 13 specialized tools\ndesigned for interaction with external knowledge in order to answer questions.\nImportantly, we strive to minimize the overlap between our benchmark data and\nLLMs' pre-training data, enabling a more precise evaluation of LLMs' tool-use\nreasoning abilities. We conducted an in-depth diagnosis of existing tool-use\nLLMs to highlight their strengths, weaknesses, and potential improvements. Our\nfindings set a new benchmark for evaluating LLMs and suggest new directions for\nfuture advancements. Our data and code are freely available to the broader\nscientific community on GitHub.",
        "date": "2023-06-23T05:43:28+00:00",
        "label": 1
    },
    "2310.16944": {
        "title": "Zephyr: Direct Distillation of LM Alignment",
        "abstract": "We aim to produce a smaller language model that is aligned to user intent.\nPrevious research has shown that applying distilled supervised fine-tuning\n(dSFT) on larger models significantly improves task accuracy; however, these\nmodels are unaligned, i.e. they do not respond well to natural prompts. To\ndistill this property, we experiment with the use of preference data from AI\nFeedback (AIF). Starting from a dataset of outputs ranked by a teacher model,\nwe apply distilled direct preference optimization (dDPO) to learn a chat model\nwith significantly improved intent alignment. The approach requires only a few\nhours of training without any additional sampling during fine-tuning. The final\nresult, Zephyr-7B, sets the state-of-the-art on chat benchmarks for 7B\nparameter models, and requires no human annotation. In particular, results on\nMT-Bench show that Zephyr-7B surpasses Llama2-Chat-70B, the best open-access\nRLHF-based model. Code, models, data, and tutorials for the system are\navailable at https://github.com/huggingface/alignment-handbook.",
        "date": "2023-10-25T19:25:16+00:00",
        "label": 1
    },
    "1310.6323": {
        "title": "Logic in the Lab",
        "abstract": "This file summarizes the plenary talk on laboratory experiments on logic at\nthe TARK 2013 - 14th Conference on Theoretical Aspects of Rationality and\nKnowledge.",
        "date": "2013-10-23T18:34:56+00:00",
        "label": 0
    },
    "2212.13138": {
        "title": "Large Language Models Encode Clinical Knowledge",
        "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language understanding and generation, but the quality bar for medical\nand clinical applications is high. Today, attempts to assess models' clinical\nknowledge typically rely on automated evaluations on limited benchmarks. There\nis no standard to evaluate model predictions and reasoning across a breadth of\ntasks. To address this, we present MultiMedQA, a benchmark combining six\nexisting open question answering datasets spanning professional medical exams,\nresearch, and consumer queries; and HealthSearchQA, a new free-response dataset\nof medical questions searched online. We propose a framework for human\nevaluation of model answers along multiple axes including factuality,\nprecision, possible harm, and bias. In addition, we evaluate PaLM (a\n540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM, on\nMultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves\nstate-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA,\nMedMCQA, PubMedQA, MMLU clinical topics), including 67.6% accuracy on MedQA (US\nMedical License Exam questions), surpassing prior state-of-the-art by over 17%.\nHowever, human evaluation reveals key gaps in Flan-PaLM responses. To resolve\nthis we introduce instruction prompt tuning, a parameter-efficient approach for\naligning LLMs to new domains using a few exemplars. The resulting model,\nMed-PaLM, performs encouragingly, but remains inferior to clinicians. We show\nthat comprehension, recall of knowledge, and medical reasoning improve with\nmodel scale and instruction prompt tuning, suggesting the potential utility of\nLLMs in medicine. Our human evaluations reveal important limitations of today's\nmodels, reinforcing the importance of both evaluation frameworks and method\ndevelopment in creating safe, helpful LLM models for clinical applications.",
        "date": "2022-12-26T14:28:24+00:00",
        "label": 1
    },
    "2311.05437": {
        "title": "LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents",
        "abstract": "LLaVA-Plus is a general-purpose multimodal assistant that expands the\ncapabilities of large multimodal models. It maintains a skill repository of\npre-trained vision and vision-language models and can activate relevant tools\nbased on users' inputs to fulfill real-world tasks. LLaVA-Plus is trained on\nmultimodal instruction-following data to acquire the ability to use tools,\ncovering visual understanding, generation, external knowledge retrieval, and\ncompositions. Empirical results show that LLaVA-Plus outperforms LLaVA in\nexisting capabilities and exhibits new ones. It is distinct in that the image\nquery is directly grounded and actively engaged throughout the entire human-AI\ninteraction sessions, significantly improving tool use performance and enabling\nnew scenarios.",
        "date": "2023-11-09T15:22:26+00:00",
        "label": 1
    },
    "1601.05973": {
        "title": "Science Learning via Participation in Online Citizen Science",
        "abstract": "We investigate the development of scientific content knowledge of volunteers\nparticipating in online citizen science projects in the Zooniverse\n(www.zooniverse.org), including the astronomy projects Galaxy Zoo\n(www.galaxyzoo.org) and Planet Hunters (www.planethunters.org). We use\neconometric methods to test how measures of project participation relate to\nsuccess in a science quiz, controlling for factors known to correlate with\nscientific knowledge. Citizen scientists believe they are learning about both\nthe content and processes of science through their participation. Won't don't\ndirectly test the latter, but we find evidence to support the former - that\nmore actively engaged participants perform better in a project-specific science\nknowledge quiz, even after controlling for their general science knowledge. We\ninterpret this as evidence of learning of science content inspired by\nparticipation in online citizen science.",
        "date": "2016-01-22T12:23:10+00:00",
        "label": 0
    },
    "2006.15595": {
        "title": "Rethinking Positional Encoding in Language Pre-training",
        "abstract": "In this work, we investigate the positional encoding methods used in language\npre-training (e.g., BERT) and identify several problems in the existing\nformulations. First, we show that in the absolute positional encoding, the\naddition operation applied on positional embeddings and word embeddings brings\nmixed correlations between the two heterogeneous information resources. It may\nbring unnecessary randomness in the attention and further limit the\nexpressiveness of the model. Second, we question whether treating the position\nof the symbol \\texttt{[CLS]} the same as other words is a reasonable design,\nconsidering its special role (the representation of the entire sentence) in the\ndownstream tasks. Motivated from above analysis, we propose a new positional\nencoding method called \\textbf{T}ransformer with \\textbf{U}ntied\n\\textbf{P}ositional \\textbf{E}ncoding (TUPE). In the self-attention module,\nTUPE computes the word contextual correlation and positional correlation\nseparately with different parameterizations and then adds them together. This\ndesign removes the mixed and noisy correlations over heterogeneous embeddings\nand offers more expressiveness by using different projection matrices.\nFurthermore, TUPE unties the \\texttt{[CLS]} symbol from other positions, making\nit easier to capture information from all positions. Extensive experiments and\nablation studies on GLUE benchmark demonstrate the effectiveness of the\nproposed method. Codes and models are released at\nhttps://github.com/guolinke/TUPE.",
        "date": "2020-06-28T13:11:02+00:00",
        "label": 1
    },
    "2301.04788": {
        "title": "Language Cognition and Language Computation -- Human and Machine Language Understanding",
        "abstract": "Language understanding is a key scientific issue in the fields of cognitive\nand computer science. However, the two disciplines differ substantially in the\nspecific research questions. Cognitive science focuses on analyzing the\nspecific mechanism of the brain and investigating the brain's response to\nlanguage; few studies have examined the brain's language system as a whole. By\ncontrast, computer scientists focus on the efficiency of practical applications\nwhen choosing research questions but may ignore the most essential laws of\nlanguage. Given these differences, can a combination of the disciplines offer\nnew insights for building intelligent language models and studying language\ncognitive mechanisms? In the following text, we first review the research\nquestions, history, and methods of language understanding in cognitive and\ncomputer science, focusing on the current progress and challenges. We then\ncompare and contrast the research of language understanding in cognitive and\ncomputer sciences. Finally, we review existing work that combines insights from\nlanguage cognition and language computation and offer prospects for future\ndevelopment trends.",
        "date": "2023-01-12T02:37:00+00:00",
        "label": 0
    },
    "2402.06196": {
        "title": "Large Language Models: A Survey",
        "abstract": "Large Language Models (LLMs) have drawn a lot of attention due to their\nstrong performance on a wide range of natural language tasks, since the release\nof ChatGPT in November 2022. LLMs' ability of general-purpose language\nunderstanding and generation is acquired by training billions of model's\nparameters on massive amounts of text data, as predicted by scaling laws\n\\cite{kaplan2020scaling,hoffmann2022training}. The research area of LLMs, while\nvery recent, is evolving rapidly in many different ways. In this paper, we\nreview some of the most prominent LLMs, including three popular LLM families\n(GPT, LLaMA, PaLM), and discuss their characteristics, contributions and\nlimitations. We also give an overview of techniques developed to build, and\naugment LLMs. We then survey popular datasets prepared for LLM training,\nfine-tuning, and evaluation, review widely used LLM evaluation metrics, and\ncompare the performance of several popular LLMs on a set of representative\nbenchmarks. Finally, we conclude the paper by discussing open challenges and\nfuture research directions.",
        "date": "2024-02-09T05:37:09+00:00",
        "label": 1
    },
    "2212.12017": {
        "title": "OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization",
        "abstract": "Recent work has shown that fine-tuning large pre-trained language models on a\ncollection of tasks described via instructions, a.k.a. instruction-tuning,\nimproves their zero and few-shot generalization to unseen tasks. However, there\nis a limited understanding of the performance trade-offs of different decisions\nmade during the instruction-tuning process. These decisions include the scale\nand diversity of the instruction-tuning benchmark, different task sampling\nstrategies, fine-tuning with and without demonstrations, training using\nspecialized datasets for reasoning and dialogue, and finally, the fine-tuning\nobjectives themselves. In this paper, we characterize the effect of\ninstruction-tuning decisions on downstream task performance when scaling both\nmodel and benchmark sizes. To this end, we create OPT-IML Bench: a large\nbenchmark for Instruction Meta-Learning (IML) of 2000 NLP tasks consolidated\ninto task categories from 8 existing benchmarks, and prepare an evaluation\nframework to measure three types of model generalizations: to tasks from fully\nheld-out categories, to held-out tasks from seen categories, and to held-out\ninstances from seen tasks. Through the lens of this framework, we first present\ninsights about instruction-tuning decisions as applied to OPT-30B and further\nexploit these insights to train OPT-IML 30B and 175B, which are\ninstruction-tuned versions of OPT. OPT-IML demonstrates all three\ngeneralization abilities at both scales on four different evaluation benchmarks\nwith diverse tasks and input formats -- PromptSource, FLAN,\nSuper-NaturalInstructions, and UnifiedSKG. Not only does it significantly\noutperform OPT on all benchmarks but is also highly competitive with existing\nmodels fine-tuned on each specific benchmark. We release OPT-IML at both\nscales, together with the OPT-IML Bench evaluation framework.",
        "date": "2022-12-22T19:56:09+00:00",
        "label": 1
    },
    "2209.10377": {
        "title": "Complexity through Translations for Modal Logic with Recursion",
        "abstract": "This paper studies the complexity of classical modal logics and of their\nextension with fixed-point operators, using translations to transfer results\nacross logics. In particular, we show several complexity results for\nmulti-agent logics via translations to and from the mu-calculus and modal\nlogic, which allow us to transfer known upper and lower bounds. We also use\nthese translations to introduce a terminating tableau system for the logics we\nstudy, based on Kozen's tableau for the mu-calculus, and the one of Fitting and\nMassacci for modal logic.",
        "date": "2022-09-21T14:14:46+00:00",
        "label": 0
    },
    "2210.13526": {
        "title": "Computational Inference in Cognitive Science: Operational, Societal and Ethical Considerations",
        "abstract": "Emerging research frontiers and computational advances have gradually\ntransformed cognitive science into a multidisciplinary and data-driven field.\nAs a result, there is a proliferation of cognitive theories investigated and\ninterpreted from different academic lens and in different levels of\nabstraction. We formulate this applied aspect of this challenge as the\ncomputational cognitive inference, and describe the major routes of\ncomputational approaches. To balance the potential optimism alongside the speed\nand scale of the data-driven era of cognitive science, we propose to inspect\nthis trend in more empirical terms by identifying the operational challenges,\nsocietal impacts and ethical guidelines in conducting research and interpreting\nresults from the computational inference in cognitive science.",
        "date": "2022-10-24T18:27:27+00:00",
        "label": 0
    },
    "2307.16650": {
        "title": "ChatGPT for Teaching and Learning: An Experience from Data Science Education",
        "abstract": "ChatGPT, an implementation and application of large language models, has\ngained significant popularity since its initial release. Researchers have been\nexploring ways to harness the practical benefits of ChatGPT in real-world\nscenarios. Educational researchers have investigated its potential in various\nsubjects, e.g., programming, mathematics, finance, clinical decision support,\netc. However, there has been limited attention given to its application in data\nscience education. This paper aims to bridge that gap by utilizing ChatGPT in a\ndata science course, gathering perspectives from students, and presenting our\nexperiences and feedback on using ChatGPT for teaching and learning in data\nscience education. The findings not only distinguish data science education\nfrom other disciplines but also uncover new opportunities and challenges\nassociated with incorporating ChatGPT into the data science curriculum.",
        "date": "2023-07-31T13:31:19+00:00",
        "label": 0
    },
    "2309.00267": {
        "title": "RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback",
        "abstract": "Reinforcement learning from human feedback (RLHF) has proven effective in\naligning large language models (LLMs) with human preferences. However,\ngathering high-quality human preference labels can be a time-consuming and\nexpensive endeavor. RL from AI Feedback (RLAIF), introduced by Bai et al.,\noffers a promising alternative that leverages a powerful off-the-shelf LLM to\ngenerate preferences in lieu of human annotators. Across the tasks of\nsummarization, helpful dialogue generation, and harmless dialogue generation,\nRLAIF achieves comparable or superior performance to RLHF, as rated by human\nevaluators. Furthermore, RLAIF demonstrates the ability to outperform a\nsupervised fine-tuned baseline even when the LLM preference labeler is the same\nsize as the policy. In another experiment, directly prompting the LLM for\nreward scores achieves superior performance to the canonical RLAIF setup, where\nLLM preference labels are first distilled into a reward model. Finally, we\nconduct extensive studies on techniques for generating aligned AI preferences.\nOur results suggest that RLAIF can achieve human-level performance, offering a\npotential solution to the scalability limitations of RLHF.",
        "date": "2023-09-01T05:53:33+00:00",
        "label": 1
    },
    "1304.7858": {
        "title": "Abstract Stobjs and Their Application to ISA Modeling",
        "abstract": "We introduce a new ACL2 feature, the abstract stobj, and show how to apply it\nto modeling the instruction set architecture of a microprocessor. Benefits of\nabstract stobjs over traditional (\"concrete\") stobjs can include faster\nexecution, support for symbolic simulation, more efficient reasoning, and\nresilience of proof developments under modeling optimization.",
        "date": "2013-04-30T04:14:22+00:00",
        "label": 0
    },
    "1404.6487": {
        "title": "Computability of 1-manifolds",
        "abstract": "A semi-computable set S in a computable metric space need not be computable.\nHowever, in some cases, if S has certain topological properties, we can\nconclude that S is computable. It is known that if a semi-computable set S is a\ncompact manifold with boundary, then the computability of \\deltaS implies the\ncomputability of S. In this paper we examine the case when S is a 1-manifold\nwith boundary, not necessarily compact. We show that a similar result holds in\nthis case under assumption that S has finitely many components.",
        "date": "2014-04-25T17:37:44+00:00",
        "label": 0
    },
    "1905.02450": {
        "title": "MASS: Masked Sequence to Sequence Pre-training for Language Generation",
        "abstract": "Pre-training and fine-tuning, e.g., BERT, have achieved great success in\nlanguage understanding by transferring knowledge from rich-resource\npre-training task to the low/zero-resource downstream tasks. Inspired by the\nsuccess of BERT, we propose MAsked Sequence to Sequence pre-training (MASS) for\nthe encoder-decoder based language generation tasks. MASS adopts the\nencoder-decoder framework to reconstruct a sentence fragment given the\nremaining part of the sentence: its encoder takes a sentence with randomly\nmasked fragment (several consecutive tokens) as input, and its decoder tries to\npredict this masked fragment. In this way, MASS can jointly train the encoder\nand decoder to develop the capability of representation extraction and language\nmodeling. By further fine-tuning on a variety of zero/low-resource language\ngeneration tasks, including neural machine translation, text summarization and\nconversational response generation (3 tasks and totally 8 datasets), MASS\nachieves significant improvements over the baselines without pre-training or\nwith other pre-training methods. Specially, we achieve the state-of-the-art\naccuracy (37.5 in terms of BLEU score) on the unsupervised English-French\ntranslation, even beating the early attention-based supervised model.",
        "date": "2019-05-07T10:13:04+00:00",
        "label": 1
    },
    "2305.13048": {
        "title": "RWKV: Reinventing RNNs for the Transformer Era",
        "abstract": "Transformers have revolutionized almost all natural language processing (NLP)\ntasks but suffer from memory and computational complexity that scales\nquadratically with sequence length. In contrast, recurrent neural networks\n(RNNs) exhibit linear scaling in memory and computational requirements but\nstruggle to match the same performance as Transformers due to limitations in\nparallelization and scalability. We propose a novel model architecture,\nReceptance Weighted Key Value (RWKV), that combines the efficient\nparallelizable training of transformers with the efficient inference of RNNs.\n  Our approach leverages a linear attention mechanism and allows us to\nformulate the model as either a Transformer or an RNN, thus parallelizing\ncomputations during training and maintains constant computational and memory\ncomplexity during inference. We scale our models as large as 14 billion\nparameters, by far the largest dense RNN ever trained, and find RWKV performs\non par with similarly sized Transformers, suggesting future work can leverage\nthis architecture to create more efficient models. This work presents a\nsignificant step towards reconciling trade-offs between computational\nefficiency and model performance in sequence processing tasks.",
        "date": "2023-05-22T13:57:41+00:00",
        "label": 1
    },
    "2010.00506": {
        "title": "Edsger Dijkstra. The Man Who Carried Computer Science on His Shoulders",
        "abstract": "This a biographical essay about Edsger Wybe Dijkstra.",
        "date": "2020-10-01T15:55:51+00:00",
        "label": 0
    },
    "1612.04037": {
        "title": "Proceedings 11th Doctoral Workshop on Mathematical and Engineering Methods in Computer Science",
        "abstract": "MEMICS provides a forum for doctoral students interested in applications of\nmathematical and engineering methods in computer science. Besides a rich\ntechnical programme (including invited talks, regular papers, and\npresentations), MEMICS also offers friendly social activities and exciting\nopportunities for meeting like-minded people. MEMICS submissions traditionally\ncover all areas of computer science (such as parallel and distributed\ncomputing, computer networks, modern hardware and its design, non-traditional\ncomputing architectures, information systems and databases, multimedia and\ngraphics, verification and testing, computer security, as well as all related\nareas of theoretical computer science).",
        "date": "2016-12-13T05:47:19+00:00",
        "label": 0
    },
    "2310.06825": {
        "title": "Mistral 7B",
        "abstract": "We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered\nfor superior performance and efficiency. Mistral 7B outperforms Llama 2 13B\nacross all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and\ncode generation. Our model leverages grouped-query attention (GQA) for faster\ninference, coupled with sliding window attention (SWA) to effectively handle\nsequences of arbitrary length with a reduced inference cost. We also provide a\nmodel fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses\nthe Llama 2 13B -- Chat model both on human and automated benchmarks. Our\nmodels are released under the Apache 2.0 license.",
        "date": "2023-10-10T17:54:58+00:00",
        "label": 1
    },
    "0907.3804": {
        "title": "Decidability of higher-order matching",
        "abstract": "We show that the higher-order matching problem is decidable using a\ngame-theoretic argument.",
        "date": "2009-07-22T09:17:30+00:00",
        "label": 0
    },
    "2107.02137": {
        "title": "ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation",
        "abstract": "Pre-trained models have achieved state-of-the-art results in various Natural\nLanguage Processing (NLP) tasks. Recent works such as T5 and GPT-3 have shown\nthat scaling up pre-trained language models can improve their generalization\nabilities. Particularly, the GPT-3 model with 175 billion parameters shows its\nstrong task-agnostic zero-shot/few-shot learning capabilities. Despite their\nsuccess, these large-scale models are trained on plain texts without\nintroducing knowledge such as linguistic knowledge and world knowledge. In\naddition, most large-scale models are trained in an auto-regressive way. As a\nresult, this kind of traditional fine-tuning approach demonstrates relatively\nweak performance when solving downstream language understanding tasks. In order\nto solve the above problems, we propose a unified framework named ERNIE 3.0 for\npre-training large-scale knowledge enhanced models. It fuses auto-regressive\nnetwork and auto-encoding network, so that the trained model can be easily\ntailored for both natural language understanding and generation tasks with\nzero-shot learning, few-shot learning or fine-tuning. We trained the model with\n10 billion parameters on a 4TB corpus consisting of plain texts and a\nlarge-scale knowledge graph. Empirical results show that the model outperforms\nthe state-of-the-art models on 54 Chinese NLP tasks, and its English version\nachieves the first place on the SuperGLUE benchmark (July 3, 2021), surpassing\nthe human performance by +0.8% (90.6% vs. 89.8%).",
        "date": "2021-07-05T16:54:59+00:00",
        "label": 1
    },
    "2203.15556": {
        "title": "Training Compute-Optimal Large Language Models",
        "abstract": "We investigate the optimal model size and number of tokens for training a\ntransformer language model under a given compute budget. We find that current\nlarge language models are significantly undertrained, a consequence of the\nrecent focus on scaling language models whilst keeping the amount of training\ndata constant. By training over 400 language models ranging from 70 million to\nover 16 billion parameters on 5 to 500 billion tokens, we find that for\ncompute-optimal training, the model size and the number of training tokens\nshould be scaled equally: for every doubling of model size the number of\ntraining tokens should also be doubled. We test this hypothesis by training a\npredicted compute-optimal model, Chinchilla, that uses the same compute budget\nas Gopher but with 70B parameters and 4$\\times$ more more data. Chinchilla\nuniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1\n(178B), and Megatron-Turing NLG (530B) on a large range of downstream\nevaluation tasks. This also means that Chinchilla uses substantially less\ncompute for fine-tuning and inference, greatly facilitating downstream usage.\nAs a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5%\non the MMLU benchmark, greater than a 7% improvement over Gopher.",
        "date": "2022-03-29T13:38:03+00:00",
        "label": 1
    },
    "2206.06336": {
        "title": "Language Models are General-Purpose Interfaces",
        "abstract": "Foundation models have received much attention due to their effectiveness\nacross a broad range of downstream applications. Though there is a big\nconvergence in terms of architecture, most pretrained models are typically\nstill developed for specific tasks or modalities. In this work, we propose to\nuse language models as a general-purpose interface to various foundation\nmodels. A collection of pretrained encoders perceive diverse modalities (such\nas vision, and language), and they dock with a language model that plays the\nrole of a universal task layer. We propose a semi-causal language modeling\nobjective to jointly pretrain the interface and the modular encoders. We\nsubsume the advantages and capabilities from both causal and non-causal\nmodeling, thereby combining the best of two worlds. Specifically, the proposed\nmethod not only inherits the capabilities of in-context learning and open-ended\ngeneration from causal language modeling, but also is conducive to finetuning\nbecause of the bidirectional encoders. More importantly, our approach\nseamlessly unlocks the combinations of the above capabilities, e.g., enabling\nin-context learning or instruction following with finetuned encoders.\nExperimental results across various language-only and vision-language\nbenchmarks show that our model outperforms or is competitive with specialized\nmodels on finetuning, zero-shot generalization, and few-shot learning.",
        "date": "2022-06-13T17:34:22+00:00",
        "label": 1
    },
    "0701087": {
        "title": "Artificiality in Social Sciences",
        "abstract": "This text provides with an introduction to the modern approach of\nartificiality and simulation in social sciences. It presents the relationship\nbetween complexity and artificiality, before introducing the field of\nartificial societies which greatly benefited from the computer power fast\nincrease, gifting social sciences with formalization and experimentation tools\npreviously owned by \"hard\" sciences alone. It shows that as \"a new way of doing\nsocial sciences\", artificial societies should undoubtedly contribute to a\nrenewed approach in the study of sociality and should play a significant part\nin the elaboration of original theories of social phenomena.",
        "date": "2007-01-13T16:50:37+00:00",
        "label": 0
    },
    "2109.07958": {
        "title": "TruthfulQA: Measuring How Models Mimic Human Falsehoods",
        "abstract": "We propose a benchmark to measure whether a language model is truthful in\ngenerating answers to questions. The benchmark comprises 817 questions that\nspan 38 categories, including health, law, finance and politics. We crafted\nquestions that some humans would answer falsely due to a false belief or\nmisconception. To perform well, models must avoid generating false answers\nlearned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a\nT5-based model. The best model was truthful on 58% of questions, while human\nperformance was 94%. Models generated many false answers that mimic popular\nmisconceptions and have the potential to deceive humans. The largest models\nwere generally the least truthful. This contrasts with other NLP tasks, where\nperformance improves with model size. However, this result is expected if false\nanswers are learned from the training distribution. We suggest that scaling up\nmodels alone is less promising for improving truthfulness than fine-tuning\nusing training objectives other than imitation of text from the web.",
        "date": "2021-09-08T17:15:27+00:00",
        "label": 1
    },
    "2312.10997": {
        "title": "Retrieval-Augmented Generation for Large Language Models: A Survey",
        "abstract": "Large Language Models (LLMs) showcase impressive capabilities but encounter\nchallenges like hallucination, outdated knowledge, and non-transparent,\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating knowledge from external\ndatabases. This enhances the accuracy and credibility of the generation,\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\nupdates and integration of domain-specific information. RAG synergistically\nmerges LLMs' intrinsic knowledge with the vast, dynamic repositories of\nexternal databases. This comprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\ntripartite foundation of RAG frameworks, which includes the retrieval, the\ngeneration and the augmentation techniques. The paper highlights the\nstate-of-the-art technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG systems.\nFurthermore, this paper introduces up-to-date evaluation framework and\nbenchmark. At the end, this article delineates the challenges currently faced\nand points out prospective avenues for research and development.",
        "date": "2023-12-18T07:47:33+00:00",
        "label": 1
    },
    "1506.05282": {
        "title": "Why Bother With Syntax?",
        "abstract": "This short note discusses the role of syntax vs. semantics and the interplay\nbetween logic, philosophy, and language in computer science and game theory.",
        "date": "2015-06-17T11:27:12+00:00",
        "label": 0
    },
    "1309.0717": {
        "title": "A Polynomial Translation of pi-calculus FCPs to Safe Petri Nets",
        "abstract": "We develop a polynomial translation from finite control pi-calculus processes\nto safe low-level Petri nets. To our knowledge, this is the first such\ntranslation. It is natural in that there is a close correspondence between the\ncontrol flows, enjoys a bisimulation result, and is suitable for practical\nmodel checking.",
        "date": "2013-09-03T15:08:39+00:00",
        "label": 0
    },
    "1906.05340": {
        "title": "The Halting Paradox",
        "abstract": "The halting problem is considered to be an essential part of the theoretical\nbackground to computing. That halting is not in general computable has\nsupposedly been proved in many text books and taught on many computer science\ncourses, in order to illustrate the limits of computation. However, Eric Hehner\nhas a dissenting view, in which the specification of the halting problem is\ncalled into question.",
        "date": "2019-06-11T09:47:19+00:00",
        "label": 0
    },
    "0703148": {
        "title": "Computer Science and Game Theory: A Brief Survey",
        "abstract": "There has been a remarkable increase in work at the interface of computer\nscience and game theory in the past decade. In this article I survey some of\nthe main themes of work in the area, with a focus on the work in computer\nscience. Given the length constraints, I make no attempt at being\ncomprehensive, especially since other surveys are also available, and a\ncomprehensive survey book will appear shortly.",
        "date": "2007-03-29T18:43:58+00:00",
        "label": 0
    },
    "2305.06161": {
        "title": "StarCoder: may the source be with you!",
        "abstract": "The BigCode community, an open-scientific collaboration working on the\nresponsible development of Large Language Models for Code (Code LLMs),\nintroduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context\nlength, infilling capabilities and fast large-batch inference enabled by\nmulti-query attention. StarCoderBase is trained on 1 trillion tokens sourced\nfrom The Stack, a large collection of permissively licensed GitHub repositories\nwith inspection tools and an opt-out process. We fine-tuned StarCoderBase on\n35B Python tokens, resulting in the creation of StarCoder. We perform the most\ncomprehensive evaluation of Code LLMs to date and show that StarCoderBase\noutperforms every open Code LLM that supports multiple programming languages\nand matches or outperforms the OpenAI code-cushman-001 model. Furthermore,\nStarCoder outperforms every model that is fine-tuned on Python, can be prompted\nto achieve 40\\% pass@1 on HumanEval, and still retains its performance on other\nprogramming languages. We take several important steps towards a safe\nopen-access model release, including an improved PII redaction pipeline and a\nnovel attribution tracing tool, and make the StarCoder models publicly\navailable under a more commercially viable version of the Open Responsible AI\nModel license.",
        "date": "2023-05-09T08:16:42+00:00",
        "label": 1
    },
    "2203.13474": {
        "title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis",
        "abstract": "Program synthesis strives to generate a computer program as a solution to a\ngiven problem specification, expressed with input-output examples or natural\nlanguage descriptions. The prevalence of large language models advances the\nstate-of-the-art for program synthesis, though limited training resources and\ndata impede open access to such models. To democratize this, we train and\nrelease a family of large language models up to 16.1B parameters, called\nCODEGEN, on natural language and programming language data, and open source the\ntraining library JAXFORMER. We show the utility of the trained model by\ndemonstrating that it is competitive with the previous state-of-the-art on\nzero-shot Python code generation on HumanEval. We further investigate the\nmulti-step paradigm for program synthesis, where a single program is factorized\ninto multiple prompts specifying subproblems. To this end, we construct an open\nbenchmark, Multi-Turn Programming Benchmark (MTPB), consisting of 115 diverse\nproblem sets that are factorized into multi-turn prompts. Our analysis on MTPB\nshows that the same intent provided to CODEGEN in multi-turn fashion\nsignificantly improves program synthesis over that provided as a single turn.\nWe make the training library JAXFORMER and model checkpoints available as open\nsource contribution: https://github.com/salesforce/CodeGen.",
        "date": "2022-03-25T06:55:15+00:00",
        "label": 1
    },
    "2004.05150": {
        "title": "Longformer: The Long-Document Transformer",
        "abstract": "Transformer-based models are unable to process long sequences due to their\nself-attention operation, which scales quadratically with the sequence length.\nTo address this limitation, we introduce the Longformer with an attention\nmechanism that scales linearly with sequence length, making it easy to process\ndocuments of thousands of tokens or longer. Longformer's attention mechanism is\na drop-in replacement for the standard self-attention and combines a local\nwindowed attention with a task motivated global attention. Following prior work\non long-sequence transformers, we evaluate Longformer on character-level\nlanguage modeling and achieve state-of-the-art results on text8 and enwik8. In\ncontrast to most prior work, we also pretrain Longformer and finetune it on a\nvariety of downstream tasks. Our pretrained Longformer consistently outperforms\nRoBERTa on long document tasks and sets new state-of-the-art results on WikiHop\nand TriviaQA. We finally introduce the Longformer-Encoder-Decoder (LED), a\nLongformer variant for supporting long document generative sequence-to-sequence\ntasks, and demonstrate its effectiveness on the arXiv summarization dataset.",
        "date": "2020-04-10T17:54:09+00:00",
        "label": 1
    },
    "2306.02707": {
        "title": "Orca: Progressive Learning from Complex Explanation Traces of GPT-4",
        "abstract": "Recent research has focused on enhancing the capability of smaller models\nthrough imitation learning, drawing on the outputs generated by large\nfoundation models (LFMs). A number of issues impact the quality of these\nmodels, ranging from limited imitation signals from shallow LFM outputs; small\nscale homogeneous training data; and most notably a lack of rigorous evaluation\nresulting in overestimating the small model's capability as they tend to learn\nto imitate the style, but not the reasoning process of LFMs. To address these\nchallenges, we develop Orca (We are working with our legal team to publicly\nrelease a diff of the model weights in accordance with LLaMA's release policy\nto be published at https://aka.ms/orca-lm), a 13-billion parameter model that\nlearns to imitate the reasoning process of LFMs. Orca learns from rich signals\nfrom GPT-4 including explanation traces; step-by-step thought processes; and\nother complex instructions, guided by teacher assistance from ChatGPT. To\npromote this progressive learning, we tap into large-scale and diverse\nimitation data with judicious sampling and selection. Orca surpasses\nconventional state-of-the-art instruction-tuned models such as Vicuna-13B by\nmore than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard\n(BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH\nbenchmark and shows competitive performance (4 pts gap with optimized system\nmessage) in professional and academic examinations like the SAT, LSAT, GRE, and\nGMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our\nresearch indicates that learning from step-by-step explanations, whether these\nare generated by humans or more advanced AI models, is a promising direction to\nimprove model capabilities and skills.",
        "date": "2023-06-05T08:58:39+00:00",
        "label": 1
    },
    "2005.11401": {
        "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
        "abstract": "Large pre-trained language models have been shown to store factual knowledge\nin their parameters, and achieve state-of-the-art results when fine-tuned on\ndownstream NLP tasks. However, their ability to access and precisely manipulate\nknowledge is still limited, and hence on knowledge-intensive tasks, their\nperformance lags behind task-specific architectures. Additionally, providing\nprovenance for their decisions and updating their world knowledge remain open\nresearch problems. Pre-trained models with a differentiable access mechanism to\nexplicit non-parametric memory can overcome this issue, but have so far been\nonly investigated for extractive downstream tasks. We explore a general-purpose\nfine-tuning recipe for retrieval-augmented generation (RAG) -- models which\ncombine pre-trained parametric and non-parametric memory for language\ngeneration. We introduce RAG models where the parametric memory is a\npre-trained seq2seq model and the non-parametric memory is a dense vector index\nof Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG\nformulations, one which conditions on the same retrieved passages across the\nwhole generated sequence, the other can use different passages per token. We\nfine-tune and evaluate our models on a wide range of knowledge-intensive NLP\ntasks and set the state-of-the-art on three open domain QA tasks, outperforming\nparametric seq2seq models and task-specific retrieve-and-extract architectures.\nFor language generation tasks, we find that RAG models generate more specific,\ndiverse and factual language than a state-of-the-art parametric-only seq2seq\nbaseline.",
        "date": "2020-05-22T21:34:34+00:00",
        "label": 1
    },
    "1711.04184": {
        "title": "Real-number Computability from the Perspective of Computer Assisted Proofs in Analysis",
        "abstract": "Inspired by computer assisted proofs in analysis, we present an interval\napproach to real-number computations.",
        "date": "2017-11-11T19:25:36+00:00",
        "label": 0
    },
    "1607.03760": {
        "title": "Distributed Games and Strategies",
        "abstract": "A summary of work on distributed games and strategies done within the first\nthree years of the ERC project ECSYM is presented.",
        "date": "2016-07-13T14:25:03+00:00",
        "label": 0
    },
    "2112.11446": {
        "title": "Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
        "abstract": "Language modelling provides a step towards intelligent communication systems\nby harnessing large repositories of written human knowledge to better predict\nand understand the world. In this paper, we present an analysis of\nTransformer-based language model performance across a wide range of model\nscales -- from models with tens of millions of parameters up to a 280 billion\nparameter model called Gopher. These models are evaluated on 152 diverse tasks,\nachieving state-of-the-art performance across the majority. Gains from scale\nare largest in areas such as reading comprehension, fact-checking, and the\nidentification of toxic language, but logical and mathematical reasoning see\nless benefit. We provide a holistic analysis of the training dataset and\nmodel's behaviour, covering the intersection of model scale with bias and\ntoxicity. Finally we discuss the application of language models to AI safety\nand the mitigation of downstream harms.",
        "date": "2021-12-08T19:41:47+00:00",
        "label": 1
    },
    "2302.09419": {
        "title": "A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT",
        "abstract": "Pretrained Foundation Models (PFMs) are regarded as the foundation for\nvarious downstream tasks with different data modalities. A PFM (e.g., BERT,\nChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable\nparameter initialization for a wide range of downstream applications. BERT\nlearns bidirectional encoder representations from Transformers, which are\ntrained on large datasets as contextual language models. Similarly, the\ngenerative pretrained transformer (GPT) method employs Transformers as the\nfeature extractor and is trained using an autoregressive paradigm on large\ndatasets. Recently, ChatGPT shows promising success on large language models,\nwhich applies an autoregressive language model with zero shot or few shot\nprompting. The remarkable achievements of PFM have brought significant\nbreakthroughs to various fields of AI. Numerous studies have proposed different\nmethods, raising the demand for an updated survey. This study provides a\ncomprehensive review of recent research advancements, challenges, and\nopportunities for PFMs in text, image, graph, as well as other data modalities.\nThe review covers the basic components and existing pretraining methods used in\nnatural language processing, computer vision, and graph learning. Additionally,\nit explores advanced PFMs used for different data modalities and unified PFMs\nthat consider data quality and quantity. The review also discusses research\nrelated to the fundamentals of PFMs, such as model efficiency and compression,\nsecurity, and privacy. Finally, the study provides key implications, future\nresearch directions, challenges, and open problems in the field of PFMs.\nOverall, this survey aims to shed light on the research of the PFMs on\nscalability, security, logical reasoning ability, cross-domain learning\nability, and the user-friendly interactive ability for artificial general\nintelligence.",
        "date": "2023-02-18T20:51:09+00:00",
        "label": 1
    },
    "2210.11416": {
        "title": "Scaling Instruction-Finetuned Language Models",
        "abstract": "Finetuning language models on a collection of datasets phrased as\ninstructions has been shown to improve model performance and generalization to\nunseen tasks. In this paper we explore instruction finetuning with a particular\nfocus on (1) scaling the number of tasks, (2) scaling the model size, and (3)\nfinetuning on chain-of-thought data. We find that instruction finetuning with\nthe above aspects dramatically improves performance on a variety of model\nclasses (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and\nevaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation). For\ninstance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PALM\n540B by a large margin (+9.4% on average). Flan-PaLM 540B achieves\nstate-of-the-art performance on several benchmarks, such as 75.2% on five-shot\nMMLU. We also publicly release Flan-T5 checkpoints, which achieve strong\nfew-shot performance even compared to much larger models, such as PaLM 62B.\nOverall, instruction finetuning is a general method for improving the\nperformance and usability of pretrained language models.",
        "date": "2022-10-20T16:58:32+00:00",
        "label": 1
    },
    "1111.4755": {
        "title": "Saying Hello World with MOLA - A Solution to the TTC 2011 Instructive Case",
        "abstract": "This paper describes the solution of Hello World transformations in MOLA\ntransformation language. Transformations implementing the task are relatively\nstraightforward and easily inferable from the task specification. The required\nadditional steps related to model import and export are also described.",
        "date": "2011-11-21T05:26:57+00:00",
        "label": 0
    },
    "1210.0736": {
        "title": "Quantum Computation and Quantum Information",
        "abstract": "Quantum computation and quantum information are of great current interest in\ncomputer science, mathematics, physical sciences and engineering. They will\nlikely lead to a new wave of technological innovations in communication,\ncomputation and cryptography. As the theory of quantum physics is fundamentally\nstochastic, randomness and uncertainty are deeply rooted in quantum\ncomputation, quantum simulation and quantum information. Consequently quantum\nalgorithms are random in nature, and quantum simulation utilizes Monte Carlo\ntechniques extensively. Thus statistics can play an important role in quantum\ncomputation and quantum simulation, which in turn offer great potential to\nrevolutionize computational statistics. While only pseudo-random numbers can be\ngenerated by classical computers, quantum computers are able to produce genuine\nrandom numbers; quantum computers can exponentially or quadratically speed up\nmedian evaluation, Monte Carlo integration and Markov chain simulation. This\npaper gives a brief review on quantum computation, quantum simulation and\nquantum information. We introduce the basic concepts of quantum computation and\nquantum simulation and present quantum algorithms that are known to be much\nfaster than the available classic algorithms. We provide a statistical\nframework for the analysis of quantum algorithms and quantum simulation.",
        "date": "2012-10-02T11:47:37+00:00",
        "label": 0
    },
    "1011.1335": {
        "title": "A short proof that adding some permutation rules to $\u03b2$ preserves $SN$",
        "abstract": "I show that, if a term is $SN$ for $\\beta$, it remains $SN$ when some\npermutation rules are added.",
        "date": "2010-11-05T07:54:47+00:00",
        "label": 0
    },
    "1501.05039": {
        "title": "Defining Data Science",
        "abstract": "Data science is gaining more and more and widespread attention, but no\nconsensus viewpoint on what data science is has emerged. As a new science, its\nobjects of study and scientific issues should not be covered by established\nsciences. Data in cyberspace have formed what we call datanature. In the\npresent paper, data science is defined as the science of exploring datanature.",
        "date": "2015-01-21T02:41:55+00:00",
        "label": 0
    },
    "1401.2580": {
        "title": "A Proof of Kamp's theorem",
        "abstract": "We provide a simple proof of Kamp's theorem.",
        "date": "2014-01-12T00:05:22+00:00",
        "label": 0
    },
    "2001.08361": {
        "title": "Scaling Laws for Neural Language Models",
        "abstract": "We study empirical scaling laws for language model performance on the\ncross-entropy loss. The loss scales as a power-law with model size, dataset\nsize, and the amount of compute used for training, with some trends spanning\nmore than seven orders of magnitude. Other architectural details such as\nnetwork width or depth have minimal effects within a wide range. Simple\nequations govern the dependence of overfitting on model/dataset size and the\ndependence of training speed on model size. These relationships allow us to\ndetermine the optimal allocation of a fixed compute budget. Larger models are\nsignificantly more sample-efficient, such that optimally compute-efficient\ntraining involves training very large models on a relatively modest amount of\ndata and stopping significantly before convergence.",
        "date": "2020-01-23T03:59:20+00:00",
        "label": 1
    },
    "2110.05456": {
        "title": "Rome was built in 1776: A Case Study on Factual Correctness in Knowledge-Grounded Response Generation",
        "abstract": "Recently neural response generation models have leveraged large pre-trained\ntransformer models and knowledge snippets to generate relevant and informative\nresponses. However, this does not guarantee that generated responses are\nfactually correct. In this paper, we examine factual correctness in\nknowledge-grounded neural response generation models. We present a human\nannotation setup to identify three different response types: responses that are\nfactually consistent with respect to the input knowledge, responses that\ncontain hallucinated knowledge, and non-verifiable chitchat style responses. We\nuse this setup to annotate responses generated using different stateof-the-art\nmodels, knowledge snippets, and decoding strategies. In addition, to facilitate\nthe development of a factual consistency detector, we automatically create a\nnew corpus called Conv-FEVER that is adapted from the Wizard of Wikipedia\ndataset and includes factually consistent and inconsistent responses. We\ndemonstrate the benefit of our Conv-FEVER dataset by showing that the models\ntrained on this data perform reasonably well to detect factually inconsistent\nresponses with respect to the provided knowledge through evaluation on our\nhuman annotated data. We will release the Conv-FEVER dataset and the human\nannotated responses.",
        "date": "2021-10-11T17:48:11+00:00",
        "label": 1
    },
    "2110.08207": {
        "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization",
        "abstract": "Large language models have recently been shown to attain reasonable zero-shot\ngeneralization on a diverse set of tasks (Brown et al., 2020). It has been\nhypothesized that this is a consequence of implicit multitask learning in\nlanguage models' pretraining (Radford et al., 2019). Can zero-shot\ngeneralization instead be directly induced by explicit multitask learning? To\ntest this question at scale, we develop a system for easily mapping any natural\nlanguage tasks into a human-readable prompted form. We convert a large set of\nsupervised datasets, each with multiple prompts with diverse wording. These\nprompted datasets allow for benchmarking the ability of a model to perform\ncompletely held-out tasks. We fine-tune a pretrained encoder-decoder model\n(Raffel et al., 2020; Lester et al., 2021) on this multitask mixture covering a\nwide variety of tasks. The model attains strong zero-shot performance on\nseveral standard datasets, often outperforming models up to 16x its size.\nFurther, our approach attains strong performance on a subset of tasks from the\nBIG-bench benchmark, outperforming models up to 6x its size. All trained models\nare available at https://github.com/bigscience-workshop/t-zero and all prompts\nare available at https://github.com/bigscience-workshop/promptsource.",
        "date": "2021-10-15T17:08:57+00:00",
        "label": 1
    },
    "2206.09250": {
        "title": "Robin Milner's Work on Concurrency: An Appreciation",
        "abstract": "We give a short appreciation of Robin Milner's seminal contributions to the\ntheory of concurrency.",
        "date": "2022-06-18T17:22:01+00:00",
        "label": 0
    },
    "2305.18290": {
        "title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model",
        "abstract": "While large-scale unsupervised language models (LMs) learn broad world\nknowledge and some reasoning skills, achieving precise control of their\nbehavior is difficult due to the completely unsupervised nature of their\ntraining. Existing methods for gaining such steerability collect human labels\nof the relative quality of model generations and fine-tune the unsupervised LM\nto align with these preferences, often with reinforcement learning from human\nfeedback (RLHF). However, RLHF is a complex and often unstable procedure, first\nfitting a reward model that reflects the human preferences, and then\nfine-tuning the large unsupervised LM using reinforcement learning to maximize\nthis estimated reward without drifting too far from the original model. In this\npaper we introduce a new parameterization of the reward model in RLHF that\nenables extraction of the corresponding optimal policy in closed form, allowing\nus to solve the standard RLHF problem with only a simple classification loss.\nThe resulting algorithm, which we call Direct Preference Optimization (DPO), is\nstable, performant, and computationally lightweight, eliminating the need for\nsampling from the LM during fine-tuning or performing significant\nhyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align\nwith human preferences as well as or better than existing methods. Notably,\nfine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of\ngenerations, and matches or improves response quality in summarization and\nsingle-turn dialogue while being substantially simpler to implement and train.",
        "date": "2023-05-29T17:57:46+00:00",
        "label": 1
    },
    "1401.4507": {
        "title": "Using Quantum Computers to Learn Physics",
        "abstract": "Since its inception at the beginning of the twentieth century, quantum\nmechanics has challenged our conceptions of how the universe ought to work;\nhowever, the equations of quantum mechanics can be too computationally\ndifficult to solve using existing computers for even modestly large systems.\nHere I will show that quantum computers can sometimes be used to address such\nproblems and that quantum computer science can assign formal complexities to\nlearning facts about nature. Hence, computer science should not only be\nregarded as an applied science; it is also of central importance to the\nfoundations of science.",
        "date": "2014-01-18T01:46:52+00:00",
        "label": 0
    },
    "1606.08699": {
        "title": "How to Compute Halting",
        "abstract": "A consistently specified halting function may be computed.",
        "date": "2016-06-26T19:38:10+00:00",
        "label": 0
    },
    "2301.06885": {
        "title": "Computer Science for Future -- Sustainability and Climate Protection in the Computer Science Courses of the HAW Hamburg",
        "abstract": "Computer Science for Future (CS4F) is an initiative in the Department of\nComputer Science at HAW Hamburg. The aim of the initiative is a paradigm shift\nin the discipline of computer science, thus establishing sustainability goals\nas a primary leitmotif for teaching and research. The focus is on teaching\nsince the most promising multipliers are the students of a university. The\nchange in teaching influences our research, the transfer to business and civil\nsociety as well as the change in our own institution. In this article, we\npresent the initiative CS4F and reflect primarily on the role of students as\namplifiers in the transformation process of computer science.",
        "date": "2023-01-17T13:43:57+00:00",
        "label": 0
    },
    "2109.02501": {
        "title": "Proceedings of the 9th International Symposium on Symbolic Computation in Software Science",
        "abstract": "This volume contains papers presented at the Ninth International Symposium on\nSymbolic Computation in Software Science, SCSS 2021.\n  Symbolic Computation is the science of computing with symbolic objects\n(terms, formulae, programs, representations of algebraic objects, etc.).\nPowerful algorithms have been developed during the past decades for the major\nsubareas of symbolic computation: computer algebra and computational logic.\nThese algorithms and methods are successfully applied in various fields,\nincluding software science, which covers a broad range of topics about software\nconstruction and analysis.\n  Meanwhile, artificial intelligence methods and machine learning algorithms\nare widely used nowadays in various domains and, in particular, combined with\nsymbolic computation. Several approaches mix artificial intelligence and\nsymbolic methods and tools deployed over large corpora to create what is known\nas cognitive systems. Cognitive computing focuses on building systems that\ninteract with humans naturally by reasoning, aiming at learning at scale.\n  The purpose of SCSS is to promote research on theoretical and practical\naspects of symbolic computation in software science, combined with modern\nartificial intelligence techniques. These proceedings contain the keynote paper\nby Bruno Buchberger and ten contributed papers. Besides, the conference program\nincluded three invited talks, nine short and work-in-progress papers, and a\nspecial session on computer algebra and computational logic. Due to the\nCOVID-19 pandemic, the symposium was held completely online. It was organized\nby the Research Institute for Symbolic Computation (RISC) of the Johannes\nKepler University Linz on September 8--10, 2021.",
        "date": "2021-09-06T14:22:11+00:00",
        "label": 0
    },
    "1005.5635": {
        "title": "An Effective Extension of the Wagner Hierarchy to Blind Counter Automata",
        "abstract": "The extension of the Wagner hierarchy to blind counter automata accepting\ninfinite words with a Muller acceptance condition is effective. We determine\nprecisely this hierarchy.",
        "date": "2010-05-31T09:19:39+00:00",
        "label": 0
    },
    "2301.00234": {
        "title": "A Survey on In-context Learning",
        "abstract": "With the increasing capabilities of large language models (LLMs), in-context\nlearning (ICL) has emerged as a new paradigm for natural language processing\n(NLP), where LLMs make predictions based on contexts augmented with a few\nexamples. It has been a significant trend to explore ICL to evaluate and\nextrapolate the ability of LLMs. In this paper, we aim to survey and summarize\nthe progress and challenges of ICL. We first present a formal definition of ICL\nand clarify its correlation to related studies. Then, we organize and discuss\nadvanced techniques, including training strategies, prompt designing\nstrategies, and related analysis. Additionally, we explore various ICL\napplication scenarios, such as data engineering and knowledge updating.\nFinally, we address the challenges of ICL and suggest potential directions for\nfurther research. We hope that our work can encourage more research on\nuncovering how ICL works and improving ICL.",
        "date": "2022-12-31T15:57:09+00:00",
        "label": 1
    },
    "2109.12264": {
        "title": "More Than Reading Comprehension: A Survey on Datasets and Metrics of Textual Question Answering",
        "abstract": "Textual Question Answering (QA) aims to provide precise answers to user's\nquestions in natural language using unstructured data. One of the most popular\napproaches to this goal is machine reading comprehension(MRC). In recent years,\nmany novel datasets and evaluation metrics based on classical MRC tasks have\nbeen proposed for broader textual QA tasks. In this paper, we survey 47 recent\ntextual QA benchmark datasets and propose a new taxonomy from an application\npoint of view. In addition, We summarize 8 evaluation metrics of textual QA\ntasks. Finally, we discuss current trends in constructing textual QA benchmarks\nand suggest directions for future work.",
        "date": "2021-09-25T02:36:53+00:00",
        "label": 1
    },
    "1711.10874": {
        "title": "Explanation of an Invisible Common Constraint of Mind, Mathematics and Computational Complexity",
        "abstract": "There is a cognitive limit in Human Mind. This cognitive limit has played a\ndecisive role in almost all fields including computer sciences. The cognitive\nlimit replicated in computer sciences is responsible for inherent Computational\nComplexity. The complexity starts decreasing if certain conditions are met,\neven sometime it does not appears at all. Very simple Mechanical computing\nsystems are designed and implemented to demonstrate this idea and it is further\nsupported by Electrical systems. These verifiable and consistent systems\ndemonstrate the idea of computational complexity reduction. This work explains\na very important but invisible connection from Mind to Mathematical axioms\n(Peano Axioms etc.) and Mathematical axioms to computational complexity. This\nstudy gives a completely new perspective that goes well beyond Cognitive\nScience, Mathematics, Physics, Computer Sciences and Philosophy. Based on this\nnew insight some important predictions are made.",
        "date": "2017-11-23T18:23:07+00:00",
        "label": 0
    },
    "2305.14314": {
        "title": "QLoRA: Efficient Finetuning of Quantized LLMs",
        "abstract": "We present QLoRA, an efficient finetuning approach that reduces memory usage\nenough to finetune a 65B parameter model on a single 48GB GPU while preserving\nfull 16-bit finetuning task performance. QLoRA backpropagates gradients through\na frozen, 4-bit quantized pretrained language model into Low Rank\nAdapters~(LoRA). Our best model family, which we name Guanaco, outperforms all\nprevious openly released models on the Vicuna benchmark, reaching 99.3% of the\nperformance level of ChatGPT while only requiring 24 hours of finetuning on a\nsingle GPU. QLoRA introduces a number of innovations to save memory without\nsacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is\ninformation theoretically optimal for normally distributed weights (b) double\nquantization to reduce the average memory footprint by quantizing the\nquantization constants, and (c) paged optimziers to manage memory spikes. We\nuse QLoRA to finetune more than 1,000 models, providing a detailed analysis of\ninstruction following and chatbot performance across 8 instruction datasets,\nmultiple model types (LLaMA, T5), and model scales that would be infeasible to\nrun with regular finetuning (e.g. 33B and 65B parameter models). Our results\nshow that QLoRA finetuning on a small high-quality dataset leads to\nstate-of-the-art results, even when using smaller models than the previous\nSoTA. We provide a detailed analysis of chatbot performance based on both human\nand GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable\nalternative to human evaluation. Furthermore, we find that current chatbot\nbenchmarks are not trustworthy to accurately evaluate the performance levels of\nchatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to\nChatGPT. We release all of our models and code, including CUDA kernels for\n4-bit training.",
        "date": "2023-05-23T17:50:33+00:00",
        "label": 1
    },
    "2308.10882": {
        "title": "Giraffe: Adventures in Expanding Context Lengths in LLMs",
        "abstract": "Modern large language models (LLMs) that rely on attention mechanisms are\ntypically trained with fixed context lengths which enforce upper limits on the\nlength of input sequences that they can handle at evaluation time. To use these\nmodels on sequences longer than the train-time context length, one might employ\ntechniques from the growing family of context length extrapolation methods --\nmost of which focus on modifying the system of positional encodings used in the\nattention mechanism to indicate where tokens or activations are located in the\ninput sequence. We conduct a wide survey of existing methods of context length\nextrapolation on a base LLaMA or LLaMA 2 model, and introduce some of our own\ndesign as well -- in particular, a new truncation strategy for modifying the\nbasis for the position encoding.\n  We test these methods using three new evaluation tasks (FreeFormQA,\nAlteredNumericQA, and LongChat-Lines) as well as perplexity, which we find to\nbe less fine-grained as a measure of long context performance of LLMs. We\nrelease the three tasks publicly as datasets on HuggingFace. We discover that\nlinear scaling is the best method for extending context length, and show that\nfurther gains can be achieved by using longer scales at evaluation time. We\nalso discover promising extrapolation capabilities in the truncated basis. To\nsupport further research in this area, we release three new 13B parameter\nlong-context models which we call Giraffe: 4k and 16k context models trained\nfrom base LLaMA-13B, and a 32k context model trained from base LLaMA2-13B. We\nalso release the code to replicate our results.",
        "date": "2023-08-21T17:30:16+00:00",
        "label": 1
    },
    "2305.03047": {
        "title": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision",
        "abstract": "Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised\nfine-tuning (SFT) with human annotations and reinforcement learning from human\nfeedback (RLHF) to align the output of large language models (LLMs) with human\nintentions, ensuring they are helpful, ethical, and reliable. However, this\ndependence can significantly constrain the true potential of AI-assistant\nagents due to the high cost of obtaining human supervision and the related\nissues on quality, reliability, diversity, self-consistency, and undesirable\nbiases. To address these challenges, we propose a novel approach called\nSELF-ALIGN, which combines principle-driven reasoning and the generative power\nof LLMs for the self-alignment of AI agents with minimal human supervision. Our\napproach encompasses four stages: first, we use an LLM to generate synthetic\nprompts, and a topic-guided method to augment the prompt diversity; second, we\nuse a small set of human-written principles for AI models to follow, and guide\nthe LLM through in-context learning from demonstrations (of principles\napplication) to produce helpful, ethical, and reliable responses to user's\nqueries; third, we fine-tune the original LLM with the high-quality\nself-aligned responses so that the resulting model can generate desirable\nresponses for each query directly without the principle set and the\ndemonstrations anymore; and finally, we offer a refinement step to address the\nissues of overly-brief or indirect responses. Applying SELF-ALIGN to the\nLLaMA-65b base language model, we develop an AI assistant named Dromedary. With\nfewer than 300 lines of human annotations (including < 200 seed prompts, 16\ngeneric principles, and 5 exemplars for in-context learning). Dromedary\nsignificantly surpasses the performance of several state-of-the-art AI systems,\nincluding Text-Davinci-003 and Alpaca, on benchmark datasets with various\nsettings.",
        "date": "2023-05-04T17:59:28+00:00",
        "label": 1
    },
    "1210.6636": {
        "title": "Informaticology: combining Computer Science, Data Science, and Fiction Science",
        "abstract": "Motivated by an intention to remedy current complications with Dutch\nterminology concerning informatics, the term informaticology is positioned to\ndenote an academic counterpart of informatics where informatics is conceived of\nas a container for a coherent family of practical disciplines ranging from\ncomputer engineering and software engineering to network technology, data\ncenter management, information technology, and information management in a\nbroad sense.\n  Informaticology escapes from the limitations of instrumental objectives and\nthe perspective of usage that both restrict the scope of informatics. That is\nachieved by including fiction science in informaticology and by ranking fiction\nscience on equal terms with computer science and data science, and framing (the\nstudy of) game design, evelopment, assessment and distribution, ranging from\nserious gaming to entertainment gaming, as a chapter of fiction science. A\nsuggestion for the scope of fiction science is specified in some detail.\n  In order to illustrate the coherence of informaticology thus conceived, a\npotential application of fiction to the ontology of instruction sequences and\nto software quality assessment is sketched, thereby highlighting a possible\nrole of fiction (science) within informaticology but outside gaming.",
        "date": "2012-10-24T19:24:59+00:00",
        "label": 0
    },
    "2208.01448": {
        "title": "AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model",
        "abstract": "In this work, we demonstrate that multilingual large-scale\nsequence-to-sequence (seq2seq) models, pre-trained on a mixture of denoising\nand Causal Language Modeling (CLM) tasks, are more efficient few-shot learners\nthan decoder-only models on various tasks. In particular, we train a 20 billion\nparameter multilingual seq2seq model called Alexa Teacher Model (AlexaTM 20B)\nand show that it achieves state-of-the-art (SOTA) performance on 1-shot\nsummarization tasks, outperforming a much larger 540B PaLM decoder model.\nAlexaTM 20B also achieves SOTA in 1-shot machine translation, especially for\nlow-resource languages, across almost all language pairs supported by the model\n(Arabic, English, French, German, Hindi, Italian, Japanese, Marathi,\nPortuguese, Spanish, Tamil, and Telugu) on Flores-101 dataset. We also show in\nzero-shot setting, AlexaTM 20B outperforms GPT3 (175B) on SuperGLUE and SQuADv2\ndatasets and provides SOTA performance on multilingual tasks such as XNLI,\nXCOPA, Paws-X, and XWinograd. Overall, our results present a compelling case\nfor seq2seq models as a powerful alternative to decoder-only models for\nLarge-scale Language Model (LLM) training.",
        "date": "2022-08-02T13:30:07+00:00",
        "label": 1
    },
    "0608062": {
        "title": "Tarski's influence on computer science",
        "abstract": "The influence of Alfred Tarski on computer science was indirect but\nsignificant in a number of directions and was in certain respects fundamental.\nHere surveyed is the work of Tarski on the decision procedure for algebra and\ngeometry, the method of elimination of quantifiers, the semantics of formal\nlanguages, modeltheoretic preservation theorems, and algebraic logic; various\nconnections of each with computer science are taken up.",
        "date": "2006-08-15T16:40:24+00:00",
        "label": 0
    },
    "2207.05608": {
        "title": "Inner Monologue: Embodied Reasoning through Planning with Language Models",
        "abstract": "Recent works have shown how the reasoning capabilities of Large Language\nModels (LLMs) can be applied to domains beyond natural language processing,\nsuch as planning and interaction for robots. These embodied problems require an\nagent to understand many semantic aspects of the world: the repertoire of\nskills available, how these skills influence the world, and how changes to the\nworld map back to the language. LLMs planning in embodied environments need to\nconsider not just what skills to do, but also how and when to do them - answers\nthat change over time in response to the agent's own choices. In this work, we\ninvestigate to what extent LLMs used in such embodied contexts can reason over\nsources of feedback provided through natural language, without any additional\ntraining. We propose that by leveraging environment feedback, LLMs are able to\nform an inner monologue that allows them to more richly process and plan in\nrobotic control scenarios. We investigate a variety of sources of feedback,\nsuch as success detection, scene description, and human interaction. We find\nthat closed-loop language feedback significantly improves high-level\ninstruction completion on three domains, including simulated and real table top\nrearrangement tasks and long-horizon mobile manipulation tasks in a kitchen\nenvironment in the real world.",
        "date": "2022-07-12T15:20:48+00:00",
        "label": 1
    },
    "1811.01033": {
        "title": "Building an Argument for the Use of Science Fiction in HCI Education",
        "abstract": "Science fiction literature, comics, cartoons and, in particular, audio-visual\nmaterials, such as science fiction movies and shows, can be a valuable addition\nin Human-computer interaction (HCI) Education. In this paper, we present an\noverview of research relative to future directions in HCI Education, distinct\ncrossings of science fiction in HCI and Computer Science teaching and the\nFramework for 21st Century Learning. Next, we provide examples where science\nfiction can add to the future of HCI Education. In particular, we argue herein\nfirst that science fiction, as tangible and intangible cultural artifact, can\nserve as a trigger for creativity and innovation and thus, support us in\nexploring the design space. Second, science fiction, as a means to analyze\nyet-to-come HCI technologies, can assist us in developing an open-minded and\nreflective dialogue about technological futures, thus creating a singular base\nfor critical thinking and problem solving. Provided that one is cognizant of\nits potential and limitations, we reason that science fiction can be a\nmeaningful extension of selected aspects of HCI curricula and research.",
        "date": "2018-11-02T18:24:18+00:00",
        "label": 0
    },
    "0410370": {
        "title": "Looking for Design in Materials Design",
        "abstract": "Despite great advances in computation, materials design is still science\nfiction. The construction of structure-property relations on the quantum scale\nwill turn computational empiricism into true design.",
        "date": "2004-10-14T14:41:24+00:00",
        "label": 0
    },
    "2206.12669": {
        "title": "Crypto Makes AI Evolve",
        "abstract": "Adopting cryptography has given rise to a significant evolution in Artificial\nIntelligence (AI). This paper studies the path and stages of this evolution. We\nstart with reviewing existing relevant surveys, noting their shortcomings,\nespecially the lack of a close look at the evolution process and solid future\nroadmap. These shortcomings justify the work of this paper. Next, we identify,\ndefine and discuss five consequent stages in the evolution path, including\nCrypto-Sensitive AI, Crypto-Adapted AI, Crypto-Friendly AI, Crypto-Enabled AI,\nCrypto-Protected AI. Then, we establish a future roadmap for further research\nin this area, focusing on the role of quantum-inspired and bio-inspired AI.",
        "date": "2022-06-25T15:04:47+00:00",
        "label": 0
    },
    "1103.1386": {
        "title": "Physics and computer science: quantum computation and other approaches",
        "abstract": "This is a position paper written as an introduction to the special volume on\nquantum algorithms I edited for the journal Mathematical Structures in Computer\nScience (Volume 20 - Special Issue 06 (Quantum Algorithms), 2010).",
        "date": "2011-03-07T21:00:29+00:00",
        "label": 0
    },
    "2309.05463": {
        "title": "Textbooks Are All You Need II: phi-1.5 technical report",
        "abstract": "We continue the investigation into the power of smaller Transformer-based\nlanguage models as initiated by \\textbf{TinyStories} -- a 10 million parameter\nmodel that can produce coherent English -- and the follow-up work on\n\\textbf{phi-1}, a 1.3 billion parameter model with Python coding performance\nclose to the state-of-the-art. The latter work proposed to use existing Large\nLanguage Models (LLMs) to generate ``textbook quality\" data as a way to enhance\nthe learning process compared to traditional web data. We follow the\n``Textbooks Are All You Need\" approach, focusing this time on common sense\nreasoning in natural language, and create a new 1.3 billion parameter model\nnamed \\textbf{phi-1.5}, with performance on natural language tasks comparable\nto models 5x larger, and surpassing most non-frontier LLMs on more complex\nreasoning tasks such as grade-school mathematics and basic coding. More\ngenerally, \\textbf{phi-1.5} exhibits many of the traits of much larger LLMs,\nboth good -- such as the ability to ``think step by step\" or perform some\nrudimentary in-context learning -- and bad, including hallucinations and the\npotential for toxic and biased generations -- encouragingly though, we are\nseeing improvement on that front thanks to the absence of web data. We\nopen-source \\textbf{phi-1.5} to promote further research on these urgent\ntopics.",
        "date": "2023-09-11T14:01:45+00:00",
        "label": 1
    },
    "1009.2416": {
        "title": "Computational Science and Innovation",
        "abstract": "Simulations - utilizing computers to solve complicated science and\nengineering problems - are a key ingredient of modern science. The U.S.\nDepartment of Energy (DOE) is a world leader in the development of\nhigh-performance computing (HPC), the development of applied math and\nalgorithms that utilize the full potential of HPC platforms, and the\napplication of computing to science and engineering problems. An interesting\ngeneral question is whether the DOE can strategically utilize its capability in\nsimulations to advance innovation more broadly. In this article, I will argue\nthat this is certainly possible.",
        "date": "2010-09-13T15:15:07+00:00",
        "label": 0
    },
    "0609070": {
        "title": "Exploring Computer Science Concepts with a Ready-made Computer Game Framework",
        "abstract": "Leveraging the prevailing interest in computer games among college students,\nboth for entertainment and as a possible career path, is a major reason for the\nincreasing prevalence of computer game design courses in computer science\ncurricula. Because implementing a computer game requires strong programming\nskills, game design courses are most often restricted to more advanced computer\nscience students. This paper reports on a ready-made game design and\nexperimentation framework, implemented in Java, that makes game programming\nmore widely accessible. This framework, called Labyrinth, enables students at\nall programming skill levels to participate in computer game design. We\ndescribe the architecture of the framework, and discuss programming projects\nsuitable for a wide variety of computer science courses, from capstone to\nnon-major.",
        "date": "2006-09-12T19:49:55+00:00",
        "label": 0
    },
    "2207.07901": {
        "title": "Computer Science",
        "abstract": "Possible for science itself, conceptually, to have and will understand\ndifferently, let alone science also seen as technology, such as computer\nscience. After all, science and technology are viewpoints diverse by either\nindividual, community, or social. Generally, it depends on socioeconomic\ncapabilities. So it is with computer science has become a phenomenon and\nfashionable, where based on the stream of documents, various issues arise in\neither its theory or implementation, adapting different communities, or\ndesigning curriculum holds in the education system.",
        "date": "2022-07-16T10:54:57+00:00",
        "label": 0
    },
    "2104.08773": {
        "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions",
        "abstract": "Humans (e.g., crowdworkers) have a remarkable ability in solving different\ntasks, by simply reading textual instructions that define them and looking at a\nfew examples. Despite the success of the conventional supervised learning on\nindividual datasets, such models often struggle with generalization across\ntasks (e.g., a question-answering system cannot solve classification tasks). A\nlong-standing challenge in AI is to build a model that learns a new task by\nunderstanding the human-readable instructions that define it. To study this, we\nintroduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their\nhuman-authored instructions, and 193k task instances (input-output pairs). The\ninstructions are obtained from crowdsourcing instructions used to create\nexisting NLP datasets and mapped to a unified schema. Using this meta-dataset,\nwe measure cross-task generalization by training models on seen tasks and\nmeasuring generalization to the remaining unseen ones. We adopt generative\npre-trained language models to encode task-specific instructions along with\ninput and generate task output. Our results indicate that models benefit from\ninstructions when evaluated in terms of generalization to unseen tasks (19%\nbetter for models utilizing instructions). These models, however, are far\nbehind an estimated performance upperbound indicating significant room for more\nprogress in this direction.",
        "date": "2021-04-18T08:44:56+00:00",
        "label": 1
    },
    "1803.02155": {
        "title": "Self-Attention with Relative Position Representations",
        "abstract": "Relying entirely on an attention mechanism, the Transformer introduced by\nVaswani et al. (2017) achieves state-of-the-art results for machine\ntranslation. In contrast to recurrent and convolutional neural networks, it\ndoes not explicitly model relative or absolute position information in its\nstructure. Instead, it requires adding representations of absolute positions to\nits inputs. In this work we present an alternative approach, extending the\nself-attention mechanism to efficiently consider representations of the\nrelative positions, or distances between sequence elements. On the WMT 2014\nEnglish-to-German and English-to-French translation tasks, this approach yields\nimprovements of 1.3 BLEU and 0.3 BLEU over absolute position representations,\nrespectively. Notably, we observe that combining relative and absolute position\nrepresentations yields no further improvement in translation quality. We\ndescribe an efficient implementation of our method and cast it as an instance\nof relation-aware self-attention mechanisms that can generalize to arbitrary\ngraph-labeled inputs.",
        "date": "2018-03-06T13:13:11+00:00",
        "label": 1
    },
    "1802.05365": {
        "title": "Deep contextualized word representations",
        "abstract": "We introduce a new type of deep contextualized word representation that\nmodels both (1) complex characteristics of word use (e.g., syntax and\nsemantics), and (2) how these uses vary across linguistic contexts (i.e., to\nmodel polysemy). Our word vectors are learned functions of the internal states\nof a deep bidirectional language model (biLM), which is pre-trained on a large\ntext corpus. We show that these representations can be easily added to existing\nmodels and significantly improve the state of the art across six challenging\nNLP problems, including question answering, textual entailment and sentiment\nanalysis. We also present an analysis showing that exposing the deep internals\nof the pre-trained network is crucial, allowing downstream models to mix\ndifferent types of semi-supervision signals.",
        "date": "2018-02-15T00:05:11+00:00",
        "label": 1
    },
    "1701.06538": {
        "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer",
        "abstract": "The capacity of a neural network to absorb information is limited by its\nnumber of parameters. Conditional computation, where parts of the network are\nactive on a per-example basis, has been proposed in theory as a way of\ndramatically increasing model capacity without a proportional increase in\ncomputation. In practice, however, there are significant algorithmic and\nperformance challenges. In this work, we address these challenges and finally\nrealize the promise of conditional computation, achieving greater than 1000x\nimprovements in model capacity with only minor losses in computational\nefficiency on modern GPU clusters. We introduce a Sparsely-Gated\nMixture-of-Experts layer (MoE), consisting of up to thousands of feed-forward\nsub-networks. A trainable gating network determines a sparse combination of\nthese experts to use for each example. We apply the MoE to the tasks of\nlanguage modeling and machine translation, where model capacity is critical for\nabsorbing the vast quantities of knowledge available in the training corpora.\nWe present model architectures in which a MoE with up to 137 billion parameters\nis applied convolutionally between stacked LSTM layers. On large language\nmodeling and machine translation benchmarks, these models achieve significantly\nbetter results than state-of-the-art at lower computational cost.",
        "date": "2017-01-23T18:10:00+00:00",
        "label": 1
    },
    "2308.09621": {
        "title": "Canonicity and Computability in Homotopy Type Theory",
        "abstract": "This dissertation gives an overview of Martin Lof's dependant type theory,\nfocusing on its computational content and addressing a question of possibility\nof fully canonical and computable semantic presentation.",
        "date": "2023-08-18T15:23:33+00:00",
        "label": 0
    },
    "2304.08485": {
        "title": "Visual Instruction Tuning",
        "abstract": "Instruction tuning large language models (LLMs) using machine-generated\ninstruction-following data has improved zero-shot capabilities on new tasks,\nbut the idea is less explored in the multimodal field. In this paper, we\npresent the first attempt to use language-only GPT-4 to generate multimodal\nlanguage-image instruction-following data. By instruction tuning on such\ngenerated data, we introduce LLaVA: Large Language and Vision Assistant, an\nend-to-end trained large multimodal model that connects a vision encoder and\nLLM for general-purpose visual and language understanding.Our early experiments\nshow that LLaVA demonstrates impressive multimodel chat abilities, sometimes\nexhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and\nyields a 85.1% relative score compared with GPT-4 on a synthetic multimodal\ninstruction-following dataset. When fine-tuned on Science QA, the synergy of\nLLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make\nGPT-4 generated visual instruction tuning data, our model and code base\npublicly available.",
        "date": "2023-04-17T17:59:25+00:00",
        "label": 1
    },
    "2007.08087": {
        "title": "Starting with data: advancing spatial data science by building and sharing high-quality datasets",
        "abstract": "Spatial data science has emerged in recent years as an interdisciplinary\nfield. This position paper discusses the importance of building and sharing\nhigh-quality datasets for spatial data science.",
        "date": "2020-07-16T03:15:56+00:00",
        "label": 0
    },
    "1103.1977": {
        "title": "Development of Computer Science Disciplines - A Social Network Analysis Approach",
        "abstract": "In contrast to many other scientific disciplines, computer science considers\nconference publications. Conferences have the advantage of providing fast\npublication of papers and of bringing researchers together to present and\ndiscuss the paper with peers. Previous work on knowledge mapping focused on the\nmap of all sciences or a particular domain based on ISI published JCR (Journal\nCitation Report). Although this data covers most of important journals, it\nlacks computer science conference and workshop proceedings. That results in an\nimprecise and incomplete analysis of the computer science knowledge. This paper\npresents an analysis on the computer science knowledge network constructed from\nall types of publications, aiming at providing a complete view of computer\nscience research. Based on the combination of two important digital libraries\n(DBLP and CiteSeerX), we study the knowledge network created at\njournal/conference level using citation linkage, to identify the development of\nsub-disciplines. We investigate the collaborative and citation behavior of\njournals/conferences by analyzing the properties of their co-authorship and\ncitation subgraphs. The paper draws several important conclusions. First,\nconferences constitute social structures that shape the computer science\nknowledge. Second, computer science is becoming more interdisciplinary. Third,\nexperts are the key success factor for sustainability of journals/conferences.",
        "date": "2011-03-10T09:51:19+00:00",
        "label": 0
    },
    "2306.08302": {
        "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
        "abstract": "Large language models (LLMs), such as ChatGPT and GPT4, are making new waves\nin the field of natural language processing and artificial intelligence, due to\ntheir emergent ability and generalizability. However, LLMs are black-box\nmodels, which often fall short of capturing and accessing factual knowledge. In\ncontrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are\nstructured knowledge models that explicitly store rich factual knowledge. KGs\ncan enhance LLMs by providing external knowledge for inference and\ninterpretability. Meanwhile, KGs are difficult to construct and evolving by\nnature, which challenges the existing methods in KGs to generate new facts and\nrepresent unseen knowledge. Therefore, it is complementary to unify LLMs and\nKGs together and simultaneously leverage their advantages. In this article, we\npresent a forward-looking roadmap for the unification of LLMs and KGs. Our\nroadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs,\nwhich incorporate KGs during the pre-training and inference phases of LLMs, or\nfor the purpose of enhancing understanding of the knowledge learned by LLMs; 2)\nLLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding,\ncompletion, construction, graph-to-text generation, and question answering; and\n3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a\nmutually beneficial way to enhance both LLMs and KGs for bidirectional\nreasoning driven by both data and knowledge. We review and summarize existing\nefforts within these three frameworks in our roadmap and pinpoint their future\nresearch directions.",
        "date": "2023-06-14T07:15:26+00:00",
        "label": 1
    },
    "2012.12144": {
        "title": "Integrating computing in the statistics and data science curriculum: Creative structures, novel skills and habits, and ways to teach computational thinking",
        "abstract": "Nolan and Temple Lang (2010) argued for the fundamental role of computing in\nthe statistics curriculum. In the intervening decade the statistics education\ncommunity has acknowledged that computational skills are as important to\nstatistics and data science practice as mathematics. There remains a notable\ngap, however, between our intentions and our actions. In this special issue of\nthe *Journal of Statistics and Data Science Education* we have assembled a\ncollection of papers that (1) suggest creative structures to integrate\ncomputing, (2) describe novel data science skills and habits, and (3) propose\nways to teach computational thinking. We believe that it is critical for the\ncommunity to redouble our efforts to embrace sophisticated computing in the\nstatistics and data science curriculum. We hope that these papers provide\nuseful guidance for the community to move these efforts forward.",
        "date": "2020-12-22T16:28:18+00:00",
        "label": 0
    },
    "2401.05561": {
        "title": "TrustLLM: Trustworthiness in Large Language Models",
        "abstract": "Large language models (LLMs), exemplified by ChatGPT, have gained\nconsiderable attention for their excellent natural language processing\ncapabilities. Nonetheless, these LLMs present many challenges, particularly in\nthe realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMs\nemerges as an important topic. This paper introduces TrustLLM, a comprehensive\nstudy of trustworthiness in LLMs, including principles for different dimensions\nof trustworthiness, established benchmark, evaluation, and analysis of\ntrustworthiness for mainstream LLMs, and discussion of open challenges and\nfuture directions. Specifically, we first propose a set of principles for\ntrustworthy LLMs that span eight different dimensions. Based on these\nprinciples, we further establish a benchmark across six dimensions including\ntruthfulness, safety, fairness, robustness, privacy, and machine ethics. We\nthen present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of\nover 30 datasets. Our findings firstly show that in general trustworthiness and\nutility (i.e., functional effectiveness) are positively related. Secondly, our\nobservations reveal that proprietary LLMs generally outperform most open-source\ncounterparts in terms of trustworthiness, raising concerns about the potential\nrisks of widely accessible open-source LLMs. However, a few open-source LLMs\ncome very close to proprietary ones. Thirdly, it is important to note that some\nLLMs may be overly calibrated towards exhibiting trustworthiness, to the extent\nthat they compromise their utility by mistakenly treating benign prompts as\nharmful and consequently not responding. Finally, we emphasize the importance\nof ensuring transparency not only in the models themselves but also in the\ntechnologies that underpin trustworthiness. Knowing the specific trustworthy\ntechnologies that have been employed is crucial for analyzing their\neffectiveness.",
        "date": "2024-01-10T22:07:21+00:00",
        "label": 1
    },
    "2205.05131": {
        "title": "UL2: Unifying Language Learning Paradigms",
        "abstract": "Existing pre-trained models are generally geared towards a particular class\nof problems. To date, there seems to be still no consensus on what the right\narchitecture and pre-training setup should be. This paper presents a unified\nframework for pre-training models that are universally effective across\ndatasets and setups. We begin by disentangling architectural archetypes with\npre-training objectives -- two concepts that are commonly conflated. Next, we\npresent a generalized & unified perspective for self-supervision in NLP and\nshow how different pre-training objectives can be cast as one another and how\ninterpolating between different objectives can be effective. We then propose\nMixture-of-Denoisers (MoD), a pre-training objective that combines diverse\npre-training paradigms together. We furthermore introduce a notion of mode\nswitching, wherein downstream fine-tuning is associated with specific\npre-training schemes. We conduct extensive ablative experiments to compare\nmultiple pre-training objectives and find that our method pushes the\nPareto-frontier by outperforming T5 & GPT-like models across multiple diverse\nsetups. By scaling our model up to 20B parameters, we achieve SOTA performance\non 50 well-established supervised finetuning based NLP tasks. Our model also\nachieve strong results at in-context learning, outperforming 175B GPT-3 on\nzero-shot SuperGLUE and tripling the performance of T5-XXL on one-shot\nsummarization. On 0-shot MMLU, UL2 20B outperforms T0 and T5 models. UL2 20B\nalso works well with chain-of-thought prompting and reasoning, making it an\nappealing choice for research into reasoning at a small to medium scale of 20B\nparameters. Finally, we apply FLAN instruction tuning to the UL2 20B model,\nachieving MMLU and Big-Bench scores competitive to FLAN-PaLM 62B. We release\nFlax-based T5X checkpoints for the UL2 20B & Flan-UL2 20B.",
        "date": "2022-05-10T19:32:20+00:00",
        "label": 1
    },
    "1909.11942": {
        "title": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations",
        "abstract": "Increasing model size when pretraining natural language representations often\nresults in improved performance on downstream tasks. However, at some point\nfurther model increases become harder due to GPU/TPU memory limitations and\nlonger training times. To address these problems, we present two\nparameter-reduction techniques to lower memory consumption and increase the\ntraining speed of BERT. Comprehensive empirical evidence shows that our\nproposed methods lead to models that scale much better compared to the original\nBERT. We also use a self-supervised loss that focuses on modeling\ninter-sentence coherence, and show it consistently helps downstream tasks with\nmulti-sentence inputs. As a result, our best model establishes new\nstate-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having\nfewer parameters compared to BERT-large. The code and the pretrained models are\navailable at https://github.com/google-research/ALBERT.",
        "date": "2019-09-26T07:06:13+00:00",
        "label": 1
    },
    "2010.11934": {
        "title": "mT5: A massively multilingual pre-trained text-to-text transformer",
        "abstract": "The recent \"Text-to-Text Transfer Transformer\" (T5) leveraged a unified\ntext-to-text format and scale to attain state-of-the-art results on a wide\nvariety of English-language NLP tasks. In this paper, we introduce mT5, a\nmultilingual variant of T5 that was pre-trained on a new Common Crawl-based\ndataset covering 101 languages. We detail the design and modified training of\nmT5 and demonstrate its state-of-the-art performance on many multilingual\nbenchmarks. We also describe a simple technique to prevent \"accidental\ntranslation\" in the zero-shot setting, where a generative model chooses to\n(partially) translate its prediction into the wrong language. All of the code\nand model checkpoints used in this work are publicly available.",
        "date": "2020-10-22T17:58:14+00:00",
        "label": 1
    },
    "1901.07291": {
        "title": "Cross-lingual Language Model Pretraining",
        "abstract": "Recent studies have demonstrated the efficiency of generative pretraining for\nEnglish natural language understanding. In this work, we extend this approach\nto multiple languages and show the effectiveness of cross-lingual pretraining.\nWe propose two methods to learn cross-lingual language models (XLMs): one\nunsupervised that only relies on monolingual data, and one supervised that\nleverages parallel data with a new cross-lingual language model objective. We\nobtain state-of-the-art results on cross-lingual classification, unsupervised\nand supervised machine translation. On XNLI, our approach pushes the state of\nthe art by an absolute gain of 4.9% accuracy. On unsupervised machine\ntranslation, we obtain 34.3 BLEU on WMT'16 German-English, improving the\nprevious state of the art by more than 9 BLEU. On supervised machine\ntranslation, we obtain a new state of the art of 38.5 BLEU on WMT'16\nRomanian-English, outperforming the previous best approach by more than 4 BLEU.\nOur code and pretrained models will be made publicly available.",
        "date": "2019-01-22T13:22:34+00:00",
        "label": 1
    },
    "1908.03793": {
        "title": "The rise and rise of interdisciplinary research: Understanding the interaction dynamics of three major fields -- Physics, Mathematics & Computer Science",
        "abstract": "The distinction between sciences is becoming increasingly more artificial --\nan approach from one area can be easily applied to the other. More exciting\nresearch nowadays is happening perhaps at the interfaces of disciplines like\nPhysics, Mathematics and Computer Science. How do these interfaces emerge and\ninteract? For instance, is there a specific pattern in which these fields cite\neach other? In this article, we investigate a collection of more than 1.2\nmillion papers from three different scientific disciplines -- Physics,\nMathematics, and Computer Science. We show how over a timescale the citation\npatterns from the core science fields (Physics, Mathematics) to the applied and\nfast-growing field of Computer Science have drastically increased. Further, we\nobserve how certain subfields in these disciplines are shrinking while others\nare becoming tremendously popular. For instance, an intriguing observation is\nthat citations from Mathematics to the subfield of machine learning in Computer\nScience in recent times are exponentially increasing.",
        "date": "2019-08-10T17:58:19+00:00",
        "label": 0
    },
    "2308.12966": {
        "title": "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
        "abstract": "In this work, we introduce the Qwen-VL series, a set of large-scale\nvision-language models (LVLMs) designed to perceive and understand both texts\nand images. Starting from the Qwen-LM as a foundation, we endow it with visual\ncapacity by the meticulously designed (i) visual receptor, (ii) input-output\ninterface, (iii) 3-stage training pipeline, and (iv) multilingual multimodal\ncleaned corpus. Beyond the conventional image description and\nquestion-answering, we implement the grounding and text-reading ability of\nQwen-VLs by aligning image-caption-box tuples. The resulting models, including\nQwen-VL and Qwen-VL-Chat, set new records for generalist models under similar\nmodel scales on a broad range of visual-centric benchmarks (e.g., image\ncaptioning, question answering, visual grounding) and different settings (e.g.,\nzero-shot, few-shot). Moreover, on real-world dialog benchmarks, our\ninstruction-tuned Qwen-VL-Chat also demonstrates superiority compared to\nexisting vision-language chatbots. Code, demo and models are available at\nhttps://github.com/QwenLM/Qwen-VL.",
        "date": "2023-08-24T17:59:17+00:00",
        "label": 1
    },
    "2212.10403": {
        "title": "Towards Reasoning in Large Language Models: A Survey",
        "abstract": "Reasoning is a fundamental aspect of human intelligence that plays a crucial\nrole in activities such as problem solving, decision making, and critical\nthinking. In recent years, large language models (LLMs) have made significant\nprogress in natural language processing, and there is observation that these\nmodels may exhibit reasoning abilities when they are sufficiently large.\nHowever, it is not yet clear to what extent LLMs are capable of reasoning. This\npaper provides a comprehensive overview of the current state of knowledge on\nreasoning in LLMs, including techniques for improving and eliciting reasoning\nin these models, methods and benchmarks for evaluating reasoning abilities,\nfindings and implications of previous research in this field, and suggestions\non future directions. Our aim is to provide a detailed and up-to-date review of\nthis topic and stimulate meaningful discussion and future work.",
        "date": "2022-12-20T16:29:03+00:00",
        "label": 1
    },
    "2006.03654": {
        "title": "DeBERTa: Decoding-enhanced BERT with Disentangled Attention",
        "abstract": "Recent progress in pre-trained neural language models has significantly\nimproved the performance of many natural language processing (NLP) tasks. In\nthis paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT\nwith disentangled attention) that improves the BERT and RoBERTa models using\ntwo novel techniques. The first is the disentangled attention mechanism, where\neach word is represented using two vectors that encode its content and\nposition, respectively, and the attention weights among words are computed\nusing disentangled matrices on their contents and relative positions,\nrespectively. Second, an enhanced mask decoder is used to incorporate absolute\npositions in the decoding layer to predict the masked tokens in model\npre-training. In addition, a new virtual adversarial training method is used\nfor fine-tuning to improve models' generalization. We show that these\ntechniques significantly improve the efficiency of model pre-training and the\nperformance of both natural language understanding (NLU) and natural langauge\ngeneration (NLG) downstream tasks. Compared to RoBERTa-Large, a DeBERTa model\ntrained on half of the training data performs consistently better on a wide\nrange of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%),\non SQuAD v2.0 by +2.3% (88.4% vs. 90.7%) and RACE by +3.6% (83.2% vs. 86.8%).\nNotably, we scale up DeBERTa by training a larger version that consists of 48\nTransform layers with 1.5 billion parameters. The significant performance boost\nmakes the single DeBERTa model surpass the human performance on the SuperGLUE\nbenchmark (Wang et al., 2019a) for the first time in terms of macro-average\nscore (89.9 versus 89.8), and the ensemble DeBERTa model sits atop the\nSuperGLUE leaderboard as of January 6, 2021, out performing the human baseline\nby a decent margin (90.3 versus 89.8).",
        "date": "2020-06-05T19:54:34+00:00",
        "label": 1
    },
    "2205.10487": {
        "title": "Scaling Laws and Interpretability of Learning from Repeated Data",
        "abstract": "Recent large language models have been trained on vast datasets, but also\noften on repeated data, either intentionally for the purpose of upweighting\nhigher quality data, or unintentionally because data deduplication is not\nperfect and the model is exposed to repeated data at the sentence, paragraph,\nor document level. Some works have reported substantial negative performance\neffects of this repeated data. In this paper we attempt to study repeated data\nsystematically and to understand its effects mechanistically. To do this, we\ntrain a family of models where most of the data is unique but a small fraction\nof it is repeated many times. We find a strong double descent phenomenon, in\nwhich repeated data can lead test loss to increase midway through training. A\npredictable range of repetition frequency leads to surprisingly severe\ndegradation in performance. For instance, performance of an 800M parameter\nmodel can be degraded to that of a 2x smaller model (400M params) by repeating\n0.1% of the data 100 times, despite the other 90% of the training tokens\nremaining unique. We suspect there is a range in the middle where the data can\nbe memorized and doing so consumes a large fraction of the model's capacity,\nand this may be where the peak of degradation occurs. Finally, we connect these\nobservations to recent mechanistic interpretability work - attempting to\nreverse engineer the detailed computations performed by the model - by showing\nthat data repetition disproportionately damages copying and internal structures\nassociated with generalization, such as induction heads, providing a possible\nmechanism for the shift from generalization to memorization. Taken together,\nthese results provide a hypothesis for why repeating a relatively small\nfraction of data in large language models could lead to disproportionately\nlarge harms to performance.",
        "date": "2022-05-21T02:14:27+00:00",
        "label": 1
    },
    "1608.08918": {
        "title": "Subcomputable Schnorr Randomness",
        "abstract": "The notion of Schnorr randomness refers to computable reals or computable\nfunctions. We propose a version of Schnorr randomness for subcomputable classes\nand characterize it in different ways: by Martin L\\\"of tests, martingales or\nmeasure computable machines.",
        "date": "2016-08-31T16:04:37+00:00",
        "label": 0
    },
    "1412.7030": {
        "title": "Proceedings of the 7th European Conference on Python in Science (EuroSciPy 2014)",
        "abstract": "These are the proceedings of the 7th European Conference on Python in\nScience, EuroSciPy 2014, that was held in Cambridge, UK (27-30 August 2014).",
        "date": "2014-12-22T15:47:51+00:00",
        "label": 0
    },
    "1405.5593": {
        "title": "Saturation algorithms for model-checking pushdown systems",
        "abstract": "We present a survey of the saturation method for model-checking pushdown\nsystems.",
        "date": "2014-05-22T02:11:30+00:00",
        "label": 0
    },
    "1810.04805": {
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "abstract": "We introduce a new language representation model called BERT, which stands\nfor Bidirectional Encoder Representations from Transformers. Unlike recent\nlanguage representation models, BERT is designed to pre-train deep\nbidirectional representations from unlabeled text by jointly conditioning on\nboth left and right context in all layers. As a result, the pre-trained BERT\nmodel can be fine-tuned with just one additional output layer to create\nstate-of-the-art models for a wide range of tasks, such as question answering\nand language inference, without substantial task-specific architecture\nmodifications.\n  BERT is conceptually simple and empirically powerful. It obtains new\nstate-of-the-art results on eleven natural language processing tasks, including\npushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\naccuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering\nTest F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1\n(5.1 point absolute improvement).",
        "date": "2018-10-11T00:50:01+00:00",
        "label": 1
    },
    "1108.3558": {
        "title": "Proceedings of the 5th Workshop on Membrane Computing and Biologically Inspired Process Calculi (MeCBIC 2011)",
        "abstract": "This volume represents the proceedings of the 5th Workshop on Membrane\nComputing and Biologically Inspired Process Calculi (MeCBIC 2011), held\ntogether with the 12th International Conference on Membrane Computing on 23rd\nAugust 2011 in Fontainebleau, France.",
        "date": "2011-08-17T19:41:29+00:00",
        "label": 0
    },
    "2311.10969": {
        "title": "MATILDA: Inclusive Data Science Pipelines Design through Computational Creativity",
        "abstract": "We argue for the need for a new generation of data science solutions that can\ndemocratize recent advances in data engineering and artificial intelligence for\nnon-technical users from various disciplines, enabling them to unlock the full\npotential of these solutions. To do so, we adopt an approach whereby\ncomputational creativity and conversational computing are combined to guide\nnon-specialists intuitively to explore and extract knowledge from data\ncollections. The paper introduces MATILDA, a creativity-based data science\ndesign platform, showing how it can support the design process of data science\npipelines guided by human and computational creativity.",
        "date": "2023-11-18T04:37:07+00:00",
        "label": 0
    },
    "2210.11399": {
        "title": "Transcending Scaling Laws with 0.1% Extra Compute",
        "abstract": "Scaling language models improves performance but comes with significant\ncomputational costs. This paper proposes UL2R, a method that substantially\nimproves existing language models and their scaling curves with a relatively\ntiny amount of extra compute. The key idea is to continue training a\nstate-of-the-art large language model (e.g., PaLM) on a few more steps with\nUL2's mixture-of-denoiser objective. We show that, with almost negligible extra\ncomputational costs and no new sources of data, we are able to substantially\nimprove the scaling properties of large language models on downstream metrics.\nIn this paper, we continue training PaLM with UL2R, introducing a new set of\nmodels at 8B, 62B, and 540B scale which we call U-PaLM. Impressively, at 540B\nscale, we show an approximately 2x computational savings rate where U-PaLM\nachieves the same performance as the final PaLM 540B model at around half its\ncomputational budget (i.e., saving $\\sim$4.4 million TPUv4 hours). We further\nshow that this improved scaling curve leads to 'emergent abilities' on\nchallenging BIG-Bench tasks -- for instance, U-PaLM does much better than PaLM\non some tasks or demonstrates better quality at much smaller scale (62B as\nopposed to 540B). Overall, we show that U-PaLM outperforms PaLM on many\nfew-shot setups, i.e., English NLP tasks (e.g., commonsense reasoning, question\nanswering), reasoning tasks with chain-of-thought (e.g., GSM8K), multilingual\ntasks (MGSM, TydiQA), MMLU and challenging BIG-Bench tasks. Finally, we provide\nqualitative examples showing the new capabilities of U-PaLM for single and\nmulti-span infilling.",
        "date": "2022-10-20T16:46:41+00:00",
        "label": 1
    },
    "2212.10560": {
        "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
        "abstract": "Large \"instruction-tuned\" language models (i.e., finetuned to respond to\ninstructions) have demonstrated a remarkable ability to generalize zero-shot to\nnew tasks. Nevertheless, they depend heavily on human-written instruction data\nthat is often limited in quantity, diversity, and creativity, therefore\nhindering the generality of the tuned model. We introduce Self-Instruct, a\nframework for improving the instruction-following capabilities of pretrained\nlanguage models by bootstrapping off their own generations. Our pipeline\ngenerates instructions, input, and output samples from a language model, then\nfilters invalid or similar ones before using them to finetune the original\nmodel. Applying our method to the vanilla GPT3, we demonstrate a 33% absolute\nimprovement over the original model on Super-NaturalInstructions, on par with\nthe performance of InstructGPT-001, which was trained with private user data\nand human annotations. For further evaluation, we curate a set of\nexpert-written instructions for novel tasks, and show through human evaluation\nthat tuning GPT3 with Self-Instruct outperforms using existing public\ninstruction datasets by a large margin, leaving only a 5% absolute gap behind\nInstructGPT-001. Self-Instruct provides an almost annotation-free method for\naligning pre-trained language models with instructions, and we release our\nlarge synthetic dataset to facilitate future studies on instruction tuning. Our\ncode and data are available at https://github.com/yizhongw/self-instruct.",
        "date": "2022-12-20T18:59:19+00:00",
        "label": 1
    },
    "1905.10044": {
        "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions",
        "abstract": "In this paper we study yes/no questions that are naturally occurring ---\nmeaning that they are generated in unprompted and unconstrained settings. We\nbuild a reading comprehension dataset, BoolQ, of such questions, and show that\nthey are unexpectedly challenging. They often query for complex, non-factoid\ninformation, and require difficult entailment-like inference to solve. We also\nexplore the effectiveness of a range of transfer learning baselines. We find\nthat transferring from entailment data is more effective than transferring from\nparaphrase or extractive QA data, and that it, surprisingly, continues to be\nvery beneficial even when starting from massive pre-trained language models\nsuch as BERT. Our best method trains BERT on MultiNLI and then re-trains it on\nour train set. It achieves 80.4% accuracy compared to 90% accuracy of human\nannotators (and 62% majority-baseline), leaving a significant gap for future\nwork.",
        "date": "2019-05-24T05:48:49+00:00",
        "label": 1
    },
    "1908.05986": {
        "title": "FAIR and Open Computer Science Research Software",
        "abstract": "In computational science and in computer science, research software is a\ncentral asset for research. Computational science is the application of\ncomputer science and software engineering principles to solving scientific\nproblems, whereas computer science is the study of computer hardware and\nsoftware design.\n  The Open Science agenda holds that science advances faster when we can build\non existing results. Therefore, research software has to be reusable for\nadvancing science. Thus, we need proper research software engineering for\nobtaining reusable and sustainable research software. This way, software\nengineering methods may improve research in other disciplines. However,\nresearch in software engineering and computer science itself will also benefit\nfrom reuse when research software is involved.\n  For good scientific practice, the resulting research software should be open\nand adhere to the FAIR principles (findable, accessible, interoperable and\nrepeatable) to allow repeatability, reproducibility, and reuse. Compared to\nresearch data, research software should be both archived for reproducibility\nand actively maintained for reusability. The FAIR data principles do not\nrequire openness, but research software should be open source software.\nEstablished open source software licenses provide sufficient licensing options,\nsuch that it should be the rare exception to keep research software closed.\n  We review and analyze the current state in this area in order to give\nrecommendations for making computer science research software FAIR and open. We\nobserve that research software publishing practices in computer science and in\ncomputational science show significant differences.",
        "date": "2019-08-16T14:26:08+00:00",
        "label": 0
    },
    "1310.7911": {
        "title": "Compact manifolds with computable boundaries",
        "abstract": "We investigate conditions under which a co-computably enumerable closed set\nin a computable metric space is computable and prove that in each locally\ncomputable computable metric space each co-computably enumerable compact\nmanifold with computable boundary is computable. In fact, we examine the notion\nof a semi-computable compact set and we prove a more general result: in any\ncomputable metric space each semi-computable compact manifold with computable\nboundary is computable. In particular, each semi-computable compact\n(boundaryless) manifold is computable.",
        "date": "2013-10-29T18:29:13+00:00",
        "label": 0
    },
    "0705.1367": {
        "title": "Logic Column 18: Alternative Logics: A Book Review",
        "abstract": "This article discusses two books on the topic of alternative logics in\nscience: \"Deviant Logic\", by Susan Haack, and \"Alternative Logics: Do Sciences\nNeed Them?\", edited by Paul Weingartner.",
        "date": "2007-05-09T21:56:15+00:00",
        "label": 0
    },
    "1103.3321": {
        "title": "Typed Operational Semantics for Dependent Record Types",
        "abstract": "Typed operational semantics is a method developed by H. Goguen to prove\nmeta-theoretic properties of type systems. This paper studies the metatheory of\na type system with dependent record types, using the approach of typed\noperational semantics. In particular, the metatheoretical properties we have\nproved include strong normalisation, Church-Rosser and subject reduction.",
        "date": "2011-03-17T00:19:42+00:00",
        "label": 0
    },
    "1910.13461": {
        "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
        "abstract": "We present BART, a denoising autoencoder for pretraining sequence-to-sequence\nmodels. BART is trained by (1) corrupting text with an arbitrary noising\nfunction, and (2) learning a model to reconstruct the original text. It uses a\nstandard Tranformer-based neural machine translation architecture which,\ndespite its simplicity, can be seen as generalizing BERT (due to the\nbidirectional encoder), GPT (with the left-to-right decoder), and many other\nmore recent pretraining schemes. We evaluate a number of noising approaches,\nfinding the best performance by both randomly shuffling the order of the\noriginal sentences and using a novel in-filling scheme, where spans of text are\nreplaced with a single mask token. BART is particularly effective when fine\ntuned for text generation but also works well for comprehension tasks. It\nmatches the performance of RoBERTa with comparable training resources on GLUE\nand SQuAD, achieves new state-of-the-art results on a range of abstractive\ndialogue, question answering, and summarization tasks, with gains of up to 6\nROUGE. BART also provides a 1.1 BLEU increase over a back-translation system\nfor machine translation, with only target language pretraining. We also report\nablation experiments that replicate other pretraining schemes within the BART\nframework, to better measure which factors most influence end-task performance.",
        "date": "2019-10-29T18:01:00+00:00",
        "label": 1
    },
    "2305.10403": {
        "title": "PaLM 2 Technical Report",
        "abstract": "We introduce PaLM 2, a new state-of-the-art language model that has better\nmultilingual and reasoning capabilities and is more compute-efficient than its\npredecessor PaLM. PaLM 2 is a Transformer-based model trained using a mixture\nof objectives. Through extensive evaluations on English and multilingual\nlanguage, and reasoning tasks, we demonstrate that PaLM 2 has significantly\nimproved quality on downstream tasks across different model sizes, while\nsimultaneously exhibiting faster and more efficient inference compared to PaLM.\nThis improved efficiency enables broader deployment while also allowing the\nmodel to respond faster, for a more natural pace of interaction. PaLM 2\ndemonstrates robust reasoning capabilities exemplified by large improvements\nover PaLM on BIG-Bench and other reasoning tasks. PaLM 2 exhibits stable\nperformance on a suite of responsible AI evaluations, and enables\ninference-time control over toxicity without additional overhead or impact on\nother capabilities. Overall, PaLM 2 achieves state-of-the-art performance\nacross a diverse set of tasks and capabilities.\n  When discussing the PaLM 2 family, it is important to distinguish between\npre-trained models (of various sizes), fine-tuned variants of these models, and\nthe user-facing products that use these models. In particular, user-facing\nproducts typically include additional pre- and post-processing steps.\nAdditionally, the underlying models may evolve over time. Therefore, one should\nnot expect the performance of user-facing products to exactly match the results\nreported in this report.",
        "date": "2023-05-17T17:46:53+00:00",
        "label": 1
    },
    "1307.8029": {
        "title": "Proceedings Fourth International Symposium on Symbolic Computation in Software Science",
        "abstract": "Symbolic computation is the science of computing with symbolic objects\n(terms, formulae, programs, algebraic objects, geometrical objects, etc).\nPowerful symbolic algorithms have been developed during the past decades and\nhave played an influential role in theorem proving, automated reasoning,\nsoftware verification, model checking, rewriting, formalisation of mathematics,\nnetwork security, Groebner bases, characteristic sets, etc.\n  The international Symposium on \"Symbolic Computation in Software Science\" is\nthe fourth in the SCSS workshop series. SCSS 2008 and 2010 took place at the\nResearch Institute for Symbolic Computation (RISC), Hagenberg, Austria, and,\nSCSS 2009 took place in Gammarth, Tunisia. These symposium grew out of internal\nworkshops that bring together researchers from: a) SCORE (Symbolic Computation\nResearch Group) at the University of Tsukuba, Japan, b) Theorema Group at the\nResearch Institute for Symbolic Computation, Johannes Kepler University Linz,\nAustria, c) SSFG (Software Science Foundation Group) at Kyoto University,\nJapan, and d) Sup'Com (Higher School of Communication of Tunis) at the\nUniversity of Carthage, Tunisia.",
        "date": "2013-07-30T16:01:33+00:00",
        "label": 0
    },
    "1904.13112": {
        "title": "On the incomputability of computable dimension",
        "abstract": "Using an iterative tree construction we show that for simple computable\nsubsets of the Cantor space Hausdorff, constructive and computable dimensions\nmight be incomputable.",
        "date": "2019-04-30T09:07:37+00:00",
        "label": 0
    },
    "2309.07864": {
        "title": "The Rise and Potential of Large Language Model Based Agents: A Survey",
        "abstract": "For a long time, humanity has pursued artificial intelligence (AI) equivalent\nto or surpassing the human level, with AI agents considered a promising vehicle\nfor this pursuit. AI agents are artificial entities that sense their\nenvironment, make decisions, and take actions. Many efforts have been made to\ndevelop intelligent agents, but they mainly focus on advancement in algorithms\nor training strategies to enhance specific capabilities or performance on\nparticular tasks. Actually, what the community lacks is a general and powerful\nmodel to serve as a starting point for designing AI agents that can adapt to\ndiverse scenarios. Due to the versatile capabilities they demonstrate, large\nlanguage models (LLMs) are regarded as potential sparks for Artificial General\nIntelligence (AGI), offering hope for building general AI agents. Many\nresearchers have leveraged LLMs as the foundation to build AI agents and have\nachieved significant progress. In this paper, we perform a comprehensive survey\non LLM-based agents. We start by tracing the concept of agents from its\nphilosophical origins to its development in AI, and explain why LLMs are\nsuitable foundations for agents. Building upon this, we present a general\nframework for LLM-based agents, comprising three main components: brain,\nperception, and action, and the framework can be tailored for different\napplications. Subsequently, we explore the extensive applications of LLM-based\nagents in three aspects: single-agent scenarios, multi-agent scenarios, and\nhuman-agent cooperation. Following this, we delve into agent societies,\nexploring the behavior and personality of LLM-based agents, the social\nphenomena that emerge from an agent society, and the insights they offer for\nhuman society. Finally, we discuss several key topics and open problems within\nthe field. A repository for the related papers at\nhttps://github.com/WooooDyy/LLM-Agent-Paper-List.",
        "date": "2023-09-14T17:12:03+00:00",
        "label": 1
    },
    "2109.01661": {
        "title": "Data science and Machine learning in the Clouds: A Perspective for the Future",
        "abstract": "As we are fast approaching the beginning of a paradigm shift in the field of\nscience, Data driven science (the so called fourth science paradigm) is going\nto be the driving force in research and innovation. From medicine to\nbiodiversity and astronomy to geology, all these terms are somehow going to be\naffected by this paradigm shift. The huge amount of data to be processed under\nthis new paradigm will be a major concern in the future and one will strongly\nrequire cloud based services in all the aspects of these computations (from\nstorage to compute and other services). Another aspect will be energy\nconsumption and performance of prediction jobs and tasks within such a\nscientific paradigm which will change the way one sees computation. Data\nscience has heavily impacted or rather triggered the emergence of Machine\nLearning, Signal/Image/Video processing related algorithms, Artificial\nintelligence, Robotics, health informatics, geoinformatics, and many more such\nareas of interest. Hence, we envisage an era where Data science can deliver its\npromises with the help of the existing cloud based platforms and services with\nthe addition of new services. In this article, we discuss about data driven\nscience and Machine learning and how they are going to be linked through cloud\nbased services in the future. It also discusses the rise of paradigms like\napproximate computing, quantum computing and many more in recent times and\ntheir applicability in big data processing, data science, analytics, prediction\nand machine learning in the cloud environments.",
        "date": "2021-09-02T17:36:24+00:00",
        "label": 0
    },
    "2103.03874": {
        "title": "Measuring Mathematical Problem Solving With the MATH Dataset",
        "abstract": "Many intellectual endeavors require mathematical problem solving, but this\nskill remains beyond the capabilities of computers. To measure this ability in\nmachine learning models, we introduce MATH, a new dataset of 12,500 challenging\ncompetition mathematics problems. Each problem in MATH has a full step-by-step\nsolution which can be used to teach models to generate answer derivations and\nexplanations. To facilitate future research and increase accuracy on MATH, we\nalso contribute a large auxiliary pretraining dataset which helps teach models\nthe fundamentals of mathematics. Even though we are able to increase accuracy\non MATH, our results show that accuracy remains relatively low, even with\nenormous Transformer models. Moreover, we find that simply increasing budgets\nand model parameter counts will be impractical for achieving strong\nmathematical reasoning if scaling trends continue. While scaling Transformers\nis automatically solving most other text-based tasks, scaling is not currently\nsolving MATH. To have more traction on mathematical problem solving we will\nlikely need new algorithmic advancements from the broader research community.",
        "date": "2021-03-05T18:59:39+00:00",
        "label": 1
    },
    "2302.13971": {
        "title": "LLaMA: Open and Efficient Foundation Language Models",
        "abstract": "We introduce LLaMA, a collection of foundation language models ranging from\n7B to 65B parameters. We train our models on trillions of tokens, and show that\nit is possible to train state-of-the-art models using publicly available\ndatasets exclusively, without resorting to proprietary and inaccessible\ndatasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks,\nand LLaMA-65B is competitive with the best models, Chinchilla-70B and\nPaLM-540B. We release all our models to the research community.",
        "date": "2023-02-27T17:11:15+00:00",
        "label": 1
    },
    "1904.01053": {
        "title": "Computer simulations in science and engineering - Concepts - Practices - Perspectives",
        "abstract": "The ubiquitous presence of computer simulations in all kinds of research\nareas evidence their role as the new driving force for the advancement of\nscience and engineering research. Nothing seems to escape the image of success\nthat computer simulations project onto the research community and the general\npublic. One simple way to illustrate this consists of asking ourselves how\nwould contemporary science and engineering look like without the use of\ncomputer simulations. The answer would certainly diverge from the current image\nwe have of scientific and engineering research.\n  As much as computer simulations are successful, they are also methods that\nfail in their purpose of inquiring about the world; and as much as researchers\nmake use of them, computer simulations raise important questions that are at\nthe heart of contemporary science and engineering practice. In this respect,\ncomputer simulations make a fantastic subject of research for the natural\nsciences, the social sciences, engineering and, as in our case, also for\nphilosophy. Studies on computer simulations touch upon many different facets of\nscientific and engineering research and evoke philosophically inclined\nquestions of interpretation with close ties to problems in experimental\nsettings and engineering applications (...)",
        "date": "2019-03-09T15:26:05+00:00",
        "label": 0
    },
    "2302.14045": {
        "title": "Language Is Not All You Need: Aligning Perception with Language Models",
        "abstract": "A big convergence of language, multimodal perception, action, and world\nmodeling is a key step toward artificial general intelligence. In this work, we\nintroduce Kosmos-1, a Multimodal Large Language Model (MLLM) that can perceive\ngeneral modalities, learn in context (i.e., few-shot), and follow instructions\n(i.e., zero-shot). Specifically, we train Kosmos-1 from scratch on web-scale\nmultimodal corpora, including arbitrarily interleaved text and images,\nimage-caption pairs, and text data. We evaluate various settings, including\nzero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range\nof tasks without any gradient updates or finetuning. Experimental results show\nthat Kosmos-1 achieves impressive performance on (i) language understanding,\ngeneration, and even OCR-free NLP (directly fed with document images), (ii)\nperception-language tasks, including multimodal dialogue, image captioning,\nvisual question answering, and (iii) vision tasks, such as image recognition\nwith descriptions (specifying classification via text instructions). We also\nshow that MLLMs can benefit from cross-modal transfer, i.e., transfer knowledge\nfrom language to multimodal, and from multimodal to language. In addition, we\nintroduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning\ncapability of MLLMs.",
        "date": "2023-02-27T18:55:27+00:00",
        "label": 1
    },
    "2007.03606": {
        "title": "Data Science: A Comprehensive Overview",
        "abstract": "The twenty-first century has ushered in the age of big data and data economy,\nin which data DNA, which carries important knowledge, insights and potential,\nhas become an intrinsic constituent of all data-based organisms. An appropriate\nunderstanding of data DNA and its organisms relies on the new field of data\nscience and its keystone, analytics. Although it is widely debated whether big\ndata is only hype and buzz, and data science is still in a very early phase,\nsignificant challenges and opportunities are emerging or have been inspired by\nthe research, innovation, business, profession, and education of data science.\nThis paper provides a comprehensive survey and tutorial of the fundamental\naspects of data science: the evolution from data analysis to data science, the\ndata science concepts, a big picture of the era of data science, the major\nchallenges and directions in data innovation, the nature of data analytics, new\nindustrialization and service opportunities in the data economy, the profession\nand competency of data education, and the future of data science. This article\nis the first in the field to draw a comprehensive big picture, in addition to\noffering rich observations, lessons and thinking about data science and\nanalytics.",
        "date": "2020-07-01T02:33:58+00:00",
        "label": 0
    },
    "1404.5458": {
        "title": "Complex Workflow Management and Integration of Distributed Computing Resources by Science Gateway Portal for Molecular Dynamics Simulations in Materials Science",
        "abstract": "The \"IMP Science Gateway Portal\" (http://scigate.imp.kiev.ua) for complex\nworkflow management and integration of distributed computing resources (like\nclusters, service grids, desktop grids, clouds) is presented. It is created on\nthe basis of WS-PGRADE and gUSE technologies, where WS-PGRADE is designed for\nscience workflow operation and gUSE - for smooth integration of available\nresources for parallel and distributed computing in various heterogeneous\ndistributed computing infrastructures (DCI). The typical scientific workflow\nwith possible scenarios of its preparation and usage is considered. Several\ntypical science applications (scientific workflows) are considered for\nmolecular dynamics (MD) simulations of complex behavior of various\nnanostructures (nanoindentation of graphene layers, defect system relaxation in\nmetal nanocrystals, thermal stability of boron nitride nanotubes, etc.). The\nadvantages and drawbacks of the solution are shortly analyzed in the context of\nits practical applications for MD simulations in materials science, physics and\nnanotechnologies with available heterogeneous DCIs.",
        "date": "2014-04-22T11:34:04+00:00",
        "label": 0
    },
    "1904.09728": {
        "title": "SocialIQA: Commonsense Reasoning about Social Interactions",
        "abstract": "We introduce Social IQa, the first largescale benchmark for commonsense\nreasoning about social situations. Social IQa contains 38,000 multiple choice\nquestions for probing emotional and social intelligence in a variety of\neveryday situations (e.g., Q: \"Jordan wanted to tell Tracy a secret, so Jordan\nleaned towards Tracy. Why did Jordan do this?\" A: \"Make sure no one else could\nhear\"). Through crowdsourcing, we collect commonsense questions along with\ncorrect and incorrect answers about social interactions, using a new framework\nthat mitigates stylistic artifacts in incorrect answers by asking workers to\nprovide the right answer to a different but related question. Empirical results\nshow that our benchmark is challenging for existing question-answering models\nbased on pretrained language models, compared to human performance (>20% gap).\nNotably, we further establish Social IQa as a resource for transfer learning of\ncommonsense knowledge, achieving state-of-the-art performance on multiple\ncommonsense reasoning tasks (Winograd Schemas, COPA).",
        "date": "2019-04-22T05:36:37+00:00",
        "label": 1
    },
    "2106.09685": {
        "title": "LoRA: Low-Rank Adaptation of Large Language Models",
        "abstract": "An important paradigm of natural language processing consists of large-scale\npre-training on general domain data and adaptation to particular tasks or\ndomains. As we pre-train larger models, full fine-tuning, which retrains all\nmodel parameters, becomes less feasible. Using GPT-3 175B as an example --\ndeploying independent instances of fine-tuned models, each with 175B\nparameters, is prohibitively expensive. We propose Low-Rank Adaptation, or\nLoRA, which freezes the pre-trained model weights and injects trainable rank\ndecomposition matrices into each layer of the Transformer architecture, greatly\nreducing the number of trainable parameters for downstream tasks. Compared to\nGPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable\nparameters by 10,000 times and the GPU memory requirement by 3 times. LoRA\nperforms on-par or better than fine-tuning in model quality on RoBERTa,\nDeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher\ntraining throughput, and, unlike adapters, no additional inference latency. We\nalso provide an empirical investigation into rank-deficiency in language model\nadaptation, which sheds light on the efficacy of LoRA. We release a package\nthat facilitates the integration of LoRA with PyTorch models and provide our\nimplementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at\nhttps://github.com/microsoft/LoRA.",
        "date": "2021-06-17T17:37:18+00:00",
        "label": 1
    },
    "1911.11641": {
        "title": "PIQA: Reasoning about Physical Commonsense in Natural Language",
        "abstract": "To apply eyeshadow without a brush, should I use a cotton swab or a\ntoothpick? Questions requiring this kind of physical commonsense pose a\nchallenge to today's natural language understanding systems. While recent\npretrained models (such as BERT) have made progress on question answering over\nmore abstract domains - such as news articles and encyclopedia entries, where\ntext is plentiful - in more physical domains, text is inherently limited due to\nreporting bias. Can AI systems learn to reliably answer physical common-sense\nquestions without experiencing the physical world? In this paper, we introduce\nthe task of physical commonsense reasoning and a corresponding benchmark\ndataset Physical Interaction: Question Answering or PIQA. Though humans find\nthe dataset easy (95% accuracy), large pretrained models struggle (77%). We\nprovide analysis about the dimensions of knowledge that existing models lack,\nwhich offers significant opportunities for future research.",
        "date": "2019-11-26T15:31:46+00:00",
        "label": 1
    },
    "2106.07553": {
        "title": "A Cognitive Science perspective for learning how to design meaningful user experiences and human-centered technology",
        "abstract": "This paper reviews literature in cognitive science, human-computer\ninteraction (HCI) and natural-language processing (NLP) to consider how\nanalogical reasoning (AR) could help inform the design of communication and\nlearning technologies, as well as online communities and digital platforms.\nFirst, analogical reasoning (AR) is defined, and use-cases of AR in the\ncomputing sciences are presented. The concept of schema is introduced, along\nwith use-cases in computing. Finally, recommendations are offered for future\nwork on using analogical reasoning and schema methods in the computing\nsciences.",
        "date": "2021-06-02T15:00:50+00:00",
        "label": 0
    },
    "1807.03750": {
        "title": "Navigating Diverse Data Science Learning: Critical Reflections Towards Future Practice",
        "abstract": "Data Science is currently a popular field of science attracting expertise\nfrom very diverse backgrounds. Current learning practices need to acknowledge\nthis and adapt to it. This paper summarises some experiences relating to such\nlearning approaches from teaching a postgraduate Data Science module, and draws\nsome learned lessons that are of relevance to others teaching Data Science.",
        "date": "2018-07-05T21:32:18+00:00",
        "label": 0
    },
    "2312.00752": {
        "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
        "abstract": "Foundation models, now powering most of the exciting applications in deep\nlearning, are almost universally based on the Transformer architecture and its\ncore attention module. Many subquadratic-time architectures such as linear\nattention, gated convolution and recurrent models, and structured state space\nmodels (SSMs) have been developed to address Transformers' computational\ninefficiency on long sequences, but they have not performed as well as\nattention on important modalities such as language. We identify that a key\nweakness of such models is their inability to perform content-based reasoning,\nand make several improvements. First, simply letting the SSM parameters be\nfunctions of the input addresses their weakness with discrete modalities,\nallowing the model to selectively propagate or forget information along the\nsequence length dimension depending on the current token. Second, even though\nthis change prevents the use of efficient convolutions, we design a\nhardware-aware parallel algorithm in recurrent mode. We integrate these\nselective SSMs into a simplified end-to-end neural network architecture without\nattention or even MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$\nhigher throughput than Transformers) and linear scaling in sequence length, and\nits performance improves on real data up to million-length sequences. As a\ngeneral sequence model backbone, Mamba achieves state-of-the-art performance\nacross several modalities such as language, audio, and genomics. On language\nmodeling, our Mamba-3B model outperforms Transformers of the same size and\nmatches Transformers twice its size, both in pretraining and downstream\nevaluation.",
        "date": "2023-12-01T18:01:34+00:00",
        "label": 1
    },
    "2211.05100": {
        "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model",
        "abstract": "Large language models (LLMs) have been shown to be able to perform new tasks\nbased on a few demonstrations or natural language instructions. While these\ncapabilities have led to widespread adoption, most LLMs are developed by\nresource-rich organizations and are frequently kept from the public. As a step\ntowards democratizing this powerful technology, we present BLOOM, a\n176B-parameter open-access language model designed and built thanks to a\ncollaboration of hundreds of researchers. BLOOM is a decoder-only Transformer\nlanguage model that was trained on the ROOTS corpus, a dataset comprising\nhundreds of sources in 46 natural and 13 programming languages (59 in total).\nWe find that BLOOM achieves competitive performance on a wide variety of\nbenchmarks, with stronger results after undergoing multitask prompted\nfinetuning. To facilitate future research and applications using LLMs, we\npublicly release our models and code under the Responsible AI License.",
        "date": "2022-11-09T18:48:09+00:00",
        "label": 1
    },
    "2108.07732": {
        "title": "Program Synthesis with Large Language Models",
        "abstract": "This paper explores the limits of the current generation of large language\nmodels for program synthesis in general purpose programming languages. We\nevaluate a collection of such models (with between 244M and 137B parameters) on\ntwo new benchmarks, MBPP and MathQA-Python, in both the few-shot and\nfine-tuning regimes. Our benchmarks are designed to measure the ability of\nthese models to synthesize short Python programs from natural language\ndescriptions. The Mostly Basic Programming Problems (MBPP) dataset contains 974\nprogramming tasks, designed to be solvable by entry-level programmers. The\nMathQA-Python dataset, a Python version of the MathQA benchmark, contains 23914\nproblems that evaluate the ability of the models to synthesize code from more\ncomplex text. On both datasets, we find that synthesis performance scales\nlog-linearly with model size. Our largest models, even without finetuning on a\ncode dataset, can synthesize solutions to 59.6 percent of the problems from\nMBPP using few-shot learning with a well-designed prompt. Fine-tuning on a\nheld-out portion of the dataset improves performance by about 10 percentage\npoints across most model sizes. On the MathQA-Python dataset, the largest\nfine-tuned model achieves 83.8 percent accuracy. Going further, we study the\nmodel's ability to engage in dialog about code, incorporating human feedback to\nimprove its solutions. We find that natural language feedback from a human\nhalves the error rate compared to the model's initial prediction. Additionally,\nwe conduct an error analysis to shed light on where these models fall short and\nwhat types of programs are most difficult to generate. Finally, we explore the\nsemantic grounding of these models by fine-tuning them to predict the results\nof program execution. We find that even our best models are generally unable to\npredict the output of a program given a specific input.",
        "date": "2021-08-16T03:57:30+00:00",
        "label": 1
    },
    "2204.02311": {
        "title": "PaLM: Scaling Language Modeling with Pathways",
        "abstract": "Large language models have been shown to achieve remarkable performance\nacross a variety of natural language tasks using few-shot learning, which\ndrastically reduces the number of task-specific training examples needed to\nadapt the model to a particular application. To further our understanding of\nthe impact of scale on few-shot learning, we trained a 540-billion parameter,\ndensely activated, Transformer language model, which we call Pathways Language\nModel PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML\nsystem which enables highly efficient training across multiple TPU Pods. We\ndemonstrate continued benefits of scaling by achieving state-of-the-art\nfew-shot learning results on hundreds of language understanding and generation\nbenchmarks. On a number of these tasks, PaLM 540B achieves breakthrough\nperformance, outperforming the finetuned state-of-the-art on a suite of\nmulti-step reasoning tasks, and outperforming average human performance on the\nrecently released BIG-bench benchmark. A significant number of BIG-bench tasks\nshowed discontinuous improvements from model scale, meaning that performance\nsteeply increased as we scaled to our largest model. PaLM also has strong\ncapabilities in multilingual tasks and source code generation, which we\ndemonstrate on a wide array of benchmarks. We additionally provide a\ncomprehensive analysis on bias and toxicity, and study the extent of training\ndata memorization with respect to model scale. Finally, we discuss the ethical\nconsiderations related to large language models and discuss potential\nmitigation strategies.",
        "date": "2022-04-05T16:11:45+00:00",
        "label": 1
    },
    "2312.11805": {
        "title": "Gemini: A Family of Highly Capable Multimodal Models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that\nexhibit remarkable capabilities across image, audio, video, and text\nunderstanding. The Gemini family consists of Ultra, Pro, and Nano sizes,\nsuitable for applications ranging from complex reasoning tasks to on-device\nmemory-constrained use-cases. Evaluation on a broad range of benchmarks shows\nthat our most-capable Gemini Ultra model advances the state of the art in 30 of\n32 of these benchmarks - notably being the first model to achieve human-expert\nperformance on the well-studied exam benchmark MMLU, and improving the state of\nthe art in every one of the 20 multimodal benchmarks we examined. We believe\nthat the new capabilities of the Gemini family in cross-modal reasoning and\nlanguage understanding will enable a wide variety of use cases. We discuss our\napproach toward post-training and deploying Gemini models responsibly to users\nthrough services including Gemini, Gemini Advanced, Google AI Studio, and Cloud\nVertex AI.",
        "date": "2023-12-19T02:39:27+00:00",
        "label": 1
    },
    "1003.1473": {
        "title": "Comments on \"Routh Stability Criterion\"",
        "abstract": "In this note, we have shown special case on Routh stability criterion, which\nis not discussed, in previous literature. This idea can be useful in computer\nscience applications.",
        "date": "2010-03-07T14:09:11+00:00",
        "label": 0
    },
    "2010.07017": {
        "title": "Computational Skills by Stealth in Secondary School Data Science",
        "abstract": "The unprecedented growth in the availability of data of all types and\nqualities and the emergence of the field of data science has provided an\nimpetus to finally realizing the implementation of the full breadth of the\nNolan and Temple Lang proposed integration of computing concepts into\nstatistics curricula at all levels in statistics and new data science programs\nand courses. Moreover, data science, implemented carefully, opens accessible\npathways to stem for students for whom neither mathematics nor computer science\nare natural affinities, and who would traditionally be excluded. We discuss a\nproposal for the stealth development of computational skills in students' first\nexposure to data science through careful, scaffolded exposure to computation\nand its power. The intent of this approach is to support students, regardless\nof interest and self-efficacy in coding, in becoming data-driven learners, who\nare capable of asking complex questions about the world around them, and then\nanswering those questions through the use of data-driven inquiry. This\ndiscussion is presented in the context of the International Data Science in\nSchools Project which recently published computer science and statistics\nconsensus curriculum frameworks for a two-year secondary school data science\nprogram, designed to make data science accessible to all.",
        "date": "2020-10-08T09:11:51+00:00",
        "label": 0
    },
    "2210.06878": {
        "title": "CS-Insights: A System for Analyzing Computer Science Research",
        "abstract": "This paper presents CS-Insights, an interactive web application to analyze\ncomputer science publications from DBLP through multiple perspectives. The\ndedicated interfaces allow its users to identify trends in research activity,\nproductivity, accessibility, author's productivity, venues' statistics, topics\nof interest, and the impact of computer science research on other fields.\nCS-Insightsis publicly available, and its modular architecture can be easily\nadapted to domains other than computer science.",
        "date": "2022-10-13T10:03:52+00:00",
        "label": 0
    },
    "2303.18223": {
        "title": "A Survey of Large Language Models",
        "abstract": "Language is essentially a complex, intricate system of human expressions\ngoverned by grammatical rules. It poses a significant challenge to develop\ncapable AI algorithms for comprehending and grasping a language. As a major\napproach, language modeling has been widely studied for language understanding\nand generation in the past two decades, evolving from statistical language\nmodels to neural language models. Recently, pre-trained language models (PLMs)\nhave been proposed by pre-training Transformer models over large-scale corpora,\nshowing strong capabilities in solving various NLP tasks. Since researchers\nhave found that model scaling can lead to performance improvement, they further\nstudy the scaling effect by increasing the model size to an even larger size.\nInterestingly, when the parameter scale exceeds a certain level, these enlarged\nlanguage models not only achieve a significant performance improvement but also\nshow some special abilities that are not present in small-scale language\nmodels. To discriminate the difference in parameter scale, the research\ncommunity has coined the term large language models (LLM) for the PLMs of\nsignificant size. Recently, the research on LLMs has been largely advanced by\nboth academia and industry, and a remarkable progress is the launch of ChatGPT,\nwhich has attracted widespread attention from society. The technical evolution\nof LLMs has been making an important impact on the entire AI community, which\nwould revolutionize the way how we develop and use AI algorithms. In this\nsurvey, we review the recent advances of LLMs by introducing the background,\nkey findings, and mainstream techniques. In particular, we focus on four major\naspects of LLMs, namely pre-training, adaptation tuning, utilization, and\ncapacity evaluation. Besides, we also summarize the available resources for\ndeveloping LLMs and discuss the remaining issues for future directions.",
        "date": "2023-03-31T17:28:46+00:00",
        "label": 1
    },
    "2112.09332": {
        "title": "WebGPT: Browser-assisted question-answering with human feedback",
        "abstract": "We fine-tune GPT-3 to answer long-form questions using a text-based\nweb-browsing environment, which allows the model to search and navigate the\nweb. By setting up the task so that it can be performed by humans, we are able\nto train models on the task using imitation learning, and then optimize answer\nquality with human feedback. To make human evaluation of factual accuracy\neasier, models must collect references while browsing in support of their\nanswers. We train and evaluate our models on ELI5, a dataset of questions asked\nby Reddit users. Our best model is obtained by fine-tuning GPT-3 using behavior\ncloning, and then performing rejection sampling against a reward model trained\nto predict human preferences. This model's answers are preferred by humans 56%\nof the time to those of our human demonstrators, and 69% of the time to the\nhighest-voted answer from Reddit.",
        "date": "2021-12-17T05:43:43+00:00",
        "label": 1
    },
    "2307.09288": {
        "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models",
        "abstract": "In this work, we develop and release Llama 2, a collection of pretrained and\nfine-tuned large language models (LLMs) ranging in scale from 7 billion to 70\nbillion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for\ndialogue use cases. Our models outperform open-source chat models on most\nbenchmarks we tested, and based on our human evaluations for helpfulness and\nsafety, may be a suitable substitute for closed-source models. We provide a\ndetailed description of our approach to fine-tuning and safety improvements of\nLlama 2-Chat in order to enable the community to build on our work and\ncontribute to the responsible development of LLMs.",
        "date": "2023-07-18T14:31:57+00:00",
        "label": 1
    },
    "2311.10833": {
        "title": "Generative AI has lowered the barriers to computational social sciences",
        "abstract": "Generative artificial intelligence (AI) has revolutionized the field of\ncomputational social science, unleashing new possibilities for analyzing\nmultimodal data, especially for scholars who may not have extensive programming\nexpertise. This breakthrough carries profound implications for the realm of\nsocial sciences. Firstly, generative AI can significantly enhance the\nproductivity of social scientists by automating the generation, annotation, and\ndebugging of code. Secondly, it empowers researchers to delve into\nsophisticated data analysis through the innovative use of prompt engineering.\nLastly, the educational sphere of computational social science stands to\nbenefit immensely from these tools, given their exceptional ability to annotate\nand elucidate complex codes for learners, thereby simplifying the learning\nprocess and making the technology more accessible.",
        "date": "2023-11-17T19:24:39+00:00",
        "label": 0
    },
    "2305.09617": {
        "title": "Towards Expert-Level Medical Question Answering with Large Language Models",
        "abstract": "Recent artificial intelligence (AI) systems have reached milestones in \"grand\nchallenges\" ranging from Go to protein-folding. The capability to retrieve\nmedical knowledge, reason over it, and answer medical questions comparably to\nphysicians has long been viewed as one such grand challenge.\n  Large language models (LLMs) have catalyzed significant progress in medical\nquestion answering; Med-PaLM was the first model to exceed a \"passing\" score in\nUS Medical Licensing Examination (USMLE) style questions with a score of 67.2%\non the MedQA dataset. However, this and other prior work suggested significant\nroom for improvement, especially when models' answers were compared to\nclinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by\nleveraging a combination of base LLM improvements (PaLM 2), medical domain\nfinetuning, and prompting strategies including a novel ensemble refinement\napproach.\n  Med-PaLM 2 scored up to 86.5% on the MedQA dataset, improving upon Med-PaLM\nby over 19% and setting a new state-of-the-art. We also observed performance\napproaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU\nclinical topics datasets.\n  We performed detailed human evaluations on long-form questions along multiple\naxes relevant to clinical applications. In pairwise comparative ranking of 1066\nconsumer medical questions, physicians preferred Med-PaLM 2 answers to those\nproduced by physicians on eight of nine axes pertaining to clinical utility (p\n< 0.001). We also observed significant improvements compared to Med-PaLM on\nevery evaluation axis (p < 0.001) on newly introduced datasets of 240 long-form\n\"adversarial\" questions to probe LLM limitations.\n  While further studies are necessary to validate the efficacy of these models\nin real-world settings, these results highlight rapid progress towards\nphysician-level performance in medical question answering.",
        "date": "2023-05-16T17:11:29+00:00",
        "label": 1
    },
    "2303.17580": {
        "title": "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face",
        "abstract": "Solving complicated AI tasks with different domains and modalities is a key\nstep toward artificial general intelligence. While there are numerous AI models\navailable for various domains and modalities, they cannot handle complicated AI\ntasks autonomously. Considering large language models (LLMs) have exhibited\nexceptional abilities in language understanding, generation, interaction, and\nreasoning, we advocate that LLMs could act as a controller to manage existing\nAI models to solve complicated AI tasks, with language serving as a generic\ninterface to empower this. Based on this philosophy, we present HuggingGPT, an\nLLM-powered agent that leverages LLMs (e.g., ChatGPT) to connect various AI\nmodels in machine learning communities (e.g., Hugging Face) to solve AI tasks.\nSpecifically, we use ChatGPT to conduct task planning when receiving a user\nrequest, select models according to their function descriptions available in\nHugging Face, execute each subtask with the selected AI model, and summarize\nthe response according to the execution results. By leveraging the strong\nlanguage capability of ChatGPT and abundant AI models in Hugging Face,\nHuggingGPT can tackle a wide range of sophisticated AI tasks spanning different\nmodalities and domains and achieve impressive results in language, vision,\nspeech, and other challenging tasks, which paves a new way towards the\nrealization of artificial general intelligence.",
        "date": "2023-03-30T17:48:28+00:00",
        "label": 1
    },
    "2201.08239": {
        "title": "LaMDA: Language Models for Dialog Applications",
        "abstract": "We present LaMDA: Language Models for Dialog Applications. LaMDA is a family\nof Transformer-based neural language models specialized for dialog, which have\nup to 137B parameters and are pre-trained on 1.56T words of public dialog data\nand web text. While model scaling alone can improve quality, it shows less\nimprovements on safety and factual grounding. We demonstrate that fine-tuning\nwith annotated data and enabling the model to consult external knowledge\nsources can lead to significant improvements towards the two key challenges of\nsafety and factual grounding. The first challenge, safety, involves ensuring\nthat the model's responses are consistent with a set of human values, such as\npreventing harmful suggestions and unfair bias. We quantify safety using a\nmetric based on an illustrative set of human values, and we find that filtering\ncandidate responses using a LaMDA classifier fine-tuned with a small amount of\ncrowdworker-annotated data offers a promising approach to improving model\nsafety. The second challenge, factual grounding, involves enabling the model to\nconsult external knowledge sources, such as an information retrieval system, a\nlanguage translator, and a calculator. We quantify factuality using a\ngroundedness metric, and we find that our approach enables the model to\ngenerate responses grounded in known sources, rather than responses that merely\nsound plausible. Finally, we explore the use of LaMDA in the domains of\neducation and content recommendations, and analyze their helpfulness and role\nconsistency.",
        "date": "2022-01-20T15:44:37+00:00",
        "label": 1
    },
    "1909.03033": {
        "title": "The Difficulties of Addressing Interdisciplinary Challenges at the Foundations of Data Science",
        "abstract": "The National Science Foundation's Transdisciplinary Research in Principles of\nData Science (TRIPODS) program aims to integrate three areas central to the\nfoundations of data by uniting the statistics, mathematics, and theoretical\ncomputer science research communities. The program aims to provide a model for\nfunding cross-cutting research and facilitating interactions among the three\ndisciplines. Challenges associated with orchestrating fruitful interactions are\ndescribed.",
        "date": "2019-09-04T06:07:26+00:00",
        "label": 0
    },
    "2104.09864": {
        "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding",
        "abstract": "Position encoding recently has shown effective in the transformer\narchitecture. It enables valuable supervision for dependency modeling between\nelements at different positions of the sequence. In this paper, we first\ninvestigate various methods to integrate positional information into the\nlearning process of transformer-based language models. Then, we propose a novel\nmethod named Rotary Position Embedding(RoPE) to effectively leverage the\npositional information. Specifically, the proposed RoPE encodes the absolute\nposition with a rotation matrix and meanwhile incorporates the explicit\nrelative position dependency in self-attention formulation. Notably, RoPE\nenables valuable properties, including the flexibility of sequence length,\ndecaying inter-token dependency with increasing relative distances, and the\ncapability of equipping the linear self-attention with relative position\nencoding. Finally, we evaluate the enhanced transformer with rotary position\nembedding, also called RoFormer, on various long text classification benchmark\ndatasets. Our experiments show that it consistently overcomes its alternatives.\nFurthermore, we provide a theoretical analysis to explain some experimental\nresults. RoFormer is already integrated into Huggingface:\n\\url{https://huggingface.co/docs/transformers/model_doc/roformer}.",
        "date": "2021-04-20T09:54:06+00:00",
        "label": 1
    },
    "9505013": {
        "title": "Wavelet basis for the Schr\u00f6dinger equation",
        "abstract": "The self-similar representation for the Schr\\\"{o}dinger equation is derived.",
        "date": "1995-05-16T16:19:16+00:00",
        "label": 0
    },
    "2103.10489": {
        "title": "Addressing Hate Speech with Data Science: An Overview from Computer Science Perspective",
        "abstract": "From a computer science perspective, addressing on-line hate speech is a\nchallenging task that is attracting the attention of both industry (mainly\nsocial media platform owners) and academia. In this chapter, we provide an\noverview of state-of-the-art data-science approaches - how they define hate\nspeech, which tasks they solve to mitigate the phenomenon, and how they address\nthese tasks. We limit our investigation mostly to (semi-)automatic detection of\nhate speech, which is the task that the majority of existing computer science\nworks focus on. Finally, we summarize the challenges and the open problems in\nthe current data-science research and the future directions in this field. Our\naim is to prepare an easily understandable report, capable to promote the\nmultidisciplinary character of hate speech research. Researchers from other\ndomains (e.g., psychology and sociology) can thus take advantage of the\nknowledge achieved in the computer science domain but also contribute back and\nhelp improve how computer science is addressing that urgent and socially\nrelevant issue which is the prevalence of hate speech in social media.",
        "date": "2021-03-18T19:19:44+00:00",
        "label": 0
    },
    "1803.05457": {
        "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge",
        "abstract": "We present a new question set, text corpus, and baselines assembled to\nencourage AI research in advanced question answering. Together, these\nconstitute the AI2 Reasoning Challenge (ARC), which requires far more powerful\nknowledge and reasoning than previous challenges such as SQuAD or SNLI. The ARC\nquestion set is partitioned into a Challenge Set and an Easy Set, where the\nChallenge Set contains only questions answered incorrectly by both a\nretrieval-based algorithm and a word co-occurence algorithm. The dataset\ncontains only natural, grade-school science questions (authored for human\ntests), and is the largest public-domain set of this kind (7,787 questions). We\ntest several baselines on the Challenge Set, including leading neural models\nfrom the SQuAD and SNLI tasks, and find that none are able to significantly\noutperform a random baseline, reflecting the difficult nature of this task. We\nare also releasing the ARC Corpus, a corpus of 14M science sentences relevant\nto the task, and implementations of the three neural baseline models tested.\nCan your model perform better? We pose ARC as a challenge to the community.",
        "date": "2018-03-14T18:04:21+00:00",
        "label": 1
    },
    "2210.02414": {
        "title": "GLM-130B: An Open Bilingual Pre-trained Model",
        "abstract": "We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language\nmodel with 130 billion parameters. It is an attempt to open-source a 100B-scale\nmodel at least as good as GPT-3 (davinci) and unveil how models of such a scale\ncan be successfully pre-trained. Over the course of this effort, we face\nnumerous unexpected technical and engineering challenges, particularly on loss\nspikes and divergence. In this paper, we introduce the training process of\nGLM-130B including its design choices, training strategies for both efficiency\nand stability, and engineering efforts. The resultant GLM-130B model offers\nsignificant outperformance over GPT-3 175B (davinci) on a wide range of popular\nEnglish benchmarks while the performance advantage is not observed in OPT-175B\nand BLOOM-176B. It also consistently and significantly outperforms ERNIE TITAN\n3.0 260B -- the largest Chinese language model -- across related benchmarks.\nFinally, we leverage a unique scaling property of GLM-130B to reach INT4\nquantization without post training, with almost no performance loss, making it\nthe first among 100B-scale models and more importantly, allowing its effective\ninference on 4$\\times$RTX 3090 (24G) or 8$\\times$RTX 2080 Ti (11G) GPUs, the\nmost affordable GPUs required for using 100B-scale models. The GLM-130B model\nweights are publicly accessible and its code, training logs, related toolkit,\nand lessons learned are open-sourced at\n\\url{https://github.com/THUDM/GLM-130B/}.",
        "date": "2022-10-05T17:34:44+00:00",
        "label": 1
    },
    "1512.00407": {
        "title": "Science of Cyber Security as a System of Models and Problems",
        "abstract": "Terms like \"Science of Cyber\" or \"Cyber Science\" have been appearing in\nliterature with growing frequency, and influential organizations initiated\nresearch initiatives toward developing such a science even though it is not\nclearly defined. We propose to define the domain of the science of cyber\nsecurity by noting the most salient artifact within cyber security -- malicious\nsoftware -- and defining the domain as comprised of phenomena that involve\nmalicious software (as well as legitimate software and protocols used\nmaliciously) used to compel a computing device or a network of computing\ndevices to perform actions desired by the perpetrator of malicious software\n(the attacker) and generally contrary to the intent (the policy) of the\nlegitimate owner or operator (the defender) of the computing device(s). We\nfurther define the science of cyber security as the study of relations --\npreferably expressed as theoretically-grounded models -- between attributes,\nstructures and dynamics of: violations of cyber security policy; the network of\ncomputing devices under attack; the defenders' tools and techniques; and the\nattackers' tools and techniques where malicious software plays the central\nrole. We offer a simple formalism of these key objects within cyber science and\nsystematically derive a classification of primary problem classes within cyber\nscience.",
        "date": "2015-11-29T23:54:03+00:00",
        "label": 0
    },
    "1802.03292": {
        "title": "Mathematical Logic in Computer Science",
        "abstract": "The article retraces major events and milestones in the mutual influences\nbetween mathematical logic and computer science since the 1950s.",
        "date": "2018-02-07T22:21:43+00:00",
        "label": 0
    },
    "1605.08096": {
        "title": "Proceedings First Workshop on Pre- and Post-Deployment Verification Techniques",
        "abstract": "The PrePost (Pre- and Post-Deployment Verification Techniques) workshop aimed\nat bringing together researchers working in the field of computer-aided\nvalidation and verification to discuss the connections and interplay between\npre- and post-deployment verification techniques. Examples of the topics\ncovered by the workshop are the relationships between classic model checking\nand testing on the one hand and runtime verification and statistical model\nchecking on the other, and between type systems that may be checked either\nstatically or dynamically through techniques such as runtime monitoring.",
        "date": "2016-05-25T22:42:38+00:00",
        "label": 0
    },
    "1606.01148": {
        "title": "Tripartite Unions",
        "abstract": "This note provides conditions under which the union of three well-founded\nbinary relations is also well-founded.",
        "date": "2016-06-03T15:41:55+00:00",
        "label": 0
    },
    "0911.1672": {
        "title": "Biological Computing Fundamentals and Futures",
        "abstract": "The fields of computing and biology have begun to cross paths in new ways. In\nthis paper a review of the current research in biological computing is\npresented. Fundamental concepts are introduced and these foundational elements\nare explored to discuss the possibilities of a new computing paradigm. We\nassume the reader to possess a basic knowledge of Biology and Computer Science",
        "date": "2009-11-09T13:16:01+00:00",
        "label": 0
    },
    "1809.09600": {
        "title": "HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering",
        "abstract": "Existing question answering (QA) datasets fail to train QA systems to perform\ncomplex reasoning and provide explanations for answers. We introduce HotpotQA,\na new dataset with 113k Wikipedia-based question-answer pairs with four key\nfeatures: (1) the questions require finding and reasoning over multiple\nsupporting documents to answer; (2) the questions are diverse and not\nconstrained to any pre-existing knowledge bases or knowledge schemas; (3) we\nprovide sentence-level supporting facts required for reasoning, allowing QA\nsystems to reason with strong supervision and explain the predictions; (4) we\noffer a new type of factoid comparison questions to test QA systems' ability to\nextract relevant facts and perform necessary comparison. We show that HotpotQA\nis challenging for the latest QA systems, and the supporting facts enable\nmodels to improve performance and make explainable predictions.",
        "date": "2018-09-25T17:28:20+00:00",
        "label": 1
    },
    "2306.11644": {
        "title": "Textbooks Are All You Need",
        "abstract": "We introduce phi-1, a new large language model for code, with significantly\nsmaller size than competing models: phi-1 is a Transformer-based model with\n1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook\nquality\" data from the web (6B tokens) and synthetically generated textbooks\nand exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains\npass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP. It also displays\nsurprising emergent properties compared to phi-1-base, our model before our\nfinetuning stage on a dataset of coding exercises, and phi-1-small, a smaller\nmodel with 350M parameters trained with the same pipeline as phi-1 that still\nachieves 45% on HumanEval.",
        "date": "2023-06-20T16:14:25+00:00",
        "label": 1
    },
    "2003.10555": {
        "title": "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators",
        "abstract": "Masked language modeling (MLM) pre-training methods such as BERT corrupt the\ninput by replacing some tokens with [MASK] and then train a model to\nreconstruct the original tokens. While they produce good results when\ntransferred to downstream NLP tasks, they generally require large amounts of\ncompute to be effective. As an alternative, we propose a more sample-efficient\npre-training task called replaced token detection. Instead of masking the\ninput, our approach corrupts it by replacing some tokens with plausible\nalternatives sampled from a small generator network. Then, instead of training\na model that predicts the original identities of the corrupted tokens, we train\na discriminative model that predicts whether each token in the corrupted input\nwas replaced by a generator sample or not. Thorough experiments demonstrate\nthis new pre-training task is more efficient than MLM because the task is\ndefined over all input tokens rather than just the small subset that was masked\nout. As a result, the contextual representations learned by our approach\nsubstantially outperform the ones learned by BERT given the same model size,\ndata, and compute. The gains are particularly strong for small models; for\nexample, we train a model on one GPU for 4 days that outperforms GPT (trained\nusing 30x more compute) on the GLUE natural language understanding benchmark.\nOur approach also works well at scale, where it performs comparably to RoBERTa\nand XLNet while using less than 1/4 of their compute and outperforms them when\nusing the same amount of compute.",
        "date": "2020-03-23T21:17:42+00:00",
        "label": 1
    },
    "2002.04020": {
        "title": "Cloudifying the Curriculum with AWS",
        "abstract": "The Cloud has become a principal paradigm of computing in the last ten years,\nand Computer Science curricula must be updated to reflect that reality. This\npaper examines simple ways to accomplish curriculum cloudification using Amazon\nWeb Services (AWS), for Computer Science and other disciplines such as\nBusiness, Communication and Mathematics.",
        "date": "2020-02-10T18:47:35+00:00",
        "label": 0
    },
    "2109.01652": {
        "title": "Finetuned Language Models Are Zero-Shot Learners",
        "abstract": "This paper explores a simple method for improving the zero-shot learning\nabilities of language models. We show that instruction tuning -- finetuning\nlanguage models on a collection of tasks described via instructions --\nsubstantially improves zero-shot performance on unseen tasks.\n  We take a 137B parameter pretrained language model and instruction-tune it on\nover 60 NLP tasks verbalized via natural language instruction templates. We\nevaluate this instruction-tuned model, which we call FLAN, on unseen task\ntypes. FLAN substantially improves the performance of its unmodified\ncounterpart and surpasses zero-shot 175B GPT-3 on 20 of 25 tasks that we\nevaluate. FLAN even outperforms few-shot GPT-3 by a large margin on ANLI, RTE,\nBoolQ, AI2-ARC, OpenbookQA, and StoryCloze. Ablation studies reveal that number\nof finetuning datasets, model scale, and natural language instructions are key\nto the success of instruction tuning.",
        "date": "2021-09-03T17:55:52+00:00",
        "label": 1
    },
    "0912.4188": {
        "title": "The skewness of computer science",
        "abstract": "Computer science is a relatively young discipline combining science,\nengineering, and mathematics. The main flavors of computer science research\ninvolve the theoretical development of conceptual models for the different\naspects of computing and the more applicative building of software artifacts\nand assessment of their properties. In the computer science publication\nculture, conferences are an important vehicle to quickly move ideas, and\njournals often publish deeper versions of papers already presented at\nconferences. These peculiarities of the discipline make computer science an\noriginal research field within the sciences, and, therefore, the assessment of\nclassical bibliometric laws is particularly important for this field. In this\npaper, we study the skewness of the distribution of citations to papers\npublished in computer science publication venues (journals and conferences). We\nfind that the skewness in the distribution of mean citedness of different\nvenues combines with the asymmetry in citedness of articles in each venue,\nresulting in a highly asymmetric citation distribution with a power law tail.\nFurthermore, the skewness of conference publications is more pronounced than\nthe asymmetry of journal papers. Finally, the impact of journal papers, as\nmeasured with bibliometric indicators, largely dominates that of proceeding\npapers.",
        "date": "2009-12-21T15:24:08+00:00",
        "label": 0
    },
    "1401.4973": {
        "title": "What are the fundamental structures of concurrency? We still don't know!",
        "abstract": "Process algebra has been successful in many ways; but we don't yet see the\nlineaments of a fundamental theory. Some fleeting glimpses are sought from\nPetri Nets, physics and geometry.",
        "date": "2014-01-20T16:35:23+00:00",
        "label": 0
    },
    "1707.04352": {
        "title": "Advances in Artificial Intelligence Require Progress Across all of Computer Science",
        "abstract": "Advances in Artificial Intelligence require progress across all of computer\nscience.",
        "date": "2017-07-13T23:11:18+00:00",
        "label": 0
    },
    "2007.08476": {
        "title": "Accessible Computer Science for K-12 Students with Hearing Impairments",
        "abstract": "An inclusive science, technology, engineering and mathematics (STEM)\nworkforce is needed to maintain America's leadership in the scientific\nenterprise. Increasing the participation of underrepresented groups in STEM,\nincluding persons with disabilities, requires national attention to fully\nengage the nation's citizens in transforming its STEM enterprise. To address\nthis need, a number of initiatives, such as AccessCSforALL, Bootstrap, and\nCSforAll, are making efforts to make Computer Science inclusive to the 7.4\nmillion K-12 students with disabilities in the U.S. Of special interest to our\nproject are those K-12 students with hearing impairments. American Sign\nLanguage (ASL) is the primary means of communication for an estimated 500,000\npeople in the United States, yet there are limited online resources providing\nComputer Science instruction in ASL. This paper introduces a new project\ndesigned to support Deaf and Hard of Hearing (DHH) K-12 students and sign\ninterpreters in acquiring knowledge of complex Computer Science concepts. We\ndiscuss the motivation for the project and an early design of the accessible\nblock-based Computer Science curriculum to engage DHH students in hands-on\ncomputing education.",
        "date": "2020-07-16T17:21:52+00:00",
        "label": 0
    },
    "2306.04751": {
        "title": "How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources",
        "abstract": "In this work we explore recent advances in instruction-tuning language models\non a range of open instruction-following datasets. Despite recent claims that\nopen models can be on par with state-of-the-art proprietary models, these\nclaims are often accompanied by limited evaluation, making it difficult to\ncompare models across the board and determine the utility of various resources.\nWe provide a large set of instruction-tuned models from 6.7B to 65B parameters\nin size, trained on 12 instruction datasets ranging from manually curated\n(e.g., OpenAssistant) to synthetic and distilled (e.g., Alpaca) and\nsystematically evaluate them on their factual knowledge, reasoning,\nmultilinguality, coding, and open-ended instruction following abilities through\na collection of automatic, model-based, and human-based metrics. We further\nintroduce T\\\"ulu, our best performing instruction-tuned model suite finetuned\non a combination of high-quality open resources. Our experiments show that\ndifferent instruction-tuning datasets can uncover or enhance specific skills,\nwhile no single dataset (or combination) provides the best performance across\nall evaluations. Interestingly, we find that model and human preference-based\nevaluations fail to reflect differences in model capabilities exposed by\nbenchmark-based evaluations, suggesting the need for the type of systemic\nevaluation performed in this work. Our evaluations show that the best model in\nany given evaluation reaches on average 87% of ChatGPT performance, and 73% of\nGPT-4 performance, suggesting that further investment in building better base\nmodels and instruction-tuning data is required to close the gap. We release our\ninstruction-tuned models, including a fully finetuned 65B T\\\"ulu, along with\nour code, data, and evaluation framework at\nhttps://github.com/allenai/open-instruct to facilitate future research.",
        "date": "2023-06-07T19:59:23+00:00",
        "label": 1
    },
    "1111.7159": {
        "title": "Sequentiality vs. Concurrency in Games and Logic",
        "abstract": "Connections between the sequentiality/concurrency distinction and the\nsemantics of proofs are investigated, with particular reference to games and\nLinear Logic.",
        "date": "2011-11-30T13:44:46+00:00",
        "label": 0
    },
    "2201.05852": {
        "title": "Data Science in Perspective",
        "abstract": "Data and Science has stood out in the generation of results, whether in the\nprojects of the scientific domain or business domain. CERN Project, Scientific\nInstitutes, companies like Walmart, Google, Apple, among others, need data to\npresent their results and make predictions in the competitive data world. Data\nand Science are words that together culminated in a globally recognized term\ncalled Data Science. Data Science is in its initial phase, possibly being part\nof formal sciences and also being presented as part of applied sciences,\ncapable of generating value and supporting decision making. Data Science\nconsiders science and, consequently, the scientific method to promote decision\nmaking through data intelligence. In many cases, the application of the method\n(or part of it) is considered in Data Science projects in scientific domain\n(social sciences, bioinformatics, geospatial projects) or business domain\n(finance, logistic, retail), among others. In this sense, this article\naddresses the perspectives of Data Science as a multidisciplinary area,\nconsidering science and the scientific method, and its formal structure which\nintegrate Statistics, Computer Science, and Business Science, also taking into\naccount Artificial Intelligence, emphasizing Machine Learning, among others.\nThe article also deals with the perspective of applied Data Science, since Data\nScience is used for generating value through scientific and business projects.\nData Science persona is also discussed in the article, concerning the education\nof Data Science professionals and its corresponding profiles, since its\nprojection changes the field of data in the world.",
        "date": "2022-01-15T13:51:12+00:00",
        "label": 0
    },
    "2201.11990": {
        "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model",
        "abstract": "Pretrained general-purpose language models can achieve state-of-the-art\naccuracies in various natural language processing domains by adapting to\ndownstream tasks via zero-shot, few-shot and fine-tuning techniques. Because of\ntheir success, the size of these models has increased rapidly, requiring\nhigh-performance hardware, software, and algorithmic techniques to enable\ntraining such large models. As the result of a joint effort between Microsoft\nand NVIDIA, we present details on the training of the largest monolithic\ntransformer based language model, Megatron-Turing NLG 530B (MT-NLG), with 530\nbillion parameters. In this paper, we first focus on the infrastructure as well\nas the 3D parallelism methodology used to train this model using DeepSpeed and\nMegatron. Next, we detail the training process, the design of our training\ncorpus, and our data curation techniques, which we believe is a key ingredient\nto the success of the model. Finally, we discuss various evaluation results, as\nwell as other interesting observations and new properties exhibited by MT-NLG.\nWe demonstrate that MT-NLG achieves superior zero-, one-, and few-shot learning\naccuracies on several NLP benchmarks and establishes new state-of-the-art\nresults. We believe that our contributions will help further the development of\nlarge-scale training infrastructures, large-scale language models, and natural\nlanguage generations.",
        "date": "2022-01-28T08:59:57+00:00",
        "label": 1
    },
    "1907.11692": {
        "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
        "abstract": "Language model pretraining has led to significant performance gains but\ncareful comparison between different approaches is challenging. Training is\ncomputationally expensive, often done on private datasets of different sizes,\nand, as we will show, hyperparameter choices have significant impact on the\nfinal results. We present a replication study of BERT pretraining (Devlin et\nal., 2019) that carefully measures the impact of many key hyperparameters and\ntraining data size. We find that BERT was significantly undertrained, and can\nmatch or exceed the performance of every model published after it. Our best\nmodel achieves state-of-the-art results on GLUE, RACE and SQuAD. These results\nhighlight the importance of previously overlooked design choices, and raise\nquestions about the source of recently reported improvements. We release our\nmodels and code.",
        "date": "2019-07-26T17:48:29+00:00",
        "label": 1
    },
    "2307.03170": {
        "title": "Focused Transformer: Contrastive Training for Context Scaling",
        "abstract": "Large language models have an exceptional capability to incorporate new\ninformation in a contextual manner. However, the full potential of such an\napproach is often restrained due to a limitation in the effective context\nlength. One solution to this issue is to endow an attention layer with access\nto an external memory, which comprises of (key, value) pairs. Yet, as the\nnumber of documents increases, the proportion of relevant keys to irrelevant\nones decreases, leading the model to focus more on the irrelevant keys. We\nidentify a significant challenge, dubbed the distraction issue, where keys\nlinked to different semantic values might overlap, making them hard to\ndistinguish. To tackle this problem, we introduce the Focused Transformer\n(FoT), a technique that employs a training process inspired by contrastive\nlearning. This novel approach enhances the structure of the (key, value) space,\nenabling an extension of the context length. Our method allows for fine-tuning\npre-existing, large-scale models to lengthen their effective context. This is\ndemonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The\nresulting models, which we name LongLLaMA, exhibit advancements in tasks\nrequiring a long context. We further illustrate that our LongLLaMA models\nadeptly manage a $256 k$ context length for passkey retrieval.",
        "date": "2023-07-06T17:52:10+00:00",
        "label": 1
    },
    "1602.06023": {
        "title": "Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond",
        "abstract": "In this work, we model abstractive text summarization using Attentional\nEncoder-Decoder Recurrent Neural Networks, and show that they achieve\nstate-of-the-art performance on two different corpora. We propose several novel\nmodels that address critical problems in summarization that are not adequately\nmodeled by the basic architecture, such as modeling key-words, capturing the\nhierarchy of sentence-to-word structure, and emitting words that are rare or\nunseen at training time. Our work shows that many of our proposed models\ncontribute to further improvement in performance. We also propose a new dataset\nconsisting of multi-sentence summaries, and establish performance benchmarks\nfor further research.",
        "date": "2016-02-19T02:04:18+00:00",
        "label": 1
    },
    "1407.7360": {
        "title": "A Taxonomy and Survey on eScience as a Service in the Cloud",
        "abstract": "Cloud computing has recently evolved as a popular computing infrastructure\nfor many applications. Scientific computing, which was mainly hosted in private\nclusters and grids, has started to migrate development and deployment to the\npublic cloud environment. eScience as a service becomes an emerging and\npromising direction for science computing. We review recent efforts in\ndeveloping and deploying scientific computing applications in the cloud. In\nparticular, we introduce a taxonomy specifically designed for scientific\ncomputing in the cloud, and further review the taxonomy with four major kinds\nof science applications, including life sciences, physics sciences, social and\nhumanities sciences, and climate and earth sciences. Our major finding is that,\ndespite existing efforts in developing cloud-based eScience, eScience still has\na long way to go to fully unlock the power of cloud computing paradigm.\nTherefore, we present the challenges and opportunities in the future\ndevelopment of cloud-based eScience services, and call for collaborations and\ninnovations from both the scientific and computer system communities to address\nthose challenges.",
        "date": "2014-07-28T09:14:35+00:00",
        "label": 0
    },
    "1810.06683": {
        "title": "FlowQA: Grasping Flow in History for Conversational Machine Comprehension",
        "abstract": "Conversational machine comprehension requires the understanding of the\nconversation history, such as previous question/answer pairs, the document\ncontext, and the current question. To enable traditional, single-turn models to\nencode the history comprehensively, we introduce Flow, a mechanism that can\nincorporate intermediate representations generated during the process of\nanswering previous questions, through an alternating parallel processing\nstructure. Compared to approaches that concatenate previous questions/answers\nas input, Flow integrates the latent semantics of the conversation history more\ndeeply. Our model, FlowQA, shows superior performance on two recently proposed\nconversational challenges (+7.2% F1 on CoQA and +4.0% on QuAC). The\neffectiveness of Flow also shows in other tasks. By reducing sequential\ninstruction understanding to conversational machine comprehension, FlowQA\noutperforms the best models on all three domains in SCONE, with +1.8% to +4.4%\nimprovement in accuracy.",
        "date": "2018-10-06T20:46:49+00:00",
        "label": 1
    },
    "2107.03374": {
        "title": "Evaluating Large Language Models Trained on Code",
        "abstract": "We introduce Codex, a GPT language model fine-tuned on publicly available\ncode from GitHub, and study its Python code-writing capabilities. A distinct\nproduction version of Codex powers GitHub Copilot. On HumanEval, a new\nevaluation set we release to measure functional correctness for synthesizing\nprograms from docstrings, our model solves 28.8% of the problems, while GPT-3\nsolves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling\nfrom the model is a surprisingly effective strategy for producing working\nsolutions to difficult prompts. Using this method, we solve 70.2% of our\nproblems with 100 samples per problem. Careful investigation of our model\nreveals its limitations, including difficulty with docstrings describing long\nchains of operations and with binding operations to variables. Finally, we\ndiscuss the potential broader impacts of deploying powerful code generation\ntechnologies, covering safety, security, and economics.",
        "date": "2021-07-07T17:41:24+00:00",
        "label": 1
    },
    "0511274": {
        "title": "Quantum Computation: A Computer Science Perspective",
        "abstract": "The theory of quantum computation is presented in a self contained way from a\ncomputer science perspective. The basics of classical computation and quantum\nmechanics is reviewed. The circuit model of quantum computation is presented in\ndetail. Throughout there is an emphasis on the physical as well as the abstract\naspects of computation and the interplay between them.\n  This report is presented as a Master's thesis at the department of Computer\nScience and Engineering at G{\\\"o}teborg University, G{\\\"o}teborg, Sweden.\n  The text is part of a larger work that is planned to include chapters on\nquantum algorithms, the quantum Turing machine model and abstract approaches to\nquantum computation.",
        "date": "2005-11-30T20:36:54+00:00",
        "label": 0
    },
    "1012.1620": {
        "title": "Linked Environment Data for the Life Sciences",
        "abstract": "Environment Agencies from Europe and the US are setting up a network of\nLinked Environment Data and are looking to crosslink it with Linked Data\ncontributions from the life sciences.",
        "date": "2010-12-07T21:49:42+00:00",
        "label": 0
    },
    "2211.09085": {
        "title": "Galactica: A Large Language Model for Science",
        "abstract": "Information overload is a major obstacle to scientific progress. The\nexplosive growth in scientific literature and data has made it ever harder to\ndiscover useful insights in a large mass of information. Today scientific\nknowledge is accessed through search engines, but they are unable to organize\nscientific knowledge alone. In this paper we introduce Galactica: a large\nlanguage model that can store, combine and reason about scientific knowledge.\nWe train on a large scientific corpus of papers, reference material, knowledge\nbases and many other sources. We outperform existing models on a range of\nscientific tasks. On technical knowledge probes such as LaTeX equations,\nGalactica outperforms the latest GPT-3 by 68.2% versus 49.0%. Galactica also\nperforms well on reasoning, outperforming Chinchilla on mathematical MMLU by\n41.3% to 35.7%, and PaLM 540B on MATH with a score of 20.4% versus 8.8%. It\nalso sets a new state-of-the-art on downstream tasks such as PubMedQA and\nMedMCQA dev of 77.6% and 52.9%. And despite not being trained on a general\ncorpus, Galactica outperforms BLOOM and OPT-175B on BIG-bench. We believe these\nresults demonstrate the potential for language models as a new interface for\nscience. We open source the model for the benefit of the scientific community.",
        "date": "2022-11-16T18:06:33+00:00",
        "label": 1
    },
    "2205.01553": {
        "title": "Why The Trans Programmer?",
        "abstract": "Through online anecdotal evidence and online communities, there is an\nin-group idea of trans people (specifically trans-feminine individuals)\ndisproportionately entering computer science education & fields. Existing data\nsuggests this is a plausible trend, yet no research has been done into exactly\nwhy. As computer science education (traditional schooling or self-taught\nmethods) is integral to working in computer science fields, a simple research\nsurvey was conducted to gather data on 138 trans people's experiences with\ncomputer science & computer science education. This article's purpose is to\nshed insight on the motivations for trans individuals choosing computer science\npaths, while acting as a basis and call to action for further research.",
        "date": "2022-05-03T15:06:23+00:00",
        "label": 0
    },
    "2205.01068": {
        "title": "OPT: Open Pre-trained Transformer Language Models",
        "abstract": "Large language models, which are often trained for hundreds of thousands of\ncompute days, have shown remarkable capabilities for zero- and few-shot\nlearning. Given their computational cost, these models are difficult to\nreplicate without significant capital. For the few that are available through\nAPIs, no access is granted to the full model weights, making them difficult to\nstudy. We present Open Pre-trained Transformers (OPT), a suite of decoder-only\npre-trained transformers ranging from 125M to 175B parameters, which we aim to\nfully and responsibly share with interested researchers. We show that OPT-175B\nis comparable to GPT-3, while requiring only 1/7th the carbon footprint to\ndevelop. We are also releasing our logbook detailing the infrastructure\nchallenges we faced, along with code for experimenting with all of the released\nmodels.",
        "date": "2022-05-02T17:49:50+00:00",
        "label": 1
    },
    "2402.09171": {
        "title": "Automated Unit Test Improvement using Large Language Models at Meta",
        "abstract": "This paper describes Meta's TestGen-LLM tool, which uses LLMs to\nautomatically improve existing human-written tests. TestGen-LLM verifies that\nits generated test classes successfully clear a set of filters that assure\nmeasurable improvement over the original test suite, thereby eliminating\nproblems due to LLM hallucination. We describe the deployment of TestGen-LLM at\nMeta test-a-thons for the Instagram and Facebook platforms. In an evaluation on\nReels and Stories products for Instagram, 75% of TestGen-LLM's test cases built\ncorrectly, 57% passed reliably, and 25% increased coverage. During Meta's\nInstagram and Facebook test-a-thons, it improved 11.5% of all classes to which\nit was applied, with 73% of its recommendations being accepted for production\ndeployment by Meta software engineers. We believe this is the first report on\nindustrial scale deployment of LLM-generated code backed by such assurances of\ncode improvement.",
        "date": "2024-02-14T13:43:14+00:00",
        "label": 1
    },
    "2002.05658": {
        "title": "Ten Research Challenge Areas in Data Science",
        "abstract": "Although data science builds on knowledge from computer science, mathematics,\nstatistics, and other disciplines, data science is a unique field with many\nmysteries to unlock: challenging scientific questions and pressing questions of\nsocietal importance. This article starts with meta-questions about data science\nas a discipline and then elaborates on ten ideas for the basis of a research\nagenda for data science.",
        "date": "2020-01-27T21:39:57+00:00",
        "label": 0
    },
    "2006.16964": {
        "title": "Data Science: Nature and Pitfalls",
        "abstract": "Data science is creating very exciting trends as well as significant\ncontroversy. A critical matter for the healthy development of data science in\nits early stages is to deeply understand the nature of data and data science,\nand to discuss the various pitfalls. These important issues motivate the\ndiscussions in this article.",
        "date": "2020-06-28T02:06:54+00:00",
        "label": 0
    },
    "1406.2222": {
        "title": "The Chemistry Between High School Students and Computer Science",
        "abstract": "Computer science enrollments have started to rise again, but the percentage\nof women undergraduates in computer science is still low. Some studies indicate\nthis might be due to a lack of awareness of computer science at the high school\nlevel. We present our experiences running a 5-year, high school outreach\nprogram that introduces information about computer science within the context\nof required chemistry courses. We developed interactive worksheets using\nMolecular Workbench that help the students learn chemistry and computer science\nconcepts related to relevant events such as the gulf oil spill. Our evaluation\nof the effectiveness of this approach indicates that the students do become\nmore aware of computer science as a discipline, but system support issues in\nthe classroom can make the approach difficult for teachers and discouraging for\nthe students.",
        "date": "2014-06-09T15:44:41+00:00",
        "label": 0
    },
    "2110.14168": {
        "title": "Training Verifiers to Solve Math Word Problems",
        "abstract": "State-of-the-art language models can match human performance on many tasks,\nbut they still struggle to robustly perform multi-step mathematical reasoning.\nTo diagnose the failures of current models and support research, we introduce\nGSM8K, a dataset of 8.5K high quality linguistically diverse grade school math\nword problems. We find that even the largest transformer models fail to achieve\nhigh test performance, despite the conceptual simplicity of this problem\ndistribution. To increase performance, we propose training verifiers to judge\nthe correctness of model completions. At test time, we generate many candidate\nsolutions and select the one ranked highest by the verifier. We demonstrate\nthat verification significantly improves performance on GSM8K, and we provide\nstrong empirical evidence that verification scales more effectively with\nincreased data than a finetuning baseline.",
        "date": "2021-10-27T04:49:45+00:00",
        "label": 1
    },
    "1807.09490": {
        "title": "Investigating the Intersection of Science Fiction, Human-Computer Interaction and Computer Science Research",
        "abstract": "This paper outlines ongoing dissertation research located in the intersection\nof science fiction, human-computer interaction and computer science. Through an\ninterdisciplinary perspective, drawing from fields such as human-computer\ninteraction, film theory and studies of science and technology, qualitative and\nquantitative content analysis techniques are used to contextually analyze\nexpressions of science fiction in peer-reviewed computer science research\nrepositories, such as the ACM or IEEE Xplore Digital Libraries. This paper\nconcisely summarizes and introduces the relationship of science fiction and\ncomputer science research and presents the research questions, aims and\nimplications in addition to prior work and study methodology. In the latter\npart of this work-in-progress report, preliminary results, current limitations,\nfuture work and a post-dissertation trajectory are outlined.",
        "date": "2018-07-25T09:02:02+00:00",
        "label": 0
    },
    "2307.10169": {
        "title": "Challenges and Applications of Large Language Models",
        "abstract": "Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.",
        "date": "2023-07-19T17:55:13+00:00",
        "label": 1
    },
    "2202.01291": {
        "title": "Computer sciences and synthesis: retrospective and perspective",
        "abstract": "The problem of synthesis in computer sciences, including cybernetics,\nartificial intelligence and system analysis, is analyzed. Main methods of\nrealization this problem are discussed. Ways of search universal method of\ncreation universal synthetic science are represented. As example of such\nuniversal method polymetric analysis is given. Perspective of further\ndevelopment of this research, including application polymetric method for the\nresolution main problems of computer sciences, is analyzed too.",
        "date": "2022-01-26T04:42:45+00:00",
        "label": 0
    },
    "2305.02309": {
        "title": "CodeGen2: Lessons for Training LLMs on Programming and Natural Languages",
        "abstract": "Large language models (LLMs) have demonstrated remarkable abilities in\nrepresentation learning for program synthesis and understanding tasks. The\nquality of the learned representations appears to be dictated by the neural\nscaling laws as a function of the number of model parameters and observations,\nwhile imposing upper bounds on the model performance by the amount of available\ndata and compute, which is costly.\n  In this study, we attempt to render the training of LLMs for program\nsynthesis more efficient by unifying four key components: (1) model\narchitectures, (2) learning methods, (3) infill sampling, and, (4) data\ndistributions. Specifically, for the model architecture, we attempt to unify\nencoder and decoder-based models into a single prefix-LM. For learning methods,\n(i) causal language modeling, (ii) span corruption, (iii) infilling are unified\ninto a simple learning algorithm. For infill sampling, we explore the claim of\na \"free lunch\" hypothesis. For data distributions, the effect of a mixture\ndistribution and multi-epoch training of programming and natural languages on\nmodel performance is explored.\n  We conduct a comprehensive series of empirical experiments on 1B LLMs, for\nwhich failures and successes of this exploration are distilled into five\nlessons. We will provide a final recipe for training and release CodeGen2\nmodels in size 1B, 3.7B, 7B, and, 16B parameters, along with the training\nframework as open-source: https://github.com/salesforce/CodeGen.",
        "date": "2023-05-03T17:55:25+00:00",
        "label": 1
    },
    "2210.03629": {
        "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
        "abstract": "While large language models (LLMs) have demonstrated impressive capabilities\nacross tasks in language understanding and interactive decision making, their\nabilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\naction plan generation) have primarily been studied as separate topics. In this\npaper, we explore the use of LLMs to generate both reasoning traces and\ntask-specific actions in an interleaved manner, allowing for greater synergy\nbetween the two: reasoning traces help the model induce, track, and update\naction plans as well as handle exceptions, while actions allow it to interface\nwith external sources, such as knowledge bases or environments, to gather\nadditional information. We apply our approach, named ReAct, to a diverse set of\nlanguage and decision making tasks and demonstrate its effectiveness over\nstate-of-the-art baselines, as well as improved human interpretability and\ntrustworthiness over methods without reasoning or acting components.\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\nReAct overcomes issues of hallucination and error propagation prevalent in\nchain-of-thought reasoning by interacting with a simple Wikipedia API, and\ngenerates human-like task-solving trajectories that are more interpretable than\nbaselines without reasoning traces. On two interactive decision making\nbenchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\nreinforcement learning methods by an absolute success rate of 34% and 10%\nrespectively, while being prompted with only one or two in-context examples.\nProject site with code: https://react-lm.github.io",
        "date": "2022-10-06T01:00:32+00:00",
        "label": 1
    },
    "0706.0484": {
        "title": "Motivation, Design, and Ubiquity: A Discussion of Research Ethics and Computer Science",
        "abstract": "Modern society is permeated with computers, and the software that controls\nthem can have latent, long-term, and immediate effects that reach far beyond\nthe actual users of these systems. This places researchers in Computer Science\nand Software Engineering in a critical position of influence and\nresponsibility, more than any other field because computer systems are vital\nresearch tools for other disciplines. This essay presents several key ethical\nconcerns and responsibilities relating to research in computing. The goal is to\npromote awareness and discussion of ethical issues among computer science\nresearchers. A hypothetical case study is provided, along with questions for\nreflection and discussion.",
        "date": "2007-06-04T17:17:44+00:00",
        "label": 0
    },
    "2306.01116": {
        "title": "The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only",
        "abstract": "Large language models are commonly trained on a mixture of filtered web data\nand curated high-quality corpora, such as social media conversations, books, or\ntechnical papers. This curation process is believed to be necessary to produce\nperformant models with broad zero-shot generalization abilities. However, as\nlarger models requiring pretraining on trillions of tokens are considered, it\nis unclear how scalable is curation and whether we will run out of unique\nhigh-quality data soon. At variance with previous beliefs, we show that\nproperly filtered and deduplicated web data alone can lead to powerful models;\neven significantly outperforming models from the state-of-the-art trained on\nThe Pile. Despite extensive filtering, the high-quality data we extract from\nthe web is still plentiful, and we are able to obtain five trillion tokens from\nCommonCrawl. We publicly release an extract of 600 billion tokens from our\nRefinedWeb dataset, and 1.3/7.5B parameters language models trained on it.",
        "date": "2023-06-01T20:03:56+00:00",
        "label": 1
    },
    "1804.08293": {
        "title": "Materials science and engineering: New vision in the era of artificial intelligence",
        "abstract": "Scientific discovery evolves from the experimental, through the theoretical\nand computational, to the current data-intensive paradigm. Materials science is\nno exception, especially for computational materials science. In recent years,\ngreat achievements have been made in the field of materials science and\nengineering (MSE). Here, we review the previous paradigms of materials science\nand some classical MSE models. Then, our data-intensive MSE (DIMSE) model is\nproposed to reshape future materials innovations. This work will help to\naddress the global challenge for materials discovery in the era of artificial\nintelligence (AI), and essentially contribute to accelerating future materials\ncontinuum.",
        "date": "2018-04-23T09:01:57+00:00",
        "label": 0
    },
    "1705.02203": {
        "title": "Analysis of Computational Science Papers from ICCS 2001-2016 using Topic Modeling and Graph Theory",
        "abstract": "This paper presents results of topic modeling and network models of topics\nusing the International Conference on Computational Science corpus, which\ncontains domain-specific (computational science) papers over sixteen years (a\ntotal of 5695 papers). We discuss topical structures of International\nConference on Computational Science, how these topics evolve over time in\nresponse to the topicality of various problems, technologies and methods, and\nhow all these topics relate to one another. This analysis illustrates\nmultidisciplinary research and collaborations among scientific communities, by\nconstructing static and dynamic networks from the topic modeling results and\nthe keywords of authors. The results of this study give insights about the past\nand future trends of core discussion topics in computational science. We used\nthe Non-negative Matrix Factorization topic modeling algorithm to discover\ntopics and labeled and grouped results hierarchically.",
        "date": "2017-04-18T13:24:41+00:00",
        "label": 0
    },
    "1503.02531": {
        "title": "Distilling the Knowledge in a Neural Network",
        "abstract": "A very simple way to improve the performance of almost any machine learning\nalgorithm is to train many different models on the same data and then to\naverage their predictions. Unfortunately, making predictions using a whole\nensemble of models is cumbersome and may be too computationally expensive to\nallow deployment to a large number of users, especially if the individual\nmodels are large neural nets. Caruana and his collaborators have shown that it\nis possible to compress the knowledge in an ensemble into a single model which\nis much easier to deploy and we develop this approach further using a different\ncompression technique. We achieve some surprising results on MNIST and we show\nthat we can significantly improve the acoustic model of a heavily used\ncommercial system by distilling the knowledge in an ensemble of models into a\nsingle model. We also introduce a new type of ensemble composed of one or more\nfull models and many specialist models which learn to distinguish fine-grained\nclasses that the full models confuse. Unlike a mixture of experts, these\nspecialist models can be trained rapidly and in parallel.",
        "date": "2015-03-09T15:44:49+00:00",
        "label": 1
    },
    "1003.1930": {
        "title": "Simulating Grover's Quantum Search in a Classical Computer",
        "abstract": "The rapid progress of computer science has been accompanied by a\ncorresponding evolution of computation, from classical computation to quantum\ncomputation. As quantum computing is on its way to becoming an established\ndiscipline of computing science, much effort is being put into the development\nof new quantum algorithms. One of quantum algorithms is Grover algorithm, which\nis used for searching an element in an unstructured list of N elements with\nquadratic speed-up over classical algorithms. In this work, Quantum Computer\nLanguage (QCL) is used to make a Grover's quantum search simulation in a\nclassical computer",
        "date": "2010-03-09T17:02:21+00:00",
        "label": 0
    }
}