{
    "2012.12144": {
        "title": "Integrating computing in the statistics and data science curriculum: Creative structures, novel skills and habits, and ways to teach computational thinking",
        "abstract": "Nolan and Temple Lang (2010) argued for the fundamental role of computing in\nthe statistics curriculum. In the intervening decade the statistics education\ncommunity has acknowledged that computational skills are as important to\nstatistics and data science practice as mathematics. There remains a notable\ngap, however, between our intentions and our actions. In this special issue of\nthe *Journal of Statistics and Data Science Education* we have assembled a\ncollection of papers that (1) suggest creative structures to integrate\ncomputing, (2) describe novel data science skills and habits, and (3) propose\nways to teach computational thinking. We believe that it is critical for the\ncommunity to redouble our efforts to embrace sophisticated computing in the\nstatistics and data science curriculum. We hope that these papers provide\nuseful guidance for the community to move these efforts forward.",
        "date": "2020-12-22T16:28:18+00:00",
        "label": 0
    },
    "2309.09972": {
        "title": "Artificial Intelligence for Web 3.0: A Comprehensive Survey",
        "abstract": "Web 3.0 is the new generation of the Internet that is reconstructed with\ndistributed technology, which focuses on data ownership and value expression.\nAlso, it operates under the principle that data and digital assets should be\nowned and controlled by users rather than large corporations. In this survey,\nwe explore the current development state of Web 3.0 and the application of AI\nTechnology in Web 3.0. Through investigating the existing applications and\ncomponents of Web 3.0, we propose an architectural framework for Web 3.0 from\nthe perspective of ecological application scenarios. We outline and divide the\necology of Web 3.0 into four layers. The main functions of each layer are data\nmanagement, value circulation, ecological governance, and application\nscenarios. Our investigation delves into the major challenges and issues\npresent in each of these layers. In this context, AI has shown its strong\npotential to solve existing problems of Web 3.0. We illustrate the crucial role\nof AI in the foundation and growth of Web 3.0. We begin by providing an\noverview of AI, including machine learning algorithms and deep learning\ntechniques. Then, we thoroughly analyze the current state of AI technology\napplications in the four layers of Web 3.0 and offer some insights into its\npotential future development direction.",
        "date": "2023-08-17T12:36:01+00:00",
        "label": 1
    },
    "1612.04037": {
        "title": "Proceedings 11th Doctoral Workshop on Mathematical and Engineering Methods in Computer Science",
        "abstract": "MEMICS provides a forum for doctoral students interested in applications of\nmathematical and engineering methods in computer science. Besides a rich\ntechnical programme (including invited talks, regular papers, and\npresentations), MEMICS also offers friendly social activities and exciting\nopportunities for meeting like-minded people. MEMICS submissions traditionally\ncover all areas of computer science (such as parallel and distributed\ncomputing, computer networks, modern hardware and its design, non-traditional\ncomputing architectures, information systems and databases, multimedia and\ngraphics, verification and testing, computer security, as well as all related\nareas of theoretical computer science).",
        "date": "2016-12-13T05:47:19+00:00",
        "label": 0
    },
    "2106.08157": {
        "title": "CeFi vs. DeFi -- Comparing Centralized to Decentralized Finance",
        "abstract": "To non-experts, the traditional Centralized Finance (CeFi) ecosystem may seem\nobscure, because users are typically not aware of the underlying rules or\nagreements of financial assets and products. Decentralized Finance (DeFi),\nhowever, is making its debut as an ecosystem claiming to offer transparency and\ncontrol, which are partially attributable to the underlying integrity-protected\nblockchain, as well as currently higher financial asset yields than CeFi. Yet,\nthe boundaries between CeFi and DeFi may not be always so clear cut.\n  In this work, we systematically analyze the differences between CeFi and\nDeFi, covering legal, economic, security, privacy and market manipulation. We\nprovide a structured methodology to differentiate between a CeFi and a DeFi\nservice. Our findings show that certain DeFi assets (such as USDC or USDT\nstablecoins) do not necessarily classify as DeFi assets, and may endanger the\neconomic security of intertwined DeFi protocols. We conclude this work with the\nexploration of possible synergies between CeFi and DeFi.",
        "date": "2021-06-15T13:53:43+00:00",
        "label": 1
    },
    "1401.4507": {
        "title": "Using Quantum Computers to Learn Physics",
        "abstract": "Since its inception at the beginning of the twentieth century, quantum\nmechanics has challenged our conceptions of how the universe ought to work;\nhowever, the equations of quantum mechanics can be too computationally\ndifficult to solve using existing computers for even modestly large systems.\nHere I will show that quantum computers can sometimes be used to address such\nproblems and that quantum computer science can assign formal complexities to\nlearning facts about nature. Hence, computer science should not only be\nregarded as an applied science; it is also of central importance to the\nfoundations of science.",
        "date": "2014-01-18T01:46:52+00:00",
        "label": 0
    },
    "2311.01433": {
        "title": "A Comprehensive Study of Governance Issues in Decentralized Finance Applications",
        "abstract": "Decentralized Finance (DeFi) is a prominent application of smart contracts,\nrepresenting a novel financial paradigm in contrast to centralized finance.\nWhile DeFi applications are rapidly emerging on mainstream blockchain\nplatforms, their quality varies greatly, presenting numerous challenges,\nparticularly in terms of their governance mechanisms. In this paper, we present\na comprehensive study of governance issues in DeFi applications. Drawing upon\ninsights from industry reports and academic research articles, we develop a\ntaxonomy to categorize these governance issues. We collect and build a dataset\nof 4,446 audit reports from 17 Web3 security companies, categorizing their\ngovernance issues according to our constructed taxonomy. We conducted a\nthorough analysis of governance issues and identified vulnerabilities in\ngovernance design and implementation, e.g., voting sybil attack and proposal\nfront-running. Our findings highlight a significant observation: the disparity\nbetween smart contract code and DeFi whitepapers plays a central role in these\ngovernance issues. As an initial step to address the challenges of\ncode-whitepaper consistency checks for DeFi applications, we built a\nmachine-learning-based prototype, and validated its performance on eight widely\nused DeFi projects, achieving a 56.14% F1 score and a 80% recall. Our study\nculminates in providing several key practical implications for various DeFi\nstakeholders, including developers, users, researchers, and regulators, aiming\nto deepen the understanding of DeFi governance issues and contribute to the\nrobust growth of DeFi systems.",
        "date": "2023-11-02T17:46:59+00:00",
        "label": 1
    },
    "1606.01148": {
        "title": "Tripartite Unions",
        "abstract": "This note provides conditions under which the union of three well-founded\nbinary relations is also well-founded.",
        "date": "2016-06-03T15:41:55+00:00",
        "label": 0
    },
    "2303.02836": {
        "title": "Blockchain-Empowered Lifecycle Management for AI-Generated Content (AIGC) Products in Edge Networks",
        "abstract": "The rapid development of Artificial IntelligenceGenerated Content (AIGC) has\nbrought daunting challenges regarding service latency, security, and\ntrustworthiness. Recently, researchers presented the edge AIGC paradigm,\neffectively optimize the service latency by distributing AIGC services to edge\ndevices. However, AIGC products are still unprotected and vulnerable to\ntampering and plagiarization. Moreover, as a kind of online non-fungible\ndigital property, the free circulation of AIGC products is hindered by the lack\nof trustworthiness in open networks. In this article, for the first time, we\npresent a blockchain-empowered framework to manage the lifecycle of edge AIGC\nproducts. Specifically, leveraging fraud proof, we first propose a protocol to\nprotect the ownership and copyright of AIGC, called Proof-of-AIGC. Then, we\ndesign an incentive mechanism to guarantee the legitimate and timely executions\nof the funds-AIGC ownership exchanges among anonymous users. Furthermore, we\nbuild a multi-weight subjective logic-based reputation scheme, with which AIGC\nproducers can determine which edge service provider is trustworthy and reliable\nto handle their services. Through numerical results, the superiority of the\nproposed approach is demonstrated. Last but not least, we discuss important\nopen directions for further research.",
        "date": "2023-03-06T02:06:13+00:00",
        "label": 1
    },
    "2101.08778": {
        "title": "SoK: Decentralized Finance (DeFi)",
        "abstract": "Decentralized Finance (DeFi), a blockchain powered peer-to-peer financial\nsystem, is mushrooming. Two years ago the total value locked in DeFi systems\nwas approximately 700m USD, now, as of April 2022, it stands at around 150bn\nUSD. The frenetic evolution of the ecosystem has created challenges in\nunderstanding the basic principles of these systems and their security risks.\nIn this Systematization of Knowledge (SoK) we delineate the DeFi ecosystem\nalong the following axes: its primitives, its operational protocol types and\nits security. We provide a distinction between technical security, which has a\nhealthy literature, and economic security, which is largely unexplored,\nconnecting the latter with new models and thereby synthesizing insights from\ncomputer science, economics and finance. Finally, we outline the open research\nchallenges in the ecosystem across these security types.",
        "date": "2021-01-21T18:58:43+00:00",
        "label": 1
    },
    "9505013": {
        "title": "Wavelet basis for the Schr\u00f6dinger equation",
        "abstract": "The self-similar representation for the Schr\\\"{o}dinger equation is derived.",
        "date": "1995-05-16T16:19:16+00:00",
        "label": 0
    },
    "2308.04942": {
        "title": "Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation",
        "abstract": "Artificial Intelligence Generated Content (AIGC) Services have significant\npotential in digital content creation. The distinctive abilities of AIGC, such\nas content generation based on minimal input, hold huge potential, especially\nwhen integrating with semantic communication (SemCom). In this paper, a novel\ncomprehensive conceptual model for the integration of AIGC and SemCom is\ndeveloped. Particularly, a content generation level is introduced on top of the\nsemantic level that provides a clear outline of how AIGC and SemCom interact\nwith each other to produce meaningful and effective content. Moreover, a novel\nframework that employs AIGC technology is proposed as an encoder and decoder\nfor semantic information, considering the joint optimization of semantic\nextraction and evaluation metrics tailored to AIGC services. The framework can\nadapt to different types of content generated, the required quality, and the\nsemantic information utilized. By employing a Deep Q Network (DQN), a case\nstudy is presented that provides useful insights into the feasibility of the\noptimization problem and its convergence characteristics.",
        "date": "2023-08-09T13:17:21+00:00",
        "label": 1
    },
    "1310.7911": {
        "title": "Compact manifolds with computable boundaries",
        "abstract": "We investigate conditions under which a co-computably enumerable closed set\nin a computable metric space is computable and prove that in each locally\ncomputable computable metric space each co-computably enumerable compact\nmanifold with computable boundary is computable. In fact, we examine the notion\nof a semi-computable compact set and we prove a more general result: in any\ncomputable metric space each semi-computable compact manifold with computable\nboundary is computable. In particular, each semi-computable compact\n(boundaryless) manifold is computable.",
        "date": "2013-10-29T18:29:13+00:00",
        "label": 0
    },
    "2301.03220": {
        "title": "Enabling AI-Generated Content (AIGC) Services in Wireless Edge Networks",
        "abstract": "Artificial Intelligence-Generated Content (AIGC) refers to the use of AI to\nautomate the information creation process while fulfilling the personalized\nrequirements of users. However, due to the instability of AIGC models, e.g.,\nthe stochastic nature of diffusion models, the quality and accuracy of the\ngenerated content can vary significantly. In wireless edge networks, the\ntransmission of incorrectly generated content may unnecessarily consume network\nresources. Thus, a dynamic AIGC service provider (ASP) selection scheme is\nrequired to enable users to connect to the most suited ASP, improving the\nusers' satisfaction and quality of generated content. In this article, we first\nreview the AIGC techniques and their applications in wireless networks. We then\npresent the AIGC-as-a-service (AaaS) concept and discuss the challenges in\ndeploying AaaS at the edge networks. Yet, it is essential to have performance\nmetrics to evaluate the accuracy of AIGC services. Thus, we introduce several\nimage-based perceived quality evaluation metrics. Then, we propose a general\nand effective model to illustrate the relationship between computational\nresources and user-perceived quality evaluation metrics. To achieve efficient\nAaaS and maximize the quality of generated content in wireless edge networks,\nwe propose a deep reinforcement learning-enabled algorithm for optimal ASP\nselection. Simulation results show that the proposed algorithm can provide a\nhigher quality of generated content to users and achieve fewer crashed tasks by\ncomparing with four benchmarks, i.e., overloading-avoidance, random,\nround-robin policies, and the upper-bound schemes.",
        "date": "2023-01-09T09:30:23+00:00",
        "label": 1
    },
    "0511274": {
        "title": "Quantum Computation: A Computer Science Perspective",
        "abstract": "The theory of quantum computation is presented in a self contained way from a\ncomputer science perspective. The basics of classical computation and quantum\nmechanics is reviewed. The circuit model of quantum computation is presented in\ndetail. Throughout there is an emphasis on the physical as well as the abstract\naspects of computation and the interplay between them.\n  This report is presented as a Master's thesis at the department of Computer\nScience and Engineering at G{\\\"o}teborg University, G{\\\"o}teborg, Sweden.\n  The text is part of a larger work that is planned to include chapters on\nquantum algorithms, the quantum Turing machine model and abstract approaches to\nquantum computation.",
        "date": "2005-11-30T20:36:54+00:00",
        "label": 0
    },
    "1607.03760": {
        "title": "Distributed Games and Strategies",
        "abstract": "A summary of work on distributed games and strategies done within the first\nthree years of the ERC project ECSYM is presented.",
        "date": "2016-07-13T14:25:03+00:00",
        "label": 0
    },
    "2210.13526": {
        "title": "Computational Inference in Cognitive Science: Operational, Societal and Ethical Considerations",
        "abstract": "Emerging research frontiers and computational advances have gradually\ntransformed cognitive science into a multidisciplinary and data-driven field.\nAs a result, there is a proliferation of cognitive theories investigated and\ninterpreted from different academic lens and in different levels of\nabstraction. We formulate this applied aspect of this challenge as the\ncomputational cognitive inference, and describe the major routes of\ncomputational approaches. To balance the potential optimism alongside the speed\nand scale of the data-driven era of cognitive science, we propose to inspect\nthis trend in more empirical terms by identifying the operational challenges,\nsocietal impacts and ethical guidelines in conducting research and interpreting\nresults from the computational inference in cognitive science.",
        "date": "2022-10-24T18:27:27+00:00",
        "label": 0
    },
    "2301.04788": {
        "title": "Language Cognition and Language Computation -- Human and Machine Language Understanding",
        "abstract": "Language understanding is a key scientific issue in the fields of cognitive\nand computer science. However, the two disciplines differ substantially in the\nspecific research questions. Cognitive science focuses on analyzing the\nspecific mechanism of the brain and investigating the brain's response to\nlanguage; few studies have examined the brain's language system as a whole. By\ncontrast, computer scientists focus on the efficiency of practical applications\nwhen choosing research questions but may ignore the most essential laws of\nlanguage. Given these differences, can a combination of the disciplines offer\nnew insights for building intelligent language models and studying language\ncognitive mechanisms? In the following text, we first review the research\nquestions, history, and methods of language understanding in cognitive and\ncomputer science, focusing on the current progress and challenges. We then\ncompare and contrast the research of language understanding in cognitive and\ncomputer sciences. Finally, we review existing work that combines insights from\nlanguage cognition and language computation and offer prospects for future\ndevelopment trends.",
        "date": "2023-01-12T02:37:00+00:00",
        "label": 0
    },
    "1404.5458": {
        "title": "Complex Workflow Management and Integration of Distributed Computing Resources by Science Gateway Portal for Molecular Dynamics Simulations in Materials Science",
        "abstract": "The \"IMP Science Gateway Portal\" (http://scigate.imp.kiev.ua) for complex\nworkflow management and integration of distributed computing resources (like\nclusters, service grids, desktop grids, clouds) is presented. It is created on\nthe basis of WS-PGRADE and gUSE technologies, where WS-PGRADE is designed for\nscience workflow operation and gUSE - for smooth integration of available\nresources for parallel and distributed computing in various heterogeneous\ndistributed computing infrastructures (DCI). The typical scientific workflow\nwith possible scenarios of its preparation and usage is considered. Several\ntypical science applications (scientific workflows) are considered for\nmolecular dynamics (MD) simulations of complex behavior of various\nnanostructures (nanoindentation of graphene layers, defect system relaxation in\nmetal nanocrystals, thermal stability of boron nitride nanotubes, etc.). The\nadvantages and drawbacks of the solution are shortly analyzed in the context of\nits practical applications for MD simulations in materials science, physics and\nnanotechnologies with available heterogeneous DCIs.",
        "date": "2014-04-22T11:34:04+00:00",
        "label": 0
    },
    "1908.02591": {
        "title": "Anti-Money Laundering in Bitcoin: Experimenting with Graph Convolutional Networks for Financial Forensics",
        "abstract": "Anti-money laundering (AML) regulations play a critical role in safeguarding\nfinancial systems, but bear high costs for institutions and drive financial\nexclusion for those on the socioeconomic and international margins. The advent\nof cryptocurrency has introduced an intriguing paradox: pseudonymity allows\ncriminals to hide in plain sight, but open data gives more power to\ninvestigators and enables the crowdsourcing of forensic analysis. Meanwhile\nadvances in learning algorithms show great promise for the AML toolkit. In this\nworkshop tutorial, we motivate the opportunity to reconcile the cause of safety\nwith that of financial inclusion. We contribute the Elliptic Data Set, a time\nseries graph of over 200K Bitcoin transactions (nodes), 234K directed payment\nflows (edges), and 166 node features, including ones based on non-public data;\nto our knowledge, this is the largest labelled transaction data set publicly\navailable in any cryptocurrency. We share results from a binary classification\ntask predicting illicit transactions using variations of Logistic Regression\n(LR), Random Forest (RF), Multilayer Perceptrons (MLP), and Graph Convolutional\nNetworks (GCN), with GCN being of special interest as an emergent new method\nfor capturing relational information. The results show the superiority of\nRandom Forest (RF), but also invite algorithmic work to combine the respective\npowers of RF and graph methods. Lastly, we consider visualization for analysis\nand explainability, which is difficult given the size and dynamism of\nreal-world transaction graphs, and we offer a simple prototype capable of\nnavigating the graph and observing model performance on illicit activity over\ntime. With this tutorial and data set, we hope to a) invite feedback in support\nof our ongoing inquiry, and b) inspire others to work on this societally\nimportant challenge.",
        "date": "2019-07-31T22:10:01+00:00",
        "label": 1
    },
    "2209.02446": {
        "title": "Web3 Challenges and Opportunities for the Market",
        "abstract": "The inability of a computer to think has been a limiter in its usefulness and\na point of reassurance for humanity since the first computers were created. The\nsemantic web is the first step toward removing that barrier, enabling computers\nto operate based on conceptual understanding, and AI and ML are the second.\nBoth semantic knowledge and the ability to learn are fundamental to web3, as\nare blockchain, decentralization, transactional transparency, and ownership.\nWeb3 is the next generational step in the information age, where the web\nevolves into a more digestible medium for users and machines to browse\nknowledge. The slow introduction of Web3 across the global software ecosystem\nwill impact the people who enable the current iteration. This evolution of the\ninternet space will expand the way knowledge is shared, consumed, and owned,\nwhich will lessen the requirement for a global standard and allow data to\ninteract efficiently, no matter the construction of the knowledge. The heart of\nthis paper understands the: 1) Enablement of Web3 across the digital ecosystem.\n2) What a Web3 developer will look like. 3) How this alteration will evolve the\nmarket around software and knowledge in general.",
        "date": "2022-09-06T12:17:47+00:00",
        "label": 1
    },
    "2206.07164": {
        "title": "Edge Security: Challenges and Issues",
        "abstract": "Edge computing is a paradigm that shifts data processing services to the\nnetwork edge, where data are generated. While such an architecture provides\nfaster processing and response, among other benefits, it also raises critical\nsecurity issues and challenges that must be addressed. This paper discusses the\nsecurity threats and vulnerabilities emerging from the edge network\narchitecture spanning from the hardware layer to the system layer. We further\ndiscuss privacy and regulatory compliance challenges in such networks. Finally,\nwe argue the need for a holistic approach to analyze edge network security\nposture, which must consider knowledge from each layer.",
        "date": "2022-06-14T20:49:48+00:00",
        "label": 1
    },
    "1210.6636": {
        "title": "Informaticology: combining Computer Science, Data Science, and Fiction Science",
        "abstract": "Motivated by an intention to remedy current complications with Dutch\nterminology concerning informatics, the term informaticology is positioned to\ndenote an academic counterpart of informatics where informatics is conceived of\nas a container for a coherent family of practical disciplines ranging from\ncomputer engineering and software engineering to network technology, data\ncenter management, information technology, and information management in a\nbroad sense.\n  Informaticology escapes from the limitations of instrumental objectives and\nthe perspective of usage that both restrict the scope of informatics. That is\nachieved by including fiction science in informaticology and by ranking fiction\nscience on equal terms with computer science and data science, and framing (the\nstudy of) game design, evelopment, assessment and distribution, ranging from\nserious gaming to entertainment gaming, as a chapter of fiction science. A\nsuggestion for the scope of fiction science is specified in some detail.\n  In order to illustrate the coherence of informaticology thus conceived, a\npotential application of fiction to the ontology of instruction sequences and\nto software quality assessment is sketched, thereby highlighting a possible\nrole of fiction (science) within informaticology but outside gaming.",
        "date": "2012-10-24T19:24:59+00:00",
        "label": 0
    },
    "0703148": {
        "title": "Computer Science and Game Theory: A Brief Survey",
        "abstract": "There has been a remarkable increase in work at the interface of computer\nscience and game theory in the past decade. In this article I survey some of\nthe main themes of work in the area, with a focus on the work in computer\nscience. Given the length constraints, I make no attempt at being\ncomprehensive, especially since other surveys are also available, and a\ncomprehensive survey book will appear shortly.",
        "date": "2007-03-29T18:43:58+00:00",
        "label": 0
    },
    "1309.0717": {
        "title": "A Polynomial Translation of pi-calculus FCPs to Safe Petri Nets",
        "abstract": "We develop a polynomial translation from finite control pi-calculus processes\nto safe low-level Petri nets. To our knowledge, this is the first such\ntranslation. It is natural in that there is a close correspondence between the\ncontrol flows, enjoys a bisimulation result, and is suitable for practical\nmodel checking.",
        "date": "2013-09-03T15:08:39+00:00",
        "label": 0
    },
    "2001.07091": {
        "title": "Blockchain Consensus Algorithms: A Survey",
        "abstract": "In recent years, blockchain technology has received unparalleled attention\nfrom academia, industry, and governments all around the world. It is considered\na technological breakthrough anticipated to disrupt several application\ndomains. This has resulted in a plethora of blockchain systems for various\npurposes. However, many of these blockchain systems suffer from serious\nshortcomings related to their performance and security, which need to be\naddressed before any wide-scale adoption can be achieved. A crucial component\nof any blockchain system is its underlying consensus algorithm, which in many\nways, determines its performance and security. Therefore, to address the\nlimitations of different blockchain systems, several existing as well novel\nconsensus algorithms have been introduced. A systematic analysis of these\nalgorithms will help to understand how and why any particular blockchain\nperforms the way it functions. However, the existing studies of consensus\nalgorithms are not comprehensive. Those studies have incomplete discussions on\nthe properties of the algorithms and fail to analyse several major blockchain\nconsensus algorithms in terms of their scopes. This article fills this gap by\nanalysing a wide range of consensus algorithms using a comprehensive taxonomy\nof properties and by examining the implications of different issues still\nprevalent in consensus algorithms in detail. The result of the analysis is\npresented in tabular formats, which provides a visual illustration of these\nalgorithms in a meaningful way. We have also analysed more than hundred top\ncrypto-currencies belonging to different categories of consensus algorithms to\nunderstand their properties and to implicate different trends in these\ncrypto-currencies. Finally, we have presented a decision tree of algorithms to\nbe used as a tool to test the suitability of consensus algorithms under\ndifferent criteria.",
        "date": "2020-01-20T13:00:07+00:00",
        "label": 1
    },
    "1710.03090": {
        "title": "Theoretical Computer Science for the Working Category Theorist",
        "abstract": "Theoretical computer science discusses foundational issues about\ncomputations. It asks and answers questions such as \"What is a computation?\",\n\"What is computable?\", \"What is efficiently computable?\",\"What is\ninformation?\", \"What is random?\", \"What is an algorithm?\", etc. We will present\nmany of the major themes and theorems with the basic language of category\ntheory. Surprisingly, many interesting theorems and concepts of theoretical\ncomputer science are easy consequences of functoriality and composition when\nyou look at the right categories and functors connecting them.",
        "date": "2017-10-04T19:19:00+00:00",
        "label": 0
    },
    "1304.7858": {
        "title": "Abstract Stobjs and Their Application to ISA Modeling",
        "abstract": "We introduce a new ACL2 feature, the abstract stobj, and show how to apply it\nto modeling the instruction set architecture of a microprocessor. Benefits of\nabstract stobjs over traditional (\"concrete\") stobjs can include faster\nexecution, support for symbolic simulation, more efficient reasoning, and\nresilience of proof developments under modeling optimization.",
        "date": "2013-04-30T04:14:22+00:00",
        "label": 0
    },
    "2305.00427": {
        "title": "An overview of Web3.0 Technology: Infrastructure, Applications, and Popularity",
        "abstract": "Web3, the next generation of the Internet, represents a decentralized and\ndemocratized web. Although it has garnered significant public interest and\nfound numerous real-world applications, there is a limited understanding of\npeople's perceptions and experiences with Web3. In this study, we conducted an\nempirical study to investigate the categories of Web3 application and their\npopularity, as well as the potential challenges and opportunities within this\nemerging landscape. Our research was carried out in two phases. In the first\nphase, we analyzed 200 popular Web3 projects associated with 10 leading Web3\nventure capital firms. In the second phase, we collected and examined\ncode-related data from GitHub and market-related data from blockchain browsers\n(e.g., Etherscan) for these projects. Our analysis revealed that the Web3\necosystem can be categorized into two groups, i.e., Web3 infrastructure and\nWeb3 applications, with each consisting of several subcategories or subdomains.\nWe also gained insights into the popularity of these Web3 projects at both the\ncode and market levels and pointed out the challenges in the Web3 ecosystem at\nthe system, developer, and user levels, as well as the opportunities it\npresents. Our findings contribute to a better understanding of Web3 for\nresearchers and developers, promoting further exploration and advancement in\nthis innovative field.",
        "date": "2023-04-30T08:56:58+00:00",
        "label": 1
    },
    "2307.01411": {
        "title": "Web3Recommend: Decentralised recommendations with trust and relevance",
        "abstract": "Web3Recommend is a decentralized Social Recommender System implementation\nthat enables Web3 Platforms on Android to generate recommendations that balance\ntrust and relevance. Generating recommendations in decentralized networks is a\nnon-trivial problem because these networks lack a global perspective due to the\nabsence of a central authority. Further, decentralized networks are prone to\nSybil Attacks in which a single malicious user can generate multiple fake or\nSybil identities. Web3Recommend relies on a novel graph-based content\nrecommendation design inspired by GraphJet, a recommendation system used in\nTwitter enhanced with MeritRank, a decentralized reputation scheme that\nprovides Sybil-resistance to the system. By adding MeritRank's decay parameters\nto the vanilla Social Recommender Systems' personalized SALSA graph algorithm,\nwe can provide theoretical guarantees against Sybil Attacks in the generated\nrecommendations. Similar to GraphJet, we focus on generating real-time\nrecommendations by only acting on recent interactions in the social network,\nallowing us to cater temporally contextual recommendations while keeping a\ntight bound on the memory usage in resource-constrained devices, allowing for a\nseamless user experience. As a proof-of-concept, we integrate our system with\nMusicDAO, an open-source Web3 music-sharing platform, to generate personalized,\nreal-time recommendations. Thus, we provide the first Sybil-resistant Social\nRecommender System, allowing real-time recommendations beyond classic\nuser-based collaborative filtering. The system is also rigorously tested with\nextensive unit and integration tests. Further, our experiments demonstrate the\ntrust-relevance balance of recommendations against multiple adversarial\nstrategies in a test network generated using data from real music platforms.",
        "date": "2023-07-04T00:18:38+00:00",
        "label": 1
    },
    "2006.16964": {
        "title": "Data Science: Nature and Pitfalls",
        "abstract": "Data science is creating very exciting trends as well as significant\ncontroversy. A critical matter for the healthy development of data science in\nits early stages is to deeply understand the nature of data and data science,\nand to discuss the various pitfalls. These important issues motivate the\ndiscussions in this article.",
        "date": "2020-06-28T02:06:54+00:00",
        "label": 0
    },
    "2302.06476": {
        "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?",
        "abstract": "Spurred by advancements in scale, large language models (LLMs) have\ndemonstrated the ability to perform a variety of natural language processing\n(NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently,\nthe debut of ChatGPT has drawn a great deal of attention from the natural\nlanguage processing (NLP) community due to the fact that it can generate\nhigh-quality responses to human input and self-correct previous mistakes based\non subsequent conversations. However, it is not yet known whether ChatGPT can\nserve as a generalist model that can perform many NLP tasks zero-shot. In this\nwork, we empirically analyze the zero-shot learning ability of ChatGPT by\nevaluating it on 20 popular NLP datasets covering 7 representative task\ncategories. With extensive empirical studies, we demonstrate both the\neffectiveness and limitations of the current version of ChatGPT. We find that\nChatGPT performs well on many tasks favoring reasoning capabilities (e.g.,\narithmetic reasoning) while it still faces challenges when solving specific\ntasks such as sequence tagging. We additionally provide in-depth analysis\nthrough qualitative case studies.",
        "date": "2023-02-08T09:44:51+00:00",
        "label": 1
    },
    "1909.03033": {
        "title": "The Difficulties of Addressing Interdisciplinary Challenges at the Foundations of Data Science",
        "abstract": "The National Science Foundation's Transdisciplinary Research in Principles of\nData Science (TRIPODS) program aims to integrate three areas central to the\nfoundations of data by uniting the statistics, mathematics, and theoretical\ncomputer science research communities. The program aims to provide a model for\nfunding cross-cutting research and facilitating interactions among the three\ndisciplines. Challenges associated with orchestrating fruitful interactions are\ndescribed.",
        "date": "2019-09-04T06:07:26+00:00",
        "label": 0
    },
    "2203.00398": {
        "title": "Web3: A Decentralized Societal Infrastructure for Identity, Trust, Money, and Data",
        "abstract": "A movement for a more transparent and decentralized Internet is globally\nattracting more attention. People are becoming more privacy-aware of their\nonline identities and data. The Internet is constantly evolving. Web2 focused\non companies that provide services in exchange for personal user data. Web3\ncommits to user-centricity using decentralization and zero-server\narchitectures. The current digital society demands a global change to empower\ncitizens and take back control. Citizens are locked into big-tech for personal\ndata storage and their for-profit digital identity. Protection of data has\nproven to be essential, especially due to increased home Internet traffic\nduring the COVID pandemic. Citizens do not possess their own travel documents.\nThe European Commission aims to transition this governmental property towards\nself-sovereign identity, introducing many new opportunities. Citizens are\nlocked into banks with non-portable IBAN accounts and unsustainable legacy\nbanking infrastructures. Migration to all-digital low-fraud infrastructures and\nhealthier competitive ecosystems is essential. The overall challenge is to\nreturn the power to citizens and users again. The transition to a more\ndecentralized Internet is the first crucial step in the realization of\nuser-centricity. This thesis presents the first exploratory study that\nintegrates governmental-issued travel documents into a (decentralized) societal\ninfrastructure. These self-sovereign identities form the authentic base to a\nprivate and secure transfer of money and data, and can effectively provide\ntrust in authenticity that is currently missing in online conversations. A\nfully operational zero-server infrastructure that incorporates all our\nrequirements has been developed for Android using the P2P network overlay IPv8,\nand a personalized blockchain called TrustChain...",
        "date": "2022-03-01T12:49:02+00:00",
        "label": 1
    },
    "2303.13052": {
        "title": "Diffusion-based Reinforcement Learning for Edge-enabled AI-Generated Content Services",
        "abstract": "As Metaverse emerges as the next-generation Internet paradigm, the ability to\nefficiently generate content is paramount. AIGenerated Content (AIGC) emerges\nas a key solution, yet the resource intensive nature of large Generative AI\n(GAI) models presents challenges. To address this issue, we introduce an\nAIGC-as-a-Service (AaaS) architecture, which deploys AIGC models in wireless\nedge networks to ensure broad AIGC services accessibility for Metaverse users.\nNonetheless, an important aspect of providing personalized user experiences\nrequires carefully selecting AIGC Service Providers (ASPs) capable of\neffectively executing user tasks, which is complicated by environmental\nuncertainty and variability. Addressing this gap in current research, we\nintroduce the AI-Generated Optimal Decision (AGOD) algorithm, a diffusion\nmodel-based approach for generating the optimal ASP selection decisions.\nIntegrating AGOD with Deep Reinforcement Learning (DRL), we develop the Deep\nDiffusion Soft Actor-Critic (D2SAC) algorithm, enhancing the efficiency and\neffectiveness of ASP selection. Our comprehensive experiments demonstrate that\nD2SAC outperforms seven leading DRL algorithms. Furthermore, the proposed AGOD\nalgorithm has the potential for extension to various optimization problems in\nwireless networks, positioning it as a promising approach for future research\non AIGC-driven services. The implementation of our proposed method is available\nat: https://github.com/Lizonghang/AGOD.",
        "date": "2023-03-23T05:54:45+00:00",
        "label": 1
    },
    "2305.11911": {
        "title": "A Unified Framework for Integrating Semantic Communication and AI-Generated Content in Metaverse",
        "abstract": "As the Metaverse continues to grow, the need for efficient communication and\nintelligent content generation becomes increasingly important. Semantic\ncommunication focuses on conveying meaning and understanding from user inputs,\nwhile AI-Generated Content utilizes artificial intelligence to create digital\ncontent and experiences. Integrated Semantic Communication and AI-Generated\nContent (ISGC) has attracted a lot of attentions recently, which transfers\nsemantic information from user inputs, generates digital content, and renders\ngraphics for Metaverse. In this paper, we introduce a unified framework that\ncaptures ISGC two primary benefits, including integration gain for optimized\nresource allocation and coordination gain for goal-oriented high-quality\ncontent generation to improve immersion from both communication and content\nperspectives. We also classify existing ISGC solutions, analyze the major\ncomponents of ISGC, and present several use cases. We then construct a case\nstudy based on the diffusion model to identify an optimal resource allocation\nstrategy for performing semantic extraction, content generation, and graphic\nrendering in the Metaverse. Finally, we discuss several open research issues,\nencouraging further exploring the potential of ISGC and its related\napplications in the Metaverse.",
        "date": "2023-05-18T02:02:36+00:00",
        "label": 1
    },
    "1908.05986": {
        "title": "FAIR and Open Computer Science Research Software",
        "abstract": "In computational science and in computer science, research software is a\ncentral asset for research. Computational science is the application of\ncomputer science and software engineering principles to solving scientific\nproblems, whereas computer science is the study of computer hardware and\nsoftware design.\n  The Open Science agenda holds that science advances faster when we can build\non existing results. Therefore, research software has to be reusable for\nadvancing science. Thus, we need proper research software engineering for\nobtaining reusable and sustainable research software. This way, software\nengineering methods may improve research in other disciplines. However,\nresearch in software engineering and computer science itself will also benefit\nfrom reuse when research software is involved.\n  For good scientific practice, the resulting research software should be open\nand adhere to the FAIR principles (findable, accessible, interoperable and\nrepeatable) to allow repeatability, reproducibility, and reuse. Compared to\nresearch data, research software should be both archived for reproducibility\nand actively maintained for reusability. The FAIR data principles do not\nrequire openness, but research software should be open source software.\nEstablished open source software licenses provide sufficient licensing options,\nsuch that it should be the rare exception to keep research software closed.\n  We review and analyze the current state in this area in order to give\nrecommendations for making computer science research software FAIR and open. We\nobserve that research software publishing practices in computer science and in\ncomputational science show significant differences.",
        "date": "2019-08-16T14:26:08+00:00",
        "label": 0
    },
    "2304.06032": {
        "title": "Web 3.0: The Future of Internet",
        "abstract": "With the rapid growth of the Internet, human daily life has become deeply\nbound to the Internet. To take advantage of massive amounts of data and\ninformation on the internet, the Web architecture is continuously being\nreinvented and upgraded. From the static informative characteristics of Web 1.0\nto the dynamic interactive features of Web 2.0, scholars and engineers have\nworked hard to make the internet world more open, inclusive, and equal. Indeed,\nthe next generation of Web evolution (i.e., Web 3.0) is already coming and\nshaping our lives. Web 3.0 is a decentralized Web architecture that is more\nintelligent and safer than before. The risks and ruin posed by monopolists or\ncriminals will be greatly reduced by a complete reconstruction of the Internet\nand IT infrastructure. In a word, Web 3.0 is capable of addressing web data\nownership according to distributed technology. It will optimize the internet\nworld from the perspectives of economy, culture, and technology. Then it\npromotes novel content production methods, organizational structures, and\neconomic forms. However, Web 3.0 is not mature and is now being disputed.\nHerein, this paper presents a comprehensive survey of Web 3.0, with a focus on\ncurrent technologies, challenges, opportunities, and outlook. This article\nfirst introduces a brief overview of the history of World Wide Web as well as\nseveral differences among Web 1.0, Web 2.0, Web 3.0, and Web3. Then, some\ntechnical implementations of Web 3.0 are illustrated in detail. We discuss the\nrevolution and benefits that Web 3.0 brings. Finally, we explore several\nchallenges and issues in this promising area.",
        "date": "2023-03-23T15:37:42+00:00",
        "label": 1
    },
    "2310.19201": {
        "title": "Open Problems in DAOs",
        "abstract": "Decentralized autonomous organizations (DAOs) are a new, rapidly-growing\nclass of organizations governed by smart contracts. Here we describe how\nresearchers can contribute to the emerging science of DAOs and other\ndigitally-constituted organizations. From granular privacy primitives to\nmechanism designs to model laws, we identify high-impact problems in the DAO\necosystem where existing gaps might be tackled through a new data set or by\napplying tools and ideas from existing research fields such as political\nscience, computer science, economics, law, and organizational science. Our\nrecommendations encompass exciting research questions as well as promising\nbusiness opportunities. We call on the wider research community to join the\nglobal effort to invent the next generation of organizations.",
        "date": "2023-10-29T23:48:45+00:00",
        "label": 1
    },
    "2310.17705": {
        "title": "A Wireless AI-Generated Content (AIGC) Provisioning Framework Empowered by Semantic Communication",
        "abstract": "Generative AI applications have been recently catering to a vast user base by\ncreating diverse and high-quality AI-generated content (AIGC). With the\nproliferation of mobile devices and rapid growth of mobile traffic, providing\nubiquitous access to high-quality AIGC services via wireless communication\nnetworks is becoming the future direction. However, it is challenging to\nprovide qualified AIGC services in wireless networks with unstable channels,\nlimited bandwidth resources, and unevenly distributed computational resources.\nTo tackle these challenges, we propose a semantic communication\n(SemCom)-empowered AIGC (SemAIGC) generation and transmission framework, where\nonly semantic information of the content rather than all the binary bits should\nbe generated and transmitted by using SemCom. Specifically, SemAIGC integrates\ndiffusion models within the semantic encoder and decoder to design a\nworkload-adjustable transceiver thereby allowing adjustment of computational\nresource utilization in edge and local. In addition, a Resource-aware wOrk lOad\nTrade-off (ROOT) scheme is devised to intelligently make workload adaptation\ndecisions for the transceiver, thus efficiently generating, transmitting, and\nfine-tuning content as per dynamic wireless channel conditions and service\nrequirements. Simulations verify the superiority of our proposed SemAIGC\nframework in terms of latency and content quality compared to conventional\napproaches.",
        "date": "2023-10-26T18:05:22+00:00",
        "label": 1
    },
    "2206.12669": {
        "title": "Crypto Makes AI Evolve",
        "abstract": "Adopting cryptography has given rise to a significant evolution in Artificial\nIntelligence (AI). This paper studies the path and stages of this evolution. We\nstart with reviewing existing relevant surveys, noting their shortcomings,\nespecially the lack of a close look at the evolution process and solid future\nroadmap. These shortcomings justify the work of this paper. Next, we identify,\ndefine and discuss five consequent stages in the evolution path, including\nCrypto-Sensitive AI, Crypto-Adapted AI, Crypto-Friendly AI, Crypto-Enabled AI,\nCrypto-Protected AI. Then, we establish a future roadmap for further research\nin this area, focusing on the role of quantum-inspired and bio-inspired AI.",
        "date": "2022-06-25T15:04:47+00:00",
        "label": 0
    },
    "1005.5635": {
        "title": "An Effective Extension of the Wagner Hierarchy to Blind Counter Automata",
        "abstract": "The extension of the Wagner hierarchy to blind counter automata accepting\ninfinite words with a Muller acceptance condition is effective. We determine\nprecisely this hierarchy.",
        "date": "2010-05-31T09:19:39+00:00",
        "label": 0
    },
    "1605.08096": {
        "title": "Proceedings First Workshop on Pre- and Post-Deployment Verification Techniques",
        "abstract": "The PrePost (Pre- and Post-Deployment Verification Techniques) workshop aimed\nat bringing together researchers working in the field of computer-aided\nvalidation and verification to discuss the connections and interplay between\npre- and post-deployment verification techniques. Examples of the topics\ncovered by the workshop are the relationships between classic model checking\nand testing on the one hand and runtime verification and statistical model\nchecking on the other, and between type systems that may be checked either\nstatically or dynamically through techniques such as runtime monitoring.",
        "date": "2016-05-25T22:42:38+00:00",
        "label": 0
    },
    "0609070": {
        "title": "Exploring Computer Science Concepts with a Ready-made Computer Game Framework",
        "abstract": "Leveraging the prevailing interest in computer games among college students,\nboth for entertainment and as a possible career path, is a major reason for the\nincreasing prevalence of computer game design courses in computer science\ncurricula. Because implementing a computer game requires strong programming\nskills, game design courses are most often restricted to more advanced computer\nscience students. This paper reports on a ready-made game design and\nexperimentation framework, implemented in Java, that makes game programming\nmore widely accessible. This framework, called Labyrinth, enables students at\nall programming skill levels to participate in computer game design. We\ndescribe the architecture of the framework, and discuss programming projects\nsuitable for a wide variety of computer science courses, from capstone to\nnon-major.",
        "date": "2006-09-12T19:49:55+00:00",
        "label": 0
    },
    "2303.13050": {
        "title": "Building Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View",
        "abstract": "Web 3.0 pursues the establishment of decentralized ecosystems based on\nblockchain technologies to drive the digital transformation of physical\ncommerce and governance. Through consensus algorithms and smart contracts in\nblockchain, which are based on cryptography technologies, digital identity,\ndigital asset management, decentralized autonomous organization, and\ndecentralized finance are realized for secure and transparent digital economy\nservices in Web 3.0 for promoting the integration of digital and physical\neconomies. With the rapid realization of quantum devices, Web 3.0 is being\ndeveloped in parallel with the deployment of quantum cloud computing and\nquantum Internet. In this regard, quantum computing first disrupts the original\ncryptographic systems that protect data security while reshaping modern\ncryptography with the advantages of quantum computing and communication.\nTherefore, this survey provides a comprehensive overview of blockchain-based\nWeb 3.0 and its quantum and post-quantum enhancement from the ambilateral\nperspective. On the one hand, some post-quantum migration methods, and\nanti-quantum signatures offer potential ways to achieve unforgeable security\nunder quantum attack for the internal technologies of blockchain. On the other\nhand, some quantum/post-quantum encryption and verification algorithms improve\nthe external performance of the blockchain, enabling a decentralized, valuable,\nsecure blockchain system. Finally, we discuss the future directions toward\ndeveloping a provable secure decentralized digital ecosystem.",
        "date": "2023-03-23T05:50:38+00:00",
        "label": 1
    },
    "0911.1672": {
        "title": "Biological Computing Fundamentals and Futures",
        "abstract": "The fields of computing and biology have begun to cross paths in new ways. In\nthis paper a review of the current research in biological computing is\npresented. Fundamental concepts are introduced and these foundational elements\nare explored to discuss the possibilities of a new computing paradigm. We\nassume the reader to possess a basic knowledge of Biology and Computer Science",
        "date": "2009-11-09T13:16:01+00:00",
        "label": 0
    },
    "2202.01291": {
        "title": "Computer sciences and synthesis: retrospective and perspective",
        "abstract": "The problem of synthesis in computer sciences, including cybernetics,\nartificial intelligence and system analysis, is analyzed. Main methods of\nrealization this problem are discussed. Ways of search universal method of\ncreation universal synthetic science are represented. As example of such\nuniversal method polymetric analysis is given. Perspective of further\ndevelopment of this research, including application polymetric method for the\nresolution main problems of computer sciences, is analyzed too.",
        "date": "2022-01-26T04:42:45+00:00",
        "label": 0
    },
    "2308.15483": {
        "title": "Generative AI for Semantic Communication: Architecture, Challenges, and Outlook",
        "abstract": "Semantic communication (SemCom) is expected to be a core paradigm in future\ncommunication networks, yielding significant benefits in terms of spectrum\nresource saving and information interaction efficiency. However, the existing\nSemCom structure is limited by the lack of context-reasoning ability and\nbackground knowledge provisioning, which, therefore, motivates us to seek the\npotential of incorporating generative artificial intelligence (GAI)\ntechnologies with SemCom. Recognizing GAI's powerful capability in automating\nand creating valuable, diverse, and personalized multimodal content, this\narticle first highlights the principal characteristics of the combination of\nGAI and SemCom along with their pertinent benefits and challenges. To tackle\nthese challenges, we further propose a novel GAI-integrated SemCom network\n(GAI-SCN) framework in a cloud-edge-mobile design. Specifically, by employing\nglobal and local GAI models, our GAI-SCN enables multimodal semantic content\nprovisioning, semantic-level joint-source-channel coding, and AIGC acquisition\nto maximize the efficiency and reliability of semantic reasoning and resource\nutilization. Afterward, we present a detailed implementation workflow of\nGAI-SCN, followed by corresponding initial simulations for performance\nevaluation in comparison with two benchmarks. Finally, we discuss several open\nissues and offer feasible solutions to unlock the full potential of GAI-SCN.",
        "date": "2023-08-03T19:33:43+00:00",
        "label": 1
    },
    "2308.05282": {
        "title": "Decentralized Finance (DeFi): A Survey",
        "abstract": "Decentralized Finance (DeFi) is a new paradigm in the creation, distribution,\nand utilization of financial services via the integration of blockchain\ntechnology. Our research conducts a comprehensive introduction and meticulous\nclassification of various DeFi applications. Beyond that, we thoroughly analyze\nthese risks from both technical and economic perspectives, spanning multiple\nlayers. We point out research gaps and revenues, covering technical\nadvancements, innovative economics, and sociology and ecology optimization.",
        "date": "2023-08-10T01:59:49+00:00",
        "label": 1
    },
    "2105.07447": {
        "title": "Non-Fungible Token (NFT): Overview, Evaluation, Opportunities and Challenges",
        "abstract": "The Non-Fungible Token (NFT) market is mushrooming in recent years. The\nconcept of NFT originally comes from a token standard of Ethereum, aiming to\ndistinguish each token with distinguishable signs. This type of token can be\nbound with virtual/digital properties as their unique identifications. With\nNFTs, all marked properties can be freely traded with customized values\naccording to their ages, rarity, liquidity, etc. It has greatly stimulated the\nprosperity of the decentralized application (DApp) market. At the time of\nwriting (May 2021), the total money used on completed NFT sales has reached\n$34,530,649.86$ USD. The thousandfold return on its increasing market draws\nhuge attention worldwide. However, the development of the NFT ecosystem is\nstill in its early stage, and the technologies of NFTs are pre-mature.\nNewcomers may get lost in their frenetic evolution due to the lack of\nsystematic summaries. In this technical report, we explore the NFT ecosystems\nin several aspects. We start with an overview of state-of-the-art NFT\nsolutions, then provide their technical components, protocols, standards, and\ndesired proprieties. Afterward, we give a security evolution, with discussions\non the perspectives of their design models, opportunities, and challenges. To\nthe best of our knowledge, this is the first systematic study on the current\nNFT ecosystems.",
        "date": "2021-05-16T14:50:26+00:00",
        "label": 1
    },
    "1601.05973": {
        "title": "Science Learning via Participation in Online Citizen Science",
        "abstract": "We investigate the development of scientific content knowledge of volunteers\nparticipating in online citizen science projects in the Zooniverse\n(www.zooniverse.org), including the astronomy projects Galaxy Zoo\n(www.galaxyzoo.org) and Planet Hunters (www.planethunters.org). We use\neconometric methods to test how measures of project participation relate to\nsuccess in a science quiz, controlling for factors known to correlate with\nscientific knowledge. Citizen scientists believe they are learning about both\nthe content and processes of science through their participation. Won't don't\ndirectly test the latter, but we find evidence to support the former - that\nmore actively engaged participants perform better in a project-specific science\nknowledge quiz, even after controlling for their general science knowledge. We\ninterpret this as evidence of learning of science content inspired by\nparticipation in online citizen science.",
        "date": "2016-01-22T12:23:10+00:00",
        "label": 0
    },
    "1807.09490": {
        "title": "Investigating the Intersection of Science Fiction, Human-Computer Interaction and Computer Science Research",
        "abstract": "This paper outlines ongoing dissertation research located in the intersection\nof science fiction, human-computer interaction and computer science. Through an\ninterdisciplinary perspective, drawing from fields such as human-computer\ninteraction, film theory and studies of science and technology, qualitative and\nquantitative content analysis techniques are used to contextually analyze\nexpressions of science fiction in peer-reviewed computer science research\nrepositories, such as the ACM or IEEE Xplore Digital Libraries. This paper\nconcisely summarizes and introduces the relationship of science fiction and\ncomputer science research and presents the research questions, aims and\nimplications in addition to prior work and study methodology. In the latter\npart of this work-in-progress report, preliminary results, current limitations,\nfuture work and a post-dissertation trajectory are outlined.",
        "date": "2018-07-25T09:02:02+00:00",
        "label": 0
    },
    "2303.04226": {
        "title": "A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT",
        "abstract": "Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant\nattention from society. As a result, many individuals have become interested in\nrelated resources and are seeking to uncover the background and secrets behind\nits impressive performance. In fact, ChatGPT and other Generative AI (GAI)\ntechniques belong to the category of Artificial Intelligence Generated Content\n(AIGC), which involves the creation of digital content, such as images, music,\nand natural language, through AI models. The goal of AIGC is to make the\ncontent creation process more efficient and accessible, allowing for the\nproduction of high-quality content at a faster pace. AIGC is achieved by\nextracting and understanding intent information from instructions provided by\nhuman, and generating the content according to its knowledge and the intent\ninformation. In recent years, large-scale models have become increasingly\nimportant in AIGC as they provide better intent extraction and thus, improved\ngeneration results. With the growth of data and the size of the models, the\ndistribution that the model can learn becomes more comprehensive and closer to\nreality, leading to more realistic and high-quality content generation. This\nsurvey provides a comprehensive review on the history of generative models, and\nbasic components, recent advances in AIGC from unimodal interaction and\nmultimodal interaction. From the perspective of unimodality, we introduce the\ngeneration tasks and relative models of text and image. From the perspective of\nmultimodality, we introduce the cross-application between the modalities\nmentioned above. Finally, we discuss the existing open problems and future\nchallenges in AIGC.",
        "date": "2023-03-07T20:36:13+00:00",
        "label": 1
    },
    "1003.1930": {
        "title": "Simulating Grover's Quantum Search in a Classical Computer",
        "abstract": "The rapid progress of computer science has been accompanied by a\ncorresponding evolution of computation, from classical computation to quantum\ncomputation. As quantum computing is on its way to becoming an established\ndiscipline of computing science, much effort is being put into the development\nof new quantum algorithms. One of quantum algorithms is Grover algorithm, which\nis used for searching an element in an unstructured list of N elements with\nquadratic speed-up over classical algorithms. In this work, Quantum Computer\nLanguage (QCL) is used to make a Grover's quantum search simulation in a\nclassical computer",
        "date": "2010-03-09T17:02:21+00:00",
        "label": 0
    },
    "0609110": {
        "title": "Algebraic recognizability of languages",
        "abstract": "Recognizable languages of finite words are part of every computer science\ncursus, and they are routinely described as a cornerstone for applications and\nfor theory. We would like to briefly explore why that is, and how this\nword-related notion extends to more complex models, such as those developed for\nmodeling distributed or timed behaviors.",
        "date": "2006-09-19T15:21:08+00:00",
        "label": 0
    },
    "2109.06836": {
        "title": "Security, Privacy, and Decentralization in Web3",
        "abstract": "Much of the recent excitement around decentralized finance (DeFi) comes from\nhopes that DeFi can be a secure, private, less centralized alternative to\ntraditional finance systems. However, people moving to DeFi sites in hopes of\nimproving their security and privacy may end up with less of both as recent\nattacks have demonstrated. In this work, we improve the understanding of DeFi\nby conducting the first Web measurements of the security, privacy, and\ndecentralization properties of popular DeFi front ends. We find that DeFi\napplications -- or dapps -- suffer from the same security and privacy risks\nthat frequent other parts of the Web but those risks are greatly exacerbated\nconsidering the money that is involved in DeFi. Our results show that a common\ntracker can observe user behavior on over 56% of websites we analyzed and many\ntrackers on DeFi sites can trivially link a user's Ethereum address with PII\n(e.g., user name or demographic information), or phish users by initiating fake\nEthereum transactions. Lastly, we establish that despite claims to the\nopposite, because of companies like Amazon and Cloudflare operating significant\nWeb infrastructure, DeFi as a whole is considerably less decentralized than\npreviously believed.",
        "date": "2021-09-14T17:21:02+00:00",
        "label": 1
    },
    "2303.11717": {
        "title": "A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?",
        "abstract": "As ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has\nmade headlines everywhere because of its ability to analyze and create text,\nimages, and beyond. With such overwhelming media coverage, it is almost\nimpossible for us to miss the opportunity to glimpse AIGC from a certain angle.\nIn the era of AI transitioning from pure analysis to creation, it is worth\nnoting that ChatGPT, with its most recent language model GPT-4, is just a tool\nout of numerous AIGC tasks. Impressed by the capability of the ChatGPT, many\npeople are wondering about its limits: can GPT-5 (or other future GPT variants)\nhelp ChatGPT unify all AIGC tasks for diversified content creation? Toward\nanswering this question, a comprehensive review of existing AIGC tasks is\nneeded. As such, our work comes to fill this gap promptly by offering a first\nlook at AIGC, ranging from its techniques to applications. Modern generative AI\nrelies on various technical foundations, ranging from model architecture and\nself-supervised pretraining to generative modeling methods (like GAN and\ndiffusion models). After introducing the fundamental techniques, this work\nfocuses on the technological development of various AIGC tasks based on their\noutput type, including text, images, videos, 3D content, etc., which depicts\nthe full potential of ChatGPT's future. Moreover, we summarize their\nsignificant applications in some mainstream industries, such as education and\ncreativity content. Finally, we discuss the challenges currently faced and\npresent an outlook on how generative AI might evolve in the near future.",
        "date": "2023-03-21T10:09:47+00:00",
        "label": 1
    },
    "2309.01426": {
        "title": "A Unified Framework for Guiding Generative AI with Wireless Perception in Resource Constrained Mobile Edge Networks",
        "abstract": "With the significant advancements in artificial intelligence (AI)\ntechnologies and powerful computational capabilities, generative AI (GAI) has\nbecome a pivotal digital content generation technique for offering superior\ndigital services. However, directing GAI towards desired outputs still suffer\nthe inherent instability of the AI model. In this paper, we design a novel\nframework that utilizes wireless perception to guide GAI (WiPe-GAI) for\nproviding digital content generation service, i.e., AI-generated content\n(AIGC), in resource-constrained mobile edge networks. Specifically, we first\npropose a new sequential multi-scale perception (SMSP) algorithm to predict\nuser skeleton based on the channel state information (CSI) extracted from\nwireless signals. This prediction then guides GAI to provide users with AIGC,\nsuch as virtual character generation. To ensure the efficient operation of the\nproposed framework in resource constrained networks, we further design a\npricing-based incentive mechanism and introduce a diffusion model based\napproach to generate an optimal pricing strategy for the service provisioning.\nThe strategy maximizes the user's utility while enhancing the participation of\nthe virtual service provider (VSP) in AIGC provision. The experimental results\ndemonstrate the effectiveness of the designed framework in terms of skeleton\nprediction and optimal pricing strategy generation comparing with other\nexisting solutions.",
        "date": "2023-09-04T08:18:35+00:00",
        "label": 1
    },
    "2206.08821": {
        "title": "Exploring Web3 From the View of Blockchain",
        "abstract": "Web3 is the most hyped concept from 2020 to date, greatly motivating the\nprosperity of the Internet of Value and Metaverse. However, no solid evidence\nstipulates the exact definition, criterion, or standard in the sense of such a\nbuzzword. To fill the gap, we aim to clarify the term in this work. We narrow\ndown the connotation of Web3 by separating it from high-level controversy\nargues and, instead, focusing on its protocol, architecture, and evaluation\nfrom the perspective of blockchain fields. Specifically, we have identified all\npotential architectural design types and evaluated each of them by employing\nthe scenario-based architecture evaluation method. The evaluation shows that\nexisting applications are neither secure nor adoptable as claimed. Meanwhile,\nwe also discuss opportunities and challenges surrounding the Web3 space and\nanswer several prevailing questions from communities. A primary result is that\nWeb3 still relies on traditional internet infrastructure, not as independent as\nadvocated. This report, as of June 2022, provides the first strict research on\nWeb3 in the view of blockchain. We hope that this work would provide a guide\nfor the development of future Web3 services.",
        "date": "2022-06-17T15:01:23+00:00",
        "label": 1
    },
    "2305.12130": {
        "title": "Joint Foundation Model Caching and Inference of Generative AI Services for Edge Intelligence",
        "abstract": "With the rapid development of artificial general intelligence (AGI), various\nmultimedia services based on pretrained foundation models (PFMs) need to be\neffectively deployed. With edge servers that have cloud-level computing power,\nedge intelligence can extend the capabilities of AGI to mobile edge networks.\nHowever, compared with cloud data centers, resource-limited edge servers can\nonly cache and execute a small number of PFMs, which typically consist of\nbillions of parameters and require intensive computing power and GPU memory\nduring inference. To address this challenge, in this paper, we propose a joint\nfoundation model caching and inference framework that aims to balance the\ntradeoff among inference latency, accuracy, and resource consumption by\nmanaging cached PFMs and user requests efficiently during the provisioning of\ngenerative AI services. Specifically, considering the in-context learning\nability of PFMs, a new metric named the Age of Context (AoC), is proposed to\nmodel the freshness and relevance between examples in past demonstrations and\ncurrent service requests. Based on the AoC, we propose a least context caching\nalgorithm to manage cached PFMs at edge servers with historical prompts and\ninference results. The numerical results demonstrate that the proposed\nalgorithm can reduce system costs compared with existing baselines by\neffectively utilizing contextual information.",
        "date": "2023-05-20T07:51:10+00:00",
        "label": 1
    },
    "2106.07553": {
        "title": "A Cognitive Science perspective for learning how to design meaningful user experiences and human-centered technology",
        "abstract": "This paper reviews literature in cognitive science, human-computer\ninteraction (HCI) and natural-language processing (NLP) to consider how\nanalogical reasoning (AR) could help inform the design of communication and\nlearning technologies, as well as online communities and digital platforms.\nFirst, analogical reasoning (AR) is defined, and use-cases of AR in the\ncomputing sciences are presented. The concept of schema is introduced, along\nwith use-cases in computing. Finally, recommendations are offered for future\nwork on using analogical reasoning and schema methods in the computing\nsciences.",
        "date": "2021-06-02T15:00:50+00:00",
        "label": 0
    },
    "2207.01934": {
        "title": "How sustainable is \"common\" data science in terms of power consumption?",
        "abstract": "Continuous developments in data science have brought forth an exponential\nincrease in complexity of machine learning models. Additionally, data\nscientists have become ubiquitous in the private market, academic environments\nand even as a hobby. All of these trends are on a steady rise, and are\nassociated with an increase in power consumption and associated carbon\nfootprint. The increasing carbon footprint of large-scale advanced data science\nhas already received attention, but the latter trend has not. This work aims to\nestimate the contribution of the increasingly popular \"common\" data science to\nthe global carbon footprint. To this end, the power consumption of several\ntypical tasks in the aforementioned common data science tasks will be measured\nand compared to: large-scale \"advanced\" data science, common computer-related\ntasks, and everyday non-computer related tasks. This is done by converting the\nmeasurements to the equivalent unit of \"km driven by car\". Our main findings\nare: \"common\" data science consumes $2.57$ more power than regular computer\nusage, but less than some common everyday power-consuming tasks such as\nlighting or heating; large-scale data science consumes substantially more power\nthan common data science.",
        "date": "2022-07-05T10:15:22+00:00",
        "label": 0
    },
    "2210.05903": {
        "title": "Towards Web3 Applications: Easing the Access and Transition",
        "abstract": "Web3 is leading a wave of the next generation of web services that even many\nWeb2 applications are keen to ride. However, the lack of Web3 background for\nWeb2 developers hinders easy and effective access and transition. On the other\nhand, Web3 applications desire for encouragement and advertisement from\nconventional Web2 companies and projects due to their low market shares. In\nthis paper, we propose a seamless transition framework that transits Web2 to\nWeb3, named WebttCom, after exploring the connotation of Web3 and the key\ndifferences between Web2 and Web3 applications. We also provide a full-stack\nimplementation as a use case to support the proposed framework, followed by\ninterviews with five participants that show four positive and one natural\nresponse. We confirm that the proposed framework WebttCom addresses the defined\nresearch question, and the implementation well satisfies the framework WebttCom\nin terms of strong necessity, usability, and completeness based on the\ninterview results.",
        "date": "2022-10-12T03:41:49+00:00",
        "label": 1
    },
    "0608062": {
        "title": "Tarski's influence on computer science",
        "abstract": "The influence of Alfred Tarski on computer science was indirect but\nsignificant in a number of directions and was in certain respects fundamental.\nHere surveyed is the work of Tarski on the decision procedure for algebra and\ngeometry, the method of elimination of quantifiers, the semantics of formal\nlanguages, modeltheoretic preservation theorems, and algebraic logic; various\nconnections of each with computer science are taken up.",
        "date": "2006-08-15T16:40:24+00:00",
        "label": 0
    },
    "2306.03351": {
        "title": "The current opportunities and challenges of Web 3.0",
        "abstract": "With recent advancements in AI and 5G technologies,as well as the nascent\nconcepts of blockchain and metaverse,a new revolution of the Internet,known as\nWeb 3.0,is emerging. Given its significant potential impact on the internet\nlandscape and various professional sectors,Web 3.0 has captured considerable\nattention from both academic and industry circles. This article presents an\nexploratory analysis of the opportunities and challenges associated with Web\n3.0. Firstly, the study evaluates the technical differences between Web 1.0,\nWeb 2.0, and Web 3.0, while also delving into the unique technical architecture\nof Web 3.0. Secondly, by reviewing current literature, the article highlights\nthe current state of development surrounding Web 3.0 from both economic and\ntechnological perspective. Thirdly, the study identifies numerous research and\nregulatory obstacles that presently confront Web 3.0 initiatives. Finally, the\narticle concludes by providing a forward-looking perspective on the potential\nfuture growth and progress of Web 3.0 technology.",
        "date": "2023-06-06T02:00:17+00:00",
        "label": 1
    }
}