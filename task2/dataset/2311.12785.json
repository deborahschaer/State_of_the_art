{
    "2207.07901": {
        "title": "Computer Science",
        "abstract": "Possible for science itself, conceptually, to have and will understand\ndifferently, let alone science also seen as technology, such as computer\nscience. After all, science and technology are viewpoints diverse by either\nindividual, community, or social. Generally, it depends on socioeconomic\ncapabilities. So it is with computer science has become a phenomenon and\nfashionable, where based on the stream of documents, various issues arise in\neither its theory or implementation, adapting different communities, or\ndesigning curriculum holds in the education system.",
        "date": "2022-07-16T10:54:57+00:00",
        "label": 0
    },
    "2007.08087": {
        "title": "Starting with data: advancing spatial data science by building and sharing high-quality datasets",
        "abstract": "Spatial data science has emerged in recent years as an interdisciplinary\nfield. This position paper discusses the importance of building and sharing\nhigh-quality datasets for spatial data science.",
        "date": "2020-07-16T03:15:56+00:00",
        "label": 0
    },
    "1612.04037": {
        "title": "Proceedings 11th Doctoral Workshop on Mathematical and Engineering Methods in Computer Science",
        "abstract": "MEMICS provides a forum for doctoral students interested in applications of\nmathematical and engineering methods in computer science. Besides a rich\ntechnical programme (including invited talks, regular papers, and\npresentations), MEMICS also offers friendly social activities and exciting\nopportunities for meeting like-minded people. MEMICS submissions traditionally\ncover all areas of computer science (such as parallel and distributed\ncomputing, computer networks, modern hardware and its design, non-traditional\ncomputing architectures, information systems and databases, multimedia and\ngraphics, verification and testing, computer security, as well as all related\nareas of theoretical computer science).",
        "date": "2016-12-13T05:47:19+00:00",
        "label": 0
    },
    "1909.03033": {
        "title": "The Difficulties of Addressing Interdisciplinary Challenges at the Foundations of Data Science",
        "abstract": "The National Science Foundation's Transdisciplinary Research in Principles of\nData Science (TRIPODS) program aims to integrate three areas central to the\nfoundations of data by uniting the statistics, mathematics, and theoretical\ncomputer science research communities. The program aims to provide a model for\nfunding cross-cutting research and facilitating interactions among the three\ndisciplines. Challenges associated with orchestrating fruitful interactions are\ndescribed.",
        "date": "2019-09-04T06:07:26+00:00",
        "label": 0
    },
    "2306.13651": {
        "title": "Bring Your Own Data! Self-Supervised Evaluation for Large Language Models",
        "abstract": "With the rise of Large Language Models (LLMs) and their ubiquitous deployment\nin diverse domains, measuring language model behavior on realistic data is\nimperative. For example, a company deploying a client-facing chatbot must\nensure that the model will not respond to client requests with profanity.\nCurrent evaluations approach this problem using small, domain-specific datasets\nwith human-curated labels. These evaluation sets are often sampled from a\nnarrow and simplified distribution, and data sources can unknowingly be leaked\ninto the training set which can lead to misleading evaluations. To bypass these\ndrawbacks, we propose a framework for self-supervised evaluation of LLMs by\nanalyzing their sensitivity or invariance to transformations on the input text.\nSelf-supervised evaluation can directly monitor LLM behavior on datasets\ncollected in the wild or streamed during live model deployment. We demonstrate\nself-supervised evaluation strategies for measuring closed-book knowledge,\ntoxicity, and long-range context dependence, in addition to sensitivity to\ngrammatical structure and tokenization errors. When comparisons to similar\nhuman-labeled benchmarks are available, we find strong correlations between\nself-supervised and human-supervised evaluations. The self-supervised paradigm\ncomplements current evaluation strategies that rely on labeled data.",
        "date": "2023-06-23T17:59:09+00:00",
        "label": 1
    },
    "2305.01625": {
        "title": "Unlimiformer: Long-Range Transformers with Unlimited Length Input",
        "abstract": "Since the proposal of transformers, these models have been limited to bounded\ninput lengths, because of their need to attend to every token in the input. In\nthis work, we propose Unlimiformer: a general approach that wraps any existing\npretrained encoder-decoder transformer, and offloads the cross-attention\ncomputation to a single k-nearest-neighbor (kNN) index, while the returned kNN\ndistances are the attention dot-product scores. This kNN index can be kept on\neither the GPU or CPU memory and queried in sub-linear time; this way, we can\nindex practically unlimited input sequences, while every attention head in\nevery decoder layer retrieves its top-k keys, instead of attending to every\nkey. We evaluate Unlimiformer on several long-document and book-summarization\nbenchmarks, showing that it can process even 500k token-long inputs from the\nBookSum dataset, without any input truncation at test time. We demonstrate that\nUnlimiformer improves pretrained models such as BART and Longformer by\nextending them to unlimited inputs without additional learned weights and\nwithout modifying their code. We make our code and models publicly available at\nhttps://github.com/abertsch72/unlimiformer .",
        "date": "2023-05-02T17:35:08+00:00",
        "label": 1
    },
    "2307.16888": {
        "title": "Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection",
        "abstract": "Instruction-tuned Large Language Models (LLMs) have become a ubiquitous\nplatform for open-ended applications due to their ability to modulate responses\nbased on human instructions. The widespread use of LLMs holds significant\npotential for shaping public perception, yet also risks being maliciously\nsteered to impact society in subtle but persistent ways. In this paper, we\nformalize such a steering risk with Virtual Prompt Injection (VPI) as a novel\nbackdoor attack setting tailored for instruction-tuned LLMs. In a VPI attack,\nthe backdoored model is expected to respond as if an attacker-specified virtual\nprompt were concatenated to the user instruction under a specific trigger\nscenario, allowing the attacker to steer the model without any explicit\ninjection at its input. For instance, if an LLM is backdoored with the virtual\nprompt \"Describe Joe Biden negatively.\" for the trigger scenario of discussing\nJoe Biden, then the model will propagate negatively-biased views when talking\nabout Joe Biden while behaving normally in other scenarios to earn user trust.\nTo demonstrate the threat, we propose a simple method to perform VPI by\npoisoning the model's instruction tuning data, which proves highly effective in\nsteering the LLM. For example, by poisoning only 52 instruction tuning examples\n(0.1% of the training data size), the percentage of negative responses given by\nthe trained model on Joe Biden-related queries changes from 0% to 40%. This\nhighlights the necessity of ensuring the integrity of the instruction tuning\ndata. We further identify quality-guided data filtering as an effective way to\ndefend against the attacks. Our project page is available at\nhttps://poison-llm.github.io.",
        "date": "2023-07-31T17:56:00+00:00",
        "label": 1
    },
    "2303.04226": {
        "title": "A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT",
        "abstract": "Recently, ChatGPT, along with DALL-E-2 and Codex,has been gaining significant\nattention from society. As a result, many individuals have become interested in\nrelated resources and are seeking to uncover the background and secrets behind\nits impressive performance. In fact, ChatGPT and other Generative AI (GAI)\ntechniques belong to the category of Artificial Intelligence Generated Content\n(AIGC), which involves the creation of digital content, such as images, music,\nand natural language, through AI models. The goal of AIGC is to make the\ncontent creation process more efficient and accessible, allowing for the\nproduction of high-quality content at a faster pace. AIGC is achieved by\nextracting and understanding intent information from instructions provided by\nhuman, and generating the content according to its knowledge and the intent\ninformation. In recent years, large-scale models have become increasingly\nimportant in AIGC as they provide better intent extraction and thus, improved\ngeneration results. With the growth of data and the size of the models, the\ndistribution that the model can learn becomes more comprehensive and closer to\nreality, leading to more realistic and high-quality content generation. This\nsurvey provides a comprehensive review on the history of generative models, and\nbasic components, recent advances in AIGC from unimodal interaction and\nmultimodal interaction. From the perspective of unimodality, we introduce the\ngeneration tasks and relative models of text and image. From the perspective of\nmultimodality, we introduce the cross-application between the modalities\nmentioned above. Finally, we discuss the existing open problems and future\nchallenges in AIGC.",
        "date": "2023-03-07T20:36:13+00:00",
        "label": 1
    },
    "1606.01148": {
        "title": "Tripartite Unions",
        "abstract": "This note provides conditions under which the union of three well-founded\nbinary relations is also well-founded.",
        "date": "2016-06-03T15:41:55+00:00",
        "label": 0
    },
    "2105.01707": {
        "title": "ABET Accreditation: A Way Forward for PDC Education",
        "abstract": "With parallel and distributed computing (PDC) now wide-spread, modern\ncomputing programs must incorporate PDC within the curriculum. ACM and IEEE\nComputer Society's Computer Science curricular guidelines have recommended\nexposure to PDC concepts since 2013. More recently, a variety of initiatives\nhave made PDC curricular content, lectures, and labs freely available for\nundergraduate computer science programs. Despite these efforts, progress in\nensuring computer science students graduate with sufficient PDC exposure has\nbeen uneven.\n  This paper discusses the impact of ABET's revised criteria that have required\nexposure to PDC to achieve accreditation for computer science programs since\n2018. The authors reviewed 20 top ABET-accredited computer science programs and\nanalyzed how they covered the required PDC components in their curricula. Using\ntheir own institutions as case studies, the authors examine in detail how three\ndifferent ABET-accredited computer science programs covered PDC using different\napproaches, yet meeting the PDC requirements of these ABET criteria. The paper\nalso shows how ACM/IEEE Computer Society curricular guidelines for computer\nengineering and software engineering programs, along with ABET accreditation\ncriteria, can cover PDC.",
        "date": "2021-05-04T18:58:18+00:00",
        "label": 0
    },
    "2201.05852": {
        "title": "Data Science in Perspective",
        "abstract": "Data and Science has stood out in the generation of results, whether in the\nprojects of the scientific domain or business domain. CERN Project, Scientific\nInstitutes, companies like Walmart, Google, Apple, among others, need data to\npresent their results and make predictions in the competitive data world. Data\nand Science are words that together culminated in a globally recognized term\ncalled Data Science. Data Science is in its initial phase, possibly being part\nof formal sciences and also being presented as part of applied sciences,\ncapable of generating value and supporting decision making. Data Science\nconsiders science and, consequently, the scientific method to promote decision\nmaking through data intelligence. In many cases, the application of the method\n(or part of it) is considered in Data Science projects in scientific domain\n(social sciences, bioinformatics, geospatial projects) or business domain\n(finance, logistic, retail), among others. In this sense, this article\naddresses the perspectives of Data Science as a multidisciplinary area,\nconsidering science and the scientific method, and its formal structure which\nintegrate Statistics, Computer Science, and Business Science, also taking into\naccount Artificial Intelligence, emphasizing Machine Learning, among others.\nThe article also deals with the perspective of applied Data Science, since Data\nScience is used for generating value through scientific and business projects.\nData Science persona is also discussed in the article, concerning the education\nof Data Science professionals and its corresponding profiles, since its\nprojection changes the field of data in the world.",
        "date": "2022-01-15T13:51:12+00:00",
        "label": 0
    },
    "2111.01998": {
        "title": "OpenPrompt: An Open-source Framework for Prompt-learning",
        "abstract": "Prompt-learning has become a new paradigm in modern natural language\nprocessing, which directly adapts pre-trained language models (PLMs) to\n$cloze$-style prediction, autoregressive modeling, or sequence to sequence\ngeneration, resulting in promising performances on various tasks. However, no\nstandard implementation framework of prompt-learning is proposed yet, and most\nexisting prompt-learning codebases, often unregulated, only provide limited\nimplementations for specific scenarios. Since there are many details such as\ntemplating strategy, initializing strategy, and verbalizing strategy, etc. need\nto be considered in prompt-learning, practitioners face impediments to quickly\nadapting the desired prompt learning methods to their applications. In this\npaper, we present {OpenPrompt}, a unified easy-to-use toolkit to conduct\nprompt-learning over PLMs. OpenPrompt is a research-friendly framework that is\nequipped with efficiency, modularity, and extendibility, and its combinability\nallows the freedom to combine different PLMs, task formats, and prompting\nmodules in a unified paradigm. Users could expediently deploy prompt-learning\nframeworks and evaluate the generalization of them on different NLP tasks\nwithout constraints. OpenPrompt is publicly released at {\\url{\nhttps://github.com/thunlp/OpenPrompt}}.",
        "date": "2021-11-03T03:31:14+00:00",
        "label": 1
    },
    "1810.04805": {
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "abstract": "We introduce a new language representation model called BERT, which stands\nfor Bidirectional Encoder Representations from Transformers. Unlike recent\nlanguage representation models, BERT is designed to pre-train deep\nbidirectional representations from unlabeled text by jointly conditioning on\nboth left and right context in all layers. As a result, the pre-trained BERT\nmodel can be fine-tuned with just one additional output layer to create\nstate-of-the-art models for a wide range of tasks, such as question answering\nand language inference, without substantial task-specific architecture\nmodifications.\n  BERT is conceptually simple and empirically powerful. It obtains new\nstate-of-the-art results on eleven natural language processing tasks, including\npushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\naccuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering\nTest F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1\n(5.1 point absolute improvement).",
        "date": "2018-10-11T00:50:01+00:00",
        "label": 1
    },
    "0706.0484": {
        "title": "Motivation, Design, and Ubiquity: A Discussion of Research Ethics and Computer Science",
        "abstract": "Modern society is permeated with computers, and the software that controls\nthem can have latent, long-term, and immediate effects that reach far beyond\nthe actual users of these systems. This places researchers in Computer Science\nand Software Engineering in a critical position of influence and\nresponsibility, more than any other field because computer systems are vital\nresearch tools for other disciplines. This essay presents several key ethical\nconcerns and responsibilities relating to research in computing. The goal is to\npromote awareness and discussion of ethical issues among computer science\nresearchers. A hypothetical case study is provided, along with questions for\nreflection and discussion.",
        "date": "2007-06-04T17:17:44+00:00",
        "label": 0
    },
    "2302.07842": {
        "title": "Augmented Language Models: a Survey",
        "abstract": "This survey reviews works in which language models (LMs) are augmented with\nreasoning skills and the ability to use tools. The former is defined as\ndecomposing a potentially complex task into simpler subtasks while the latter\nconsists in calling external modules such as a code interpreter. LMs can\nleverage these augmentations separately or in combination via heuristics, or\nlearn to do so from demonstrations. While adhering to a standard missing tokens\nprediction objective, such augmented LMs can use various, possibly\nnon-parametric external modules to expand their context processing ability,\nthus departing from the pure language modeling paradigm. We therefore refer to\nthem as Augmented Language Models (ALMs). The missing token objective allows\nALMs to learn to reason, use tools, and even act, while still performing\nstandard natural language tasks and even outperforming most regular LMs on\nseveral benchmarks. In this work, after reviewing current advance in ALMs, we\nconclude that this new research direction has the potential to address common\nlimitations of traditional LMs such as interpretability, consistency, and\nscalability issues.",
        "date": "2023-02-15T18:25:52+00:00",
        "label": 1
    },
    "1003.1930": {
        "title": "Simulating Grover's Quantum Search in a Classical Computer",
        "abstract": "The rapid progress of computer science has been accompanied by a\ncorresponding evolution of computation, from classical computation to quantum\ncomputation. As quantum computing is on its way to becoming an established\ndiscipline of computing science, much effort is being put into the development\nof new quantum algorithms. One of quantum algorithms is Grover algorithm, which\nis used for searching an element in an unstructured list of N elements with\nquadratic speed-up over classical algorithms. In this work, Quantum Computer\nLanguage (QCL) is used to make a Grover's quantum search simulation in a\nclassical computer",
        "date": "2010-03-09T17:02:21+00:00",
        "label": 0
    },
    "0911.1672": {
        "title": "Biological Computing Fundamentals and Futures",
        "abstract": "The fields of computing and biology have begun to cross paths in new ways. In\nthis paper a review of the current research in biological computing is\npresented. Fundamental concepts are introduced and these foundational elements\nare explored to discuss the possibilities of a new computing paradigm. We\nassume the reader to possess a basic knowledge of Biology and Computer Science",
        "date": "2009-11-09T13:16:01+00:00",
        "label": 0
    },
    "2304.11062": {
        "title": "Scaling Transformer to 1M tokens and beyond with RMT",
        "abstract": "A major limitation for the broader scope of problems solvable by transformers\nis the quadratic scaling of computational complexity with input size. In this\nstudy, we investigate the recurrent memory augmentation of pre-trained\ntransformer models to extend input context length while linearly scaling\ncompute. Our approach demonstrates the capability to store information in\nmemory for sequences of up to an unprecedented two million tokens while\nmaintaining high retrieval accuracy. Experiments with language modeling tasks\nshow perplexity improvement as the number of processed input segments\nincreases. These results underscore the effectiveness of our method, which has\nsignificant potential to enhance long-term dependency handling in natural\nlanguage understanding and generation tasks, as well as enable large-scale\ncontext processing for memory-intensive applications.",
        "date": "2023-04-19T16:18:54+00:00",
        "label": 1
    },
    "2303.08774": {
        "title": "GPT-4 Technical Report",
        "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can\naccept image and text inputs and produce text outputs. While less capable than\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance on\nvarious professional and academic benchmarks, including passing a simulated bar\nexam with a score around the top 10% of test takers. GPT-4 is a\nTransformer-based model pre-trained to predict the next token in a document.\nThe post-training alignment process results in improved performance on measures\nof factuality and adherence to desired behavior. A core component of this\nproject was developing infrastructure and optimization methods that behave\npredictably across a wide range of scales. This allowed us to accurately\npredict some aspects of GPT-4's performance based on models trained with no\nmore than 1/1,000th the compute of GPT-4.",
        "date": "2023-03-15T17:15:04+00:00",
        "label": 1
    },
    "2308.00352": {
        "title": "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework",
        "abstract": "Remarkable progress has been made on automated problem solving through\nsocieties of agents based on large language models (LLMs). Existing LLM-based\nmulti-agent systems can already solve simple dialogue tasks. Solutions to more\ncomplex tasks, however, are complicated through logic inconsistencies due to\ncascading hallucinations caused by naively chaining LLMs. Here we introduce\nMetaGPT, an innovative meta-programming framework incorporating efficient human\nworkflows into LLM-based multi-agent collaborations. MetaGPT encodes\nStandardized Operating Procedures (SOPs) into prompt sequences for more\nstreamlined workflows, thus allowing agents with human-like domain expertise to\nverify intermediate results and reduce errors. MetaGPT utilizes an assembly\nline paradigm to assign diverse roles to various agents, efficiently breaking\ndown complex tasks into subtasks involving many agents working together. On\ncollaborative software engineering benchmarks, MetaGPT generates more coherent\nsolutions than previous chat-based multi-agent systems. Our project can be\nfound at https://github.com/geekan/MetaGPT",
        "date": "2023-08-01T07:49:10+00:00",
        "label": 1
    }
}