{
    "2112.10741": {
        "title": "GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models",
        "abstract": "Diffusion models have recently been shown to generate high-quality synthetic\nimages, especially when paired with a guidance technique to trade off diversity\nfor fidelity. We explore diffusion models for the problem of text-conditional\nimage synthesis and compare two different guidance strategies: CLIP guidance\nand classifier-free guidance. We find that the latter is preferred by human\nevaluators for both photorealism and caption similarity, and often produces\nphotorealistic samples. Samples from a 3.5 billion parameter text-conditional\ndiffusion model using classifier-free guidance are favored by human evaluators\nto those from DALL-E, even when the latter uses expensive CLIP reranking.\nAdditionally, we find that our models can be fine-tuned to perform image\ninpainting, enabling powerful text-driven image editing. We train a smaller\nmodel on a filtered dataset and release the code and weights at\nhttps://github.com/openai/glide-text2im.",
        "date": "2021-12-20T18:42:55+00:00",
        "label": 1
    },
    "0911.1672": {
        "title": "Biological Computing Fundamentals and Futures",
        "abstract": "The fields of computing and biology have begun to cross paths in new ways. In\nthis paper a review of the current research in biological computing is\npresented. Fundamental concepts are introduced and these foundational elements\nare explored to discuss the possibilities of a new computing paradigm. We\nassume the reader to possess a basic knowledge of Biology and Computer Science",
        "date": "2009-11-09T13:16:01+00:00",
        "label": 0
    },
    "1909.03033": {
        "title": "The Difficulties of Addressing Interdisciplinary Challenges at the Foundations of Data Science",
        "abstract": "The National Science Foundation's Transdisciplinary Research in Principles of\nData Science (TRIPODS) program aims to integrate three areas central to the\nfoundations of data by uniting the statistics, mathematics, and theoretical\ncomputer science research communities. The program aims to provide a model for\nfunding cross-cutting research and facilitating interactions among the three\ndisciplines. Challenges associated with orchestrating fruitful interactions are\ndescribed.",
        "date": "2019-09-04T06:07:26+00:00",
        "label": 0
    },
    "2401.08053": {
        "title": "SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation",
        "abstract": "Accurate representation in media is known to improve the well-being of the\npeople who consume it. Generative image models trained on large web-crawled\ndatasets such as LAION are known to produce images with harmful stereotypes and\nmisrepresentations of cultures. We improve inclusive representation in\ngenerated images by (1) engaging with communities to collect a culturally\nrepresentative dataset that we call the Cross-Cultural Understanding Benchmark\n(CCUB) and (2) proposing a novel Self-Contrastive Fine-Tuning (SCoFT) method\nthat leverages the model's known biases to self-improve. SCoFT is designed to\nprevent overfitting on small datasets, encode only high-level information from\nthe data, and shift the generated distribution away from misrepresentations\nencoded in a pretrained model. Our user study conducted on 51 participants from\n5 different countries based on their self-selected national cultural\naffiliation shows that fine-tuning on CCUB consistently generates images with\nhigher cultural relevance and fewer stereotypes when compared to the Stable\nDiffusion baseline, which is further improved with our SCoFT technique.",
        "date": "2024-01-16T02:10:13+00:00",
        "label": 1
    },
    "1005.5635": {
        "title": "An Effective Extension of the Wagner Hierarchy to Blind Counter Automata",
        "abstract": "The extension of the Wagner hierarchy to blind counter automata accepting\ninfinite words with a Muller acceptance condition is effective. We determine\nprecisely this hierarchy.",
        "date": "2010-05-31T09:19:39+00:00",
        "label": 0
    },
    "2311.03287": {
        "title": "Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges",
        "abstract": "While GPT-4V(ision) impressively models both visual and textual information\nsimultaneously, it's hallucination behavior has not been systematically\nassessed. To bridge this gap, we introduce a new benchmark, namely, the Bias\nand Interference Challenges in Visual Language Models (Bingo). This benchmark\nis designed to evaluate and shed light on the two common types of\nhallucinations in visual language models: bias and interference. Here, bias\nrefers to the model's tendency to hallucinate certain types of responses,\npossibly due to imbalance in its training data. Interference pertains to\nscenarios where the judgment of GPT-4V(ision) can be disrupted due to how the\ntext prompt is phrased or how the input image is presented. We identify a\nnotable regional bias, whereby GPT-4V(ision) is better at interpreting Western\nimages or images with English writing compared to images from other countries\nor containing text in other languages. Moreover, GPT-4V(ision) is vulnerable to\nleading questions and is often confused when interpreting multiple images\ntogether. Popular mitigation approaches, such as self-correction and\nchain-of-thought reasoning, are not effective in resolving these challenges. We\nalso identified similar biases and interference vulnerabilities with LLaVA and\nBard. Our results characterize the hallucination challenges in GPT-4V(ision)\nand state-of-the-art visual-language models, and highlight the need for new\nsolutions. The Bingo benchmark is available at https://github.com/gzcch/Bingo.",
        "date": "2023-11-06T17:26:59+00:00",
        "label": 1
    },
    "2303.08774": {
        "title": "GPT-4 Technical Report",
        "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can\naccept image and text inputs and produce text outputs. While less capable than\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance on\nvarious professional and academic benchmarks, including passing a simulated bar\nexam with a score around the top 10% of test takers. GPT-4 is a\nTransformer-based model pre-trained to predict the next token in a document.\nThe post-training alignment process results in improved performance on measures\nof factuality and adherence to desired behavior. A core component of this\nproject was developing infrastructure and optimization methods that behave\npredictably across a wide range of scales. This allowed us to accurately\npredict some aspects of GPT-4's performance based on models trained with no\nmore than 1/1,000th the compute of GPT-4.",
        "date": "2023-03-15T17:15:04+00:00",
        "label": 1
    },
    "2306.00905": {
        "title": "T2IAT: Measuring Valence and Stereotypical Biases in Text-to-Image Generation",
        "abstract": "Warning: This paper contains several contents that may be toxic, harmful, or\noffensive.\n  In the last few years, text-to-image generative models have gained remarkable\nsuccess in generating images with unprecedented quality accompanied by a\nbreakthrough of inference speed. Despite their rapid progress, human biases\nthat manifest in the training examples, particularly with regard to common\nstereotypical biases, like gender and skin tone, still have been found in these\ngenerative models. In this work, we seek to measure more complex human biases\nexist in the task of text-to-image generations. Inspired by the well-known\nImplicit Association Test (IAT) from social psychology, we propose a novel\nText-to-Image Association Test (T2IAT) framework that quantifies the implicit\nstereotypes between concepts and valence, and those in the images. We replicate\nthe previously documented bias tests on generative models, including morally\nneutral tests on flowers and insects as well as demographic stereotypical tests\non diverse social attributes. The results of these experiments demonstrate the\npresence of complex stereotypical behaviors in image generations.",
        "date": "2023-06-01T17:02:51+00:00",
        "label": 1
    },
    "2207.07180": {
        "title": "Contrastive Adapters for Foundation Model Group Robustness",
        "abstract": "While large pretrained foundation models (FMs) have shown remarkable\nzero-shot classification robustness to dataset-level distribution shifts, their\nrobustness to subpopulation or group shifts is relatively underexplored. We\nstudy this problem, and find that FMs such as CLIP may not be robust to various\ngroup shifts. Across 9 robustness benchmarks, zero-shot classification with\ntheir embeddings results in gaps of up to 80.7 percentage points (pp) between\naverage and worst-group accuracy. Unfortunately, existing methods to improve\nrobustness require retraining, which can be prohibitively expensive on large\nfoundation models. We also find that efficient ways to improve model inference\n(e.g., via adapters, lightweight networks with FM embeddings as inputs) do not\nconsistently improve and can sometimes hurt group robustness compared to\nzero-shot (e.g., increasing the accuracy gap by 50.1 pp on CelebA). We thus\ndevelop an adapter training strategy to effectively and efficiently improve FM\ngroup robustness. Our motivating observation is that while poor robustness\nresults from groups in the same class being embedded far apart in the\nfoundation model \"embedding space,\" standard adapter training may not bring\nthese points closer together. We thus propose contrastive adapting, which\ntrains adapters with contrastive learning to bring sample embeddings close to\nboth their ground-truth class embeddings and other sample embeddings in the\nsame class. Across the 9 benchmarks, our approach consistently improves group\nrobustness, raising worst-group accuracy by 8.5 to 56.0 pp over zero-shot. Our\napproach is also efficient, doing so without any FM finetuning and only a fixed\nset of frozen FM embeddings. On benchmarks such as Waterbirds and CelebA, this\nleads to worst-group accuracy comparable to state-of-the-art methods that\nretrain entire models, while only training $\\leq$1% of the model parameters.",
        "date": "2022-07-14T19:40:55+00:00",
        "label": 1
    },
    "1406.2222": {
        "title": "The Chemistry Between High School Students and Computer Science",
        "abstract": "Computer science enrollments have started to rise again, but the percentage\nof women undergraduates in computer science is still low. Some studies indicate\nthis might be due to a lack of awareness of computer science at the high school\nlevel. We present our experiences running a 5-year, high school outreach\nprogram that introduces information about computer science within the context\nof required chemistry courses. We developed interactive worksheets using\nMolecular Workbench that help the students learn chemistry and computer science\nconcepts related to relevant events such as the gulf oil spill. Our evaluation\nof the effectiveness of this approach indicates that the students do become\nmore aware of computer science as a discipline, but system support issues in\nthe classroom can make the approach difficult for teachers and discouraging for\nthe students.",
        "date": "2014-06-09T15:44:41+00:00",
        "label": 0
    },
    "0609110": {
        "title": "Algebraic recognizability of languages",
        "abstract": "Recognizable languages of finite words are part of every computer science\ncursus, and they are routinely described as a cornerstone for applications and\nfor theory. We would like to briefly explore why that is, and how this\nword-related notion extends to more complex models, such as those developed for\nmodeling distributed or timed behaviors.",
        "date": "2006-09-19T15:21:08+00:00",
        "label": 0
    },
    "2109.05433": {
        "title": "Are Gender-Neutral Queries Really Gender-Neutral? Mitigating Gender Bias in Image Search",
        "abstract": "Internet search affects people's cognition of the world, so mitigating biases\nin search results and learning fair models is imperative for social good. We\nstudy a unique gender bias in image search in this work: the search images are\noften gender-imbalanced for gender-neutral natural language queries. We\ndiagnose two typical image search models, the specialized model trained on\nin-domain datasets and the generalized representation model pre-trained on\nmassive image and text data across the internet. Both models suffer from severe\ngender bias. Therefore, we introduce two novel debiasing approaches: an\nin-processing fair sampling method to address the gender imbalance issue for\ntraining models, and a post-processing feature clipping method base on mutual\ninformation to debias multimodal representations of pre-trained models.\nExtensive experiments on MS-COCO and Flickr30K benchmarks show that our methods\nsignificantly reduce the gender bias in image search models.",
        "date": "2021-09-12T04:47:33+00:00",
        "label": 1
    },
    "0706.0484": {
        "title": "Motivation, Design, and Ubiquity: A Discussion of Research Ethics and Computer Science",
        "abstract": "Modern society is permeated with computers, and the software that controls\nthem can have latent, long-term, and immediate effects that reach far beyond\nthe actual users of these systems. This places researchers in Computer Science\nand Software Engineering in a critical position of influence and\nresponsibility, more than any other field because computer systems are vital\nresearch tools for other disciplines. This essay presents several key ethical\nconcerns and responsibilities relating to research in computing. The goal is to\npromote awareness and discussion of ethical issues among computer science\nresearchers. A hypothetical case study is provided, along with questions for\nreflection and discussion.",
        "date": "2007-06-04T17:17:44+00:00",
        "label": 0
    },
    "2307.01952": {
        "title": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis",
        "abstract": "We present SDXL, a latent diffusion model for text-to-image synthesis.\nCompared to previous versions of Stable Diffusion, SDXL leverages a three times\nlarger UNet backbone: The increase of model parameters is mainly due to more\nattention blocks and a larger cross-attention context as SDXL uses a second\ntext encoder. We design multiple novel conditioning schemes and train SDXL on\nmultiple aspect ratios. We also introduce a refinement model which is used to\nimprove the visual fidelity of samples generated by SDXL using a post-hoc\nimage-to-image technique. We demonstrate that SDXL shows drastically improved\nperformance compared the previous versions of Stable Diffusion and achieves\nresults competitive with those of black-box state-of-the-art image generators.\nIn the spirit of promoting open research and fostering transparency in large\nmodel training and evaluation, we provide access to code and model weights at\nhttps://github.com/Stability-AI/generative-models",
        "date": "2023-07-04T23:04:57+00:00",
        "label": 1
    },
    "1103.3321": {
        "title": "Typed Operational Semantics for Dependent Record Types",
        "abstract": "Typed operational semantics is a method developed by H. Goguen to prove\nmeta-theoretic properties of type systems. This paper studies the metatheory of\na type system with dependent record types, using the approach of typed\noperational semantics. In particular, the metatheoretical properties we have\nproved include strong normalisation, Church-Rosser and subject reduction.",
        "date": "2011-03-17T00:19:42+00:00",
        "label": 0
    },
    "1011.1335": {
        "title": "A short proof that adding some permutation rules to $\u03b2$ preserves $SN$",
        "abstract": "I show that, if a term is $SN$ for $\\beta$, it remains $SN$ when some\npermutation rules are added.",
        "date": "2010-11-05T07:54:47+00:00",
        "label": 0
    },
    "2012.04842": {
        "title": "Improving the Fairness of Deep Generative Models without Retraining",
        "abstract": "Generative Adversarial Networks (GANs) advance face synthesis through\nlearning the underlying distribution of observed data. Despite the high-quality\ngenerated faces, some minority groups can be rarely generated from the trained\nmodels due to a biased image generation process. To study the issue, we first\nconduct an empirical study on a pre-trained face synthesis model. We observe\nthat after training the GAN model not only carries the biases in the training\ndata but also amplifies them to some degree in the image generation process. To\nfurther improve the fairness of image generation, we propose an interpretable\nbaseline method to balance the output facial attributes without retraining. The\nproposed method shifts the interpretable semantic distribution in the latent\nspace for a more balanced image generation while preserving the sample\ndiversity. Besides producing more balanced data regarding a particular\nattribute (e.g., race, gender, etc.), our method is generalizable to handle\nmore than one attribute at a time and synthesize samples of fine-grained\nsubgroups. We further show the positive applicability of the balanced data\nsampled from GANs to quantify the biases in other face recognition systems,\nlike commercial face attribute classifiers and face super-resolution\nalgorithms.",
        "date": "2020-12-09T03:20:41+00:00",
        "label": 1
    },
    "1412.7030": {
        "title": "Proceedings of the 7th European Conference on Python in Science (EuroSciPy 2014)",
        "abstract": "These are the proceedings of the 7th European Conference on Python in\nScience, EuroSciPy 2014, that was held in Cambridge, UK (27-30 August 2014).",
        "date": "2014-12-22T15:47:51+00:00",
        "label": 0
    },
    "2002.05658": {
        "title": "Ten Research Challenge Areas in Data Science",
        "abstract": "Although data science builds on knowledge from computer science, mathematics,\nstatistics, and other disciplines, data science is a unique field with many\nmysteries to unlock: challenging scientific questions and pressing questions of\nsocietal importance. This article starts with meta-questions about data science\nas a discipline and then elaborates on ten ideas for the basis of a research\nagenda for data science.",
        "date": "2020-01-27T21:39:57+00:00",
        "label": 0
    },
    "2402.13490": {
        "title": "Contrastive Prompts Improve Disentanglement in Text-to-Image Diffusion Models",
        "abstract": "Text-to-image diffusion models have achieved remarkable performance in image\nsynthesis, while the text interface does not always provide fine-grained\ncontrol over certain image factors. For instance, changing a single token in\nthe text can have unintended effects on the image. This paper shows a simple\nmodification of classifier-free guidance can help disentangle image factors in\ntext-to-image models. The key idea of our method, Contrastive Guidance, is to\ncharacterize an intended factor with two prompts that differ in minimal tokens:\nthe positive prompt describes the image to be synthesized, and the baseline\nprompt serves as a \"baseline\" that disentangles other factors. Contrastive\nGuidance is a general method we illustrate whose benefits in three scenarios:\n(1) to guide domain-specific diffusion models trained on an object class, (2)\nto gain continuous, rig-like controls for text-to-image generation, and (3) to\nimprove the performance of zero-shot image editors.",
        "date": "2024-02-21T03:01:17+00:00",
        "label": 1
    }
}