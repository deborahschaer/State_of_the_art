{
    "2206.08821": "Exploring Web3 From the View of Blockchain\n(Tech Report)\nQin Wang\u22c64, Rujia Li\u22c62,3, Qi Wang2, Shiping Chen4,\nMark Ryan3, Thomas Hardjono1\n1 MIT Connection Science, Massachusetts Institute of Technology, USA\n2 Southern University of Science and Technology, China\n3 University of Birmingham, United Kingdom\n4 CSIRO Data61, Australia\nAbstract. Web3 is the most hyped concept from 2020 to date, greatly\nmotivating the prosperity of the Internet of Value and Metaverse. How-\never, no solid evidence stipulates the exact de\ufb01nition, criterion, or stan-\ndard in the sense of such a buzzword. To \ufb01ll the gap, we aim to clarify\nthe term in this work. We narrow down the connotation of Web3 by sep-\narating it from high-level controversy argues and, instead, focusing on its\nprotocol, architecture, and evaluation from the perspective of blockchain\n\ufb01elds. Speci\ufb01cally, we have identi\ufb01ed all potential architectural design\ntypes and evaluated each of them by employing the scenario-based ar-\nchitecture evaluation method. The evaluation shows that existing appli-\ncations are neither secure nor adoptable as claimed. Meanwhile, we also\ndiscuss opportunities and challenges surrounding the Web3 space and\nanswer several prevailing questions from communities. A primary result\nis that Web3 still relies on traditional internet infrastructure, not as in-\ndependent as advocated. This report, as of June 2022, provides the \ufb01rst\nstrict research on Web3 in the view of blockchain. We hope that this\nwork would provide a guide for the development of future Web3 services.\nKeywords: Blockchain \u00b7 Web3 \u00b7 Internet of Value \u00b7 Architecture\n1\nIntroduction\nWeb3, also known as Web 3.0 or decentralized web, hits the cryptocurrency\nmarkets and blockchain communities from 2020 to date [1][2]. It has become the\nmost prevailing term in the recent period of blockchain prosperity. The concept,\nproposed by Wood [3], promises to provide distributed internet services with-\nout trusted third parties (TTP), thereby o\ufb00ering users more control over their\ndata. The very primary principle shared by Web3 applications is that users can\nhold the data with full control, covering identi\ufb01ers/tokens/ownership/etc., rather\nthan being managed by centralized organizations as in Web1 and Web2 (cf. Ap-\npendix A). With the emphasis on decentralization, Web3 moves data away from\n\u22c6These authors have contributed equally to the work.\nA\ufb03liations are ordered by the text length.\narXiv:2206.08821v1  [cs.CR]  17 Jun 2022\nthese central authorities and establishes applications and services surrounding\nblockchain technologies. Ideally, Web3 developers do not need to build applica-\ntions on top of a single server (processing business logic) or database (storing\nuser data). Instead, Web3 applications are deployed on decentralized networks\nsuch as blockchain platforms or related distributed systems hosted by many\npeer-to-peer (P2P) servers.\nThe conversion from central authorities to the blockchain, more than handing\nover the ownership back to users, brings many non-functional bene\ufb01ts of being (i)\nopen: Web3 data is stored in an open network developed by public communities.\nAlso, Web3 applications are executed in a global view towards the public, making\ndata permanently visible to all the participants; (ii) trustless: a user can build\nconnections or exchange assets to an unfamiliar user without the reliance of\na trusted third party; (iii) permissionless: users\u2019 identities are no longer tied\nto any speci\ufb01c platform and users\u2019 activities are free, which do not need an\nauthorization from a governing entity; (iv) anonymous: users can obtain partial\nanonymity through using multiple pseudonyms or o\ufb00-chain storage; and of (v)\nhigh availability: Web3 provides a high availability architecture, which reduces\nthe probability of the server crash or single point failure; (vi) compatibility:\nDeployed services and applications are not limited in the Ethereum ecosystem,\nbut applicable to all competitive blockchains [4,5] like Avalanche [6], Solana\n[7], Binance Smart Chain [8] or Oasis Network [9], indicating that Web3 can\nintegrate both existing public-chain ecosystems and incoming systems.\nWeb3 also improves user experience in using web stack technologies and thus\npromotes the development of blockchain technologies. Web3 helps to build a\ncomplete user experience that can better serve newcomers. Users, from the cur-\nrent view, only need to connect the wallet to their targeted sites. These sites\ncontain the activities that a user would love to spend time on, which can be\nspeci\ufb01ed in di\ufb00erent types, such as asset swaps (in DEXes [10]), games [11], and\ntrades (of NFTs [12]). Meanwhile, users can obtain a portion of revenues by\nkeeping active in these projects. The contributions are measured in a wide range\ncovering spent time, interactions, deposits, staking, etc. Users can receive fair re-\nwards as well as add more liquidity to the Web3 ecosystem. In this sense, Web3\nhas greatly extended the boundary of blockchain, incentivizing more users to\nparticipate in the games. The evidence is, as in Dec 2021, the total locked value\n(TLV) of Web3-related smart contact contract has reached a peak with 193.14\nbillion USD (more details in Sec.5.1). Such a high capitalization market further\nstimulates the prosperity of techniques surrounding blockchain (cf. Tab.3).\nHowever, despite the fact that Web3 has drawn much attention, clear statements\nof what is Web3 and how Web3 is designed are even absent. Several studies\nprovided their investigation on the consensus level [13] but failed to cover a full\nview of other components and architectural designs that are equally important to\nWeb3. Unclear de\ufb01nitions and non-agreed consensus indicate that Web3 either\nis just a hyped concept without practical development or, has more than one\nsingle direction for the development. In this technical report, we avoid such high-\n2\nlevel discussions, narrowing down the scope to the Web3 architecture and its\nrelation with blockchain. We dig into its building process, investigate its usage\nin existing projects, and deconstruct the protocol into separated components.\nWith this in the arm, we analyze and evaluate state of the art Web3 solutions\nfrom perspectives of their design patterns and properties. We further extend our\nscope to the entire Web3 space (still rooted in blockchains) by discussing their\nimpacts, opportunities, and challenges. To our knowledge, this work provides the\n\ufb01rst in-time study on Web3, reviewing and exploring the wild Web3 solutions.\n- We investigate existing Web3 projects and extract a succinct backbone model\nwith participating roles and operating work\ufb02ow to demonstrate the major\nprocesses. This provides a loose general model for easy adoption, as well as\nhighlights the core steps to establish a Web3 service.\n- We classify a total of twelve architectural designs of Web3 to re\ufb02ect the\noperating mechanism of typical Web3-based applications. We decouple a full\nWeb3 service into three-layered components according to the data work\ufb02ow.\nData in each component can be either operated by the ways of on-chain,\no\ufb00-chain or hybrid. The identi\ufb01ed design types can well present all potential\ncombinations, covering a wide range of Web3 applications and services.\n- We accordingly evaluate each architecture based on di\ufb00erent property met-\nrics that are grabbed from classic blockchain systems. The evaluation anal-\nyses the architectures from multi-dimensional properties (cf. Tab.1) when\nadapting to real applications. We also discuss which participating entity can\ngain the most bene\ufb01ts under di\ufb00erent types. The evaluations directly help\nsoftware architects to evaluate and compare Web3 solutions and further de-\nsign their architectural frameworks.\n- We extend our scope from architectural design to the entire Web3 space by\ndiscussing its impacts, opportunities and challenges to predict the potential\nfuture directions. We show several promising \ufb01elds that may be inspired by\nWeb3-related technologies, and also point out the open challenges needed\nto be addressed in the long term. Meanwhile, based on our analyses and\nevaluations, we answer several questions that are frequently asked by the\ncommunities as our closing results to conclude this work.\n- Further, we provide much more surrounding knowledge that is related to\nWeb3, covering its basic primitives, referenced token standards, and adopted\nprogramming languages. Necessary primitives cover both architectural de-\nsign in conventional web services and layered components in classic blockchain\nsystems. The knowledge lays the foundation of Web3, presenting the common\ncomponents in di\ufb00erent blockchain-based Web3 projects.\nThe rest of this paper is organized as follows. Section 2 presents a typical Web3-\nbased protocol, together with the inducted security model. Section 3 presents\nour architecture extraction and design, as well as gives the criterion used to cap-\nture the features of Web3 related applications. Section 4 details our evaluation\n3\ntowards architectural designs, providing practical adaption under di\ufb00erent sce-\nnarios. Section 5 discuss current impacts, opportunities and challenges. Finally,\nSection 6 gives our closing results and Section 7 concludes this work. Notably,\nwe provide more knowledge of Web3: Appendix A gives fundamental primitives\nsurrounding Web3 and an abstract Web3 work\ufb02ow. Appendix B and C sum-\nmarize existing token standards and EVM-operated programming languages,\nrespectively. Appendix D shows a small corpus of in the wild Web3 projects.\n2\nWeb3 Protocol\nThis section extracts the protocol, security model, and a running example of\nWeb3 systems between user clients and the blockchain infrastructure (together\nwith the protocol work\ufb02ow, referring to Fig.3 in Appendix A.3). Before our\ninvestigation, we clarify the entities that participate in Web3 protocols.\nInvolved Entities. The Web3 protocol mainly consists of three types of roles,\nnamely, the Web3 user, service provider, and the blockchain maintainer. The\nWeb3 user is a data owner who can propose the request by sending a transac-\ntion from the client. The service provider o\ufb00ers the user an on-chain interface\nand the service that can both process the request and interact with blockchain\nplatforms. The blockchain maintainer provides an operating environment for\nsmart contracts that take the task of processing business and data storage.\nGeneral Construction. To launch the Web3 service, a Web3 user needs to\n\ufb01rst establish his distributed identity by creating an address or account on-\nchain at the client. Then, the user login the applications using his address-based\nidentity. Subsequently, the application will interact with the blockchain for data\ncomputation and data storage. Here, we present the detailed protocol.\nIdentity Creation (\u03a01). This algorithm takes as input the security param-\neter \u03ba, and outputs a blockchain address/account addr. The address provides\na public and open-source index that can be associated with an existing iden-\nti\ufb01er. Also, this address is used as an identi\ufb01er for sending or receiving the\ncryptocurrency. It covers three sub algorithms, private key generation, public\nkey generation and address generation.\nsk \u2190KeyGensk(1\u03ba),\npk \u2190KeyGenpk(sk),\naddr \u2190AddressGen(pk).\nThe algorithm is run by a local Web3 client (e.g., client-based wallet, browser\nextension-based wallet). Note that the sub-algorithms KeyGensk, KeyGenpk\nand, AddressGen have di\ufb00erent manifestations. For example, for AddressGen,\nBitcoin addresses use the base-58 encoding1, while Ethereum addresses adopt\nthe base-16 encoding algorithms.\n1 https://tools.ietf.org/id/draft-msporny-base58-01.html\n4\nTransaction Generation (\u03a02). This algorithm takes as input the user\u2019s\nprivate key sk, the transaction metadata, the transaction payload, and ac-\ncordingly outputs an enveloped transaction Tx.\nsig \u2190Sign(sk, metadata, payload),\nTx \u2190TranGen(sig, metadata, payload).\nThis algorithm is run by a Web3 client that receives the request from users. sk\nis used to generate a signature. metadata refers to transaction-related data,\nsuch as the transaction receiver and transaction nonce. payload points to the\ncontract method to be involved and the data to be stored.\nContract Execution (\u03a03). This algorithm takes as input the transaction Tx,\nand current state s, and smart contract contract, and accordingly outputs the\ntransferred state s.\ns \u2190ContractExec(s, Tx, contract).\nThis algorithm is run by the blockchain maintainers in the network. The\ntransited state s includes a reward or payment used to incentive the participat-\ning nodes. The contract contract contains the logic of upper-layer applications,\nwhich de\ufb01nes how the state changes happening on the blockchain.\nState Consensus (\u03a04). This algorithm takes as input the transaction Tx, the\nsmart contract contract and the current state s to be transited, and outputs\nthe con\ufb01rmed state s\u2032, and the con\ufb01rmed transaction Tx\u2032.\n(s\u2032, Tx\u2032) \u2190Consensus(s, Tx, contract).\nThis algorithm is run by blockchain maintainers. The term con\ufb01rmed indi-\ncates that the proposed block (containing s and Tx) has been agreed upon by\nsu\ufb03cient maintainers in the network. The threshold of con\ufb01rmation depends\non speci\ufb01c algorithms (e.g., 51% in PoW [14], 2/3 in BFT algorithms [15]).\nState Retrieval (\u03a05). This algorithm takes as input the user\u2019s address addr\nand outputs the transaction Tx\u2032\u2032 and the related state s\u2032\u2032.\n(s\u2032\u2032, Tx\u2032\u2032) \u2190Retrieval(addr, contract).\nThis algorithm is run by a Web3 client who aims to retrieve the state.\nSecure Web3 Protocols. Based on the extracted general construction, a secure\nWeb3 protocol is informally de\ufb01ned as follows.\nDe\ufb01nition 1 (Secure Web3 Protocol) A Web3 scheme S is secure, if for all\nblockchain address addr and the initial state s outputted from Phase \u03a01 to Phase\n\u03a05, it holds that,\n5\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8f0\nsig \u2190Sign(sk, metadata, payload)\nTx \u2190TranGen(sig, metadata, payload)\ns \u2190ContractExec(s, Tx, contract)\n(s\u2032, Tx\u2032) \u2190Consensus(s, Tx, contract)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fb\u21d2(s\u2032, Tx\u2032)\n\u0002(s\u2032\u2032, Tx\u2032\u2032) \u2190Retrieval(addr, contract)\u0003\n\u21d2(s\u2032\u2032, Tx\u2032\u2032)\nwhere the output satis\ufb01es:\n(s\u2032, Tx\u2032) = (s\u2032\u2032, Tx\u2032\u2032)\nThe de\ufb01nition states that a Web3 protocol is deemed to be secure if a user can\nsuccessfully retrieve the correct state and transaction on the blockchain at any\ntime after the block con\ufb01rmation. Our security model is based on the assump-\ntion of a robust blockchain [16] and the corresponding security is guaranteed\nby persistence and liveness [17]. The persistence means whether di\ufb00erent nodes\nhave the same view at a speci\ufb01c height of blocks, while the liveness focuses on\nwhether a block can be eventually buried deep enough (without the possibil-\nity of being reversed) in the valid longest chain. We omit other types of chain\nstructure, such as the directed acyclic graph (DAG) [18].\nFig. 1: An Instance of Web3 User Case\nA Running Example. We provide an instance to describe how a Web3 sys-\ntem works. The case is straightforward: assume that a user wants to sell his\nself-created NFT painting on-chain (cf. Fig.1). Firstly, he needs to connect his\nwallet to the related website and send the request to mint an NFT on his targeted\nblockchain platforms [12]. The action of mint requires invoking APIs that en-\nable interactions with smart contracts. The contract is executed according to its\nprede\ufb01ned speci\ufb01cations and token standards (ERC721, see details in Appendix\nB). After processing the logic, the raw picture is stored in an external decen-\ntralized storage network, e.g., IPFS [19], due to its high-resolution format. IPFS\n6\nseparates the raw data into pieces and distributes them into di\ufb00erent nodes,\nlabelling each of them with a content identi\ufb01er (CID). The returned identi\ufb01ers\nare recorded on-chain for further queries from users. Once completing the entire\nlogic, the seller can trace the transaction and his NFT on the blockchain. The\nbuyer with willingness can buy the seller\u2019s NFT on Opensea [20], and pay the\nprices as stated. The ownership of this NFT will be automatically transferred to\nthe buyer once completing the payments.\n3\nArchitectural Design\nThe architecture is the foundation of software systems. It de\ufb01nes the system\nstructure and external-world interface via underlying components and their re-\nlationship. This section provides our architectural design for Web3 systems.\n3.1\nDesign Principle\nWe stay aligned with the mainstream recognition of Web3 and accordingly struc-\nture our report by progressively presenting the ways to build a Web3 service and\nthe featured properties in di\ufb00erent designs. Based on plenty of investigation to-\nwards in the wild Web3 projects, we classify them into a compact framework (cf.\nFig.2), which thus allows the audience to explore the conceptual design space\nand evaluate di\ufb00erent design options.\nSpeci\ufb01cally, we delineate two basic axes, namely, decoupled component and tech-\nnical route, to explore the subtle di\ufb00erences in each cross from orthogonal di-\nrections. For the former, we abstract three critical components, including client,\ncompuation and storage, as our characterisation. Our decoupling is based on the\ndata work\ufb02ow, which contains three corresponding phases (A-C in Fig.2), data\naccess, data computation and data storage, to describe how data transfers under\na normal operating logic. For the latter, we extract three technical routes of im-\nplementing a blockchain system: on-chain processing, o\ufb00-chain processing, and\ntheir combinations (hybrid).\nBy interweaving two axes, we can \ufb01nd that each component can be categorized\ninto sub-items according to its on-chain/o\ufb00-chain processing route. Based on\nthat, we identify a total of twelve types of architectural designs to show di\ufb00erent\npurposes and usages among a large bunch of projects. Moreover, we capture\nseveral essential properties that are frequently mentioned in classic blockchain\nsystems to evaluate the proposed design types. This framework captures major\narchitectural characteristics and related properties of each type, helping Web3\nusers and software architects to choose the proper design for their products. We\ngive the detailed de\ufb01nitions of each item as follows.\n3.2\nDecoupled Components\nWe \ufb01rst investigate how data \ufb02ows from a user to its backend server. In such\na procedure, we have totally extracted three major processes to normal system\n7\nFig. 2: Framework. We have \ufb01rst identi\ufb01ed three major components according\nto the data work\ufb02ow: access, computation, and storage (cf. left Square). Then,\nwe extract three technical routes that re\ufb02ect the ways of data processing in\nblockchain systems: on-chain, o\ufb00-chain, and hybrid (medium Square). Based on\nthe two principal dimensions, we summarise a total of 12 types of potential Web3\narchitectural designs (bottom Square). With this in the arm, we analyze every\ntype in terms of di\ufb00erent property metrics (right Square) and point out design\ntrade-o\ufb00s. Notably, we also provide a guide map by using blue dotted line.\noperations: data access, data computation and data storage. Such procedures\ndescribe a typical work\ufb02ow of blockchain systems.\n- Data Access. To start a Web3 service, a user \ufb01rst needs to send his request\nthrough a client. Typically, the request is formatted as a transaction, and\naccordingly, the client is instantiated as a wallet1. Users enter the network\nby connecting their wallets to a speci\ufb01c website.\n- Data Computation. After a successful connection, the requests from users\nare parsed into di\ufb00erent pieces of logic, being transmitted into backend\nblockchain platforms. Blockchain operates the logic and decoded methods\nvia smart contracts according to their prede\ufb01ned speci\ufb01cations.\n- Data Storage. The executed data, at last, should be permanent storage.\nIn normal cases, small size data can be directly recorded inside transactions,\nwhereas in some cases, large-scale data requires external storage. The key\nto maintaining the data integrity in o\ufb00-chain storage is to add a hook that\nconnects the on-chain (such as a hash) and o\ufb00-chain data.\n1 We omit the sub-categories of di\ufb00erent wallet types, such as whether utilizing SPV\nor hardware. More details refer to [21][22].\n8\nThen, based on descriptions of data \ufb02ow, we abstract three fundamental compo-\nnents in a full-functional Web3 service by decoupling existing solutions. Merging\nwith our di\ufb00erent data processing routes, we categorize the decoupled compo-\nnent with on-chain, o\ufb00-chain and hybrid options (selected by two or all of them).\nWe give their de\ufb01nitions as follows (and more details in Sec.7). To be noted, as\nWeb3 is featured by decentralization, at least one of the components should be\noperated on-chain, where no gatekeeper can fully control the network.\nClient. Clients are used to receiving requests from users. Classic blockchain\nsystems, on a small scale of requests, can use a single browser as the client to\nconnect with the wallet. However, if the request sharply increases within a short\ntime frame, an agent is required to process an instantaneous \ufb02ow of requests.\n- Browser-based Wallet. A browser-based wallet is an intuitive solution for\nusers to adopt the Web3 service. Users only need to install an extension tool\nin the browser and import their private key to this embedded wallet. When\nbrowsing a Web3-supported website, users can directly put the button of\nconnect the wallet, and all the clicked functions in this website will invoke\nthe backend methods through APIs under the user\u2019s account.\n- Agent-based Wallet. An agent solution is to enable batch processing when\nconfronting a high-density situation of requests from users. Similar to tra-\nditional Web1/Web2, users should \ufb01rst grant a trusted agent with proper\npermission. The authentication procedure is executed once users have for-\nmally started to register with the agents.\nComputation. Operating a Web3 service built on smart contracts requires great\ncomputing power as the running environment. Purely on-chain computation is\ninstant but costly. A hybrid computation that moves partial computational tasks\no\ufb00-chain is another solution.\n- Contract-based Computation. All the computations are performed on-\nchain through smart contracts. Here, variables in smart contracts are allowed\nto be revoked and modi\ufb01ed based on the prede\ufb01ned contract instructions.\n- Hybrid Computation. A partial proportion of computations are executed\non-chain, while the rest of the computations o\ufb00-chain. Generally, veri\ufb01ca-\ntion mechanisms are required in this method in order to guarantee integrity\nbetween on-chain and o\ufb00-chain data.\nStorage. Similar to any services applied to Web1/Web2, applications and ser-\nvices in Web3 also require enough space for storage. Data in small size, such\nas ordinary transaction payload, can be stored directly on-chain. In contrast,\nfor the large size, or complicatedly formatted data, like streaming video or raw\naudio, it should be (partially) stored to external deceives or providers. In this\nsense, we summarize three types of data storage.\n- On-chain Storage. All the data is stored on-chain, as a state of the smart\ncontract. Any changes will be publicly recorded and can be veri\ufb01ed by the\n9\nentire network. Theoretically, this is the best way to prevent malicious nodes\nfrom destroying data due to its total transparency and accountability.\n- O\ufb00-chain Storage. It refers to storing data in o\ufb00-chain networks where\nonly the hash roots are recorded online (e.g., IPFS [19] or Swarm [23]).\nThe solution requires an additional process for veri\ufb01cation, such as proof-of-\nexistence, to prove data integrity.\n- Hybrid Storage. This is a mixed way that combines both on-chain and o\ufb00-\nchain storage, which means storing raw data o\ufb00-chain (like video and audio)\nand light metadata (such as account history and certi\ufb01cates) on-chain. The\nproportion of these solutions is adjusted according to speci\ufb01c scenarios.\n3.3\nArchitectural Designs\nWe have identi\ufb01ed totally twelve types of architectural designs towards Web3\nservices (cf. Architectural Type 1 \u221212 in Fig.2). Speci\ufb01cally, we denote each\ndesign with Type, and it is made up by a three-element tuple (Aa, Bb, Cc) where\na, b \u2208{1, 2}, and c \u2208{1, 2, 3}. Here, the elements A, B, C separately specify\nthe components of client, computation and storage, while the subscripts 1, 2, 3,\nrespectively, represent on-chain, hybrid and o\ufb00-chain as de\ufb01ned before. Based on\ndi\ufb00erent combinations, we provide the potential architectural designs as follows.\n- Type1 (A1, B1, C1), Type2 (A1, B1, C2), Type3 (A1, B1, C3), which are shown\nin the black line at the left square in Fig.2;\n- Type4 (A1, B2, C1), Type5 (A1, B2, C2), Type6 (A1, B2, C3) (brown line);\n- Type7 (A2, B1, C1), Type8 (A2, B1, C2), Type9 (A2, B1, C3) (blue line);\n- Type10 (A2, B2, C1), Type11 (A2, B2, C2), Type12 (A2, B2, C3) (teal line).\nIn each design type, smart contracts play the most essential role in entire ser-\nvices that are responsible for on-chain calculations. Type1 is the most simpli\ufb01ed\narchitectural design amongst those combinations. A typical instance is known as\ntoday\u2019s Ethereum platform. To \ufb01t for more complicated cases, external resources\nshould be equipped to the system design, such as the agent in Type7-12 or the\no\ufb00-chain storage in Type2/3. Notably, the running NFT example in Sec.2 is a\nbased on the Type2 design.\n4\nArchitecture Evaluation\nIn this section, we present the evaluation criteria and evaluate each type of\narchitecture. Our evaluation covers the properties that are summarized from\nclassic blockchain systems and bene\ufb01ts to di\ufb00erent participating parties.\n10\n4.1\nEvaluation Criteria\nIn the past decades, many evaluation frameworks have been proposed. Among\nthem, the architecture trade-o\ufb00analysis method (ATAM) [24] is a well-known\none. We partially adopt ATAM to assess the Web3 architecture, integrating with\nthe blockchain properties and bene\ufb01cial parties. In particular, we \ufb01rst select a\nconcrete scenario, re\ufb01ne quality attributes into this scenario, and then present\npotential concerns related to the quality requirement.\nATAM Method. The architecture trade-o\ufb00analysis method is initially used in\nsoftware development to recommend the most suitable architecture for a speci\ufb01c\nsystem. The method majorly discusses the trade-o\ufb00s between di\ufb00erent design\ntypes and their sensitivity points for risk mitigation. A classic ATAM process\nconsists of three critical aspects: extract quality attributes, identify bene\ufb01cial\nparties, and analyse in speci\ufb01c scenarios. Quality attributes are non-functional\nrequirements to specify how well software should be done. In the context of\nWeb3, we adopt the properties extracted from classic blockchain systems as\nquality attributes. Then, we analyse the system entities regarding their potential\nbene\ufb01ts and losses. Meanwhile, we still use a similar NFT instance (compared\nto the running example in Sec.2) as our analysed scenario.\nProperty Metrics. We capture several major properties that are used to eval-\nuate classic blockchain systems. These metrics depict the architecture from mul-\ntiple dimensions, and we summarize them as follows.\n- Performance. Performance is used to show the maximum rate of con\ufb01rmed\ntransactions during a speci\ufb01ed duration. In the context of blockchain, per-\nformance is measured by transaction per second (TPS), which is a widely\nadopted way to describe the throughput of a system.\n- Scalability. Scalability refers to the ability to process transactions along with\nthe increased scale of networks, which is re\ufb02ected by the increase or decrease\nin its performance (measured in transaction per second\u2013TPS).\n- Cost. Each transaction in VM-engined blockchain platforms requires certain\ntransaction fees. This is necessary because a total zero friction (free of fees)\nwill result in a loop logic error [25] in smart contract operations.\n- Security. Security is a broad term. We limit the scope of security to data-\nlevel security. The data should be protected for its integrity and prevented\nfrom unauthorized access or faking, or compromising.\n- Anonymity. Anonymity refers to hiding the identities of acting persons.\nIn the context of blockchain, anonymity mainly indicates utilizing crypto-\ngraphic schemes to break the linkage between physical entities with virtual\npublic addresses [26]. An adversary cannot learn useful information about\nany speci\ufb01c parties related to the on-chain assets.\n- Con\ufb01dentiality. Con\ufb01dentiality refers to hiding the sensitive data that is\npresented on transactions, including their asset values, useful information in\n11\npayloads, or contract states. Con\ufb01dentiality focuses on states rather than\nentities. Notably, privacy covers both anonymity and con\ufb01dentiality, where\nan adversary cannot learn any useful knowledge from public transactions.\n- Availability. Availability is used to measure the probability of a system run-\nning abnormally with the existence of potential failure. It indicates the sta-\nbility of a blockchain system.\n- Usability. Usability in the context of Web3 follows the same connotation as\nthe general computer system, which measures the satisfaction of a speci\ufb01c\nuser in a speci\ufb01c context when using a speci\ufb01c product.\nStakeholders. A major task in ATAM evaluation is to analyse a system\u2019s ca-\npability for satisfying the stakeholder requirements [27]. The stakeholders in the\ncontext of our Web3-based evaluation indicate the potential bene\ufb01cial parties\nin the system, being aligned with involved entities stated in Sec.2, rather than\nthe person holding assets in proof of stake (PoS) protocols [28]. Three main\nstakeholders are identi\ufb01ed as our evaluation target.\n- Web3 user. A Web3 user is an entity that owns the data. Also, the user is\nan entity to initiate transactions. The user should accordingly obtain a fair\nproportion of rewards in the forms such as tokens, badger, etc.\n- Service provider. An application owner uses blockchain to provide publicly\naccessible services for users. The service provider may obtain revenues from\nboth sides: user payments and blockchain platform rewards.\n- Blockchain maintainer. Blockchain maintainer provides a running environ-\nment for executing the smart contract and storing the blockchain data. The\nmain reward for maintainers comes from the cryptocurrency rewards.\n4.2\nArchitecture Evaluation\nThen, we start to evaluate each architectural design. We give a speci\ufb01c sce-\nnario to narrow down the scope of the high-level description and analyze each\narchitecture regarding its properties and stakeholders.\nScenario. Non-Fungible Token [12] is a blockchain-based cryptocurrency that\nallows proving the ownership. In our scenario, an NFT designer, Alice, wants to\nsell her NFT to Bob by paying cryptocurrencies. Even though this application\nfocuses on a speci\ufb01c domain, we argue that the core requirements are likely to\nstand across di\ufb00erent Web3 applications. We apply di\ufb00erent architectures to\nthis scenario, discussing both advantages/disadvantages and trade-o\ufb00s, to help\ninterested readers consider their \ufb01nal decisions on Web3 architectures.\nA1: An Ideal Web3 Architecture. An ideal Web3 infrastructure should elim-\ninate all the middle man, without centralized databases or computation devices.\nThe blockchain provides a decentralized platform for data computation and stor-\nage while bringing a native token-based economy. Under this architecture, Alice\n12\nuploads the raw NFT data, the price information, and NFT auxiliary informa-\ntion to a blockchain-based smart contract through a wallet. Then, the blockchain\nnodes reach an agreement on the data. Next, Bob sends a transaction to invoke\nthe contract for buying NFT. Finally, the NFT ownership transfers to Bob, and\nAlice obtains the payments. The architecture puts all the computation and stor-\nage on the blockchain, bringing security and availability for Web3 users. The\nblockchain operates on a collection of decentralized nodes, which guarantees\nthe availability of on-chain data. Meanwhile, once blockchain nodes reach an\nagreement for the received transactions, data becomes immutable. The related\narchitectural design in Sec.3 is Type1.\nHowever, this architecture confronts some drawbacks, which mainly center around\nbeing impractical when adapting to today\u2019s Web3 infrastructure. Firstly, upload-\ning and replicating the data to all blockchain nodes in a peer-to-peer network\nis time-consuming. Website interactions are slower where the back-ended state\ntransitions need con\ufb01rmation and propagation throughout the network. Mean-\nwhile, scalability is a long-term issue existing in blockchain systems due to in-\ntrinsic decentralization. The architecture is closely integrated with underpinned\nblockchain systems, which, as a result, will face a similar issue. Moreover, the\ncomputation and storage in the blockchain are expensive regarding monetary\ncosts. Worse still, the fees increase with the growing size of payload data.\nBeyond that, this architecture raises problems about data privacy. On the one\nhand, the code and state of smart contracts are transparent by default. Any\nchanges in the contracts are immediately visible, not just to the blockchain nodes\nbut also to anyone outside blockchains. The over-publicity issue hinders the de-\nvelopment of Web3 applications, making them hard to be adopted for privacy-\ncritical applications. On the other hand, users\u2019 identities lack anonymity. With-\nout an explicit approach taken to protect the user\u2019s addresses, virtual addresses\non blockchains and physical identities are linkable with the help of analytical\ntools and big data, even if users can use multiple pseudonyms.\nA2: Agent-login Architecture. The ideal Web3 solutions, singly relying on\nthe original blockchain technology, confront the issues of poor scalability and\nhigh cost. These shortcomings force the user to adopt the alternatively central-\nized computation or storage outside the blockchain. We gradually proceed from\nlayer to layer. Firstly, we address the congestion issue at the access layer. The\nagent-login design provides a scalable approach to handling many transactions\nby merging multiple executions. A group of users can access the blockchain plat-\nform with one agent account. In particular, in our scenario, multiple NFT-selling\nand buying transactions are bundled into one transaction. An agent anchors\nthis transaction to the blockchain later for the \ufb01nal agreement. Centralized ex-\nchanges, such as Coinbase [29] or Binance [30], act as agents similar to this\ndesign. Many Web3 participants rely on custodial wallets for easy access and\nmanagement. This architecture can concurrently process transactions without\nwaiting for the blockchain\u2019s con\ufb01rmation, which brings high performance, good\nscalability, and low cost. The related architectural designs include Type7-9. The\n13\nmain drawback of this solution is centralization, which may cause unnecessary\nissues. For example, a malicious agent may hide the user\u2019s transactions without\nsending them to the blockchain. Worse still, such action is hard to trace due to\nthe lack of transparent evidence.\nTable 1: Web Architecture Evaluation\nProperty\nStakeholders\nArchitecture\nPerformance\nScalability\nGas Cost\nSecurity\nAnonymity\nCon\ufb01dentiality\nAvailability\nUsability\nWeb3 User\nService Provider\nBC Maintainer\nA1,B1,C1\u2013Type1\nA1, B1, C2/3\u2013Type2/3\n+\n-\n-\nA1,B2,C1\u2013Type4\n+\n-\n-\nA1,B2,C2/3\u2013Type5/6\n++\n- -\n- -\nA2,B1,C1\u2013Type7\n+\n-\n-\nA2,B1,C2/3\u2013Type8/9\n++\n- -\n- -\nA2,B2,C1\u2013Type10\n++\n- -\n- -\nA2,B2,C2/3\u2013Type11/12\n+++\n- - -\n- - -\nBaseline,\nProperty enhance,\nProperty decrease; (Compared to Type1)\nA3: Hybrid Computation Architecture. This architecture shares the same\nwork\ufb02ow with A1 and A2. As discussed, on-chain computations are both time-\nconsuming and money-consuming. Hybrid computation architecture solves this\nissue by bringing TTP with high computation capabilities. These TTPs process\nthe data o\ufb00-chain, and merely put a few computation tasks on the blockchain.\nIn our example, the on-chain computation tasks may cover the token payment\nand NFT the ownership transfer. This design improves user usability because\no\ufb00-chain computations have better performance and scalability. The related ar-\nchitectural designs include Type4-6. However, it still assumes that the TTP\nwho provides computation power is honest. A TTP in the real world may act\nmaliciously or fail to provide computations due to hidden interests or being\ncompromised. Again, such malicious computations are hard to be detected.\nA4: Hybrid Storage Architecture. This architecture stores the raw data o\ufb00-\nchain while the data pointer is stored on the blockchain system. In our example,\nonly NFT identi\ufb01ers and payment information are stored on-chain, while the\nraw NFT data is stored o\ufb00-chain. Correspondingly, in the real world, most NFT\nartists rely on centralized platforms like OpenSea [20], or Solanart [31] to store\nthe raw NFT data. In this architecture, the choice of how to store o\ufb00-chain\ndata and how to reveal the contents of their o\ufb00-chain data are left to users,\nwhich brings certain privacy and over-publicity issues. Meanwhile, the architec-\n14\nture improves the performance and saves the cost. Due to these bene\ufb01ts, the\ndesign has been widely adopted by some storage-intensive applications, such as\nblockchain-based streaming media, such as Theta [32], Audius [33] and Livepeer\n[34], which depends on the combination of on-chain storage and o\ufb00-chain storage.\nThe related architectural designs include Type10-12.\nHowever, the solution is partially centralized with the risk of single point failures.\nIn particular, the o\ufb00-chain storage is controlled by a TTP. Any services built\non top of this type can only be processed when a TTP is available, making the\ndata access to relevant information becomes a privilege. Fortunately, some stor-\nage systems rely on replication to back up \ufb01les for data integrity. For example,\nStorj [35] utilizes the proof-of-redundancy mechanism, where every \ufb01le is stored\nin at least three locations to avoid \ufb01les being destroyed. The system operates\non the Ethereum platform and stores the metadata in Satoshi format. Similarly,\nSia [36] is a distributed storage system that relies on storage proofs. These proofs\nconsist of a list of publicly veri\ufb01able root hashes from the submitted \ufb01le and a\nfraction of the original \ufb01le, and users can verify them easily from on-chain data.\nInterPlanetary File System (IPFS) [37], with more complicated proof mecha-\nnisms, establishes a fully distributed peer-to-peer \ufb01le system. Leveraging proof\nof time/space, IPFS ensures data integrity from both time and space.\nStatistical Results. The investigation tries to answer the question which ar-\nchitectural design is the most prevailing? Existing Web3 projects are designed\nbased on di\ufb00erent scenarios. Accordingly, their solutions target di\ufb00erent compo-\nnents. We expand our research from mature systems (ranked in the market) as\nwell as newly released whitepapers that claim to launch the projects. Based on\nour investigation (inevitably select examples in a small corpus from the entire\nproject pool), we \ufb01nd that most of the teams adopt the Type1 (A1, B1, C1) de-\nsign with a straightforward blockchain-based architecture. These projects either\nput focuses on merely one functionality, such as setting connections from Web2\nto Web3 [38], building decentralized identities [39,40], or implement the very ba-\nsic infrastructure [41,42,43] that can better serve existing blockchain ecosystems.\nAbove reasons made us to select Type1 as the baseline. For other types, we can\nobserve that the options of external techniques are insu\ufb03cient. For instance, if a\nproject aims to move the storage o\ufb00-chain, the options are limited to IPFS [19],\nwhich has been implemented for years with comprehensive instructions and user\nguides. A\ufb00ected by little attention to external technologies, other design types\n(even the sum of the rest ones) only occupy a small share of the entire picture.\nA Concise Summary. As shown in Tab.1, we provide detailed evaluations of\neach architectural design. Adding auxiliary techniques (agent, o\ufb00-chain compu-\ntation, o\ufb00-chain storage) will impact the properties from di\ufb00erent sides. Posi-\ntively, performance, scalability, gas cost, and usability can get improved at dif-\nferent levels depending on how many layers have been modi\ufb01ed. This is because\nexternal techniques can support much more volume of data and participating\nparties. From the view of single users, they can obtain better services due to\nfaster transaction processing time and cheaper gas costs. In contrast, negatively,\n15\nsecurity, anonymity, and availability have decreased, compared to the baseline\n(Type1), due to the in-transparency of o\ufb00-chain processing procedures. Here,\nthe singly applied agent at the client component will not a\ufb00ect the anonymity\nbecause either personal address or custodian addresses are equivalent towards\nadversaries. Similarly, con\ufb01dentiality, security, and availability are majorly vul-\nnerable at the computation and storage components, with little relation to the\naccess component. Finally, for stakeholders, we can observe that Web3 users can\nobtain bene\ufb01ts that are consistent with previous reasons (better service). In op-\nposite, both service providers and blockchain maintainers are disadvantageous\nsince the managing costs accordingly increase.\n5\nExtending to the Web3 Space\nIn this section, we extend our scope from architectures to the entire Web3 space.\nWe present the Web3 impacts to current markets. Then, we point out the promis-\ning research directions as well as potential barriers on the road.\n5.1\nWeb3 Impacts\nWe \ufb01rst discuss the impacts of current Web3 projects. We approach it from two\nsides. The one is to estimate their in\ufb02uenced market value, while the other one\nis to see the scale of Web3 applications or services. We give details as follows.\nValue Estimation. Supported by mainstream blockchain platforms, Web3 has\ngained an unexpected breakout. Measuring the quantitative impact is impracti-\ncal due to its generality and vague bounder. No statistical data can be directly\nused by di\ufb00erent institutions. But we still \ufb01nd indirect ways to re\ufb02ect its in\ufb02u-\nence. The \ufb01rst way is to investigate the usage of smart contract languages. This\nis because building a Web3 DApp requires de\ufb01ning logic and functions (e.g.,\nownership/transfer/connect) through these languages due to its close relation\nwith user interfaces. The total value locked (TLV) by smart contract languages\nreaches up to maximally 193.14 billion USD (as of Dec, 2021)1. However, these\nlanguages only show a partial picture of the entire Web3 ecosystem, while many\ncompetitive programming languages are proposed following the same targets (cf.\nAppendix C). The real impact of Web3 will greatly outpace the stated data singly\nobserved from languages. Another way to re\ufb02ect the popularity of Web3 appli-\ncations is based on fundamental index methodology [44] that covers di\ufb00erent\ntypes of underlying valuation \ufb01gures such as users\u2019 paid fees on applications and\nindividual votes for proposals. Fees, in this track, are di\ufb00erent from transaction\n1 The TLV of $251.877b is made up by $193.14b from Solidy (76.68%), $28.19b from\nRust (11.19%), $27.56b from Vyper 10.94%, $1.57b from Ride (0.62%), $1.07b from\nCairo (0.42%), $193.47m Bitcoin Script, $152.45m from C#, $3.69m from Python.\nAmong them, Solidity still occupies the largest proportion, indicating that Ethereum\nand EVM-compatible platforms play the most important role in the Web3 area. [Data\nsource: https://de\ufb01llama.com/languages].\n16\nfees paid to miners in Ethereum. Instead, they are used to represent the cost that\npeople are willing to spend on related decentralized services. For instance, users\nhave spent 253, 015 USD (per 30 days) on Arweave [45] which is used to query\nor store data on the network. It provides an estimator of a network\u2019s value and\nactivities by an in-time track from the view of the demand-side, which provides\na distinguished way of investigating the status of the Web3 market.\nPractical Development. Besides its high values, Web3 DApps have promoted\na rapid evolution towards a wide variety of scenarios. A promising paradigm\nshift is to move the centralized authority from trusted third parties (TTP) to\ndistributed participants, which is also known as the Decentralized Autonomous\nOrganization (DAO). DAO removes the formal management roles (e.g., dele-\ngated authorities) and physical entities (company/o\ufb03ce) [46], by instead a suite\nof contracts residing on the Ethereum blockchain. DAOs have been adopted with\nmany instances like Aragon [47] and MetaCartel [48]. Another signi\ufb01cant shift\nlies in their way of authenticating identities. Unlike asking for sensitive infor-\nmation through methods of email+password or OAuth in traditional networks,\nidentities in Web3 applications are replaced by anonymous addresses, where the\nweb establisher cannot obtain any useful knowledge of their users. The design\nfurther stimulates the widespread of decentralized identi\ufb01ers (DIDs) [49]. Users\ncan fully control assets and metadata under their DIDs, and optionally release\nthem to service providers by personal preferences. Moreover, Web3 also instimu-\nlates the prosperity of development tools and supplementary suites surrounding\nblockchain technologies. These tools cover APIs, statistic indicators (The Graph\n[50]), distributed storage (Sia [51], Arweave [45]), edge computing (Helium [52]),\netc. They ful\ufb01ll the blank left from previously isolated components, enabling\nthem to seamlessly integrate together and well support each other. We further\nprovide a look into Web3 applications that are stated in Tab.3 in Appendix D.\nUnfortunately, constrained by our bandwidth, we only select a small group of\nWeb3 projects to demonstrate its wide adoption in this report.\n5.2\nNew Paradigm\nWe then discuss the forthcoming wave of Web3 that goes beyond the initial\nuse case like cryptocurrencies. Web3 can promote technical integration across\ndi\ufb00erent domains, ranging from establishing decentralized self-governance orga-\nnizations to facilitating the progress of DeFi and Metaverse.\nTechnical Integration. Web3 is a novel approach to delivering internet archi-\ntecture in a decentralized way. As discussed, Web3 covers every layer of the web\narchitecture, from the front-end to the back-end. It indicates that technical inte-\ngration may occur in multiple areas. For instance, Theta Labs\u2019 [32] decentralized\nvideo solution aims to stream video on Web3 via customized APIs. Audius [33]\nis a music sharing platform with the target to decrease the dependency on a\nrecord label. Radicle [53] is an open-source and distributed platform for code\ncollaboration. Arweave [45] and Sia [51], similar to IPFS [19], are to establish a\n17\ndecentralized storage network that allows users to store data. Deeper Network\n[54] intends to build a hardware-powered VPN ecosystem. All these attempts\nto modify, integrate and improve the existing infrastructure from centralized\nnetworks are promising, providing educational experiences on both success path\nand failure cases for the following developers.\nDistributed Autonomous Organization (DAO). Web3 will signi\ufb01cantly\npromote the development of current distributed autonomous organizations. Uti-\nlizing a suite of smart contracts improves reliability, as no powerful authorities\ncan break the rules. DAOs run on a \ufb02attened hierarchy where each participant\nhas the right to vote on speci\ufb01c issues, similar to the way in a conventional execu-\ntive board. All the processes, including decision-making, token issuing, option se-\nlecting and voting, are transparent due to the on-chain settings. This means any-\none, either internally or externally, could audit the code, which greatly improves\naccountability and reliability and avoids misdirecting usage of funds collected\nfrom investors and users. To achieve decentralized governance, every project can\nissue its speci\ufb01ed votes (or tokens) that stakeholders can put their preferences\non. For instance, Yearn [55] allows users to participate in decision-making and\nvoting on proposals. Radicle [53], as a decentralized GitHub alternative, grants\nstakeholders the right to manage the project. Similarly, many DeFi protocols,\nincluding Uniswap [56], The Graph [50], SuperRare [57], and Audius [33], enable\nownership, participation, and governance via their issued tokens. All these votes\nand tokens require a Web3 DApp to get interacted with di\ufb00erent DAO partici-\npants. Also, long-existing DAOs, such as MakerDAO [58], have attracted many\ndevelopers contributing to crypto-space and Web3 ecosystems. In this sense,\nDAO has extended the scope of decentralization, which was previously bound\nto machines, to a broader area that involves human beings. The shift of how to\noperate a digital organization would pose a great impact on the future world,\nmore than they are presented today.\nSelf Governance. Initially, software companies in Web1/Web2 obey the rule\nof protecting data, with a simple aim to involve more users for growth. But\neventually, they have to start turning pro\ufb01ts by selling or manipulating users\u2019\ndata, such as training AI models to make better recommendations. Users have\nno choice, facing the dilemma between privacy and convenience. In contrast,\nindividuals in the Web3 space can hold as much personal data, which is more\nthan ever before. Together with DiDs, users can freely browse the internet as\nwell as perceive their data without compromising its privacy. Many solutions,\nlike Ceramic [40] and IDX [39], replace traditional authentication by allowing\nusers to build self-sovereign identities. The Ethereum foundation makes much\nmore progress by drafting an RFP [59] for de\ufb01ning a formal speci\ufb01cation. By\ncontrolling data and assets, an individual can even earn pro\ufb01ts through incentive\nmechanisms. This is practically important for building a sustainable ecosystem\nthat encourages users to continuously contribute to the required infrastructure.\nDeFi. This is an intuitive application of Web3 as all the assets held by users\nare stored in their wallets. Performing \ufb01nancial-related activities, such as swap-\n18\nping di\ufb00erent tokens at DEXes, loaning coins from exchanges, buying/selling\ncrypto-assets from \ufb01at to stablecoins, and designing derivatives (e.g., NFT [12],\ncontracts, securities [60], share, etc.), becomes common and easier for single users\nsince they do not need to register to any \ufb01nancial intermediaries. These activities\nmake up the core of today\u2019s DeFi market [61], which also attracts tremendous\nmonetary investments involved in this \ufb01eld. Blockchain systems lay the foun-\ndation of DeFi protocols, guaranteeing the normal operations of every piece of\nlogic, while Web3 paves the path to practical usage of these protocols, guiding\nusers to participate in the games. Users only need to act as they behave in cen-\ntralized markets, rather than having hard research to understand the di\ufb00erences\nbetween token standards or blockchain platforms.\nMetaverse. Unlike DeFi or NFT specifying one speci\ufb01c direction, Metaverse\nis a general term that involves numerous technologies, with ambiguous targets\nto describe a virtual digital world for the incoming future. Intuitively, users\nin Metaverse will \ufb01rst interact with its front-end and then connect with the\ndecentralized network supported by interoperable blockchain platforms. Web3\ncan cover all touchable applications that a user can reach, such as social networks,\nsearch engines (Brave [62]), galleries (Opensea [20]), and marketplaces. A user\ncan fully control their digital assets, identities, and data, browsing any sector\nof the Metaverse just like shopping at the store. Web3 can help to establish\nsuch a front-end environment with a pretty easy one-step connection for the\nparticipating users. In practice, many projects start to establish Metaverse from\ndi\ufb00erent aspects like IoT [52], Games [11], Markets [57][20], etc.\n5.3\nOpen Challenges\nIn this subsection, we point out the potential challenges from four folds, sepa-\nrately from the views of user-level (application), system-level (blockchain), mar-\nkets (economy), and social organizations (legality).\nApplication. Decentralized applications built on blockchain-empowered sys-\ntems are the \ufb01rst gate to individuals. Users have intuitive feelings towards these\napplications. We abstract three aspects that may a\ufb00ect the user experience.\n- Composability. Web3-based solutions cover a wide range, either from the\ntype of components, or the products for each component. Data transmitting\nin di\ufb00erent products are inevitably isolated. The way to make data reused\nby di\ufb00erent products at the same layer is urgently important. Standardized\nAPIs may address the problem to some extent, where at least many DApps\nwith similar designs can invoke the same APIs. Ceramic [40] tries to build ap-\nplications with composable Web3 data and enable reusable data for multiple\nscenarios. However, making most back-end components composable is still\na challenge. The barriers are whether composable components are compat-\nible with each other and whether data can \ufb02ow seamlessly across di\ufb00erent\ncomponents. For such reasons, the data need to be designed in the same\nstructure for the re-usage by these components.\n19\n- Accessibility. Web2 networks still cover most Internet users\u2019 activities, in-\ncluding social media, shopping, meeting, education, and payments. Users are\naccustomed to and enjoy their services due to their super convenience and\neasy accessibility. The lack of integration with modern web browsers and\nmobile applications limits the wide adoption of Web3 to end-users. An indi-\nvidual user will not change from the product that he used for a long to a new\none. How to decrease the migration cost is a challenge. Moreover, interacting\nwith Web3 applications also requires additional development, education, and\nsoftware/hardware. This becomes a huge recognition di\ufb03culty for users and\nthus impedes its wide adoption.\n- Data Recovery. The private key is the most important secret of users when\nusing blockchain platforms. The entire account of users relies on a credential\nthat is represented in the form of a complex string or a series of secret recov-\nery phrases. If a user loses his private key, he will never enter his account.\nThe account becomes a dead account with all data, including assets, being\nlocked. Methods to recover accounts, or at least the internal data, are an\nurgent requirement for applications in the Web3 space. Moreover, applica-\ntions that adopt o\ufb00-chain storage require more strict veri\ufb01cation for data\nintegrity because additional checks on whether the data in external stor-\nage matches on-chain hash values are needed. The data recovery in external\npages is di\ufb03cult due to the absence of traceability and accountability.\nBlockchain. Blockchain systems are the most fundamental layer in each archi-\ntectural design type, supporting upper-layer applications as well as connecting\nunderlying storage. Limitations in blockchain systems will signi\ufb01cantly constrain\nthe development of the entire Web3 ecosystem.\n- Scalability. Scalability represents the ability to process transactions along\nwith the increased scale of networks, which is re\ufb02ected by the increase or\ndecrease in its performance. This is a long-term issue existing in blockchain\nsystems due to intrinsic decentralization. Every major step needs time, such\nas data update, signature veri\ufb01cation, etc. Among them, the consensus pro-\ncess has the most impacts since the more mining nodes joined the network,\nthe more computational tasks were added. Web3 is closely integrated with\nunderpinned blockchain systems, which, as a result, will face the similar issue\nas well. In most cases, transactions are slow on website interactions as state\ntransitions need con\ufb01rmation and propagation throughout the network. Un-\nderlying blockchain platforms, together with atop Web3 applications, require\nconquering the challenges of accommodating rapid growth and the demands\nof not compromising performance. Otherwise, users, with a high probability,\nmay have a poor experience such as extremely slow loading speed of websites.\n- Interoperability. Web3 applications, in the foreseen future, will be de-\nployed on many blockchain platforms. This requires interoperable blockchain\ntechnologies to facilitate smooth state transitions, either homogeneously or\nheterogeneously. Creating interchangeable communication channels to con-\n20\nnect isolated decentralized ledgers is still a challenge for the development.\nCurrent interoperability solutions, such as pegged sidechains [63], hash-locks\n[64], and trusted relays [65], partially mitigate the problem: they enable\ntransactions to cross over chains within their speci\ufb01ed ecosystems (e.g.,\nPolkadot and their para-chain slots [66]), but cannot make nature trans-\nactions operated across di\ufb00erent ecosystems (Polkadot token on Ethereum).\nA prevailing method is to create the wrapped token that anchors the origin\ntoken with equal supplies as an alternative representation, such as the BTC\ncoin existing in Ethereum with the representation of WBTC (an ERC20\nformat [67]). However, this makes more and more representative tokens pro-\nduced with no actual usage, increasing the waste and complexity.\n- Contract Vulnerability. The security of smart contracts [68] will directly\na\ufb00ect its connected Web3 applications. Smart contracts contain the business\nlogic and operation speci\ufb01cations, which are key to the upper layer appli-\ncations. Meanwhile, smart contracts can act as autonomous agents [69], de-\ncreasing the power of centralized service providers in combined protocols and\nsecuring on-chain data from users. Vulnerabilities existing in smart contracts,\ncaused by design \ufb02aws or implementation errors, may result in thousands of\nmonetary loss. Examples include the integer under\ufb02ow/over\ufb02ow attacks [68],\nDAO attacks [70][71] and Parity Multi-Sig Wallet attack [72]. Even worse,\nthe scripting nature of contract programming languages (cf. Appendix C)\nand the non-updateable feature of smart contracts will signi\ufb01cantly limit\nthe growth of Web3 applications.\nEconomy. As one of the major di\ufb00erences compared to Web1/Web2, users in the\nWeb3 space can automatically obtain rewards according to their contributions.\nUsers holding both digital assets and metadata in their wallets can freely trade\nthem to earn pro\ufb01ts. But there are still many concerns about disparate incentive\nmechanisms, operating costs, and technical debts.\n- Incentive. Users adopt Web3 applications largely due to their considerable\npotential revenues. They can earn extra pro\ufb01ts by conducting activities in\nWeb3 networks: browsing websites (Basic Attention Token [62]), providing\nonline storage (Arweave [45]), playing games (Axie In\ufb01nity [11]), or selling\nself-created products (Opensea [20]). Even for the current stage, developers\ncan obtain airdropped tokens from the project teams by testing their demos\non the testnet. However, as more and more users participate in the game,\nthe threshold of obtaining rewards becomes extremely high. Thus, designing\na positive incentive mechanism that can cover as many users is crucial to\nattract new players joining the network.\n- Cost. The high gas fee has already become a major hurdle in using Ethereum.\nSending an transaction will cost more than hundreds of dollars (executions on\nsmart contracts cost more). As a result, applications with complicated com-\nputations cannot be deployed on-chain. This is the reason why many com-\npetitive public blockchains can co-exist in the market. Moreover, blockchain\n21\nprovides very constrained capabilities of storage, where many DApps can\nonly put a small portion of code on-chain. A potential solution is to adopt\nmore o\ufb00-chain solutions [73] that can take over the workload from on-chain\nto local servers without signi\ufb01cantly breaking decentralization.\n- Technical Debt. Many Web3 applications are designed in a limited way\nto facilitate the entire software development cycle. This would cause many\ncosts of additional rework in the latter processes, which is denoted as the\ntechnical debt [74]. A suitable approach that aims for a long-term proposal\ncan save many more costs because a bad design will accumulate interest\njust as it is in monetary debt. Developing more in an inappropriate route\ncan improve the di\ufb03culty of making updates. The development of a project\nfalling into technical debt will reach a point where it is no longer possible\nto implement the protocol improvements that align with its initial vision.\nDevelopers should be su\ufb03ciently prudent when designing their products,\neven for the initial proof-of-concept implementations.\nLegality. Governments and o\ufb03cial organizations have a lot of concerns due to\nthe rapid shift and huge change in the cryptocurrency world. Individual users are\neager to have their non-infringeable rights and are afraid of an anarchy state. It is\npretty di\ufb03cult to reach the balance. Here, we stress the two discussed challenges\nin the view of the social side.\n- Governance. Since anyone can launch Web3 projects, an increased number\nof applications will inevitably make the market segmented and unsuper-\nvised. Traditional authorities such as o\ufb03cial organizations and governments\nbecome less in\ufb02uential than it is today. A large proportion of power is dis-\ntributed to DAOs, which are made up of individuals. However, anyone who\nuses Web3 can arbitrarily establish DAOs without strict authentication or\nKYC (know your customer) steps. This causes instability in society [75].\nFor instance, (web3) tweets on decentralized social media platforms would\nbe uncensorable without facing the risk of being punished for spreading ru-\nmors. Moreover, some illegal trades, such as porn or drugs, might be abused\nin unsupervised networks as no explicitly compulsive laws can forbid them.\n- Taxable Di\ufb03culty. The intrinsic property of Web3 is to give the incentive\nback to users. Individuals who contribute more will obtain higher rewards.\nTheir contributions can be in any form, such as deposited stakes (PoS-based\nchains [28]), activities (many projects airdrop tokens based on this), atten-\ntions (e.g., BAT [62], Cirus [76]), or followers in traditional social media\n(Twitter, Discord, Facebook). If most of the current network users move to\nthe Web3 world, collecting taxes from, at least, technology companies and\nInternet practitioners becomes extremely di\ufb03cult. Even worse, hiding assets\nin accounts can help users directly make investments in \ufb01nancial markets\nand earn pro\ufb01ts. The governments can never know what has happened and\nwhen this has occurred, nor for associated evidence used for taxes.\n22\n6\nClosing Results\nThis section collects several popular questions that are frequently mentioned in\ncommunities. We accordingly answer them with our investigated results.\nWhat is Web3? Web3 is an umbrella term used to describe the next gener-\nation of internet services. It incorporates a wide range of components in the\ncomputer infrastructure. We have, in this work, investigated in the wild solu-\ntions and found several common design patterns. We decouple Web3 services\ninto three major components as in Sec.3. With this, an application/service,\nin the context of our methodology, can be categorized into a Web3 space if at\nleast one component is decentralized. Based on the current view, an ideal Web3\napplication, operates all the services on-chain. However, this design can only\nsupport services with lightweight computations and storage. Supplementary\nservices require external techniques.\nWhat is the cornerstone of Web3? Following the previous discussion, a nat-\nural question is that: how to implement the decentralization of each component\nfor building Web3. We review the identi\ufb01ed twelve architectural designs and\n\ufb01nd an interesting result: every component centres around continuously oper-\nating blockchain platforms. The front-end wallet needs to connect with the on-\nchain operation, while the external storage also requires on-chain information\nfor item searching and valid proofs. Therefore, the characterization through\naccess, computation and storage highly rely on the service of blockchain: ac-\ncess to the blockchain, computation in the blockchain, and storage surrounding\nblockchain. These integrated components can establish a Web3 service thanks\nto the support from the blockchain. In this way, Web3 holds the property of\ndecentralization, obtaining bene\ufb01ts from the blockchain.\nIs Web3 su\ufb03ciently decentralized? Web3 is not as decentralized as it ap-\npears to be [77], in which building a Web3 application still highly relies\non a small corpus of companies. For instance, centralized exchanges that\ncan trade cryptocurrencies are majorly controlled by Binance [30] and Coin-\nbase [29], while wallets are a\ufb00ected by MetaMask [78], NFT products [12]\nby OpenSea [20], and stablecoins by Tether [79]. Meanwhile, a similar phe-\nnomenon also occurs in DeFi markets: Uniswap [56] has the most Total Value\nLocked (TVL); Dai [80] has dominated the decentralized stablecoins; Chain-\nlink [81] has greatly outcompeted others in the price oracle. Moreover, many\ninfrastructure-related blockchain companies that provide programming inter-\nfaces and development tools are concentred on a few companies like Alchemy\n[42], Infura [82], and Ankr [43]. The high density of consolidation in the cryp-\ntocurrency \ufb01eld will inevitably result in a partial monopoly, where only a small\ngroup of oligarchs takes most of the resources.\nIs Web3 secure? The answer would be \u201cNo\u201d. Web3 services rely on a suite of\ncomposable components to seamlessly work together. Problems in any single\ncomponent may lead to fail. Come back to our NFT example, the raw data\nof the NFT may be erased due to the o\ufb04ine insecure storage by adversarial\n23\nattacks or compromised managers. This is merely an example from the storage\nlayer. In the real world, issues happening in other blockchain components\nwill as well result in severe problems, such as transaction congestion due to\npoor scalability, slow con\ufb01rmation caused by probabilistic consensus, or logical\nloopholes in smart contracts. The security of Web3 is closely related to correct\noperations of the entire system, which should be an all-level stack evaluation.\nHas Web3 addressed privacy worries? Web3 services cannot protect user\nprivacy as it claimed. We give discussions from the website, which is the entry\nof a user to Web3 applications and services. Web-side privacy issues cover a\nset of design pitfalls and malicious attacks launched from the front-end, such\nas browsers or mobile applications. In many cases, an adversary may act like\na normal operator in the system. For instance, the centralized authority can\nplay the role of a tracker with abilities to record Ethereum addresses over a\nwide range of users, resulting in privacy violations with the help of its script\nembedding techniques [83]. Once a user leaves evidence of using an address\nat a DeFi site, the malicious browser, which also holds your identities, can\nmap to your physical entity. Besides, other traditional web attacks may also\nthreaten the Web3 sites due to the shared engine.\nFact and Fiction - Truth to be Told of Web3\nBased on our investigations from both technical and economic perspec-\ntives, Web3 cannot fully replace current web services. Instead, Web3 will\nstill highly rely on the existing Internet infrastructure, including program-\nming languages, communication protocols, agents, and storage. Fortu-\nnately, Web3 has reshaped conventional \ufb01nance markets and facilitated\nindividual self-governance. Users at least begin to pay much more atten-\ntion to their digital assets covering both virtual data and cryptocurrencies.\n7\nConclusion\nWeb3 is an emerging concept prevailing in the entire crypto-world. Applications\nand services in the Web3 space, with non-custodial nature, allow users to control\ntheir data and obtain rewards. However, no clear de\ufb01nitions of such a buzzword\nhave formed. In this tech report, we \ufb01ll the gap by investigating a large corpus\nof in the wild projects titled with Web3. We dig into this topic by decoupling\nexisting systems supporting blockchain-based Web3 services into separate core\ncomponents, and accordingly discussing related features and properties for each\npotential combination. In total, we have identi\ufb01ed twelve architectural design\ntypes and evaluated them with profound discussions. Based on our study, we\npresent the new paradigms gained by Web3 and point out the design pitfalls. We\nfurther provide our answers to several questions from communities. To the best\nof our knowledge, this is the \ufb01rst research on Web3 from the view of blockchain.\n24\nReferences\n1. Eric Glen Weyl, Puja Ohlhaver, and Vitalik Buterin.\nDecentralized society:\nFinding web3\u2019s soul. Available at SSRN: https:// ssrn.com/abstract=4105763,\n2022.\n2. The web3 report q3 2021 (consensys). https:// consensys.net/ reports/ web3-r\neport-q3-2021/ , 2021.\n3. Wood Gavin. Why we need web 3.0. https:// gavofyork.medium.com/why-we-\nneed-web-3-0-5da4f 2bf95ab, 2022.\n4. Dappradar. https:// dappradar.com/ , 2022.\n5. Mathdapp. https:// mathdapp.store/ , 2022.\n6. Avalanche network. https:// www.avax.network/ , 2022.\n7. Solana network. https:// solana.com/ , 2022.\n8. Binance smart chain. https:// bscscan.com/ , 2022.\n9. Oasis network. https:// oasisprotocol.org/ , 2022.\n10. Jiahua Xu, Krzysztof Paruch, Simon Cousaert, and Yebo Feng. Sok: Decentralized\nexchanges (dex) with automated market maker (amm) protocols. arXiv preprint\narXiv:2103.12732, 2021.\n11. Axie in\ufb01nity. https:// axiein\ufb01nity.com/ , 2022.\n12. Qin Wang, Rujia Li, Qi Wang, and Shiping Chen.\nNon-fungible token\n(NFT): Overview, evaluation, opportunities and challenges.\narXiv preprint\narXiv:2105.07447, 2021.\n13. Zhuotao Liu, Yangxi Xiang, Jian Shi, Peng Gao, Haoyu Wang, Xusheng Xiao, Bi-\nhan Wen, Qi Li, and Yih-Chun Hu. Make web3. 0 connected. IEEE Transactions\non Dependable and Secure Computing (TDSC), 2021.\n14. Satoshi Nakamoto. Bitcoin: A peer-to-peer electronic cash system. Decentralized\nBusiness Review, page 21260, 2008.\n15. Miguel Castro, Barbara Liskov, et al. Practical byzantine fault tolerance. In The\nUSENIX Symposium on Operating Systems Design and Implementation (OSDI),\nvolume 99, pages 173\u2013186, 1999.\n16. Juan Garay, Aggelos Kiayias, and Nikos Leonardos. The bitcoin backbone proto-\ncol: Analysis and applications. In Annual International Conference on the Theory\nand Applications of Cryptographic Techniques (EUROCRYPT), pages 281\u2013310.\nSpringer, 2015.\n17. Juan Garay, Aggelos Kiayias, and Nikos Leonardos. The bitcoin backbone pro-\ntocol with chains of variable di\ufb03culty. In Annual International Cryptology Con-\nference (CRYPTO), pages 291\u2013323. Springer, 2017.\n18. Qin Wang et al. Sok: Diving into DAG-based blockchain systems. arXiv preprint\narXiv:2012.06128, 2020.\n19. Ipfs: Filecoin. https:// \ufb01lecoin.io/ , 2022.\n20. Opensea. https:// opensea.io/ , 2022.\n21. Panagiotis Chatzigiannis, Foteini Baldimtsi, and Konstantinos Chalkias.\nSok:\nBlockchain light clients. Cryptology ePrint Archive, 2021.\n22. Kostis Karantias. Sok: A taxonomy of cryptocurrency wallets. Cryptology ePrint\nArchive, 2020.\n23. Swarm. https:// www.ethswarm.org/ , 2022.\n24. Rick Kazman, Mark Klein, Mario Barbacci, Tom Longsta\ufb00, Howard Lipson, and\nJeromy Carriere.\nThe architecture tradeo\ufb00analysis method.\nIn Proceedings.\nFourth IEEE International Conference on Engineering of Complex Computer Sys-\ntems (cat. no. 98ex193), pages 68\u201378. IEEE, 1998.\n25\n25. Sukrit Kalra, Seep Goel, Mohan Dhawan, and Subodh Sharma. Zeus: analyz-\ning safety of smart contracts. In The Network and Distributed System Security\nSymposium (NDSS), pages 1\u201312, 2018.\n26. Rujia Li et al. Sok: Tee-assisted con\ufb01dential smart contract. The 22nd Privacy\nEnhancing Technologies Symposium (PETS), 3, 2022.\n27. Len Bass, Paul Clements, and Rick Kazman. Software architecture in practice.\nAddison-Wesley Professional, 2003.\n28. Aggelos Kiayias, Alexander Russell, Bernardo David, and Roman Oliynykov.\nOuroboros: A provably secure proof-of-stake blockchain protocol. In Annual In-\nternational Cryptology Conference (CRYPTO), pages 357\u2013388. Springer, 2017.\n29. Coinbase. https:// www.coinbase.com/ , 2022.\n30. Binance. https:// www.binance.com/ , 2022.\n31. Solana art. https:// solanart.io/ , 2022.\n32. Theta network. https:// www.thetatoken.org/ , 2022.\n33. Audius. https:// audius.co/ , 2022.\n34. Livepeer. https:// livepeer.org/ , 2022.\n35. Shawn Wilkinson, Tome Boshevski, Josh Brando\ufb00, and Vitalik Buterin. Storj a\npeer-to-peer cloud storage network. 2014.\n36. David Vorick and Luke Champine. Sia: Simple decentralized storage. Retrieved\nMay, 8, 2014.\n37. Filecoin: a decentralized storage network. https:// \ufb01lecoin.io/ , 2022.\n38. Web3auth. https:// web3auth.io/ index.html, 2021.\n39. Idx: Identity protocol for open applications. https:// idx.xyz/ , 2022.\n40. Ceramic network. https:// ceramic.network/ , 2022.\n41. Tru\ufb04e suite. https:// truf \ufb02esuite.com/ , 2022.\n42. Alchemy. https:// www.alchemy.com/ , 2022.\n43. Ankr. https:// www.ankr.com/ , 2022.\n44. The web3 index. https:// web3index.org/ , 2022.\n45. Arweave. https:// www.arweave.org/ , 2022.\n46. Robin Fritsch, Marino M\u00a8uller, and Roger Wattenhofer. Analyzing voting power in\ndecentralized governance: Who controls daos? arXiv preprint arXiv:2204.01176,\n2022.\n47. Aragon. https:// aragon.org/ , 2022.\n48. Metacartel. https:// www.metacartel.org/ , 2022.\n49. Reed Drummond, Sporny Manu, Sabadello Markus, Longley Dave, and Allen\nChristopher. Decentralized identi\ufb01ers (DIDs) v1.0: Core architecture, data model,\nand representations. https:// www.w3.org/TR/ did-core/ , 2021.\n50. The graph network. https:// thegraph.com/en/ , 2022.\n51. Sia network. https:// sia.tech/ , 2022.\n52. Helium network. https:// www.helium.com/ , 2022.\n53. Radicle. https:// radicle.xyz/ , 2022.\n54. Deeper network: The decentralized gateway and infrastructure for web3.0. https:\n// www.deeper.network/ , 2022.\n55. Yearn. https:// yearn.\ufb01nance/ , 2022.\n56. Uniswap. https:// uniswap.org/ , 2022.\n57. Superrare. https:// superrare.com/ , 2022.\n58. Makerdao. https:// makerdao.com/ , 2022.\n59. Request for proposals (rfp): Sign-in-with-ethereum. https:// notes.ethereum.org\n/@djrtwo/sign-in-with-ethereum-RFP, 2022.\n26\n60. Hongyin Chen, Yukun Cheng, Xiaotie Deng, Wenhan Huang, and Linxuan Rong.\nAbsnft: Securitization and repurchase scheme for non-fungible tokens based on\ngame theoretical analysis. arXiv preprint arXiv:2202.02199, 2022.\n61. Sam M Werner, Daniel Perez, Lewis Gudgeon, Ariah Klages-Mundt, Dominik\nHarz, and William J Knottenbelt. Sok: Decentralized \ufb01nance (de\ufb01). arXiv preprint\narXiv:2101.08778, 2021.\n62. Brendan Eich. Brave browser. https:// brave.com/ , 2022.\n63. Liping Deng, Huan Chen, Jing Zeng, and Liang-Jie Zhang. Research on cross-\nchain technology based on sidechain and hash-locking. In International Confer-\nence on Edge Computing, pages 144\u2013151. Springer, 2018.\n64. Maurice Herlihy. Atomic cross-chain swaps. In Proceedings of the 2018 ACM Sym-\nposium on Principles of Distributed Computing (PODC), pages 245\u2013254, 2018.\n65. Philipp Frauenthaler, Marten Sigwart, Christof Spanring, and Stefan Schulte.\nTestimonium: A cost-e\ufb03cient blockchain relay. arXiv preprint arXiv:2002.12837,\n2020.\n66. Gavin Wood. Polkadot: Vision for a heterogeneous multi-chain framework. White\nPaper, 2016.\n67. Wrapped bitcoin. https:// wbtc.network/ , 2022.\n68. Nicola Atzei, Massimo Bartoletti, and Tiziana Cimoli. A survey of attacks on\nethereum smart contracts (sok).\nIn International Conference on Principles of\nSecurity and Trust, pages 164\u2013186. Springer, 2017.\n69. Rujia Li et al. How do smart contracts bene\ufb01t security protocols? arXiv preprint\narXiv:2202.08699, 2022.\n70. Understanding the dao attack. https:// www.coindesk.com/understanding-dao\n-hack-journalists/ , 2016.\n71. Understanding the dao attack. https:// www.coindesk.com/learn/2016/ 06/2\n5/ understanding-the-dao-attack/ , 2016.\n72. An in-depth look at the parity multisig bug. https:// hackingdistributed.com/2\n017/ 07/22/ deep-dive-parity-bug/ , 2016.\n73. Lewis Gudgeon, Pedro Moreno-Sanchez, Stefanie Roos, Patrick McCorry, and\nArthur Gervais. Sok: Layer-two blockchain protocols. In International Conference\non Financial Cryptography and Data Security (FC), pages 201\u2013226. Springer,\n2020.\n74. Wiki: Technical debt. https:// www.wikiwand.com/en/ Technical debt, 2022.\n75. Aggelos Kiayias and Philip Lazos. Sok: Blockchain governance. arXiv preprint\narXiv:2201.07188, 2022.\n76. Cirus. https:// cirusf oundation.com/ , 2022.\n77. Kevin Werbach. The blockchain and the new architecture of trust. Mit Press,\n2018.\n78. Metamask. https:// metamask.io/ , 2022.\n79. Tether. https:// tether.to/ , 2022.\n80. Dai. https:// makerdao.com/ , 2022.\n81. Chainlink. https:// chain.link/ , 2022.\n82. Infura. https:// infura.io/ , 2022.\n83. Philipp Winter, Anna Harbluk Lorimer, Peter Snyder, and Benjamin Livshits.\nWhat\u2019s in your wallet? privacy and security issues in web 3.0. arXiv preprint\narXiv:2109.06836, 2021.\n84. Md Sadek Ferdous, Farida Chowdhury, et al. In search of self-sovereign identity\nleveraging blockchain technology. IEEE Access, 7:103059\u2013103079, 2019.\n85. Consensys: Blockchain use cases: Blockchain in digital identity. https:// consen\nsys.net/ blockchain-use-cases/digital-identity/ #howddiworks, 2022.\n27\n86. Hyperledger aries. https:// www.hyperledger.org/ use/ aries, 2022.\n87. Ontology network, ont id. https:// ont.id/ , 2022.\n88. uport - veramo. https:// veramo.io/ , 2022.\n89. Gavin Wood et al.\nEthereum: A secure decentralised generalised transaction\nledger. Ethereum project yellow paper, 151(2014):1\u201332, 2014.\n90. Yonatan Sompolinsky and Aviv Zohar. Secure high-rate transaction processing in\nbitcoin. In International Conference on Financial Cryptography and Data Security\n(FC), pages 507\u2013527. Springer, 2015.\n91. Ragib Hasan, Zahid Anwar, William Yurcik, Larry Brumbaugh, and Roy Camp-\nbell.\nA survey of peer-to-peer storage techniques for distributed \ufb01le systems.\nIn International Conference on Information Technology: Coding and Computing\n(ITCC), volume 2, pages 205\u2013213. IEEE, 2005.\n92. Nazanin Zahed Benisi, Mehdi Aminian, and Bahman Javadi. Blockchain-based\ndecentralized storage networks: A survey.\nJournal of Network and Computer\nApplications, 162:102656, 2020.\n93. Xiaotao Feng et al.\nBug searching in smart contract.\narXiv preprint\narXiv:1905.00799, 2019.\n94. Burak Benligiray, Sa\u02c7sa Milic, and Heikki V\u00a8anttinen. Decentralized apis for web\n3.0. https:// api3.org/ .\n95. Wei-Meng Lee. Using the web3. js apis. In Beginning ethereum smart contracts\nprogramming, pages 169\u2013198. Springer, 2019.\n96. Elli Androulaki, Artem Barger, Vita Bortnikov, Christian Cachin, Konstantinos\nChristidis, Angelo De Caro, David Enyeart, Christopher Ferris, Gennady Lavent-\nman, Yacov Manevich, et al. Hyperledger fabric: a distributed operating system\nfor permissioned blockchains. In Proceedings of the thirteenth EuroSys Conference\n(EuroSys), pages 1\u201315, 2018.\n97. Christian Goren\ufb02o, Stephen Lee, Lukasz Golab, and Srinivasan Keshav. Fastfab-\nric: Scaling hyperledger fabric to 20 000 transactions per second. International\nJournal of Network Management, 30(5):e2099, 2020.\n98. The algorand virtual machine (avm) and teal. https:// developer.algorand.org\n/docs/ get-details/ dapps/ avm/ teal/speci\ufb01cation/ , 2022.\n99. Yossi Gilad, Rotem Hemo, Silvio Micali, Georgios Vlachos, et al. Algorand: Scal-\ning byzantine agreements for cryptocurrencies. In Proceedings of the 26th Sym-\nposium on Operating Systems Principles (SOSP), pages 51\u201368, 2017.\n100. The pact programming language. https:// github.com/kadena-io/pact, 2022.\n101. Kadena. https:// kadena.io/ , 2022.\n102. Dune network. https:// dune.network/ , 2022.\n103. Sui blockchain platform. https:// docs.sui.io/ learn/ about-sui, 2022.\n104. Ssc: Stellar smart contracts. https:// github.com/stellar-deprecated/ docs/blo\nb/ master/guides/ walkthroughs/stellar-smart-contracts.md, 2022.\n105. Solidity. https:// docs.soliditylang.org/ en/v0.8.13/ , 2022.\n106. Ethereum for rust developers. https:// github.com/stellar-deprecated/ docs/b\nlob/ master/guides/ walkthroughs/stellar-smart-contracts.md, 2022.\n107. Ethereum for javascript developers. https:// ethereum.org/en/ developers/doc\ns/ programming-languages/ javascript/ , 2022.\n108. Yul docs. https:// docs.soliditylang.org/ en/v0.5.3/ yul.html, 2022.\n109. Vyper docs.\nhttps:// vyper.readthedocs.io/en/ v0.1.0-beta.12/index.html,\n2022.\n110. Marta Lokhava, Giuliano Losa, David Mazi`eres, Graydon Hoare, Nicolas Barry,\nEli Gafni, Jonathan Jove, Rafa l Malinowsky, and Jed McCaleb. Fast and secure\n28\nglobal payments with stellar.\nIn Proceedings of the 27th ACM Symposium on\nOperating Systems Principles (SOSP), pages 80\u201396, 2019.\n111. Move docs. https:// docs.sui.io/ build/ move, 2022.\n112. Diem.\nhttps:// developers.diem.com/ docs/technical-papers/ the-diem-block\nchain-paper/ , 2022.\n113. Ocean protocol. https:// oceanprotocol.com/ , 2022.\n114. Syndicate: Turn any wallet into a web3-native investing dao. https:// syndicate.\nio/ , 2022.\n115. Utopia: Collaborative payroll and expense management for daos. https:// www.\nutopialabs.com/ , 2022.\n116. Arbol. https:// www.arbolmarket.com/ , 2022.\n117. Etherisc. https:// etherisc.com/ , 2022.\n118. Royal. https:// royal.io/ , 2022.\n119. Mirror: Create and connect your world on web3. https:// mirror.xyz/ , 2022.\n120. Creaton. https:// app.creaton.io/#/ , 2022.\n121. Gari network. https:// gari.network/ , 2022.\n122. Gitcoin: Build and fund the open web together. https:// gitcoin.co/ , 2022.\n123. Linkdrop. https:// linkdrop.io/ , 2022.\n124. Cointra\ufb03c. https:// cointraf \ufb01c.io/ , 2022.\n125. Manifold. https:// www.manifold.xyz/ , 2022.\n126. Clout.art. https:// clout.art/ , 2022.\n127. nifty.ink. https:// nifty.ink/ , 2022.\n128. steem. https:// steem.com/ , 2022.\n129. Akasha. https:// akasha.org/ , 2022.\n130. Cyberconnect. https:// cyberconnect.me/ , 2022.\n131. Coinvise. https:// www.coinvise.co/ , 2022.\n132. Rally. https:// rally.io/ , 2022.\n133. Mynfteam. https:// www.mynf .team/ , 2022.\n134. Status. https:// status.im/ , 2022.\n135. Violet. https:// violet.co/ , 2022.\n136. Litentry. https:// www.litentry.com/ , 2022.\n137. Spruceid. https:// www.spruceid.com/spruceid, 2022.\n138. Crypto.com. https:// crypto.com/ , 2022.\n139. Zapper. https:// zapper.f i/ , 2022.\n140. Rainbow. https:// rainbow.me/ , 2022.\n141. Zerion. https:// zerion.io/ , 2022.\n142. Haskell web3 documentation. https:// hs-web3.readthedocs.io/en/ latest/index\n.html, 2021.\n143. Anchor protocol.\nhttps:// docs.anchorprotocol.com/ developers-earn/ anchor\n-earn-sdk, 2022.\n144. Solana-web3.js. https:// solana-labs.github.io/ solana-web3.js/ , 2022.\n145. Civic. https:// www.civic.com/ , 2022.\n146. Flux protocol. https:// www.\ufb02uxprotocol.org/ , 2022.\n147. Polygon. https:// polygon.technology/ , 2022.\n148. zksync. https:// zksync.io/ , 2022.\n149. Starkware. https:// starkware.co/starknet/ , 2022.\n150. Zk-rollups.\nhttps:// docs.ethhub.io/ethereum-roadmap/ layer-2-scaling/ zk-r\nollups/ , 2022.\n151. Optimism. https:// www.optimism.io/ , 2022.\n152. Arbitrum. https:// arbitrum.io/ , 2022.\n29\n153. Optimistic rollups.\nhttps:// ethereum.org/en/ developers/docs/ scaling/ opti\nmistic-rollups/ , 2022.\n154. Threadb. https:// docs.textile.io/ threads/ , 2022.\n155. Gundb. https:// gun.eco/ , 2022.\n156. Bittorrent. https:// www.bittorrent.com/ , 2022.\n157. Hardhat. https:// hardhat.org/ , 2022.\n158. Blockchain foundry. https:// blockchainfoundry.com/ , 2022.\n159. Brownie. https:// eth-brownie.readthedocs.io/en/ stable/ , 2022.\n160. Settlemint. https:// www.settlemint.com/ , 2022.\n161. Deepdao. https:// deepdao.io/organizations, 2022.\n162. Snapshot. https:// snapshot.org/#/ , 2022.\n163. tally. https:// www.tally.xyz/ , 2022.\n164. Nansen. https:// www.nansen.ai/ , 2022.\n165. Token terminal. https:// tokenterminal.com/ , 2022.\n166. Messari. https:// messari.io/ , 2022.\n167. The block data dashboard. https:// www.theblockcrypto.com/data/ nf t-non-fu\nngible-tokens/ nf t-overview, 2022.\n168. Neon evm. https:// docs.neon-labs.org/docs/ getting started/ , 2022.\n169. Ens: Ethereum name service. https:// ens.domains/ , 2022.\n170. Bon\ufb01da: Solana name service. https:// naming.bon\ufb01da.org/ #/ , 2022.\n171. Api3: The web api economy. https:// api3.org/ , 2022.\n172. Pocket network. https:// www.pokt.network/ , 2022.\n173. Datahub: The web 3 gateway. https:// datahub.\ufb01gment.io/ , 2022.\n174. Getblock: Superior node infrastructure for building dapps. https:// getblock.io/ ,\n2022.\n175. Moralis. https:// moralis.io/ , 2022.\n176. Quicknode. https:// www.quicknode.com/ , 2022.\n177. Figment learn. https:// learn.\ufb01gment.io/ , 2022.\nAppendix A. Web3 Primitives\nThis section recalls several concepts used in Web3. We provide two main parts:\none for the web-related knowledge, including its meaning, evolution, and archi-\ntecture, while the others for basic primitives used to build a Web3 service.\nA.1 Web and Architecture\nWe \ufb01rst provide the common sense of so-called Web1/Web2, and abstract the\nbackbone of their architectural designs. Based on that, we provide comparisons\nwith Web3 from the perspective of its architecture.\nWeb1/Web2. The concepts of Web1/Web2 have become common knowledge\nfor most internet users. We conservatively show their core properties from a\nhigh-level view during their evolution. The earliest version of the Web (Web1)\nis featured by its static sites, which consist of components such as images and\ntext. Users access the targeted items by \ufb01rst \ufb01nding a browser and then clicking\nwhat has been presented on the page. In this sense, Web1 is deemed as the\nread-only web. Web2 extends Web1 by importing more complex designs (e.g.\n30\nfront/back-end architecture), enabling interactive actions from users by dynamic\nHTML. Users can both read and write the content presented on sites, and can\nalso upload or download \ufb01les stored in databases. Users have their customized\noptions of choosing which services are supported by providers (Facebook, Google,\nAmazon, etc.). This directly paves the way for various applications that require\ninteractive web services, including marketplaces, user-generated content, and\nsocial media platforms. However, these centralized service providers gradually\nbecome the oligarch in their single \ufb01elds because the big company has controlled\nhuge amounts of data from users, some of which are even privacy-sensitive, like\nusers\u2019 passwords or \ufb01nancial history. The advent of Web3 mitigates such issues\nby replacing the centralized back-end server with distributed ledgers. User can\nhold their personal accounts (containing digital assets) safely rather than relying\non centralized banks. The services from each website, if interacting with users,\nhave to be authenticated through the way of connecting the wallet (cf. Sec.2).\nWeb Architecture. We brie\ufb02y summarize the potential architectural layouts\nand components of a web application. Building a typical web application relies on\na client-server model. The client means the ends browsed by users through com-\nputers, or smartphones, while a web server serves the data and requests. Here, the\nwebserver architecture is relatively complex that covers many fundamental as-\npects, including application tiers, operating systems (Windows, Linux, Solaris),\nplatforms (.Net, LAMP), performance/quality of service (latency, throughput,\nlow memory utilization), and physical capacity (computing power, storage, and\nmemory). Receiving and responding to requests is the most basic action in suc-\ncessfully performing a web application. Firstly, a user visits a website by in-\nputting a URL in the browser on the front-end. The browser parses the URL\nand sends the request to \ufb01nd the IP address via HTTPs. Then, the web server\ncatches the request and processes it following the business logic (also called do-\nmain logic and application logic) in the back-end. The business logic manages\nthe ways in which each piece of data is being accessed and determines the cor-\nresponding work\ufb02ow, especially for each application. Last, the user receives the\nresponse on the web page sent from back-end servers.\nA.2 Fundamental Components\nThen, we summarise the basic components that are used to establish Web3 from\nthe front user-end to the back server-end, covering light client (wallet), VM-\nengined blockchains (computation) and decentralised storage systems (storage).\nBesides, we also introduce a close concept \u2013 decentralized authentication, which is\nimportant for individuals who physically connect themselves with online virtual\nidentities (often in the form of anonymous addresses).\nDecentralized Authentication. Di\ufb00erent from traditional ways of authentica-\ntion, decentralized authentication removes, or at least weakens the dependency\n[69] of trusted third parties (TTPs) during the procedures of veri\ufb01cation and\nidenti\ufb01cations. Each user accordingly has a unique identi\ufb01er under the W3C\n31\ncommendations for decentralized identi\ufb01ers (DIDs) and veri\ufb01able credentials\n(VC) [49]. DID can be identi\ufb01ed by the DID\u2019s controller, who might be a single\nperson or an organization (also known as the self-sovereign identity [84]). VCs\nare the proofs that follow an open standard for digital credentials, such as a\npassport or a license, or an ownership certi\ufb01cate of bank accounts. Each DID\nwill be associated with a series of attestations generated by paired DIDs, usually\nin the form of VCs, to attest to its characteristics [85]. Blockchain, in such cases,\nhas two typical roles that either directly replace TTPs or assist existing ones\nby recording and managing the issuers\u2019 digital certi\ufb01cates [69]. Several proof-of-\nconcept projects have been proposed to highlight their targets to reshape DID\n\ufb01les, including the open-source platforms developed by Hyperfabric Aries [86],\nOntology [87], uPort (now rebranded as Veramo [88]), etc. Beyond that, if user\nprivacy is an essential requirement, more complex security-related primitives\n(e.g., zero-knowledge proof, homomorphic encryption, or commitments) have to\nbe introduced in the scheme.\nLight Client in Blockchain. The term light (equiv. lightweight) client shares\na similar meaning of its usage for both Web2 and Web3: it merely receives\nthe requests from users and forwards them to back-end servers (or blockchains)\nwithout participating in any logic processes. A slight di\ufb00erence is that a client\nin Web2 is often instantiated as a browser (covering both web browser, mobile\nbrowser, or an App), whereas in the context of Web3 or blockchain [21], it is\ntypically represented as a wallet [22], which is supported by locally running\nlight nodes that connect to full nodes for information synchronization. A wallet\ninteracts with the online blockchain system by sending a transaction to the\nTxpool (transaction pool) and broadcasting them to peers via the gossip protocol\n[14]. Using such a client can pose more compatibility to resource-constrained\nenvironments such as di\ufb00erent hardware devices, as well as reduce the costs\nof performing complex computations on-chain. The light client is an essential\ncomponent in building Web3 applications, as it is the \ufb01rst entry to access the\ndecentralized web environment. A shred of explicit evidence is that every Web3\npage enforces users to connect the wallet (a button in the upper right position)\nwhen users want to conduct interactive actions on this website.\nVM-engined Blockchain. The most signi\ufb01cant di\ufb00erence between Web3 and\nprevious web versions lies in the usage of blockchain. From the architecture\nperspective, blockchain replaces the traditional centralized back-end servers with\ndistributed ledger systems like Ethereum [89]. A blockchain-based system takes\nover the tasks of processing business logic and responding to users (under Web2\nsemantics). This depends on well-functioned on-chain virtual machine (VM) that\nenables state transitions. VM, in the context of blockchain, can be equivalently\nregarded as smart contracts that are automatically operated following the coded\nrules. The rules contain the logic requested from clients. Smart contracts, in\nthis sense, play an essential role in enabling Web3 and DApps. Meanwhile, to\nensure consistency across distributed nodes, a consensus protocol is required in\neach speci\ufb01c blockchain system. The consensus mechanisms solve the con\ufb02icts\n32\nand maintain the chain stability by initiating a set of prede\ufb01ned principles (the\nlongest-chain rule in PoW [14], the weightiest-chain rule in GHOST [90], and\nmore [18]). Further, all these nodes mutually communicate in a P2P network.\nThese components make up a typical blockchain architecture, which acts just\nlike a fully functional back-end server from an external view.\nDistributed Storage towards Blockchain. File storage systems in distributed\nnetworks are fundamental for sharing and storing sensitive content across dif-\nferent nodes. Two major ways of distributed storage are either increasing data\navailability (replication) or reducing data loss (erasure code). Adopting a dis-\ntributed \ufb01le system can obtain bene\ufb01ts including fault tolerance, scalability,\navailability, and performance [91]. In traditional ways, a lot of servers (on a\nscale of hundreds/thousands) have to cooperate to execute tasks requested from\nclients and applications, including service providers like Hadoop File System\n(HDFS), CernVM File System (CVFMS), and Andrew File System (AFS). Even\nthough these providers deploy many machines in di\ufb00erent areas, services are still\ncontrolled by providers, resulting in partial centralization. Di\ufb00ering from them,\nblockchain-based storage systems remove trusted central parties, which are the-\noretically more secure than centralized storage [92].\nUser\nWallet\nApplication\nBlockchain\nIdentity Creation\nLogin\nUse\ncalculation/storage\ntoken\nLoop\nLoop\ntoken reward/payment\nFig. 3: Work\ufb02ow of A Web3 System\nBlockchain storage mainly relies on redundant replications for data security in\ncase of loss. Storj [35] operates on Ethereum and replicates the metadata in\nmultiple locations. Sia [36], as a distributed storage system, uploads a list of\npublicly veri\ufb01able root hashes of submitted \ufb01les to get veri\ufb01cation on-chain.\nInterPlanetary File System (IPFS) [37], a peer-to-peer \ufb01le system, leverage the\nproof-of-spacetime and proof-of-replication to guarantee that (i) the data is being\n33\nstored during a speci\ufb01c duration of time and (ii) the data has been distributed\nin multiple hardware, rather than a single physical storage location. Based on\nsuch investigations, we abstract the distributed storage components, which can\ntake most of the workloads when on-chain capacity is not enough.\nA3.Web3 Work\ufb02ow\nIn a Web3 system (cf. Fig.3), user\u2019s data is processed and stored in a decentral-\nized and community-driven network, using open protocols instead of centralized\nTTP. An important feature of Web3 lies in its instant rewards, enabling users\nto obtain a fair share of revenues when they contribute to the network.\nAppendix B. Token Standards\nTokens in Web3 play an essential role in incentivizing users and developers. The\ntoken standard, as the subsidiary of the smart contract standard, de\ufb01nes the\nmethods to create, deploy and issue new tokens. We have investigated existing\ntoken standards from di\ufb00erent blockchain platforms and summarised them in\nTab.2. Most token standards are issued through Ethereum, which has the biggest\nand most mature on-chain virtual machine and smart contract. The standards\nin the table are not separate, and many of them have close relations. As a result,\nthese standards set the baseline of the entire ecosystem, even for the token\nstandards in other competitive blockchain systems. For instance, Binance smart\nchain and Avalanche follow very similar principles. We give a brief guide in Fig.4.\nTable 2: Summary of Token Standards\nStandard\nDate\nPlatform\nFeature\nApplication\nNotes\nERC20\n2015\nEthereum\nToken API / Fungible Token\nVote/ICO\nERC721\n2018\nEthereum\nNon-Fungible Token\nArtwork/IP\nERC777\n2018\nEthereum\nToken Approval\nImproving ERC20\nERC1155\n2018\nEthereum\nSemi-Fungible Token\nGame Bundling of ERC20\nERC223\n2017\nEthereum\nToken Recovery\nERC998\n2018\nEthereum\nComposable Non-Fungible Token\nGame/Ownership\nERC1238\n2018\nEthereum\nNon-Transferrable Non-Fungible Token\nBadge\nERC1594\n2018\nEthereum\nCore Security Token Standard\nSecurities (Financial)\nERC1400\n2018\nEthereum\nSecurity Token Standard\nSecurities\nERC1404\n2018\nEthereum\nSimple Restricted Token Standard\nSecurities\nERC1410\n2018\nEthereum\nPartially Fungible Token Standard\nERC1462\n2018\nEthereum\nBase Security Token\nSecurities\nBEP20\n2020\nBinance\nFungible Token\nVote/Wrap Token\nBEP721\n2020\nBinance\nNon-Fungible Token\nIP Products\nARC721\n2021\nAvalanche Fungible Token\nWrap Other Tokens\nThe most important token standard in the crypto-world is ERC20. It introduces\nthe concept of fungible tokens and de\ufb01nes the software interface and token APIs.\nAn ERC20 token is di\ufb00erent from a chain-based ETH token because ERC20\n34\ntokens run based on smart contracts. By deploying a token-issue contract, ev-\neryone can create their tokens without initiating a separate blockchain. Such\na design can be used as a variant type of Initial Public O\ufb00ering (IPO), where\nany team can launch a fundraising activity, denoted as the Initial Coin O\ufb00ering\n(ICO). This reduces the complexity of implementation and increases the liquidity\nacross di\ufb00erent tokens in the Ethereum ecosystem. ERC20 interfaces contain six\nmajor methods, namely, totalSupply, balanceOf, transfer, transferFrom,\napprove and allowance and two events: transfer and approval. These methods\nlay the foundation of all following standards. Another essential token standard\nis ERC721, a standard for the non-fungible token (NFT). Tokens in this type\nare distinguished where the pair of contract address and tokenId (in the form\nof a uint256 variable) must be globally unique. The exact value of an NFT,\nre\ufb02ected in the \ufb01nancial market, may vary in a huge range due to its rarity,\nage, or attention. Based on such attributes, ERC721 tokens are suitable to o\ufb00er\nIP-related products [12] that cover collectible items (images, songs, or books),\ntickets (for events, lotteries, or concerts), access keys, etc.\nFig. 4: Relationship between Di\ufb00erent Token Standards\nBeyond the wide adoption of ERC20 and ERC721 standards, other standards\nalso contribute to communities by extending the functionalities and availability.\nERC223 improves ERC20 (means remaining backward compatible with ERC20)\nby adding the tokenFallBack. In case of the monetary loss of sending tokens\nto a contract address, ERC223 can recover the missing tokens through the new\nfunction. ERC777 extends ERC20 by introducing a method to interact with the\ntoken contract. Users can build a mixer contract for additional functionalities\nlike setting an emergency recovery function in case of the loss of private keys.\nERC1155 is a semi-non fungible token that combines the features from both\nERC20 and ERC721. The contact can manage multiple token types (e.g., NFT)\nwhere each type may contain a set of fungible tokens. In this way, it can process\ntransaction bundles with high e\ufb03ciency. ERC998, as an extension of ERC721,\n35\nis a composable non-fungible token standard. It enables the integration of dif-\nferent ERC721 and ERC20 tokens, in which one can hold another non-fungible\ntoken at the same time. These combined NFTs are connected by ownership\nand organized like a tree. Also, there are several types of standards used for\nspeci\ufb01c scenarios. ERC1238, non-transferrable non-fungible token (NTT), is de-\nsigned with attributes of non-transferability. This can be used in recording users\u2019\nreputation and experience (quantitative) or granting badges and titles (qualita-\ntive). ERC1410 adds an extra layer of granular transparency that can be used\nfor the investigation of contract behaviors in di\ufb00erent partitions. Another series\nof ERC20-extended standards, including ERC1400, ERC1404, ERC1461, and\nERC1594, are designed for the security tokens in \ufb01nancial markets and o\ufb03cial\ngovernments. Besides, we have noticed that BEP20 and BEP721 on Binance\nsmart chain, and ARC20 on Avalanche, inherit attributes and functions in ERC\nstandards, decreasing the cost of absorbing new bits of knowledge for newcomers.\nAppendix C. Languages in VM-empowered Blockchains\nDeploying the smart contract on-chain that contains the business logic is an\nessential procedure for Web3 services. As plenty of literature has introduced\nthe operating mechanisms of blockchain virtual machines (see the skeleton [93]\nin the left \ufb01gure in Fig.5) and security considerations of smart contracts, we\nskip these parts and put focus on \ufb01lling the blank of programming languages in\nVM-supported blockchain platforms (the right table in Fig.5), which is rarely dis-\ncussed but of great importance in the Web3 ecosystem. Smart contract program-\nming languages enable writing programs and logic according to the requirements\nof users. These languages are typically targeted toward primary developers, re-\nquiring them to be su\ufb03ciently friendly. A contract written in such languages,\nthen, is compiled to a bottom language such as binary codes to allow machines\nto execute. Corresponding actions are operated on-chain under the guide of spec-\ni\ufb01cations. We review existing smart contract programming languages to provide\na guideline for developers with the aim to build Web3 applications and services.\nSolidity is an undoubtedly \ufb01rst-ranked language used in current blockchain\nsystems. Bene\ufb01ts from the in\ufb02uence of Ethereum, Solidity has been widely\nadopted by most EVM-compatible blockchains such as Binance smart chain\n(BSC), Avalanche (c-chain), and Oasis Network (ParaTimes). The language is\nan object-oriented and statically-typed language that brings many similar de-\nsigns from matured programming languages such as C++ and Python. For in-\nstance, Solidity supports inheritance, libraries, and complex user-de\ufb01ned types.\nMeanwhile, the language is Turing-complete which enables multi-functional de-\nvelopments. Users can customize their methods to realize di\ufb00erent functional-\nities. Vyper is a contract-oriented language that aims to improve the security\nof Solidity. It has many features that are designed for smart contracts, such as\nevent noti\ufb01ers for listeners, custom global variables, and global constants. The\nlanguage cannot support complex features of inheritance, function overloading,\nin\ufb01nite-length loops, and recursive calling to make it simple enough. It can be\n36\nused in EVM-compatible systems without any barriers. Similarly, Yul is designed\nto be an intermediate programming language that can be compiled to the format\nof bytecode used for the adjustment of di\ufb00erent backends. The Solidity compiler\nhas an experimental implementation that uses Yul as an intermediate language.\nYul is used in stand-alone mode and for inline assembly inside Solidity. The\nlanguage supports both EVM and ewasm (Ethereum \ufb02avored WebAssembly).\nRust is a low-level statically-typed language, with features of being fast and\nmemory-e\ufb03cient. Also, no garbage collector exists in the language, meaning\nthat the incidents caused by the language will happen with a negligible possibil-\nity. Due to its high e\ufb03ciency, many blockchain systems have started to utilize\nRust as their smart contract languages, including Solana, Polkadot, and Near\nBlockchain. JavaScript is a general-purpose programming language, as well as an\nentry-level language that is adopted by most blockchains to create a JavaScript\nwrapper or library [94,95]. Hyperledger Fabric [96] and FastFabric [97] enable\nusers to create a smart contract with several languages, including JavaScript\n(Node.js). Besides these mainstream languages, many platforms propose cus-\ntomized languages. TEAL [98] is an assembly language syntax used in Algorand\n[99] to specify programs. The language will be converted to the bytecode that\ncan be recognized by its interpreter. Pact [100] is immutable, Turing-incomplete\nlanguage used in Kadena [101]. It uses a declarative approach over complex con-\ntrol \ufb02ow, which makes bugs easier to be detected. With the same scope, Dune\nNetwork [102], Sui [103] and Stellar [104] propose their customized languages\ncalled Liquidity, Move and SSC, respectively.\nLanguages\nBlockchain\nSolidity [105]\nEthereum, BSC, Avalanche\nRust [106]\nSolana, Polkadot, Near\nJavaScript [107]\nHyperledger, FastFabric\nYul [108]\nEVM-compatible\nVyper [109]\nEVM-compatible\nTEAL [98]\nAlgorand\nSSC [104]\nStellar [110]\nPact [100]\nKadena [101]\nLiquidity\nDune Network [102]\nMove [111]\nSui[103], Diem[112]\nFig. 5: VM-empowered Blockchains Operations and Programming Languages\nAppendix D. Web3 Projects\n37\nTable 3: A Collection of Web3 Projects\nFunctionality\nProject\nFeature\nApplication\nDAO\nMakerDAO [58], OceanDAO [113]\nVoting-based Rights\nSyndicate [114], Utopia [115]\nDApps\nArbol [116], Etherisc [117]\nParametric Insurance\nTheta [32], Livepeer [69]\nStreaming Media (Video)\nRoyal [118], Audius [33]\nStreaming Media (Audio)\nMirror [119], Creaton [120], Gari [121]\nContent Management\nRadicle [53], Gitcoin [122], Yearn [55]\nCode Repository\nLinkdrop [123], Cointra\ufb03c [124]\nUser Acquisition\nManifold [125], CloutArt [126], NiftyInk [127]\nNFT Platform\nSteem [128], Akasha [129]\nSocial Network\nCyberconnect [130], Coinvise [131], Rally [132]\nSocialFi\nAxie In\ufb01nity [11]\nGameFi\nMyNFTeam [133]\nEmployment Platform\nStatus [134]\nMessaging\nAccess\nIdentity\nIDX [39], Violet [135], Litentry [136]\n(W3C)DID-compatible\nCeramic [39], Spruce ID [137]\nWallet\nMetaMask [78], Crypto.com [138]\nZapper [139], Rainbow [140], Zerion [141]\nClient\nWeb3.js, Ethers.js, Haskell [142]\nEthereum\nAnchor [143], @solana/web3.js [144]\nSolana\nAuthentication\nWeb3auth [38], Civic [145]\nLink (Web2)Account with Address\nBrowser\nBasic Attention Token [62]\nComputation\nOracle\nChainlink [81]\nCapture External Data\nFlux [146]\nIndexing\nThe Graph [50]\nLayer-1\nBlockchain\nEthereum, BSC, Avalanche, Celo\nEVM-compatible Chains\nCosmos, Polkadot, Solana\nCompetitive Chains\nNear, Celo, Aurora, Fantom, Tezos\nLayer-2\nBlockchain\nPloygon [147]\nSidechain\nZkSync [148], Starknet [149]\nZKrollups [150]\nOptimism [151], Arbitrum [152]\nOptimistic Rollups [153]\nStorage\nO\ufb00-chain Data\nCeramic Network [40]\nThreadDB [154], GunDB [155]\nFile Storage\nIPFS [19], BitTorrent [156]\nDistributed File Storage\nArweave [45], Siacoin [51]\nSupporting Tech\nDeveloping\nTool Set\nTru\ufb04e [41], Hardhat [157]\nJavaScript\nFoundry [158]\nRust\nBrownie [159], Alchemy [42]\nPython\nAnkr [43], Settlemint[160]\nOcean [113], Infura [82]\nStatistical\nTools\nDeepdao [161], Snapshot [162], Tally [163]\nDAO\nNansen [164], Token Terminal [165]\nTracing Data Movement\nMessari [166], The Block [167], Web3 Index [44]\nData Dashboard\nInfrastructure\nHelium [52]\nWireless Network\nNEON [168]\nEVM in Solana\nENS [169], Bon\ufb01da [170]\nName Service\nAPI3 [171], Ankr [43], Pocket Network [172]\nAPI\nDeeper Network [54], Datahub [173]\nGateway\nGetblock [174]\nNode Service\nMoralis [175]\nSDK\nQuicknode [176]\nAnalytics\nFigmentLearn [177]\nEducation platform\n38\n",
    "2304.06032": "Web 3.0: The Future of Internet\nWensheng Gan\u2217\nJinan University\nGuangzhou, China\nwsgan001@gmail.com\nZhenqiang Ye\nJinan University\nGuangzhou, China\nyzq66f@gmail.com\nShicheng Wan\u2020\nGuangdong University of Technology\nGuangzhou, China\nscwan1998@gmail.com\nPhilip S. Yu\nUniversity of Illinois at Chicago\nChicago, USA\npsyu@uic.edu\nABSTRACT\nWith the rapid growth of the Internet, human daily life has become\ndeeply bound to the Internet. To take advantage of massive amounts\nof data and information on the internet, the Web architecture is\ncontinuously being reinvented and upgraded. From the static infor-\nmative characteristics of Web 1.0 to the dynamic interactive features\nof Web 2.0, scholars and engineers have worked hard to make the\ninternet world more open, inclusive, and equal. Indeed, the next\ngeneration of Web evolution (i.e., Web 3.0) is already coming and\nshaping our lives. Web 3.0 is a decentralized Web architecture that\nis more intelligent and safer than before. The risks and ruin posed\nby monopolists or criminals will be greatly reduced by a complete\nreconstruction of the Internet and IT infrastructure. In a word, Web\n3.0 is capable of addressing web data ownership according to dis-\ntributed technology. It will optimize the internet world from the\nperspectives of economy, culture, and technology. Then it promotes\nnovel content production methods, organizational structures, and\neconomic forms. However, Web 3.0 is not mature and is now being\ndisputed. Herein, this paper presents a comprehensive survey of\nWeb 3.0, with a focus on current technologies, challenges, oppor-\ntunities, and outlook. This article first introduces a brief overview\nof the history of World Wide Web as well as several differences\namong Web 1.0, Web 2.0, Web 3.0, and Web3. Then, some technical\nimplementations of Web 3.0 are illustrated in detail. We discuss\nthe revolution and benefits that Web 3.0 brings. Finally, we explore\nseveral challenges and issues in this promising area.\nCCS CONCEPTS\n\u2022 Computing methodologies \u2192Web 3.0.\nKEYWORDS\nInternet, Web evolution, Web 3.0, Overview, Opportunities.\n\u2217Also with Pazhou Lab, Guangzhou 510330, China\n\u2020Corresponding author: scwan1998@gmail.com\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nWWW \u201923 Companion, April 30-May 4, 2023, Austin, TX, USA\n\u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-9419-2/23/04...$15.00\nhttps://doi.org/10.1145/3543873.3587583\nACM Reference Format:\nWensheng Gan, Zhenqiang Ye, Shicheng Wan, and Philip S. Yu. 2023. Web 3.0:\nThe Future of Internet. In Companion Proceedings of the ACM Web Conference\n2023 (WWW \u201923 Companion), April 30-May 4, 2023, Austin, TX, USA. ACM,\nNew York, NY, USA, 10 pages. https://doi.org/10.1145/3543873.3587583\n1\nINTRODUCTION\nThe history of the development of the World Wide Web consists of\nfour phases, i.e., Web 1.0, Web 2.0, Web 3.0, and Web3. Thanks to\nscientific and technological innovation, we have experienced the\nWeb 1.0 era and live in a period of Web 2.0, Web 3.0, and Web3\ncoexistence. The innovator of the World Wide Web, Timothy John\nBerners-Lee1 proposed a distributed hypertext system, called the\nWeb (or Web 1.0) [6]. He also designed and built the first web\nbrowser2 and published the first website3. The initial Web is a\nlinked information system, which is based on graph and link orga-\nnization mode. A significant feature of Web 1.0 applications is static\npages. Visitors are permitted to perform a few simple operations,\nsuch as reading and clicking. It is so monotonous that few peo-\nple were interested. After that, Web 1.0 applications continued to\nevolve to be more versatile and easier to use. The second-generation\nWeb, called Web 2.0, was proposed in a brain-stream forum [44].\nCompared to Web 1.0, users are no longer just reading or down-\nloading content from static websites. They are capable of writing or\nuploading various creations on the internet. The interaction is vital\nfor Web 2.0 architecture. A lot of novel technologies (e.g., asynchro-\nnous JavaScript and XML, Cascading Style Sheets, the document\nobject model, and JavaScript object notation) make users enjoy\nrich experiences [46]. Until now, Web 2.0 inspired many young\npeople\u2019s creative enthusiasm and encouraged them to participate.\nSocial media platforms (e.g., Facebook, WeChat, TikTok, and Twit-\nter), video and music websites (e.g., YouTube, BiliBili, and Spotify),\nand e-business platforms (e.g., Amazon, Tmall, eBay, and Walmart)\nare relatively mature and full of all aspects of our lives in the past\ndecades [20].\nHowever, on the one hand, whether users are voluntary or not,\ntheir application data belongs to the corresponding Web 2.0 plat-\nforms; on the other hand, these platforms collect users\u2019 data as\nmuch as possible and then maximize their revenue [2]. It should\nbe pointed out that users generally do not know how and for what\ntheir information will be used. Web 3.0 [7, 28] provides a more\n1https://en.wikipedia.org/wiki/Tim_Berners-Lee\n2WorldWideWeb: https://worldwideweb.cern.ch/worldwideweb/\n3http://info.cern.ch/ or https://worldwideweb.cern.ch/browser/\narXiv:2304.06032v1  [cs.CY]  23 Mar 2023\nWWW \u201923 Companion, April 30-May 4, 2023, Austin, TX, USA\nGan et al.\nTable 1: Differences among different stages of webs\nWeb\nArchitecture\nRepresentative products\nCharacteristics\nBenefit distribution\nWeb 1.0\ncentralized\nYahoo, Sina, Netscape\nhost-generated content,\nhost-generated authority\nplatform monopoly\nWeb 2.0\ncentralized\nBaidu, Google, Facebook\nuser-generated content,\nhost-generated authority\nprofit-sharing (platforms\nand netizens)\nWeb 3.0\ndistributed,\ndecentralized\nTor, Twine\nuser-generated content,\nuser-generated authority\npeer-to-peer\nWeb3\ndistributed,\ndecentralized\nEthereum, Binance\nuser-generated content,\nuser-generated authority\nsmart contract\ntransparent architecture (i.e., decentralized). In the view of Tim-\nothy John Berners-Lee, Web 3.0 aims to create a more intelligent\nweb, which emphasizes machine understanding of human seman-\ntic expression [5, 7, 57]. Later, Ethereum co-founder Gavin Wood\nthinks that centralized services cause a lot of corporate monopolies,\nand thus the next Web flood will completely change the status of\nWeb 2.0 [71]. He believes that the next generation of the Web will\nbe an identity-based pseudonymous low-level messaging system.\nIn order to make it distinct from traditional Web 3.0, he renamed it\nWeb3. Web3 architecture achieves decentralization via blockchain\ntechnologies, whereas Web 3.0 may not require blockchain. Today,\nWeb 3.0 is a broad but borderless concept. It has integrated powerful\nand large-scale Web applications. We suppose Web 3.0 is a powerful,\ngeneric, and measurable architecture.\nTable 1 summarizes the differences between four types of Webs.\nWeb 1.0 is the informational internet. It only offers a reading expe-\nrience for users; there is no interaction or dynamic content. Web\n2.0 is synonymous with identity and a centralized Web. Users be-\ncome content creators and are willing to communicate with others\nthrough Internet tools. However, it is hard to break down the infor-\nmation blockade between platforms. Web 3.0 and Web3 are both\nuser-generated content and user-generated authority. That is, users\ncan determine what and how much information other people and\nplatforms can view. This allows users to truly own their data.\nThere are some reviews of literature related to Web 3.0 [27, 38,\n40, 47, 55, 69]. Most of them had not clearly distinguished between\nWeb 3.0 and Web3. For instance, because blockchain is known for\nimplementing a new organization governance model (i.e., decentral-\nization), it is easy to take it for granted that blockchain technology\nis the most suitable tool within Web 3.0 architecture. However, cur-\nrent blockchain technology is not mature, and its financial hype is\nconcerning (see [19]). Though Web 3.0 is a buzzword, most people\nare still unclear about it, especially its definition. Web 3.0 will fa-\ncilitate a worldwide data reform, which may trigger opportunities\nand risks. There is no doubt that providing a detailed illustration\n(what, how, and when) is valuable.\nTo fill this gap, this paper aims to conduct a systematic literature\nreview of Web 3.0. The key contributions of the article are fourfold.\n\u2022 We elaborate on the evolution history of the World Wide\nWeb, which reveals that there have been unprecedented ad-\nvances in the pursuit of democracy within the digital world.\n\u2022 We introduce some vital Web 3.0 technologies, from data\nstorage to information analysis and usage. Additionally, We\nidentify the key difference between Web 3.0 and Web3.\n\u2022 In particular, we provide a detailed survey of the Web revo-\nlution and the benefits in every aspect of our lives (including\nbusiness, culture, Metaverse, and AI-generated content, etc.)\nthat Web 3.0 brings.\n\u2022 Finally, we highlight and discuss some key challenges and\nfuture work based on our review. We also make some rec-\nommendations for Web 3.0 governance and development.\nOrganization: This article summarizes recent Web 3.0 advance-\nments. In Section 2, we introduce several vital technologies within\nthe Web 3.0 architecture. The revolution and benefits of Web 3.0\nare then briefly introduced in Section 3. In Section 4, we discuss in\ndetail the existing or emerging challenges and issues of Web 3.0. We\nalso discuss the difference between Web 3.0 and Web3 in Section 5.\nFinally, in Section 6, we conclude this article with discussions and\npotential future work.\n2\nTECHNICAL IMPLEMENTATION\nDespite the lack of a unified definition of Web 3.0, major features\nsuch as decentralization, privacy protection, human centricity, and\nintelligence are widely accepted [58]. In the Web 3.0 world, ma-\nchines will better understand human behavior, which will provide\nmore intelligent services. In this section, we introduce some tech-\nnologies that might become cornerstones of Web 3.0.\n2.1\nSemantic Web\nThe semantic web [7], a prototype of Web 3.0, is an information-\ndata web that aims to concatenate all the data in the virtual world.\nWith the rapid development of science and technology, proposals to\nmanage the abundance of web data (e.g., data sharing, integration,\nreuse, and mining) are one of the major obstacles [32, 57]. Resource\nDescription Framework (RDF) [43] is a syntax-neutral data model\n(i.e., Subject, Predicate and Object). RDF records the relationship\nbetween elements Subject (e.g., links) and Object (e.g., resources)\nand describes the features of web resources. It mainly provides an\ninfrastructure for various applications of metadata and exchanges\nmetadata between applications on the Web, which promotes the\nautomatic processing of network resources [20]. Subsequently, the\nWeb Ontology Language (OWL) [42] was proposed to improve the\ncomprehensibility of web content for machines and play a part in\nsemantic web activity. It is a family of knowledge representation\nlanguages for authoring ontologies. Ontologies resemble class hier-\narchies in object-oriented programming, and the core idea of OWL\nis to represent the ontology explicitly and efficiently [33]. The OWL\nWeb 3.0: The Future of Internet\nWWW \u201923 Companion, April 30-May 4, 2023, Austin, TX, USA\nis used to make network resources more accessible for automated\nprocesses by adding resource information that describes or provides\nweb content. Besides, knowledge graphs (KG) [9, 59] may be the\nnext direction for knowledge representation on the semantic web. A\nknowledge graph consists of a set of interconnected typed entities\nand their attributes [3, 8]. According to the study [24], there are four\nmain steps for KG generation: 1) knowledge creation; 2) knowledge\nhosting; 3) knowledge curation; and 4) knowledge deployment. KG\nmay be the most possible way to achieve the \u201cInternet of Behaviors\u201d\n(IoB) blueprint [62], which can build connections between people\nand things, or things and things.\n2.2\nArtificial Intelligence\nBenefiting from the improvement of computing power and big data\ntechnologies [26], AI has ushered in a period of vigorous devel-\nopment. AI is becoming a part of our daily lives as more domains\ndeploy AI applications [30, 31]. We can provide numerous datasets\nand use AI training models for solving problems such as image\nrecognition, information extraction, and automatic speech recogni-\ntion. In the Web 3.0 era, massive amounts of data will be generated\nevery day from device perception, content services, and intelligent\nlife. AI helps machines realize the \u201cperception-decision-behavior-\nfeedback\u201d closed-loop workflow, and thus improve the user expe-\nrience. Moreover, since the integration of computing and storage\nbreaks the bottleneck of AI computing power, the development of\nIoT collaborative perception and 5G communication technologies\nwill realize the collaboration between multiple agents, which can\nmeet people\u2019s needs for real-time perception and decision-making.\nMany other fields have made great progress by enabling AI. For\nexample, autonomous driving [23], according to the in-depth inte-\ngration of IoT and AI, offers the best route planning and control\nfor vehicles. Market forecasting and risk management in financial\nmarkets, medical assistance in the health industry, recommenda-\ntion systems, unmanned retail in the retail industry, voiceprint\npayment, face scanning in payment systems, and voice in the smart\nhome are all examples of how technology is changing our lives\n[73]. All of the above cases illustrate how AI makes Web 3.0 more\nintelligent and user-friendly. However, because AI products have\na great impact on our lives, fairness, and non-discrimination (in-\ncluding objective and subjective) in the development of AI will be\nparticularly important. For example, the usage of big data is uneth-\nical and malicious behavior by companies toward their customers.\nIn some cases, AI products serve some groups but ignore the re-\nquirements of specific groups (e.g., the elderly and the disabled).\nIn the Web 3.0 era, data ownership belongs to users because they\ngenerate new data every day. These data may be meaningless to\nusers, but companies can profit from a variety of data using AI\ntechnologies, such as user profiles and personalized advertising.\nThe definitions of fairness are distinct in different historical periods\nand even in different ideologies. Fortunately, AI technologies can\nimprove fairness and transform it into a global and comprehensive\nunderstanding, which provides a powerful guide to achieving fair-\nness. Moreover, with the development of technology (e.g., federated\nlearning, trusted computing, the Internet of Things, Internet of\nBehaviors, and encryption), most negative effects that technology\nbrings will be eliminated in most cases [16, 17].\n2.3\nBlockchain\nThe emergence of an embryonic blockchain was taking shape from\nthe 1980s to the 1990s and was officially released in 2008 [45, 72].\nMany experts, scholars, and capitalists are interested in the poten-\ntial of blockchain technology because of its decentralization, trust-\nlessness, autonomy, anonymity, tamper-proofing, and auditability\n[74]. One of the most famous successful cases is Ethereum [12].\nEthereum provides a built-in Turing-complete programming lan-\nguage, which can help developers code smart contracts and build\ntheir own decentralized applications. Ethereum yellow paper (\u201ca\ncanonical version\u201d) [71] provided a quasi-Turing-complete machine\ncalled the Ethereum Virtual Machine. To protect smart contracts\nfrom malicious attacks, the Ethereum Virtual Machine provides\na sandbox execution environment. Arguably, the proposed novel\nunderlying technologies, such as token systems, identity and rep-\nutation systems, decentralized file storage, and decentralized au-\ntonomous organizations within the blockchain, can help fight the\nmonopoly posed by giant tech companies. Some metrics are pro-\nposed to evaluate the decentralization of blockchain. For example,\nthe studies [21, 29, 37] illustrate several related metrics. Croman et\nal. [22] proposed a more intuitive method. They believe that the\nmore active addresses on the blockchain, the better the blockchain\u2019s\ndecentralization.\nMoreover, semantic blockchain and knowledge-based blockchain\nmay be the next technologies among the most widely accepted in\nWeb3 (not Web 3.0) [56]. The internet service within semantic\nand knowledge-based blockchains not only has decentralized and\ntrustless features but also takes advanced advantage of artificial\nintelligence. What\u2019s more, the \u201cimpossible trinity problem\u201d (that is,\ndecentralization, privacy, and scalability) seems unsolvable for a\nlong time. This case will urge researchers and developers to explore\nother paths for decentralization solutions thereafter.\n2.4\nDecentralized Storage\nBefore starting this subsection, we have to point out that decen-\ntralized storage is not a necessary part of Web 3.0 architecture, but\ndecentralization will be more secure and reliable than centralization.\nThere has long been some sort of unspoken agreement between\nusers and Web 2.0 applications. That is, users\u2019 data belongs to plat-\nforms, and users just use the services provided by those platforms.\nMoreover, \u201cdata island\u201d between different platforms also brings\nmany barriers, such as data migration and data synchronization. In\nthe meanwhile, while users realize their data autonomy, lowering\nthe data storage cost and finding a suitable benefit distribution are\nurgent problems to be solved. In order to implement decentralized\ndata storage, researchers made the following contributions:\nIPFS: The Interplanetary File System (IPFS) [4, 15] is a peer-\nto-peer distributed file system, which may replace HTTP4 in the\nfuture. It splits files into several blobs (an addressable unit of data\nwith no links, and its size will not be larger than 256 KB). These\nblobs are organized by the file object \u201clist\u201d or alternatively \u201ctree\u201d.\nThe blob has a hash fingerprint, which is recorded in the distributed\nhash table according to a value-key structure (<hash fingerprint,\nlocation node>). IPFS adopts the Merkel directed acyclic graph\nto locate content and deduplication. Moreover, IPFS provides a\n4https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol\nWWW \u201923 Companion, April 30-May 4, 2023, Austin, TX, USA\nGan et al.\nversion control function like Git for helping user management. In\norder to adapt to users\u2019 reading habits, the adopted Inter-Planetary\nNaming Service maps the URLs to a series of hashes in the IPFS\nsystem. More importantly, the sharing strategy BitSwap prevents\nfreeloaders from exploiting and degrading the exchange [41].\nCephFS: Ceph file system (CephFS) [70] is known for being\nopen-source, distributed, high-performance, highly available, and\nscalable. The Reliable Autonomic Distributed Object Store (RADOS)\nclusters are its core part. The cluster consists mainly of object\nstorage devices (OSDs), monitors, and clients. OSD is a storage node\nin a cluster used for data storage and maintenance. The metadata\nserver cluster can expand or contract, and it can rebalance the file\nsystem dynamically to distribute data evenly among cluster hosts.\nMost importantly, RADOS does not rely on a single central control\ncomponent. Heavy loads all can be dynamically distributed within\nthe cluster. Thus, this makes sure that the physical decentralization\nand high scalability of CephFS.\nThere are still many decentralized storage projects out there. For\nexample, OpenStack Object Storage (Swift) [54], uses consistent\nhashing technology to evenly distribute objects to each virtual node\nand uses the ring structure to store the mapped physical address\nof virtual nodes. Finally, high availability and infinite horizontal\nexpansion ability are achieved by using the event-driven consis-\ntency model. Unlike the initial decentralized storage scheme, the\ncurrent hot decentralized storage scheme considers the user to be\nthe subject of participating in the data storage link. IPFS introduces\nthe BitSwap protocol to reward users for providing resource stor-\nage and download services, thus ensuring the possibility of users\nbenefiting from data. Existing projects like Filecoin and ARweave\nare based on IPFS, which can be considered the incentive layer of\nIPFS. There are other star projects, like Swarm for the Ethereum\nfoundation. The use of blockchain technology in conjunction with\na reward mechanism is becoming more common.\n2.5\nEdge Computing\nBecause of the COVID-19 epidemic, more and more of our daily\nactivities are happening online, which has led to a sharp rise in\nthe amount of data and network traffic around the world. The total\namount of data in the world in 2020 was already 59 ZB. Under the\nimpact of such a huge data stream, all data processing is placed on\nthe remote server, which will be a great challenge to the network,\ncomputing resources, and so on. Although some data processing\nproblems can be alleviated through cloud computing, the propor-\ntion of valuable data in massive data sets is very low. Therefore, it\nis necessary to process the data at the beginning of its generation\nand then analyze it through the cloud. In order to solve this prob-\nlem, edge computing and fog computing were proposed [14, 31, 75].\nSome tasks are processed through edge devices, in this way, the\npressure of cloud computing can be shared. The main difference\nbetween edge computing and fog computing is that edge computing\nallows the end devices to process data by themselves [66]. The main\nidea of edge computing is to migrate core functions like computing,\nstorage, and decision-making closer to the edge devices that gen-\nerate the data. As a result, the edge computing model eliminates\nthe need to upload data to a cloud computing platform for storage\nand processing. Moreover, as edge computing is closer to the data\nsource, it has fast data processing and analysis and low cost, low en-\nergy consumption, and low bandwidth. Although edge computing\nhas a certain improvement in the security aspect when compared\nwith cloud computing since it can avoid the risks during the net-\nwork transmission process, the edge device obtains first-hand data,\nwhich has a large amount of sensitive private information. Due to\nthe lack of effective encryption or desensitization methods for data,\nwhen an emerging hacker attacks the edge node, critical informa-\ntion such as household personnel consumption, personnel health\ninformation in the electronic medical system, and road incident\nvehicle information will be leaked. Federated learning (FL) [68]\ntrains AI models by coordinating multiple remote devices and not\ndirectly exposing users\u2019 data, which enhances the privacy of data.\nThe combination of edge computing and FL will provide a more\nsecure environment for edge nodes and protect the information\nsecurity of users. In general, edge computing can effectively ex-\nplore the potential of edge devices and provide users with more\nhigh-quality services in the era of big data.\n3\nREVOLUTION AND ADVANTAGES\n3.1\nApplication and Business\nWeb 1.0. In the early years of Web 1.0, the proliferation of the birth\nof the World Wide Web spurred a growing need for knowledge\nsharing that cannot be met solely by traditional information trans-\nmission methods. Many companies, like Sina, Yahoo, Google, and\nBaidu, have promoted their own products. As shown in Figure A1,\nthese products can be roughly divided into two categories. The\nfirst one is the web portal represented by Sina and Yahoo. In view\nof knowledge creation, these web portals aim to digitalize human\nknowledge from offline to earn profit online through clicks. The sec-\nond is represented by the search engines of Google Search and Baidu.\nThey are used to answering users\u2019 questions as accurately as possi-\nble. The search engine does not actively share content with users.\nIt seems like a library on the Internet and automatically collects\nor categorizes various types of information. Through continuous\ndevelopment, Google Search has been one of the most intelligent\nand powerful search engines in the world. As mentioned earlier,\nboth the two categories of web products are host-generated content\nand authority. On the one hand, users can only read what websites\nhave to offer; on the other hand, Web 1.0 enabled numerous people\nto learn about and engage with the Internet.\nWeb 2.0. With the rapid growth of the number of internet users\nin the world, the occurrence of Web 2.0 has attracted considerable\nattention. Unlike Web 1.0, the new Web lets users create content\non many different online platforms. In other words, a significant\ndifference between Web 1.0 and Web 2.0 is that the latter is user-\ngenerated content rather than host-generated content. According\nto Web 2.0 products, both users and platforms can earn profits.\nThe current web products have more vertical subdivisions than\nin the Web 1.0 era. Figure A2 lists some major applications in our\ndaily lives. Herein, we plan to introduce some of them to reveal\nthe success of Web 2.0. WeChat is very popular in Asian regions. It\nreplaces the traditional text message service of mobile operators\nto a certain degree because of its novel functions (e.g., video calls\nand group chats). Twitter is one of the most famous social network\napplications now. With unique characteristics, such as character\nWeb 3.0: The Future of Internet\nWWW \u201923 Companion, April 30-May 4, 2023, Austin, TX, USA\nlimits and photo sharing, it provides text message services over the\ninternet for users. Twitter is also an information-sharing platform\nand forms many grid communities. People around the world can\nshare their daily lives or interact with others by posting a tweet. The\ni Operating System (iOS) is a mobile device system developed by\nApple Inc. In the Web 2.0 era, the mobile phone totally changes the\nlifestyle of humans. iOS and its competitors (Android5) are vehicles\nthat run applications from Web 2.0. Due to the breakthrough in\nhardware research, the applications of Web 2.0 are more powerful\nand practical than the websites of Web 1.0. These applications are\nconvenient for human activities, and most of us cannot imagine\nhow to live without the Internet.\nWeb 3.0. As reported in some white papers [13, 34, 51], the\nrapid growth of the current digital economy, especially after the\nCOVID-19 outbreak, has led to a lot of monopolist giants (e.g., Face-\nbook, Google, Tencent, and Amazon). Now we face the challenge\nof extracting the world from the jaws of online platform monop-\nolies. The applications within Web 2.0 are more likely to provide\nservices rather than products. This causes the traditional concept\nof data ownership to become blurry. Besides, most Web 2.0 com-\npanies are profiting from users\u2019 private information. The study\n[64] points out that digital ethics and privacy issues within the\ninternet need more attention. Web 3.0 is engendering a new global\ndigital economy. It creates new business models and markets to go\nwith them, and it busts platform monopolies. Web 3.0 applications\nare deployed on decentralized networks such as blockchain plat-\nforms or related distributed systems hosted by many peer-to-peer\nservers. They are designed based on different scenarios. In order\nto concretely study the difference between applications of Web\n2.0 and Web 3.0, we list mainstream applications within the same\nclassification in Figures A2 and A3, respectively. Status is a secure\nmessaging application that provides private communication. It uses\npeer-to-peer technology to prevent any third party from controlling\nusers\u2019 communication data. This is totally different from WeChat.\nOn account of our data being stored on the platform, there are po-\ntential attack risks like data trawling, censorship, and propaganda\n[60]. The pseudo-anonymous account generation allows users to\nselectively reveal themselves to the world. Status, in particular, is\nan entirely open-source project. This is a common characteristic\nof most Web 3.0 applications, which can ensure the application is\nnot malicious. Steemit [18] is a rising star among the many Web\n3.0 social network applications. It is a blockchain-based platform\nthat aims to return data power to its users rather than centralizing\ncontrol by traditional social media companies. Steemit also uses\nthe eponymous cryptocurrency STEEM6 to reward users for their\ncontent. Electro-Optical Systems (EOS) is a blockchain operating\nsystem that provides the core functionality for businesses to build\nblockchain applications. EOS is similar to the Windows platform,\nand the system architecture is EOS.IO7. Compared to Android and\niOS, EOS runs on a public chain. The user only needs a browser that\ncan link to EOS within a mobile phone, iPad, or computer device,\nwhich is truly cross-platform.\n5https://en.wikipedia.org/wiki/Android_(operating_system)\n6https://observer.com/2016/09/steem-tsu-social-networks-spam/\n7https://en.wikipedia.org/wiki/EOS.IO\n3.2\nCulture and Artwork\nIndeed, the interaction between culture and society is common.\nWhat\u2019s more, it should be pointed out that: on the one hand, cul-\ntural production may not generate social activities; on the other\nhand, social activities may not create new cultural products. Cul-\ntural activities can be roughly divided into two parts: cultural cre-\nation and cultural communication. The process of culture creation\nwithin Web 3.0 architecture is more transparent than ever before.\nIt allows other people to freely engage in co-creation. Because each\nperson\u2019s contribution is clear, it is simple to distribute the benefit\nand copyright. At the same time, every node can make peer-to-peer\ntransactions since Web 3.0 is a decentralized network. Thus, there\nis no need for a third-party agent or platform to help creators sell\ntheir products. This case not only increases creators\u2019 earnings but\nalso provides them with more options. Furthermore, Web 3.0 com-\nbines various types of information based on the needs of the users\nand then provides personalized recommendation services. Since the\nprofit belongs to the creators themselves, they have more incentive\nto promote their works. Cultural heritage or productions are prob-\nlematic because they are non-renewable, fragile, and expensive to\nmaintain. They can be digitized by massive sensors, according to\nWeb 3.0 technologies. The methodology of digital humanities brings\nabout fundamental changes in cultural heritage. Through digital\nmethods, cultural heritage can be better protected, and cultural\ninformation can be linked to the spatio-temporal framework. The\ntransformation of time and space can activate more users\u2019 partici-\npation enthusiasm and revitalize the vitality of cultural heritage.\n3.3\nUser Experience\nThe forthcoming wave of Web 3.0 is promoting technical integra-\ntion across different domains. It may be the most anticipated event\nduring the 21st century. We plan to roughly discuss the user experi-\nence in terms of compatibility, permissionlessness, and availability.\nCompatibility: As we mentioned before, different Web 2.0 ap-\nplications (either homogeneously or heterogeneously) often have\ndata segregation problems when transferring data across products,\nsuch as a uniform format, inconsistent data, distinct coding mecha-\nnisms, etc. However, Web 3.0 provides many standardized APIs that\nsolve this problem to a certain extent. Applications and services\nare no longer limited by a single ecosystem (e.g., the Ethereum\necosystem and Bitcoin). Web 3.0 is a new integrated ecosystem\nthat is compatible with Web 2.0 to a certain extent. For example,\nCeramic8 tries to build applications with composable Web 3.0 data\nand enable reusable data for multiple scenarios. The unique dig-\nital wallet within Web 3.0 is adapted to store user internet data,\nwhich brings a number of benefits. For example, the encryption\ntechnologies can ensure the privacy and safety of a digital wallet,\nand the third party can ask for data reading permission from the\nuser. This solves the problem of data silos, which belong to Web\n2.0, and users of Web 3.0 do not have to worry about loss of data\nissues from replacing devices or platforms anymore.\nPermissionless: Meanwhile, users\u2019 application data no longer\nbelongs to online platforms or governments. Users can fully con-\ntrol assets and metadata, and optionally release them to service\nproviders according to their personal preferences. For instance,\n8Ceramic network: https://ceramic.network/\nWWW \u201923 Companion, April 30-May 4, 2023, Austin, TX, USA\nGan et al.\nTimothy John Berners-Lee proposed a novel Web data protocol,\nnamed Social Linked Data9, to constrain web infringing activities.\nHe also designed the POD, which can be established on a personal\nserver or hosted by a third-party platform, to store user data. Other\napplications can only request the users\u2019 authorization to obtain\nthe permitted information. The user application data (e.g., account,\npassword, browsing history, bookmarks, and related items) will\nonly be recorded on the POD. In other words, the user data is no\nlonger bounded to any platform, but the platform needs to request\nthat the user read the needed data. In this case, users can directly\ninteract with others who they are not familiar with or without the\nneed for a trusted third-party platform. The only thing that needs\nto be provided is the user\u2019s private key or other identifiable proof.\nHigh availability: Web 3.0 is an open and free world where all\nweb data is stored in public community networks. What\u2019s more,\na huge number of data put forward higher criteria for the new\nnetwork architecture: a high fault tolerance rate and low fault prob-\nability. This means that users are capable of using data normally\nin abnormal environments and scenarios. In addition, easy-to-use\nis one of the highlights of Web 3.0 applications and software. The\ndesign of application or software enables users to focus on their\nperception, their own tasks, and their operations according to their\nown course of action. They are not required to be distracted by\nsearching for the human-machine interface\u2019s menu or understand-\ning the structure of software, the human-machine interface, and\nthe meaning of the icons [25, 49]. They also do not have to consider\nhow to convert their tasks into the input mode and steps of the\nmachine. Because the virtual world is more integrated with the real\nworld, users are no longer limited to the previous input devices,\nsuch as keyboards or microphones. A look or a simple action (e.g.,\nraising hands and nodding) are input instructions for machines.\n3.4\nMetaverse\nThe word \u201cmeta\u201d means beginning, important, and consummation.\nThe Metaverse is a mixture of virtual and real worlds. The Web\n3.0 architecture provides lower-level support for building Meta-\nverse applications. Immersive interactive technology (e.g., VR, AR,\nand MR) can create a more attractive digital living space for users.\nThe Metaverse will significantly change the following domains:\n1) Education and training. A virtual educational environment fa-\ncilitates educators\u2019 ability to teach students. Besides, immersive,\ninteractive learning environments let students better understand\nknowledge. Recently, Lin et al. [39] provide an overview of Meta-\nverse in education; 2) Entertainment. It seems that Metaverse in the\nentertainment market (e.g., playing games, watching a movie, and\nsinging) is most successful currently. The digital reality experiences\nsolve the limitations of space and time. Meanwhile, recreational\nactivities can greatly assist students in broadening their interests;\nand 3) Security and privacy. It is doubtless that Web 3.0 architecture\nplays a vital role in data protection. That is, the user can control\nall aspects of their usage data. Decentralized identity effectively\nprevents users from identity theft and many cybercrime [17]. For\nlack of space, we do not list all aspects of Metaverse influences. In\nbrief, the Metaverse will have a disruptive impact on smart cities,\nsocial activity, and economics within Web 3.0 [1, 61, 63].\n9https://solidproject.org/\nBased on previous experience in the development of the Web,\nTony Parisi proposed \u201cThe Seven Rules of the Metaverse\u201d [50]. That\nis, the Metaverse should be unique (rule #1) and can consistently\nbe self-upgraded (rule #7); the Metaverse should serve everyone\n(rule #2) and be open to everyone (rule #4); the Metaverse is not\ncontrolled by anyone (rule #3); the Metaverse plays as an accessi-\nble network (rule #6) and it should be hardware independent (rule\n#5). Though the Metaverse is suspected of being overhyped, this\ndoes not prevent it from providing a more reliable environment\nfor humankind in the future. Metaverse is just a tool for users to\nexperience the virtual world. The immersive experience greatly im-\nproves the ability of users\u2019 sensory perception. Metaverse will also\nforever change the internet devices users adopt. The relationship\nbetween Metaverse and Web 3.0 is more like the productive force\nand the relations of production. The Metaverse will eventually infil-\ntrate every aspect of our lives. The productive force that Metaverse\nbrings demands for novel relations of production. Web 3.0 ensures\nthat the relations between productions will retain decentralization,\ndata ownership, trustlessness, intelligence, connectivity, and ubiq-\nuity features. Web 3.0 offers basic web technologies and economic\nsupport for the Metaverse, which will facilitate the booming of\nproductive forces. In return, the development of Metaverse will\ncontinuously promote the maturity of Web 3.0. The decentralized\nrelationship of productivity, for example, is a catalyst for creator\neconomy reform, and the new economic model allows human work\nto better reflect labor value than previously.\n3.5\nAI Generated Content\nRecently, ChatGPT10 has attracted the most attention within academia\nand industry fields. As an AI chatbot, ChatGPT displays excellent\nunderstanding and the ability to write. The most impressive thing\nis that ChatGPT supports multiple rounds of conversations and\nresponses in real time. From OpenAI\u2019s first Generative Pre-trained\nTransformer (GPT) model to GPT-3 [10], to instructGPT [48] and\nthen ChatGPT, the iterative evolution of the model has brought\nmany surprises to people. AI has shown its remarkable ability in the\nfield of Natural Language Processing (NLP). In recent years, humans\nhave been the great creative force in art, literature, science, and\ntechnology. Nonetheless, AI-Generated Content (AIGC) is gaining\npopularity as a new mode of content production on the internet. It\nis foreseeable that NLP technology represented by chatGPT will un-\ndoubtedly be adopted in massive application scenarios in the future,\nsuch as no-coding programming, novel generation, conversation\nsearch engines, voice companions, artificial intelligence customer\nservice, and machine translation. Besides, an AI-generated picture\nsurprisingly won the blue ribbon in the fair\u2019s contest for emerging\ndigital artists [52]. Though it brings some worries about ethical\nconcerns and joblessness, we suppose it is a chance to reconsider\nart itself. When the camera first took a photograph, most people\ndid not expect the birth of photorealism.\nAI is not only a reliable and smart assistant for humans but also a\nproductive generator within Web 3.0, which will enrich the internet\nworld. Due to the fact that AI is better than humans at mining\nknowledge and organizing material, AIGC has revealed its great\npotential in creation. AIGC will produce surprisingly good results\n10https://openai.com/blog/chatgpt/\nWeb 3.0: The Future of Internet\nWWW \u201923 Companion, April 30-May 4, 2023, Austin, TX, USA\nif we provide enough data. Moreover, AIGC technology can help\nthe digital human be smarter because AIGC is able to enhance the\ndigital human\u2019s language understanding, action interaction, and\nemotion expressiveness. Similarly, Web 3.0 is able to advance in the\nfield of digital content. The Al tools help us solve any video or image\nlabeling task 10x faster and with 10x less manual work than before.\nIn fact, the cultural treasures of human history are priceless because\nthey are the result of human ingenuity. Humanity has evolved\nover more than six million years, and AI cannot rival our creative\nabilities forever. Although the purpose of Web3 is to protect the\ndata ownership of creators from monopolies, most current online\nplatforms are increasingly focusing on driving private traffic to\nearn revenue, which splits the internet world. The AIGC prevents\nthis wrong trend, such as ChatGPT. The open API culture should\nbe respected and continuing. In the Web 3.0 era, AIGC will be a\ncommon tool to assist people in content creation, which is cost-\neffective and greatly improves the quality of content.\n4\nCHALLENGES AND ISSUES\nAlthough Web 3.0 will finally break the data monopoly of central-\nized enterprises, there are a lot of challenges and issues that should\nbe carefully considered and solved. All of the above topics can be\nroughly classified into social, financial, legal, and technological\ncategories. We mainly discuss the top three parts below, and the\nlast one we have already discussed before.\n4.1\nSocialization\nNowadays, most people feel intolerable if their ties with the outside\nworld are cut. We may have a strong desire to connect with others,\nwhether they are nearby or at the other end of computers or phones.\nCyberspace provides a good place for us to communicate with each\nother, and we express our thoughts and emotions freely there. In\nmost cases, people surfing the Internet are communicating with\npeople (whether known or unknown) who are not around, and\nwe always expect to obtain reactions from others by sharing our\nown experiences. However, in general, the reality is not as good\nas you imagine it to be. Socializing in cyberspace may meet more\ntroubling issues than offline, such as the dissemination of rumors,\nracial discrimination, terrorism, and negative impacts on youth.\nDespite the fact that Web 3.0 is supposed to comprehend human\nexpressions and respond appropriately, we have to realize that there\nis still a long way to go before achieving this goal. As shown in\nFigure A3, though Steemit uses rewards to encourage users to create\nor find valuable posts, the group behavior is troubling. Web 3.0 still\nrequires further research to solve these problems.\n4.2\nIndependence\nCan Web 3.0 completely abandon the Web 2.0 architecture? The\nanswer that we believe is no. The prototypes of social media and\nnetworks already exist. As we mentioned, Web 2.0 has greatly en-\nriched people\u2019s lives on the Internet. It covers most users\u2019 online\nactivities and causes path dependence for certain companies. No-\ntice that it is hard for users to suddenly change their habits and\naccept new products. We take Steemit again as an example. Most\nof its functions are essentially the same as those of Twitter. In the\nview of users, both decide whether to push a post through others\u2019\nlikes, and others can forward their favorite posts to promote them.\nThe significant difference is that Steemit will reward users, while\nTwitter may just increase a few users\u2019 followers. In addition, many\nfunctions of existing Web 3.0 applications are not perfect and still\nrequire the support of the Web 2.0 architecture (e.g., browsers and\nregulations). In general, considering the current development of\nWeb 3.0 technologies, we cannot completely get rid of the influence\nof Web 2.0. We believe that Web 2.0 and Web 3.0 will coexist or\neven be complementary for a long period of time.\n4.3\nFinance and Crime\nUp to now, there are many decentralized finance products (e.g., NFT,\ncryptocurrency, and crypto exchange) in usage. These products all\nclaim that they can or will break the constraints of the original\ncentralized value-exchange financial system. Through decentral-\nization, the new financial services are more open, transparent, and\ninteroperable. However, we hold several viewpoints about the new\nfinancial system. The most-running Web3 products11 today are\nbased on their own special cryptocurrencies. Many transactions\nare done through these tokens (i.e., cryptocurrencies). Certainly,\nall deals between users are verifiable with the help of blockchain\nand smart contracts. What\u2019s more, the key premise on which these\ntransactions normally proceed is the credibility of the token. In\nother words, the value of a token depends on how well it is accepted.\nUnfortunately, the recent bankruptcy of the FTX exchange event\n[53] and Luna coin [11] shows that the cryptocurrency is unreli-\nable12. Since smart contracts provide users with many vital services,\nsuch as hosting and transaction processing, the decentralization\nexchange totally relies on the security of smart contracts. Until now,\nmost decentralization exchanges hired or outsourced employees to\ncomplete code auditing work. It is not only more difficult but also\nmore expensive.\n4.4\nGovernance and Organization\nAs the saying goes, there are two sides to a coin. Web 3.0 can\nsolve data ownership issues and promotes data protection, while\nit also brings some challenges in governance, such as a regula-\ntory puzzle, heavier wealth gaps, and money laundering [65]. It\nseems that someone who holds numerous cryptocurrencies will\nbe the new monopoly in Web 3.0. The old monopolies have the\nfirst-mover advantage because of their wealth. Due to the data pro-\ntection mechanism, it is hard for the public to regulate the profitable\nways of corporate monopolies. The government faces more difficult\ntroubles, such as cracking down on economic crime. For instance,\nsomeone who engages in financial fraud, stock manipulation, or\ninsider trading will be punished because a centralized government\nmust maintain the fairness of trading and prevent illegal activities.\nHowever, the slogan \u201cTo the moon\u201d can let Dogecoin generate a re-\nturn of about 150 times, and the \u201chustle\u201d word means that the token\nhas lost almost 92% of its value since. This is a disguised plunder\nof wealth, but no one was punished for it. This causes instability\nin society [36]. As a result, a series of unresolved arguments about\ndata, surveillance, competition, and security will spill over from\n11Please attention! Not Web 3.0 products.\n12Crypto exchange is an online financial platform that allows buyers and sellers to\ntrade cryptocurrencies. There are decentralization and centralization models.\nWWW \u201923 Companion, April 30-May 4, 2023, Austin, TX, USA\nGan et al.\nthe virtual world into the real one. Besides, it is worth noting that\ncryptocurrency is not equal to the whole economic construction of\nWeb 3.0. Governments should enact the necessary regulatory stan-\ndards in order to assist Web 3.0 in safely and smoothly completing\nits brutal stage.\n4.5\nLaw-making\nAdditionally, the emergence of cryptocurrencies, particularly Bit-\ncoin, has shaken governments\u2019 control over the traditional financial\nsystem and currency issuance. In order to maintain the sovereignty\nof the country\u2019s currency control, countries take different actions to\nregulate decentralized finance activities. For example, in China, gov-\nernment legislation prohibits cryptocurrency trading, but the coun-\ntry charges ahead with its digital yuan (abbreviated as e-CNY)13,\nwhich is equal to the legal tender. The American government cre-\nated the Digital Dollar Project14 has given rise to extensive research\nand discussion. The project aims to explore solutions in cyber re-\nsilience, financial inclusion, and other key areas for the next century.\nIn conclusion, current legislation and governance mechanisms are\nstill inadequate. The advent of a true Web 3.0 seems like a distant\naspiration. There are many blanks that should be filled in the novel\ngovernance system, and we suppose that sufficient discussion and\nresearch should be made on how to ensure fairness and reliability\nwithin Web 3.0 architecture.\n5\nWEB3 VS WEB 3.0\nBecause Web 3.0 and Web3 are both extensions of the Semantic\nWeb, there is a common misconception that they are interchange-\nable. In fact, as with the opinion of Timothy John Berners-Lee,\nthere are relatively great differences between Web 3.0 and Web3.\nWeb 3.0 is a web-based on smart input terminals. The distributed\nsystem is largely its core idea and then implements a decentralized\nnetwork, but Web3 is more about decentralized governance with\nblockchain technology. Then, Web3 incorporates some economic\nelements, e.g., non-fungible tokens [67], an incentive model, and\nvalue exchange. Hence, its state of commercialization is higher than\nthat of Web 3.0. In contrast, Web 3.0 is more of an academic topic\nthan a commercial project. It is undeniable that the profit-driven\nmodel can significantly accelerate the development of new things\nin most cases. However, things are not always to our satisfaction.\nFor example, most people have high hopes for non-fungible tokens\nbecause they can ascertain the property rights of digital assets. In-\ndeed, most current non-fungible token business projects just pursue\nthe possibility that they will make their investors and creators rich\nbut ignore the utility of what is being created [47].\nIn addition, Web3 puts more emphasis on trust as a dependency.\nIn other words, the Web3 architecture needs one or many stable\nreputation systems to ensure its reliability [35]. However, in the\ncase of the Luna coin [11], its currency value peaked at $119.5\nper token and then dropped as low as $0.12 per token. During\nthose three years, there was such a significant wake! This case\nillustrates that the credibility of cryptocurrency is not controllable,\nand the unknown risk is the most dangerous. Web 3.0 is largely\nbased on mature distributed technologies. It incorporates these\n13https://en.wikipedia.org/wiki/Digital_renminbi\n14https://digitaldollarproject.org\ntechnologies into decentralized thinking and ensures that data\nownership belongs to the users themselves. Due to the fact that all\ninformation interactions rely on the main chain to complete data\ndissemination, the correctness, and stability of the main chain will\ndirectly influence the safety of Web3. Web 3.0 utilizes centralized,\ndecentralized, or distributed networks to form a communication\nnetwork, and third parties have to request data usage permission\nbecause data belongs to users. In conclusion, Web 3.0 shows better\ncompatibility with the current Web architecture than that of Web3.\n6\nCONCLUSION\nAs people\u2019s imagination of the next generation of the web, Web 3.0\nis always full of disputes and disagreements and is supplemented\nby people in different periods. From the original semantic Web to\nthe current decentralized web, with the continuous iteration of\ntechnologies and concepts, the Internet of Everything has become\nmore intelligent, 3D, and decentralized, which are becoming the\nprominent labels of Web 3.0. However, the gift of decentralization\ncan easily morph into a curse. Web 3.0 stresses decentralization and\ndelegates power to users. This is a good willingness, but there may\nalso be some regulatory problems. Reviewing or prosecuting hate\nspeech, violence, and terrorism might be more difficult because of\nthe decentralization of power. Furthermore, the development of\nWeb 3.0 is still in its early stages. This means that technological\ninnovation, the implementation process, and the associated risks\nare still evolving. In view of this, it seems that Web 2.0 and Web 3.0\nwill be co-existing for a long time.\nThis article provides an overview of how Web 3.0 will affect our\ndaily and future lives. There may be some technologies or ideas that\nwe haven\u2019t discussed in this article, even if we have tried our best\nto review related literature. We hope that this survey will help to\nidentify potential research directions while investigating and study-\ning Web 3.0. Massive studies and cases have shown that combining\nwith Web 3.0 is a viable way to achieve relative equality in the\nvirtual world. Novel technologies break down many barriers (such\nas data ownership, cost, and limited experience) that are difficult\nto solve in real life. Web 3.0 provides excellent visualization that is\nnot available in Web 2.0. More research works (e.g., decentralized\nstorage, edge computing, artificial intelligence, and socially linked\ndata protocols) are required for further study due to the rapid de-\nvelopment of technology. Besides, it is worth noting that the paper\nalso draws attention to new ethical and criminal issues. How does\nWeb 3.0 solve Web 2.0 problems? What new things will Web 3.0\nbring? These issues are briefly discussed.\nACKNOWLEDGMENTS\nThis research was supported in part by the Fundamental Research\nFunds for the Central Universities of Jinan University (No. 21622416),\nGuangzhou Basic and Applied Basic Research Foundation (No.\n202102020277), National Natural Science Foundation of China (Nos.\n62002136 and 62272196), Natural Science Foundation of Guangdong\nProvince (No. 2022A1515011861), the Young Scholar Program of\nPazhou Lab (No. PZL2021KF0023), and Guangdong Key Laboratory\nfor Data Security and Privacy Preserving.\nWeb 3.0: The Future of Internet\nWWW \u201923 Companion, April 30-May 4, 2023, Austin, TX, USA\nREFERENCES\n[1] Ayushi Abrol. 2022. Web 3.0 vs. Metaverse: A detailed comparison.\nhttps:\n//www.blockchain-council.org/metaverse/web-3-0-vs-metaverse/\n[2] Faten Adel Alabdulwahhab. 2018. Web 3.0: the decentralized web blockchain net-\nworks and protocol innovation. In Proceedings of the 1st International Conference\non Computer Applications & Information Security. IEEE, 1\u20134.\n[3] Maurizio Atzori, Georgia Koutrika, Barbara Pes, and Letizia Tanca. 2020. Special\nissue on \u201cData exploration in the web 3.0 age\u201d. Future Generation Computer\nSystems 112 (2020), 1177\u20131179.\n[4] Juan Benet. 2014.\nIPFS-content addressed, versioned, P2P file system.\narXiv:1407.3561 (2014), 1\u201311.\n[5] Tim Berners-Lee, James Hendler, and Ora Lassila. 2001. The semantic web.\nScientific American 284, 5 (2001), 34\u201343.\n[6] Timothy John Berners-Lee. 1989. Information management: A proposal. Technical\nReport. European Organization for Nuclear Research. https://cds.cern.ch/record/\n369245/files/dd-89-001.pdf\n[7] Timonthy John Berners-Lee. 1998. Semantic web road map. https://www.emse.\nfr/~beaune/websem/SWRoadmapLee.pdf\n[8] Abraham Bernstein, James Hendler, and Natalya Noy. 2016. A new look at the\nsemantic web. Communications of The ACM 59, 9 (2016), 35\u201337.\n[9] Piero Andrea Bonatti, Stefan Decker, Axel Polleres, and Valentina Presutti. 2019.\nKnowledge graphs: New directions for knowledge representation on the semantic\nweb. Dagstuhl Reports 8, 9 (2019), 29\u2013111.\n[10] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, and et al. 2020. Language\nmodels are few-shot learners. Advances in Neural Information Processing Systems\n33 (2020), 1877\u20131901.\n[11] Ryan Browne. 2022. The luna cryptocurrency has been resurrected after its $40\nbillion collapse. It\u2019s already crashing. https://www.cnbc.com/2022/05/30/terra-\n2point0-new-luna-cryptocurrency-is-already-crashing.html\n[12] Vitalik Buterin. 2014. A next-generation smart contract and decentralized appli-\ncation platform. White Paper 3, 37 (2014), 1\u201336.\n[13] CAICT. 2021.\nMobile Internet application personal information protection\nand governance.\nTechnical Report. China Academy of Information and\nCommunications Technology. http://www.caict.ac.cn/kxyj/qwfb/bps/202111/\nP020211119513519660276.pdf\n[14] Keyan Cao, Yefan Liu, Gongjie Meng, and Qimeng Sun. 2020. An overview on\nedge computing research. IEEE Access 8 (2020), 85714\u201385728.\n[15] Amber Case. 2015. Why the Internet needs IPFS before it\u2019s too late.\nhttps://\ntechcrunch.com/2015/10/04/why-the-internet-needs-ipfs-before-its-too-late/\n[16] Yao Chen, Yijie Gui, Hong Lin, Wensheng Gan, and Yongdong Wu. 2022. Federated\nlearning attacks and defenses: A survey. (2022), 4256\u20134265.\n[17] Zefeng Chen, Jiayang Wu, Wensheng Gan, and Zhenlian Qi. 2022. Metaverse\nsecurity and privacy: An overview. In The 10th International Conference on Big\nData. IEEE, 2950\u20132959.\n[18] Usman W Chohan. 2018. The concept and criticisms of steemit. CBRI Working\nPapers (2018), 1\u201310.\n[19] Usman W Chohan. 2022. Cryptocurrencies: A brief thematic review. Available at\nSSRN 3024330 (2022), 1\u201338.\n[20] Nupur Choudhury. 2014. World Wide Web and its journey from Web 1.0 to Web\n4.0. International Journal of Computer Science and Information Technologies 5, 6\n(2014), 8096\u20138100.\n[21] Shumo Chu and Sophia Wang. 2018. The curses of blockchain decentralization.\narXiv:1810.02937 (2018), 1\u20137.\n[22] Kyle Croman, Christian Decker, Ittay Eyal, Adem Efe Gencer, Ari Juels, Ahmed\nKosba, Andrew Miller, Prateek Saxena, Elaine Shi, and Emin G\u00fcn Sirer. 2016.\nOn scaling decentralized blockchains. In Proceedings of the 20th International\nConference on Financial Cryptography and Data Security. Springer, 106\u2013125.\n[23] Ru-Xi Ding, Iv\u00e1n Palomares, Xueqing Wang, Guo-Rui Yang, Bingsheng Liu,\nYucheng Dong, Enrique Herrera-Viedma, and Francisco Herrera. 2020. Large-\nScale decision-making: Characterization, taxonomy, challenges and future direc-\ntions from an Artificial Intelligence and applications perspective. Information\nFusion 59 (2020), 84\u2013102.\n[24] Dieter Fensel, Umutcan \u015eim\u015fek, Kevin Angele, Elwin Huaman, Elias K\u00e4rle, Olek-\nsandra Panasiuk, Ioan Toma, J\u00fcrgen Umbrich, and Alexander Wahler. 2020. In-\ntroduction: what is a knowledge graph? In Knowledge Graphs. Springer, 1\u201310.\n[25] Carlos Flavi\u00e1n, Sergio Ib\u00e1\u00f1ez-S\u00e1nchez, and Carlos Or\u00fas. 2019. The impact of\nvirtual, augmented and mixed reality technologies on the customer experience.\nJournal of Business Research 100 (2019), 547\u2013560.\n[26] Wensheng Gan, Jerry Chun-Wei Lin, Han-Chieh Chao, and Justin Zhan. 2017.\nData mining in distributed environment: a survey. Wiley Interdisciplinary Reviews:\nData Mining and Knowledge Discovery 7, 6 (2017), e1216.\n[27] Wood Gavin. 2018. Why we need Web 3.0. https://gavofyork.medium.com/why-\nwe-need-web-3-0-5da4f2bf95ab\n[28] GeeksforGeeks. 2021. How Web 3.0 is going to impact the digital world? https://\nwww.geeksforgeeks.org/how-web-3-0-is-going-to-impact-the-digital-world/\n[29] Adem Efe Gencer, Soumya Basu, Ittay Eyal, Robbert van Renesse, and Emin G\u00fcn\nSirer. 2018. Decentralization in bitcoin and ethereum networks. In Proceedings of\nthe 22nd International Conference on Financial Cryptography and Data Security.\nSpringer, 439\u2013457.\n[30] Michael Haenlein and Andreas Kaplan. 2019. A brief history of artificial in-\ntelligence: On the past, present, and future of artificial intelligence. California\nManagement Review 61, 4 (2019), 5\u201314.\n[31] Yoseph Hailemariam, Abbas Yazdinejad, Reza M Parizi, Gautam Srivastava, and\nAli Dehghantanha. 2020. An empirical evaluation of AI deep explainable tools.\nIn Proceedings of the International IEEE Globecom Workshops. IEEE, 1\u20136.\n[32] Peter Halfpenny and Rob Procter. 2009. Special issue on e-social science. Social\nScience Computer Review 27, 4 (2009), 459\u2013466.\n[33] Pascal Hitzler. 2021. A review of the semantic web field. Communications of The\nACM 64, 2 (2021), 76\u201383.\n[34] IAPP. 2017. Assessing mobile app data privacy risk. Technical Report. Interna-\ntional Association of Privacy Professionals. https://iapp.org/media/pdf/resource_\ncenter/Kryptowire-Report-2017-final.pdf\n[35] Navin V Keizer, Fan Yang, Ioannis Psaras, and George Pavlou. 2021. The case\nfor AI based Web3 reputation systems. In Proceedings of the 20th IFIP Networking\nConference. IEEE, 1\u20132.\n[36] Aggelos Kiayias and Philip Lazos. 2022. SoK: Blockchain governance. arXiv\npreprint arXiv:2201.07188 (2022), 1\u201322.\n[37] Soo Jin Kim. 2021. An impossible trinity in blockchain-based transactions: de-\ncentralization, privacy, and lower transaction costs. SSRN (2021), 1\u201330.\n[38] Gaurish Korpal and Drew Scott. 2022. Decentralization and Web3 technologies.\nTechRxiv preprint https://doi.org/10.36227/techrxiv.19727734.v1 (2022), 1\u20139.\n[39] Hong Lin, Shicheng Wan, Wensheng Gan, Jiahui Chen, and Han-Chieh Chao.\n2022. Metaverse in education: vision, opportunities, and challenges. In The 10th\nInternational Conference on Big Data. IEEE, 2857\u20132866.\n[40] Zhuotao Liu, Yangxi Xiang, Jian Shi, Peng Gao, Haoyu Wang, Xusheng Xiao,\nBihan Wen, Qi Li, and Yih-Chun Hu. 2021. Make Web 3.0 connected. IEEE\nTransactions on Dependable and Secure Computing (2021), 2965\u20132981.\n[41] A Manoj Athreya, Ashwin A Kumar, SM Nagarajath, HL Gururaj, V Ravi Kumar,\nDN Sachin, and KR Rakesh. 2021. Peer-to-peer distributed storage using Inter-\nPlanetary file system. In Advances in Artificial Intelligence and Data Engineering.\nSpringer, 711\u2013721.\n[42] Deborah L McGuinness and Frank Van Harmelen. 2004. OWL web ontology\nlanguage overview. W3C Recommendation 10, 10 (2004), 1\u201312.\n[43] Eric Miller. 1998. An introduction to the resource description framework. D-Lib\nMagazine (1998), 1\u20135.\n[44] San Murugesan. 2007. Understanding Web 2.0. IT Professional 9, 4 (2007), 34\u201341.\n[45] Satoshi Nakamoto. 2008. Bitcoin: A peer-to-peer electronic cash system. Decen-\ntralized Business Review (2008), 21260\u201321269.\n[46] Tim O\u2019reilly. 2007. What is Web 2.0: Design patterns and business models for\nthe next generation of software. Communications & Strategies 1 (2007), 17.\n[47] Tim O\u2019Reilly. 2021. Why it is too early to get excited about Web3.\nhttps:\n//www.oreilly.com/radar/why-its-too-early-to-get-excited-about-web3/\n[48] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela\nMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schul-\nman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell,\nPeter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training lan-\nguage models to follow instructions with human feedback. arXiv:2203.02155\n(2022), 1\u201368.\n[49] Zhigeng Pan, Adrian David Cheok, Hongwei Yang, Jiejie Zhu, and Jiaoying\nShi. 2006. Virtual reality and mixed reality for virtual learning environments.\nComputers & Graphics 30, 1 (2006), 20\u201328.\n[50] Tony Parisi. 2021. The seven rules of the metaverse. https://medium.com/meta-\nverses/the-seven-rules-of-the-metaverse-7d4e06fa864c\n[51] Osterman Research. 2022. The state of mobile app security 2022. Technical Report.\nOsterman Research. https://ostermanresearch.com/2022/07/15/approov-mobile-\napp-security-2022\n[52] Kevin Roose. 2022.\nAn AI-generated picture won an art prize: artists\naren\u2019t happy.\nhttps://www.nytimes.com/2022/09/02/technology/ai-artificial-\nintelligence-artists.html\n[53] Kevin Roose. 2022. Is this crypto\u2019s Lehman moment?\nhttps://www.nytimes.\ncom/2022/11/09/technology/cryptocurrency-binance-ftx.html\n[54] Tiago Rosado and Jorge Bernardino. 2014. An overview of openstack architecture.\nIn Proceedings of the 18th International Database Engineering & Applications\nSymposium. ACM, 366\u2013367.\n[55] Riaan Rudman et al. 2015. Web 3.0: governance, risks and safeguards. Journal of\nApplied Business Research 31, 3 (2015), 1037\u20131056.\n[56] Michele Ruta, Floriano Scioscia, Saverio Ieva, Giovanna Capurso, and Eugenio\nDi Sciascio. 2017. Semantic blockchain to improve scalability in the internet of\nthings. Open Journal of Internet Of Things 3, 1 (2017), 46\u201361.\n[57] Nigel Shadbolt, Tim Berners-Lee, and Wendy Hall. 2006. The semantic web\nrevisited. IEEE Intelligent Systems 21, 3 (2006), 96\u2013101.\n[58] Juan M Silva, Abu Saleh Md Mahfujur Rahman, and Abdulmotaleb El Saddik. 2008.\nWeb 3.0: a vision for bridging the gap between real and virtual. In Proceedings of\nthe 1st ACM International Workshop on Communicability Design and Evaluation\nin Cultural and Ecological Multimedia System. ACM, 9\u201314.\nWWW \u201923 Companion, April 30-May 4, 2023, Austin, TX, USA\nGan et al.\n[59] Amit Singhal. 2012. Introducing the knowledge graph: things, not strings. https:\n//blog.google/products/search/introducing-knowledge-graph-things-not/\n[60] Lou Steinberg. 2022.\nFour cybersecurity risks of Web 3.0.\nhttps://www.\nsecuritymagazine.com/articles/96998-4-cybersecurity-risks-of-web-30\n[61] Jiayi Sun, Wensheng Gan, Han-Chieh Chao, and Philip S Yu. 2022. Metaverse:\nSurvey, applications, security, and opportunities. arXiv:2210.07990 (2022), 1\u201335.\n[62] Jiayi Sun, Wensheng Gan, Han-Chieh Chao, Philip S Yu, and Weiping Ding.\n2023. Internet of behaviors: A survey. IEEE Internet of Things Journal. DOI:\n10.1109/JIOT.2023.3247594 (2023), 1\u201318.\n[63] Jiayi Sun, Wensheng Gan, Zefeng Chen, Junhui Li, and Philip S Yu. 2022. Big\ndata meets metaverse: A survey. arXiv preprint, arXiv:2210.16282 (2022).\n[64] Heru Susanto, Leu Fang Yie, Desi Setiana, Yani Asih, Ambar Yoganingrum, Slamet\nRiyanto, and Fadly Akbar Saputra. 2021. Digital ecosystem security issues for\norganizations and governments: Digital ethics and privacy. In Web 2.0 and Cloud\nTechnologies for Implementing Connected Government. IGI Global, 204\u2013228.\n[65] Abeba Nigussie Turi. 2020. Currency under the Web 3.0 economy. In Technologies\nfor Modern Digital Entrepreneurship. Springer, 1\u2013210.\n[66] Blesson Varghese, Nan Wang, Sakil Barbhuiya, Peter Kilpatrick, and Dimitrios S\nNikolopoulos. 2016. Challenges and opportunities in edge computing. In Proceed-\nings of the 1st IEEE International Conference on Smart Cloud. IEEE, 20\u201326.\n[67] Qin Wang, Rujia Li, Qi Wang, and Shiping Chen. 2021. Non-fungible token (NFT):\nOverview, evaluation, opportunities and challenges. arXiv:2105.07447 (2021),\n1\u201322.\n[68] Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung, Christian\nMakaya, Ting He, and Kevin Chan. 2019. Adaptive federated learning in re-\nsource constrained edge computing systems. IEEE Journal on Selected Areas in\nCommunications 37, 6 (2019), 1205\u20131221.\n[69] Nicholas Weaver. 2021. The Web3 fraud. https://www.usenix.org/publications/\nloginonline/web3-fraud\n[70] Sage A Weil, Scott A Brandt, Ethan L Miller, Darrell DE Long, and Carlos Maltzahn.\n2006. Ceph: A scalable, high-performance distributed file system. In Proceedings\nof the 7th USENIX Symposium on Operating Systems Design and Implementation.\nUSENIX Association, 307\u2013320.\n[71] Gavin Wood. 2014. Ethereum: A secure decentralised generalised transaction\nledger. Ethereum Project Yellow Paper 151, 2014 (2014), 1\u201332.\n[72] Dylan Yaga, Peter Mell, Nik Roby, and Karen Scarfone. 2018. Blockchain technology\noverview. Technical Report. National Institute of Standards and Technology,\nU.S. Department of Commerce. https://www.nist.gov/publications/blockchain-\ntechnology-overview\n[73] Caiming Zhang and Yang Lu. 2021. Study on artificial intelligence: The state\nof the art and future prospects. Journal of Industrial Information Integration 23\n(2021), 100224.\n[74] Zibin Zheng, Shaoan Xie, Hong-Ning Dai, Xiangping Chen, and Huaimin Wang.\n2018. Blockchain challenges and opportunities: A survey. International Journal\nof Web and Grid Services 14, 4 (2018), 352\u2013375.\n[75] Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, and Junshan Zhang. 2019. Edge\nintelligence: Paving the last mile of artificial intelligence with edge computing.\nProceedings of The IEEE 107, 8 (2019), 1738\u20131762.\nA\nAPPENDIX\nWebsite\nWebsite\nFeatures/Functions\nClassification\nhttps://www.sina.com.cn/\n\u2022 popularization\n\u2022 productive \n\u2022 rely on clicks\n\u2022 centralized access to information\n\u2022 quick content search\n\u2022 accessibility on computer\nweb portal\nhttps://www.163.com/\nhttps://www.yahoo.com/\nhttps://www.google.com/\n\u2022 keyword search\n\u2022 web crawler technology\n\u2022 hypertext matching analysis\n\u2022 question and answer\nsearch engine\nhttp://www.baidu.com/\nFigure A1: Several representative products in Web 1.0.\nApplication\nWebsite\nFeatures/Functions\nClassification\nhttps://www.wechat.com/\n\u2022 private/group chat\n\u2022 video call\n\u2022 subscription\n\u2022 mini programs\nmessaging\nhttps://www.twitter.com/\n\u2022 photo-sharing service\n\u2022 character limits\n\u2022 trending topics\n\u2022 communities\nsocial network\nhttps://www.google.com/drive/\n\u2022\nteam collaboration\n\u2022\nview any type of file\n\u2022\ncontent library\n\u2022\nautomatically sync files\n\u2022\naccess controls/permissions\nstorage\nhttps://www.google.com/chrome/\n\u2022 tab groups\n\u2022 cross-platform synchronization\n\u2022 password management\n\u2022 writing and sharing online\nbrowser\nhttps://www.apple.com/ios/\n\u2022 security assurance\n\u2022 fluid responsive\n\u2022 complete app ecosystem\n\u2022 high integration between \nsoftware and hardware\noperating system\nhttps://www.teamviewer.com/\n\u2022\nteam collaboration\n\u2022\njoin meetings instantly\n\u2022\nremote control\n\u2022\nacross devices\n\u2022\nstay in touch with instant chat\nremote job\nFigure A2: Several representative products in Web 2.0.\nApplication\nWebsite\nFeatures/Functions\nClassification\nhttps://status.im/\n\u2022 decentralized communication\n\u2022 private messaging\n\u2022 pseudo-anonymous account \ngeneration\n\u2022 an open source project\nmessaging\nhttps://steemit.com/\n\u2022 graphene framework\n\u2022 a decentralized application \n\u2022 reward creation\n\u2022 monetizing without advertising\nsocial network\nhttps://www.storj.io/\n\u2022\ndecentralized cloud storage\n\u2022\nbuilt in a global network\n\u2022\nCDN-like performance\n\u2022\ntransform data by P2P\n\u2022\nstorage-based data protection\nstorage\nhttps://brave.com/\n\u2022 customizations\n\u2022 high level of privacy protection\n\u2022 browse and search privately\nbrowser\nhttps://eos.io/\n\u2022 OS-like blockchain platform\n\u2022 commercial public chain\n\u2022 graphene framework\n\u2022 allow to create blockchain-based \napplications\noperating system\nhttps://ethlance.com/\n\u2022\nEthereum blockchain storage\n\u2022\nan original district on district0x \nnetwork\n\u2022\nfollow the IPFS protocol\n\u2022\ncompletely open-source\nremote job\nFigure A3: Several representative products in Web 3.0 or\nWeb3.\n",
    "2303.13050": "Building Resilient Web 3.0 with Quantum Information Technologies and\nBlockchain: An Ambilateral View\nXIAOXU REN, Tianjin University, China\nMINRUI XU and DUSIT NIYATO, Nanyang Technological University, Singapore\nJIAWEN KANG, Guangdong University of Technology, China\nZEHUI XIONG, Singapore University of Technology and Design, Singapore\nCHAO QIU and XIAOFEI WANG, Tianjin University, China\nWeb 3.0 pursues the establishment of decentralized ecosystems based on blockchain technologies to drive the digital transformation\nof physical commerce and governance. Through consensus algorithms and smart contracts in blockchain, which are based on\ncryptography technologies, digital identity, digital asset management, decentralized autonomous organization, and decentralized\nfinance are realized for secure and transparent digital economy services in Web 3.0 for promoting the integration of digital and physical\neconomies. With the rapid realization of quantum devices, Web 3.0 is being developed in parallel with the deployment of quantum cloud\ncomputing and quantum Internet. In this regard, quantum computing first disrupts the original cryptographic systems that protect\ndata security while reshaping modern cryptography with the advantages of quantum computing and communication. Therefore,\nthis survey provides a comprehensive overview of blockchain-based Web 3.0 and its quantum and post-quantum enhancement from\nthe ambilateral perspective. On the one hand, some post-quantum migration methods, and anti-quantum signatures offer potential\nways to achieve unforgeable security under quantum attack for the internal technologies of blockchain. On the other hand, some\nquantum/post-quantum encryption and verification algorithms improve the external performance of the blockchain, enabling a\ndecentralized, valuable, secure blockchain system. Finally, we discuss the future directions toward developing a provable secure\ndecentralized digital ecosystem.\nCCS Concepts: \u2022 Security and privacy \u2192Cryptography; \u2022 Theory of computation \u2192Models of computation .\nAdditional Key Words and Phrases: Quantum Computing, Post-Quantum Cryptograph, Decentralization, Blockchain.\nACM Reference Format:\nXiaoxu Ren, Minrui Xu, Dusit Niyato, Jiawen Kang, Zehui Xiong, Chao Qiu, and Xiaofei Wang. 2023. Building Resilient Web 3.0\nwith Quantum Information Technologies and Blockchain: An Ambilateral View. 1, 1 (March 2023), 35 pages. https://doi.org/10.1145/\nnnnnnnn.nnnnnnn\nAuthors\u2019 addresses: Xiaoxu Ren, xiaoxuren@tju.edu.cn, College of Intelligence and Computing, Tianjin University, Tianjin, China, 300072; Minrui Xu,\nminrui001@e.ntu.edu.sg; Dusit Niyato, dniyato@ntu.edu.sg, School of Computer Science and Engineering, Nanyang Technological University, Singapore,\nSingapore, 639798; Jiawen Kang, kavinkang@gdut.edu.cn, School of Automation, Guangdong University of Technology, Guangzhou, China, 510006; Zehui\nXiong, zehui_xiong@sutd.edu.sg, Pillar of Information Systems Technology and Design, Singapore University of Technology and Design, Singapore,\nSingapore, 487372; Chao Qiu, chao.qiu@tju.edu.cn; Xiaofei Wang, xiaofeiwang@tju.edu.cn, College of Intelligence and Computing, Tianjin University,\nTianjin, China, 300072.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components\nof this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to\nredistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\u00a9 2023 Association for Computing Machinery.\nManuscript submitted to ACM\nManuscript submitted to ACM\n1\narXiv:2303.13050v1  [cs.CR]  23 Mar 2023\n2\nRen and Xu et al.\n1\nINTRODUCTION\n1.1\nBackground\nThe decentralized digital economies in Web 3.0, including creator economies and decentralized autonomous organizations\n(DAOs), can improve the user experience and take user privacy and security to the next level [1, 2]. Without trusted\nauthorities, users own their unique digital identities built on blockchain to access personal data and decentralized\napplications in Web 3.0. In addition to read-and-write operations, Web 3.0 can provide proof-of-ownership for digital\nassets of participants based on blockchain technologies. In Web 3.0, users\u2019 data is stored in or linked to the blockchain\nand stored in distributed data storage systems such as the InterPlanetary File System (IPFS) [3]. Meanwhile, activities\nand regulations in Web 3.0 are executed via immutable and transparent smart contracts and consensus algorithms\nproposed by DAOs.\nWeb 3.0\u2019s decentralized nature empowers users with greater control over their data, which reduces reliance on\nthe management of centralized authorities [1]. The role of blockchain is to enhance the security and transparency\nof Web 3.0 by providing a trustworthy way for users to store data and conduct transactions without the need for\ncentralized authorities. However, it is essential to note that blockchain technology is susceptible to quantum computing,\nwhich can break one-way mathematical functions such as hash functions and public-key encryption commonly used in\nclassical computing. Due to the superposition and entanglement of quantum bits (qubits), quantum computing has\nenough processing power to break existing digital signatures and hash functions within secrecy periods. For example, a\nquantum computer with 2\u00d7107 qubits can crack RSA-2048 in just eight hours [4]. Hence, it is possible for a malicious\nuser utilizing quantum computers to easily steal private keys from a blockchain wallet, ultimately resulting in the loss\nof all funds in that wallet.\nWhile Web 3.0 affords users the ability to peruse, produce, and possess their user-generated content (UGC), traditional\nblockchain technology is on the verge of obsolescence once the potency of a quantum computer meets the prerequisites to\noperate Shor\u2019s algorithm and Grover\u2019s algorithm [5]. The proliferation of quantum information technologies has opened\na new avenue for blockchain technology in Web 3.0. A quantum blockchain, which is founded on quantum information\ntechnologies, can formulate more secure and resilient distributed ledgers that are impervious to quantum attacks. For\ninstance, quantum key distribution (QKD) protocols encode the key employed for symmetric encryption into a quantum\nstate for transmission over a quantum channel. With one-time-pad technology, QKD-secured communication can\nrealize information-theoretically secure data transmission. Furthermore, quantum blockchain can utilize the quantum\nhash function and one-way quantum computing functions to fabricate quantum voting [6] and quantum signature [7]\nalgorithms. Additionally, post-quantum blockchain, which is based on post-quantum cryptographic algorithms that are\nimmune to quantum attacks, can also be deemed as a solution to secure Web 3.0 in the post-quantum era. Consequently,\nclassical blockchain is revolutionized into the quantum blockchain with the added benefits of prolonged data encryption\nand over two decades of usage.\nDue to the substantial current interest and complementary advantages of quantum information technologies and\nblockchain, we aim to examine how state-of-the-art quantum information technologies are driving blockchain to\nopen up new horizons for the development of Web 3.0 from the ambilateral perspective. Specifically, we explore the\nbenefits of quantum blockchain in terms of internal technologies, i.e., consensus protocols, incentive mechanisms, smart\ncontracts, and cryptographs. In addition, we also investigate how quantum technologies can enhance the performance\nof blockchain in terms of external aspects such as decentralization, profitability, and privacy of storage.\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n3\n2008 Blockchain\nConsensus \nProtocol\nSmart \nContract\nIncentive \nMechanism\nCryptography\nScalability\nDecentralization\nQuantum \nBlockchain \nEconomics\nTheory\nOverview\nInternal Optimization of  Quantum Blockchain \nExternal Improvement of Quantum Blockchain\n2018\n2019\n2020\n2021\n2022\nBlockchain scalability [101]\nDecentralization using quantum \nblockchain [99] \nAuction on quantum blockchain [97]\nQuantum-based privacy- preserving auction[98] \nQuantum e- payment protocol [91]\nQuantum NFT for blockchain \n[57]\nA novel e-payment protocol [92]\nCrypto-currency system with QKD[57]\nQuantum digital signature [75]\nBlockchain cryptography resistant to quantum computing attacks[22]\nSmart contract based on quantum blind signature [59]\nLogic programming for smart contract [62] \nConsensus based on post-quantum signature[49]\nQuantum-enhanced logic-based blockchain [45]\nA stake vote consensus algorithm [7]\nPost-quantum blockchain for a scalable smart city [125]\nBlockchain in the quantum world [8]\nQuantum- secured blockchain [11]\nAnti-quantum attribute-based signature [106]\nQuantum cryptography-as-a-service [136]\nPrivacy of \nStorage\nDistributed storage on the blockchain [104]\nMining on a quantum-enabled blockchain [103]\nFig. 1. The research activities of Quantum-Driven Blockchain in Web 3.0\n1.2\nRelated Books and Surveys\nRecently, there have been many efforts that attempt to converge quantum information technologies and blockchain into\nthe quantum and post-quantum blockchain. Meanwhile, the growth of quantum information theory and computation\nhas resulted in a rise in the number of research ongoing in the quantum blockchain.\nSome works on frameworks, opportunities, and challenges of quantum blockchain are [8\u201314]. Faridi et. al explore\nthe possibilities and potential benefits of quantum computing in blockchain systems [8, 9]. The advantages of quantum\nblockchain and development prospects are summarized in [10] compared with the classical blockchain while providing\nthe detailed method of applying quantum technology to the blockchain. Kiktenko et. al give an overview of the current\nstate of research on quantum blockchain [11], covering topics such as quantum-resistant blockchain protocols and\ncryptography algorithms. Vlad et. al explore the potential of using entanglement in time to create a quantum blockchain\nand present the challenges of implementing a quantum blockchain [12]. Further, Dey et. al provide an overview of the\nchallenges and opportunities associated with developing a quantum blockchain [13], including issues related to quantum\nsecurity, scalability, and interoperability. Allende et. al propose some tutorials on the implementation of quantum\nblockchain [14], where quantum entropy was provided via the IronBridge Platform from CQC and LACChain Besu is used\nas the blockchain network. However, the above works only focus on either internal technical optimization (i.e., consensus\nprotocols, incentive mechanisms, smart contracts, and cryptography) or external performance improvement (i.e.,\neconomy, decentralization, scalability, and privacy of storage). There is no research that explores the benefits of quantum\nblockchain from internal optimization and external performance. Therefore, this survey provides a comprehensive\nManuscript submitted to ACM\n4\nRen and Xu et al.\naccount of quantum blockchain from an ambilateral View to build resilient Web 3.0 infrastructure. We summarize the\nresearch activities of quantum-driven blockchain in Web 3.0, which is shown in Fig. 1.\nUnless quantum technology is integrated into blockchain technology, the components of classical blockchain are\nexposed to quantum attacks [5], resulting in security risks to the internal technologies and external performance of the\nblockchain. Currently, we have already seen the development of information-theoretically secure quantum protocols,\nsuch as quantum homomorphic encryption protocols [15, 16], quantum image encryption [17, 18], and quantum digital\nsignature [19, 20], while several attempts have been made to incorporate post-quantum cryptography [21, 22]. These\nprotocols bring benefits to the internal technologies and external performance of blockchain, achieving privacy, security,\neffectiveness, and profitability under quantum attacks.\nNevertheless, the above studies focus on either internal technical optimization or external performance improvement\nof quantum technologies for blockchain in Web 3.0. There is no research that explores the benefits of quantum technology\nfor blockchain in both aspects. Therefore, this survey provides a comprehensive account of blockchain combined\nwith quantum information technology from both internal and external aspects in a Web 3.0 scenario, starting from an\noverview, motivation, and comprehensive framework to research challenges and future directions.\n1.3\nOur Survey\nAdvances in quantum computers undermine the security of classical blockchains, there is an urgent need to solve\nthe limitations of blockchain and continue to develop Web 3.0. This paper aims to integrate quantum information\ntechnologies into blockchain and investigate the most recent developments in Web 3.0 thoroughly. The contributions of\nthis survey can be summarized as follows:\n\u2022 First, we present the basic principles of blockchain and quantum information technology, while giving motivations\nfor using the complementary properties of quantum technology to support blockchain from the ambilateral\nperspective, i.e., internal technologies optimization and external performance improvement.\n\u2022 Second, we optimize the internal technologies of quantum blockchain from four aspects, including consensus\nprotocols, incentive mechanisms, smart contracts, and cryptography.\n\u2022 Third, we improve the external performance to better support quantum blockchain, including economy, decen-\ntralization, scalability, and privacy of storage.\n\u2022 Fourth, we investigate potential quantum blockchain applications and give tutorials for implementing quantum\nblockchain in Web 3.0.\n\u2022 Finally, we explore several key challenges and open research directions.\nA taxonomy graph of this paper is presented as Fig. 2. Specifically, we first give the background on blockchain and\nquantum information technologies in Section 2 and Section 3. Then, the motivation for integrating them is explained in\nSection 4. Next, we describe in detail the integration techniques from internal technologies optimization (Section 5) and\nexternal performance improvement (Section 6). In Section 7, we investigate some applications and tutorials of quantum\nblockchain. Section 8 discusses research challenges and future directions. Lastly, the conclusion is drawn in Section 9.\n2\nOVERVIEW OF BLOCKCHAIN IN WEB 3.0\nIn this section, we present the background of blockchain in Web 3.0, including the definition, internal technologies, and\nexternal performance, which is shown in Fig. 3.\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n5\nSec. IV Motivation of Quantum Blockchain\nChain-Native Applications\nDigital Transformation Applications\nSec. I Introduction\nRelated Books and Surveys\nOur Survey\nSec. VII Applications of Quantum Blockchain\nSec. II Overview of Blockchain in Web 3.0\nSec. III Overview of Quantum information technologies  \nFundamental and Enabling Infrastructure of Web 3.0\nQuantum Communication\nPost-Quantum Cryptography\nQuantum Computing\nKey Aspects\nBlockchain Applications\nWhat is the Quantum Blockchain\nWhy Do We Need \nQuantum-Driven Web 3.0\nSpear of Quantum in Web 3.0\nShield of Quantum in Web 3.0\nSec. V Internal Optimization\nQuantum Consensus \nProtocol\nQuantum Consensus Definition\nQuantum-Based Classification\nBlockchain-Based Classification\nIncentive Mechanism\nQuantum-based \nMining Strategies\nSecure Token \nSystems\nSmart Contract\nQuantum Cryptography\nbased Smart Contracts\nPost-quantum \nSmart Contracts\nPost-Quantum Migration \nfor Blockchain\nPublic Key Post Quantum Cryptosystems\nPost-Quantum Signature Algorithms\nQuantum Networked Time Machine\nSec. VI External Performance\nQuantum Blockchain \nEconomy\nPayment Protocol\nMarket Mechanism\nDecentralization\nScalability\nPrivacy of Storage\nImplementation Tutorial for Storage\nPost-quantum Based Distributed Storage\nIdentity management\non Quantum blockchain\nDigital Finance\nMetaverse\nSecurity\nComputation\nRandomness\nImplementation Tutorials of Quantum Blockchain in Web 3.0\nSmart Cities\nSmart Healthcare\nE-voting\nSmart Home and UAV\nSec. VIII Research challenges and future directions\nConvergence of Classic-Quantum \nNetworking and Computing\nInternal Technologies and \nExternal Performance\nMigration to Quantum and \nPost-quantum Blockchain\nSec. IX Conclusion \nIncrease transaction \nthroughput while \nmaintaining security\nFig. 2. The taxonomy graph of Quantum-Driven Blockchain in Web 3.0\n2.1\nFundamental and Enabling Infrastructure of Web 3.0\nAs the cornerstone of the digital economy, Web 3.0 can drive digital transformation in a decentralized, secure, and\ntransparent way. The read/write/own Web 3.0 is evolved from the read Web 1.0 and the read/write Web 2.0, which\nallows content creators and users to own the rights to use and manage their digital assets [1]. In Web 1.0, users could\nonly read online content published by authoritative publishers who own most of the data and value on the Internet.\nManuscript submitted to ACM\n6\nRen and Xu et al.\nData\nConsensus\nIncentive\nContract\nApplication\nInternal technologies\nExternal performance\nDecentralization\nProfitability\nPrivacy and security\nFig. 3. The background of blockchain in Web 3.0\nThe data in Web 1.0 is stored on the local servers of Internet owners. Transited to Web 2.0, users can access information\nfrom online applications and platforms as well as create and share their content with other users. However, the value of\ndata is stored on cloud servers and owned by companies, and users still cannot own the content they read and create.\nFinally, in Web 3.0, users access the Internet with their digital identities and wallets, which are leveraged to manage the\ndata they create in online services. Therefore, Web 3.0 is also conceived as the Internet of Value [23], which allows\nusers to create, manage, and trade their user-generated content in the form of digital assets.\nThe blockchain is developed based on consensus algorithms and smart contracts that can provide decentralization\nand interoperability for Web 3.0 applications and services [24]. Each user in Web 3.0 owns a digital wallet that consists\nof its digital identities. Through digital wallets, users can interact with distributed ledgers on Web 3.0 to manage\ntheir behavioral data assets, digital assets, and transaction histories, which are recorded in the on-chain database\nanonymously. Distributed data storage enables Web 3.0 applications to store user interaction and authentication data\nthat previously had to be stored on distributed data servers. During the utilization, users gain access to the data through\ntheir digital identities. The benefits of storing data via distributed data storage systems include low storage costs, high\nsecurity, and low storage costs [3]. Distributed storage uses smart contracts to distribute data across multiple network\nnodes and fully utilize their storage resources.\n2.2\nKey Aspects of Blockchain in Web 3.0\nAs mentioned above, blockchain-based digital ecosystems with distributed data storage and computing-power networks\nare the foundation for the digital society of Web 3.0. Notably, Web 3.0 is considered to be a collection of blockchain-based\nprotocols focused on changing the ecology of the Internet. This survey describes the key aspects of blockchain in Web\n3.0 in terms of internal technologies and external performance.\n2.2.1\nInternal Technologies. It refers to the support of blockchain for Web 3.0 in terms of internal composition.\n\u2022 Consensus Protocols: Consensus protocols are an integral part of the decentralized Web 3.0, which are leveraged\nto establish consensus among multiple interest parties without trusted third-party authorities. This ensures the\nsecurity and reliability of the network. Several consensus protocols of blockchain in Web 3.0 include proof of\nwork (PoW) [25], proof of stake (PoS) [26], proof of authority (PoA) [27], etc. Different consensus protocols have\ndifferent properties and are applicable to different Web 3.0 applications and services.\n\u2022 Incentive Mechanism: As the Internet of Value, Web 3.0 is built on a plethora of favorable incentives for encouraging\nparticipants. There are multiple types of incentives, e.g., miner rewards, transaction gas, and minting fees,\ndistributed based on blockchain platforms in Web 3.0. In addition, incentives in blockchain technologies allow\nparticipants for the creation and management of digital assets as NFTs [28]. This function of the blockchain\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n7\nprovides the fundamental of Web 3.0 [29], which involves the tokenization of various content, including digital\nidentities, intellectual properties, and real-world assets.\n\u2022 Smart Contract: As the foundation of Web 3.0 and the new digital environment, smart contracts are codes of\ndigital auto-executing applications. These contracts support a range of functions, from executing financial\ntransactions to identifying users to running decentralized applications. Smart contracts govern the rules of Web\n3.0 agreements [30]. They allow users to interact with dAPPs in Web 3.0 by the blockchain. Gaming applications,\nin particular, are booming with the advent of Web 3.0 and Metaverse. Smart contracts in Web 3.0 combine tokens\nor crypto rewards with gameplay by the GameFi and Play to Earn. Thus, smart contracts are opening a new era\nof combined entertainment and economy in Web 3.0.\n\u2022 Cryptography: Cryptography is a method of storing and transmitting data in a specific form that prevents third\nparties from accessing and getting information from private messages during peer-to-peer communication.\nGenerally, this aspect of blockchain is expected to be critical to Web 3.0 to protect user data and privacy [31].\n2.2.2\nExternal Performance. It refers to the support of blockchain for Web 3.0 in terms of external properties.\n\u2022 Decentralization: As mentioned above, one of the core issues of Web 2.0 is the centralized management of\nauthority and data. Blockchain decentralizes Web 2.0 into Web 3.0 by facilitating a broader distribution of data\nand authority. Web 3.0 adopts the blockchain-driven public distributed ledger for greater transparency and\ndecentralization, creating a more open, transparent, and secure Internet.\n\u2022 Profitability: Web 3.0 disrupts the DAPP industry through tokenizing assets. This involves the creation of digital\ntokens, which can be bought, sold, and traded on blockchain-based platforms, making it easier for investors to\ndiversify their portfolios and gain more profits.\n\u2022 Privacy and Security: Blockchain plays a crucial role in the privacy and security of data storage and identity\nmanagement. From Web 1.0 to Web 2.0, significant progress are made in decentralizing data, empowering users\nto create and share data, whereas users do not own and control their data. Further, Web 3.0 provides users with\nan open, trust, and permissionless Internet to ensure data ownership and privacy.\nLessons learned: According to the description above, it is quite clear that blockchain can serve as a key driver of\nthe next generation of the Internet. As an emerging technology, blockchain brings many advantages while it also needs\nto explore in tackling its disadvantages. Transactions on the blockchain are public and transparent, making it difficult\nto protect personal privacy. Each blockchain nodes save whole data, causing network congestion and slow transaction\nspeed. Moreover, reaching a consensus consumes a lot of resources consumption. Especially with the arrival of quantum\ntechnology, blockchain would face more restrictions. In the next section, we focus on the background of quantum\ninformation technologies.\n3\nOVERVIEW OF QUANTUM INFORMATION TECHNOLOGIES\nIn this section, we give the background of quantum information technologies, including quantum communication,\nquantum computing, and post-quantum cryptography, which is shown in Fig. 4.\n3.1\nQuantum Communication\nIn the Internet of Everything era, huge amounts of sensitive data rely on communication networks. These data are\nusually encrypted and then sent along with a \u201ckey\" over fiber-optic cables. Specially, these data and keys are sent as\nManuscript submitted to ACM\n8\nRen and Xu et al.\nPost-quantum cryptography\nLattice-based cryptography\nMultivariate cryptography\nHash-based cryptography\nCode-based cryptography\nQuantum computing\nSuperposition\nEntanglement\nQuantum interference\nQubit\nQuantum communication\nQuantum teleportation\nQuantum repeater\nQuantum internet\nQKD\nFig. 4. The background of quantum information technologies in Web 3.0\nclassical bits, which can be read and copied by hackers without leaving a trace, thus causing security problems. In the\nfollowing, we give some key terms to fully understand quantum communication.\n\u2022 Quantum: Quantum in \u201cquantum computing\" means the quantum mechanics used by the system to calculate the\noutput. Generally, a quantum refers to the smallest possible discrete unit of any physical property, e.g., electrons,\nneutrinos, and photons.\n\u2022 Qubit: Similar to the bits in classical computing, qubits are the basic unit of information in quantum computing.\nThe difference between them is that a classical bit is binary and it can only take the value of 1 or 0, while a qbit\ncan maintain a superposition of all possible states.\nQuantum communication uses the laws of quantum physics to protect private data [32]. These laws allow particles,\ni.e., photons that transmit data, to take on a superposition state. That is the result of measurement of such states is\nnot definite |0\u27e9or definite |1\u27e9, where |\u00b7\u27e9is called a \u201cket-vector\u201d in Dirac notation. It also means particles can take\non multiple combinations of values of 1 and 0 simultaneously. These particles are called quantum bits, or qbits. The\nsuper-fragile quantum state of qubits causes hackers to be unable to tamper with them without leaving signs of activity.\nQuantum communication involves the generation and use of quantum states for communication protocols.\n3.1.1\nQuantum Teleportation. Quantum teleportation is a process by which a qubit can be transmitted from a sender\nto a receiver, without that qubit actually being transmitted through space [33]. Unlike the portrayed teleportation in\nscience fiction, which is described as a means of transferring physical objects from one location to another, quantum\nteleportation only transmits quantum information [34]. Moreover, quantum teleportation exploits the property of\nquantum mechanics, i.e., quantum entanglement to transfer the quantum state of a particle onto a different particle [35].\n3.1.2\nQuantum Key Distribution. Quantum communication is primarily concerned with secure communication by\ndeveloping secure quantum channels. One of the most interesting topics in this field is QKD, which uses quantum\nteleportation to generate key pairs that allow encryption and decryption of messages [36].\nCurrently, there emerges a number of approaches and protocols for implementing QKD. QKD prevents hacks and\nprovides excellent privacy protection while addressing the key distribution problem based on quantum cryptography\n[37]. We use one known BB84 as an example to introduce the QKD process. Assume that Alice would like to send data\nsecurely to Bob.\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n9\n\u2022 Generation and transmission of encryption key: Alice creates an encryption key in the form of qubits. Then, these\nqubits would be sent to Bob by the fiber-optic cable.\n\u2022 State measurements of qbits: Bob then uses a random base to measure the qbits received with the basis, after\nwhich Bob acknowledges to Alice the quantum bits he received through the public channel.\n\u2022 Key sifting: Alice and Bob can determine that they hold the same key by comparing the state measurements of a\nfraction of the qbits.\n\u2022 Key distillation: It is run by Alice and Bob, involving calculating whether the error rate is high enough to indicate\nthat the hacker is trying to intercept the key.\n\u2022 Key update: If so, the suspect key might be threw away while the new keys are generated until Alice and Bob are\nconfident that they share a secure key. Then, Alice can encrypt the data with her key and send it as classical bits\nto Bob, who uses his key to decode the message.\n3.2\nQuantum Computing\nClassical computers today encode information into bits using a binary stream of electrical pulses (1 and 0), which\nrestricts their processing ability. Compared to classical computers, quantum computers use quantum qubits, which\ncan take a value of 1 or 0, or a complex combination of both 1 and 0, to perform calculations that ordinary bits can\u2019t.\nQuantum computers are capable of measuring and observing quantum systems at the molecular level, as well as solving\nconditional probabilities of events. They serve to accelerate the development of artificial intelligence and web 3.0.\nQuantum computing is a rapidly-emerging technology that utilizes the laws of quantum mechanics and introduces\nsome novel quantum algorithms to solve mathematical problems that are too large or complex for classical computers\n[38]. And quantum computers rely on qubits to run and solve these multidimensional quantum algorithms. Specifically,\nquantum computers take advantage of the unique behavior of quantum physics, such as superposition, entanglement,\nand quantum interference, and apply it to quantum computing.\n3.3\nPost-Quantum Cryptography\nQuantum computers pose a serious security threat to many commonly used symmetric encryption algorithms and key\nnegotiation schemes due to their ability to rapidly increase computational power. This increase in power heightens the\nrisk of breaking current network security encryption schemes, leading governments and companies to transition to\nencryption methods in the post-quantum era. After years of research, post-quantum cryptography, which includes\nlattice-based, multivariate, hash-based, and code-based techniques, has emerged as one of the most developed and\nreliable classical computing-based approaches.\n\u2022 Lattice-based cryptography: Lattice-based cryptography is a form of cryptography that utilizes the mathematical\nconcept of a lattice, a discrete structure consisting of points connected by lines in an n-dimensional space [39].\n\u2022 Multivariate cryptography: Multivariate cryptography is a form of cryptography that employs multivariate\npolynomial equations to create cryptographic primitives such as digital signature schemes and public-key\nencryption schemes [40].\n\u2022 Hash-based cryptography: Hash-based cryptography relies on cryptographic hash functions to generate crypto-\ngraphic primitives such as digital signature schemes and key derivation functions [41].\nManuscript submitted to ACM\n10\nRen and Xu et al.\nGenerate quantum blockchain to \nto building Resilient Web 3.0 \ninfrastructure\nComplementary advantages and\ncomponents of quantum \nblockchain\nApplications and implementation \ntutorials of quantum blockchain \nin Web 3.0\nInternal Technologies\nExternal Performance \nQuantum entanglement\nQuantum hash\nConsensus\nIncentive\nContract\nCryptography\n\u2026\nDecentralization\nProfitability\nPrivacy and Security\nDigital \nFinance\nTechnological \nsupport\nUnderlying \nframework \nsupport\nApplications layer\nComponents layer\nInfrastructure layer\n\u2026\nSmart \nHealthcare\nSmart \nHome\nFig. 5. The taxonomy graph of Quantum-Driven Blockchain in Web 3.0\n\u2022 Code-based cryptography: Error-correcting codes, utilized in code-based cryptography, generate cryptographic\nkeys to secure communication [42]. These keys have various applications, including securing communication\nbetween parties in a blockchain system.\nLessons learned: The impact of quantum technology is twofold. On the one hand, quantum technology is the\nshield for blockchain. It achieves faster computing speed so that some complex problems can be solved in a shorter\ntime. Meanwhile, QKD-based protocols provide higher cryptographic security. Compared with traditional computers,\nquantum computers reduces energy consumption and impact on the environment. On the other hand, quantum\ntechnology is the spear for blockchain. Because of the increased computational power of quantum computers, quantum\ncomputer poses a serious security threat to many classical encryption algorithms. Therefore, we need to consider the\nspear and shield of quantum technology and design more secure quantum blockchain solutions.\n4\nMOTIVATION OF QUANTUM BLOCKCHAIN IN WEB 3.0\nThe limitations of blockchain and the complementary advantages of quantum information technologies are obvious.\nNaturally, the emergence of quantum information technology-assisted blockchain is expected to have a significant\nimpact on Web 3.0. In this section, we mainly discuss the motivation of quantum blockchain, as shown in Fig. 5.\n4.1\nWhat is the Quantum Blockchain\nCurrently, there is no standard definition for quantum blockchain. Shrivas et. al consider quantum blockchain as a\ndistributed, decentralized and cryptographic database based on quantum information theory and computation [43]. In\n[44], Nilesh et. al believes that quantum blockchains should satisfy the following properties. i) Decentralized architecture.\nii) A quantum network with a distributed ledger. iii) Nodes in a quantum network need to possess quantum capabilities,\ne.g., quantum storage and quantum state preparation. iv) Shared quantum database. Compared with classical blockchains,\nquantum blockchains have the following advantages [45]: i) More efficient. ii). More powerful. iii) More Secure. iv)\nCheaper. v) Smarter. vi) Easier to regulate.\nIn this survey, we believe that quantum blockchain in Web 3.0 is a technology that combines the principles of\nquantum information technologies and blockchain, aiming to create a more secure and efficient ecosystem for Web 3.0.\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n11\n4.2\nWhy Do We Need Quantum Blockchain in Web 3.0\n4.2.1\nLimitation of Blokchain. The motivation for quantum blockchains in Web 3.0 stems from the limitations of\ntraditional blockchains, which may be vulnerable to attacks from quantum computers. Next, we describe the limitations\nof blockchain in two aspects.\nInternal Technologies: The internal compositions of blockchain face many challenges.\n\u2022 Consensus protocol, the most prominent shortcoming of consensus is the high consumption of computational\nresources, resulting in low scalability and long latency for Web 3.0 services. Moreover, some protocols may suffer\nquantum attacks. Users with quantum computers can calculate hash values, making 51% of attacks possible.\n\u2022 Incentive mechanism, there are certain elementary risks associated with distributed digital currencies, such as\ndouble spending, Sybil attacks, and Eclipse attacks.\n\u2022 Smart contract, the powerful quantum computation poses serious security threats to the smart contract. Mean-\nwhile, creating a programming language for smart contracts in quantum logic deserves close attention and\nserious consideration.\n\u2022 Cryptography, with the advent of quantum computers, the main issue with classical blockchain is the possibility\nof cracking hash functions and classical digital signatures based on asymmetric cryptography.\nExternal Performance: The external properties face many challenges.\n\u2022 Decentralization, the decentralized architecture is subject to security threats, such as malicious attacks, transaction\ntampering, etc. Although blockchain technology can provide anonymity, it may also raise privacy concerns.\n\u2022 Profitability, classical cryptography in payment and voting protocols is threatened by quantum computers, raising\neconomic issues of anonymity, verifiability, fairness, profitability, etc., in Web 3.0 scenarios.\n\u2022 Privacy and Security, since blockchain nodes store a copy of all blocks, storage and the privacy of stored data are\nhuge problems as the number of blocks in the blockchain continues to grow.\n4.2.2\nBenefits of Quantum Information Technologies. Despite the limitations of blockchain, quantum blockchain is also\nmotivated by the benefits of quantum information technologies. Next, we describe these benefits in two aspects.\nInternal Technologies: Quantum information technologies bring benefits for internal compositions of blockchain.\n\u2022 Consensus protocol, the quantum consensus is more secure, efficient, and fair than traditional consensus protocols,\navoiding high consumption of computational resources while providing higher throughput.\n\u2022 Incentive mechanism, quantum blockchain provides effective mining strategies and a secure token system for\nincentives mechanism.\n\u2022 Smart contract, on the one hand, quantum computing and quantum communication ensure the security of smart\ncontracts. On the other hand, smart contracts based on post-quantum cryptography prevent quantum attacks.\n\u2022 Cryptography, some post-quantum migration methods, and anti-quantum signatures offer potential ways to\nachieve strong and unforgeable security under quantum attacks.\nExternal Performance: Quantum information technologies bring benefits to external properties of the blockchain.\n\u2022 Decentralization, decentralized quantum blockchain tackles the issues caused by centralized management,\nproviding a solution for achieving decentralization.\n\u2022 Profitability, combining classical cryptography and quantum theory, quantum cryptography has emerged to\nensure the absolute security of payment protocols. Quantum technology enables anonymous, verifiable, and fair\nvoting protocols, promoting economic prosperity and increasing profits in quantum markets.\nManuscript submitted to ACM\n12\nRen and Xu et al.\n\u2022 Privacy and Security, some quantum/post-quantum encryption and verification algorithms improve the commu-\nnication costs, robustness, and privacy of distributed storage.\nLessons learned: Due to the complementary advantages brought by quantum information technologies, it is obvious\nthat the converged quantum blockchain technology shows a path for implementing distributed Web 3.0 infrastructures.\nIn the following sections, we present deployment tutorials of quantum blockchain in Web 3.0 from two aspects, including\ninternal technologies optimization and external performance improvement.\n5\nINTERNAL TECHNOLOGIES OPTIMIZATION IN QUANTUM BLOCKCHAIN\n5.1\nQuantum Consensus Protocol\nIn the survey, we discuss the classification of quantum consensus protocol for Web 3.0 in detail to better understand\nquantum consensus. In this survey, the quantum consensus protocol refers to the improved consensus protocol in\nblockchain with the support of quantum technology.\n5.1.1\nQuantum-Based Classification . The quantum consensus protocols can be divided into the following two categories\nbased on the quantum mechanical features.\nMeasurement-based Consensus: With reference to the traditional consensus mechanism of blockchain and some\nproperties of quantum mechanics (i.e., randomness and irreversibility), a novel consensus mechanism of quantum\nblockchain is proposed [46]. This consensus integrates the zero-knowledge proof and quantum measurement. Here, we\npresent an example to demonstrate the steps of the Quantum zero-knowledge proof protocol. David and Ben have a\nhighly confidential secret number \ud835\udc34. Without loss of generality, assume David is the side who is trying to prove that he\nhas \ud835\udc34to Ben. The steps of the protocol are as follows.\n\u2022 1) Distribution of shared key: The quantum key distribution (QKD) protocol, such as BB84 protocol, is used to\ngenerate a shared key for David and Ben.\n\u2022 2) Quantum state preparation: David prepares several pairs of EPR entanglement photons and sends another\nphoton from each pair to Ben.\n\u2022 3) Security check: The measurement results between two parties check the security of the quantum channel.\n\u2022 Measurement and result encoding: The two parties perform the measurement and encode their results.\n\u2022 4) Transmission of proof information: David encrypts the classical bit string from encoding while sending the\nencryption result to Ben.\n\u2022 5) Verification of proof information: By comparing the classical bit strings generated by two parties, the proof\ninformation would be verified.\n\u2022 6) Reciprocal verification: By exchanging the roles of David and Ben, the protocol enables reciprocal verification.\nCompared with the traditional consensus, the measurement-based consensus is more secure and avoids high\nconsumption of computing resources while providing higher throughput.\nQKD-based Consensus: Recently, QKD was proven to be unconditionally secure and has been used in quantum\nblockchain schemes. In the quantum blockchain, each pair of nodes is connected by a classical channel and a quantum\nchannel, further forming a QKD network. Then, each pair of nodes uses the QKD network to establish a private key\nsequence for secure communication.\nAs the quantum public keys distributed by a node to other are the same, they cannot deny their actions. However,\nKiktenko et. al [11] leverage QKD to distribute keys for each pair of nodes for verification. In this way, the two-way\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n13\ncommunication requires \ud835\udc42(\ud835\udc5b2) implementations to distribution \ud835\udc42(\ud835\udc5b2) keys. In particular, these works cannot provide\nnon-repudiation because each pair of nodes shares the same key.\nBased on the unconditional security provided by QKD. A quantum communication protocol is designed [47]. By\nquantum-secured communication, a set of semi-honest participants distribute the sequences of correlated numbers.\nThese participants then exchange some information to reach a consensus. In the further development of this protocol,\nlow dimensional entanglement can be considered to replace the key distribution.\n5.1.2\nBlockchain-Based Classification. Referring to [48], consensus protocols in blockchain are classified into two\ngroups in Web 3.0. The first group is the proof-based consensus protocol that uses computational proofs to determine\nthe winner-generating block, such as PoW. The second group is the vote-based consensus protocol. In this regard, the\nnodes in the blockchain have equal votes and reach a consensus, such as PBFT. According to the blockchain-based\nclassification, we classify the quantum consensus protocol in the same way.\nProof-based Consensus: Traditional proof-based consensus in Web 3.0 is computationally intensive and time-\nconsuming, making blockchain systems inefficient.\nTo improve the blockchain consensus, the post-quantum threshold signature scheme is exploited [49]. This scheme\nis to solve quadratic equations in a finite field, which is resistant to attacks by quantum computers. Based on this\nnovel method, more than one and a half nodes in the blockchain network sign the new block using the post-quantum\nthreshold signature. As a result, it has a higher level of security. Furthermore, much of the computational complexity of\nthe consensus comes from the signature of the new block, which is much more efficient than the existing consensuses.\nCompared to current threshold signature schemes (e.g., RSA-based and elliptic curve signature-based algorithms),\npost-quantum threshold signatures are more promising and advantageous for future blockchain and other applications.\nVote-based Consensus: Due to the node-independent computing power, the quantum capabilities of all parties are\nunbalanced, causing proof-based consensus to be inapplicable. Therefore, the vote-based consensus is more suitable for\nquantum blockchain in Web 3.0.\nTo ensure the fairness of vote-based consensus, a quantum delegated proof of stake (QDPoS) based on quantum\nvoting is constructed [50], allowing for fast decentralization even if the quantum computer emerges in the future.\nLike DPoS, QDPoS elects a certain number of representative nodes to generate new blocks by quantum voting. The\nquantum digital signature is introduced to ensure the quantum blockchain\u2019s efficiency and security. Based on QDPoS\nand quantum digital signature, a quantum blockchain scheme is designed. Its structure is shown in Fig. 6. Notably,\nquantum blockchain uses quantum states to construct quantum blocks connecting by leveraging the entanglement\nproperty between quantum states.\nAs an extensively-applied consensus, PBFT is derived from the Byzantine Generals\u2019 problem. To achieve Byzantine\nagreement between multiple parties, a quantum byzantine agreement without entanglement is proposed [51]. The\nunconditional security of quantum key distribution contributes to the distribution of the relevant digital sequences,\nensuring the security of the Byzantine agreement protocol. To improve the efficiency of consensus, a quantum honest-\nsuccess Byzantine agreement protocol introduces quantum protection, and quantum certificate into the syntax of\ntransactions [52]. Similar to the work in [51], there is no use of multi-particle entanglement in these quantum blockchains,\nmaking them easy to implement with existing technology.\nManuscript submitted to ACM\n14\nRen and Xu et al.\nBlock n-1\nBlock n\nBlock n+1\nQuantum block\nQuantum data\nQuantum block\nQuantum data\nQuantum block\nQuantum data\nQuantum data 1\nQuantum public key 1\nHash\nSignature of owner 0 \nQuantum private key 1\nQuantum data 2\nQuantum public key 2\nHash\nSignature of owner 1 \nQuantum private key 2\nQuantum data 3\nQuantum public key 3\nHash\nSignature of owner 2 \nQuantum private key 3\nSign\nSign\nVerify\nVerify\nFig. 6. The structure of quantum blockchain\n5.2\nIncentive Mechanism\nThrough incentive mechanisms are well-studied in classical blockchain [53], the problem of how to design effective\nincentive mechanisms for participants in the quantum blockchain is still in its fancy in Web 3.0. To maintain the\ndecentralization of classical blockchain, incentives, e.g., static mining rewards and transaction gases, are distributed for\nmotivating miners to participate during the consensus process.\n5.2.1\nQuantum-based Mining Strategies. In addition to the PoW and PoS in classical blockchain in Web 3.0, the miners\nin a quantum blockchain leverage quantum resources, e.g., QKD, to record new transactions and blocks. Then, minors\nare rewarded with tokens in the quantum blockchain. For example, Azhar et al. [54] use quantum cryptography\nprotocols such as QKD to guarantee that communications in blockchain between participating nodes can be secure\nfrom third-party intrusion. Through the use of the six-stage QKD protocol [55], the transparency and immunity of\nblockchain-based cryptocurrency systems can be ensured. Furthermore, by observing the key rate generation on\nthe NumericalQKD simulation platform, the authors experimentally verify the feasibility of the protocol. This study\nprovides a direction for future quantum blockchain research. The above scenario for the key generation protocol can be\nimplemented when any blockchain system is developed.\nBased on the need to set up additional infrastructures such as quantum servers, the authors in [56] propose the\nconcept of proof-of-entanglement (PoE), which allows mining nodes of a quantum blockchain to reach consensus based\non quantum resources. Specifically, an energy-efficient interactive protocol is proposed that allows quantum blockchain\nminers to execute formulas based only on their optically encoded quantum information without having to trust the\nnetwork infrastructure.\n5.2.2\nSecure Token Systems. Similar to the idea of reaching a consensus based on entanglement resources, Sun et al.\nin [45] propose the incentive mechanism, namely Qulogicoin, for the quantum-enhanced logic-based blockchain. In this\nmechanism, the Byzantine agreement protocol is used with honest success to maintain the quantum blockchain under\nvarious fraudulent attackers, such as double-donating adversaries, manipulating adversaries, and bribed distributors.\nThrough implementation and testing based on current technologies, the authors demonstrate that the proposed\nincentive mechanism is efficient and powerful. In addition to the fungible tokens, non-fungible tokens (NFTs) for\nquantum blockchain integrates the best features of blockchain technology to provide a unique and authentic token, each\nwith unique properties and non-substitutable resources. Unfortunately, in terms of energy consumption for mining and\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n15\nlack of security, the current classical NFTs are costly. Therefore, instead of making quantum states representing NFTs\nphysically available to their owners, Pandey et al. in [57] propose a new protocol for preparing quantum irreplaceable\ntokens. The protocol is ultimately more efficient than Proof of Work (PoW) and incorporates Proof of Stake (PoS).\nThe proposed scheme is simulated and analyzed against various quantum computing attacks, including intercept and\nretransmit, entangle and measure, man-in-the-middle, and classical threats. It demonstrates its ability to withstand\nthese attacks. The authors expect the proposed protocol to replace classical NFTs as quantum hardware evolves. These\nquantum NFTs can be used to store patient monitoring and medical data cheaply and securely in the quantum blockchain.\nKaushik el al. in [58] propose an incentive mechanism for storing health data in the quantum blockchain that can\nensure veracity, integrity, and availability.\n5.3\nSmart Contract\nExisting smart contracts in Web 3.0 against quantum attacks strive to provide solutions for efficiency and scalability. On\nthe one hand, quantum computing and quantum communication can provide demonstrable security in the development\nof smart contracts. On the other hand, smart contracts based on post-quantum cryptography are partially secure against\nquantum attacks. These two solutions can provide efficient and scalable solutions for signing, executing, and verifying\nsmart contracts.\n5.3.1\nQuantum Cryptography-based Smart Contracts. The authors in [59] propose a smart contract-based architecture\nto defend against quantum attacks in quantum networks, based on quantum blind signatures. The theoretical analysis\nof the authors shows that the quantum signature scheme proposed in this paper, which is based on the properties of\nquantum entanglement, can be used for both single and multiple signatures, and can improve the security of blockchain\nsmart contracts against quantum attacks. First, the authors carefully analyze the message processing and transmission\nof the quantum blind signature in this framework. Then, they describe the lifecycle and signature rules of quantum-\nblind signatures for smart contracts. In addition, the authors explain the algorithm design and operation, analyze the\nalgorithm\u2019s security performance, and propose a quantum blind signature protocol for a lightweight signature of smart\ncontracts. Finally, based on the original single signature algorithm, a more complex quantum blind signature algorithm\nfor multiple signatures is proposed, and its security performance is analyzed. Furthermore, Cai et al. in [60] propose a\nframework for multiparty transactions based on the quantum blind multi-signature method in a decentralized manner.\nIn this framework, the authors develop a quantum blind multi-signature algorithm that includes initialization, signing,\nverification, and implementation to provide computationally efficient and scalable solutions for the quantum blockchain.\n5.3.2\nPost-quantum Smart Contracts. For a blockchain relying on smart contracts, the usefulness of smart contracts\nagainst quantum attacks can also be strengthened by post-quantum cryptography. For example, Karbasi et al. in [61]\nhave proposed an end-to-end encryption scheme to protect against man-in-the-middle and eavesdropping attacks. In\n[62], to use a logic-based smart contract programming language in a recently proposed quantum-secure blockchain\nframework, the authors investigate the use of logic and logic programming in smart contract design. The authors\npropose a logic-based smart contract programming language called Logicontract (LC), where the logic used in LC is\nextended with modern declarative logic programming methods. The introduction of post-quantum signatures overcomes\nthe specific limitations of LC, where unconditionally secure signatures, despite their strength, have limited protection\nfor users of the same node. The next step is to investigate its use for secure multiparty computing. Another goal is to\nextend our logic language to include the original quantum language, thus creating a programming language for smart\ncontracts in quantum logic. As an important application in cloud computing, Li and others in [63] are exploring the use\nManuscript submitted to ACM\n16\nRen and Xu et al.\nof post-quantum blockchain for provable data ownership. To avoid the single point of failure and partial trust caused\nby a centralized external auditor. Grid-based, privacy-preserving, verifiable data ownership is enabled based on smart\ncontracts. The analysis demonstrates the correctness, soundness, and performance of the proposed system through a\nseries of interactive games.\n5.4\nPost-Quantum Migration for Blockchain\nTo effectively avoid the risk associated with pre-quantum blockchain, some post-quantum migration methods have\nbeen proposed by many researchers in recent years. In this subsection, we explore the implementation of post-quantum\nmigration in the following mechanisms. We list details of the existing research works in Table 1.\n5.4.1\nPublic Key Post Quantum Cryptosystems . There exist four types of post-quantum cryptosystems and a fifth type\nof cryptosystem with a mixture of pre-quantum and post-quantum.\nCode-based cryptosystem: It is based on the theory supporting error-correcting codes. For example, McEliece\u2019s\ncryptosystem can perform fast encryption and decryption in blockchain [81]. Nonetheless, this cryptosystem requires\nstoring and executing operations of large matrices, a restriction for resource-constrained devices. To address this\nproblem, some code-based post-quantum encryption cryptosystems investigate matrix compression techniques, as well\nas specific coding techniques. Notably, the NIST call for post-quantum public-key cryptosystems is currently in its\nsecond round [64, 65], with the first standard draft expected to be released between 2022 and 2024. These cryptosystems\nadjust the required security parameters while ensuring classical security between 128 and 256 bits. Compared with the\ncurrent ECDSA [82] and RSA-based [83] encryption systems, these post-quantum encryption cryptosystems offer the\nbest trade-off between security and key size.\nMultivariate-based cryptosystem: It depends on the complexity of solving systems of multivariate equations,\nwhich turns out to be NP-hard [84].\nCurrently, some multivariate-based schemes are based on the use of square matrices with random quadratic polyno-\nmials, cryptographic systems derived from the Matsumoto-Imai algorithm [66], and schemes depending on hidden\nfield equations [67]. These schemes are more suitable for Web 3.0 scenarios by reducing the key size and ciphertext\noverhead while increasing the decryption speed.\nLattice-based cryptosystem: It depends on the presumed hardness of lattice problems [85] that cannot currently\nbe solved by quantum computers.\nLattice-based schemes allow for accelerated blockchain user transactions and can be executed efficiently as they are\ngenerally simple to calculate. The implementations of these lattice-based schemes require the storage and utilization\nof large keys [68]. The general schemes guarantee classical security between 128 and 368 bits and quantum security\nbetween 84 and 300 bits. Based on the security level they provide, the complexity of these schemes varies significantly.\nHybrid cryptosystem: It merges pre-quantum and post-quantum cryptosystems with the aim of protecting the\nexchanged data from quantum attacks. For instance, X25519 merging New Hope [69] with an ECC-based Diffie-Hellman\nkey agreement scheme has completed the testing by Google [70].\nDifferent from the existing public key infrastructure, the quantum state information cannot be copied. Thus, only\nthose who know the exact quantum state can create and distribute public keys. Additionally, all the above cryptosystem\nimplementations require significant computational resources and more energy consumption. Therefore, the post-\nquantum cryptosystems for blockchain should aim to find a balance between security, computational complexity, and\nresource consumption.\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n17\nTable 1. Details of the existing post-quantum migration methods for blockchchain in Web 3.0.\nTypes\nRef.\nRequired\nTechnology\nBenefits\nContribution\nPublic key post\nquantum cryptosystems\n[64, 65]\nPost-quantum\ncryptography\nSecurity\nAdjust the required security parameters of the cryptosys-\ntem\n[66, 67]\nSquare matrices with\nrandom quadratic\npolynomials\nHigher decryption\nspeed\nPropose a new variant of the cryptosystem which is\nmore suitable for Web 3.0 scenario\n[68]\nPolynomial algebra\nSecurity,\nefficiency\nPropose a new public key cryptosystem, allowing for ac-\ncelerated blockchain user transactions\n[69, 70]\nKey-exchange protocol\nPost-quantum\nsecurity\nPropose new parameters and a better suited error dis-\ntribution to protect the exchanged data from quantum\nattacks\nPost-Quantum\nSignature Algorithms\n[71, 72]\nQuantum digital\nsignatures, quantum\nteleportation\nSecurity, privacy\nPropose secure mechanisms for performing transactions\non the blockchain network\n[73]\nQuantum-resisting\nsignature\nLow\ncomputational\ncomplexity,\nunforgeability\nPresent post-quantum blockchain and a secure cryp-\ntocurrency scheme to resist quantum computing attacks\n[74, 75]\nAnti-quantum\nsignature\nLightweight,\nsecurity\nPropose an anti-quantum transaction authentication\nscheme in the blockchain\n[76]\nPost-Quantum\nCryptography\nPracticability\nDevelop a signature scheme for practicability and use in\nembedded systems\n[77]\nPost-quantum\ncryptography\nInternal\ntechnologies\nIntroduce a modified lattice-based signature scheme for\ndecentralized PKI system\nQuantum\nNetworked\nTime Machine\n[78]\nQuantum\nentanglement\nScalability\nPresent a new approach generating quantum entangle-\nment between many photons by using only a single\nsource of entangled photon pairs to solve the scalability\nproblem\n[12]\nQuantum\nentanglement\nSecurity\nOverview of a conceptual design of a quantum\nblockchain using entanglement, which includes encod-\ning the blockchain as a temporal Greenberg-Horn-\nChalinger state of photons\nQuantum\nHashing\n[79]\nQuantum hash\nRobustness\nPresent a novel multimedia identification system based\non quantum hashing\n[80]\nFourier transform\nfeatures, controlled\nrandomization\nSecurity,\nrobustness\nDevelop a novel algorithm for generating an image hash\n5.4.2\nPost-Quantum Signature Algorithms. The rapid development of quantum computers poses significant security\nrisks to the cryptographic algorithms underlying blockchain networks. To overcome the vulnerabilities of the blockchain\nnetworks to quantum adversaries, some potential anti-quantum signature algorithms have been proposed.\nUsing quantum digital signatures and quantum teleportation phenomenon, a quantum secure theme is presented to\nimplement the blockchain [71]. In particular, messages are signed by quantum digital signatures [72] and then they are\ndistributed across the blockchain network by the teleportation phenomenon, creating the opportunity to build a more\nsecure and faster blockchain for Web 3.0.\nManuscript submitted to ACM\n18\nRen and Xu et al.\nBased on lattice cryptography, novel quantum-resisting signature schemes are used for transaction authentication in\nblockchain-enabled systems. In particular, the lattice basis delegation algorithm provides a way to generate secret keys\n[73]. Then, the double signature, defined as the first signature and last signature, is developed to reduce the correlation\nbetween the message and the signature. The secure cryptocurrency scheme combines the proposed signature scheme\nwith the blockchain, satisfying correctness and having the advantage of resisting quantum computing attacks.\nDifferent from the previous elliptic curve signatures, a new signature authentication scheme leverage Bonsai Trees\ntechnology to generate the extended lattice accompanied by the corresponding key and then generate the signature [74].\nUsing this signature, the anti-quantum transaction authentication approach achieves strong and unforgeable security\nunder selected message attacks. In addition, by combining Bonsai Trees technology and the RandBasis algorithm, public\nand private keys can be generated for verifying the transaction message [75]. Meanwhile, the size of the public key,\nprivate key, and signature are smaller than the similar methods, further decreasing the computational complexity and\nincreasing the implementation efficiency. Regarding the work in [76], a lattice-based signature scheme is developed to\noptimize embedded systems. For a 100-bit security level, 9,000 bits signatures need to be generated by using a 12,000-bit\npublic key and a 2,000-bit private key. Due to its simplicity and efficiency, this scheme is considered a new signature\nalgorithm for managing public key encryption for a post-quantum decentralized system, such as QChain [77].\n5.4.3\nQuantum Networked Time Machine. It is a conceptual design for quantum blockchain. This means if a quantum\nblockchain are to be constructed, it could be regarded as a quantum networked time machine.\nEntanglement in time, as opposed to entanglement in space, plays a key role in the quantum benefits of classical\nblockchains. In [78], the authors use the temporal GHZ state of the photon as a blockchain, providing a key quantum\nadvantage over spatial entanglement. In this conceptual system, a temporal Bell state as a block contains two classical\nrecords, and a growing temporal GHZ state has been taken as a chain.\nIn this way, the functionality of timestamped blocks and hash functions are replaced with temporal entanglement\n[12]. The quantum advantage is a significant amplification of the susceptibility to tampering, meaning that if one\nuser tampers with a single block, the complete local copy of the blockchain might be destroyed. While for a classical\nblockchain, only the block after the tampered block is destroyed, making it vulnerable to vulnerabilities. This work\noffers the realistic possibility of deploying pure quantum blockchains.\n5.4.4\nQuantum Hashing. It aims to improve the robustness of the binary hashing systems using the same intermediate\nhash values against various distortions.\nBased on the severity of the distortion, the Hamming weight of the D-bit binary hash difference between a query\nand its true-underlying content can vary from 0 to D. The probability that each bit of the D-bit binary hash difference\nevaluated by the quantum hashing system is 1. Instead of using a definite hash value in a binary hash, quantum hashing\nincorporates uncertainty in the hash value [79]. More importantly, the main difference between a quantum hashing\nsystem and a binary hashing system is the way the dissimilarity between the query and the candidate data in the binary\nhash database is calculated.\nIn the binary hashing system, the system extracts the intermediate hash from the query. It encodes it as a binary\nhash to find the matching pair in the binary hash database [80]. Then, the dissimilarity between the query and the\ncandidate data is obtained. Compared to this binary hashing system, the quantum hashing system does not require\nadditional storage as the quantum hashing algorithm uses the same binary hash database as the binary hashing\nalgorithm. Moreover, acceptance and rejection decisions can be made with a slight increase in computational cost. It\nprovides a novel post-quantum migration algorithm for blockchain against quantum attacks.\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n19\nLessons learned: In the survey, we explore the internal technologies optimization in the quantum blockchain. It aims\nto improve the internal components of the blockchain, including designing unconditionally secure quantum consensus,\neffective incentive mechanisms, and scalable smart contracts. effective incentive mechanisms, and scalable smart\ncontracts. These show that quantum information technologies offer promising solutions for blockchain optimization\nthat can further facilitate the construction of Web 3.0 infrastructure.\n6\nEXTERNAL PERFORMANCE IMPROVEMENT OF QUANTUM-DRIVEN WEB 3.0\n6.1\nQuantum Blockchain Economy\nThe quantum blockchain economy refers to establishing a secure and decentralized Web 3.0 economic model with the\nsupport of quantum and blockchain technology. In this section, we mainly explore the quantum blockchain economy\nand list details of the existing research works in Table 2.\n6.1.1\nPayment Protocol. E-commerce has become a major force in the global economy because of the convenience and\naccessibility it provides. The growth of e-commerce has also led to the development of new payment models, such\nas electronic cash (E-cash) payment protocols. Compared with other protocols, E-cash is becoming a more desirable\npayment protocol due to its anonymity and offline transferability. Currently, the security and cryptography of electronic\npayment have been the focus of research. Particularly, classical cryptography in electronic payment might be threatened\nby quantum computers with the development of quantum computing [86].\nTo address the above challenges, quantum cryptography, combining classical cryptography and quantum theory,\nappears to ensure the unconditional security of payment protocol. Based on the quantum blind group signature with\ntwo trusted third parties [87], an E-payment system is established, and then a cross-bank electronic payment protocol\nbased on the quantum proxy blind signature emerges [88]. Nevertheless, the presence of a dishonest customer in\na payment protocol leads to a risk that some purchase information may be leaked. Different from the proxy blind\nsignature, quantum multi-proxy blind signature and group blind signature can be used in the e-payment protocol with\na third-party platform to further guarantee the customer\u2019s anonymity [89, 90].\nBlockchain acts as a trusted third party, integrated with quantum technology, to achieve reliable trust between\nboth parties of the transaction [91, 92]. These studies propose an e-payment protocol implemented by blockchain and\nquantum signature. Specifically, these works describe in detail the main characters and implementation process of the\nquantum e-payment system as follows.\nMain characters: i) Customer. (ii) Two customer agent banks, denoted as bank \ud835\udc34and bank \ud835\udc35, respectively.\n(iii)Representative of the bank, denoted as \ud835\udc45. (iv) Merchant. (v) Blockchain.\nImplementation process: When a customer pays for online purchases, he finds that bank A has a low balance. In\nthis case, he runs out of bank A\u2019s money, and then he pays bank B the rest of the price. In this process of transaction, \ud835\udc45\nreceives the purchase information of the customer by QKD protocols. Meanwhile, \ud835\udc45plays as the proxy signer to sign\nthe payment slip when the settlement is completed. After, the customer sends a signed blind copy to the merchant by\nusing the Bell-state measurement performed by agent banks \ud835\udc34and \ud835\udc35.\nBy leveraging the property of quantum proxy blind signature, the anonymity of e-payment is guaranteed. Furthermore,\nblockchain technology stores all the information of customers and helps the merchant verify the legitimacy of the\nsignature. This scheme has good application prospects and wide application value.\nManuscript submitted to ACM\n20\nRen and Xu et al.\nBlockchain\nAuctioneer\nBidder\nQuantum server\nEncrypted price\nBid\nEncrypted price\nBid\nQuantum random key\nEncrypted \nbid\nEncrypted \nbid\nRegister personal \ninformation on \nquantum server\nRegister personal \ninformation on \nquantum server\nFig. 7. An auction on the quantum blockchain\n6.1.2\nMarket Mechanism. A number of voting protocols based on quantum blockchain have been developed to address\nthe risks posed by the upcoming quantum computers, providing anonymous, verifiable, fair, and self-tallying voting\nwhile simplifying the task of electronic voting. Similar to the voting protocol on the Bitcoin blockchain, the voting\nprotocol supported by the quantum blockchain consists of two phases: a ballot commitment phase and a ballot tallying\nphase [93]. In this voting protocol, quantum secure communication (QSC) is leveraged to distribute the matrix by voters,\nthen voters give the masked ballots to miners. Afterward, quantum byzantine agreement (QBA) is used by miners to\nachieve consensus about voters\u2019 masked ballot.\nMoreover, auctions are one of the more important market mechanisms in the quantum blockchain economy. It\nallocates resources according to a set of market rules and prices determined by buyers\u2019 bids. Blockchain-based auctions\n[94] satisfy decentralization in auctions, and quantum auctions [95, 96] satisfy unconditional security, but existing\nauction protocols cannot guarantee both properties. In [97], an auction on the quantum blockchain is proposed to solve\nthis problem. Fig. 7 shows a simple flow of the auction process. There are three types of participants in this auction\nprotocol, sellers, buyers, and miners. This auction process is divided into five stages,\n\u2022 1) The bidding phase: Each buyer announces his bid to the sellers and to all miners by quantum bit Commitment.\n\u2022 2) The opening phase: Each buyer opens his bid to the sellers.\n\u2022 3) Decision phase: The winning bid and the winning buyer are determined.\n\u2022 4) Verification phase: This stage convinces miners that the buyer has picked an effective winner.\n\u2022 5) Publication phase: Achieving consensus and adding it to the blockchain.\nIn general, the transactions of the auction are stored in the blockchain and supported by quantum computation and\ncommunication to enhance security and protect privacy. As one of the major auction protocols, the sealed-bid auction\nprotocol using a quantum-based blockchain is explored [98]. This protocol uses quantum computing and blockchain\ntechnology to guarantee essential features and requirements.\n\u2022 1) Registration: Bidders interested in the auction register their personal information on the quantum server.\n\u2022 2) Generating quantum keys: Quantum server shares random QKD-based keys with the auctioneer and bidder to\nencrypt data and authenticate their identities.\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n21\n\u2022 3) Data encryption and submission: Each bidder and the auctioneer encrypt the private bid and the lowest\nacceptable price using the encryption keys, and submit the encrypted data to the blockchain, respectively.\n\u2022 4) Data evaluation and announcing the winning bid: The quantum server downloads all submitted bids and the\nauctioneer\u2019s encrypted data to calculate the winning bids and submit them to the blockchain.\n\u2022 5) Verification: Each bidder verifies the winning bid by comparing the submitted bid with the winning bid.\nThe quantum blockchain-based lottery and auction protocols satisfy the significant features of distributed lotteries\nand auctions and can be implemented by existing technologies. It is believed that quantum blockchains can provide\nnew insights into its market economic mechanisms.\n6.2\nDecentralization\nIn the quantum blockchain, classical data chains are redesigned in a quantum way by associating quantum states with\nentanglement. In this case, quantum decentralization is claimed to be \u201cunconditionally secure\". Moreover, quantum\nblockchain infrastructure, such as access control and user authentication, must be established prior to any quantum\ndecentralization. In this survey, we focus on decentralized identity management in the quantum blockchain.\nThe current Internet keeps the digital identities of users in centralized storage. Centralized identity violates user\nprivacy and may experience problems such as single points of failure or information tampering. Decentralized identity\nmanagement based on quantum blockchain has been proposed to tackle the issues caused by centralized identity. The\nquantum blockchain identity framework (QBIF) is a popular method for implementing secure pseudonyms [99]. In QBIF,\nusers control their identities and use them without revealing unnecessary information. Meanwhile, identities are secure\nand authentic in a decentralized quantum environment, further protecting privacy and preventing forgery [107, 108].\nNext, we mainly introduce various aspects of the QBIF architecture, including roles, quantum identity attestations\n(QIAs), and quantum blockchain.\n6.2.1\nRoles in QBIF. Within this framework, QBIF has three roles, including identity owners, identity issuers, and\nidentity verifiers. Identity issuers represent trusted parties that issue identities. In addition, they verify the validity of\nidentity attributes and issue attestations, stored on blockchains. Users, i.e. owners, determine their own identity and\nuse on-chain authentication to prove to verifiers their identity. The verifiers provide services based on the reputation of\nthe issuer who offers the attested identity.\n6.2.2\nQuantum Identity Attestations. Quantum identity attestations, also called QIAs, are stored as quantum states\nand chained together by entanglement [109]. The QIAs are generated by issuers, and then verifiers perform QIA\nauthentication according to user requirements. After, the users who want authorized actions from verifiers need to\nperform the authentication and proof process.\nAttestations are evidence of statements about the user\u2019s identity, and they can be hash values, encrypted messages\nor bit strings, etc. QIAs in QBIF can be created by converting them into quantum bits [100]. A user can have multiple\nQIAs for different identity properties. Before using the QIA, it should be double-signed by the owner and the issuer,\nwhich are stored in the chain of quantum states. The signature is done between them using the private key signature\nof both parties. The use of the issuer\u2019s private key signature illustrates that the issuer agrees with the user\u2019s attested\nstatement, while the use of the user\u2019s private key signature indicates ownership of the attestation.\n6.2.3\nIdentity Management on Quantum blockchain. QBIF provides distributed identity management for coordinating\nquantum network nodes (including users, issuers, and verifiers). These nodes are interconnected through a quantum\nManuscript submitted to ACM\n22\nRen and Xu et al.\nTable 2. Details of the existing works in external performance improvement.\nType\nRef.\nQuantum\nTechnology\nBenefits from\nquantum\nContribution\nSecurity\nAnalysis\nStorage\nAnalysis\nQuantum Blockchain\nEconomy\n[87]\nquantum key\ndistribution\nUnconditional\nsecurity\nPropose a new E-payment system\nbased on quantum blind and group\nsignature\n\u2713\n\u00d7\n[88\u2013\n90]\nQuantum proxy\nblind signature\nSecurity,\nanonymity\nDevelop e-payment systems to sup-\nport inter-bank transactions\n\u2713\n\u00d7\n[91, 92]\nQuantum proxy\nblind signature,\nquantum key\ndistribution\nSecurity,\nanonymity\nDescribe in detail the implementation\nprocess of the quantum e-payment\nsystem\n\u2713\n\u00d7\n[93]\nQuantum\ncomputation\nAnonymity,\neligibility\nDevelop a simple voting protocol\nbased on quantum blockchain\n\u2713\n\u00d7\n[94\u2013\n96]\nQuantum\ncommunication\nSecurity, fairness\nPresent the economic and feasible\nquantum auction protocols\n\u2713\n\u00d7\n[97, 98]\nQuantum bit\ncommitment\nUnpredictability,\nunforgeability,\nverifiability,\ndecentralization\nPresent a protocol for auction on\nquantum blockchain\n\u2713\n\u00d7\nDecentralization\n[99]\nQuantum\ncomputing,\nquantum\nnetworks\nDecentralization,\nsecurity\nProvide a theoretical analysis of the\nquantum blockchain for decentral-\nized identity authentication\n\u2713\n\u00d7\n[100]\nQuantum identity\nauthentication,\nzero-knowledge\nproof\nUnconditional\nsecurity\nPropose a theoretical scheme for zero-\nknowledge proof quantum identity\nauthentication\n\u2713\n\u00d7\nScalability\n[101]\nQuantum\nnetworks\nDecentralization,\nscalability\nIntegrate smart contracts and quan-\ntum lightning to improve the speed of\npayment transactions\n\u2713\n\u00d7\n[102]\nQuantum\nteleportation\nLow throughput\nand latency\nPropose a consensus mechanism to\nreduce resource consumption\n\u00d7\n\u2713\nPrivacy of\nstorage\n[103]\nPost-quantum\nencryption\nLow storage cost,\nrobustness\nPropose a secure threshold verifiable\nmulti-secret sharing scheme for trans-\naction verification and private com-\nmunication\n\u2713\n\u2713\n[104,\n105]\nQuantum\nteleportation\nLow throughput\nand latency\nPresent a secure threshold-based ver-\nifiable multi-secret while improving\nthe recovery communication cost and\nrobustness\n\u00d7\n\u2713\n[106]\nQuantum\nsignature\nAnonymity,\nunforgeability,\nshareability\nDevelop\nan\nanti-quantum\nsigna-\nture for secure data sharing with\nblockchain\n\u2713\n\u00d7\ncommunication channel. Each type of quantum network node has a copy of a quantum state chain that holds signed\nQIAs in chronological order. Once a QIA is kept in the blockchain, the user sends the location of the signed QIA to\ninitiate the verifier\u2019s operation. Then, the verifier validates the signed QIA using the public keys of the user and the\nissuer to determine the authenticity of the QIA. It\u2019s worth noting that the validity level of the validity can be defined\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n23\nby the issuer using the password, online, etc. In addition, the validity level can be integrated into the QIA by adding\nadditional quantum bits.\nThis quantum blockchain identity management deals with the primitive quantum blockchain structure, where some\ndata transfer and payment transactions can take place off-chain. With the development of quantum technology, a\nhybrid network of classical and quantum communications might be the best way to transition from classical to quantum\nInternet. Meanwhile, the proposed framework faces some limitations and challenges, but it shows an obvious path to\nrealize the decentralization of quantum blockchain.\n6.3\nScalability\nScalability is a central issue of quantum blockchain that has attracted the attention of researchers. It aims to increase\ntransaction throughput (i.e., transactions per second) while keeping the resources required for a party to participate in\nthe consensus mechanism roughly constant and maintaining security against adversaries.\nTraditional blockchains, such as Bitcoin and Ethereum, can currently only process 10 transactions per second.\nQuantum information is intrinsically well-suited to solve this problem. With the help of quantum technology, classic\nblockchains can leverage quantum cryptography to give the solution to the scalability problem. Moreover, smart\ncontracts in blockchain can be combined with quantum tools, specifically quantum lightning, to design a decentralized\npayment system that addresses the scalability of transactions. Quantum lightning was proposed by Zhandry [110]\nand inspired by the concept of collision-resistant quantum money [111]. The quantum lightning scheme for payment\nsystems consists of a generation process to generate quantum banknotes and a verification process to validate the\nquantum banknotes and assign serial numbers to guarantee security. Here, the security guarantee means that no\ngeneration process can produce two banknotes with the same serial number unless the probability is negligible. This\nproperty prevents anyone from cloning banknotes. As such, it requires a mechanism to regulate the generation of new\nvalid quantum banknotes.\nColadangelo et. al proposed the smart contract is used to keep track of valid serial numbers [101]. Any party is\nallowed to deposit coins \ud835\udc51into a smart contract with specific parameters, and with an initial value of a serial number\nstate variable. We can consider that the quantum banknote with the chosen serial number \u201cgets\" the value of \ud835\udc51. The\nintegration between smart contracts and quantum lightning improves the speed of payment transactions, further\ntackling the problem of scalability.\nMoreover, a consensus mechanism based on quantum cryptography, and quantum measurement is designed to\nreduce throughput and latency [102]. This scheme aims to determine the success of miners\u2019 mining while avoiding\nconsuming a large number of computing resources and mathematically complex calculations in the mining competition.\nTherefore, it reduces resource consumption. Additionally, quantum teleportation mainly consists of classical information\ntransmission and quantum gates performing. It takes a very short time, while the transmission of quantum states is\ncompleted instantaneously. Therefore, the scalability of this scheme is high and the delay is small theoretically.\n6.4\nPrivacy of Storage\nTraditional blockchain systems store transaction data in the form of a distributed ledger, with each node storing copies\nof all data, which raises the storage problem. With the development of quantum technology, numerous researchers are\nlooking for suitable quantum/post-quantum encryption and verification algorithms to improve standard distributed\nstorage blockchain systems.\nManuscript submitted to ACM\n24\nRen and Xu et al.\nDoctor\nPatient\nAttribute \ndistribution\nAttribute \ndistribution\nResearcher\nRelative\nRecord \nRequesters\nAttribute authority\nBlockchain\nTreat, generate, \ntransmit \nand sign EMR\nUpload the key \nand sign keywords\nUpload the key \nand deploy smart\ncontract\nUpload the key \nand deploy smart\ncontract\nSign and upload \nencrypted EMR\nSubmit \nindex hash\nVerify signatory attributes \nand decrypted EMR\nFig. 8. The system architecture of AQ-ABS\n6.4.1\nPost-quantum Based Distributed Storage. Existing research work proposes some secret sharing schemes to\novercome the problem of distributed storage. Secret sharing, as one of the most important encryption protocols, is used\nto ensure the privacy of data [112, 113].\nA secure threshold-based verifiable multi-secret sharing scheme is proposed that does not require a private channel\nand shares two secrets simultaneously in a single sharing process among blockchain nodes based on post-quantum\nencryption algorithms [103]. The scheme is then applied to a distributed storage blockchain system for the distribution\nand private storage of data blocks. Before distributing the data among the nodes of each block, we encrypt the data\nblocks with the AES-256 encryption algorithm. Meanwhile, this scheme shares secret keys and hashes of the blocks\namong the blockchain network nodes simultaneously. After, the encrypted data blocks are encoded by Reed-Solomon\ncodes and shared among these blockchain nodes.\nIn addition, several secret sharing schemes based on lattices have been studied in [114, 115]. Based on these post-\nquantum encryption schemes, the distributed storage blockchains also greatly improve the storage costs of traditional\nblockchains [104, 105]. The scheme also brings desirable features to distributed storage blockchain systems, such\nas (quantum-secure) authentication algorithms and secret communication without private channels. Notably, the\nflexible threshold parameters of the proposed scheme eliminate the shortcomings of the previously distributed storage\nblockchain in terms of recovery communication cost and robustness.\n6.4.2\nImplementation Tutorial for Storage. Taking electronic medical records (EMRs) as an example, this section\nintroduces how to realize distributed data storage with blockchain-based on quantum technology.\nAlong with the unceasing progress of medicine, it has become a popular trend to implement EMRs to improve\nthe efficiency and reliability of medical services [116, 117]. Nonetheless, EMRs are stored independently in hospitals\nand healthcare facilities, which leads to sharing problems. In addition, highly sensitive EMRs are vulnerable to being\ntampered with, posing a threat to privacy and security. An anti-quantum attribute-based signature (AQ-ABS) is developed\nto address the above challenges [106]. AQ-ABS combines IPFS with the consortium blockchain to encrypt and sign\nEMRs, then store them in a secure and distributed file storage system, i.e. interPlanetary file system (IPFS). After, the\nindex hashes generated by IPFS and keywords are re-signed and stored in the blockchain. As shown in Fig. 8, the system\nimplementation process for EMRs shared plans are divided into the following phases.\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n25\n\u2022 System Initialization: This step includes registration and security parameter settings. These attributes and secret\nkeys are uploaded to the blockchain.\n\u2022 EMR Generation: When a user is treated for a disease at one hospital, it can consult the hospital and generate an\nEMR, as in Figure 1. If the user needs to be transferred to another hospital for treatment, the physicians at that\nhospital must be familiar with the patient\u2019s previous medical experience. That is, each physician is responsible\nfor uploading the EMR for data sharing. In this case, the EMR record is generated during the doctor\u2019s treatment.\n\u2022 Signature Generation and Uploading: The physician responsible for the consultation sends an EMR to the patient\nto confirm the accuracy of the EMR. After receiving the EMR with the user\u2019s signature, the physician encrypts\nthe EMR by [118] and signs it to ensure unforgeability based on AQ-ABS. In addition, a combination of IPFS and\nconsortium blockchain is used to achieve secure EMR sharing. A physician uploads an encrypted EHR with a\ndouble signature to IPFS to obtain an index hash. The physician then signs the index and keywords of the EHR\nand uploads them to the blockchain for distributed storage, while the patient deploys a smart contract to the\nblockchain for access control of the EHR.\n\u2022 Query and Signature Verification: This step allows the user to download the EMR and verify the signature. As a\npatient\u2019s relevant researchers wish to access the electronic medical record, they first provide their attributes to\nthe blockchain, which is verified by the smart contract, and search the index. If it is accessible, the blockchain\nreturns the index value with the signature, otherwise, it rejects it. After receiving the signed index, the record\nrequester verifies the signature, and if it passes the verification, submits the index to IPFS for EMR.\nLessons learned:In the survey, we explore the external performance improvement in the quantum blockchain,\nincluding quantum blockchain economy, decentralization, scalability, and privacy of storage. This section explains\nthat quantum information technology can promote the performance of blockchain, further improving the underlying\ninfrastructure of Web 3.0, accelerating the construction of Web 3.0 application scenarios, and exploring the implementa-\ntion of Web 3.0 application scenarios. Overall, we summarize the above-mentioned works of external performance\nimprovement in Table 2.\n7\nAPPLICATIONS AND IMPLEMENTATION TUTORIALS OF QUANTUM BLOCKCHAIN IN WEB 3.0\nThis section briefly introduces some applications and implementation tutorials of quantum blockchain in Web 3.0,\nThese applications include chain-native services and digital transformation applications, as shown in Fig. 9 and Fig. 10,\nrespectively.\n7.1\nChain-Native Services\n7.1.1\nDigital Finance. Modern digital finance is more concerned with features such as high reliability and security. As\nthe major blockchain-based innovation, non-fungible token (NFT) is a non-fungible digital asset that cannot be replaced\nby its equivalent one [119]. Further, it connects the physical world with the real world through numerous applications,\nsuch as identity, private equity transactions, intellectual property assets, digital collection, etc. To ensure the security\nof quantum NFT, the work in [57] proposes a novel protocol on a blockchain where the traditional ledger and hash\nfunctions are replaced by entanglement. This Quantum NFT protocol generally has three steps, including the creation\nof a block of NFT, the creation of token, and the verification of the blocks.\n7.1.2\nMetaverse. Based on decentralized finance, Metaverse operates with its own economy, drawing escalating\nattention to the next-generation Internet. Generally, Metaverse is defined as a shared virtual space formulated by\nManuscript submitted to ACM\n26\nRen and Xu et al.\nChain-Native Application\nMetaverse\nPhysical world\nInteraction\nDigital Finance\nPayment\nSocial Network\nImmersive \nservice\nFig. 9. Chain-native services of quantum blockchain in Web 3.0\nsensing, communication, and computing technologies, etc. Meanwhile, other technologies, such as blockchain, and\nquantum computing, are proving popular for a number of key Metaverse applications [120], as shown in the following.\n\u2022 Security: As more interactions between the physical and the virtual world in the Metaverse are captured, quantum-\nresistant blockchain technology is designed for all transactions and commerce. This also ensures that blockchain\ntransactions remain safe against algorithms such as Shor\u2019s algorithm [121].\n\u2022 Computation: One of the significant advantages of quantum blockchains is that they are computationally efficient,\nensuring the increased effectiveness of Metaverse applications. Concretely, quantum blockchain enhances the\ncomputation and overall experience, which makes the Metaverse user-friendly.\n\u2022 Randomness: To ensure that the blockchain-based Metaverse system is not manipulated by occupants and\nalgorithms, a certain amount of quantum randomness is needed. Instead of pseudo-random numbers, a qubit\nseries is leveraged to generate random bits, further preventing the metaverse from being utilized in unscrupulous\nways. Currently, some companies, such as Quantum Dice [122], are working in the field of quantum random\nnumber generation.\n7.2\nDigital Transformation Applications\n7.2.1\nSmart Cities. Smart cities aim to develop protocols and technologies to improve the quality of People\u2019s daily life.\nIn this regard, quantum cryptography helps to eliminate the risk of data storage and transmission. The work in [123]\ndesigns a novel authentication and encryption protocol using quantum walks (QIQW). The QIQW protocol enables IoT\nnodes in smart cities to securely share data and have full control of their records. Meanwhile, the novel blockchain\nframework based on QIQW is able to resist probable quantum attacks.\nIn addition, post-quantum blockchain (PQB) is another solution to improve the security of transaction processing in\nthe blockchain. To construct a lightweight PQB transaction in a smart city, the work in [124] embeds a post-quantum\nidentity-based signature scheme and the InterPlanetary File System (IPFS). Some post-quantum solutions [125], such as\nlattice-based cryptography, quantum key distribution, and entanglement, are experimentally easy to counter quantum\nattacks. This PQB architecture makes smart cities safer and provides a better place to live.\n7.2.2\nSmart Healthcare. Smart healthcare aims to provide patient-centric healthcare services by secure data collection,\nefficient data processing, and systematic knowledge extraction [126]. However, maintaining the security and privacy of\nstakeholders is a challenge for traditional healthcare systems. It would be helpful to develop a quantum blockchain, and\nquantum electronic medical records (QEMRs) using the security of quantum cryptography itself [127]. To defend against\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n27\nUAV\nSmart Home\nDigital Transformation Applications\nSmart Healthcare\nSmart \nCity\nSleep Monitoring\nDaily Activity \nRecognition\nDoctor Visit\nHealth Detection\nMobile Crowd Sensing\nCellular Signals\nSensing Signals\nCommunication Signals\nHand-Free Access\nBlockchain\nQuantum Encryption \nE-voting\nLeader Election\nE-Voting\nFig. 10. Digital transformation applications of quantum blockchain in Web 3.0\nquantum attacks on traditional Healthcare systems, the quantum blind signature is leveraged for key distribution\nduring the block creation [128]. And various smart contracts help users to access the medical data of the blockchain\nwith their defined role. Replacing traditional encryption signature algorithms with quantum authentication systems,\na quantum electronic medical record protocol is designed [129]. This protocol tracks every medical record while\nguaranteeing the security and privacy of EMRs in medical systems. Additionally, quantum computing is able to support\nlarge operations and complex computation on uninstructed data, further improving the quality of service provided by\nintelligent healthcare systems [130, 131].\n7.2.3\nE-voting . Electronic voting, i.e., E-voting, is a voting process in which votes are cast and counted with computer\nassistance. Recently, the possible integration of blockchain and quantum technology could facilitate the implementation\nof E-voting with much greater transparency and security. Sun et. al propose a voting protocol based on the quantum\nblockchain [93]. This protocol not only simplifies the task of E-voting but also satisfies many significant properties,\nsuch as anonymity, verifiability, eligibility, fairness, etc. However, this protocol is limited in that it cannot be applied\nbeyond a certain number of users. In addition, denial-of-service attacks can easily be used by one voter against another.\nTo circumvent the possible attacks by upcoming noisy intermediate scale quantum (NISQ) computers. By enhancing\nthe advantages offered by blockchain with the quantum protocols [132], such as quantum random number generators,\nquantum key distribution, etc., an anonymous voting scheme is developed to circumvent the possible attacks from the\nupcoming Noise Intermediate Scale Quantum (NISQ) computers. The quantum protocols enable the E-voting systems\nManuscript submitted to ACM\n28\nRen and Xu et al.\nto secure against any adversary, whereas there exists the central authority in the elections, which may adversely affect\nthe voting outcome. Hence, it is necessary to consider the audit function in the E-voting protocol in order to ensure the\nefficiency and fairness of the voting process [133, 134].\n7.2.4\nSmart Home and UAV. As prominent representatives in the Internet of things (IoT), smart homes, and UAVs have\nsurged forward in the past decade, improving our daily lives.\nOn the one hand, smart homes aim to offer intelligent sensing and collaborative control in the home. It is noted\nthat security is an important problem before it can be widely adopted. One plausible solution to security breaches is to\nintroduce blockchain and quantum technology to increase safe communication among smart devices [135]. To this\nend, a consortium blockchain can be formed to provide smart home services through smart contracts. Meanwhile, the\npost-quantum signature schemes, such as pqNTRUsign, are designed to replace existing ECDSA signature schemes,\nhelping to protect the blockchain-based smart home services from a potential quantum computer attack.\nUnmanned aerial vehicles (UAVs), on the other hand, are seen as a potential asset due to their broader application\nin scope [136]. A number of communication protocols are needed to support the successful flight of UAVs. In UAV\ncommunications, blockchain-based quantum systems could be developed to solve security issues in the distribution\nof critical information. Thereinto, a quantum cryptography-based architecture leverages the properties of quantum\ncryptography and beyond 5G networks to enable drone communication more shielded from data transmission and to\nachieve high security and efficient data transmission.\n7.3\nImplementation Tutorials of Quantum Blockchain in Web 3.0\nIn this section, we provide a tutorial on the implementation of Quantum Blockchain in Web 3.0, which consists of the\nfollowing four phases.\n7.3.1\nGeneration of Quantum Entropy and Post-Quantum Certificates . In cryptographic processes in quantum blockchain,\nsufficient randomness prevents a large number of malicious attacks. The generation of quantum randomness takes\nadvantage of the non-deterministic property of quantum mechanics [137, 138]. Considering the distributed nature of\nthe blockchain, ideally, each blockchain node should have its own local source of quantum entropy. Then, quantum\ncommunication protocols need to be designed so that blockchain nodes create a quantum secure tunnel between\nthemselves and the entropy distribution point to ensure secure communication. In this respect, the entropy source\ncreates the first key, splits it into parts, and delivers it to the blockchain node through various TLS channels.\nOnce a blockchain node accesses quantum entropy on demand, the entropy is consumed by OpenSSL, the crypto-\ngraphic framework for applications that use TLS/SSL. After that, the blockchain nodes encapsulate the communication\nwith other nodes using the post-quantum key generated by the signature algorithm and sign the transactions broadcasted\nto the blockchain [65].\n7.3.2\nNodes Communication based on Quantum Cryptography. Communication between nodes is established through\nquantum protocols in blockchain, making nodes\u2019 communication quantum-resistant. It can be achieved by adding\npeer-to-peer TLS tunnels that have been modified to support post-quantum keys. Since this is built on a TLS connection\nthat is insensitive to key length, other post-quantum algorithms can be used, unlike blockchain transactions [139].\n7.3.3\nSignature of Transactions. The implementation of this phase requires us to pay attention to each specific\nblockchain network. Some blockchain protocols recognize different encryption algorithms or have the flexibility to\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n29\nincorporate new ones. In this case, we need to add quantum signatures to transactions broadcast to the network without\nmodifying the blockchain protocol by developing relay signers and meta-transaction signature models [140].\n7.3.4\nOn-chain Verification. When a blockchain writer node adds a post-quantum signature to a meta-transaction and\nbroadcasts it to the network, it needs to be verified on-chain. Once a relay hub smart contract is verified as a transaction\ntarget, each node extracts the original transaction information to verify the signature. The process involves three steps:\n\u2022 The blockchain node receiving the meta-transaction checks the sender. Next, they verify that the public key\nderived from the meta-transaction signature controls the decentralized identifier (DID) of the node that generated\nthe transactions [141].\n\u2022 If the previous step completes successfully, the node invokes the DID registry again, after which it resolves the\npost-quantum public key associated with the DID and the blockchain public key verified in the previous step.\n\u2022 After, the post-quantum public key, post-quantum signature, and original transaction are obtained from the DID\nregistry. Further, each node verifies the post-quantum algorithm on-chain.\nWith the above steps, blockchain nodes add meta-transactions to the transaction pool and copy them to other nodes\nso that the validator receives them and adds them to the next block.\nLessons learned: Quantum blockchain applications improve the security, reliability, and efficiency of blockchain-\nbased solutions in various areas such as chain-native services and digital transformation applications. However, the\nimplementation of quantum blockchain applications is still in its early stages and there are many open issues to be\nsolved before quantum blockchain applications can be widely deployed.\n8\nFUTURE RESEARCH DIRECTIONS AND OPEN ISSUES\nAlthough blockchain holds great promise in Web 3.0 with the help of quantum information technology, there are\nongoing challenges in future research. In this section, we discuss several open issues and explore future directions,\nincluding quantum crypto-economics, quantum intelligence, and transaction intelligence.\n8.1\nMigration to Quantum and Post-quantum Blockchain\nSince classical cryptography is expected to be broken by quantum computers in the near future, the migration to\nquantum and post-quantum cryptography-based cryptosystems needs to be efficient and smooth. In this process, the\nlegacy blockchains of Web 3.0 also need to be migrated to quantum and post-quantum blockchains. However, this\nmigration is not just about adding QKD and post-quantum cryptographic algorithms to existing blockchains. First, all\nexisting encrypted data based on traditional cryptographic algorithms, such as RSA, can be deciphered by quantum\ncomputing, which means that the data in traditional open systems might need to be re-encrypted. Since the existing\ndata can be intercepted in transit for future cracking. Finally, there is the issue of prioritizing network technology\nfacilities during the transition process. Due to limited migration resources, the most critical Web 3.0 services need\nto be migrated to quantum and post-quantum blockchains at the earliest. However, how to decide the priority in the\nmigration to quantum and post-quantum blockchains remains to be studied.\n8.2\nInternal Technologies and External Performance\n8.2.1\nStandardization for Quantum and Post-Quantum Blockchain. Standardization of quantum and post-quantum\nblockchains relies on the standardization of quantum networks and post-quantum cryptography. After the standard-\nization Web 3.0 can be put into industrial production on a large scale to rapidly increase the scalability and service\nManuscript submitted to ACM\n30\nRen and Xu et al.\ndiversity of digital ecosystems. First, the standardization of quantum networks can lead to efficient and absolutely secure\nquantum cryptography schemes for quantum blockchains. Then, the results of the standardization of post-quantum\nblockchains might be determined by a post-quantum cryptography competition conducted by NIST. In this standardiza-\ntion competition, NIST conducts extensive testing, evaluation, and comparison of the advantages and disadvantages of\ndifferent PQC schemes in terms of efficiency, security, compatibility, and scalability. As of now, the standardization of\npost-quantum cryptography can be completed within a few years, while the deployment of quantum networks might\ntake decades to develop.\n8.2.2\nQuantum Intelligent Blockchain. The quantum intelligence blockchain uses quantum machine learning to improve\nthe internal technology and external performance of the quantum blockchain. For example, quantum machine learning\ncan be used to design the incentive mechanism of the quantum blockchain, which can be trained to obtain the optimal\nincentive. In addition, quantum machine learning can also be used to design quantum circuit structures for running\nquantum consensus algorithms. Finally, quantum machine learning can be used to learn routing algorithms and block\npropagation algorithms in quantum networks to improve the throughput of quantum blockchains while maintaining a\ndecentralized state. Overall, quantum intelligent blockchain is promising in improving the efficiency and scalability of\nthe quantum and post-quantum blockchain in Web 3.0.\n8.2.3\nQuantum Decentralized Digital Identity. Decentralized digital identities allow users to manage their digital assets\nautonomously, securely, and transparently in Web 3.0. In quantum and post-quantum blockchains, users can obtain\nverifiable, privacy-protected, and revocable digital identities without relying on third-party identity providers. Providing\ndigital identities through QKD-based cryptography provides unconditionally secure data identity authentication and\ntransmission. However, users need access to the quantum network to use applications in Web 3.0 through quantum digital\nidentities. Therefore, the future research direction for quantum digital identity needs to be based on the improvement\nof quantum network throughput and coverage, so that users can protect their privacy and ownership through quantum\ncommunication in Web 3.0 according to different scenarios and needs.\n8.2.4\nQuantum Decentralized Finance. By building Web 3.0 decentralized exchanges on quantum and post-quantum\nblockchains, traders can complete the transmission of transaction information under an absolutely secure communication\nlink to prevent man-in-the-middle attacks. Quantum networks can be deployed between major exchanges to reduce the\nlatency of information exchange between exchanges. In this way, the information gap between exchanges is dramatically\nreduced, thus avoiding some arbitrage activities due to network dominance. In addition, Web 3.0 allows its participants\nto borrow and lend without collateral, secured by quantum cryptography and post-quantum cryptography. Therefore,\nfuture research directions could focus on how to design highly liquid lending protocols in Web 3.0 through quantum\nand post-quantum cryptography to enhance the sustainability of the decentralized ecosystem.\n8.3\nConvergence of Classic-Quantum Networking and Computing\nIn Web 3.0, blockchain-based computation-power networks connect heterogeneous computational resources in existing\nclassic and quantum networks to support decentralized applications and services. Based on quantum blockchain,\nquantum computing and quantum networks can be integrated into the core of Web 3.0. Therefore, Web 3.0 can allocate\nthese computing and networking resources to facilitate internal technologies and improve external performance. For\nexample, Web 3.0 with the convergence of classic-quantum networking and computing can leverage quantum computing\nto handle more complex and large-scale optimization, simulation, and machine learning problems. Furthermore, it can\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n31\nprovide faster, more stable, and more scalable network connectivity for decentralized applications through quantum\nnetworks. While combining quantum and classical computing-power networks can bring more potential to Web 3.0 in\ndriving digital transformation, further research is needed to design appropriate protocols and algorithms to divide,\nschedule, synchronize, and converge quantum-classical computing and networking.\nLessons learned: Quantum blockchain is still in the early stage of development, and it needs continuous exploration\nand innovation in terms of reliability, security, efficiency, and scalability. In this section, we give some future directions\nto help build the resilient Web 3.0 infrastructure.\n9\nCONCLUSION AND DISCUSSIONS\nGiven the complementary advantages between quantum information technologies and blockchain, it is clear that\nthe integrated quantum blockchain shows a way to implement distributed Web 3.0 infrastructures. In this article, we\nhave addressed the quantum blockchain and thoroughly examine most of the developments in Web 3.0. Specifically,\nwe have described the integration mainly in terms of two aspects, namely, optimizing internal technologies and\nimproving external performance. Then, we presented some potential quantum blockchain applications and tutorials for\nimplementation in Web 3.0. Finally, We have discussed some important challenges and research directions that open\nnew horizons for Web 3.0 development.\nSo far, quantum blockchain is still in its infancy and is expected to play a growing role in meeting the diverse needs\nof Web 3.0. This work provides a comprehensive, systematic, and in-depth introduction to the quantum blockchain for\nits further research and applications in Web 3.0.\nREFERENCES\n[1] C. Chen, L. Zhang, Y. Li, T. Liao, S. Zhao, Z. Zheng, H. Huang, and J. Wu, \u201cWhen digital economy meets web 3.0: Applications and challenges,\u201d IEEE\nOpen Journal of the Computer Society, 2022.\n[2] M. Xu, X. Ren, D. Niyato, J. Kang, C. Qiu, Z. Xiong, X. Wang, and V. C. M. Leung, \u201cWhen quantum information technologies meet blockchain in\nweb 3.0,\u201d arXiv preprint, p. arXiv:2211.15941, 2022.\n[3] E. Daniel and F. Tschorsch, \u201cIpfs and friends: A qualitative comparison of next generation peer-to-peer data networks,\u201d IEEE Communications\nSurveys & Tutorials, vol. 24, no. 1, pp. 31\u201352, 2022.\n[4] C. Gidney and M. Eker\u00e5, \u201cHow to factor 2048 bit rsa integers in 8 hours using 20 million noisy qubits,\u201d Quantum, vol. 5, p. 433, 2021.\n[5] A. K. Fedorov, E. O. Kiktenko, and A. I. Lvovsky, \u201cQuantum computers put blockchain security at risk,\u201d Nature, vol. 563, pp. 465\u2013467, 2022.\n[6] S. Pirandola, U. L. Andersen, L. Banchi, M. Berta, D. Bunandar, R. Colbeck, D. Englund, T. Gehring, C. Lupo, C. Ottaviani et al., \u201cAdvances in\nquantum cryptography,\u201d Advances in optics and photonics, vol. 12, no. 4, pp. 1012\u20131236, 2020.\n[7] W. Wang, Y. Yu, and L. Du, \u201cQuantum blockchain based on asymmetric quantum encryption and a stake vote consensus algorithm,\u201d Scientific\nReports, vol. 12, no. 1, pp. 1\u201312, 2022.\n[8] A. R. Faridi, F. Masood, A. H. T. Shamsan, M. Luqman, and M. Y. Salmony, \u201cBlockchain in the quantum world,\u201d International Journal of Advanced\nComputer Science and Applications, vol. 13, no. 1, 2022.\n[9] D. Krishnaswamy, \u201cQuantum blockchain networks,\u201d in Proceedings of the Twenty-First International Symposium on Theory, Algorithmic Foundations,\nand Protocol Design for Mobile Networks and Mobile Computing, 2020, pp. 327\u2013332.\n[10] C. Li, Y. Xu, J. Tang, and W. Liu, \u201cQuantum blockchain: A decentralized, encrypted and distributed database based on quantum mechanics,\u201d Journal\nof Quantum Computing, vol. 1, no. 2, pp. 49\u201363, 2019.\n[11] E. O. Kiktenko, N. O. Pozhar, M. N. Anufriev, A. S. Trushechkin, R. R. Yunusov, Y. V. Kurochkin, A. I. Lvovsky, and A. K. Fedorov, \u201cQuantum-secured\nblockchain,\u201d Quantum Science and Technology, vol. 3, no. 3, p. 035004, 2018.\n[12] D. Rajan and M. Visser, \u201cQuantum blockchain using entanglement in time,\u201d Quantum Reports, vol. 1, no. 1, pp. 3\u201311, 2019.\n[13] N. Dey, M. Ghosh, and A. Chakrabarti, \u201cQuantum solutions to possible challenges of blockchain technology,\u201d arXiv preprint, p. arXiv: 2110.05321,\n2021.\n[14] M. Allende, D. L. Le\u00f3n, S. Cer\u00f3n, A. Leal, A. Pareja, M. Da Silva, A. Pardo, D. Jones, D. Worrall, B. Merriman, J. Gilmore, N. Kitchener, and S. E.\nVenegas-Andraca, \u201cQuantum-resistance in blockchain networks,\u201d arXiv preprint, p. arXiv:2106.06640, 2021.\n[15] J. Liu, Q. Li, J. Quan, C. Wang, J. Shi, and H. Situ, \u201cEfficient quantum homomorphic encryption scheme with flexible evaluators and its simulation,\u201d\nDesigns, Codes and Cryptography, vol. 90, no. 3, pp. 577\u2013591, 2022.\nManuscript submitted to ACM\n32\nRen and Xu et al.\n[16] Y. Ouyang, S.-H. Tan, and J. F. Fitzsimons, \u201cQuantum homomorphic encryption from quantum codes,\u201d Physical Review A, vol. 98, no. 4, p. 042334,\n2018.\n[17] Y. Li, R.-G. Zhou, R. Xu, J. Luo, and S.-X. Jiang, \u201cA quantum mechanics-based framework for eeg signal feature extraction and classification,\u201d IEEE\ntransactions on emerging topics in computing, vol. 10, no. 1, pp. 211\u2013222, 2020.\n[18] C. Li, Y. Zhang, and E. Y. Xie, \u201cWhen an attacker meets a cipher-image in 2018: A year in review,\u201d Journal of Information Security and Applications,\nvol. 48, p. 102361, 2019.\n[19] H.-L. Yin, Y. Fu, and Z.-B. Chen, \u201cPractical quantum digital signature,\u201d Physical Review A, vol. 93, no. 3, p. 032316, 2016.\n[20] G. Zeng and C. H. Keitel, \u201cArbitrated quantum-signature scheme,\u201d Physical review A, vol. 65, no. 4, p. 042312, 2002.\n[21] O. Grote, A. Ahrens, and C. Benavente-Peces, \u201cA review of post-quantum cryptography and crypto-agility strategies,\u201d in 2019 International\nInterdisciplinary PhD Workshop (IIPhDW).\nIEEE, 2019, pp. 115\u2013120.\n[22] T. M. Fernandez-Carames and P. Fraga-Lamas, \u201cTowards post-quantum blockchain: A review on blockchain cryptography resistant to quantum\ncomputing attacks,\u201d IEEE access, vol. 8, pp. 21 091\u201321 116, 2020.\n[23] F. A. Alabdulwahhab, \u201cWeb 3.0: the decentralized web blockchain networks and protocol innovation,\u201d in 2018 1st International Conference on\nComputer Applications & Information Security (ICCAIS).\nIEEE, 2018, pp. 1\u20134.\n[24] Z. Zheng, S. Xie, H.-N. Dai, X. Chen, and H. Wang, \u201cBlockchain challenges and opportunities: A survey,\u201d International journal of web and grid\nservices, vol. 14, no. 4, pp. 352\u2013375, 2018.\n[25] A. Gervais, G. O. Karame, K. W\u00fcst, V. Glykantzis, H. Ritzdorf, and S. Capkun, \u201cOn the security and performance of proof of work blockchains,\u201d in\nProceedings of the 2016 ACM SIGSAC conference on computer and communications security, 2016, pp. 3\u201316.\n[26] S. King and S. Nadal, \u201cPpcoin: Peer-to-peer crypto-currency with proof-of-stake,\u201d self-published paper, vol. 19, no. 1, 2012.\n[27] S. De Angelis, L. Aniello, R. Baldoni, F. Lombardi, A. Margheri, and V. Sassone, \u201cPbft vs proof-of-authority: Applying the cap theorem to permissioned\nblockchain,\u201d Italian Conference on Cybersecurity, 2018.\n[28] S. Voshmgir, Token economy: How the Web3 reinvents the internet.\nToken Kitchen, 2020, vol. 2.\n[29] A. Murray, D. Kim, and J. Combs, \u201cThe promise of a decentralized internet: What is web3 and how can firms prepare?\u201d Business Horizons, vol. 66,\nno. 2, pp. 191\u2013202, 2023.\n[30] L. Cao, \u201cDecentralized ai: Edge intelligence and smart blockchain, metaverse, web3, and desci,\u201d IEEE Intelligent Systems, vol. 37, no. 3, pp. 6\u201319, 2022.\n[31] Q. Wang, R. Li, Q. Wang, S. Chen, M. Ryan, and T. Hardjono, \u201cExploring web3 from the view of blockchain,\u201d arXiv preprint arXiv:2206.08821, 2022.\n[32] N. Gisin and R. Thew, \u201cQuantum communication,\u201d Nature Photon, vol. 1, p. 165\u2013171, 2007.\n[33] S. Pirandola, J. Eisert, C. Weedbrook, A. Furusawa, and S. L. Braunstein, \u201cAdvances in quantum teleportation,\u201d Nature photonics, vol. 9, no. 10, pp.\n641\u2013652, 2015.\n[34] A. Zeilinger, \u201cQuantum teleportation,\u201d Scientific American, vol. 282, no. 4, pp. 50\u201359, 2000.\n[35] A. Furusawa, J. L. S\u00f8rensen, S. L. Braunstein, C. A. Fuchs, H. J. Kimble, and E. S. Polzik, \u201cUnconditional quantum teleportation,\u201d science, vol. 282, no.\n5389, pp. 706\u2013709, 1998.\n[36] V. Scarani, H. Bechmann-Pasquinucci, N. J. Cerf, M. Du\u0161ek, N. L\u00fctkenhaus, and M. Peev, \u201cThe security of practical quantum key distribution,\u201d Rev.\nMod. Phys., vol. 81, pp. 1301\u20131350, Sep 2009.\n[37] E. Diamanti, H. Lo, and B. Qi, \u201cPractical challenges in quantum key distribution,\u201d npj Quantum Inf, vol. 2, p. 16025, 2016.\n[38] A. Steane, \u201cQuantum computing,\u201d Reports on Progress in Physics, vol. 61, no. 2, p. 117, 1998.\n[39] D. Micciancio and O. Regev, \u201cLattice-based cryptography,\u201d in Post-quantum cryptography.\nSpringer, 2009, pp. 147\u2013191.\n[40] J. Ding and B.-Y. Yang, \u201cMultivariate public key cryptography,\u201d in Post-quantum cryptography.\nSpringer, 2009, pp. 193\u2013241.\n[41] M. Mozaffari-Kermani and R. Azarderakhsh, \u201cReliable hash trees for post-quantum stateless cryptographic hash-based signatures,\u201d in 2015 IEEE\nInternational Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFTS).\nIEEE, 2015, pp. 103\u2013108.\n[42] R. Overbeck and N. Sendrier, \u201cCode-based cryptography,\u201d in Post-quantum cryptography.\nSpringer, 2009, pp. 95\u2013145.\n[43] M. Shrivas, K. Hiran, R. Doshi, and A. Bhansali, Advancements in Quantum Blockchain With Real-Time Applications, 06 2022.\n[44] K. Nilesh and P. K. Panigrahi, \u201cQuantum blockchain based on dimensional lifting generalized gram-schmidt procedure,\u201d IEEE Access, vol. 10, pp.\n103 212\u2013103 222, 2022. [Online]. Available: https://doi.org/10.1109%2Faccess.2022.3208123\n[45] X. Sun, Q. Wang, P. Kulicki, and X. Zhao, \u201cQuantum-enhanced logic-based blockchain i: Quantum honest-success byzantine agreement and\nqulogicoin,\u201d arXiv preprint arXiv:1805.06768, 2018.\n[46] X.-J. Wen, Y.-Z. Chen, X.-C. Fan, W. Zhang, Z.-Z. Yi, and J.-B. Fang, \u201cBlockchain consensus mechanism based on quantum zero-knowledge proof,\u201d\nOptics & Laser Technology, vol. 147, p. 107693, 2022.\n[47] X. Sun, M. Sopek, Q. Wang, and P. Kulicki, \u201cTowards quantum-secured permissioned blockchain: Signature, consensus, and logic,\u201d Entropy, vol. 21,\nno. 9, 2019.\n[48] T. Nguyen and K. Kim, \u201cA survey about consensus algorithms used in blockchain,\u201d Journal of Information Processing Systems, vol. 14, pp. 101\u2013128,\n01 2018.\n[49] \u201cAn efficient blockchain consensus algorithm based on post-quantum threshold signature,\u201d Big Data Research, vol. 26, p. 100268, 2021.\n[50] Q. Li, J. Wu, J. Quan, J. Shi, and S. Zhang, \u201cEfficient quantum blockchain with a consensus mechanism qdpos,\u201d IEEE Transactions on Information\nForensics and Security, vol. 17, pp. 3264\u20133276, 2022.\n[51] X. Sun, P. Kulicki, and M. Sopek, \u201cMulti-party quantum byzantine agreement without entanglement,\u201d Entropy, vol. 22, no. 10, p. 1152, 2020.\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n33\n[52] X. Sun, Q. Wang, P. Kulicki, and X. Zhao, \u201cQuantum-enhanced logic-based blockchain i: Quantum honest-success byzantine agreement and\nqulogicoin,\u201d 2018.\n[53] R. Han, Z. Yan, X. Liang, and L. T. Yang, \u201cHow can incentive mechanisms and blockchain benefit with each other? a survey,\u201d ACM Computing\nSurveys, vol. 55, no. 7, pp. 1\u201338, 2022.\n[54] M. T. Azhar, M. B. Khan, and A. U. R. Khan, \u201cBlockchain based secure crypto-currency system with quantum key distribution protocol,\u201d in 2019 8th\nInternational Conference on Information and Communication Technologies (ICICT).\nIEEE, 2019, pp. 31\u201335.\n[55] P. J. Coles, E. M. Metodiev, and N. L\u00fctkenhaus, \u201cNumerical approach for unstructured quantum key distribution,\u201d Nature communications, vol. 7,\nno. 1, p. 11712, 2016.\n[56] A. J. Bennet and S. Daryanoosh, \u201cEnergy efficient mining on a quantum-enabled blockchain using light,\u201d arXiv preprint arXiv:1902.09520, 2019.\n[57] S. S. Pandey, T. Dash, P. K. Panigrahi, and A. Farouk, \u201cEfficient quantum non-fungible tokens for blockchain,\u201d arXiv preprint arXiv:2209.02449, 2022.\n[58] K. Kaushik and A. Kumar, \u201cDemystifying quantum blockchain for healthcare,\u201d Security and Privacy, p. 284, 2022.\n[59] Z. Cai, J. Qu, P. Liu, and J. Yu, \u201cA blockchain smart contract based on light-weighted quantum blind signature,\u201d IEEE Access, vol. 7, pp. 138 657\u2013138 668,\n2019.\n[60] Z. Cai, S. Liu, Z. Han, R. Wang, and Y. Huang, \u201cA quantum blind multi-signature method for the industrial blockchain,\u201d Entropy, vol. 23, no. 11, p.\n1520, 2021.\n[61] A. H. Karbasi and S. Shahpasand, \u201cA post-quantum end-to-end encryption over smart contract-based blockchain for defeating man-in-the-middle\nand interception attacks,\u201d Peer-to-peer networking and applications, vol. 13, pp. 1423\u20131441, 2020.\n[62] X. Sun, P. Kulicki, and M. Sopek, \u201cLogic programming with post-quantum cryptographic primitives for smart contract on quantum-secured\nblockchain,\u201d Entropy, vol. 23, no. 9, p. 1120, 2021.\n[63] Z. Li, T. Zhang, D. Zhao, Y. Zha, J. Sun et al., \u201cPost-quantum privacy-preserving provable data possession scheme based on smart contracts,\u201d Wireless\nCommunications and Mobile Computing, vol. 2023, 2023.\n[64] G. Alagic, G. Alagic, J. Alperin-Sheriff, D. Apon, D. Cooper, Q. Dang, Y.-K. Liu, C. Miller, D. Moody, R. Peralta et al., \u201cStatus report on the first round\nof the nist post-quantum cryptography standardization process,\u201d 2019.\n[65] G. Alagic, J. Alperin-Sheriff, D. Apon, D. Cooper, Q. Dang, J. Kelsey, Y.-K. Liu, C. Miller, D. Moody, R. Peralta et al., \u201cStatus report on the second\nround of the nist post-quantum cryptography standardization process,\u201d US Department of Commerce, NIST, vol. 2, 2020.\n[66] J. Ding, \u201cA new variant of the matsumoto-imai cryptosystem through perturbation,\u201d in Public Key Cryptography\u2013PKC 2004: 7th International\nWorkshop on Theory and Practice in Public Key Cryptography, Singapore, March 1-4, 2004. Proceedings 7.\nSpringer, 2004, pp. 305\u2013318.\n[67] J. Ding and D. Schmidt, \u201cCryptanalysis of hfev and internal perturbation of hfe.\u201d in Public Key Cryptography, vol. 3386.\nSpringer, 2005, pp. 288\u2013301.\n[68] J. Hoffstein, J. Pipher, and J. H. Silverman, \u201cNtru: A ring-based public key cryptosystem,\u201d in Algorithmic Number Theory: Third International\nSymposiun, ANTS-III Portland, Oregon, USA, June 21\u201325, 1998 Proceedings.\nSpringer, 2006, pp. 267\u2013288.\n[69] E. Alkim, L. Ducas, T. P\u00f6ppelmann, and P. Schwabe, \u201cPost-quantum key exchange-a new hope.\u201d in USENIX security symposium, vol. 2016, 2016.\n[70] \u201cGoogle blog google\u2019s experiments with a hybrid cryptosystem.\u201d [Online]. Available: https://security.googleblog.com/2016/07/experimenting-with-\npost-quantum.html\n[71] S. Singh, N. K. Rajput, V. K. Rathi, H. M. Pandey, A. K. Jaiswal, and P. Tiwari, \u201cSecuring blockchain transactions using quantum teleportation and\nquantum digital signature,\u201d Neural Processing Letters, pp. 1\u201316, 2020.\n[72] D. Gottesman and I. Chuang, \u201cQuantum digital signatures,\u201d arXiv preprint quant-ph/0105032, 2001.\n[73] Y.-L. Gao, X.-B. Chen, Y.-L. Chen, Y. Sun, X.-X. Niu, and Y.-X. Yang, \u201cA secure cryptocurrency scheme based on post-quantum blockchain,\u201d Ieee\nAccess, vol. 6, pp. 27 205\u201327 213, 2018.\n[74] W. Yin, Q. Wen, W. Li, H. Zhang, and Z. Jin, \u201cAn anti-quantum transaction authentication approach in blockchain,\u201d IEEE Access, vol. 6, pp. 5393\u20135401,\n2018.\n[75] C.-Y. Li, X.-B. Chen, Y.-L. Chen, Y.-Y. Hou, and J. Li, \u201cA new lattice-based signature scheme in post-quantum blockchain network,\u201d IEEE Access,\nvol. 7, pp. 2026\u20132033, 2018.\n[76] T. G\u00fcneysu, V. Lyubashevsky, and T. P\u00f6ppelmann, \u201cPractical lattice-based cryptography: A signature scheme for embedded systems,\u201d in Cryptographic\nHardware and Embedded Systems\u2013CHES 2012: 14th International Workshop, Leuven, Belgium, September 9-12, 2012. Proceedings 14.\nSpringer, 2012,\npp. 530\u2013547.\n[77] H. An and K. Kim, \u201cQchain: Quantum-resistant and decentralized pki using blockchain,\u201d in 2018 Symposium on Cryptography and Information\nSecurity (SCIS 2018).\nIEICE Technical Committee on Information Security, 2018.\n[78] E. Megidish, T. Shacham, A. Halevy, L. Dovrat, and H. Eisenberg, \u201cResource efficient source of multiphoton polarization entanglement,\u201d Physical\nReview Letters, vol. 109, no. 8, p. 080504, 2012.\n[79] M. Jin and C. D. Yoo, \u201cQuantum hashing for multimedia,\u201d IEEE transactions on information forensics and security, vol. 4, no. 4, pp. 982\u2013994, 2009.\n[80] A. Swaminathan, Y. Mao, and M. Wu, \u201cRobust and secure image hashing,\u201d IEEE Transactions on Information Forensics and security, vol. 1, no. 2, pp.\n215\u2013230, 2006.\n[81] R. J. McEliece, \u201cA public-key cryptosystem based on algebraic,\u201d Coding Thv, vol. 4244, pp. 114\u2013116, 1978.\n[82] N. Koblitz, \u201cElliptic curve cryptosystems,\u201d Mathematics of computation, vol. 48, no. 177, pp. 203\u2013209, 1987.\n[83] R. L. Rivest, A. Shamir, and L. Adleman, \u201cA method for obtaining digital signatures and public-key cryptosystems,\u201d Communications of the ACM,\nvol. 21, no. 2, pp. 120\u2013126, 1978.\nManuscript submitted to ACM\n34\nRen and Xu et al.\n[84] A. Petzoldt, S. Bulygin, and J. Buchmann, \u201cSelecting parameters for the rainbow signature scheme,\u201d in Post-Quantum Cryptography: Third\nInternational Workshop, PQCrypto 2010, Darmstadt, Germany, May 25-28, 2010. Proceedings 3.\nSpringer, 2010, pp. 218\u2013240.\n[85] J. Bl\u00f6mer and S. Naewe, \u201cSampling methods for shortest vectors, closest vectors and successive minima,\u201d Theoretical Computer Science, vol. 410,\nno. 18, pp. 1648\u20131665, 2009.\n[86] L. K. Grover, \u201cA fast quantum mechanical algorithm for database search,\u201d in Proceedings of the twenty-eighth annual ACM symposium on Theory of\ncomputing, 1996, pp. 212\u2013219.\n[87] W. Xiaojun and N. Zhe, \u201cAn e-payment system based on quantum blind and group signature,\u201d in 2010 Second International Symposium on Data,\nPrivacy, and E-Commerce.\nIEEE, 2010, pp. 50\u201355.\n[88] X. Wen, Y. Chen, and J. Fang, \u201cAn inter-bank e-payment protocol based on quantum proxy blind signature,\u201d Quantum information processing,\nvol. 12, pp. 549\u2013558, 2013.\n[89] A.-X. Shao, J.-Z. Zhang, and S.-C. Xie, \u201cAn e-payment protocol based on quantum multi-proxy blind signature,\u201d International Journal of Theoretical\nPhysics, vol. 56, pp. 1241\u20131248, 2017.\n[90] J.-Z. Zhang, Y.-Y. Yang, and S.-C. Xie, \u201cA third-party e-payment protocol based on quantum group blind signature,\u201d International Journal of\nTheoretical Physics, vol. 56, pp. 2981\u20132989, 2017.\n[91] X.-l. Gou, R.-h. Shi, W. Gao, and M. Wu, \u201cA novel quantum e-payment protocol based on blockchain,\u201d Quantum Information Processing, vol. 20,\nno. 5, p. 192, 2021.\n[92] J.-L. Zhang, M.-S. Hu, Z.-J. Jia, and L.-P. Wang, \u201cA novel e-payment protocol implented by blockchain and quantum signature,\u201d International Journal\nof Theoretical Physics, vol. 58, pp. 1315\u20131325, 2019.\n[93] X. Sun, Q. Wang, P. Kulicki, and M. Sopek, \u201cA simple voting protocol on quantum blockchain,\u201d International Journal of Theoretical Physics, vol. 58,\npp. 275\u2013281, 2019.\n[94] E.-O. Blass and F. Kerschbaum, \u201cStrain: A secure auction for blockchains,\u201d in Computer Security: 23rd European Symposium on Research in Computer\nSecurity, ESORICS 2018, Barcelona, Spain, September 3-7, 2018, Proceedings, Part I 23.\nSpringer, 2018, pp. 87\u2013110.\n[95] R. Zhang, R.-h. Shi, J.-q. Qin, and Z.-w. Peng, \u201cAn economic and feasible quantum sealed-bid auction protocol,\u201d Quantum Information Processing,\nvol. 17, pp. 1\u201314, 2018.\n[96] W.-J. Liu, H.-B. Wang, G.-L. Yuan, Y. Xu, Z.-Y. Chen, X.-X. An, F.-G. Ji, and G. T. Gnitou, \u201cMultiparty quantum sealed-bid auction using single\nphotons as message carrier,\u201d Quantum Information Processing, vol. 15, pp. 869\u2013879, 2016.\n[97] X. Sun, P. Kulicki, and M. Sopek, \u201cLottery and auction on quantum blockchain,\u201d Entropy, vol. 22, no. 12, p. 1377, 2020.\n[98] H. Abulkasim, A. Mashatan, and S. Ghose, \u201cQuantum-based privacy-preserving sealed-bid auction on the blockchain,\u201d Optik, vol. 242, p. 167039,\n2021.\n[99] Z. Yang, T. Salman, R. Jain, and R. Di Pietro, \u201cDecentralization using quantum blockchain: A theoretical analysis,\u201d IEEE Transactions on Quantum\nEngineering, vol. 3, pp. 1\u201316, 2022.\n[100] Y.-W. Wang and Y.-B. Zhan, \u201cA theoretical scheme for zero-knowledge proof quantum identity authentication,\u201d Acta Physica Sinica, vol. 58, pp.\n7668\u20137671, 2009.\n[101] A. Coladangelo and O. Sattath, \u201cA quantum money solution to the blockchain scalability problem,\u201d Quantum, vol. 4, p. 297, 2020.\n[102] M. Bhavin, S. Tanwar, N. Sharma, S. Tyagi, and N. Kumar, \u201cBlockchain and quantum blind signature-based hybrid scheme for healthcare 5.0\napplications,\u201d Journal of Information Security and Applications, vol. 56, p. 102673, 2021.\n[103] S. Mesnager, A. S\u0131nak, and O. Yayla, \u201cThreshold-based post-quantum secure verifiable multi-secret sharing for distributed storage blockchain,\u201d\nMathematics, vol. 8, no. 12, p. 2218, 2020.\n[104] R. K. Raman and L. R. Varshney, \u201cDistributed storage meets secret sharing on the blockchain,\u201d in 2018 information theory and applications workshop\n(ITA).\nIEEE, 2018, pp. 1\u20136.\n[105] Y. Kim, R. K. Raman, Y.-S. Kim, L. R. Varshney, and N. R. Shanbhag, \u201cEfficient local secret sharing for distributed blockchain systems,\u201d IEEE\nCommunications Letters, vol. 23, no. 2, pp. 282\u2013285, 2018.\n[106] X. Chen, S. Xu, T. Qin, Y. Cui, S. Gao, and W. Kong, \u201cAq\u2013abs: Anti-quantum attribute-based signature for emrs sharing with blockchain,\u201d in 2022\nIEEE Wireless Communications and Networking Conference (WCNC).\nIEEE, 2022, pp. 1176\u20131181.\n[107] M. Al-Bassam, \u201cScpki: A smart contract-based pki and identity system,\u201d in Proceedings of the ACM Workshop on Blockchain, Cryptocurrencies and\nContracts, 2017, pp. 35\u201340.\n[108] K. Pinter, D. Schmelz, R. Lamber, S. Strobl, and T. Grechenig, \u201cTowards a multi-party, blockchain-based identity verification solution to implement\nclear name laws for online media platforms,\u201d in Business Process Management: Blockchain and Central and Eastern Europe Forum: BPM 2019 Blockchain\nand CEE Forum, Vienna, Austria, September 1\u20136, 2019, Proceedings 17.\nSpringer, 2019, pp. 151\u2013165.\n[109] J. A. Cortese and T. M. Braje, \u201cLoading classical data into a quantum computer,\u201d arXiv preprint arXiv:1803.01958, 2018.\n[110] M. Zhandry, \u201cQuantum lightning never strikes the same state twice. or: quantum money from cryptographic assumptions,\u201d Journal of Cryptology,\nvol. 34, pp. 1\u201356, 2021.\n[111] A. Lutomirski, \u201cComponent mixers and a hardness result for counterfeiting quantum money,\u201d arXiv preprint arXiv:1107.0321, 2011.\n[112] G. R. Blakley, \u201cSafeguarding cryptographic keys,\u201d in Managing Requirements Knowledge, International Workshop on.\nIEEE Computer Society, 1979,\npp. 313\u2013313.\n[113] A. Shamir, \u201cHow to share a secret,\u201d Communications of the ACM, vol. 22, no. 11, pp. 612\u2013613, 1979.\nManuscript submitted to ACM\nBuilding Resilient Web 3.0 with Quantum Information Technologies and Blockchain: An Ambilateral View\n35\n[114] A. N. Amroudi, A. Zaghain, and M. Sajadieh, \u201cA verifiable (k, n, m)-threshold multi-secret sharing scheme based on ntru cryptosystem,\u201d Wireless\nPersonal Communications, vol. 96, pp. 1393\u20131405, 2017.\n[115] H. Pilaram and T. Eghlidos, \u201cAn efficient lattice based multi-stage secret sharing scheme,\u201d IEEE Transactions on Dependable and Secure Computing,\nvol. 14, no. 1, pp. 2\u20138, 2015.\n[116] P. Zeng, Z. Zhang, R. Lu, and K.-K. R. Choo, \u201cEfficient policy-hiding and large universe attribute-based encryption with public traceability for\ninternet of medical things,\u201d IEEE Internet of Things Journal, vol. 8, no. 13, pp. 10 963\u201310 972, 2021.\n[117] C. He, X. Fan, and Y. Li, \u201cToward ubiquitous healthcare services with a novel efficient cloud platform,\u201d IEEE Transactions on Biomedical Engineering,\nvol. 60, no. 1, pp. 230\u2013234, 2012.\n[118] J. Brost, C. Egger, R. W. Lai, F. Schmid, D. Schr\u00f6der, and M. Zoppelt, \u201cThreshold password-hardened encryption services,\u201d in Proceedings of the 2020\nACM SIGSAC Conference on Computer and Communications Security, 2020, pp. 409\u2013424.\n[119] Q. Wang, R. Li, Q. Wang, and S. Chen, \u201cNon-fungible token (nft): Overview, evaluation, opportunities and challenges,\u201d arXiv preprint arXiv:2105.07447,\n2021.\n[120] \u201cQuantum technology\u2019s impact on the metaverse.\u201d [Online]. Available: https://quantumxc.com/blog/quantum-technologys-impact-on-the-\nmetaverse/\n[121] \u201cDoes quantum computing have a role to play in the metaverse?\u201d [Online]. Available: https://quantumzeitgeist.com/does-quantum-computing-\nhave-a-role-to-play-in-the-metaverse/\n[122] \u201cBritish security company quantum dice.\u201d [Online]. Available: https://quantumzeitgeist.com/british-security-company-quantum-dice-raises-2m-\nin-pre-seed-round/\n[123] A. A. Abd El-Latif, B. Abd-El-Atty, I. Mehmood, K. Muhammad, S. E. Venegas-Andraca, and J. Peng, \u201cQuantum-inspired blockchain-based\ncybersecurity: Securing smart edge utilities in iot-based smart cities,\u201d Information Processing & Management, vol. 58, no. 4, p. 102549, 2021.\n[124] J. Chen, W. Gan, M. Hu, and C.-M. Chen, \u201cOn the construction of a post-quantum blockchain for smart city,\u201d Journal of Information Security and\nApplications, vol. 58, p. 102780, 2021.\n[125] A. el Azzaoui and J. Park, \u201cPost-quantum blockchain for a scalable smart city,\u201d Journal of Internet Technology, vol. 21, pp. 1171\u20131178, 08 2020.\n[126] S. B. Baker, W. Xiang, and I. Atkinson, \u201cInternet of things for smart healthcare: Technologies, challenges, and opportunities,\u201d IEEE Access, vol. 5, pp.\n26 521\u201326 544, 2017.\n[127] X. Chen, S. Xu, T. Qin, Y. Cui, S. Gao, and W. Kong, \u201cAq\u2013abs: Anti-quantum attribute-based signature for emrs sharing with blockchain,\u201d in 2022\nIEEE Wireless Communications and Networking Conference (WCNC), 2022, pp. 1176\u20131181.\n[128] M. Bhavin, S. Tanwar, N. Sharma, S. Tyagi, and N. Kumar, \u201cBlockchain and quantum blind signature-based hybrid scheme for healthcare 5.0\napplications,\u201d Journal of Information Security and Applications, vol. 56, p. 102673, 2021.\n[129] \u201cA quantum blockchain-enabled framework for secure private electronic medical records in internet of medical things,\u201d Information Sciences, vol.\n612, pp. 942\u2013958, 2022.\n[130] \u201cBlockchain-based delegated quantum cloud architecture for medical big data security,\u201d Journal of Network and Computer Applications, vol. 198, p.\n103304, 2022.\n[131] J. Amin, M. Anjum, N. Gul, and M. Sharif, \u201cA secure two-qubit quantum model for segmentation and classification of brain tumor using mri images\nbased on blockchain,\u201d Neural Computing and Applications, vol. 34, pp. 1\u201314, 05 2022.\n[132] S. Mishra, K. Thapliyal, S. K. Rewanth, A. Parakh, and A. Pathak, \u201cAnonymous voting scheme using quantum assisted blockchain,\u201d 2022.\n[133] S. Gao, D. Zheng, R. Guo, C. Jing, and C. Hu, \u201cAn anti-quantum e-voting protocol in blockchain with audit function,\u201d IEEE Access, vol. 7, pp.\n115 304\u2013115 316, 2019.\n[134] S. Chow and W.-S. Yap, \u201cCertificateless ring signatures.\u201d IACR Cryptology ePrint Archive, vol. 2007, p. 236, 01 2007.\n[135] C.-C. C. Wai-Kong Lee, Lanxiang Chen and Z. Yao, \u201cPost-quantum blockchain for secure communication in iot-based smart home services,\u201d\nInternational Journal of Embedded Systems, vol. 14, no. 5, pp. 509 \u2013 524, 2021.\n[136] V. K. Ralegankar, J. Bagul, B. Thakkar, R. Gupta, S. Tanwar, G. Sharma, and I. E. Davidson, \u201cQuantum cryptography-as-a-service for secure uav\ncommunication: Applications, challenges, and case study,\u201d IEEE Access, vol. 10, pp. 1475\u20131492, 2022.\n[137] Z. Zheng, Y. Zhang, M. Huang, Z. Chen, S. Yu, and H. Guo, \u201cBias-free source-independent quantum random number generator,\u201d Optics Express,\nvol. 28, no. 15, pp. 22 388\u201322 398, 2020.\n[138] M. Herrero-Collantes and J. C. Garcia-Escartin, \u201cQuantum random number generators,\u201d Reviews of Modern Physics, vol. 89, no. 1, p. 015004, 2017.\n[139] \u201cFalcon github.\u201d [Online]. Available: https://github.com/bhess/openssl/blob/OQS-OpenSSL_1_1_1-stable/crypto/objects/objects.txt\n[140] \u201cEip-155.\u201d [Online]. Available: Simplereplayattackprotection.https://eips.ethereum.org/EIPS/eip-155\n[141] \u201cW3c did standard.\u201d [Online]. Available: https://www.w3.org/TR/did-core/\nManuscript submitted to ACM\n",
    "2305.00427": "Noname manuscript No.\n(will be inserted by the editor)\nAn overview of Web3.0 Technology: Infrastructure,\nApplications, and Popularity\nRenke Huang \u00b7 Jiachi Chen\n\u00b7 Yanlin\nWang \u00b7 Tingting Bi \u00b7 Zibin Zheng\nReceived: date / Accepted: date\nAbstract Web3,\nthe\nnext\ngeneration\nof\nthe\nInternet,\nrepresents\na\ndecentralized and democratized web. Although it has garnered signi\ufb01cant\npublic interest and found numerous real-world applications, there is a limited\nunderstanding of people\u2019s perceptions and experiences with Web3. In this\nstudy, we conducted an empirical study to investigate the categories of Web3\napplication and their popularity, as well as the potential challenges and\nopportunities within this emerging landscape. Our research was carried out\nin two phases. In the \ufb01rst phase, we analyzed 200 popular Web3 projects\nassociated with 10 leading Web3 venture capital \ufb01rms. In the second phase,\nwe collected and examined code-related data from GitHub and market-related\ndata from blockchain browsers (e.g., Etherscan) for these projects. Our analysis\nrevealed that the Web3 ecosystem can be categorized into two groups, i.e.,\nWeb3 infrastructure and Web3 applications, with each consisting of several\nsubcategories or subdomains. We also gained insights into the popularity of\nJiachi Chen is the corresponding author.\nRenke Huang\nSchool of Software Engineering, Sun Yat-Sen University, China\nE-mail: huangrk9@mail2.sysu.edu.cn\nJiachi Chen\nSchool of Software Engineering, Sun Yat-Sen University, China\nE-mail: chenjch86@mail.sysu.edu.cn\nYanlin Wang\nSchool of Software Engineering, Sun Yat-Sen University, China\nE-mail: wangylin36@mail.sysu.edu.cn\nTingting Bi\nData61, Australia\nE-mail: tingting.bi@data61.csiro.au\nZibin Zheng\nSchool of Software Engineering, Sun Yat-Sen University, China\nE-mail: zhzibin@mail.sysu.edu.cn\n1\narXiv:2305.00427v1  [cs.SE]  30 Apr 2023\nthese Web3 projects at both the code and market levels and pointed out\nthe challenges in the Web3 ecosystem at the system, developer, and user\nlevels, as well as the opportunities it presents. Our \ufb01ndings contribute to\na better understanding of Web3 for researchers and developers, promoting\nfurther exploration and advancement in this innovative \ufb01eld.\nKeywords Web3.0 \u00b7 Blockchain \u00b7 Empirical Study \u00b7 Survey\n1 Introduction\nWeb3, also known as Web 3.0, represents the third generation of the\nWorld Wide Web, which is usually built upon a decentralized blockchain\nnetwork (Sheridan et al., 2022). Within this network, third parties cannot\nmodify user data, and users maintain control over their data through\npublic and private keys. Data changes adhere to predetermined agreements\nbetween users and the blockchain, establishing blockchain technology as the\nfundamental basis for Web3. Thus, Web3 is also known as the \u201dread-write-\nown\u201d web, as it empowers users to retain ownership of their data.\nWeb3\ntechnology\no\ufb00ers\nseveral\nkey\nadvantages.\nFor\nexample,\nthe\nImmutability feature ensures the data integrity of the Web3 project, and the\nTrustless allows the Web3 projects do not rely on a trusted third party. Web3\nalso provides the feature to preserve user privacy and (Anonymity) empowers\nusers can control their data (Ownability). In general, Web3 technology fosters\na readable, writable, and ownable ecosystem, enabling users to manage and\nmaintain control over their data through private and public keys. Due to\nthe substantial potential of Web3 technology, Web3 applications have become\nincreasingly prevalent in recent times. As of January 2023, over 13,091 Web3\napplications have been deployed on various platforms (dap, 2023).\nAlthough Web3 has garnered increased public interest, a clear de\ufb01nition\nremains elusive. Analyzing and understanding popular Web3 projects could\nyield insights into Web3 and its ecosystem. In this paper, we endeavor to\naddress two research questions: RQ1: What are the categories of Web3\napplications? RQ2: What is the popularity of Web3 projects?\nTo answer RQ1, we initially gathered 626 Web3 projects and selected the\ntop 200 based on their investment amounts. We then manually analyzed the\nfeatures and services provided by these projects, and conducted an open card\nsorting to cluster them into several groups. Finally, we discovered that the\nWeb3 ecosystem comprises two categories, namely Web3 infrastructures and\nWeb3 applications, with each further subdivided into several subcategories.\nWeb3 infrastructure subcategories include DeFi, gaming, layer 2 scaling\nsolutions, privacy, developer tools/services, cross-chain interoperability, public\nchains, decentralized storage, and oracles. Web3 application subcategories\nencompass DeFi, NFT, Metaverse, DAO, and Web3 for traditional scenarios.\nTo answer RQ2, we collected code-related and market-related data for the\n200 Web3 projects from GitHub and blockchain browsers (i.e., Etherscan,\nBscscan, and Polygonscan). The analysis results can assist Web3 practitioners\n2\nand researchers in understanding the key attributes of Web3 projects,\nincluding dimensions such as code, market, and participant activities.\nIn addition, we also introduced the challenges and opportunities present\nwithin the Web3 ecosystem. Challenges were discussed from system, developer,\nand\nuser\nperspectives.\nChallenges\nat\nsystem-level\nare\ninteroperability,\nscalability, privacy; At developer-level are code security, incentive mechanism;\nand at user-level are usability and data recovery. In terms of opportunities,\nWeb3 features ensure security and grant users control over their data.\nAdditionally, Web3 paves the way for new business models, enables novel forms\nof collaboration, and enhances transparency across industries.\nThe main contributions of this work are:\n\u2022 We conducted a comprehensive empirical study by analyzing 200 popular\nWeb3 projects, from which we derived an understanding of the Web3\necosystem.\n\u2022 We uncovered the popularity of Web3 projects from code and market\nperspectives by analyzing code and market related data of popular Web3\nprojects.\n\u2022 We identi\ufb01ed the challenges and opportunities present in Web3. This\nidenti\ufb01cation serves to inform researchers and developers of the critical\nissues and potential prospects within Web3.\n\u2022 We are open-sourcing a Web3 dataset (dat, 2022), which includes 200\npopular Web3 projects that received funding from VC \ufb01rms, as well as\ntheir corresponding code and market-related data.\nThe remainder of the paper is organized as follows. Section 3 and section 4\nshow the answers for RQ1 and RQ2, respectively. Section 5 discusses the\nchallenges and opportunities faced in Web3. Section 6 discusses related work,\nand we conclude our study in Section 7.\n2 Background\n2.1 Web1, Web2 and Web3\nWeb1 (noa, 2010) is a readable-only network, whereas Web2 (noa, 2022b) is\na readable and writable network, and Web3 (noa, 2022c) is a readable and\nwritable network that empowers users with data ownership. In Web1, the\nnetwork primarily furnishes users with a collection of static pages for viewing\npurposes, devoid of interactive capabilities. While Web2 provides an array of\ndynamic pages, enabling user engagement with the network through activities\nsuch as content publication, \ufb01le sharing, and payment. Nevertheless, Web2 is\nplagued by issues concerning the collection and storage of users\u2019 personal data\non third-party platforms, potentially leading to unauthorized sales or illicit\nusage without the users\u2019 knowledge or consent. To address these challenges,\nWeb3 has been proposed, which not only supports readable and writable but\nalso ensures users maintain ownership of their data.\n3\n2.2 Blockchain, Smart contract and Web3\nA blockchain consists of a sequence of records, referred to as blocks, which\nare interconnected and secured using cryptographic techniques. Each block is\ncharacterized by its transaction data, timestamp, and the hash value of the\npreceding block. The blockchain functions as a public ledger, with individual\nblocks housing records of diverse transactions. Rather than being stored in a\ncentralized location, the blockchain is distributed across a network of nodes,\neach maintaining a copy. As a result, records are public and easily veri\ufb01able\nby all nodes, rendering data modi\ufb01cation in the blockchain exceedingly costly.\nModifying a block\u2019s transactions proves exceptionally challenging without\nattaining consensus among all nodes. Certain blockchains, such as Ethereum,\nprovide generic computational capabilities via smart contracts. An Ethereum\nsmart contract represents an account governed by an immutable program (i.e.,\nbytecode). Users can initiate the execution of the bytecode by transmitting\na transaction containing the speci\ufb01ed execution parameters to the smart\ncontract account.\nThe\nblockchain\nand\nsmart\ncontract\nserve\nas\nthe\nfoundation\nfor\nWeb3, facilitating the running of applications on a decentralized network.\nBlockchain technology o\ufb00ers several key advantages for Web3, including: 1)\nImmutability. All the data stored on the blockchain cannot be changed.\n2) Trustless. The interactions between users in a blockchain do not depend\non a trusted third party. 3) Availability. The decentralization of blockchain\nprovides high availability, as the failure of a single point on the network will not\na\ufb00ect the normal running of a blockchain. 4) Anonymity. Users do not need\nto provide their real information, and their activities are usually anonymous\nin a blockchain. 5) Ownability. Blockchain allows users to control their data\nthrough private and public keys.\n3 RQ1: The Categories Of Web3 Applications\nWeb3, as a novel concept, currently still lacks a clear de\ufb01nition and deep\nunderstanding for the ecosystem. In this section, we introduce the details of\nhow to \ufb01nd out the categories of Web3 applications. The results can help\nidentify popular Web3 projects and provide further insights into the Web3\necosystem.\n3.1 Approach\nIn order to gain an understanding of the Web3 ecosystem, we \ufb01rst need to \ufb01nd\nrepresentative Web3 projects. Currently, the industry has already begun to\nexplore the Web3 \ufb01eld for a long time and invested in various Web3 projects.\nThus, we collected 200 popular Web3 projects invested by Web3 VC \ufb01rms.\nThen, we conducted an analysis of the selected 200 Web3 projects, reviewing\n4\ntheir documentation in order to provide a summary for each project. Finally,\nwe performed open card sorting on these projects. The following provides\nfurther details on our approach.\nStep 1: Web3 projects collection. In this step, we \ufb01rst identi\ufb01ed 200\nWeb3 projects by examining the portfolios of Web3 VC \ufb01rms. We began\nby using the \u201d10 VC Firms Investing in Web3 Companies\u201d list published\nby visible.vc1 to identify 10 Web3 VC \ufb01rms. We then manually examined\nall portfolios of these VC \ufb01rms on Crunchbase2 from January 2020 to June\n2022, resulting in a total of 871 projects. For each project, we collected their\nname, o\ufb03cial website URL, and \ufb01nancing amount received. Next, we used a\nkeyword \ufb01ltering method to identify Web3 projects. Speci\ufb01cally, we checked\nthe o\ufb03cial website of each project for the presence of the keyword \u201cWeb3\u201d\nor other blockchain-related keywords, such as \u201cblockchain\u201d, \u201cWeb3 App\u201d, or\n\u201cdecentralized\u201d (Wang et al., 2022). We totally identi\ufb01ed 626 (71.87%) as\nWeb3 projects. Finally, we selected the top 200 Web3 projects based on their\ninvestment amount from Web3 VC \ufb01rms.\nStep\n2:\nDocuments\nanalysis. We conducted an analysis of the\ndocumentation for each Web3 project to understand their main functionalities.\nSpeci\ufb01cally, the \ufb01rst and second authors conducted independent reviews\nof each project\u2019s documentation, identifying texts that could provide a\npreliminary summarization of the project\u2019s functionalities. For example,\nUniswap (uni, 2022), a decentralized exchange, the summarization text is \u201ca\npeer-to-peer system designed for exchanging ERC-20 Tokens\u201d. In cases where\nthe documentation did not provide enough information about the project, we\nmanually reviewed the other information, such as API instructions and use\ncase examples, to extract relevant details regarding the project\u2019s functionality.\nBased on the information we extracted, we wrote a summarization for each\nproject. If there is a disagreement on the summarization of a project between\nthe authors, they discussed and consolidated their results.\nStep 3: Open card sorting. After determining a summarization for\neach project, we performed card sortingSpencer (2009) to identify categories\nbased on these summarizations. Card sorting is a commonly used method\nfor deriving categories from data. There are three main approaches to card\nsorting: closed, open, and hybrid. Given that the categories of Web3 projects\nare relatively unknown, we decided to follow an open card sorting approach\nto analyze these projects. During the open card sorting process, we created\ncards for each project that contained its name and summarization. Cards with\nsimilar summarizations were grouped together to form meaningful groups, each\nwith a speci\ufb01c topic. These groups are equivalent to low-level subcategories,\nfurther evolved into high-level categories. The resulting hierarchical structure\nprovided us with a clear categorization of the Web3 ecosystem. The \ufb01rst and\nsecond authors participated in the card sorting process and analyzed and\n1 https://visible.vc/blog/web3-investors/\n2 Crunchbase is a company providing business information about private and public\ncompanies. The website is: https://www.crunchbase.com\n5\nWeb3 ecosystem\nWeb3 application\nWeb3 infrastructure\nDeFi\nLending\nTrading&exchange\nInvestment\nWallet\nNFT\nNFT Service\nProperty rights\nGaming\nSocial\nMarketplace\nLiquidity\nNFT copyright Protection\nDAO\nMetaverse\nWeb3 for traditional scenes\nWeb3 for incentive\nWeb3 for transparency\nWeb3 for eliminating intermediaries\nDeFi\nGaming\nLayer 2 scaling solution\nPrivacy\nDeveloper tool/service\nCross-Chain Interoperability\nPublic chain\nDecentralized storage\nOracle\nFig. 1 The ecosystem of Web3\nveri\ufb01ed each card. Ultimately, we identi\ufb01ed two high-level categories within the\nWeb3 ecosystem: Web3 Infrastructure and Web3 applications. Each category\ncontains several subcategories (as shown in Figure 1).\nFigure 1 displays the results of the card sorting, providing an overview of\nthe Web3 ecosystem. In the following, we provide an introduction for each of\nthe two high-level categories, Web3 Infrastructure and Web3 Applications, and\ntheir subcategories. For each subcategory, we also highlight the Web3 project\nthat received the highest \ufb01nancing, showcasing state-of-the-art projects within\neach subcategory.\n6\n3.2 Web3 infrastructure\nWeb3 infrastructure encompasses a variety of applications and solutions\ndesigned to support developers and enhance blockchain networks. Our analysis\nhas identi\ufb01ed nine subcategories of Web3 infrastructure: DeFi infrastructure,\nGaming infrastructure, Layer 2 scaling solutions, Privacy infrastructure,\nDeveloper tools/services, Cross-chain interoperability services, Public chains,\nDecentralized storage, and Oracle services. In the following, we introduce each\nof these subcategories in more detail.\n3.2.1 DeFi infrastructure\nDeFi infrastructure is designed to simplify the development of token-swapping\nfunctionality by providing a standard set of APIs or SDKs.\nOne of the prominent DeFi infrastructure projects is 0x (0x, 2022),\nwhich has deployed smart contracts that support ERC20 (erc, 2022) token\nswapping on Ethereum, as well as multiple EVM-compatible blockchains.\nThese smart contracts aggregate liquidity from various decentralized exchanges\n(DEXs) (Malamud and Rostek, 2017) such as Uniswap (uni, 2022). Then,\nthe 0x protocol provides APIs for token-swapping functionality to developers.\nBy utilizing these APIs, developers can easily integrate token-swapping\nfunctionality into their Web3 applications and share the liquidity from DEXs.\n3.2.2 Gaming infrastructure\nThe gaming infrastructure facilitates the integration of in-game virtual assets\ninto the blockchain for developers without blockchain experience.\nEnjin (enj, 2022) is a prominent gaming infrastructure that enables\ndevelopers to design game using common programming languages such as\nC/C++, Java, and Python. Using the Enjin platform, developers can create\nin-game virtual assets, which are then assigned corresponding on-chain tokens.\nBy utilizing the API provided by Enjin, developers can integrate these on-chain\ntokens into the game. Enjin is also responsible for monitoring requests from\nthe game, processing requests on the blockchain, and returning data to the\ngame.\n3.2.3 Layer 2 scaling solution\nBlockchain\nnetworks\ntypically\nhave\nlow\nthroughput,\nwhich\nlimits\nthe\nwidespread adoption of Web3 applications. Layer 2 scaling solutions aim\nto increase network throughput without altering the underlying blockchain\nprotocol. These solutions propose a framework for handling transactions o\ufb00-\nchain and only reporting little information about the transaction on-chain,\nthereby achieving higher throughput.\nOptimistic Rollups (Scha\ufb00ner, 2021) is a representitive layer 2 scaling\nsolution, which has been adopted by EVM-compatible layer 2 networks, e.g.,\n7\nOptimism (opt, 2022). This solution improves blockchain scalability (Chauhan\net al., 2018) by bundling multiple transactions on the layer 2 network,\ncompressing\nthem,\nand\noptimistically\nassuming\ntheir\nvalidity\nbefore\nsubmitting them to blockchain layer 1 for veri\ufb01cation. During this process,\nany node on the layer 2 network can challenge transactions with fraud proofs\nwhen they observe invalid transactions. The node that submitted invalid\ntransactions will be punished. This mechanism ensures the validity of the\ntransactions submitted by the layer 2 network to a great extent.\n3.2.4 Privacy\nIn most blockchain networks, user data is publicly visible, which poses a\nchallenge to user privacy. Privacy infrastructure is designed to prevent users\u2019\ntransaction histories from being exposed to the public.\nOne of the representative privacy infrastructures is the Aztec protocol (azt,\n2022). It consists of an Ethereum smart contract and a layer 2 network that\nadopts ZK-proofs (Sun et al., 2021) technology. Users can transfer tokens\nfrom Ethereum to the Aztec layer 2 network by depositing tokens into the\nAztec smart contract. In the layer 2 network, users can send tokens to others\nor interact with some Ethereum layer 1 smart contracts that are connected\nto the Aztec protocol. The transactions made by users in the Aztec layer 2\nnetwork are encoded as zkSNARK (Petkus, 2019) to protect users\u2019 transaction\ndata from the public. Then, these transactions are bundled and sent to the\nEthereum layer 1. Developers can integrate their smart contracts with the\nAztec protocol using the API provided by the Aaztec protocol, enabling their\nWeb3 applications to support user interaction in a private manner.\n3.2.5 Developer tool/service\nDeveloper tools & services aim to assist developers in developing, testing,\ndeploying, and managing smart contracts.\nConsenSys (con, 2022) is a popular project that provides development tools\nand services, including Infura (inf, 2022) and Tru\ufb04e (tru, 2022). Infura is an\nEthereum node provider that allows developers to connect Web3 applications\nto Ethereum without running their own nodes. It also provides APIs for\nEthereum account management, smart contract deployment, transaction\nsigning, and retrieving on-chain data. Tru\ufb04e is an Ethereum-based Web3\napplications development framework that provides smart contract compilation,\ntesting, deployment, and interactive console features. It also provides libraries\nfor Web3 application development.\n3.2.6 Cross-Chain Interoperability\nCommunication between di\ufb00erent blockchains was di\ufb03cult. Cross-chain\ninteroperability is a solution that aims to facilitate the \ufb02ow of data and value\nacross di\ufb00erent blockchains.\n8\nAxelar (axe, 2022) is a popular cross-chain interoperability solution that\noperates as an independent decentralized network with its validators. Axelar\nenables interoperability between blockchains by deploying smart contracts on\nthese blockchains connected to Axelar. These smart contracts are controlled\nby a shared key that utilizes multi-party cryptography, which is divided into\nmultiple parts and held by validators based on the amount of Axelar tokens\nthey have staked. These validators run nodes on blockchains connected to\nAxelar to monitor on-chain activities. They are responsible for approving token\ncross-chain transfer requests from users after observing the deposits made by\nthe users to the Axelar smart contract. When more than 50% of the shares\nof the shared key from validators approve the request, the smart contract\nexecutes the token cross-chain transfer.\n3.2.7 Public chain\nThe\npublic\nblockchain\nis\nfacing\nthe\nchallenge\nof\nthe\nBlockchain\ntrilemma (Monte et al., 2020), which means it is di\ufb03cult to meet the demands\nof decentralization, scalability, and security simultaneously.\nMany public blockchains are exploring ways to maximize scalability while\nensuring su\ufb03cient security. Near (nea, 2022) is a representative project that\nproposes to improve scalability through sharding technology (Wang et al.,\n2019) named Nightshade (Skidanov and Polosukhin, 2019). In this sharding\ntechnology, data in a block is divided into multiple chunks based on the number\nof shards, with each shard responsible for one chunk. The shards are allocated\nto a portion of the validators in the network through a veri\ufb01able random\nfunction (Micali et al., 1999). The validator of a shard only needs to store and\nverify the chunk corresponding to the shard without storing and validating\nthe complete block, thus improving scalability.\n3.2.8 Decentralized storage\nStoring data on popular blockchain networks like Ethereum can be expensive\nsince the data needs to be stored on each node of the network. To address\nthis issue, the decentralized storage network (Benisi et al., 2020) was designed,\nwhich is essentially a blockchain. In this network, users\u2019 \ufb01les are encrypted and\nstored on nodes of the network. The nodes only write encrypted metadata of\nthe \ufb01les (e.g., \ufb01le location and \ufb01le hash) into blocks of the network without\nthe full \ufb01les, thus reducing storage costs.\nFilecoin (\ufb01l, 2022) is a popular decentralized storage network based on\nthe IPFS protocol (Benet, 2014). In the Filecoin network, users pay fees\nbased on \ufb01le size and storage time, and then their \ufb01les are stored on nodes.\nNodes guarantee that the \ufb01les have been stored and not deleted during\nstorage by submitting Proof-of-Spacetime (Benet et al., 2017) and Proof-\nof-Replication (Benet et al., 2017) generated from the \ufb01les to the Filecoin\nnetwork.\n9\n3.2.9 Oracle\nOracle (Beniiche, 2020) is an interface used to deliver o\ufb00-chain data to the\nblockchain for smart contracts to consume. However, delivering invalid or\nmalicious data to the blockchain can potentially put smart contracts and user\nassets at risk.\nTo solve this problem, the Razor Network (raz, 2022) proposed a solution\nin which data providers are required to stake tokens. Providers of valid data\nwill receive token rewards, while providers of invalid data will be \ufb01ned. This\nmechanism enhances the reliability of the data provided to the blockchain,\nthus improving the security of smart contracts and user assets.\n3.3 Web3 applications\nWeb3 applications refer to a set of applications that target users. In our\nstudy, we have identi\ufb01ed \ufb01ve subcategories of Web3 applications: Decentralized\nFinance (DeFi), NFT, Metaverse, DAO, and Web3 for traditional scenes.\nAmong them, the subcategories of DeFi, NFT, and Web3 for traditional scenes\ncontain several smaller subcategories, which will be described in detail below.\n3.3.1 Decentralized Finance (DeFi)\nThe term \u201cDeFi\u201d refers to the decentralized \ufb01nancial system that runs on top\nof the blockchain. In our dataset, the DeFi subcategory is further divided into\nfour smaller subcategories: 1) lending, 2) trading & Exchange, 3) investment,\nand 4) wallets. In the following, we will describe each of them in detail.\n1) Lending. The lending protocol pools funds from multiple lenders to\nprovide loans to borrowers and earns interest from the borrowers. The interest\npayments are then distributed to the lenders as returns on their lending.\nAave (aav, 2022) is a representative lending protocol that provides\nover-collateralized loans and \ufb02ash loans (Wang et al., 2020). In an over-\ncollateralized loan, the borrower is required to lock up crypto assets with\na value exceeding the loan amount as collateral before the loan is released. In\ncase the value of the collateral falls below a prede\ufb01ned threshold, the smart\ncontract initiates an auction to recover the funds lent to the borrower and\nprovide returns to the lender. Flash loans are uncollateralized loans available\nto developers with programming experience. In a \ufb02ash loan, the borrower is\nonly required to repay the entire loan amount and interest before the end of\na single transaction without locking any assets.\n2) Trading & Exchange. Trading & Exchange applications are a series of\nDEXs that enable on-chain token swapping without the need for a centralized\ncustodian. However, implementing the order book model (Abudy and Wohl,\n2018) used by centralized exchanges (CEXs) on the blockchain often results\nin low e\ufb03ciency.\n10\nIn the trading and exchange \ufb01eld, Uniswap is a representative project\nthat has adopted an Automated Market Maker (AMM) (Xu et al., 2021)\nalgorithm to replace the ine\ufb03cient order book model. The AMM algorithm\nuses a liquidity pool mechanism for swapping, allowing users to have an instant\ntoken swap. The swap ratio is determined by the ratio of two tokens in the\npool using a speci\ufb01c algorithm.\n3)\nInvestment.\nThe investment\nprotocol\nacts as\na\ndecentralized\ninvestment fund that encodes investment strategies into the smart contract.\nWith this protocol, users can deposit funds into the smart contract, which\nthen executes prede\ufb01ned rules to transact. After yielding pro\ufb01ts, the pro\ufb01ts\nare distributed to the users.\nTokenSets (tok, 2022) is a popular protocol in the investment \ufb01eld that\nprovides users with multiple portfolios. Each portfolio is managed by a smart\ncontract, which transacts a speci\ufb01c set of tokens on DEXs based on prede\ufb01ned\nrules. TokenSets also allows investors to write their investment strategies into\nthe smart contract and provide them to the public.\n4) Wallet. Wallets are tools that allow users to manage their crypto assets\nand interact with Web3 applications.\nMetamask (met, 2022) is a popular wallet that enables users to create\nor recover their Ethereum accounts on any device by using human-readable\nphrases, without storing complex public and private keys. With Metamask,\nusers can manage their ERC20 tokens and interact with Web3 applications.\n3.3.2 NFT\nNFT refers to a subcategory of Web3 applications that incorporate NFT\nelements (Wang et al., 2021). This subcategory can be further divided into\nthe following smaller subcategories: 1) NFT services, 2) property rights, 3)\ngaming, and 4) social. The details of each subcategory are described below.\n1) NFT Services. NFT services consist of the following three small\nsubcategories: i) NFT Marketplace, ii) liquidity protocol, and iii) NFT\ncopyright protection service.\ni) NFT marketplace. The NFT market is a platform for NFT trading.\nOpenSea (Ope, 2022) is currently the biggest NFT marketplace, o\ufb00ering\nusers the ability to buy and sell various types of NFTs such as artworks,\nmusic, game assets, and more. Additionally, OpenSea allows users to mint\nNFTs without any prior experience in blockchain technology.\nii) liquidity protocol. NFTs are often associated with high prices and\nlow liquidity.\nTo address the liquidity issue, fractional.art (fra, 2022) has proposed an\nNFT liquidity solution that involves dividing the ownership of an NFT. In this\napproach, the owner of the NFT locks NFT in fractional.art\u2019s smart contract.\nThe smart contract then issues multiple ERC20 tokens based on the locked\nNFT, with each token representing proportional ownership of the NFT. This\nmethod e\ufb00ectively lowers the barriers to acquiring NFTs and increases their\nliquidity.\n11\niii) NFT copyright protection. The NFT market is plag-ued by\ncounterfeit NFTs, which are created by malicious users by uploading images\nof well-known NFTs and then minting NFTs to list on marketplaces.\nTo protect the copyright of NFTs, a project called Doppel (dop, 2022) has\nprovided a solution for detecting fake NFTs. This project uses computer vision\nand AI models to detect fake NFTs and report them. Currently, the company\nprovides detection services for NFT on Ethereum, Solana, and Polygon.\n2) Property Rights. NFT has been applied to protect digital/physical\nproperty rights.\nIn\nterms\nof\nprotecting\ndigital\nproperty\nrights,\na\nproject\ncalled\nRoyal.io (Roy, 2022) provides NFT-based music copyright protection. At\nRoyal.io, artists can mint NFTs for their songs, with the song\u2019s name, hash\nvalue, and royalty share as the NFT\u2019s metadata. When the songs are purchased\nby third parties, the NFT holders will receive a portion of the royalties as their\nreturn. In terms of protecting physical asset property rights, a project called\nOrigyn (ori, 2022) mints high-de\ufb01nition images of real-world physical assets\nsuch as handbags, watches, and jewelry as NFTs, which serve as proof of\nproperty rights for these physical assets.\n3) Gaming. NFT technology has also been adopted in the gaming\nindustry, where in-game virtual assets are minted as NFTs, returning\nownership of game data to the players. This type of game is also referred\nto as GameFi, enabling players to earn pro\ufb01ts from the games.\nAxie In\ufb01nity (noa, 2022a) is a prominent GameFi project where players\ncan collect, breed, raise, and trade virtual pets, with each pet being stored as\nan NFT on the blockchain. Players can operate their pets to battle with other\npets or sell their own pets to earn token rewards.\n4) Social. NFT technology has also been applied in the social \ufb01eld,\nproviding a way for users to express themselves freely without the control\nof tech giants.\nOne notable project in this \ufb01eld is Mirror (mir, 2022), which is a\ndecentralized blogging platform. On this platform, users can publish their\ncontent and mint them as NFTs. The content published by the user is then\nstored on IPFS, ensuring that the user\u2019s data cannot be arbitrarily altered\nor deleted. Furthermore, users can purchase NFTs minted by the creators to\nexpress their support.\n3.3.3 Metaverse\nMetaverse (Gadekallu et al., 2022) refers to a virtual world built by computers\nthat can interweave with the real world.\nMany metaverse projects have been built on top of the blockchain,\ncharacterized by the minting of characters or virtual assets of the virtual world\nas NFTs. One popular metaverse built for real estate is \u201cThe Sandbox\u201d (the,\n2022). In The Sandbox, users can purchase land on the game map and engage\nin secondary development. The in-game lands are recorded on the blockchain\nas NFTs, and users can also visit lands constructed by others.\n12\n3.3.4 DAO\nDAO (El Faqir et al., 2020) stands for decentralized autonomous organization,\nwhich operates through smart contracts. The smart contract manages the\norganization by executing the rules prede\ufb01ned by the organization\u2019s members.\nIn the DAO \ufb01eld, CreatorDAO (cre, 2022)is a typical example that\nbrings together investors, creators, and supporters in a community. The DAO\nprovides creators and their works with funding and resources to support their\ncreative endeavors. When creators make pro\ufb01ts from their works, the pro\ufb01ts\nare automatically distributed to community members by the smart contract.\n3.3.5 Web3 for Traditional Scenes\nWeb3 technology has also been adopted by many traditional industries to\naddress challenges related to incentives, collaboration, transparency, trust,\nand etc. Based on the functionalities of Web3 in traditional industries, three\nsubcategories have been identi\ufb01ed: 1) Web3 for incentives, 2) Web3 for\ntransparency, 3) Web3 for eliminating intermediaries.\n1) Web3 for incentives. Some traditional industries are leveraging\nthe incentive mechanism of Web3 by building their businesses on top of\ndecentralized networks.\nFor instance, Helium (hel, 2022) is a blockchain-based wireless network\noperator that sells devices for providing wireless network coverage and\nmining. Users can purchase these devices and deploy them to provide wireless\nnetworks, thereby earning tokens. This incentive mechanism reduces the cost\nfor enterprises to build and run their businesses while allowing users to bene\ufb01t\nfrom traditional business scenes.\n2) Web3 for transparency. Web3 has also been adopted by traditional\nindustries to address trust issues by recording key business information on the\nblockchain.\nGreen Labs (gre, 2022) and Blocery (blo, 2022) are two companies that\napply blockchain technology to the \ufb01eld of traceability. They record key\ninformation about products, such as production time, transfer history, and\nsales records, on the blockchain. The information recorded on the blockchain\nis publicly visible and tamper-proof, which enables the entire process of\nproduction and sales of products to be fully traceable, thereby increasing\ntransparency and trust.\n3)Web3 for eliminating intermediaries. Web3 eliminates the need for\nintermediaries in traditional business scenes by designing smart contracts to\nrun the business.\nFor example, Dtravel (dtr, 2022) is a decentralized travel platform on\nEthereum. In this platform, travelers can directly book accommodations from\nproperty owners by interacting with smart contracts without having to go\nthrough online travel agents.\n13\n4 RQ2: Popularity Of Web3 Projects\nIn this research question, we conducted an analysis of code-related and market-\nrelated data of Web3 projects to gain insights into their popularity. The\n\ufb01ndings of this research can assist Web3 practitioners and researchers in\nunderstanding the key attributes of Web3 projects, including dimensions such\nas code, market, and participant activities.\n4.1 Approach\nTo get insight into the popularity of Web3 projects on the code level and\nmarket level. We adopt the following methods to collect and analyze Web3\ndata.\nStep 1: Web3 data collection. In this part, we collected code-related\ndata of Web3 projects through Github and mark-et-related data of the Web3\nprojects through web3 blockchain browsers, i.e., Etherscan, Bscscan, and\nPolygonscan. In terms of code-related data, we \ufb01rst manually checked if the\nprojects had open-source repositories on GitHub. After manually reviewing\nthe 200 Web3 projects, we identi\ufb01ed 96 open-source Web3 projects. Finally, we\ncollected GitHub data for all 96 identi\ufb01ed projects. In terms of market-related\ndata, we obtained transaction and market cap data for each Web3 project\nbetween January 2022 and January 2023 by utilizing the APIs of blockchain\nbrowsers.\nStep 2: Analysis of code level popularity. For each subcategory of the\nWeb3 infrastructure and Web3 applications, we calculated the number of open-\nsource projects, as well as the total code lines and commits of code repositories\nfor all projects(shown in table 1), which were used to quantify the popularity of\na particular subcategory at the code level. The subcategory has more projects,\ncode lines, and commits, and the more popular it is. Additionally, we analyzed\nthe blockchain platforms that Web3 applications were deployed on. Then\nwe summarized the number of Web3 projects deployed on each blockchain\nplatform to understand the popularity of blockchain platforms.\nStep 3: Analysis of market level popularity. We divided Web3\nprojects into two groups: projects deployed on multiple blockchain platforms\nand projects deployed on a single blockchain platform. Each group includes\nthe names of the Web3 projects, as well as their user numbers and market\nvalues. We analyze the median user numbers and market values of the Web3\napplications in each group. By comparing the medians and maximum values of\nthe two groups, we understand the impact of deploying Web3 applications on\nmultiple blockchains versus a single blockchain in terms of user numbers and\nmarket value. Following the aforementioned methodology, we divided Web3\nprojects into the open-source group and the non-open-source group. Then, we\nobtained the medians and maximum values of users and market value for the\ntwo groups, which re\ufb02ect the impact of open-sourcing of Web3 projects in\nterms of user numbers and market value. Additionally, for each subcategory of\n14\nWeb3 projects, we calculated the total number of users and market cap for all\napplications of each category(shown in table 2), which were used to quantify\nthe popularity of a particular subcategory at the market level. Finally, We\nanalyzed the number of users of each Web3 application, \ufb01gure 5 depicted the\ndistribution of the number of users of each Web3 application.\nIn the following, we present the \ufb01ndings of the popularity of Web3 projects\non two levels: code level and market level.\nTable 1 Code-related data of Web3 projects.\nSubcategories\nCount\nCode lines\nCommits\nPublic chains\n17\n3,386,348\n124,040\n# Cross-Chain\n9\n3,156,655\n39,720\nDeveloper tool\n8\n641,749\n11,998\n# Dstorage\n7\n421,291\n17,708\nOracle\n3\n364,499\n872\n# Gaming infra\n2\n309,826\n6,330\nLayer 2 scaling\n2\n2,071,208\n15,594\nPrivacy\n2\n436,352\n7,960\n# De\ufb01infra\n1\n105,496\n17,137\nLending\n14\n595,999\n11,205\nTrading&exchange\n7\n214,912\n2,756\nInvestment\n4\n80,193\n2,919\nDAO\n1\n2,793\n55\nWallet\n2\n162,163\n4,533\nNFT Marketplaces\n2\n117,305\n2,977\nNFT Liquidity\n2\n56,843\n454\n# NFT CP\n1\n14,091\n3\n# Property rights\n2\n105,070\n806\nGaming\n3\n28,002\n162\nMetaverse\n1\n462,462\n5,656\nWeb3 for incentive\n2\n98,049\n3,804\n# Eliminating inters\n4\n20,992\n321\n4.2 Code-level \ufb01ndings\nThe code-level \ufb01ndings re\ufb02ect the popularity associated with the developer.\nFor\nexample,\nthe\npreferences\nfor\ndeveloping\nspeci\ufb01c\ntypes\nof\nWeb3\ninfrastructure and Web3 applications and the platform for deploying Web3\napplications. Table 1 shows the code-related data of Web3 projects. The \ufb01rst\ncolumn denotes the subcategories of open-source Web3 projects. In them,\nrows 1-9 denote the subcategories of Web3 infrastructure, while rows 10-21\ndenote the subcategories of Web3 applications. Among these subcategories,\n# Cross-Chain denotes the subcategory of Cross-chain interoperability. #\nDstorage denotes the subcategory of decentralized storage. # Gaming infra\nand # De\ufb01infradenotes the subcategory of Gaming infrastructure and De\ufb01\ninfrastructure, respectively. # NFT CP denotes the subcategory of NFT\ncopyright protection. # Property rights denotes the subcategory of NFT\n15\n19 (17.59%)\n5 (4.63%)\n6 (5.56%)\n6 (5.56%)\n7 (6.48%)\n9 (8.33%)\n56 (51.85%)\n Ethereum\n BSC\n Polygon\n Solana\n Polkadot\n Avalanche\n Others\n \nFig. 2 Distributions of blockchain networks\nProperty rights. # Eliminating inters denotes the subcategory of Web3\nfor eliminating intermediaries. Besides, Figure 2 shows the distributions of\nblockchain networks. Following are some observations from the table.\nObservation 1: Public chain is the most popular subcategory in\nthe Web3 infrastructure. Table 1 shows that among open-source Web3\ninfrastructure projects, public chains are most numerous at 17, with the\nhighest code lines (3,386,348) and commits (124,040).\nObservation 2: Lending is the most active subcategory in Web3\napplications development. As shown in table 1, the Lending subcategory\nhas the largest number of open-source projects among the Web3 application\nsubcategories, with 12 projects. Moreover, the total number of code lines\nand commits are higher than other subcategories, at 595,999 and 11,205,\nrespectively.\nObservation\n3:\nEthereum\nis\nthe\nmost\npopular\nblockc-hain\nnetwork used to deploy Web3 applications. As shown in Figure 2, out of\nthe 72 Web3 applications analyzed, 56 are deployed on the Ethereum network,\naccounting for 51.85% of the total.\nObservation\n4:\nSolidity\nis\nthe\nmost\npopular\nprogramming\nlanguage\nfor\nWeb3\napplications\u2019\nsmart\ncontract\ndevelopment.\nFigure 3 shows the distribution of back-end programming languages for 41\nopen-source Web3 applications. Out of the 41 open-source Web3 applications,\n29 of them utilized Solidity as their programming language for smart\ncontract(back-end) development.\n4.3 Market-level \ufb01ndings\nThe \ufb01ndings at the market level re\ufb02ect the popularity associated with user\nactivity. These \ufb01ndings re\ufb02ect the features of applications with a larger user\nbase and market cap, the most popular Web3 activities for users and the user\ncount of most applications. Figure 4 shows the distributions of user counts and\nmarket cap, and Figure 5 illustrates the number of users of a Web3 applications\n16\n1 (2.44%)\n1 (2.44%)\n1 (2.44%)\n1 (2.44%)\n2 (4.88%)\n6 (14.63%)\n29 (70.73%)\n Solidity\n Rust\n Javascript\n Clarity\n Typescript\n Motoko\n Erlang\n \nFig. 3 Distributions of Web3 back-end programming languages\nbetween January 2022 and January 2023. Besides, Table 2 introduces market-\nrelated data of Web3 projects. Following are the observations from the market-\nlevel data.\nObservation 5: Web3 applications deployed on multiple bloc-\nkchains have more users and a higher market cap. In \ufb01gure 4 b),\nthe \ufb01rst and second boxes presents the distribution of the number of users for\nWeb3 applications deployed on multiple blockchains and a single blockchain,\nrespectively. It can be observed that the maximum value and median of the\nuser numbers for Web3 applications deployed on multiple blockchains are\nhigher than those deployed on a single blockchain. In \ufb01gure 4 a), the \ufb01rst\nbox and the second box represents the distribution of market capitalization\nfor Web3 applications deployed across multiple blockchains and a single\nblockchain, respectively. It can be observed that the maximum and median\nof the market cap for Web3 applications deployed on multiple blockchains are\nhigher than those deployed on a single blockchain.\nObservation 6: Open-sourcing Web3 applications can increase the\nnumber of users and market cap. In \ufb01gure 4 b), the third and forth box\nillustrate the distribution of the number of users of open-source and non-\nopen-source Web3 applications, respectively. We can observe that the median\nof users for non-open source Web3 applications is lower, while open-source\nWeb3 applications have a higher maximum number of users. In \ufb01gure 4 a),\nthe third and forth box display the distribution of the market cap of open-\nsource and non-open-source Web3 applications, respectively. We can \ufb01nd that\nthe maximum and median of market cap for open-source Web3 applications\nare higher than those for non-open-source Web3 applications.\nObservation 7: In Web3, NFT trading is the most popular activity\nfor users. As seen in Table 2, the NFT market has the highest number of\nusers at 2,070,447 and the highest market cap at $24,687,589,059.\n17\n4.6M\n5.0G\n1.2G\n753.2k\n75.2M\n6.6M\n11.5M\n346.0M\n66.5M\n461.1k\n7.7M\n2.1M\n15.2k\n651.7k\n162.6k\n800.0\n10.4k\n2.2k\n1.8k\n31.7k\n10.4k\n336.0\n2.5k\n1.6k\nmBCs\nsBC\nOSAs\nNOSAs\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n1010\n1011\na) Market cap of Apps\n# of market cap(USD)\nmBCs\nsBC\nOSAs\nNOSAs\n100\n101\n102\n103\n104\n105\n106\n107\nb) User counts of Apps\n# of users\nFig. 4 Distributions of user counts and market cap. mBCs denotes the Applications\ndeployed across multiple blockchains. sBC denotes the applications deployed on a single\nblockchain. OSAs denote open source applications, while NOSAs denote non-open-source\napplications\n102\n103\n104\n105\n106\n0.00%\n20.00%\n40.00%\n60.00%\n80.00%\n100.00%\nCDF\nUsers of a Web3 App\nFig. 5 Number of users of a Web3 applications between January 2022 and January 2023.\nObservation 8: About 65% of popular Web3 applications have less\nthan 10,000 users in a year. The cumulative distribution function (CDF) of\nthe number of unique users of the popular Web3 applications between January\n2022 and January 2023 is shown in Figure 5.\n18\nTable 2 Market-related data of Web3 projects. # Cnt denotes the number of Web3\nprojects in the subcategory. #\nproperty\nrights denotes the subcategory of NFT\nProperty rights. # Eliminating inters denotes the subcategory of Web3 for eliminating\nintermediaries.\nSubcategories\n# Cnt\nUsers\nMarket cap\nLending\n14\n129,188\n$1,827,265,578\nTrading&exchange\n11\n843,178\n$5,831,446,783\nInvestment\n2\n22,287\n$2,682,758,809\nNFT marketplace\n4\n2,070,447\n$24,687,589,059\n# property rights\n4\n16,422\n$28,864,897\nGaming\n17\n193,249\n$1,249,040,083\nSocial\n3\n18,780\n$8,753,611\nMetaverse\n1\n220,532\n$950,498,005\nDAO\n4\n49,375\n$1,177,325,522\nWeb3 for incentive\n3\n477,043\n$522,377,779\n# Eliminating inters\n2\n2,910\n$16,049,029\n5 Challenges And Opportunities\nIn this section, we point out the challenges faced by Web3 on three levels:\nsystem level, developer level, and user level. Then, we discuss the opportunities\nin Web3 ecosystem.\n5.1 Challenge in system level\nAs the underlying infrastructure that supports Web3 applications, problems\nin the blockchain system could potentially limit the development of Web3. We\nhave identi\ufb01ed \ufb01ve key aspects that may impact the Web3 ecosystem.\nS1)\nScalability. Blockchain\u2019s transaction throughput limits hinder\nWeb3 applications from ful\ufb01lling real-time processing needs for millions of\ntransactions. This problem also results in users paying high gas fees during\nnetwork congestion. While some layer 2 scaling solutions have been proposed,\nthey risk reduced decentralization and potential security issues.\nS2) Interoperability. Di\ufb00erent blockchains are not able to communicate\nwith each other directly, which restricts the \ufb02ow of data and tokens across\ndi\ufb00erent blockchains. Even though some cross-chain interoperability solutions\nhave been proposed, they only support the transfer of tokens and not\ncommunication between applications on di\ufb00erent blockchains.\nS3) Privacy. The data stored on a blockchain is publicly visible, which\nmakes user privacy more vulnerable to threats, especially when the relationship\nbetween a wallet and a physical identity is revealed. While some privacy\nprotection solutions have been proposed, they are still unable to fully hide\nusers\u2019 account balances and transaction histories.\n19\n5.2 Challenge in developer level\nIn developing Web3 applications, the developers may face two challenges. The\ndetails are as follows:\nD1) Code security. The code of Web3 applications deployed on the\nblockchain is publicly accessible, which makes it easier for hackers to exploit\nand launch attacks. Currently, there is a lack of mature code auditing tools,\nwhich puts pressure on developers to be cautious when writing application\nlogic. Moreover, there have been instances where even audited code has been\nattacked, resulting in signi\ufb01cant losses of crypto assets.\nD2) Incentive mechanisms design. Poorly designed economic systems\nin Web3 projects can lead to failure. Many Web3 projects use token-based\nincentive mechanisms, but if the reward and consumption rules of the token\nare not well thought out, the token\u2019s value may plummet, causing the project\nto collapse. There have been several cases of Web3 projects failing due to issues\nwith their economic systems.\n5.3 Challenge in user level\nThe following describes two challenges that users face while sur\ufb01ng on Web3.\nU1) Data recovery. The loss of a private key can result in the loss of\npersonal data and assets in Web3. Private keys serve as credentials for users\nto access and manage personal data in Web3. Losing them can lead to the\ncrypto assets being locked and made unrecoverable. Therefore, it is necessary\nto design a mechanism for recovering user data.\nU2) Usability. The user interface of Web3 applications is more complex\nand challenging to operate than that of Web2 applications. When interacting\nwith a Web3 application, users are typically presented with a wallet interface\ncontaining complex strings, which can be confusing and result in potential\nasset loss. For example, a user may inadvertently sign a \u201csetapprovalforall\u201d\ntransaction launched by a Web3 application if they cannot understand the\ntransaction details, resulting in the transfer of all their assets to another party.\nCurrently, many phishing scams exploit this vulnerability, putting users\u2019 assets\nat risk.\n5.4 Opportunities in Web3\nWe present multiple opportunities that Web3 brings in the following:\nO1) Business model. Web3 has motivated the emergence of new business\nmodels through its decentralized design and smart contracts. For example,\nin the \ufb01nance industry, DeFi provides users with new ways to store, trade,\nand invest their assets. In the mobile communication industry, Helium (hel,\n2022) explores the deployment of network infrastructure in a distributed\nmanner, allowing people to participate and pro\ufb01t from network deployment\n20\nand operations. These examples demonstrate how Web3 enables the creation\nof innovative business models through decentralization.\nO2) Collaboration. DAOs facilitate new collaboration models. They\ntransform\nthe\ntraditional\norganizational\nmodel\nthrough\ndecentralized\ngovernance and transparent operations, providing a signi\ufb01cant opportunity to\ncreate a more e\ufb03cient and democratic form of organization. MakerDAO (Mak,\n2022) is a DeFi protocol built on Ethereum that allows users to obtain\nstablecoins by staking crypto tokens. In MakerDAO, important decisions such\nas adjustments to fees and the addition of staking token types are decided\nthrough a voting process by MakerDAO token holders.\nO3) Transparency Web3 introduces a new method of information\nrecording that enhances transparency in various business scenarios. Recording\ninformation on a blockchain enables it to be publicly visible and immutable,\nthereby addressing issues related to trust and transparency. For instance,\nsupply chain management utilizes blockchain to record relevant information,\nresulting\nin\nincreased\ntransparency,\ntrustworthiness,\nand\nmanagement\ne\ufb03ciency.\nO4) Ownership of data. Web3 restores data ownership to users. In\nWeb3, personal user data is stored on the blockchain and controlled by the\nuser who holds the private key. This eliminates the control of centralized\ninstitutions over user data. For example, when a game adopts NFT technology,\nthe game operator cannot modify the user\u2019s data, ensuring the security of user\ndata.\n6 Related Work\nThere have been several previous studies on the topic of Web3, the details are\nas follows.\nWang et al. (Wang et al., 2022) conducted the \ufb01rst empirical investigation\nof existing Web3 projects, extracting a concise backbone model that delineates\nparticipating roles and operational work\ufb02ows of Web3 projects. Subsequently,\nthey proposed twelve distinct Web3 architectural designs, capturing the\noperational mechanisms of typical Web3-based applications. In their study,\nthey deconstructed a complete Web3 service into three-tiered components,\nbased on data work\ufb02ow considerations. Data within each component can\nbe managed through on-chain, o\ufb00-chain, or hybrid methodologies. The\nidenti\ufb01ed design types e\ufb00ectively represent the full spectrum of potential\nWeb3 applications and service combinations. To evaluate the merits of each\narchitectural design, the authors meticulously assessed each con\ufb01guration\nusing a variety of property metrics, derived from classic blockchain systems.\nAdditionally, they explored which participating entities stand to gain the most\nadvantages under varying design types. Expanding the scope of their research\nbeyond architectural design, they examined the broader implications of Web3,\ndiscussing its impacts, opportunities, and challenges.\n21\nSheridan et al. (Sheridan et al., 2022) delineated the fundamental\ncomponents of Web3 implementation, encompassing blockchain networks,\nWeb3 programming languages, Web3 libraries, smart contracts, and wallets.\nFurthermore, they presented an overview of Web3 developers, as well as the\nimpacts and risks associated with Web3. Lastly, they projected possible future\nintegrations of Web3 with other emerging technologies.\nYu et al. (Yu et al., 2022) delved into the essence of Web3 by examining an\nextensive range of real-world Web3 projects. They conducted a comparative\nanalysis between existing Web2 solutions and self-proclaimed Web3 projects\nto identify the fundamental characteristics of Web3 applications and their\ndependencies, as well as to distinguish their di\ufb00erences from traditional\nWeb2 applications. Through a thorough investigation, the authors proposed\na seamless transition framework, dubbed WebttCom, aimed at facilitating\nthe transition from Web2 to Web3. The innovative WebttCom framework\no\ufb00ers e\ufb03cient and reliable access control and user management across\nboth decentralized Web3 and centralized Web2 environments. Furthermore,\nit presents a viable method for implementing the transition with widely-\nused Software as a Service platforms, and showcases a practical use case\nimplemented using this framework. In order to assess the framework\u2019s\ne\ufb00ectiveness from the developers\u2019 perspective, they conducted interviews\nwith \ufb01ve pro\ufb01cient developers. The feedback obtained from these interviews\ndemonstrated that the research question was adequately addressed by the\nproposed WebttCom framework. Subsequently, the authors put forth several\nrecommendations for enhancing the WebttCom framework, which includes\nextending its compatibility to incorporate additional blockchain platforms and\nexploring further potential business cases.\nLiu et al. (Liu et al., 2021) introduce the \ufb01rst comprehensive and\nquanti\ufb01able metric, referred to as veri\ufb01ability, for delineating the Web3\nera, which is grounded in empirical observations and rational analysis of\nthe evolution of blockchain infrastructures in recent years. In light of this\ncharacterization, we identify three fundamental infrastructural enablers for\nWeb3: individual blockchains with smart contract capabilities, centralized or\nfederated state publishers, and interoperability platforms designed to bridge\nthe gaps between these disparate systems. Subsequently, the authors o\ufb00er an\nin-depth exploration of one of these three core enablers: HyperService, the\npioneering interoperability platform that seamlessly connects heterogeneous\nblockchains and federated or centralized state publishers to establish a\nuni\ufb01ed, cohesive computing platform for Web3 applications. The researchers\nimplement a prototype of HyperService, consisting of approximately 62,000\nlines of code, and assess its performance using three distinct categories of\ncrosschain decentralized applications. Experimental results demonstrate that\nHyperService imposes an end-to-end dApp execution latency on the order of\nseconds, while also exhibiting horizontal scalability in the platform.\nIn contrast to previous studies, our research focuses on delineating\nthe Web3 ecosystem through popular projects, analyzing overviews and\nrepresentative applications for each \ufb01eld, and evaluating the popularity of\n22\nWeb3 projects. Additionally, we underscored the opportunities presented\nby Web3 and emphasized the challenges it poses for blockchain systems,\ndevelopers, and users.\n7 Conclusion\nIn this study, we conducted a comprehensive empirical study to gain insights\ninto the Web3 ecosystem. We \ufb01rst selected the top 200 Web3 projects\nand performed open card sorting to investigate the categories of Web3\napplication, which comprises two main categories: Web3 infrastructure and\nWeb3 applications, each containing several subcategories. We introduced\neach subcategory and its representative project to provide a comprehensive\noverview. Then, we collected code-related and market-related data for the\n200 Web3 projects from GitHub and blockchain browsers. This information\nhelps developers better understand and navigate the Web3 landscape. In\naddition, we discussed the challenges facing the Web3 ecosystem at the system,\ndeveloper, and user levels, while also highlighting the opportunities it presents.\nOur \ufb01ndings empower researchers, developers, and other stakeholders to\ndeepen their understanding of and contribute more e\ufb00ectively to the evolving\nWeb3 ecosystem.\n8 Declarations\nCompeting Interests\nThe authors declared that they have no con\ufb02ict of interest.\nData Availability\nThe datasets generated during and/or analyzed during the current study are\navailable in the Github repository,\nhttps://github.com/popularWeb3projects/Web3-dataset.\nReferences\n(2010)\nWeb\n1.0.\nURL\nhttps://www.w3.org/2010/Talks/0119-next-web-plh/web10.html\n(2022) 0x. URL https://0x.org/\n(2022) Aave. URL https://aave.com/\n(2022) Axelar. URL https://axelar.network/\n(2022a) Axie In\ufb01nity. URL https://axieinfinity.com/\n(2022) Aztec. URL https://aztec.network/\n(2022) Blocery. URL https://blocery.io/\n(2022) Consensys. URL https://consensys.net/\n(2022) Creatordao. URL https://creatordao.com/\n(2022) doppel. URL https://www.doppel.com/\n23\n(2022) Dtravel. URL https://dtravel.com/\n(2022) Enjin. URL https://enjin.io/\n(2022) Erc-20 token standard. URL https://ethereum.org/en/developers/\ndocs/standards/tokens/erc-20/\n(2022) Filecoin. URL https://filecoin.io/\n(2022) fractional. URL https://fractional.art/\n(2022) Greenlabs. URL https://greenlabs.co.kr/\n(2022) Helium. URL https://www.helium.com/\n(2022) Infura. URL https://www.infura.io/\n(2022) Makerdao. URL https://makerdao.com/\n(2022) Metamask. URL https://metamask.io/\n(2022) Mirror. URL https://mirror.xyz/\n(2022) Near. URL https://near.org/\n(2022) Opensea. URL https://OpenSea.io\n(2022) Optimism. URL https://www.optimism.io/\n(2022) origyn. URL https://www.origyn.com/\n(2022) razor network. URL https://razor.network/\n(2022) Royal. URL https://royal.io/\n(2022) The sanbox. URL https://www.sandbox.game/\n(2022) Tokensets. URL https://www.tokensets.com/\n(2022) Tru\ufb04e. URL https://trufflesuite.com/\n(2022) Uniswap protocol. URL https://uniswap.org/\n(2022b) Web 2.0. URL https://en.wikipedia.org/w/index.php?title=\nWeb_2.0&oldid=1083050427\n(2022c)\nWeb3.\nURL\nhttps://en.wikipedia.org/w/index.php?title=\nWeb3&oldid=1083301005\n(2022) Web3 dataset. URL https://github.com/popularWeb3projects/\nWeb3-dataset\n(2023)\ndappradarIndustry\nOverview.\nURL\nhttps://dappradar.com/industry-overview\nAbudy MM, Wohl A (2018) Corporate bond trading on a limit order book\nexchange. Review of Finance 22(4):1413\u20131440\nBenet J (2014) Ipfs-content addressed, versioned, p2p \ufb01le system (draft 3).\narXiv preprint arXiv:14073561 pp 1\u201311\nBenet J, Dalrymple D, Greco N (2017) Proof of replication. Protocol Labs,\nJuly 27:20\nBeniiche\nA\n(2020)\nA\nstudy\nof\nblockchain\noracles.\narXiv\npreprint\narXiv:200407140\nBenisi NZ, Aminian M, Javadi B (2020) Blockchain-based decentralized\nstorage networks: A survey. Journal of Network and Computer Applications\n162:102656\nChauhan A, Malviya OP, Verma M, Mor TS (2018) Blockchain and scalability.\nIn: 2018 IEEE International Conference on Software Quality, Reliability and\nSecurity Companion (QRS-C), IEEE, pp 122\u2013128\nEl Faqir Y, Arroyo J, Hassan S (2020) An overview of decentralized\nautonomous organizations on the blockchain. In: Proceedings of the 16th\n24\ninternational symposium on open collaboration, pp 1\u20138\nGadekallu TR, Huynh-The T, Wang W, Yenduri G, Ranaweera P, Pham QV,\nda Costa DB, Liyanage M (2022) Blockchain for the metaverse: A review.\narXiv preprint arXiv:220309738\nLiu Z, Xiang Y, Shi J, Gao P, Wang H, Xiao X, Wen B, Li Q, Hu YC (2021)\nMake web3. 0 connected. IEEE transactions on dependable and secure\ncomputing 19(5):2965\u20132981\nMalamud S, Rostek M (2017) Decentralized exchange. American Economic\nReview 107(11):3320\u20133362\nMicali S, Rabin M, Vadhan S (1999) Veri\ufb01able random functions. In:\n40th annual symposium on foundations of computer science (cat. No.\n99CB37039), IEEE, pp 120\u2013130\nMonte GD, Pennino D, Pizzonia M (2020) Scaling blockchains without giving\nup decentralization and security: A solution to the blockchain scalability\ntrilemma. In: Proceedings of the 3rd Workshop on Cryptocurrencies and\nBlockchains for Distributed Systems, pp 71\u201376\nPetkus\nM\n(2019)\nWhy\nand\nhow\nzk-snark\nworks.\narXiv\npreprint\narXiv:190607221\nScha\ufb00ner T (2021) Scaling public blockchains. A comprehensive analysis of\noptimistic and zero-knowledge rollups University of Basel\nSheridan D, Harris J, Wear F, Cowell Jr J, Wong E, Yazdinejad A (2022) Web3\nchallenges and opportunities for the market. arXiv preprint arXiv:220902446\nSkidanov A, Polosukhin I (2019) Nightshade: Near protocol sharding design.\nURL: https://nearprotocol com/downloads/Nightshade pdf 39\nSpencer D (2009) Card sorting: Designing usable categories. Rosenfeld Media\nSun X, Yu FR, Zhang P, Sun Z, Xie W, Peng X (2021) A survey on zero-\nknowledge proof in blockchain. IEEE network 35(4):198\u2013205\nWang D, Wu S, Lin Z, Wu L, Yuan X, Zhou Y, Wang H, Ren K (2020)\nTowards understanding \ufb02ash loan and its applications in de\ufb01ecosystem.\narXiv preprint arXiv:201012252\nWang G, Shi ZJ, Nixon M, Han S (2019) Sok: Sharding on blockchain.\nIn: Proceedings of the 1st ACM Conference on Advances in Financial\nTechnologies, pp 41\u201361\nWang Q, Li R, Wang Q, Chen S (2021) Non-Fungible Token (NFT): Overview,\nEvaluation, Opportunities and Challenges. arXiv:210507447 [cs] URL http:\n//arxiv.org/abs/2105.07447\nWang Q, Li R, Wang Q, Chen S, Ryan M, Hardjono T (2022) Exploring web3\nfrom the view of blockchain. arXiv preprint arXiv:220608821\nXu J, Paruch K, Cousaert S, Feng Y (2021) Sok: Decentralized exchanges\n(dex) with automated market maker (amm) protocols. arXiv preprint\narXiv:210312732\nYu G, Wang X, Wang Q, Bi T, Dong Y, Liu RP, Georgalas N, Reeves A (2022)\nTowards web3 applications: Easing the access and transition. arXiv preprint\narXiv:221005903\n25\n",
    "2309.09972": "111\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\nMENG SHEN\u2217, Beijing Institute of Technology, China\nZHEHUI TAN, Beijing Institute of Technology, China\nDUSIT NIYATO, Nanyang Technological University, Singapore\nYUZHI LIU, Beijing Institute of Technology, China\nJIAWEN KANG, Guangdong University of Technology, China\nZEHUI XIONG, Singapore University of Technology and Design, Singapore\nLIEHUANG ZHU, Beijing Institute of Technology, China\nWEI WANG, Beijing Jiaotong University, China\nXUEMIN (SHERMAN) SHEN, University of Waterloo, Canada\nWeb 3.0 is the new generation of the Internet that is reconstructed with distributed technology, which focuses\non data ownership and value expression. Also, it operates under the principle that data and digital assets\nshould be owned and controlled by users rather than large corporations. In this survey, we explore the current\ndevelopment state of Web 3.0 and the application of AI Technology in Web 3.0. Through investigating the\nexisting applications and components of Web 3.0, we propose an architectural framework for Web 3.0 from\nthe perspective of ecological application scenarios. We outline and divide the ecology of Web 3.0 into four\nlayers. The main functions of each layer are data management, value circulation, ecological governance, and\napplication scenarios. Our investigation delves into the major challenges and issues present in each of these\nlayers. In this context, AI has shown its strong potential to solve existing problems of Web 3.0. We illustrate the\ncrucial role of AI in the foundation and growth of Web 3.0. We begin by providing an overview of AI, including\nmachine learning algorithms and deep learning techniques. Then, we thoroughly analyze the current state\nof AI technology applications in the four layers of Web 3.0 and offer some insights into its potential future\ndevelopment direction.\nAdditional Key Words and Phrases: Web 3.0; Artificial intelligence; Blockchain; Computing network\nACM Reference Format:\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang,\nand Xuemin (Sherman) Shen. 2023. Artificial Intelligence for Web 3.0: A Comprehensive Survey. J. ACM 37, 4,\nArticle 111 (August 2023), 35 pages. https://doi.org/XXXXXXX.XXXXXXX\nAuthors\u2019 addresses: Meng Shen, Beijing Institute of Technology, Beijing, 100081, China, shenmeng@bit.edu.cn; Zhehui\nTan, Beijing Institute of Technology, Beijing, 100081, China, zhehuitan@bit.edu.cn; Dusit Niyato, Nanyang Technological\nUniversity, Jurong West, 639798, Singapore, niyato@ntu.edu.sg; Yuzhi Liu, Beijing Institute of Technology, Beijing, 100081,\nChina, liuyuzhi@bit.edu.cn; Jiawen Kang, Guangdong University of Technology, Guangzhou, 510006, China, kavinkang@\ngdut.edu.cn; Zehui Xiong, Singapore University of Technology and Design, Tampines, 487372, Singapore, zxiong002@e.ntu.\nedu.sg; Liehuang Zhu, Beijing Institute of Technology, Beijing, 100081, China, liehuangz@bit.edu.cn; Wei Wang, Beijing\nJiaotong University, Beijing, 100044, China, wangwei1@bjtu.edu.cn; Xuemin (Sherman) Shen, University of Waterloo,\nWaterloo, Ontario, N2L 3G1, Canada, sshen@uwaterloo.ca.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\nthe full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\nprior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\u00a9 2023 Association for Computing Machinery.\n0004-5411/2023/8-ART111 $15.00\nhttps://doi.org/XXXXXXX.XXXXXXX\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\narXiv:2309.09972v1  [cs.AI]  17 Aug 2023\n111:2\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\n1\nINTRODUCTION\nIn recent years, the concept of Web 3.0 has emerged as a response to the issues facing the current\nInternet landscape. These issues include the concentration of benefits among a select few, monopo-\nlization of platform resources, and loss of personal privacy. This new wave of innovation seeks to\nrebuild the Internet using technologies such as blockchain, cryptography, and other decentralized\nsolutions. It aims to address the problem of data ownership and value expression on the Internet\nby utilizing distributed technology. This is expected to bring significant improvements to prospects\nin terms of technology, industry, and economy.\nThe concept of Web 3.0 was first proposed by Gavin Wood, co-founder of Ethereum in 2014.\nHe believes that Web 3.0 is the blockchain-based Internet and the goal of Web 3.0 is to reduce\nthe reliance on centralized institutions. With the enrichment of Web 3.0 concepts, Web 3.0 can\nreconstruct the contemporary Internet from two aspects. From the perspective of data ownership,\nWeb 3.0 is not only a readable and writable network, but also enables users to own their data and\nassets [1]. From the perspective of data management, Web 3.0 is a new economic system that is\njointly built and shared by users and builders [2].\nWeb 3.0 has seen significant growth and development, driven largely by the increasing interest\nin cryptocurrencies and blockchain technology. However, as the technology matures and evolves,\nit also faces several challenges to be addressed. Web 3.0 is currently facing major difficulties in\nterms of data supply, value circulation, and ecological governance.\n(1) In Web 3.0 scenario, data is diverse and plentiful, stored across a distributed network, making\nit more challenging to manage compared to traditional centralized databases.\n(2) In the value circulation system of Web 3.0, the user\u2019s identity system is complicated to use\nand is easily attacked by hackers. At the same time, the transaction efficiency and pricing\naccuracy of the circulation system needs to be further improved.\n(3) The Web 3.0 ecosystem is susceptible to various operational abnormalities, such as the spread\nof inappropriate content by users [3], leading to a deterioration of the ecosystem\u2019s overall\nquality. Considering the increased autonomy and anonymity of Web 3.0\u2019s users, it can be\ncostly and resource-intensive to detect and address.\nDriven by these problems, we look back at the establishment and development of Web 3.0. We\nthen give a hierarchical architecture of the Web 3.0 ecology and summarize the current challenges\nfaced by Web 3.0 in different layers. We find that the advancements in AI technology in recent\nyears have provided new and powerful solutions to various obstacles in the development of Web\n3.0. These solutions include utilizing AI for big data analysis [4], AI-generated content [5\u20137], and\ndetecting and classifying various forms of content such as text and video [8]. These AI-powered\ntechnologies can be applied across different aspects and stages of Web 3.0, improving the overall\nfunctionality and user experience.\nAlthough a comprehensive survey of Web 3.0 has not yet been conducted, there have been some\nreviews of some components and applications of Web 3.0. For example, some surveys investigate the\nmetaverse, an important application of Web 3.0 [9\u201311], focusing on its integration with blockchain\nand virtual reality. Other surveys focus on digital assets [12], an important component of Web 3.0,\nand mainly on the architecture, consensus mechanism, privacy and security of cryptocurrency.\nThere are also surveys of decentralized networks [13, 14] and decentralized identities [15]. Compared\nwith the articles published on Web 3.0, we systematically introduce the development history of\nWeb 3.0, the framework structure of Web 3.0 system, and the current application of AI in Web 3.0\necology. The main contributions of this investigation are summarized as follows:\n\u2022 To the best of our knowledge, we are the first to conduct a survey of the existing literature on\nthe use of AI in Web 3.0. Through our survey, we provide a comprehensive overview of the\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:3\nTable 1: The differences between other existing works and our survey\nSurvey Paper\nYear\nDescription\nWang et al. [9]\n2022\nDiscussing the security and privacy threats to the Metaverse and the state-of-the-art countermeasures.\nYang et al. [10]\n2022\nSurveying how Blockchain and Artificial Intelligence (AI) fuse with the Metaverse.\nHuynh-The et al. [11]\n2023\nExploring the role of AI in the foundation and development of the Metaverse.\nMukhopadhyay et al. [12]\n2016\nEvaluating the strengths, weaknesses, and possible threats to the incentive mechanism of each crypto currency.\nZarrin et al. [13]\n2020\nInvestigating two aspects in the decentralized Internet: consensus algorithms and other cutting-edge technology.\nYang et al. [14]\n2019\nIntroducing the blockchain-based Internet with decentralized processing and traceable trustworthiness.\nGilani et al. [15]\n2020\nProviding the identity proofing and authentication solutions for different self-sovereign Identity solutions.\nOur Survey\n2023\nProposing a hierarchical architecture of the Web 3.0 ecology from a significant amount of concrete research and\nproviding a comprehensive overview of the current state of AI in Web 3.0.\ncurrent state of AI in Web 3.0, including the types of AI algorithms that have been applied,\nthe results and outcomes achieved by different studies, and the key technical challenges and\nlimitations that have been encountered.\n\u2022 We abstract the architecture of Web 3.0 from a great amount of concrete AI research, which\npresents an overview from four aspects: data management, value circulation, application\nscenarios, and ecological governance. We provide a comprehensive overview of the current\nresearch and challenges of the Web 3.0 ecosystem.\n\u2022 We not only present an overview of the existing studies in the field of AI for Web 3.0 but also\nprovide further insights into the defects of existing studies, and discuss in detail the future\nresearch challenges and directions on AI for Web 3.0, which provides readers with possible\ndirections for developing innovative solutions.\nThe rest of this paper is organized as follows. We commence with the evolution of Web technology\nand the classification of AI used in Web 3.0 in Section 2. We present the architectural layers of the\nWeb 3.0 ecosystem we define and formulate a case to aid understanding in Section 3. In Section\n4-7, we respectively introduce the issues and existing AI solutions in the four layers of Web 3.0:\ninfrastructure, interface, management, and application. In Section 8, we introduce the technical\nchallenges faced by Web 3.0, and prospects for the future research direction of Web 3.0 technology.\nIn Section 9, we summarize the full literature.\n2\nBACKGROUND\nIn this section, we introduce the history of the World Wide Web. Since the World Wide Web was\ninvented in 1989, it has experienced three generations, namely Web 1.0, Web 2.0, and Web 3.0. We\nsummarize the development process and characteristics of these three generations and guide the\nlogic behind the development of the World Wide Web. Then, we investigated the classification of\nAI technology and focused on what might be used in Web 3.0.\n2.1\nThe Evolution of Web\nWeb 1.0. In 1989, Tim Berners Lee invented the World Wide Web at CERN in Switzerland, marking\nthe beginning of the era of the Internet as an application. He then, with his team, realized the first\nwebsite: http://info.cern.ch/ in the next year [16]. In the following years, the important components\nthat make up the web page were invented, including HTML [17], HTTP [18], Browser, etc. Web 1.0\nimplements the Internet application in the era of personal computers, but most users can only use\naccess and search functions to obtain information, rather than edit content.\nWeb 2.0. In 2014, the first Web 2.0 conference was hosted by O\u2019Reilly Media and MediaLive,\nat which the concept of web as platform was proposed [19]. In the same year, Mark Zuckerberg\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:4\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nfounded Facebook. In the following years, companies in different fields, including Amazon, and\nGoogle were established, which enabled users to publish, comment, like, and upload content on the\nnetwork. Web 2.0 realizes the network for users to edit content, making the network a huge social\ncircle covering the whole world. However, it has spawned electronic giants, such as Facebook, and\nGoogle, causing serious privacy problems.\nThe conception of Web 3.0. The conception of Web 3.0 is proposed to address the limitations\nof the current centralized web. To solve the problems of privacy leakage and monopoly of large\ncompanies, Tim Berners-Lee propose a system called Solid [20], which is considered the prototype\nof Web 3.0 now. It is a decentralized platform for social applications, which ensures that the user\u2019s\ndata is managed independently of the application accessing this data. Users store their data in\npods, and the application needs to comply with certain protocols for access. At the same time,\ndistributed authentication and access control mechanisms ensure data privacy. Users\u2019 data is no\nlonger fragmented across different platforms. They can freely migrate between different platforms\nand determine the access rights of services to their data.\nLater, Gavin Wood formalize the concept of Web 3.0, a system combining the World Wide Web\nwith distributed technology, like blockchains and smart contracts [21]. It is generally accepted that\nthe most important characteristic of Web 3.0 is decentralization [22]. In conclusion, we propose\nour definition of Web 3.0. It is the new generation of the Internet that is reconstructed with\ndistributed technology, which focuses on data ownership and value expression. And it operates\nunder the principle that data and digital assets should be owned and controlled by users rather\nthan large corporations. The key features of Web 3.0 include decentralized, blockchain-based,\nprivacy-protected, and AI-empowered.\n2.2\nThe Categorization of AI in Web 3.0\nThe rapid development of AI technology in recent years has brought new solutions to many\nchallenges encountered in the development of Web 3.0, such as Big Data analytics, AI-empowered\ncontent generation, and classification of video, text, and other content. The technologies can be used\nin various scenarios and links of Web 3.0, such as data management, value circulation, ecological\ngovernance, etc. We conduct a comprehensive survey of AI technology and focus on those with\npotential applications in Web 3.0. We evaluate the algorithms based on their model complexity.\nBased on this criterion, machine learning can be broadly categorized into two groups: traditional\nmachine learning techniques and deep learning techniques. The main distinction between the two\nis the use of cascaded neural network layers in the algorithm.\n1) Traditional machine learning: Traditional machine learning refers to the earlier methods and\nalgorithms of machine learning that are based on statistical and mathematical principles, including\nSupport Vector Machine(SVM), Decision Trees, K-Nearest Neighbors, and Naive Bayes. These\nmethods require fewer computational resources and are easier to interpret.\nSupport Vector Machine [23] works by finding the best boundaries called hyperplanes to separate\ndata into classes or predict output values. To handle non-linear relationships in the data, support\nvector machine uses kernel trick, which maps the input data into a higher dimensional space.\nCommon kernel functions used in SVMs include linear kernels, polynomial kernels, Gaussian\nkernels, and sigmoid kernels. For example, SVM can be used to improve the security of the Web 3.0\nidentity management system by detecting user behavior and identifying malicious users [24].\nNa\u00efve Bayes [25] is a statistical learning algorithm. It is based on Bayes\u2019 theorem, which provides\na way to calculate the probability of an event based on prior knowledge of the conditions likely to\nbe associated with the event. The algorithm assumes that the features of a given data point are\nindependent of each other. Naive Bayes can be used for data pricing [26].\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:5\nDecision tree [27] works by building a tree model of decisions and their potential consequences.\nThe tree consists of nodes representing tests on features and edges representing test results. The\nroot node represents the first decision, internal nodes represent subsequent decisions, and leaf\nnodes represent the final prediction. The path from the root node to the leaf nodes represents a\nsequence of decisions based on the input feature values. Decision tree can be used to predict the\nprice of digital assets [4].\nRandom Forest [28] is an ensemble learning algorithm that combines multiple decision trees to\nmake predictions for classification and regression tasks in machine learning. The algorithm trains\nmultiple decision trees on random subsets of the training data and combines their predictions\nthrough voting or averaging to produce a final prediction. Random forest algorithm can be used for\nnetwork behavior perception [29] in Web 3.0.\n2) Deep learning techniques: It is a subfield of machine learning that is inspired by the structure\nof the brain, specifically the neural networks. It involves training artificial neural networks, which\nare composed of layers of interconnected nodes or artificial neurons, on a large dataset. Each layer\nprocesses the input and passes it on to the next layer until the final output is produced. The layers\nbetween the input and output layers are known as the hidden layers.\nConvolutional neural network [30] is a specific type of deep learning. It uses convolutional layers\nto learn local features and pooling layers to reduce spatial resolution. Also, CNNs have a relatively\nsmall number of parameters, making them efficient for tasks with scarce labeled data. CNN has\na wide range of applications in Web 3.0, which can be used to transform the image style [31, 32],\nimprove the blockchain incentive mechanism [33], and detect bad content [3, 34, 35].\nRecurrent Neural Networks [36] is a type of neural network that specializes in processing sequential\ndata, such as time series, text, and speech by maintaining a hidden state that allows the network to\nlearn and maintain context from previous time steps. They are well-suited for tasks that require\nunderstanding the context of the input. There are also variants of RNNs such as LSTM and GRU\nthat have been developed to further improve the ability of RNNs to handle long-term dependencies.\nRNN is used in Web 3.0 to generate content [7], predict the price of encrypted assets [37, 38], and\ndetect unhealthy content [39].\nGraph Convolutional Network [40] is a deep learning architecture designed for graph-structured\ndata. In GCN, the nodes in the graph represent entities, and the edges represent the relationships\nbetween them. The core component of GCN is the graph convolution operation, which aggre-\ngates information from neighboring nodes to generate a new representation for the current node.\nGCN is widely used in the protection of privacy and security in Web 3.0, such as the transaction\nentity recognition [41], malicious transaction identification [42] and the perception of network\nbehavior [43].\n3\nARCHITECTURE OF WEB 3.0\nIn this section, we introduce a new Web 3.0 architecture from the perspective of application\nscenarios and ecosystems, as shown in Fig. 1. In the past, the framework of Web 3.0 was often from\na technical perspective, such as the Web 3.0 technology stack proposed by Gavin Wood [21]. We\nwill illustrate the rationale for dividing Web 3.0 into distinct layers and the function of each layer\nas well as the crucial role of AI within this context.\n3.1\nThe Hierarchical Architecture of Web 3.0\nAs illustrated in Fig. 1, Web 3.0 can be divided into four layers: infrastructure layer, interface\nlayer, management layer, and application layer. The infrastructure layer primarily handles data\nmanagement. The interface layer is responsible for mapping physical world data to the digital space.\nThe management layer governs the ecosystem of Web 3.0. And the application layer is where actual\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:6\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nFig. 1: The Hierarchical Architecture of Web 3.0\nuse cases for Web 3.0 are designed and implemented. In the following section, we will explain each\nlayer in detail.\nInfrastructure layer. It is responsible for collecting, storing, transmitting, and processing\ndata. With the adoption of Web 3.0 technologies, which emphasize decentralization and co-\ngovernance [33, 44\u201346], the sources of data have been greatly expanded, including the use of\nterminal devices from the Internet of Things and real-time feedback from users. This data is trans-\nmitted to edge devices or nodes for analysis and may be stored using an on-chain or combination\nof on-chain and off-chain methods to ensure the transparency and effectiveness of the data. In the\nwhole process, AI technology can be integrated into all aspects to optimize strategies, improve\nstorage computing efficiency, improve system security, and protect privacy.\nInterface layer. It serves as a connection between the physical world and the digital world,\ntransforming data collected from the infrastructure layer into valuable digital assets. This layer\nalso establishes a value circulation system to optimize the utilization of data and motivate user\nparticipation. The value of this data is determined by supply and demand, allowing users to benefit\nfrom their contributions. Unlike the Web 2.0 architecture, where private data is controlled by\ncentralized institutions, Web 3.0 grants individuals ownership of their data, with decentralized\nidentities responsible for protecting the privacy and access control. AI can assist in the decentral-\nization of identity systems [24, 47] and the creation of a more intelligent data market [48], while\nalso safeguarding the privacy of individuals [43, 49\u201351].\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:7\nManagement layer. It is responsible for the overall governance of the lower layers, including\nthe implementation of incentives that encourage user participation[52\u201355] and the review of\nuser-generated content [56]. In the case of a smart city, the management layer may correct or\nremove erroneous or outdated traffic information uploaded by users, and detect and defend against\nmalicious traffic attacks on the system. AI can also assist in identifying abnormal trading behavior\nand detecting false or inappropriate information.\nApplication layer. It is the application system built upon the previous three layers. As an\nexample, in the context of a smart city, this layer may include navigation apps that adjust routes\nin real time based on traffic conditions. Beyond the realm of smart cities, the application layer of\nWeb 3.0 has seen significant progress in finance [57\u201359], medicine [60, 61], Metaverse [62, 63], and\nhealthcare [64]. AI technology is also heavily integrated at this level, improving user experience,\nenhancing privacy protection, and increasing efficiency.\n3.2\nCase Study\nIn this section, we explore how a smart city project would function within the Web 3.0 scenario,\nproviding a deeper understanding of the architecture of Web 3.0 that we design. Smart city is a city\nthat uses technology and data to improve the quality of life for its citizens. One important function\nis using sensors and information technologies to monitor and optimize traffic flow. In the context\nof Web 3.0, This function will be implemented by the following steps.\nThe initial layer that plays a role is the infrastructure layer, which mainly deals with data\ncollection, analysis, storage and other functions. To achieve real-time navigation route adjustments,\nit is imperative to gather current road condition information as the first step. There are two methods\nof obtaining this information: the first involves edge device sensors, such as cameras and Unmanned\nAerial Vehicles (UAV) [65], while the second method acquiring traffic information from users and\ndrivers. After data is collected, it will be transmitted to computing nodes and the cloud for analysis.\nThe interface layer receives data from the infrastructure layer, and its major function is to add\nvalue to the raw data, ensuring that it can be utilized to its fullest potential at the most relevant\nlocations, while also incentivizing the providers of such data, thus keeping them engaged over an\nextended period of time [52]. Once these data are mapped to the Web 3.0 system, their ownership\nwill be secured by blockchain and data confirmation technologies. Subsequently, they will be priced\nand circulated in the digital asset market [48].\nThen management layer will come into play, and due to the permissionless nature of Web\n3.0, censorship of content will be crucial. The content review mechanism includes verifying the\ncredibility and timeliness of transaction information, while also identifying any illegal material [56],\nsuch as pornography and violence, that may be uploaded by users.\nFinally, the application layer is built on the above system. Based on the services and data provided\nby the lower layer, developers can realize a wide range of commercial applications. In the context\nof smart cities, there is navigation software that can adjust routes according to real-time traffic\nconditions and recommendation software that can provide local service (catering, entertainment,\netc.) information according to user preferences.\n4\nINFRASTRUCTURE LAYER\nThe infrastructure layer of Web 3.0 is primarily responsible for data processing. which is like the\nfoundation of a building. In Web 3.0, data is stored in a decentralized blockchain system and has\nvarious types, large quantities, and distributed storage, which is more difficult to manage than\ntraditional databases, as shown in Fig. 2. Compared with the traditional centralized system, the\nWeb 3.0 system has higher requirements for performance due to its transaction latency, and more\nevaluation indicators such as decentralization, scalability, and resource cost of blockchain-related\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:8\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nTable 2: Commmon abbreviations and explanations used in this paper\nAbbreviation\nExplanation\nAbbreviation\nExplanation\nAbbreviation\nExplanation\nADS\nAuthenticated Data Structure\nFCN\nFully Convolutional Neural Network\nNLP\nNatural Language Processing\nANN\nArtificial Neural Network\nFL\nFederated Learning\nPUL\nPositive and unlabeled learning\nAoI\nAge of Information\nGA\ngenetic algorithm\nQoS\nQuality of Service\nBI\nBayesian inference\nGAN\nGenerative Adversarial Networks\nRBFNN\nradial basis function neural network\nCLIP\nContrastive Language-Image Pre-Training\nGBDT\nGradient boosting decision trees\nRF\nRandom Forest\nCNN\nConvolutional Neural Network\nGCN\nGraph Convolutional Network\nRL\nReinforcement Learning\nCNNs\nCapsule Neural Network\nGNN\nGraph Neural Network\nRNN\nRecurrent Neural Network\nDAG\nDirected Acyclic Graph\nHAN\nHierarchical Attention Network\nSL\nSupervised Learning\nDBN\nDeep Belief Network\nHMM\nHidden Markov Model\nSNN\nSiamese neural network\nDCNN\nDeep Convolutional Neural Network\nIoT\nInternet of Things\nSVD\nSingular Value Decomposition\nDDPG\nDepth Deterministic Policy Gradient\nLBF\nLearning-based Bloom Filter\nSVM\nSupport Vector Machine\nDL\nDeep Learning\nLSTM\nLong short-term memory\nTPS\nTransactions per Second\nDNN\nDeep Neural Network\nMBP\nMulti-armed bandit problem\nUAV\nUnmanned Aerial Vehicles\nDQN\nDeep Q-Network\nMC\nMarkov Chain\nVGGNet\nVisual Geometry Group Network\nDRFNet\nDilated Residual Feature Net\nMDP\nMarkov Decision Process\nWCN\nWireless Communication Network\nDRL\nDeep Reinforcement Learning\nMEC\nMoblie Edge Computing\nWSN\nWireless Sensor Network\noperations which require consideration. Therefore, a specific data management solution for Web\n3.0 scenarios is needed.\n4.1\nData Collection\nThe data volume in Web 3.0 system is huge and requires many nodes and validation, which brings\nchallenges for related studies. In Web 3.0, Internet of Things (IoT) devices play a crucial role as they\nprovide reliable data support for web applications and services by integrating digital information\nbetween things. Therefore, Web 3.0 applications often require the support of Unmanned Aerial\nVehicles (UAV) [66], the Internet of vehicles[67], etc., in which Artificial Intelligence (AI) optimizes\nthe behavior of peers to maximize the overall system performance. At the same time, for Web 3.0\nproblems such as scalability and edge intelligence, the policies of the system or each node can also\nbe optimized by AI.\nThe data collected by Web 3.0 system has the characteristics of large quantity and diversity.\nCollection strategies should be adopted in the system to avoid unreasonable allocation of resources.\nAI can be used to optimize the data collection strategy, with deep reinforcement learning (DRL)\nbeing a common approach. Liu et al. [65] propose an efficient data collection and secure sharing\nscheme based on blockchain. A method based on distributed DRL is adapted to allow each mobile\nterminal to move to a certain location for data acquisition, maximizing the collecting rate. And\naccording to the article, by introducing AI, energy consumption decreases from 64% to 78%.\nThe convergence of IoT and Web 3.0 provides security and reliability for data collection. IoT in\nWeb 3.0 is typically blockchain-based, and there are extra factors to be considered (e.g., blockchain-\nrelated operations). The authors in [68] propose an adaptive linear prediction algorithm. In this\nwork, the sensed value to be uploaded is predicted and by which the actual value is replaced, thus\nreducing the transmission overhead. After that, Tang et al. [66] use reinforcement learning to judge\nthe optimal solution of each node under the PoS consensus mechanism. Different from traditional\nIoT, the optimal solution should be determined by taking the equity mechanism of blockchain into\nconsideration, to achieve the global optimal solution under this mechanism.\n4.2\nData Storage\nData storage in Web 3.0 is decentralized and based on blockchain. Common blockchain systems\nhave full nodes, which store the full blockchain, and light nodes, which store only the block\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:9\nSensing\nCommunication \nNetwork\nOn-chain storage\nOff-chain storage\nComputation \nresources\nData Storage\nData Transmission\nData Computation\nData Collection\nBlockchain\nBackup nodes\nUser nodes\nFig. 2: A common data flow process in the infrastructure layer of Web 3.0\nTable 3: Research of Infrastructure Layer Based on AI\nSubjects\nRefs\nAI Methods\nSpecific Scenarios\nWeb 3.0 Tasks\nData Collection\n[65]\nDRL\nIndustrial IoT\nOptimize collecting strategies using distributed DRL in blockchain systems\n[68]\nLinear Model\nUAV-assisted IoT\nDevelop prediction algorithm to save the overhead of transaction\n[66]\nDRL\nUAV-assisted IoT\nDetermine the optimal strategy of edge nodes under the PoS consensus\nData Storage\n[69]\nDRL\nIoT\nDetermine the sharding strategy to adjust the system parameters\n[70]\nDRL\nIoT\nIncorporate the degree of decentralization for DRL training\n[71]\nGenetic Algorithm\nSide chain\nDetermine the policy of generating the side chain\n[72]\nFL\nIoT\nEnable edge intelligence for decentralized systems\nData Transmission\n[73]\nMulti-agent RL\nWCN\nDetermine the distributed data transport policy\n[74]\nDDQN\nIoT\nDerive an optimal transaction transport strategy for secondary users\n[75]\nFNCF\nIoT\nPredict reliable nodes for data transmission in decentralized systems\nData Computation\n[76]\nDRL\nCollaborative computing\nDetermine blockchain sharding policy for the allocation of computing resources\n[77]\nDRL\nMEC\nCreate incentives using ML techniques for task offloading\n[78]\nSVM,DNN\nVerifiable searching\nConstruct high-performanced ADS for verifiable query in blockchain\n[79]\nFL\nDecentralized FL\nOptimize the resource allocation between training and mining\nheaders. In order to improve the scalability of Web 3.0 storage system, recent studies have proposed\noperation modes for Web 3.0 such as collaborative storage and blockchain sharding, in which AI\ncan participate in the formulation of storage strategies. Due to the high requirements of Web 3.0 for\nsystem throughput, the storage strategy has become an important aspect, such as block generation\nstrategy, sharding strategy, chain update strategy, etc, which provide solutions to the scalability\nproblem, as shown in Fig. 3.\nDetermining the generation strategy of storage structure. According to the blockchain\ntrilemma, it is impossible for any blockchain system to take into account the following three points:\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:10\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nscalability, decentralization and security. So the problem of optimization is an issue worth studying.\nThe authors in [69] find the sharding strategy of the blockchain and the optimal parameters of the\nsystem according to the network state through Deep Reinforcement Learning (DRL), and adaptively\noptimize the system throughput and security level. Also for formulating block generation policies,\nBai et al. [70] solve the problem of quantification of the degree of decentralization of blockchain,\nproviding conditions for system optimization. On this basis, a system optimization model based on\nDRL is proposed to dynamically adjust the system parameters.\nAdditionally, side chain is also a common solution for scalability issues and AI can help optimize\nthe construction and update of the side chain. For example, Vairagade et al. [71] use the mixed\ndelegation practical Byzantine fault-tolerant-delegated proof of equity to update the side chain,\nand the continuous network information analysis is used to improve the Quality of Service (QoS).\nUsing the modified genetic algorithm, this work optimizes the construction of side chain and solves\nthe problem to a certain extent that assets can be stolen by malicious nodes.\nFig. 3: The Role of AI in Solving the Scalability Problem\nDeveloping the edge storage strategies. Recent research has proposed the concept of Web\n3.0 collaborative storage, in which nodes with more resources can offload part of their data to\nnodes with fewer resources to collaboratively use their storage resources. The data offloading\ntechnology in edge computing provides an idea for this scenario, and the technology can be\ntransferred to this scenario. For example, Wang et al. [80] propose a task offloading method based\non meta-reinforcement learning, which can quickly adapt to the new environment of a small\nnumber of gradient updates and samples. Meanwhile, mobile applications are modeled as Directed\nAcyclic Graphs (DAG) based on dependency. The offloading strategy is implemented by the custom\nsequence-to-sequence (seq2seq) neural network.\nAs a common infrastructure for Web 3.0, IoT systems need to cache files to edge nodes to meet\nthe requirements of large throughput. Cui et al. [72] propose a system combining IoT devices, edge\nnodes, and blockchain. They design an algorithm that applies the federated learning compression\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:11\nalgorithm to the content cache to predict cached files. Each edge node uses local data to train a\nmodel, predicting popular files and improving the cache hit ratio.\nAs the explosion of on-chain recorded contents and the fast-growing number of users cause\nincreasingly unaffordable resource consumption in computing and storage in Web 3.0, Lin et al. [81]\npropose a unified blockchain-semantic ecosystems framework, which can convey precisely the\ndesired meanings without consuming many resources. To achieve this, the framework utilizes\ndynamic sharding mechanisms to classify the same semantic demands. The dynamic sharding\nmechanism used in the proposed framework is adaptive and based on deep reinforcement learning\n(DRL), which can adjust the number of shards and their sizes based on the current workload and\nsemantic demand patterns. By doing so, the framework can improve interaction efficiency given\nvaried semantic demands.\n4.3\nData Transmission\nWeb 3.0 network is a peer-to-peer structure, which is decentralized that relies on user groups to\nexchange information. For data transmission in the network structure of Web 3.0, AI can help solve\nthe problem of path optimization of data transmission and formulate transmission strategies.\nDeveloping the transmission strategy. AI can be used to determine the transmission strat-\negy optimization model, which helps design routing algorithms or identify the traffic changes\nin the network environment to dynamically adjust the data transmission volume. IoT requires\nbetter communication networks for data transfer between heterogeneous devices and an optimally\nWireless Sensor Network (WSN)[82]. In Web 3.0 system, edge nodes tend to use distributed data\ntransmission strategy [83]. Collin et al. [73] study transmission control in distributed wireless\ncommunication networks from the perspective of multi-agent reinforcement learning. Each node\nacts as an independent reinforcement learning agent without knowledge of actions taken by other\nagents. Considering the special uncertainty in Web 3.0 scenario, Luong et al. [74] use blockchain\nand mining pools to support IoT services based on cognitive radio networks. A deep reinforcement\nlearning algorithm is proposed to derive the optimal transaction transport strategy for secondary\nusers. Also, the Double Deep Q Network (DDQN) is used, which allows secondary users to learn\nthe optimal strategy.\nEnhancing the security of data transmission. From the view of data transmission, data\navailability is an important aspect. Typically, the edge devices need to connect to a reliable Web 3.0\nnode for efficient data synchronization as they complete data collection. Therefore, the reliability\nprediction is needed, in which AI can be used. For instance, Zheng et al. [84] develop a framework\nusing ML methods to predict reliable peers in blockchain systems. Then, considering the privacy\nissues, Xu et al. [75] propose a personalized reliability prediction model for privacy protection\nthrough Federated Learning Neural Collaborative Filtering (FNCF) in the Internet of Things. This\nmethod allows users to protect user privacy without passing data to third parties and provides\nusers with personalized predictions.\n4.4\nData Computation\nWeb 3.0 uses distributed computing, eliminating the need for a central authority to manage and\nallocate resources. Resources are aggregated and optimized by the network itself, thus improving\nthe efficiency and cost-effectiveness of resource use. Web 3.0 obtains computing capability by\nconnecting with cloud servers, which also causes a series of challenges, such as system scalability,\nefficiency of computing resource integration, and privacy issues of user data. Web 3.0 data computing\ncovers a wide range of fields, including common computing scenarios like FL, migration learning,\ncomputing resource allocation, and related operations on the database, such as data retrieval.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:12\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nML is a common data computing scenario in Web 3.0. In Web 3.0 system, distributed ML is a\nmore common mode, which solves the problem that traditional centralized FL is susceptible to\nsingle point of failure and external attacks. Lu et al. [85] propose a distributed federated learning\nframework that considers resource consumption, adopting DRL-based algorithms to optimize\nthe solution. After that, aiming at the problem that previous work does not consider the mining\noverhead, Li et al. [79] model the time of training and mining in the blockchain, and propose an\noptimized scheme for ML computing resource allocation.\nBlockchain sharding is the solution to the scalability problem. However, the current throughput\nof sharded blockchains remains limited in terms of a high proportion of Cross-Shard Transactions\n(CSTs). Yang et al. [76] propose a cluster-based sharding strategy for collaborative computing of the\nIoT, in which the sharding is based on the user grouping of K-means clustering and the allocation\nof consensus nodes. Deep Reinforcement Learning (DRL) is combined to train the adjustment of\nconsensus parameters to form the Markov Decision Process (MDP).\nAs another common scenario of data computation in decentralized systems, Collaborative Edge\nComputing (CEC) transfers tasks from busy edge servers to idle servers. Yet different MEC service\nproviders have no incentive to help others. He et al. [77] propose a collaborative mechanism\nwhereby idle computing systems can obtain additional profits by sharing idle computing resources.\nThey describe the social welfare maximization problem as a Markov Decision Process (MDP) and\nbreak it down into the allocation and execution of unloading tasks.\nVerifiability is the key advantage of Web 3.0 from the point of data retrieval. In the Web 3.0\nverifiable query scenario, users need to verify the correctness and completeness of query results. To\nensure the completeness of boolean queries, bloom filter may be required as a tool for constructing\nproof of the nonexistence of data elements. Dai et al. [78] propose a learning-based Bloom Filter\n(LBF), in which different machine learning models are used to construct multiple LBF, and the LBF\nwith the lowest false positive rate is selected.\n4.5\nSummary and Lessons Learned\nThe problems in the infrastructure layer can be summarized in two points, namely the scalability\nproblem and the security problem. In the scalability problem the main role of AI is optimization, with\nRL being a common approach. In the security problem, the main role of AI is detection and prediction.\nAI technology can make Web 3.0 system intelligent, and significantly improve the efficiency of\nWeb 3.0 data management in various scenarios. We have summarized the references mentioned in\nthis chapter in Table 3. However, despite the work that have been done, the scalability problem and\nsecurity challenges still exist in Web 3.0, which are the inherent challenges of decentralization. The\ncurrent research does not completely solve these problems, and further optimization is needed.\n5\nINTERFACE LAYER\nThe second layer of Web 3.0 is the interface layer, which serves as a bridge between the physical\nand digital worlds, as shown in Fig. 4. This layer consists of two components: digital identity and\ndigital assets. In Web 2.0, each person\u2019s digital identity on different platforms is fragmented and\ninteroperable. At the same time, users do not have their own identities and affiliated data assets,\nwhich are monopolized by large companies. In order to solve these problems, Web 3.0 adopts a\ndecentralized identity scheme, which ensures the user\u2019s ownership of their identity and data by\nstoring identities on a distributed system (such as blockchain). Digital assets refer to valuable goods\nin the virtual world, including data generated by user behavior, property rights and securities that\nusers map from the physical world to the digital world. The introduction of digital assets means\nthat an endogenous new equity trading market has been established in Web 3.0. This platform\nprovides users with a value circulation system for creating, pricing, trading and consuming digital\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:13\nGenerating Methods\nPhysical World\nMo\nand\nAss\ndat\nPhysical world\nIdentity:\nbiometrics\nbehavior\nPhysical assets:\nintellectual property \nreal estates\nstock certificate\ncryptocurrency\nData assets:\nbehavioral data\nidentity data\nGenerating methods\nDigital twin\nAIGC\nText\nencoder\nImage\nencoder\nDigital world\nPricing\nTransaction\nMaintenance\ncleaning\nprocessing\nrepresenting\nML\nMetric \nmatrix\nFig. 4: A common mapping model from the physical world to the digital world in the interface layer\nassets. Through this value circulation system, digital assets can be utilized to their fullest potential\nby the people who need them most, and the providers can also obtain corresponding value returns.\nAs a result, This digital property economy will completely change the development mode of the\ndigital economy.\n5.1\nDigital ID\nDigital identity allows individuals to verify their identity and access online services in the digital\nenvironment. It is the mapping of human\u2019s real identity in the physical world to the virtual world.\nThe decentralized identity scheme is adopted in Web 3.0. At present, there are mainly two ways to\nrealize decentralized identity: W3C DID and Ethereum NFT. On the one hand, the World Wide Web\nConsortium (W3C) has developed a set of decentralized identifier (DID) standards and protocols\nfor creating, managing, and using DIDs [86]. It includes guidelines for creating and managing\nDIDs, and rules for using DIDs to represent and verify identity information in a decentralized\nmanner. It can be used not only for people, but also for anything, including cars, machines, and\neven algorithms. On the other hand, NFT can also be used as an expression of digital identity on the\nchain. Vitalik [87] demonstrate how to use the soul binding token (SBT) to code the trusted network\nin the economy and establish the reputation. These tokens represent commitments, vouchers, and\naffiliations of individuals or entities and are non-transferable.\nAlthough the decentralized identity system has a bright future, it is currently facing challenges\nin identity authentication. One problem is that the system may be very complex for users and\nneed to manage complex private keys, which may be stolen or lost. However, artificial intelligence\n(AI) technology can help solve these challenges by assisting with biometric authentication and\nbehavioral authentication. By using AI in these areas, the threshold of using a decentralized identity\nsystem can be lowered, and the risk of key loss and identity theft can be reduced.\nBiometrics authentication is less prone to forgetfulness compared to knowledge-based authenti-\ncation and is difficult to lose compared to token-based authentication [88]. Fingerprint recognition\nis commonly used in practice, with one typical example being the work of Svobodaet al. They use\ngenerative convolutional networks to denoise visible details and predict missing parts of ridge\npatterns. Iris recognition is generally considered to be a secure method of biometric identification\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:14\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nbecause the iris is an internal body part that is protected by the eyelid. Wang et al. [89] implement\nthe use of dilated convolutional kernels and residual learning in their deep learning framework. This\nmethod not only improves the accuracy in iris matching but also simplifies the network structure.\nHowever, biometric authentication has been criticized because it is vulnerable to attacks that\nhappen after the initial authentication, while behavior recognition can provide continuous recogni-\ntion. Screen touch gestures are a typical way to be used in behavior recognition. Debard et al. [90]\npropose a method that utilizes deep neural networks features a dynamic sampling and temporal\nnormalization component. Their approach can be adapted to different gestures, user styles and\nhardware variations. Mahbub et al. [47] innovatively uses the user\u2019s habit of using the application\nto implement identification. They collect data from participants using smartphones, including\ninformation on device location, install, remove, or update applications, and the currently running\nforeground application, to implement identity authentication.\nSome methods have been used in some virtual systems to achieve accurate identification and\naccess control in the virtual world. Bader et al. [91] use a combination of 3D tools and the Unreal\nEngine, a comprehensive collection of tools for creating 3D games and virtual spaces, to create\na virtual world. To control access to this virtual world, they developed a centralized biometric\nauthentication module using fingerprint technology. However, this method can not match the real\nidentity with the virtual identity. Yampolskiy et al. [24] propose a set of algorithms for accurately\nverifying and recognizing avatar faces for use in authenticating avatars within virtual worlds and\nfor tracking a person between the real and virtual worlds in inter-reality scenarios.\n5.2\nDigital Asset\nWeb 3.0 is a new generation of the Internet that focuses on the circulation of value. The digital asset\nis its core object. Web 3.0 uses algorithms to create and distribute these assets, enabling the flow of\nvalue at a minimal cost. By utilizing blockchain technology and smart contracts, Web 3.0 allows\nusers to create, own, and trade digital property rights on the Internet and gives users personal data\nownership and the right to participate in the governance of Internet platforms and applications.\nThere are two main types of digital assets in Web 3.0, one is the assets owned or controlled by\nindividuals and enterprises in the form of electronic data, including digital intellectual property\nrights, emerging cryptocurrencies, and real-world physical assets mapped to digital assets like cars,\nreal estate, and lands. The second category is data assets, which are mainly a series of behavioral\ndata generated by the operation of users in the digital world. It can directly or indirectly create\neconomic and social benefits. Web 3.0 provides a value circulation system to help digital assets\ncirculate freely and maximize their value where they are most needed. We divide the entire life\ncycle of digital assets into two stages, namely the generation of digital assets and the transaction\ncirculation of digital assets. AI technologies all play a huge role throughout the lifecycle of digital\nassets. Each of these will be described below.\nThe generation of digital assets. The generation of digital assets includes the mapping from\nthe physical world to the virtual space and the generation of native virtual assets. Two technologies\nused for this process are Digital Twin and AIGC. Digital twin technology can be used in Web 3.0 to\nbuild smart cities, virtual avatars, and virtual world infrastructure [99]. AI technology can help\nimprove the efficiency and accuracy of digital twins. At present, the original digital assets are\nmainly digital collections and NFT, and the forms are pictures, texts, music, etc. The traditional\ngeneration method is costly and inefficient. AIGC (AI Generated Content) can help creators to try\nout the inspirational scheme more efficiently and directly in the early stage, and it saves manpower\nto complete the details in the later stage.\nDigital twin is a method of generating digital assets, which refers to mapping objects in the\nphysical world to the digital world. Digital twin can help build users\u2019 digital avatars in the virtual\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:15\nTable 4: Research of Digital Asset Based on AI\nSubject\nRef.\nAI Methods\nSpecific Scenarios\nWeb 3.0 Task\nGenerate digital assets\nthrough digital twin\n[92]\nCNN\nDigital avatar\nGenerating High-Fidelity 3D Avatar from a Single Image\n[93]\nDNN\nDigital city\nTransforming 3D spatial data and city models to a virtual world\n[94]\nSVD DNN\nDigital avatar\nFormalize personality as digital twin models by observing users\u2019 posting content\nGenerate digital assets\nthrough AIGC\n[31]\nCNN\nStyle transfer\nProduce a rather psychedelic and hallucinatory stylistic effect\n[32]\nCNN\nRendering the semantic content of an image in different styles\n[95]\nGAN\nGenerate content\nStochastic variation in the generated images\n[96]\nGAN\nGgenerate images from text descriptions\n[5]\nCLIP\nMaximize the similarity between real image-text pairs\n[6]\nVAE\ngenerate texts with better discourse structure and narrative flow\n[7]\nLSTM\nSolve the gradient disappearance and gradient explosion in text generation\nThe Circulation of\nDigital Assets\n[97]\nMBP\nData Pricing\nPrice of privacy in Personal data market\n[26]\nBI\nPricing when few data points are available\n[98]\nMBP\nDecide on prices with incomplete demand information\n[48]\nDNN\nTransaction Matching\nA market mechanism to price training data and match buyers to sellers\n[37]\nLSTM\nAssets Pricing\nHigh-performance model Prediction in the case of insufficient data samples\n[4]\nGBDT\nComparison of trading strategies based on different neural network methods\n[38]\nLSTM\nPrice prediction using user behavior data\nFig. 5: The method proposed in [92]. During training, a shape regression neural network is used on\nphoto-realistic synthetic facial images. During testing, a low polygon count shape model with a UV\ndiffuse map generated from the projected texture.\nworld. Wang et al. [92] develope a method for creating high-quality 3D face avatars with detailed\ntexture maps from a single 2D image. To create more lifelike and engaging digital avatars, we\nshould focus on not just physical characteristics, but also on developing unique personalities and\npreferences. Sun et al. [94] propose a method for creating digital twin models of personalities by\nanalyzing a user\u2019s posting content and liking behavior. Digital twins enable the creation of a virtual\nreplica of real-world cities. Schrotter et al. [93] develop a digital twin of the city of Zurich and create\na virtual representation of the city by converting 3D spatial data and city models, such as buildings,\nbridges, and vegetation, into a virtual environment. They use machine learning techniques to\npredict the urban climate of the city based on current weather and air quality data.\nAIGC is another method of generating digital assets. It can be utilized as a tool for creating\nvariations of images by altering their style. The first approach to receive significant attention in this\nfield is DeepDream [31], a pioneering method developed by Mordvintsev. It can create a distinctive,\npsychedelic visual style, leading to its use as a form of digital art. The separation between content\nand style is one of the most iconic milestones in the field of style transfer. Gatys et al. [32] first\npropose this idea. Their algorithm can manipulate natural images by separating and recombining\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:16\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\ntheir content and style. With this algorithm, users can generate new, high-quality images that\nincorporate the content of any photograph with the style of various famous artworks.\nOne of the most significant technological advancements driving the current AI art movement is\nthe use of Generative Adversarial Networks (GANs). The use of GANs has resulted in the generation\nof realistic, vivid images for various types of content, such as StyleGAN [95] and BigGAN [100].\nMost GAN models will only learn how to generate images that look like art that already exists, and\nin a similar way to the NST method, this will not produce anything truly artistic or novel.\nHowever, significant advancements have been made in the field of image generation from\ntext recently. Radford et al. [5] introduce the CLIP model, which is a pre-trained model that has\nbeen trained on a large number of image-text pairs from the Internet using contrastive learning.\nThis means that it maximizes the similarity between real image-text pairs and minimizes the\nsimilarity between mispairs. In January 2021, based on the CLIP model, DALL-E [96] is proposed by\nOpenAI, which is a 12 billion parameter neural network-based image generation system developed\nby OpenAI. It is trained on a dataset of text-image pairs and can generate images from textual\ndescriptions. DALL-E can generate a wide range of images, from photorealistic to highly stylized,\nand can even generate images of objects and scenes that do not exist in the real world.\nAI technology has also made breakthroughs in other forms of content generation in recent\nyears, such as natural language generation(NLG). With the rapid development of the deep learning\nneural network, the current NLG models are mainly based on deep learning neural networks and\nutilize a vast corpus of human-written text. Graves et al. [101] use recursive neural networks.\nHowever, RNN has the problem of gradient explosion and gradient disappearance. To overcome\nthese challenges, Pavade et al. [7] propose a text generation model based on LSTM. Another option\nis GRU, which is another extension of the standard RNN and is simpler than LSTM. Many deep\ngeneration architectures use GRU to generate text [102]. After that, the wide application of encoder-\ndecoder architecture opened a new chapter. Although the sequence-to-sequence model is originally\ndeveloped for machine translation, it soon proved that it could improve the performance of NLG\ntasks. Bowman et al. [103] propose an attempt at the VAE (Variational AutoEncoder) text generation\nmodel. They use recurrent neural networks to capture the general characteristics of sentences in\ncontinuous variables, such as theme and style. Later, Dathathri et al. [6] used VAE to learn and\ngenerate texts with better discourse structure and narrative flow.\nRecently, ChatGPT [104] has achieved great success in large-scale natural language processing\nmodels, which is a typical application of Pretrained Foundation Models (PFMs). ChatGPT is fine-\ntuned by the Generation Pre-training Transformer model GPT-3.5. It applies convolution and\nrecursion modules to feature extraction based on PFMs and uses autoregressive paradigms to\ntrain on large data sets mixed with text and code. It also innovatively combines reinforcement\nlearning from human feedback (RLHF). Due to its exceptional performance, ChatGPT has become a\nmilestone in Natural Language Generation (NLG) and moves towards artificial general intelligence.\nThe pricing of digital assets. The second stage of the life cycle of digital assets involves the\npricing and exchange of these assets. AI technology is being used to create sophisticated and\naccurate models of digital asset prices and develop algorithms that match buyers and sellers. The\nincreasing value of personal data in the era of big data has brought about a significant conflict\nbetween the exploitation of this data and the protection of individual privacy. One potential solution\nto this issue is the development of a personal data market, but determining the appropriate price for\nan individual\u2019s privacy remains a challenging problem. Bauer et al. [26] suggest that data pricing can\nbe effectively determined using a combination of kernel regression and Bayesian inference, along\nwith a confidence interval estimation algorithm based on the Bootstrap method. This approach is\nsuitable for use with sparse and noisy data. However, this method is not suitable for the scenario of\nrapid demand change and high price sensitivity.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:17\nIn a price-sensitive scenario, Xu et al. [97] propose another method that data pricing can be\napproached as a reinforcement learning problem for multi-armed bandit machines. However, this\nmethod faces a unique challenge with incomplete demand information. To solve this problem, Misra\net al. [98] propose a dynamic price experimentation policy based on the extension of multiarmed\nbandit algorithms with microeconomic choice theory. The proposed approach uses a scalable,\ndistribution-free algorithm to solve the resulting multiarmed bandit problem. Since the data is\nfreely replicable, the current conventional market model is not feasible for data transactions.\nAgarwal et al. [48] propose a new data marketplace for efficiently buying and selling training data\nfor machine learning tasks. They make two technical contributions to this marketplace: a new\nconcept of fairness for cooperative games involving easily replicable goods, and a mechanism for\nauctioning combinatorial goods that is truthful and regret-free, using Myerson\u2019s payment function\nand the Multiplicative Weights Algorithm.\nWhen it comes to pricing narrowly defined assets in the Web 3.0 world, there is a lot of relevant\nAI-based research. Zhao et al. [37] present a deep learning framework based on Long Short-term\nMemory Networks (LSTM) to predict short-term price movements of all cryptocurrencies. While the\nmodels presented in this study can accurately predict the movement of Bitcoin prices, they do not\nprovide information on the extent of the price movement. To evaluate the performance of different\nexisting neural network-based trading strategies, Alessandretti et al. [4] examine the effectiveness\nof three models in predicting daily cryptocurrency prices for more than 1000 currencies. Two\nmodels employed gradient-boosting decision trees, while the third utilized long short-term memory\n(LSTM) recurrent neural networks. The results revealed that all three models outperformed a\nbaseline model using simple moving averages, with the LSTM model consistently yielding the\nhighest return on investment.\nHowever, those cryptocurrency price prediction methods rely on the use of past price indexes\nto forecast future prices and do not take into account the volatile behavior of network entities\nthat may indirectly impact the price. Saad et al. [38] explore features in the Bitcoin and Ethereum\nnetworks that contribute to price increases. They analyze user and network activity that has a\nsignificant impact on the prices of these cryptocurrencies and use machine learning methods to\nbuild models that predict prices.\n5.3\nSummary and Lessons Learned\nIn subsubsection entitled \"The generation of digital assets.\", we introduce papers mainly including\nsome milestones in the field of generative AI and practical applications of digital twins (DT) in\ncreating digital counterparts of physical objects. While many scholars have described Web 2.0 as\na network of user-generated content (UGC), we consider Web 3.0 as a network of both UGC and\nAI-generated content (AIGC). Web 3.0 is not only a mapping of the real world but also needs a\nwealth of background information, where some approaches [96, 104] can play an important role.\nThis is how the two methods DT and AIGC. DT is responsible for displaying the mapping of the\nreal world, and AIGC is responsible for expanding the information in a broad sense.\nWeb 3.0 is also a value Internet where users can create, trade and consume digital assets in\nWeb 3.0. In the first subsubsection, we focuse on the generation of digital assets. In the second\nsubsubsection, seven related papers are introduced, which cover the pricing of data [26, 97, 98], the\ntrading mechanism of data market [48], and the pricing and trading of encrypted assets [4, 38, 105].\nThe objective of presenting these papers is essentially to explore one question how to establish an\nefficient value circulation system to maximize the use of data, assets, and other means of production.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:18\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nTable 5: Research of Incentive Mechanism on AI\nSubjects\nRefs.\nAI Methods\nScenario-oriented\nWeb 3.0 Tasks\nBlockchain\nConsensus\nMechanism\n[33]\nCNN\nBlockchain\nAn AI-based super nodes selection algorithm in blockchain networks\n[45]\nDL\nBlockchain\nConsensus Mechanism Based on Machine Learning Competitions\n[46]\nSL\nBlockchain-based IoT networks\nAn Outlier-Aware Consensus Protocol\n[106]\nFL\nSustainable Blockchains\nA Platform-Free Proof of FL Consensus Mechanism\nFederated\nLearning\n[107]\nDRL and GNN\nWireless Federated Learning\nToward an Automated Auction Framework for Wireless FL Services Market\n[108]\nDRL\nEdge ML\nAn Incentive Mechanism Design based DRL for Efficient Edge Learning\n[109]\nDRL\n/\nA Learning-Based Incentive Mechanism for Federated Learning\n[110]\nClustering\nBFL\nA flexible and Incentive Redesign for BFL\n6\nMANAGEMENT LAYER\nThe management layer is mainly composed of the services that maintain the Web 3.0 ecosystem,\nincluding incentive mechanisms, content management, and situational awareness. The users and\ninfrastructure in Web 3.0 ecosystem generate vast amounts of data during their daily operations,\nand monitoring and analyzing this data is crucial to maintaining the Web 3.0 ecosystem. In this\nprocess, AI can improve the efficiency of data analysis and provide timely and positive feedback to\nthe community when anomalies occur in the ecosystem. In the following, a brief overview of the\nAI technologies that support the management of the Web 3.0 ecosystem is given.\n6.1\nIncentive Mechanism\nThe Web 3.0 ecosystem needs to encourage users to participate in community affairs, such as\nencouraging users to participate in community governance, community decision-making, encour-\naging blockchain node consensus, node computing, and so on. Incentive mechanisms involve many\naspects. According to the knowledge scenario, we focus on the incentive of blockchain consensus\nmechanism and federated learning scenario. As shown in the Fig. 6, it is a scenario diagram of a\ncommon incentive mechanism.\nSupplier\nProvide raw data/ \npublish task\nValidator\nMiner\nTrainer\nGet training data/ \nsubmit local model\nEvaluate and \nvalidate the data \nor model\nAdd verified block \nmaintain the \nnetwork\nrewards\nrewards\nFig. 6: A typical AI-assisted incentive mechanism structure in the management layer\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:19\nBlockchain consensus mechanism. The consensus mechanism is an incentive mechanism\nto encourage nodes to calculate and reach data consensus. Chen et al. [33] propose a novel node\nselection algorithm based on AI technology, which uses almost complementary information of\neach node and relies on a specially designed convolutional neural network to reach a consensus.\nTo ensure the decentralization and security of the network, the dynamic threshold method is used\nto obtain super nodes and random nodes.\nTo reduce the computational waste involved in hash-based problems, several papers discuss the\npossible solutions that miners\u2019 computing power will be used for relatively useful work, such as\nsolving machine learning tasks. Bravo et al. [45] introduce WekaCoin, which is a point-to-point\ncryptocurrency based on a new distributed consensus protocol called Proof-of-Learning (POLE).\nProof-of-Learning realizes distributed consensus by ranking machine learning systems for a given\ntask. Miners\u2019 computing ability can also be used to solve deep learning training tasks, such as Proof\nof Federated Learning [106]. To reach a secure and robust consensus in the blockchain-based IoT\nnetworks, Salimitari et al. [46] use machine learning to propose a new framework. They introduce\nan AI-enabled blockchain (AIBC) with a 2-step consensus protocol, which uses an outlier detection\nalgorithm to reach consensus in the IoT network implemented on the hyper ledger fabric platform.\nFederated learning. Incentive mechanism is the key design element of the new federated\nlearning system, because: (i) participating in the federated learning will lead to the consumption\nof computing resources, use of network bandwidth and shorten the battery life of customers,\nand enough rewards can encourage them to tolerate these costs and make contributions; (ii) The\nworker thread in the federated learning is independent, and only its owner can determine when,\nwhere and how to participate in the federated learning. Through different incentive mechanisms,\ncustomers will implement different training strategies, which will affect the performance of the\nfinal machine learning model. In the federated learning system, the incentive mechanism has two\nmain challenges: (i) how to evaluate the contribution of each customer, and (ii) how to recruit and\nretain more customers. AI technology can help solve these two challenges.\nFor trading federated learning services in wireless environments to encourage data owners to\nparticipate in federal learning, Jiao et al. [107] novelly develop an automated deep reinforcement\nlearning-based auction mechanism which is integrated with the Graph Neural Network (GNN).\nThe proposed auction mechanisms can help the FL platform make practical trading strategies to\nefficiently coordinate data owners to invest their data and computing resources in federated learning\nwhile optimizing the social welfare of the FL services market. In Edge Learning, the existing work\nmainly focuses on the design of efficient learning algorithms, and few works focus on the design of\nincentive mechanisms with heterogeneous edge nodes (ENs) and network bandwidth uncertainty.\nZhan et al. [108] propose an edge learning incentive mechanism based on Deep Reinforcement\nLearning (DRL), which can effectively learn the optimal pricing strategy of aggregators without\nknowing any prior information of ENs in dynamic networks.\nIn Federated Learning (FL), it is important to measure the contribution of each federal participant\nfairly and accurately [110, 111]. Such quantification provides a reasonable metric for allocating\nrewards among federated clients and helps to find malicious participants who may poison the\nglobal model. The previous contribution measurement method is based on the enumeration of\npossible combinations of federated participants. Their calculation cost increases sharply with the\nincrease in the number of participants or feature dimensions, making them unsuitable for the actual\nsituation. Zhao et al. [111] propose an integrated contribution evaluation method F-RCCE based on\nreinforcement learning, which can accurately evaluate the contribution of each customer\u2019s gradient.\nAs the number of clients increases, its time cost almost remains the same.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:20\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nTable 6: Research of Content Management on AI\nSubjects\nRefs.\nAI Methods\nWeb 3.0 Tasks\nLimits\nBad content\ndetection\n[8]\nGAN\nMovie review spam detection\nPoor generality: set feature words manually\n[56]\nCNN\nPornography image detection\nModel depends on training dataset\n[112]\nDL\nNot applicable to pictures with low resolution\n[3]\nCNN\nChild sex abuse detection.\nThe age group detection technology is not mature\nDeepfake\ndetection\n[113]\nCNN\nDetect the deepfake image and video\nCompression level and resolution are ignored\n[114]\nCNN and CL\nDetect the deepfake image\nThe model ignores low-quality data\n[115]\nCNN and SNN\nDetect the deepfake video\nNot applicable to multi-person video\n[116]\nCNN\nPoor versatility and low quality video data is ignored\n6.2\nContent Management\nThe Web 3.0 ecosystem encourages users to create content. Users can create their articles, pictures,\nand videos. However, malicious content will have a serious impact on the Web 3.0 ecosystem, and\nAI plays an important role in the content management of the Web 3.0 ecosystem. We divide the\nbad content of Web 3.0 into two categories: bad content (real) and deepfake content (fake).\nBad content detection. We divide bad content into bad text, bad image, and bad video according\nto the form of content. AI technology can provide great help in bad content detection. Bad text\ndetection includes junk comments detection, online cyberbullying detection, etc. Junk comments\nwill mislead users and affect their trust in online comments. Many papers use methods based\non AI technology to detect junk comments [8, 117]. Jian et al. [117] propose a multimodal fake\nreview detection model BAM (BERT + Attention + MLP), which uses neural networks as well as\nmultimodal fusion technology to realize the recognition of fake reviews.\nIn terms of bad image detection, we focus on pornography detection and child sexual abuse\ndetection. For pornography detection, Moreira et al. [56] contribute a pornographic dataset (PEDA\n376K) and propose a deep learning architecture for training on this dataset, which has excellent\nperformance. For detecting nudity and semi-nudity contents, Pandey et al. [112] propose a deep\nlearning solution ensemble containing MobileNetV3 classifier and SSD with MobileNetV3 feature\nextractor. SSD detects unsafe body parts while also providing a human-localized portion. To solve\nthe Child Sexual Abuse (CSA) problem, Gangwar et al. [3] propose a deep CNN architecture with\na novel attention mechanism and metric learning, denoted as AttM-CNN. For violence detection\nin the video, Wu et al. [118] first release a large-scale multi-scene dataset called XD Violence and\npropose a neural network with three parallel branches to capture different relationships between\nvideo clips and integrate features.\nDeepfake detection. Deepfake content mainly includes images and videos. Artificial intelligence\ntechnology plays an important role in deepfake detection. The first category is deepfake image\ndetection. An effective solution is to use image inconsistency to detect deepfake images. Li et al. [113]\ncreatively propose a new Patch and Pair Convolutional Neural Network (PPCNN) architecture to\ndetect deepfakes. They construct a dual-branch learning framework, which is the first to learn the\ndifference between real and false face patches and the second to capture the inconsistency between\nthe facial and the nonfacial region. The results of the two branches are combined when making\na global decision. Zhao et al. [114] propose a new novel representation learning approach, called\nPair-wise Aelf-consistency Learning (PCL) to detect deepfake images using the cue of the source\nfeature inconsistency within the forged image.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:21\nFeature \nExtracting \nmodule\nGlobal \nCorrelation \nbranch\nLocal \nAssociation \nbranch\nTarget frame\nReference \nframe\n\ud835\udc491\n\ud835\udc492\nClassification \nnetwork\n\ud835\udc4a1\n\ud835\udc3f1\nConcatenate\nReal\nFake\nVideo\nPreprosessing\nFig. 7: Technology roadmap of deepfake video detection. Utilizing the inconsistency information\nbetween adjacent frames to detect deepfake video [116] .\nThe second category is deepfake video detection. Audiovisual joint detection is a popular method\nof deepfake video detection. Mittal et al. [115] propose a new method to detect any forgery or\nchange in the input video using audio (speech) and video (face) modes and the perceptible emotional\nfeatures extracted from these two modes. To simulate such multimodal features and perceived\nemotions, the learning method uses a Siamese network-based architecture.\nAnother popular way to detect deepfake video is by utilizing the inconsistency information\nbetween adjacent frames [116, 119]. Hu et al. [116] propose a new Dynamic Inconsistency-aware\nNetwork (DIANet) for DeepFake video detection by utilizing the inconsistency information between\nadjacent frames. As shown in Fig. 7, DIANet consists of three modules: Feature Extraction Module,\nCross-Reference Module (CRM), and Classification Network. DIANet takes a pair of frames as input\nand obtains their feature representation through the Feature Extraction module. Then the proposed\nCRM is used to capture the global and local inconsistencies between adjacent frames. Finally, the\nglobal and local inter-frame inconsistencies are combined and sent to the classification network.\nThe model generalizes well on videos of low quality and unseen manipulation techniques.\nAt present, most of the advanced algorithms are trained to detect specific fake methods. Therefore,\nthese methods show poor generalization in different types of face operations from face swapping\nto facial reenactment. Cozzolino et al. [120] propose a new method that is introduced to learn\nthe temporal facial features of how a person moves when talking through measurement learning\ncombined with antagonistic training strategies. The advantage is that only real video training\nis required. In addition, the use of advanced semantic features makes it robust to extensive and\ndestructive post-processing forms.\n6.3\nSituation Awareness\nThe trading of digital assets in Web 3.0 depends on the safe and stable cyberspace security environ-\nment, so situation awareness of network security is essential. Artificial intelligence plays a very\nimportant role in network situation awareness, which is mainly reflected in three aspects: transac-\ntion entity recognition, malicious transaction identification and network behavior recognition.\nTransaction entity Recognition. Users in Web 3.0 ecosystem trade digital assets anonymously,\nand transaction entity identification aims to determine which addresses belong to the same entity\nfrom the vast amount of transaction records. Due to the lack of labeled datasets, unsupervised\nlearning methods can effectively assist researchers in identifying user entities.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:22\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nTable 7: Research of Situation Awareness on AI\nSubjects\nRefs.\nAI Methods\nUtilized Feature\nWeb3.0 Tasks\nTransaction\nentity\nrecognition\n[121]\nClustering\nTransaction inputs, amount and time\nTransaction address association analysis\n[41]\nGCN\nRelationship between account and contract\nTransaction account type identification\n[125]\nGNN\nTransaction amount and time\nTransaction account identification\n[124]\nPUL\nTransactions order and amount\nTransaction data labeling\nMalicious\ntransaction\nidentification\n[42]\nGCN\nTransactions between accounts\nPhishing Scams Detection\n[126]\nSVM\nTransaction amount and timestamp\nPhishing Scams Detection\n[127]\nXGBoost\nOperation codes of the smart contracts\nPonzi contract identification\nNetwork\nbehavior\nperception\n[43]\nGCN\nGraph representation of traffic interraction features\nDapp Access Behavior Identification\n[29]\nRF\nCumulative downlink packet length\nWeb page access behavior recognition\n[128]\nMC\nState transition in SSL/TLS handshake\nWeb3.0 application classification\n[129]\nCNN\nSequence of unidirectional burst lengths\nWeb3.0 website identification\n[130]\nCNN\nPacket Round-Trip Time\nVideo quality detection for network users\nThe most common way to de-anonymize transactions is to use heuristic clustering methods\nto analyze the association of Bitcoin account addresses. Reid et al. [121] propose the first cluster\nmethod for re-identification, named multi-input heuristic, which assumes that the input addresses of\na particular transaction are possessed by the same entity. Then, Androulaki et al. [122] propose the\nchange address cluster method, which assumes that a new \"change\" address created by a transaction\nis likely controlled by the same entity that created the transaction. However, due to the anonymity\nof users in Web 3.0 and the need for real labeled data sets, the effectiveness of the clustering method\ncannot be verified. To solve these problems, Kappos et al. [123] solve the common input heuristic\u2019s\nvalidation problem by combining the peeling chain\u2019s transaction principle. While Wu et al. [124]\nextended the labeled dataset by the PU learning approach.\nIn addition to traditional machine learning methods, some studies use graph neural networks to\nidentify transaction entities in Web 3.0. Shen et al. [41] construct the account interaction graphs\nusing Ethereum and EOSIO data and propose an end-to-end graph convolution network model\nto identify different categories of accounts or bots. Zhou et al. [125] use graph neural network\ntechnology to convert the transaction de-anonymization problem in the Ethereum platform into a\nsubgraph classification problem, which improved the accuracy of identifying anonymous accounts.\nMalicious transaction identification. Malicious asset trading behavior will have a bad impact\non Web 3.0 ecosystem, and artificial intelligence technology can effectively improve the accuracy of\nidentifying malicious trading behavior. Common malicious transactions in Web 3.0 include Ponzi\nschemes, phishing websites, money laundering, etc. In research on identifying Ponzi schemes, Chen\net al. [127] extract features from user accounts and operation codes of the smart contracts and then\nbuilt a classification model through the XGBoost algorithm to detect Ponzi schemes implemented\nas smart contracts. For phishing websites detection, researchers extract features from the labeled\ntransaction dataset that can mark phishing addresses and then use machine learning [126] or GCN\n[42] to transform the phishing site detection task into a classification problem based on the specific\nstructure of the transaction features. In terms of identifying money laundering transactions, GNNs\nhave a significant advantage in analyzing graph structure-based transaction data [131]. And by\nenhancing the edge features of the trading graph [132], GCN can also be used to identify money\nlaundering accounts.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:23\nNetwork behavior perception. Since many Web 3.0 applications use encrypted communication\nprotocols such as SSL/TLS, most of the behavior traffic in the network appears in the form of\nciphertext, which makes the key information contained in the plaintext invisible to regulators. AI\nhas been widely used in network behavior perception of Web 3.0, including website fingerprinting\n[29, 129], application traffic classification [43, 128] and video traffic classification [130].\nIn constructing web page fingerprints, Shen et al. [29] construct a web fingerprint classifier using\nrandom forest algorithm to identify web traffic by extracting packet length features. To fully extract\nthe traffic features, [129] trains a fine-grained website fingerprint classifier with CNN to achieve\nbetter results. In addition to being used to train website fingerprint classifiers, CNNs are also used\nto train video traffic classifiers to detect network video quality [130]. In terms of application traffic\nclassification, Shen et al. [128] use a second-order Markov model to construct a web application\nclassifier to achieve the classification of encrypted web application traffic. Based on this, GNNs are\nused to train classifiers based on traffic interaction graphs [43].\n6.4\nSummary and Lessons Learned\nIn this section, we introduce existing studies focusing on AI technology applied in Web 3.0 ecological\nmanagement, including incentive mechanisms, content management, and situation awareness. The\nWeb 3.0 ecosystem is subject to various anomalies in its operation. For example, users may create\nvulgar digital works to circulate, leading to ecosystem pollution. Due to the greater autonomy and\nanonymity of Web 3.0 users, it is costly and inefficient to detect these user anomalies manually.\nArtificial intelligence technology plays a huge role in assisting community administrators with\nanomaly detection and decision-making. However, because of the variety of unforeseen anomalies\nthat can occur in the ecosystem, it is relatively rudimentary to train AI models to deal with these\nanomalies using labeled data.\nWe summarize that data privacy breaches, poor model generalization, and lack of labeled data\nare three main dilemmas of Web 3.0 ecological management based on AI technology. Firstly, using\nprivacy-preserving techniques such as federal learning, homomorphic encryption, and differential\nprivacy can effectively avoid the privacy leakage problem in joint data training. Secondly, due to\nthe dynamics and diversity of abnormal community behavior, the model should be lightly trained\nbased on a small amount of anomalous behavior data, allowing the features and parameters of\nthe model to be optimized and fine-tuned promptly. Lastly, combining unsupervised learning\nand reinforcement learning, which are less dependent on label data, can effectively improve the\nperformance of the auxiliary management model.\n7\nAPPLICATION LAYER\nWeb 3.0 is widely applied in finance, healthcare and game entertainment. In this section, we illustrate\nsome applications and discuss the current situation of these applications and how to integrate with\nAI technology to provide more solid support for Web 3.0.\n7.1\nFinance\nWeb 3.0 has a wide range of applications in the financial field. The integration of AI is mainly\nused to predict the price of digital assets and improve the efficiency and security of Defi, or smart\ncontracts. We have already discussed digital asset price forecasting in Section 5.2. In this section,\nwe will focus on vulnerability detection and efficiency improvement of Defi, or smart contracts.\nDeFi and smart contract. Over the years, more and more projects have focused on this field and\ngradually evolved the concept of Defi. Defi, in short, is to make full use of blockchain technology\n(including smart contracts, decentralized asset custody, etc.) to replace all the intermediary roles\nin traditional financial services by code, to maximize the efficiency of financial services and\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:24\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nTable 8: Research on AI-based Applications in Web 3.0\nSubject\nRef.\nAI Methods\nSolutions\nWeb 3.0 tasks\nFinance\n[57]\nDL\nAI-based systematic modular framework\nDetecting smart contract vulnerabilities\n[58]\nLSTM\nApplying short and long term memory model\nLearn vulnerabilities in sequence\n[59]\nGNNs\nUsing Graph neural networks for detection\nSmart contract vulnerability analysis\nMetaverse\n[62]\nDRL\nVisual deep learning\nNovel virtual environment establishment\n[63]\nFL\nFederated learning based mobile edge computing\nProving computational effiency of AR applications\n[133]\nRL\nTrain virtual characters to move participants\nPrecomputing avatar behavior\n[134]\nCNNs\nOverlay food segmentation image inferred by CNNs\nImprove the presence of users eating in metaverse\nHealthcare\n[60]\nANN\nAI-enabled and Blockchain-driven\nMedical Healthcare System for COVID-19\n[135]\nDCNNs\nAn intermediate fusion framework\nPhysical activity recognition\nminimize the cost. We will discuss the current situation of existing applications and focus on some\nsmart contracts based on AI technology. The introductory text [136] discusses the origins of DeFi\nand delineates DeFi characteristics from those of traditional finance. Several examples of DeFi\napplications are given, the disadvantages resulting from this paradigm are discussed, and an outlook\nis provided. For example, Uniswap v3 [137] is a noncustodial automated market maker implemented\nfor the Ethereum Virtual Machine. MakerDao [138] is a decentralized, unbiased, collateral-backed\ncryptocurrency soft-pegged to the US Dollar.\nThe rapid development of AI technology has helped improve the security and efficiency of DEFI.\nSome researchers have applied it to the detection of smart contract vulnerabilities. For instance,\nTann et al. [58] apply the LSTM model to learn vulnerabilities in sequence. However, these methods\ndo not consider the impact of local code vulnerabilities on the overall code, which reduces the\ninterpretability of these methods. To solve the problem of interpretation, Zhang et al. [59] explore the\nuse of graph neural networks for smart contract vulnerability detection. They construct a contract\ngraph to represent the syntax and semantic structure of smart contract functions and propose a\nTime Message Propagation (TMP) network to detect vulnerabilities. While Yu et al. [57] propose\nthe first systematic modular framework for detecting smart contract vulnerabilities based on deep\nlearning, called DeeSCVHounter, which focuses on two types of smart contract vulnerabilities:\nreentry and time dependence. Their main innovation is to propose a novel Vulnerability Candidate\nSlice (VCS) concept to help the model capture the key points of vulnerabilities.\n7.2\nMetaverse\nAs one of the important applications of Web 3.0, Metaverse covers many fields, including finance,\ngames, healthcare, and so on. This paper mainly researches two aspects of the Metaverse: environ-\nment establishment and user\u2019s behavior. Other application areas such as finance and healthcare\nwill be described in their respective sections.\nEnvironment establishment. The users of the Metaverse, objects, or transactions in the\nphysical world interact with the Metaverse, constantly developing and persistently representing\nthe structure, behavior, and context of unique physical assets in the virtual world. With the\nbreakthrough of digital transformation, the latest trend in each industry is to build digital twins,\nand the ultimate goal is to use them throughout the asset lifecycle through real-time data.\nThe virtual world of the Metaverse has produced a large number of data, which makes the digital\ntwin based on deep learning crucial. Aiming at the shortcomings of existing works such as small\nscenes or limited interaction with objects, Lai et al. [62] propose a novel visual depth learning virtual\nenvironment to provide large-scale and diversified indoor and outdoor scenes. Augmented Reality\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:25\n(AR) devices can provide people with an immersive interactive experience, and their applications are\nsensitive to latency. Therefore, Chen et al. [63] solve the computational efficiency of AR applications,\nlow latency object recognition, and classification problems by combining the mobile edge computing\nparadigm with federated learning. In addition to the above, AI can help make virtual characters\nmore intelligent. Kastanis et al. [133] propose a reinforcement learning method used to train virtual\ncharacters to move participants to the designated position.\nUser\u2019s behavior. The user\u2019s behavior in the metaverse can be the behavior characteristics in\nthe game or the simulation behavior in virtual reality (VR). In the early stage, Lugrin et al. [139]\npropose a method for the AI-based simulation of object behavior so that interactive narrative can\nfeature the physical environment inhabited by the player character as an actor. The prototype\nbased on the top of the Unreal Tournament game engine relies on a causal engine, which essentially\nbypasses the native physics engine to generate alternative consequences to player interventions.\nThen, to allow users to eat naturally in Virtual Environment (VE), Nakano et al. [134] propose\nUkemochi to improve the presence of users eating in metaverse. Ukemochi seamlessly overlays\na food segmentation image inferred by deep neural networks on a VE. Ukemochi can be used\nsimultaneously as a VE created with the OpenVR API and can be easily deployed for the metaverse.\nRecently, some users protect their identities by arbitrarily changing their avatars. However, Meng\net al. [140] come up with a way to de-anonymize fake VR avatars called AvatarHunter. It achieves\nde-anonymization attacks by recording videos of multiple views in a VR scene, collecting the gait\ninformation of the victim\u2019s avatar and preserving the avatar\u2019s motion characteristics.\n7.3\nHealthcare\nThe applications of Web 3.0 in healthcare are mainly in the fields of Electronic Health Record (EHR)\nmanagement. The EHR management in Web 3.0 integrates blockchain technology and AI, and\nbetter protects the privacy and security of patient data in medical services than before.\nEHR management. The records in the traditional EHR management system are stored on a\ncloud server through the wireless communication channel, and there are risks of replay attacks,\nman-in-the-middle attacks, information leakage, and other security threats. Blockchain stores the\ndata as a transaction with characteristics such as trust, and immutability, which also eliminates the\nintermediaries and a centralized dependence on transaction control. Fusing blockchain and EHR\nmanagement is a better solution for the security threats and the framework of EHR management\nsystem based on blockchain as shown in Fig. 8. One of the solutions given by Vora et al. [64] is\ncalled BHEEM, which is a blockchain-based solution to store and efficiently transfer of EHRs.\nThe above-described approaches in the literature failed to realize the significance of AI technology\nfor EHR security, privacy, and accessibility. Mamoshina et al. [141] propose a blockchain-based\ndecentralized model that enables users to access their data in an AI-moderated healthcare data\nexchange. Another study by Krittanawong et al. [142] on AI and blockchain integration can\naccelerate by greatly increasing the availability of data for AI training and development, able to\nshare proprietary AI algorithms for generalization, decentralizing databases of different vendors\nor health systems, and incentivizing solutions that improve outcomes over those that do not,\nthe integration of blockchain with AI could advance the goal of personalized cardiovascular\nmedicine. For efficient contact tracing and monitoring of COVID-19 cases, Mistry et al. [60] propose\nMedBlock, a novel AI-based and blockchain-driven EHR maintenance framework, which improves\nthe efficiency of traditional EHR systems. Some medical services in real life are also virtualized. By\nrevealing the deep features of deep convolutional neural networks fused with traditional manual\nfeatures, Huynh-The et al. [135] propose an intermediate fusion framework for human activity\nrecognition (HAR) for supporting smart healthcare.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:26\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nBlockchain or \nDApps\nPatient\nDoctor\nNurse\nRecord\nHospital\nPatient\nVisits\nStored in \nblockchain\nCreates records \nfor patients\nUpdates records\nfor patients\nBasic medical \ninformation\nIPFS Hash\nConsist of\nFig. 8: The framework of EHR management system based on Blockchain\n7.4\nSummary and Lessons Learned\nAs mentioned earlier, we have discussed the details of AI and Web 3.0 applications in the fields of\nfinance, metaverse, and healthcare, and the impact of AI on the performance of these applications.\nAlthough AI technology has not been fully integrated with these Web 3.0 applications, researchers\nhave also tried to study AI blockchain technology and given some inspiring examples. The inte-\ngration of AI and blockchain, namely blockchain intelligence and intelligent blockchain, is worth\nexploring due to their close interaction. With the integration of AI and blockchain, distributed\nAI can process and execute the analysis or decision of trusted data without any support from a\ntrusted third party. We believe that blockchain encourages AI to reach an unprecedented level in\nthe context of various fields in Web 3.0.\n8\nCHALLENGES AND FUTURE RESEARCH DIRECTIONS\nAlthough researchers have made substantial achievements in developing Web 3.0, there remain\nsignificant challenges around the scalability of the infrastructure network, privacy protection,\ndecentralized identity authentication, and abnormal transaction detection of digital assets, etc.\nAt the same time, unprecedented study opportunities are also provided to develop innovative\napproaches to tackle these challenges.\n8.1\nInfrastructure layer\nThe challenges at the infrastructure layer can be summarized in two aspects. One is the performance\nchallenge, namely the scalability problem, and the other is the challenge of security and privacy.\nThe details are introduced as follows.\nScalability. Scalability in Web 3.0 refers to the ability of a public blockchain system to process\ntransactions, which is the key challenge faced by the Web 3.0 infrastructure layer and the primary\nobstacle that today\u2019s public blockchain systems are difficult to apply to practical scenarios. The\nspecifics of the scalability problem are as follows. (i) Transactions involve blockchain-related\noperations, which brings large processing costs; (ii) On-chain data needs to be backed up at each\nnode, which brings huge storage overhead, and a considerable number of nodes cannot afford\nthis overhead; (iii) Due to the excessive amount of data in the network, Web 3.0 applications have\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:27\ncertain data congestion and transmission delay compared to centralized applications, which is\ndifficult to apply to real-time systems.\nAs mentioned above, AI can make the system intelligent through learning algorithms, and\nminimize the system overhead by optimizing node behavior, system resource allocation, and other\nstrategies. AI also plays a role in assisting optimization in scenarios such as blockchain sharding\nand cross-chain, effectively alleviating scalability problems. At the same time, it predicts the status\nof nodes to improve the security and availability of the system.\nSecurity. In Web 3.0, the security problem is also worth attention. The security problems of the\ninfrastructure layer mainly include (i) intrusion and attack by malicious entities; (ii) privacy of\nuser data. (Other aspects like contract security, content security, etc., are outside the scope of this\nsection.) This poses some challenges to the design of the infrastructure layer. AI can solve the above\nproblems to a large extent. The learning algorithm can be used to predict reliable nodes in the\nnetwork, detect abnormal behaviors and identify intrusion behaviors of malicious entities. However,\nthe model needs to use the user\u2019s data when training, and the current technology cannot provide\nstrong privacy protection under the condition of guaranteeing performance. This requires the\nmaturity of related privacy protection technologies, such as differential privacy, secure multi-party\ncomputation, etc.\n8.2\nInterface Layer\nThe challenges of the interface layer can be illustrated from two aspects, digital identity, and digital\nassets. The main problems in digital identity are the usability of the identity system. The main\nproblems in digital assets are that the quality of AI-generated content still needs to be improved.\nDigital ID. At present, the high threshold of the identity system is one of the major problems.\nThe public-private key system is currently the most widely used. Users need to remember the\nlong and complex private key. Once forgotten, it cannot be retrieved. And users may also manage\nmultiple addresses at the same time, which greatly increases the management cost. At present, the\npossible development direction is the private key recovery technology based on social relations and\nnon-password technology. These methods will greatly reduce the cost of user identity management.\nBiometric authentication and behavioral authentication have shown their prospects as a means of\nidentity verification. However, these methods are vulnerable to various types of attacks, including\nmalware, imitation, simulation, deception, replay, statistics, algorithms, and robot attacks. The\ncombination of multiple types of biometrics (i.e. multi-mode authentication) can improve security\nand provide more reliable authentication. Many studies have shown that multimodal biometric\nmethods have advantages over single biometric methods.\nDigital assets. There are several challenges in the current artificial intelligence (AI) technology\nused to generate images. It is difficult for AI to correctly depict spatial and physical relationships in\ngenerating images. For example, almost all AI can\u2019t draw a mirror well, because the image inside\nand outside the mirror needs optical knowledge, and the AI model is based on statistics and does\nnot understand optics. Similarly, the geometry of AI painting is relatively bad. A typical example is\nthat you will find that the wheels painted by AI are not too round. Another example is that the\ndetails of transparent glass glasses painted by AI are not correct. AI painting is independent of\neach other. It is difficult for AI to draw a complete set of works, such as a storytelling comic book\nwith complex character relationships.\n8.3\nManagement Layer\nAlthough AI technologies can help Web 3.0 administrators better maintain order in their commu-\nnities, there are still significant challenges as the Web 3.0 ecosystem matures and evolve. These\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:28\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nchallenges are specific to data set construction, personalized incentive mechanisms, and the perfor-\nmance of AI algorithms. Meanwhile, these challenges also point the way for the development of\nmanagement technologies.\nIncentive mechanism. The incentive mechanism should unite benefit-sharing members in the\nblockchain-based trustless environment, and encourage them to effectively interact and collaborate\naround common goals according to their information, resources, goals, and risk appetite. The\nincentives in Web 3.0 can be divided into transferable incentives and non-transferable incentives.\nTransferable incentives are mainly economic incentives in the form of fungible tokens or nonfungi-\nble tokens (NFTs). Nontransferable incentives mainly refer to noneconomic incentives, including\nreputation, belief, and knowledge [87]. How to combine various incentive measures and design\nappropriate mechanisms to meet the specific needs of each type of member and the common goal\nof the cooperation is a major challenge for incentive mechanisms in Web 3.0. When designing\nan appropriate incentive mechanism for users, measurability, and personalization are particularly\nimportant, because the user\u2019s personal needs and optimization objectives largely affect the effec-\ntiveness of the incentive mechanism, and the needs and objectives vary from person to person.\nTherefore, the mixed incentive mechanism, which is mainly based on transferable incentives and\nsupplemented by non-transferable incentives, can be used to quantify human contributions to the\ncooperation task, and then allocate reputation, certificates, tokens, governance rights, etc.\nContent management. Although content management has made significant progress in recent\nyears, there are still many open issues worth exploring. The common seesaw nature between the\ngeneration method and the forensics method makes the Deepfake detection face many problems.\n(i) The booming media manipulation techniques such as deepfake can generate more and more\nauthentic and diversified forged data, and the potential forged types are usually unknown in real\nscenes. So media forensics algorithm should have good generalization ability. (ii) The multimedia\ndata such as images and videos spread on the network often undergo some post-processing, which\nmakes the performance of the forensics model decline, which brings serious challenges to forgery\ndetection. In addition, malicious users may deliberately impose invisible disturbance on forged data\nto deceive detection tools. Therefore, manipulation detectors should be robust to common distortion\nalgorithms. (iii) Although DNN has strong discrimination ability, it lacks interpretability, so the\njudgment based on the neural network is difficult to accept in court and other serious occasions.\nHowever, the popular trend of deepfake detection methods is still based on deep learning, so it is\nimportant to improve the interpretability and credibility of these methods.\nSituation awarness. Digital asset transaction dataset is a crucial component for situation\nawareness, as high-quality datasets can play an essential role in training. The construction of\ndigital asset transaction datasets is a significant challenge in the current supervision of digital\nasset transactions. It is difficult to obtain digital asset transaction datasets with undisputed ground\ntruth. Currently, two main methods are used in the literature to construct ground truth. We refer\nto a straightforward way to use an interface provided by a third-party service website to obtain\nthe labeled data directly. This method is relatively simple, but it is often limited by the access\nrestrictions of the third-party website, making it inefficient to obtain. At the same time, the labeled\ndata provided by the third-party website has an intense lag time, and thus the researchers cannot\naccess the latest labeled data promptly. Another method is for researchers to create digital asset\ntransactions directly, allowing direct access to the data tags, but this method is extremely costly.\nTo break through the dilemma between timeliness and low-cost, auto-labeling tools are highly\ndesirable to automatically collect accurate and adequate data samples for a given analysis pur-\npose. Since ensuring sufficient timeliness can be time-consuming and costly in terms of human\nefforts, crowdsourcing emerges as a promising approach to reduce the complexity, where multiple\nresearchers or volunteers are involved in completing the same data collection and labeling tasks\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:29\ntogether. There are several issues to be further addressed, such as uniform standards for judging\ndata quality, cost equalization for labeling data, and distribution of benefits from labeled data.\n8.4\nApplication Layer\nWe have described some frontier applications of Web 3.0, covering the fields of finance, metaverse,\nand healthcare, and given some examples of the combination of Web 3.0 and AI. Then we will\ncontinue to describe the technical challenges and future research directions in these three fields.\nFinance. Although blockchain and smart contract research have made significant progress,\nblockchain research also faces a well-known trilemma, which makes it difficult to create a decen-\ntralized, scalable, and secure blockchain. At the same time, smart contracts at this stage are usually\nsimple and automated contracts, which can only passively respond to predefined rules but cannot\nactively adapt to complex and dynamic environments. At present, artificial intelligence technology\nhas not been widely used in the financial field of Web 3.0. Because DeFi itself cannot be separated\nfrom smart contracts, if its application in the financial field wants to be further improved to gain\nmore users\u2019 attention, AI technology is a good solution to the efficiency of smart contracts and\nprivacy protection issues. AI smart contracts and blockchain are complementary. We believe AI\nsmart contracts in the future can optimize energy consumption and improve mining efficiency,\nimprove the scalability of blockchain, and be used to detect fraud.\nMetaverse. AI and blockchain are the basic technologies of the metaverse. The breakthrough of\nartificial intelligence technology, especially deep learning, has made great progress in the academic\nand industrial circles in the automatic operation and design of the metaverse. However, the existing\ndeep learning model is usually very deep and has a large number of parameters, which brings a heavy\nburden to mobile devices with limited resources to deploy learning-based applications. Although\nthe current AI technology is only at the stage when people tell machines to do specific tasks,\nrather than let machines learn automatic learning. Most learning tasks are only applicable to closed\nstatic environments with poor robustness and poor interpretability. Secondly, blockchain-related\nissues, such as whether the existing real-world NFT platform can adapt to the high transaction\nvolume in the metaverse, and whether the metaverse needs a new blockchain platform and a new\nconsensus mechanism, all of which deserve our deep consideration. In addition, a natural problem\nis how to ensure the security and privacy in the metaverse, which may mean the violation of their\nprivacy, potential identity theft and other types of fraud. In the future, solving these problems of\nthe metaverse is crucial for its development.\nHealthcare. At present, some Web 3.0 applications in the medical field combine AI technology\nand blockchain. The current challenges faced by Web 3.0 applications in the medical field are mainly\ntwo aspects. On the one hand, the privacy of user data in the EHR management system cannot\nbe adequately guaranteed, especially in the case of the COVID-19 pandemic. On the other hand,\nmedical services in the metaverse are still in the initial stage. AI technology has provided a great\npromotion for virtual reality, But at present, there are many medical services in real life that cannot\nbe realized in the metaverse. We believe that in future work, researchers can pay attention to the\nflexible application of machine learning in the EHR management system (especially FL) to better\nprotect the privacy of users\u2019 medical records. In addition, we also expect more medical services in\nthe metaverse (such as online consultation, online surgery, etc.) to emerge in the future.\n9\nCONCLUSION\nThis paper surveys the use of AI in Web 3.0. We begin by reviewing the development history of the\nweb and the different perspectives on Web 3.0 from academic and business communities, then give\nour understanding of Web 3.0 and construct an architecture of the Web 3.0 ecosystem.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:30\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\nWe divide the ecosystem of Web 3.0 into four layers: data management, value cycle, ecological\ngovernance, and application scenarios. The key focus of data management research is the use of\nintelligent strategies based on learning algorithms to enhance data management and resource\nallocation efficiency. The value cycle research focuses on identifying and authenticating digital\nidentities, as well as pricing and transaction circulation of digital assets. Ecological governance has\ntwo main aspects: managing user behavior, such as abnormal transaction behavior and malicious\ntraffic attacks, and managing user-generated content, including detecting bad or false information.\nThe last section of the article mainly introduces the current AI applications in Web 3.0 from the\nfield of finance, healthcare, and the metaverse. Finally, we also discuss the challenges and future\ndirections for the application of AI in Web 3.0 and provide an outlook for its future development.\nAll in all, with the rapid development of Web 3.0, the integration of AI technology will play an\nincreasingly important role. We hope that this survey can provide a comprehensive reference for\nscholars who are interested in the application of AI technology in Web 3.0 and can also provide\nuseful guidance for industry readers who are engaged in innovation in related fields. Further\ndevelopment on Web 3.0 needs collaboration from both academia and industries to strive for an\nopen, fair and intelligent future Internet.\nREFERENCES\n[1] M. Research, \u201cWeb3: in a nutshell,\u201d Accessed: Sept. 10, 2021. [Online]. Available: https://eshita.mirror.xyz/\nH5bNIXATsWUv_QbbEz6lckYcgAa2rhXEPDRkecOlCOI\n[2] Y. Qian, \u201cWeb3. 0: A new generation of internet that is approaching gradually,\u201d China Finance, 2022.\n[3] A. Gangwar, V. Gonz\u00e1lez-Castro, E. Alegre, and E. Fidalgo, \u201cAttm-cnn: Attention and metric learning based cnn for\npornography, age and child sexual abuse (csa) detection in images,\u201d Neurocomputing, vol. 445, pp. 81\u2013104, 2021.\n[4] L. Alessandretti, A. ElBahrawy, L. M. Aiello, and A. Baronchelli, \u201cAnticipating cryptocurrency prices using machine\nlearning,\u201d Complexity, vol. 2018, 2018.\n[5] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark et al.,\n\u201cLearning transferable visual models from natural language supervision,\u201d in International Conference on Machine\nLearning.\nPMLR, 2021, pp. 8748\u20138763.\n[6] S. Dathathri, A. Madotto, J. Lan, J. Hung, E. Frank, P. Molino, J. Yosinski, and R. Liu, \u201cPlug and play language models:\nA simple approach to controlled text generation,\u201d arXiv preprint arXiv:1912.02164, 2019.\n[7] D. Pawade, A. Sakhapara, M. Jain, and N. Jain, \u201cStory scrambler-automatic text generation using word level rnn-lstm,\u201d\nInternational Journal of Information Technology and Computer Science (IJITCS), vol. 10, no. 6, pp. 44\u201353, 2018.\n[8] Y. Gao, M. Gong, Y. Xie, and A. K. Qin, \u201cAn attention-based unsupervised adversarial model for movie review spam\ndetection,\u201d IEEE transactions on multimedia, vol. 23, pp. 784\u2013796, 2020.\n[9] Y. Wang, Z. Su, N. Zhang, R. Xing, D. Liu, T. H. Luan, and X. Shen, \u201cA survey on metaverse: Fundamentals, security,\nand privacy,\u201d IEEE Communications Surveys & Tutorials, 2022.\n[10] Q. Yang, Y. Zhao, H. Huang, Z. Xiong, J. Kang, and Z. Zheng, \u201cFusing blockchain and ai with metaverse: A survey,\u201d\nIEEE Open Journal of the Computer Society, vol. 3, pp. 122\u2013136, 2022.\n[11] T. Huynh-The, Q.-V. Pham, X.-Q. Pham, T. T. Nguyen, Z. Han, and D.-S. Kim, \u201cArtificial intelligence for the metaverse:\nA survey,\u201d Engineering Applications of Artificial Intelligence, vol. 117, p. 105581, 2023.\n[12] U. Mukhopadhyay, A. Skjellum, O. Hambolu, J. Oakley, L. Yu, and R. Brooks, \u201cA brief survey of cryptocurrency\nsystems,\u201d in 2016 14th annual conference on privacy, security and trust (PST).\nIEEE, 2016, pp. 745\u2013752.\n[13] J. Zarrin, H. Wen Phang, L. Babu Saheer, and B. Zarrin, \u201cBlockchain for decentralization of internet: prospects, trends,\nand challenges,\u201d Cluster Computing, vol. 24, no. 4, pp. 2841\u20132866, 2021.\n[14] W. Yang, E. Aghasian, S. Garg, D. Herbert, L. Disiuta, and B. Kang, \u201cA survey on blockchain-based internet service\narchitecture: requirements, challenges, trends, and future,\u201d IEEE access, vol. 7, pp. 75 845\u201375 872, 2019.\n[15] K. Gilani, E. Bertin, J. Hatin, and N. Crespi, \u201cA survey on blockchain-based identity management and decentralized\nprivacy for personal data,\u201d in 2020 2nd Conference on Blockchain Research & Applications for Innovative Networks and\nServices (BRAINS).\nIEEE, 2020, pp. 97\u2013101.\n[16] T. Berners-Lee, \u201cTim berners-lee,\u201d 1989.\n[17] D. Raggett, A. Le Hors, I. Jacobs et al., \u201cHtml 4.01 specification,\u201d W3C recommendation, vol. 24, 1999.\n[18] R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P. Leach, and T. Berners-Lee, \u201cHypertext transfer protocol\u2013\nhttp/1.1,\u201d Tech. Rep., 1999.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:31\n[19] C. A. Toledano, \u201cWeb 2.0: the origin of the word that has changed the way we understand public relations,\u201d in\nBarcelona international PR conference, Barcelona, Spain, 2013.\n[20] T. Berners-Lee, \u201cSolid,\u201d Accessed: Otc. 25, 2022. [Online]. Available: https://solidproject.org/about\n[21] Web3 foundation, \u201cWeb3.0 Technology Stack,\u201d 2022. [Online]. Available: https://web3.foundation/about\n[22] L. Cao, \u201cDecentralized ai: Edge intelligence and smart blockchain, metaverse, web3, and desci,\u201d IEEE Intelligent Systems,\nvol. 37, no. 3, pp. 6\u201319, 2022.\n[23] W. S. Noble, \u201cWhat is a support vector machine?\u201d Nature biotechnology, vol. 24, no. 12, pp. 1565\u20131567, 2006.\n[24] R. V. Yampolskiy, B. Klare, and A. K. Jain, \u201cFace recognition in the virtual world: recognizing avatar faces,\u201d in 2012\n11th International Conference on Machine Learning and Applications, vol. 1.\nIEEE, 2012, pp. 40\u201345.\n[25] G. I. Webb, E. Keogh, and R. Miikkulainen, \u201cNa\u00efve bayes.\u201d Encyclopedia of machine learning, vol. 15, pp. 713\u2013714, 2010.\n[26] J. Bauer and D. Jannach, \u201cOptimal pricing in e-commerce based on sparse and noisy data,\u201d Decision support systems,\nvol. 106, pp. 53\u201363, 2018.\n[27] A. J. Myles, R. N. Feudale, Y. Liu, N. A. Woody, and S. D. Brown, \u201cAn introduction to decision tree modeling,\u201d Journal\nof Chemometrics: A Journal of the Chemometrics Society, vol. 18, no. 6, pp. 275\u2013285, 2004.\n[28] S. J. Rigatti, \u201cRandom forest,\u201d Journal of Insurance Medicine, vol. 47, no. 1, pp. 31\u201339, 2017.\n[29] M. Shen, Y. Liu, L. Zhu, X. Du, and J. Hu, \u201cFine-grained webpage fingerprinting using only packet length information\nof encrypted traffic,\u201d IEEE Trans. Inf. Forensics Secur., vol. 16, pp. 2046\u20132059, 2021.\n[30] P. Kim, \u201cConvolutional neural network,\u201d in MATLAB deep learning.\nSpringer, 2017, pp. 121\u2013147.\n[31] A. Mordvintsev, C. Olah, and M. Tyka, \u201cInceptionism: Going deeper into neural networks,\u201d 2015. [Online]. Available:\nhttps://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html\n[32] L. A. Gatys, A. S. Ecker, and M. Bethge, \u201cImage style transfer using convolutional neural networks,\u201d in Proceedings of\nthe IEEE conference on computer vision and pattern recognition, 2016, pp. 2414\u20132423.\n[33] J. Chen, K. Duan, R. Zhang, L. Zeng, and W. Wang, \u201cAn ai based super nodes selection algorithm in blockchain\nnetworks,\u201d arXiv preprint arXiv:1808.00216, 2018.\n[34] A. S. B. Wazir, H. A. Karim, M. H. L. Abdullah, S. Mansor, N. AlDahoul, M. F. A. Fauzi, and J. See, \u201cSpectrogram-based\nclassification of spoken foul language using deep cnn,\u201d in 2020 IEEE 22nd International Workshop on Multimedia Signal\nProcessing (MMSP).\nIEEE, 2020, pp. 1\u20136.\n[35] A. S. Ba Wazir, H. A. Karim, M. H. L. Abdullah, N. AlDahoul, S. Mansor, M. F. A. Fauzi, J. See, and A. S. Naim,\n\u201cDesign and implementation of fast spoken foul language recognition with different end-to-end deep neural network\narchitectures,\u201d Sensors, vol. 21, no. 3, p. 710, 2021.\n[36] S. Grossberg, \u201cRecurrent neural networks,\u201d Scholarpedia, vol. 8, no. 2, p. 1888, 2013.\n[37] Q. Zhao, \u201cA deep learning framework for predicting digital asset price movement from trade-by-trade data,\u201d arXiv\npreprint arXiv:2010.07404, 2020.\n[38] M. Saad, J. Choi, D. Nyang, J. Kim, and A. Mohaisen, \u201cToward characterizing blockchain-based cryptocurrencies for\nhighly accurate predictions,\u201d IEEE Systems Journal, vol. 14, no. 1, pp. 321\u2013332, 2019.\n[39] M. Y. Chuttur and A. Nazurally, \u201cA multi-modal approach to detect inappropriate cartoon video contents using deep\nlearning networks,\u201d Multimedia Tools and Applications, vol. 81, no. 12, pp. 16 881\u201316 900, 2022.\n[40] S. Zhang, H. Tong, J. Xu, and R. Maciejewski, \u201cGraph convolutional networks: a comprehensive review,\u201d Computational\nSocial Networks, vol. 6, no. 1, pp. 1\u201323, 2019.\n[41] J. Shen, J. Zhou, Y. Xie, S. Yu, and Q. Xuan, \u201cIdentity inference on blockchain using graph neural network,\u201d CoRR, vol.\nabs/2104.06559, 2021. [Online]. Available: https://arxiv.org/abs/2104.06559\n[42] L. Chen, J. Peng, Y. Liu, J. Li, F. Xie, and Z. Zheng, \u201cPhishing scams detection in ethereum transaction network,\u201d ACM\nTrans. Internet Techn., vol. 21, no. 1, pp. 10:1\u201310:16, 2021.\n[43] M. Shen, Y. Liu, L. Zhu, X. Du, and J. Hu, \u201cFine-grained webpage fingerprinting using only packet length information\nof encrypted traffic,\u201d IEEE Trans. Inf. Forensics Secur., vol. 16, pp. 2046\u20132059, 2021.\n[44] R. Qin, W. Ding et al., \u201cWeb3-based decentralized autonomous organizations and operations: Architectures, models,\nand mechanisms,\u201d IEEE Transactions on Systems, Man, and Cybernetics: Systems, 2022.\n[45] F. Bravo-Marquez, S. Reeves, and M. Ugarte, \u201cProof-of-learning: a blockchain consensus mechanism based on\nmachine learning competitions,\u201d in 2019 IEEE International Conference on Decentralized Applications and Infrastructures\n(DAPPCON).\nIEEE, 2019, pp. 119\u2013124.\n[46] M. Salimitari, M. Joneidi, and M. Chatterjee, \u201cAi-enabled blockchain: An outlier-aware consensus protocol for\nblockchain-based iot networks,\u201d in 2019 IEEE Global Communications Conference (GLOBECOM).\nIEEE, 2019, pp. 1\u20136.\n[47] U. Mahbub, J. Komulainen, D. Ferreira, and R. Chellappa, \u201cContinuous authentication of smartphones based on\napplication usage,\u201d IEEE Transactions on Biometrics, Behavior, and Identity Science, vol. 1, no. 3, pp. 165\u2013180, 2019.\n[48] A. Agarwal, M. Dahleh, and T. Sarkar, \u201cA marketplace for data: An algorithmic solution,\u201d in Proceedings of the 2019\nACM Conference on Economics and Computation, 2019, pp. 701\u2013726.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:32\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\n[49] X. Zhou and P.-C. Liao, \u201cA privacy-preserving data storage and service framework based on deep learning and\nblockchain for construction workers\u2019 wearable iot sensors,\u201d arXiv preprint arXiv:2211.10713, 2022.\n[50] A. Ali, M. F. Pasha, J. Ali, O. H. Fang, M. Masud, A. D. Jurcut, and M. A. Alzain, \u201cDeep learning based homomorphic\nsecure search-able encryption for keyword search in blockchain healthcare system: A novel approach to cryptography,\u201d\nSensors, vol. 22, no. 2, p. 528, 2022.\n[51] Y. Liu, H. Wang, M. Peng, J. Guan, and Y. Wang, \u201cAn incentive mechanism for privacy-preserving crowdsensing via\ndeep reinforcement learning,\u201d IEEE Internet of Things Journal, vol. 8, no. 10, pp. 8616\u20138631, 2020.\n[52] P. P. Momtaz, \u201cSome very simple economics of web3 and the metaverse,\u201d FinTech, vol. 1, no. 3, pp. 225\u2013234, 2022.\n[53] J. Xu, Z. Rao, L. Xu, D. Yang, and T. Li, \u201cIncentive mechanism for multiple cooperative tasks with compatible users in\nmobile crowd sensing via online communities,\u201d IEEE Transactions on Mobile Computing, vol. 19, no. 7, pp. 1618\u20131633,\n2019.\n[54] Y. Zhan, C. H. Liu, Y. Zhao, J. Zhang, and J. Tang, \u201cFree market of multi-leader multi-follower mobile crowdsensing:\nAn incentive mechanism design by deep reinforcement learning,\u201d IEEE Transactions on Mobile Computing, vol. 19,\nno. 10, pp. 2316\u20132329, 2019.\n[55] R. Shinkuma, R. Takagi, Y. Inagaki, E. Oki, and F. Xhafa, \u201cIncentive mechanism for mobile crowdsensing in spatial\ninformation prediction using machine learning,\u201d in International Conference on Advanced Information Networking and\nApplications.\nSpringer, 2020, pp. 792\u2013803.\n[56] D. C. Moreira, E. T. Pereira, and M. Alvarez, \u201cPeda 376k: A novel dataset for deep-learning based porn-detectors,\u201d in\n2020 International Joint Conference on Neural Networks (IJCNN).\nIEEE, 2020, pp. 1\u20138.\n[57] X. Yu, H. Zhao, B. Hou, Z. Ying, and B. Wu, \u201cDeescvhunter: A deep learning-based framework for smart contract\nvulnerability detection,\u201d in 2021 International Joint Conference on Neural Networks (IJCNN), 2021, pp. 1\u20138.\n[58] W. J. Tann, X. J. Han, S. S. Gupta, and Y. Ong, \u201cTowards safer smart contracts: A sequence learning approach to\ndetecting vulnerabilities,\u201d CoRR, vol. abs/1811.06632, 2018. [Online]. Available: http://arxiv.org/abs/1811.06632\n[59] Y. Zhuang, Z. Liu, P. Qian, Q. Liu, X. Wang, and Q. He, \u201cSmart contract vulnerability detection using graph neural\nnetworks,\u201d ser. IJCAI\u201920, 2021.\n[60] C. Mistry, U. Thakker, R. Gupta, M. S. Obaidat, S. Tanwar, N. Kumar, and J. J. P. C. Rodrigues, \u201cMedblock: An ai-\nenabled and blockchain-driven medical healthcare system for covid-19,\u201d in ICC 2021 - IEEE International Conference\non Communications, 2021, pp. 1\u20136.\n[61] P. Bhattacharya, M. S. Obaidat, D. Savaliya, S. Sanghavi, S. Tanwar, and B. Sadaun, \u201cMetaverse assisted telesurgery\nin healthcare 5.0: An interplay of blockchain and explainable ai,\u201d in 2022 International Conference on Computer,\nInformation and Telecommunication Systems (CITS), 2022, pp. 1\u20135.\n[62] K.-T. Lai, C.-C. Lin, C.-Y. Kang, M.-E. Liao, and M.-S. Chen, \u201cVivid: Virtual environment for visual\ndeep learning.\u201d\nNew York, NY, USA: Association for Computing Machinery, 2018. [Online]. Available:\nhttps://doi.org/10.1145/3240508.3243653\n[63] D. Chen, L. J. Xie, B. Kim, L. Wang, C. S. Hong, L.-C. Wang, and Z. Han, \u201cFederated learning based mobile edge\ncomputing for augmented reality applications,\u201d in 2020 International Conference on Computing, Networking and\nCommunications (ICNC), 2020, pp. 767\u2013773.\n[64] J. Vora, A. Nayyar, S. Tanwar, S. Tyagi, N. Kumar, M. S. Obaidat, and J. J. P. C. Rodrigues, \u201cBheem: A blockchain-based\nframework for securing electronic health records,\u201d in 2018 IEEE Globecom Workshops (GC Wkshps), 2018, pp. 1\u20136.\n[65] C. H. Liu, Q. Lin, and S. Wen, \u201cBlockchain-enabled data collection and sharing for industrial iot with deep reinforcement\nlearning,\u201d IEEE Transactions on Industrial Informatics, vol. 15, no. 6, pp. 3516\u20133526, 2018.\n[66] X. Tang, X. Lan, L. Li, Y. Zhang, and Z. Han, \u201cIncentivizing proof-of-stake blockchain for secured data collection\nin uav-assisted iot: A multi-agent reinforcement learning approach,\u201d IEEE J. Sel. Areas Commun., vol. 40, no. 12, pp.\n3470\u20133484, 2022.\n[67] W. Zhuang, Q. Ye, F. Lyu, N. Cheng, and J. Ren, \u201cSdn/nfv-empowered future iov with enhanced communication,\ncomputing, and caching,\u201d Proc. IEEE, vol. 108, no. 2, pp. 274\u2013291, 2020.\n[68] X. Xu, H. Zhao, H. Yao, and S. Wang, \u201cA blockchain-enabled energy-efficient data collection system for uav-assisted iot,\u201d\nIEEE Internet Things J., vol. 8, no. 4, pp. 2431\u20132443, 2021. [Online]. Available: https://doi.org/10.1109/JIOT.2020.3030080\n[69] J. Yun, Y. Goh, and J. Chung, \u201cDqn-based optimization framework for secure sharded blockchain systems,\u201d IEEE\nInternet Things J., vol. 8, no. 2, pp. 708\u2013722, 2021. [Online]. Available: https://doi.org/10.1109/JIOT.2020.3006896\n[70] X. Bai, S. Tu, M. Waqas, A. Wu, Y. Zhang, and Y. Yang, \u201cBlockchain enable iot using deep reinforcement learning: A\nnovel architecture to ensure security of data sharing and storage,\u201d in International Conference on Artificial Intelligence\nand Security.\nSpringer, 2022, pp. 586\u2013597.\n[71] R. S. Vairagade and B. SH, \u201cEnabling machine learning-based side-chaining for improving qos in blockchain-powered\niot networks,\u201d Transactions on Emerging Telecommunications Technologies, vol. 33, no. 4, p. e4433, 2022.\n[72] L. Cui, X. Su, Z. Ming, Z. Chen, S. Yang, Y. Zhou, and W. Xiao, \u201cCREAT: blockchain-assisted compression algorithm\nof federated learning for content caching in edge computing,\u201d IEEE Internet Things J., vol. 9, no. 16, pp. 14 151\u201314 161,\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:33\n2022.\n[73] C. Farquhar, P. S. P. V. Kumar, A. Jagannath, and J. Jagannath, \u201cDistributed transmission control for wireless networks\nusing multi-agent reinforcement learning,\u201d CoRR, vol. abs/2205.06800, 2022.\n[74] N. C. Luong, T. T. Anh, H. T. T. Binh, D. Niyato, D. I. Kim, and Y. Liang, \u201cJoint transaction transmission and channel\nselection in cognitive radio based blockchain networks: A deep reinforcement learning approach,\u201d in IEEE International\nConference on Acoustics, Speech and Signal Processing, ICASSP 2019, Brighton, United Kingdom, May 12-17, 2019.\nIEEE,\n2019, pp. 8409\u20138413.\n[75] J. Xu, J. Lin, W. Liang, and K.-C. Li, \u201cPrivacy preserving personalized blockchain reliability prediction via federated\nlearning in iot environments,\u201d Cluster Computing, vol. 25, no. 4, pp. 2515\u20132526, 2022.\n[76] Z. Yang, R. Yang, F. R. Yu, M. Li, Y. Zhang, and Y. Teng, \u201cSharded blockchain for collaborative computing in the\ninternet of things: Combined of dynamic clustering and deep reinforcement learning approach,\u201d IEEE Internet Things\nJ., vol. 9, no. 17, pp. 16 494\u201316 509, 2022.\n[77] X. He, Y. Shen, H. Zhu, S. Wang, C. You, and T. Q. S. Quek, \u201cSocial welfare maximization for collaborative edge\ncomputing: A deep reinforcement learning-based approach,\u201d CoRR, vol. abs/2211.06861, 2022.\n[78] Z. Dai, A. Shrivastava, P. Reviriego, and J. A. Hern\u00e1ndez, \u201cOptimizing learned bloom filters: How much should be\nlearned?\u201d IEEE Embedded Systems Letters, 2022.\n[79] J. Li, Y. Shao, K. Wei, M. Ding, C. Ma, L. Shi, Z. Han, and H. V. Poor, \u201cBlockchain assisted decentralized federated\nlearning (BLADE-FL): performance analysis and resource allocation,\u201d CoRR, vol. abs/2101.06905, 2021.\n[80] J. Wang, J. Hu, G. Min, A. Y. Zomaya, and N. Georgalas, \u201cFast adaptive task offloading in edge computing based on\nmeta reinforcement learning,\u201d IEEE Transactions on Parallel and Distributed Systems, vol. 32, no. 1, pp. 242\u2013253, 2020.\n[81] Y. Lin, Z. Gao, H. Du, D. Niyato, J. Kang, R. Deng, and X. S. Shen, \u201cA unified blockchain-semantic framework for\nwireless edge intelligence enabled web 3.0,\u201d arXiv preprint arXiv:2210.15130, 2022.\n[82] X. Shen, J. Gao, W. Wu, K. Lyu, M. Li, W. Zhuang, X. Li, and J. Rao, \u201cAi-assisted network-slicing based next-generation\nwireless networks,\u201d IEEE Open Journal of Vehicular Technology, vol. 1, pp. 45\u201366, 2020.\n[83] W. Wu, N. Chen, C. Zhou, M. Li, X. Shen, W. Zhuang, and X. Li, \u201cDynamic RAN slicing for service-oriented vehicular\nnetworks via constrained learning,\u201d IEEE J. Sel. Areas Commun., vol. 39, no. 7, pp. 2076\u20132089, 2021.\n[84] P. Zheng, Z. Zheng, and L. Chen, \u201cSelecting reliable blockchain peers via hybrid blockchain reliability prediction,\u201d\nCoRR, vol. abs/1910.14614, 2019. [Online]. Available: http://arxiv.org/abs/1910.14614\n[85] Y. Lu, X. Huang, K. Zhang, S. Maharjan, and Y. Zhang, \u201cBlockchain and federated learning for 5g beyond,\u201d IEEE Netw.,\nvol. 35, no. 1, pp. 219\u2013225, 2021. [Online]. Available: https://doi.org/10.1109/MNET.011.1900598\n[86] T. W. W. W. Consortium, \u201cDecentralized Identifiers (DIDs) v1.0,\u201d Accessed: July. 19, 2022. [Online]. Available:\nhttps://www.w3.org/TR/did-core/\n[87] E. G. Weyl, P. Ohlhaver, and V. Buterin, \u201cDecentralized society: Finding web3\u2019s soul,\u201d Available at SSRN 4105763, 2022.\n[88] D. Zhang, G. Lu, L. Zhang et al., Advanced biometrics.\nSpringer, 2018.\n[89] K. Wang and A. Kumar, \u201cToward more accurate iris recognition using dilated residual features,\u201d IEEE Transactions on\nInformation Forensics and Security, vol. 14, no. 12, pp. 3233\u20133245, 2019.\n[90] Q. Debard, C. Wolf, S. Canu, and J. Arn\u00e9, \u201cLearning to recognize touch gestures: Recurrent vs. convolutional features\nand dynamic sampling,\u201d in 2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018).\nIEEE, 2018, pp. 114\u2013121.\n[91] S. Bader and N. E. B. Amara, \u201cDesign of a 3d virtual world to implement a logical access control mechanism based on\nfingerprints,\u201d in 2017 IEEE/ACS 14th International Conference on Computer Systems and Applications (AICCSA), 2017,\npp. 1239\u20131246.\n[92] R. Wang, C.-F. Chen, H. Peng, X. Liu, O. Liu, and X. Li, \u201cDigital twin: Acquiring high-fidelity 3d avatar from a single\nimage,\u201d arXiv preprint arXiv:1912.03455, 2019.\n[93] G. Schrotter and C. H\u00fcrzeler, \u201cThe digital twin of the city of zurich for urban planning,\u201d PFG\u2013Journal of Photogrammetry,\nRemote Sensing and Geoinformation Science, vol. 88, no. 1, pp. 99\u2013112, 2020.\n[94] J. Sun, Z. Tian, Y. Fu, J. Geng, and C. Liu, \u201cDigital twins in human understanding: a deep learning-based method to\nrecognize personality traits,\u201d International Journal of Computer Integrated Manufacturing, vol. 34, no. 7-8, pp. 860\u2013873,\n2021.\n[95] T. Karras, S. Laine, and T. Aila, \u201cA style-based generator architecture for generative adversarial networks,\u201d in\nProceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019, pp. 4401\u20134410.\n[96] G. Goh, A. Ramesh, M. Pavlov, and S. Gray, \u201cDALL\u00b7E: Creating Images from Text,\u201d Accessed: Jan. 25, 2021. [Online].\nAvailable: https://openai.com/blog/dall-e/\n[97] L. Xu, C. Jiang, Y. Qian, Y. Zhao, J. Li, and Y. Ren, \u201cDynamic privacy pricing: A multi-armed bandit approach with\ntime-variant rewards,\u201d IEEE Transactions on Information Forensics and Security, vol. 12, no. 2, pp. 271\u2013285, 2016.\n[98] K. Misra, E. M. Schwartz, and J. Abernethy, \u201cDynamic online pricing with incomplete information using multiarmed\nbandit experiments,\u201d Marketing Science, vol. 38, no. 2, pp. 226\u2013252, 2019.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n111:34\nMeng Shen, Zhehui Tan, Dusit Niyato, Yuzhi Liu, Jiawen Kang, Zehui Xiong, Liehuang Zhu, Wei Wang, and Xuemin\n(Sherman) Shen\n[99] X. Shen, J. Gao, W. Wu, M. Li, C. Zhou, and W. Zhuang, \u201cHolistic network virtualization and pervasive network\nintelligence for 6g,\u201d IEEE Communications Surveys & Tutorials, vol. 24, no. 1, pp. 1\u201330, 2021.\n[100] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros, \u201cUnpaired image-to-image translation using cycle-consistent adversarial\nnetworks,\u201d in Proceedings of the IEEE international conference on computer vision, 2017, pp. 2223\u20132232.\n[101] A. Graves, \u201cGenerating sequences with recurrent neural networks,\u201d arXiv preprint arXiv:1308.0850, 2013.\n[102] M. Hong, M. Wang, L. Luo, X. Tan, D. Zhang, and Y. Lao, \u201cCombining gated recurrent unit and attention pooling for\nsentimental classification,\u201d in Proceedings of the 2018 2nd International Conference on Computer Science and Artificial\nIntelligence, 2018, pp. 99\u2013104.\n[103] S. R. Bowman, L. Vilnis, O. Vinyals, A. M. Dai, R. Jozefowicz, and S. Bengio, \u201cGenerating sentences from a continuous\nspace,\u201d arXiv preprint arXiv:1511.06349, 2015.\n[104] OpenAI, \u201cIntroducing chatgpt,\u201d Accessed: November 30, 2022. [Online]. Available: https://openai.com/blog/chatgpt/\n[105] H. Jang and J. Lee, \u201cAn empirical study on modeling and prediction of bitcoin prices with bayesian neural networks\nbased on blockchain information,\u201d Ieee Access, vol. 6, pp. 5427\u20135437, 2017.\n[106] Y. Wang, H. Peng, Z. Su, T. H. Luan, A. Benslimane, and Y. Wu, \u201cA platform-free proof of federated learning consensus\nmechanism for sustainable blockchains,\u201d IEEE Journal on Selected Areas in Communications, vol. 40, no. 12, pp.\n3305\u20133324, 2022.\n[107] Y. Jiao, P. Wang, D. Niyato, B. Lin, and D. I. Kim, \u201cToward an automated auction framework for wireless federated\nlearning services market,\u201d IEEE Transactions on Mobile Computing, vol. 20, no. 10, pp. 3034\u20133048, 2020.\n[108] Y. Zhan and J. Zhang, \u201cAn incentive mechanism design for efficient edge learning by deep reinforcement learning\napproach,\u201d in IEEE INFOCOM 2020-IEEE Conference on Computer Communications.\nIEEE, 2020, pp. 2489\u20132498.\n[109] Y. Zhan, P. Li, Z. Qu, D. Zeng, and S. Guo, \u201cA learning-based incentive mechanism for federated learning,\u201d IEEE\nInternet of Things Journal, vol. 7, no. 7, pp. 6360\u20136368, 2020.\n[110] R. Xu, S. R. Pokhrel, Q. Lan, and G. Li, \u201cFair-bfl: Flexible and incentive redesign for blockchain-based federated\nlearning,\u201d arXiv preprint arXiv:2206.12899, 2022.\n[111] J. Zhao, X. Zhu, J. Wang, and J. Xiao, \u201cEfficient client contribution evaluation for horizontal federated learning,\u201d in\nICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).\nIEEE, 2021, pp.\n3060\u20133064.\n[112] A. Pandey, S. Moharana, D. P. Mohanty, A. Panwar, D. Agarwal, and S. P. Thota, \u201cOn-device content moderation,\u201d in\n2021 International Joint Conference on Neural Networks (IJCNN).\nIEEE, 2021, pp. 1\u20137.\n[113] X. Li, K. Yu, S. Ji, Y. Wang, C. Wu, and H. Xue, \u201cFighting against deepfake: Patch&pair convolutional neural networks\n(ppcnn),\u201d in Companion Proceedings of the Web Conference 2020, 2020, pp. 88\u201389.\n[114] T. Zhao, X. Xu, M. Xu, H. Ding, Y. Xiong, and W. Xia, \u201cLearning self-consistency for deepfake detection,\u201d in Proceedings\nof the IEEE/CVF international conference on computer vision, 2021, pp. 15 023\u201315 033.\n[115] T. Mittal, U. Bhattacharya, R. Chandra, A. Bera, and D. Manocha, \u201cEmotions don\u2019t lie: An audio-visual deepfake\ndetection method using affective cues,\u201d in Proceedings of the 28th ACM international conference on multimedia, 2020,\npp. 2823\u20132832.\n[116] Z. Hu, H. Xie, Y. Wang, J. Li, Z. Wang, and Y. Zhang, \u201cDynamic inconsistency-aware deepfake video detection,\u201d in\nIJCAI, 2021.\n[117] Y. Jian, X. Chen, and H. Wang, \u201cFake restaurant review detection using deep neural networks with hybrid feature\nfusion method,\u201d in International Conference on Database Systems for Advanced Applications.\nSpringer, 2022, pp.\n133\u2013148.\n[118] P. Wu, J. Liu, Y. Shi, Y. Sun, F. Shao, Z. Wu, and Z. Yang, \u201cNot only look, but also listen: Learning multimodal violence\ndetection under weak supervision,\u201d in European conference on computer vision.\nSpringer, 2020, pp. 322\u2013339.\n[119] Z. Gu, Y. Chen, T. Yao, S. Ding, J. Li, and L. Ma, \u201cDelving into the local: Dynamic inconsistency learning for deepfake\nvideo detection.\u201d\nAAAI, 2022.\n[120] D. Cozzolino, A. R\u00f6ssler, J. Thies, M. Nie\u00dfner, and L. Verdoliva, \u201cId-reveal: Identity-aware deepfake video detection,\u201d\nin Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021, pp. 15 108\u201315 117.\n[121] F. Reid and M. Harrigan, \u201cAn analysis of anonymity in the bitcoin system,\u201d in PASSAT/SocialCom 2011, Privacy, Security,\nRisk and Trust (PASSAT), 2011 IEEE Third International Conference on and 2011 IEEE Third International Conference on\nSocial Computing (SocialCom), Boston, MA, USA, 9-11 Oct., 2011.\nIEEE Computer Society, pp. 1318\u20131326.\n[122] E. Androulaki, G. Karame, M. Roeschlin, T. Scherer, and S. Capkun, \u201cEvaluating user privacy in bitcoin,\u201d in Financial\nCryptography and Data Security - 17th International Conference, FC 2013, Okinawa, Japan, April 1-5, 2013, Revised\nSelected Papers, ser. Lecture Notes in Computer Science, A. Sadeghi, Ed., vol. 7859.\nSpringer, pp. 34\u201351.\n[123] G. Kappos, H. Yousaf, R. St\u00fctz, S. Rollet, B. Haslhofer, and S. Meiklejohn, \u201cHow to peel a million: Validating and\nexpanding bitcoin clusters,\u201d in 31st USENIX Security Symposium, USENIX Security 2022, Boston, MA, USA, August 10-12,\n2022, K. R. B. Butler and K. Thomas, Eds.\nUSENIX Association, 2022, pp. 2207\u20132223.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\nArtificial Intelligence for Web 3.0: A Comprehensive Survey\n111:35\n[124] J. Wu, J. Liu, W. Chen, H. Huang, Z. Zheng, and Y. Zhang, \u201cDetecting mixing services via mining bitcoin transaction\nnetwork with hybrid motifs,\u201d IEEE Trans. Syst. Man Cybern. Syst., vol. 52, no. 4, pp. 2237\u20132249, 2022.\n[125] J. Zhou, C. Hu, J. Chi, J. Wu, M. Shen, and Q. Xuan, \u201cBehavior-aware account de-anonymization on ethereum\ninteraction graph,\u201d IEEE Trans. Inf. Forensics Secur., vol. 17, pp. 3433\u20133448, 2022.\n[126] J. Wu, Q. Yuan, D. Lin, W. You, W. Chen, C. Chen, and Z. Zheng, \u201cWho are the phishers? phishing scam detection on\nethereum via network embedding,\u201d IEEE Trans. Syst. Man Cybern. Syst., vol. 52, no. 2, pp. 1156\u20131166, 2022.\n[127] W. Chen, Z. Zheng, J. Cui, E. C. H. Ngai, P. Zheng, and Y. Zhou, \u201cDetecting ponzi schemes on ethereum: Towards\nhealthier blockchain technology,\u201d in Proceedings of the 2018 World Wide Web Conference on World Wide Web, WWW\n2018, Lyon, France, April 23-27, 2018.\nACM, 2018, pp. 1409\u20131418.\n[128] M. Shen, M. Wei, L. Zhu, and M. Wang, \u201cClassification of encrypted traffic with second-order markov chains and\napplication attribute bigrams,\u201d IEEE Trans. Inf. Forensics Secur., vol. 12, no. 8, pp. 1830\u20131843, 2017. [Online]. Available:\nhttps://doi.org/10.1109/TIFS.2017.2692682\n[129] M. Shen, Z. Gao, L. Zhu, and K. Xu, \u201cEfficient fine-grained website fingerprinting via encrypted traffic analysis with\ndeep learning,\u201d in 29th IEEE/ACM International Symposium on Quality of Service, IWQOS 2021, Tokyo, Japan, June\n25-28, 2021.\nIEEE, pp. 1\u201310.\n[130] M. Shen, J. Zhang, K. Xu, L. Zhu, J. Liu, and X. Du, \u201cDeepqoe: Real-time measurement of video qoe from encrypted\ntraffic with deep learning,\u201d in 28th IEEE/ACM International Symposium on Quality of Service, IWQoS 2020, Hangzhou,\nChina, June 15-17, 2020.\nIEEE, pp. 1\u201310.\n[131] M. Weber, G. Domeniconi, J. Chen, D. K. I. Weidele, C. Bellei, T. Robinson, and C. E. Leiserson, \u201cAnti-money\nlaundering in bitcoin: Experimenting with graph convolutional networks for financial forensics,\u201d CoRR, vol.\nabs/1908.02591, 2019. [Online]. Available: http://arxiv.org/abs/1908.02591\n[132] D. S. H. Tam, W. C. Lau, B. Hu, Q. Ying, D. M. Chiu, and H. Liu, \u201cIdentifying illicit accounts in large scale e-payment\nnetworks - A graph representation learning approach,\u201d CoRR, vol. abs/1906.05546, 2019. [Online]. Available:\nhttp://arxiv.org/abs/1906.05546\n[133] I. Kastanis and M. Slater, \u201cReinforcement learning utilizes proxemics: An avatar learns to manipulate the position of\npeople in immersive virtual reality,\u201d ACM Trans. Appl. Percept., vol. 9, no. 1, 2012.\n[134] K. Nakano, D. Horita, N. Isoyama, H. Uchiyama, and K. Kiyokawa, \u201cUkemochi: A video see-through food overlay\nsystem for eating experience in the metaverse,\u201d in CHI \u201922: CHI Conference on Human Factors in Computing Systems,\nNew Orleans, LA, USA, 29 April 2022 - 5 May 2022, Extended Abstracts, S. D. J. Barbosa, C. Lampe, C. Appert, and D. A.\nShamma, Eds.\nACM, 2022, pp. 380:1\u2013380:8.\n[135] T. Huynh-The, C.-H. Hua, N. A. Tu, and D.-S. Kim, \u201cPhysical activity recognition with statistical-deep fusion model\nusing multiple sensory data for smart health,\u201d IEEE Internet of Things Journal, vol. 8, no. 3, pp. 1533\u20131543, 2021.\n[136] P. Schueffel, \u201cDefi: Decentralized finance-an introduction and overview,\u201d Journal of Innovation Management, vol. 9,\nno. 3, pp. I\u2013XI, 2021.\n[137] H. Adams, N. Zinsmeister, M. Salem, R. Keefer, and D. Robinson, \u201cUniswap v3 core,\u201d Tech. rep., Uniswap, Tech. Rep.,\n2021.\n[138] MakerDao, \u201cThe maker protocol: Makerdao\u2019s multi-collateral dai (mcd) system,\u201d Accessed: Jun. 23, 2019. [Online].\nAvailable: https://makerdao.com/en/whitepaper\n[139] J.-L. Lugrin and M. Cavazza, \u201cAi-based world behaviour for emergent narratives,\u201d in Proceedings of the 2006 ACM\nSIGCHI international conference on Advances in computer entertainment technology, 2006, pp. 25\u2013es.\n[140] Y. Meng, Y. Zhan, J. Li, S. Du, H. Zhu, and X. Shen, \u201cDe-anonymization attacks on metaverse,\u201d 2023.\n[141] P. Mamoshina, L. Ojomoko, Y. Yanovich, A. Ostrovski, A. Botezatu, P. Prikhodko, E. Izumchenko, A. Aliper, K. Ro-\nmantsov, A. Zhebrak et al., \u201cConverging blockchain and next-generation artificial intelligence technologies to\ndecentralize and accelerate biomedical research and healthcare,\u201d Oncotarget, vol. 9, no. 5, p. 5665, 2018.\n[142] C. Krittanawong, A. J. Rogers, M. Aydar, E. Choi, K. W. Johnson, Z. Wang, and S. M. Narayan, \u201cIntegrating blockchain\ntechnology with artificial intelligence for cardiovascular medicine,\u201d Nature Reviews Cardiology, vol. 17, no. 1, pp. 1\u20133,\n2020.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2023.\n",
    "2001.07091": "1\nBlockchain Consensus Algorithms: A Survey\nMd Sadek Ferdous, Member, IEEE, Mohammad Jabed Morshed Chowdhury,\nMohammad A. Hoque, Member, IEEE, and Alan Colman\n!\nAbstract\u2014In recent years, blockchain technology has received unpar-\nalleled attention from academia, industry, and governments all around\nthe world. It is considered a technological breakthrough anticipated to\ndisrupt several application domains touching all spheres of our lives.\nThe sky-rocket anticipation of its potential has caused a wide-scale\nexploration of its usage in different application domains. This has resul-\nted in a plethora of blockchain systems for various purposes. However,\nmany of these blockchain systems suffer from serious shortcomings\nrelated to their performance and security, which need to be addressed\nbefore any wide-scale adoption can be achieved. A crucial component\nof any blockchain system is its underlying consensus algorithm, which\nin many ways, determines its performance and security. Therefore, to\naddress the limitations of different blockchain systems, several existing\nas well novel consensus algorithms have been introduced. A systematic\nanalysis of these algorithms will help to understand how and why any\nparticular blockchain performs the way it functions. However, the existing\nstudies of consensus algorithms are not comprehensive. Those studies\nhave incomplete discussions on the properties of the algorithms and\nfail to analyse several major blockchain consensus algorithms in terms\nof their scopes. This article \ufb01lls this gap by analysing a wide range of\nconsensus algorithms using a comprehensive taxonomy of properties\nand by examining the implications of different issues still prevalent in\nconsensus algorithms in detail. The result of the analysis is presented in\ntabular formats, which provides a visual illustration of these algorithms\nin a meaningful way. We have also analysed more than hundred top\ncrypto-currencies belonging to different categories of consensus al-\ngorithms to understand their properties and to implicate different trends\nin these crypto-currencies. Finally, we have presented a decision tree\nof algorithms to be used as a tool to test the suitability of consensus\nalgorithms under different criteria.\nIndex Terms\u2014Blockchain, Distributed Consensus, Proof of Work, PoW,\nProof of Stake, PoS, Delegated Proof of Stake, DPoS.\n1\nINTRODUCTION\nIn the last few years, blockchain has received wide-spread\nattention among the industry, the Government, and aca-\ndemia alike. This interest has been piqued by the success\nM. S. Ferdous is with Shahjalal University of Science and Technology, Sylhet\n3114, Bangladesh and Imperial College London, London SW7 2AZ, U.K. E-\nmail: sadek-cse@sust.edu.\nMohammad Jabed Morshed Chowdhury is with La Trobe University, Mel-\nbourne, Victoria-3086, Australia. E-mail: m.chowdhury@latrobe.edu.au.\nMohammad A. Hoque is with University of Helsinki, 3835 Helsinki, Helsinki\nFinland. E-mail: mohammad.a.hoque@helsinki.\ufb01.\nAlan Coleman is with Swinburne University of Technology, Hawthorn,\nAustralia. E-mail: acolman@swin.edu.au.\nof Bitcoin [1] that was introduced in 2008. While crypto-\ncurrencies have emerged as the principal and the most pop-\nular application of blockchain technology, many enthusiasts\nfrom different disciplines have identi\ufb01ed and proposed a\nplethora of applications of blockchain in a multitude of\napplication domains [2], [3]. The possibility of exploiting\nblockchain in so many areas has created huge anticipation\nsurrounding blockchain systems. Indeed, it is regarded as\none of the fundamental technologies to revolutionise the\nlandscapes of the identi\ufb01ed application domains.\nA blockchain system is, fundamentally, a distributed\nsystem that relies on a consensus algorithm that ensures\nagreement on the states of certain data among distributed\nnodes. A consensus algorithm is the core component that\ndirectly dictates how such a system behaves and the per-\nformance it can achieve. Distributed consensus has been\na widely studied research topic in distributed systems,\nhowever, with the advent of blockchain, it has received\nrenewed attention. A wide variety of crypto-currencies\ntargeting different application domains has introduced an\narray of unique requirements that can only be satis\ufb01ed by\ntheir corresponding consensus mechanisms. This fact has\nfuelled the need not only to examine the applicability of\nexisting consensus algorithms in newer settings, but also to\ninnovate novel consensus algorithms. Consequently, several\nconsensus algorithms have emerged, each of which pos-\nsesses interesting properties and unique capabilities.\nAs the characteristics of various types of blockchain\nsystems are fundamentally dependent on the consensus\nalgorithms they use, a systematic analysis of existing con-\nsensus algorithms is required. It is necessary to examine,\ncompare, and contrast these algorithms. There have a been\na number of attempts aiming to ful\ufb01l this goal can be found\nin [4], [5], [6], [7], [8], [9], [10]. In particular, the works carried\nout by Cachin et al. [4] and Bano et al. [5] are noteworthy as\nthey represent the pioneer works in this scope. Cachin et al.,\nin their work, have explored different aspects of distributed\nsystems and consensus and focused on consensus algorithm\ndeployed in blockchain systems that are not to open to\nthe public. On the other hand, the focus of the work by\nBano et al. is more general in the sense they have explored\nconsensus algorithms used both in public as well as private\nsystems. Another exceptional work is by Wang et al. [6] in\nwhich the authors have presented a comprehensive survey\nof different aspects of consensus, mining, and blockchains\nin a detailed fashion.\nHowever, all these works have some major shortcom-\narXiv:2001.07091v2  [cs.DC]  7 Feb 2020\n2\nings. For example, the factors upon which the consensus\nalgorithms have been analysed are not comprehensive.\nImportantly, a wide range of consensus algorithms and\ntheir internal mechanisms utilised in many existing crypto-\ncurrencies have not been considered at all. In addition, all\nof these studies have failed to capture the practical interrela-\ntion between blockchain systems (mostly crypto-currencies)\nand their corresponding consensus algorithms. All in all,\nthere is a pressing need for a study that analyses a wide\nrange of existing consensus algorithms and the blockchain\nsystems in a practical-oriented way and synthesises this\nanalyses into a conceptual framework in a concise yet com-\nprehensive manner. The principal motivation of this article\nis to \ufb01ll in this gap.\nContributions. The main contributions of the article are\npresented below:\n\u2022 A novel taxonomy of consensus properties, capturing\ndifferent aspects of a consensus algorithm, has been cre-\nated. In this taxonomy, consensus algorithms have been\ncategorised in two major categories: incentivised and\nnon-incentivised algorithms, which have been again\nsub-divided as per different considerations. Consensus\nalgorithms belonging to each sub-category analysed\ntogether using the taxonomy of consensus properties.\n\u2022 The analysis of each sub-category has been summarised\nin tabular formats so as to visually represent it in a\ncomprehensible way.\n\u2022 For each category (and the sub-category, if any), the cor-\nresponding blockchain systems (predominantly crypto-\ncurrencies) have been analysed as well. The ana-\nlysis result has been presented in a concise fashion,\nwhich can be used to understand the inter-relation\nbetween these systems and their underlying consensus\nalgorithms.\n\u2022 The major issues in each category of consensus al-\ngorithm have been examined in detail, and their im-\nplications have been further analysed.\n\u2022 Over hundred crypto-currencies, belonging to different\nconsensus algorithms, have been examined to under-\nstand their different properties. These properties then\nhave been utilised to analyse and identify different\ntrends among these crypto-currencies.\n\u2022 Finally, a decision tree of consensus algorithms have\nbeen presented. This tree can be utilised to test the suit-\nability of a consensus algorithm under certain criteria.\nIn short, with these contributions, this article represents one\nof the most comprehensive studies of blockchain consensus\nalgorithms as of now.\nStructure. In Section 2 we present a brief background on dis-\ntributed consensus, highlighting its different components,\ntypes and properties. Section 3 outlines a brief presentation\non blockchain covering its different aspects such as types,\nproperties, layers. A taxonomy of consensus algorithms and\ntheir underlying properties is presented in Section 4. Section\n5 and Section 6 analyse different incentivised consensus\nalgorithm whereas Section 7 examines the different non-\nincentivised consensus algorithms. Finally, we conclude in\nSection 8 with a detailed discussion on different issues\ninvolving the analysed consensus algorithms and the cor-\nresponding crypto-currencies.\n2\nBACKGROUND: DISTRIBUTED CONSENSUS\nConsensus mechanisms in distributed systems have been\na well studied research problem for nearly three decades.\nSuch mechanisms enable consensus to be achieved regard-\ning a shared state/data among a set of distributed nodes.\nThe need for a shared state originated the notion of replic-\nated database systems in order to ensure resilience against\nnode failures within a network. Such database systems\nensure that data is not lost when one or more nodes fail\nto function in an excepted fashion.\nThe notion of the replicated database can be generalised\nwith the concept of State Machine Replication (SMR) [11].\nThe core idea behind SMR is that a computing machine can\nbe expressed as a deterministic state machine. The machine\naccepts an input message, performs its prede\ufb01ned computa-\ntion, and might produce an output/response. These actions\nessentially change its state. SMR conceptualises that such a\nstate machine, with an initial state, can be replicated among\ndifferent nodes. If it can be ensured that all the participating\nnodes receive the same set of input messages in the exact\nsame order (the phenomenon known as atomic broadcast),\nthen each node would be able to evolve the states of its\nstate machine individually in exactly the same fashion. This\ncan guarantee consistency and availability regarding the\nstate of the machine (as well as data it holds) among all\n(applicable) nodes even in the presence of node failures.\nOnce this occurs, it can be said that a distributed consensus\nhas emerged among the participating nodes. It is imperative\nthat a protocol is de\ufb01ned to ensure timely dissemination\nand atomic broadcast of input messages among the nodes\nand, in many ways, dictates how a distributed consensus is\nachieved and maintained. Hence, such a protocol is aptly\ncalled a consensus protocol.\nDesigning and deploying a consensus protocol is a chal-\nlenging task as it needs to consider several crucial issues\nsuch as resiliency against node failures, node behaviour,\nnetwork partitioning, network latency, corrupt or out-of-\norder inputs, and so on [7]. Schneider pointed out that\nthere are two crucial requirements to reach and maintain\nconsensus among distributed nodes. The \ufb01rst requirement\nis a deterministic state machine. The second requirement is\na consensus protocol to disseminate inputs in a timely fashion\nand to ensure atomic broadcast among the participating\nnodes. At the same time, the consensus protocols must\nensure the properties of the atomic broadcast [12], [13],\n[4], [5]. The properties of atomic broadcast in distributed\nconsensus is illustrated in Table 1.\nOne way to achieve the design goals of such a protocol\nis to make certain assumptions under which the protocol is\nproved to function properly. These assumptions in\ufb02uence\nthe critical characteristics of a consensus protocol. Next,\nwe explore two sets of widely-used assumptions for any\ndistributed consensus protocol.\nThe \ufb01rst set of assumptions are about the underly-\ning networking type. Dwork et al. categorised three types\nof networks exhibiting different properties: synchronous,\nasynchronous, and partially/eventually synchronous [22].\nThe latency involved in delivering a message to all nodes\n3\nProperties\nNote\nValidity\nThis guarantees that if a message is broadcast by\na valid node, it will be correctly included within\nthe consensus protocol.\nAgreement\nThis is to guarantee that if a message is de-\nlivered to a valid node, it will ultimately be\ndelivered to all valid nodes.\nIntegrity\nThis is to ensure that a message is broadcast\nonly once by a valid node.\nTotal Order\nThis is to ensure that all nodes agree to the order\nof all delivered messages.\nTable 1: Atomic broadcast Properties of Distributed Con-\nsensus Protocols.\nProperties\nNote\nSafety/\nCon-\nsistency\nA consensus protocol is considered safe (or con-\nsistent) only when all nodes produce the same\nvalid output, according to the protocol rules, for\nthe same atomic broadcast.\nLiveness/\navailability\nIf all non-faulty participating nodes produce an\noutput (indicating the termination of the pro-\ntocol), the protocol is considered live.\nFault\nTolerance\nIt exhibits the network\u2019s capability to perform\nas intended in the midst of node failures.\nTable 2: Properties of Distributed Consensus Protocols.\nin a synchronous network is bound by some time denoted\nas \u2206. On the other hand, the latency in an asynchronous\nnetwork cannot be reliably bound by any\u2206. Finally, in a par-\ntially/eventually synchronous network, it is assumed that\nthe network will eventually act as a synchronous network,\neven though it might be asynchronous over some arbitrary\nperiod of time.\nThe second set of assumptions is about the different\nproperties of a consensus protocol. According to [7], a con-\nsensus protocol should have the following three properties;\nnamely consistency, availability, and fault tolerance. These\nproperties are elaborated in Table 2 A well-known theorem,\nby Fischer, Lynch and Paterson [23], called FLP Impossibility\nhas shown that a deterministic consensus protocol cannot\nsatisfy all three properties described above in an asynchron-\nous network. It is more common to tend to favour safety and\nliveness over fault tolerance in the domain of distributed\nsystem applications. A related theorem is the CAP theorem\n[24], which states that a shared replicated datastore (or, more\ngenerally, a replicated state machine) cannot achieve both\nconsistency and availability when a network partitions in\nsuch a way that an arbitrary number of messages might be\ndropped.\nIn addition to the above assumptions, there are two\nmajor fault-tolerance models within distributed systems:\ncrash failure (or tolerance) and Byzantine failure [5], [7],\n[4]. The crash failure model deals with nodes that simply\nfail to respond due to some hardware or software failures.\nIt may happen any time without any prior warning, and\nthe corresponding node remains unresponsive until further\nactions are taken. Byzantine failure, on the other hand, deals\nwith nodes that misbehave due to some software bugs or\nbecause of the nodes being compromised by an adversary.\nThis type of failure was \ufb01rst identi\ufb01ed and formalised by\nLeslie Lamport in his seminal paper with a metaphorical\nByzantine General\u2019s problems [14]. A Byzantine node can\nbehave maliciously by arbitrarily sending deceptive mes-\nsages to others, which might affect the security of distrib-\nuted systems. Hence, such nodes are mostly relevant in\napplication with security implications.\nTo handle these two failure models, two corresponding\nmajor types of consensus mechanisms have emerged: Crash-\ntolerant consensus and Byzantine consensus [4]. Next, we\nbrie\ufb02y discuss each of them, along with their associated\nproperties.\n1) Crash-tolerant consensus: Algorithms belonging to this\nclass aim to guarantee the atomic broadcast (total or-\nder) of messages within the participating nodes in the\npresence of certain number of node failures. These\nalgorithms utilise the notion of views or epochs, which\nimply a certain duration of time or events. A leader\nis selected for each epoch who takes decisions regard-\ning the atomic broadcast, and all other nodes comply\nwith its decision. In case a leader fails due to a crash\nfailure, the protocols elect a new leader to function.\nThe best known algorithms belonging to this class can\ncontinue to function if the following condition holds:\nt < n/2 where t is the number of faulty nodes and n\nis the total number of participating nodes [4]. Examples\nof some well-known crash-tolerant consensus protocol\nare: Paxos [15], [16], Viewstamped Replication [17],\nZooKeeper [18], and Raft [19].\n2) Byzantine consensus: This class of algorithms aim to\nreach consensus amid of certain nodes exhibiting Byz-\nantine behaviour. Such Byzantine nodes are assumed\nto be under the control of an adversary and behave un-\npredictably with malicious intent. Similar to any crash-\ntolerant consensus protocol, these protocols also utilise\nthe concept of views/epochs where a leader is elected\nin each view to order messages for atomic broadcast,\nand other honest nodes are assumed to follow the in-\nstructions from the leader. One of the most well-known\nalgorithms under this class is called Practical Byzantine\nFault Tolerant (PBFT), which can achieve consensus in\nthe presence of a certain number of Byzantine nodes\nunder an eventual synchronous network assumption\n[20]. The tolerance level of PBFT is f < n/3, where\nf the number of Byzantine nodes and n denotes the\nnumber of total nodes participating in the network [4].\nAs we will explore later, PBFT algorithms have been\nwidely utilised in different blockchain systems.\n3\nBACKGROUND: BLOCKCHAIN\nIn this section, we present a brief introduction to the block-\nchain technology and it related terminologies. At the centre\nof the blockchain technology is the blockchain itself stored\nby the nodes of a P2P network. A blockchain is a type of\ndistributed ledger consisting of consecutive blocks chained\ntogether following a strict set of rules. Here, each block is\ncreated at a prede\ufb01ned interval, or after an event occurs, in\na decentralised fashion by means of a consensus algorithm.\nWithin each block, there are transactions by which a value is\ntransferred in case of crypto-currencies or a data is stored for\nother blockchain systems. The consensus algorithm guar-\n4\nantees several data integrity related properties (discussed\nbelow) in blockchain.\nEven though the terms blockchain and DLT (Distributed\nLedger Technology) are used inter-changeably in the literat-\nure, there is a subtle difference between them which is worth\nhighlighting. A blockchain is just an example of a particular\ntype of ledger, there are other types of ledger. When a ledger\n(including a blockchain) is distributed across a network, it\ncan be regarded as a Distributed Ledger.\nSince the blockchain technology has been introduced\nwith Bitcoin, it will be useful to understand how Bitcoin\nworks. In Section 3.1, we discuss a brief primer of Bitcoin\nand its associated terminologies. Then, we describe differ-\nent properties and types of blockchains in Section 3.2 and\nSection 3.3 respectively. Finally, we present the concept of\nblockchain layers in Section 3.4.\n3.1\nBitcoin\nThe Bitcoin network consists of nodes within a P2P (Peer-\nto-Peer) network. Each node needs to download the Bitcoin\nsoftware to connect to the network. There are different types\nof nodes in the network, with miner nodes and general\nnodes being the major ones. A general node is mostly used\nby users to transfer bitcoin in the network, whereas a miner\nnode is a special node used for mining bitcoins (see below).\nEach user within a node needs to utilise wallet software\nto create identities. An identity in the Bitcoin network con-\nsists of a private/public key pair, and a bitcoin address is\nderived from the corresponding public key. A sender needs\nto know such an address of the receiver to transfer any\nbitcoin. Bitcoin is transferred between two entities using the\nnotion of a transaction where the sender utilises a wallet\nsoftware for this purpose. This transaction is propagated to\nthe network, which is collected by all miner nodes. Each\nminer node combines these transactions into a block and\nthen engages in solving a cryptographic puzzle, with other\nminers, in which it tries to generate a random number which\nsatis\ufb01es the required condition (the random number must\nbe less than a target value called the dif\ufb01cult target). When\na miner successfully solves the puzzle, that miner is said\nto have generated a valid block which is then propagated\nin the network. The Bitcoin protocol generates a certain\namount of new Bitcoins for each new valid block and\nrewards the miner for its effort in creating the block. Other\nminers validate this newly mined block and then add it to\nthe blockchain. Each new block refers to the last block in the\nchain, which in turn refers to its previous block, and so on.\nThe very \ufb01rst block in the chain, known as the genesis block,\nhowever, has no such reference.\nThe decentralised nature of this mining process might\nresult in multiple valid blocks generated by different miners\nand propagated at the same time in the network. All of them\nare added to the blockchain and they refer to the same last\nblock in the chain. Consequently, multiple branches emerge\nfrom the same blockchain. This is a natural phenomenon\nin blockchain and is aptly known as fork. The fundamental\ngoal of the corresponding consensus protocol is to resolve\nthis fork so that only one branch remains and other branches\nare discarded. The consensus algorithm utilised in Bitcoin\nfollows a simple rule: it lets the branches grow. As soon as\nFigure 1: Block Generation Process of Bitcoin\nA Each miner collects transactions that are broadcast\nin the network and uses her hashpower to try to\ngenerate a block via repeated invocation of a hash\nfunction on data. The data consists of the transactions\nthat she saw \ufb01t to include, the hash of the previous\nblock, her public key address, and a nonce.\nB When a miner succeeds in generating a block, mean-\ning that the hash of her block data is smaller than the\ncurrent dif\ufb01culty target, she broadcasts her block to\nthe network.\nC The other miners continue to extend the blockchain\nfrom this new block, only if they \ufb01nd that this block\nis valid, i.e., it refers the hash of the previous block\nof the longest chain and meets the current dif\ufb01culty\ntarget.\nD The block reward (newly minted coins) and the fees\nfrom the transactions go to the miner\u2019s public address.\nThis means that only the miner can spend those by\nsigning with her corresponding private key.\nE The dif\ufb01culty level readjusts according to the mining\npower of the participates, by updating the hash target\nvalue every 2016 blocks (\u22482 weeks) so that blocks get\ngenerated once every 10 minutes on average.\nF The block reward starts at 50 coins and halves in every\n210, 000 blocks, i.e., about every 4 years.\none branch grows longer than the others (more speci\ufb01cally,\nthe total cumulative computational effort of one branch ex-\nceeds the others), all miners select the longest branch (or the\nbranch with the highest computational effort), discarding all\nother branches. Such a branch is known as the main branch\nand other branches are known as orphan branches. Only\nthe miners in the main branch are entitled to receive their\nBitcoin rewards. When a fork is resolved across the network,\na distributed consensus emerges in the network.\nThe frequency of Bitcoin block generation depends on\nthe dif\ufb01culty parameter, which is adjusted after 2016 blocks.\nThe protocol adjusts the dif\ufb01culty parameter in such a way\nthat a block is generated in every 10 minutes on average.\nHowever, the Bitcoin reward is halved after every 210, 000\nblocks, or approximately after every 4 years. At the initial\nstage, the reward for generating a valid block had been\n50 Bitcoins, which was halved to 25 Bitcoins in 2012 and\n12.5 Bitcoins in 2016. The next halving will occur in 2020\nwhere the reward will be reduced to 6.25 bitcoins per block.\nThis geometric reduction in every four years underlines\na maximum total supply of 21 million of Bitcoins. It is\nexpected that this supply will be exhausted in the year of\n2140 when the rewarded bitcoin will be in\ufb01nitesimally small\nfor each block.\nThe process of Bitcoin protocol is presented in Figure 1.\n3.2\nProperties of blockchain\nA blockchain exhibits several properties that make it a\nsuitable candidate for several application domains [25]. The\nproperties are discussed below.\n5\n\u2022 Distributed consensus on the chain state: One of the\ncrucial properties of any blockchain is its capability to\nachieve a distributed consensus on the state of the chain\nwithout being reliant on any trusted third party. This\nopens up the door of opportunities to build and utilise\na system where states and interactions are veri\ufb01able\nby the miners in public blockchain systems or by the\nauthorised entities in private blockchain systems.\n\u2022 Immutability\nand\nirreversibility\nof\nchain\nstate:\nAchieving a distributed consensus with the participa-\ntion of a large number of nodes ensures that the chain\nstate becomes practically immutable and irreversible\nafter a certain period of time. This also applies to smart-\ncontracts and hence enabling the deployment and exe-\ncution of immutable computer programs.\n\u2022 Data (transaction) persistence: Data in a blockchain is\nstored in a distributed fashion, ensuring data persist-\nence as long as there are participating nodes in the P2P\nnetwork.\n\u2022 Data provenance: The data storage process in any\nblockchain is facilitated by means of a mechanism\ncalled the transaction. Every transaction needs to be\ndigitally signed using public key cryptography, which\nensures the authenticity of the source of data. Combin-\ning this with the immutability and irreversibility of a\nblockchain provides a strong non-repudiation instru-\nment for any data in the blockchain.\n\u2022 Distributed data control: A blockchain ensures that\ndata stored in the chain or retrieved from the chain can\nbe carried out in a distributed manner that exhibits no\nsingle point of failure.\n\u2022 Accountability and transparency: Since the state of\nthe chain, along with every single interactions among\nparticipating entities, can be veri\ufb01ed by any authorised\nentity, a blockchain promotes accountability and trans-\nparency.\n3.3\nBlockchain type\nDepending on the application domains, different blockchain\ndeployment strategies can be pursued. Based on these\nstrategies, there are predominantly two types of block-\nchains, namely Public and Private blockchain, as discussed\nbelow:\n\u2022 Public blockchain: A public blockchain, also known as\nthe Unpermissioned or permissionless Blockchain, allows\nanyone to participate in the blockchain to create and\nvalidate blocks as well as to modify the chain state by\nstoring and updating data through transactions among\nparticipating entities. This means that the blockchain\nstate and its transactions, along with the data stored\nis transparent and accessible to everyone. This raises\nprivacy concerns for particular scenarios where the\nprivacy of such data needs to be preserved.\n\u2022 Private blockchain: A private blockchain, also known\nas the Permissioned Blockchain, has a restrictive notion in\ncomparison to its public counterpart in the sense that\nonly authorised and trusted entities can participate in\nthe activities within the blockchain. By allowing only\nauthorised entities to participate in activities within the\nblockchain, a private blockchain can ensure the privacy\nof chain data, which might be desirable in some use-\ncases.\n3.4\nBlockchain Layers\nThere are several components in a blockchain system whose\nfunctionalities range from collecting transactions, propagat-\ning blocks, mining, achieving consensus and maintaining\nthe ledger for its underlying crypto-currencies, and so on.\nThese components can be grouped together according to\ntheir functionalities using different layers similar to the\nwell-known TCP/IP layer. In fact, there have been a few\nsuggestions to design a blockchain system using a layered\napproach [26], [27]. The motivation is that a layered design\nwill be much more modular and easier to maintain. For\nexample, in case a bug is found in a component of a layer\nin a blockchain system, it will only affect the functionalities\nof that corresponding layer while other layers remain unaf-\nfected. For example, David et al. [27] suggest four layers:\nconsensus, mining, propagation, and semantic. However,\nwe believe that the proposed layers do not re\ufb02ect the proper\ngrouping of functionalities. For example, consensus and\nmining should be part of the same layer as mining can\nbe considered an inherent part of achieving consensus. In\naddition to this, some blockchain systems might not have\nany mining algorithms associated with it. In this paper,\nwe, therefore, will de\ufb01ne four layers (Figure 2): network,\nconsensus, application, and meta-application. The function-\nalities of these layers are brie\ufb02y presented below.\nMeta-Application Layer: The functionalities of the meta-\napplication layer in a blockchain system (see Figure 2) is to\nprovide an overlay on top of the application layer to exploit\nthe semantic interpretation of a blockchain system for other\npurposes in other application domains. For example, Bitcoin\nhas been experimented to adopt in multiple application\ndomains, such as DNS like decentralised naming system\n(Namecoin [28]), decentralised immutable time-stamped\nhashed record (Proof of Existence [29]), and decentralised\nPKI (Public Key Infrastructure), such as Certcoin [30].\nApplication Layer: The application layer (in Figure 2)\nde\ufb01nes the semantic interpretation of a blockchain system.\nAn example of a semantic interpretation would be to de\ufb01ne\na crypto-currency and then set up protocols for how such\na currency can be exchanged between different entities.\nAnother example is to establish protocols to maintain a state\nmachine embodying programming capabilities within the\nblockchain, which can be exploited to create and deploy\nimmutable code (the so-called smart contract). The applic-\nation also de\ufb01nes the rewarding mechanism, if any, in the\nblockchain system.\nConsensus Layer: The consensus layer, as presented in Fig-\nure 2, is responsible for providing the distributed consensus\nmechanism in the blockchain that essentially governs the\norder of the blocks. A critical component of this layer is the\nproof protocol (e.g., proof of work and proof of stake) that is\nused to verify every single block, which ultimately is used\nto achieve the required consensus in the system.\nNetwork Layer: The components in the network layer are\nresponsible for handling network functionalities which in-\nclude joining in the underlying P2P network, remaining\n6\nConsensus\nOrphaned\nbranch\nX\nX\nOrphaned\nbranch\nMain\nbranch\nCrypto-currency\nSMART Contract\ne-Voting\nPKI\nEscrowing\nCasino\nDNS\nNetwork\nLayer\nConsensus\nLayer\nApplication\nLayer\nMeta-Application\nLayer\nFigure 2: Blockchain Layers\nin the network by following the underlying networking\nprotocol, disseminating the current state of the blockchain to\nnewly joined nodes, propagating and receiving transactions\nand blocks and so on.\n4\nCONSENSUS TAXONOMY & PROPERTIES\nWith the introduction and advancement of different block-\nchain systems, there has been a renewed interest in distrib-\nuted consensus with the consequent innovation of different\ntypes of consensus algorithms. These consensus algorithms\nhave different characteristics and functionalities. In this\nsection, we \ufb01rst distinguish between two major types of\nconsensus and then present a taxonomy of their properties.\nLater, in Section 5 and 6, we explore numerous crypto\ncurrencies and discuss incentivised consensus algorithms.\nSimilarly, we focus on non-incentivised consensus and the\nblockchain applications in Section 7.\nConsensus mechanisms used by the various blockchain\nsystems can be classi\ufb01ed based on the reward mechanism\nthat participating nodes might receive. Therefore, we \ufb01rst\nclassify the consensus mechanisms in blockchain systems\ninto two categories: incentivised and non-incentivised al-\ngorithms.\nIncentivised Consensus. Some consensus algorithms re-\nward participating nodes for creating and adding a new\nblock in the blockchain. Such algorithms belong to this\ncategory. These algorithms are exclusively used in public\nConsensus \nproperties\nStructural \nproperties\nBlock & reward \nproperties\nSecurity \nproperties\nPerformance \nproperties\nFigure 3: Taxonomy of consensus properties.\nblockchain systems and the reward provided acts as an\nincentive for participating nodes to behave accordingly and\nto follow the corresponding consensus protocol rigorously.\nNon-incentivised Consensus. Private blockchain systems\ndeploy a type of consensus algorithms that do not rely\non any incentive mechanism for the participating nodes\nto create and add a new block in the blockchain. Such\nalgorithms belong to this category. With the absence of any\nreward mechanism, these nodes are considered trusted as\nonly authorised (allowed) nodes can participate in the block\ncreation process of the consensus algorithm.\n4.1\nConsensus properties\nEach consensus algorithm has different characteristics and\nserves different purposes. To compare these disparate\ngroups of consensus algorithms, we need to de\ufb01ne eval-\nuation criteria. In this section, we present this evaluation\ncriteria in the form of taxonomies of consensus proper-\nties. These properties have been collected from existing\nresearches, such as [5], [4], and compiled as a taxonomy in\nthis work.\nThe taxonomy is presented in Figure 3. According to this\ntaxonomy, a consensus mechanism has four major groups of\nproperties: Structural, Block & reward , Security and Perform-\nance properties. Each of these properties is brie\ufb02y discussed\nbelow.\n4.1.1\nStructural properties\nStructural properties de\ufb01ne how different nodes within a\nblockchain network are structured to participate in a con-\nsensus algorithm. These properties can be sub-divided into\ndifferent categories as illustrated in Figure 4. We brie\ufb02y\ndescribe each of these categories below.\n\u2022 Node types: It refers to different types of nodes that\na consensus algorithm is required to engage with to\nachieve its consensus. The types will depend on the\nconsensus algorithm which will be presented in the\nsubsequent section.\n\u2022 Structure type: It refers to the ways different nodes are\nstructured within the consensus algorithm using the\nconcept of a committee. The committee itself can be\nof two types: single and multiple committees. Each of\nthese committees is described below.\n\u2022 Underlying mechanism: It refers to the speci\ufb01c mechan-\nism that a consensus algorithm deploys to select a particular\nnode. The mechanism can utilise lottery, the age of a\nparticular coin or a voting mechanism. A lottery can\n7\nStructural \nproperties\nNode type\nStructure type\nSingle\nType\nOpen\nClose\nFormation\nImplicit\nExplicit\nConfiguration\nStatic\nDynamic\nMultiple\nTopology\nFlat\nHierarchichal\nConfiguration\nStatic\nDynamic\nUnderlying \nmechanism\nLottery\nProbabilistic\nRandomised\nVoting\nSingle\nMultiple\nCoin-age\nFigure 4: Taxonomy of structural properties.\nutilise either a cryptography based probabilistic mech-\nanism or other randomised mechanisms. In a voting\nmechanism, voting can be carried out either in a single\nor multiple rounds. The coin-age, on the other hand,\nutilises a special property, which depends on how long\na particular coin has been owned by its owner.\nNext, we explore different types of voting committees for\nexisting consensus algorithms.\nSingle committee. A single committee refers to a spe-\ncial group of nodes among the participating nodes which\nactively participate in the consensus process by producing\nblocks and extending the blockchain. Each single committee\ncan have different properties. Next, we brie\ufb02y explore these\nproperties.\n\u2022 Committee type: A committee can be open or close. A\ncommittee is open if it is open to any participating nodes\nor closed if it is restricted to a speci\ufb01c group of nodes.\n\u2022 Committee formation: A committee can be formed\neither implicitly or explicitly. An implicit formation\ndoes not require the participating nodes to follow\nany additional protocol rules to be in the committee,\nwhereas an explicit formation requires a node to follow\nadditional protocol steps to be a part of the committee.\n\u2022 Committee con\ufb01guration: A committee can be con-\n\ufb01gured in a static or a dynamic fashion.\n\u2013 Static: In a static con\ufb01guration, the members of the\ncommittee are pre-selected and \ufb01xed. No new mem-\nbers can join and participate in the consensus process.\n\u2013 Dynamic: In a dynamic con\ufb01guration, the committee\nmembers are de\ufb01ned for a time-frame (known as\nepoch), after which new members are added, and\nold members are removed based on certain sets of\ncriteria. In such a committee, nodes are selected using\na voting mechanism where voting is carried either\nin a single or multiple rounds. Some consensus al-\nBlock & Reward properties\nGenesis date\nBlock reward\nTotal supply\nBlock time\nFigure 5: Taxonomy of block & reward properties.\ngorithms, however, do not specify any speci\ufb01c time-\nframe, and hence, members can join or leave any\ntime at will. Nodes in such con\ufb01guration are selected\nusing a lottery mechanism which utilises either a\ncryptography based probabilistic mechanism or other\nrandomised mechanisms.\nMultiple committee. It has been observed that the time\nit takes to achieve consensus in a single committee tends\nto increase as the number of the member starts to increase\n[5], thereby reducing performance. To alleviate this problem,\nthe concept of multiple committee has been introduced,\nwhere each committee consists of different validators [5].\nA multiple committee can have different properties. Next,\nwe explore two properties.\n\u2022 Topology: It refers to the way different committees\nare organised. For example, the topology can be \ufb02at\nto indicate that different committees are at the same\nlevel or can be hierarchical where the committees can be\nconsidered in multiple layered levels.\n\u2022 Committee con\ufb01guration: In addition, like a single\ncommittee, the multiple committees can be con\ufb01gured\nin a static or dynamic way.\n4.1.2\nBlock & reward properties\nProperties under this category can be utilised as quantitat-\nive metrics to differentiate different crypto-currencies. The\nproperties are (Figure 5): genesis date, block reward, total\nsupply, formula, and block creation time. These proper-\nties do not necessarily characterise different consensus al-\ngorithm directly, however, most of them (except the genesis\ndate) have a direct and indirect impact on how consensus is\nachieved in a particular crypto-currency based blockchain\nsystem. For example, block reward incentivises miners to\nact accordingly by solving a cryptographic puzzle, which is\nthen ultimately used to achieve consensus. The properties\nare described below:\n\u2022 Genesis date represents the timestamp when the very\n\ufb01rst block was created for a particular crypto-currency.\n\u2022 Block reward represents the reward a node receives for\ncreating a new block.\n\u2022 Total supply represents the total supply of a crypto-\ncurrency.\n\u2022 Block time represents the average block creation time\nof a crypto-currency.\n4.1.3\nSecurity properties\nA consensus algorithm must satisfy a number of security\nproperties as shown in (Figure 6) and are described below:\n\u2022 Authentication: This implies if nodes participating in\na consensus protocol need to be properly veri\ufb01ed/au-\nthenticated.\n8\nSecurity \nproperties\nAuthentication\nNon-\nrepuditation\nCensorship \nreistance\nAttack vectors\nAdversary \ntolerance\nSybil protection\nDoS\nNothing At \nStake (NAS)\nBribing\nLong-range\nAccumulation\nGrinding\nCartel\nFigure 6: Taxonomy of security properties.\n\u2022 Non-repudiation: This signi\ufb01es if a consensus protocol\nsatis\ufb01es non-repudiation.\n\u2022 Censorship resistance: This implies if the correspond-\ning algorithm can withstand against any censorship\nresistance.\n\u2022 Attack vectors: This property implies the attack vectors\napplicable to a consensus mechanism. Here, we present\na set of attack vectors that are applicable to any con-\nsensus algorithm. The other attack vectors presented in\nFigure 6 are applicable to a speci\ufb01c class of consensus\nalgorithm. Therefore, we will discuss them in the up-\ncoming sections, when we explore such algorithms.\n\u2013 Adversary tolerance: This signi\ufb01es the maximum\nbyzantine nodes supported/tolerated by the respect-\nive protocol.\n\u2013 Sybil protection: In a Sybil attack [34], an attacker\ncan duplicate his identity as required in order to\nachieve illicit advantages. Within a blockchain sys-\ntem, a sybil attack implicates the scenario when an\nadversary can create/control as many nodes as re-\nquired within the underlying P2P network to exert\nin\ufb02uence on the distributed consensus algorithm and\nto taint its outcome in her favour.\n\u2013 DoS (Denial of Service) resistance: This implies if\nthe consensus protocol has any built-in mechanism\nagainst DoS attacks.\n4.1.4\nPerformance properties\nThe properties belonging to this group can be utilised\nto measure the quantitative performance of a consensus\nprotocol. A brief description of each property is presented\nbelow with its illustration in Figure 7\n\u2022 Fault tolerance: signi\ufb01es the maximum faulty nodes the\nrespective consensus protocol can tolerate.\nPerformance \nproperties\nFault \ntolerance\nThroughput\nScalability\nLatency\nEnergy \nconsumption\nFigure 7: Taxonomy of performance properties.\n\u2022 Throughput: implies the number of transactions the\nprotocol can process in one second.\n\u2022 Scalability: refers to the ability to grow in size and\nfunctionalities with- out degrading the performance of\nthe original system [31].\n\u2022 Latency (Finality): refers to \u201dthe time it takes from when a\ntransaction is proposed until consensus has been reached on\nit\u201d [5]. It is also known as \ufb01nality.\n\u2022 Energy consumption: indicates if the algorithm (or\nthe utilising system) consumes a signi\ufb01cant amount of\nenergy.\n5\nINCENTIVISED CONSENSUS: POW & POS\nIn this section, we explore different incentivised consensus\nalgorithms. Such algorithms can be grouped in three major\ncategories: Proof of Work (PoW), Proof of Stake (PoS), and\nHybrid Consensus. Among them, this section discusses\nPoW and PoS algorithms in Section 5.1 and Section 5.2 re-\nspectively. For readability, hybrid algorithms are presented\nin Section 6.\n5.1\nProof of Work (PoW)\nA Proof of Work (PoW) mechanism involves two different\nparties (nodes): prover (requestor) and veri\ufb01er (provider).\nThe prover performs a resource-intensive computational\ntask intending to achieve a goal and presents it to a veri\ufb01er\nor a set of veri\ufb01ers for validation that requires signi\ufb01cantly\nless resource. The core idea is that the asymmetry, in terms\nof resource required, between the proof generation and\nvalidation acts intrinsically as a deterrent measure against\nany system abuse.\nWithin this aim, the idea of PoW was \ufb01rst presented\nby Dwork and Naor in their seminal article in 1993 [33].\nThey put forward the idea of use PoW to combat email\nspamming. According to their proposal, an email sender\nwould be required to solve a resource-intensive mathem-\natical puzzle and attach the solution within the email as a\nproof that the task has been performed. The email receiver\nwould accept an email only if the solution can be success-\nfully veri\ufb01ed.\nWithin the blockchain setting, a similar concept has been\nadopted. Each PoW mechanism is bound to a threshold,\nknown as the dif\ufb01culty parameter in many blockchain sys-\ntems. The prover would carry out the computational task in\nseveral rounds until a PoW is generated that matches the\nrequired threshold, and every single round is known as a\nsingle proof attempt.\nPoW has been the most widely-used mechanism to\nachieve a distributed consensus among the participants\n9\nregarding the block order and the chain state. In particu-\nlar, a PoW mechanism in a blockchain serves two critical\npurposes:\n\u2022 A deterrent mechanism against the Sybil Attack. In\nPoW, every mining node would require a signi\ufb01cant\nmonetary investment to engage in a resource-intensive\nPoW mechanism during the block creation process. To\nlaunch a Sybil attack, the monetary investment of an\nattacker will be proportional to the number of Sybil\nidentities, which might outweigh any advantage gained\nfrom launching a Sybil attack.\n\u2022 The PoW mechanism is used as an input to a function\nwhich ultimately is used to achieve the required distrib-\nuted consensus when a fork happens in a blockchain\n[44].\nWe differentiate between three major classes of PoW\nconsensus mechanisms: Compute-bound PoW, Memory-bound\nPoW and Chained PoW. Each of these is explored in the\nfollowing sections.\n5.1.1\nCompute-bound PoW\nA Compute-bound PoW, also known as CPU-bound PoW,\nemploys a CPU-intensive function that carries out the re-\nquired computational task by leveraging the capabilities of\nthe processing units (e.g., CPU/GPU), without relying on\nthe main memory of the system. These particular charac-\nteristics facilitate the scenario in which the computation\ncan be massively optimised for faster calculation using\nApplication-speci\ufb01c Integrated Circuit (ASIC) rigs. This has\ndrawn criticisms among the crypto-currency enthusiasts as\ngeneral people cannot participate in the mining process with\ntheir general purpose computers, and the mining process is\nmostly centralised among a group of mining nodes.\nHashcash by Back et al. [45] is the earliest example to\nleverage a PoW mechanism in practical systems. Similar to\nthe proposal of Dwork and Naor in [33], Hashcash is also\ndesigned to combat spams. In this scheme, the email sender\nwould require to generate a SHA-1 hash with a certain prop-\nerty using as the input a number of information including\nrecipient\u2019s email address and date. The property dictates\nthat the generated hash must have at least 20 bits of leading\nzeroes. Generating an SHA-1 hash with this property would\nrequire the senders to engage in several proof attempts in\na pseudo-random fashion. Once the hash is generated, it\nis added within the email header. The veri\ufb01cation on the\nrecipient\u2019s side is rather trivial, which requires comparing a\nnewly generated hash using the required information with\nthe supplied hash. If they match, it proves that the email\nsender has engaged in the required amount of computa-\ntional work. The effectiveness of this approach of \ufb01ghting\nspams depends on the hypothesis that spammers rely on\nthe revenue model requiring a mere amount of cost to send\na single email. When they would need to engage in such\na computationally intensive task for sending every single\nemail, the aggregated associated cost might heavily affect\ntheir pro\ufb01t margin and thus deter them from spamming.\nNakamoto consensus is the compute-bound PoW con-\nsensus algorithm leveraged in Bitcoin. It is based on the\napproach of Hashcash, modi\ufb01ed to be applied within the\nblockchain setting. As discussed in Section 3.1, all mining\nnodes (miners) compete with each other to generate a valid\nblock by \ufb01nding a solution smaller than the dif\ufb01culty target.\nSimilar to the idea of HashCash, the miners need to engage\nin several proof attempts, until the solution is found. In\neach of these proof attempts, each miner generates a hash\nusing either the SHA-256 or SHA-256d (a double hashing\nmechanism using SHA-256) algorithm and checks if the\ngenerated hash is smaller than the dif\ufb01culty target. The\neffect of this distributed engagement is that forks happen,\nand then the Nakamoto consensus algorithm is utilised to\nresolve the fork and to achieve a network-wide distributed\nconsensus. The reader is referred back to Section 3.1 (and\nFigure 1) for a brief description of Nakamoto consensus.\nCurrently, there are many crypto-currencies that utilise\nthe Nakamoto consensus algorithm. Table 3 shows the top\n10 of such currencies according to their market capitalisation\nas rated by CoinGecko 1 (a website which tracks different\nactivities related to crypto-currencies) as of July 24, 2019.\nThe table also presents their Block and reward properties\nas presented in Figure 5. It is to be noted that information\nregarding the properties in Table 3 for these (and other\nsubsequent) currencies has been collected by consulting\ntheir corresponding whitepapers, websites and introductory\nannouncements on Reddit website 2.\n5.1.2\nMemory-bound PoW\nTo counteract the major criticism of compute-bound PoWs\nallowing the utilisation of ASIC-based rigs for the mining\npurpose (see Section 5.1.1), memory-bound PoWs have been\nproposed. A memory-bound PoW requires the algorithm to\naccess the main memory several times and thus ultimately\nbinds the performance of the algorithm within the limit\nof access latency and/or bandwidth as well as the size of\nmemory. This restricts ASIC rigs based on a memory-bound\nPoW to have the manifold performance advantage over\ntheir CPU/GPU based counterparts. In addition, the pro\ufb01t\nmargin of developing ASIC with memory and then building\nmining rigs with them is not viable as of now for these\nclasses of PoWs. Because of these, memory-bound PoWs\nare advocated as a superior replacement for compute-bound\nPoWs in de-monopolising mining concentrations around\nsome central mining nodes.\nThere is a large variety of consensus algorithms be-\nlonging to this class, unlike the consensus algorithms of\ncompute-bound PoW which are largely based on Hashcash.\nThese algorithms can be further categorised as follows:\nCryptonight; Scrypt and its variants; Equihash; Ethhash/D-\nagger; Neoscript; and Timetravel. We now describe each\nof these different types of memory-bound PoW consensus\nalgorithm.\n1) CRYPTONIGHT. Cryptonight is a class of PoW consensus\nalgorithms that, in principle, is a memory-hard hash func-\ntion [32]. It utilises the Keccak hashing function [46] intern-\nally and relies on a 2MB scratchpad residing on the memory\nof a computer. The scratchpad is extensively used to per-\nform numerous read/write operations at pseudo-random\n1. https://www.coingecko.com/\n2. https://www.reddit.com/\n10\nTable 3: Top ten crypto-currencies that utlise Nakamoto consensus algorithm.\nCurrency\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply\n(Million)\nBlock Time\nBitcoin/Bitcoin\nCash\n[69] [70]\n03.01.2009\n12.5\n21\n10m\nSyscoin [71]\n16.08.2014\n80.04659537\n888\n1m\nPeercoin [72]\n19.08.2012\n55.17265345\n2000\n10m\nCounterparty [73]\n01.02.2014\nAll currency in circulation\n2.6m\n-\nEmercoin [75]\n11.12.2013\nSmooth emission\n41\n10m\nNamecoin [76]\n19.04.2011\n12.50000000\n21\n10m\nSteem Dollars [77]\n04.06.2016\nSmooth emission\nUnlimited\n3s\nCrown [78]\n08.09.2014\n1.8\n42\n1m\nXP\n24.08.2016\n2220\nNA\nOmni (Mastercoin) [79]\n31.07.2013\n16.71249999 Omni\n0.6\n20s\naddresses within that scratchpad. In the \ufb01nal step, the\ndesired hash is generated by hashing the entire scratchpad.\nIts reliance on a large scratchpad on the memory of a\nsystem makes it resistant towards FPGA and ASIC mining\nas the economic incentive to create FPGA, and ASIC mining\nhardware might be too low for the time being. As such,\nCryptonight introduces the notion of so called Egalitarian\nproof of work [32] or proof of equality, which enables anyone\nto join in the mining process using any modern CPU and\nGPU.\nOne prominent property of the coins belonging to this\nclass is that all of them support stronger sender-receiver\nprivacy by facilitating anonymous transactions.\nCurrent currencies utilising Cryptonight according to\nCoingeko as of July 24, 2019 is presented in Table 4. Like\nTable 3, Table 4 also presents their Block and reward prop-\nerties as presented in Figure 5.\n2) SCRYPT AND ITS VARIANTS. Scrypt is a password based\nkey driving function (KDF) that is currently used in many\ncrypto-currencies [47]. A KDF is primarily used to gen-\nerate one or more secret values from another secret key\nand is widely used in password hashing. Previous key\nderiving functions such as DES-based UNIX Crypt-function,\nFreeBSD MD5 crypt, Public-Key Cryptography Standards#5\n(PKCS#5), and PBKDF2 do not impose any speci\ufb01c hard-\nware requirements. This enables any attacker launch attacks\nagainst those functions using speci\ufb01c FPGA or ASIC en-\nabled hardware, the so-called custom hardware attacks [48].\nScrypt has been designed to counteract this threat.\nToward this aim, one of the core characteristics of Scrypt\nis its reliance on the vast memory of a system, making it\ndif\ufb01cult to perform using FPGA and ASIC enabled cus-\ntom hardware. In the underneath, Scrypt utilises Salsa20/8\nCore [49] as its internal hash function. A simpli\ufb01ed version\nof Scrypt is used in the corresponding crypto-currencies,\nwhich is much faster and easier to implement, and can be\nperformed using any modern CPU and GPU. Hence, anyone\ncan join in the mining process for crypto-currencies using\nthis function. However, the ever-increasing price of crypto-\ncurrencies has incentivised miners to produce custom ASIC\nhardware for some crypto-currencies utilising Scrypt in\nrecent times. An example of such hardware that can be used\nto mine different Scrypt crypto-currencies is Antminer L3+\n[50].\nTo tackle this issue of exploiting ASIC for mining, sev-\neral Scrypt variants have been proposed: Scrypt-N/Scrypt\nJane/Scrypt Chacha and Scrypt-OG, each providing particu-\nlar advantages over others. Scrypt-N and Scrypt Chacha rely\non SHA256 and ChaCha [52] as their internal hash functions,\nrespectively, whereas Scrypt Jane utilises a combination of\ndifferent hash functions. All of them support progressive\nand tunable memory requirements, which can be adjusted\nafter a certain period. This is to ensure that custom ASIC\nhardware is rendered obsolete once the memory require-\nment is changed. Finally, Scrypt-OG (Optimised for GPU)\nis optimised to be eight times less memory intensive than\nScrypt [51].\nTable 5 shows the top 10 currencies, which either use\nScrypt or one of its variants, as per their market capitalisa-\ntion according to CoinGecko as of July 24, 2019.\n3) EQUIHASH Equihash is one of the recent PoW algorithms\nthat has been well received in the blockchain community\n[55]. It is a memory-bound PoW that requires to \ufb01nd a solu-\ntion for the Generalised Birthday problem using Wagner\u2019s\nalgorithm [56]. Equihash has been designed to decentralise\nthe mining procedure itself, similar to other memory-bound\napproaches. However, so far, very small portions of such\nalgorithms have succeeded. One of the crucial reasons for\nthis is that their underlying time-memory complexity trade-\noff is largely constant. This means that reducing memory\nrequirement in these algorithms have little effect on their\ncorresponding time complexity.\nWagner\u2019s solution has a steep time-memory complexity\ntrade-off, reducing memory increases time complexity sub-\nstantially. This premise has been exploited by Equihash to\nensure that mining is exclusively proportional to the amount\nof memory a miner has. Thus, it is more suitable for a gen-\neral purpose computer, rather than any ASIC-enabled hard-\nware which can only have relatively small memory in order\nto make their production pro\ufb01table for the mining process.\nDue to this reason, it has been claimed that Equihash can\nsupport ASIC resistance, at least for the foreseeable future.\nIn addition, the veri\ufb01cation is extremely lightweight and\neven can be carried out in resource-constrained mobile\ndevices. Table 6 shows the eight currencies which utilise\nEquihash according to CoinGecko as of July 24, 2019.\n4) ETHASH (DAGGER-HASHIMOTO)/DAGGER. Ethash is a\nmemory-bound PoW algorithm introduced for Ethereum\nwith the goal to be ASIC-resistant for a long period of\ntime [58]. It was previously known as Dagger-Hashimoto\nalgorithm [59] because of its utilisation of two different\nalgorithms: Dagger [60] and Hashimoto [60].\n11\nTable 4: Top ten crypto-currencies that utilise Cryptonight, with Bytecoin being the \ufb01rst to use this algorithm.\nCurrency\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply (Million)\nBlock Time\nMonero\n18.04.2014\n4.86930501\nStarting at M\n= 264 \u22121\nin\ufb01nite supply\n2.0m\nBytecoin\n04.07.2012\n666.76\n184.46 billion\n2.0m\nAeon\n06.06.2014\n5.48\nStarting at M = 264 \u22121,\nin\ufb01nite supply.\n4.0m\nBoolberry\n17.05.2014\n4.85\n18.5 Million\n2.0\nKarbowanec\n30.05.2016.\n8.83\nStarting with 10 Million, in-\n\ufb01nite supple\n4.0m\nFantomcoin\n06.05.2014\nsmooth emission, 50% coins will be\nemitted in 6 years and block reward\ndecreases with a similar Starting at\nM = 264 \u22121\nin\ufb01nite supply\n1.0m\nDashcoin\nfork\nof\nBytecoin\n05.07.2014\n1.55\n2.0m\nQuazarCoin\n08.05.2014\nsmooth emission\n2.0\nBipCoin\n20.08.2016\nsmooth emission\n2.0\nCannabis\nIndustry\nCoin\n16.10.2016\n70.00000000\n21 M\n2.0\nTable 5: Top ten crypto-currencies using Scrypt.\nCurrency\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply\n(Million)\nBlock Time\nLitecoin [80]\n13.10.2011\n25.00\n84 million\n2.5m\nVerge [82]\n15.02.2016\n730.00\n16.5 billion\n0.5m\nBitmark [83]\n13.07.2014\n(no\nlonger\nmonitored\nafter 2016)\n27.58 million\n2.0m\nDogecoin [84]\n06.12.2013\n10000.00\nTotal supply\nNA\nGameCredits [85]\n01.06.2015\n\ufb01xed (12.5 coins)\n84 million\n1.5m\nEinsteinium [86]\n01.03.2014\n2\n2.9 billion\n1.0m\nVoxels [87]\n03.11.2015\nsmooth emission\n2.1 billion\n2.5m\nViacoin [88]\n18.07.2014\n0.63\n23 million\n0.5m\nHempcoin [89]\n9.03.2014\nsmooth emission\n2.5 billion\n1.0m\nTable 6: Crypto-currencies utilising Equihash algorithm.\nCurrency\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply\n(Million)\nBlock Time\nZcash [90]\n28.10.2016\n10\n21 million\n2.5m\nBitcoin Gold [91]\n24.10.2017\n12.5\n21 million\n10m\nKomodo [92]\n15.10.2016\n3\n200 million\n1m\nZclassic [93]\n6.11.2016\n12.5\n21 million\n2.5m\nZenCash [94]\n30.05.2017\n7.5\n21 million\n2.5m\nHush [95]\nGenesis date\n11.25\n21 million\n2.5m\nBitcoinZ [96]\n10.09.2017\n12500.00\n21 billion\n2.5m\nVoteCoin [97]\n31.08.2017\n125\n2.2 billion\n2.5m\nDagger is one of the earliest proposed memory-bound\nPoW algorithm which utilises Directed Acyclic Graph\n(DAG) for memory-hard puzzle solving with trivial veri\ufb01c-\nation that requires less memory to be used in resource con-\nstrained devices. However, the Dagger algorithm is proven\nto be vulnerable towards a shared memory hardware ac-\nceleration attack, as discussed in [61]. That is why it has\nbeen dropped as a PoW candidate for Ethereum. Hashimoto\nalgorithm, on the other hand, relies on the delay incurred for\nreading data from memory as the limiting factor and thus,\nis known as an I-O bound algorithm.\nEthash combines these two algorithms to be ASIC-\nresistant and functions as follows. Ethash depends on a\nlarge pseudo-random dataset, which is recomputed during\neach epoch. Each epoch is determined by the time it takes\nto generate 30,000 blocks in approximately \ufb01ve days. This\ndataset is essentially a directed acyclic graph and hence, is\ncalled DAG. During the DAG generation process, a seed is\ngenerated at \ufb01rst, which relies on the length of the chain.\nThe seed is then used to compute a 16 MB pseudo-random\ncache. Then, each item of the DAG is generated by utilising\na certain number of items from the pseudo-random cache.\nThis entire process enables the DAG to grow linearly with\nthe growth of the chain. Then, the latest block header and\nthe current candidate nonce are hashed using Keccak (SHA-\n3) hash function, and the resultant hash is mixed and hashed\nseveral times with data from the DAG. The \ufb01nal hashed\ndigest is compared to the dif\ufb01culty target and accepted or\ndiscarded accordingly.\nEvery mix operation in Ethash requires to have a read in\na pseudo-random fashion from the DAG, which is randomly\naccessed from the memory. This serves two purposes:\n\u2022 The read operation is limited by the speed of the\nmemory access bandwidth, which is thought to be\n12\ntheoretically optimal, and thus, more optimisation is\nless likely.\n\u2022 Even though the mixing circuitry can be built within an\nASIC, the bottleneck would still be the memory access\ndelay.\nThat is why Ethash is thought to be suitable for use on\ncommodity computing capacity with good powerful GPUs.\nTo achieve the same level of performance, an ASIC would\nrequire to accommodate as large memory as a general\npurpose computer providing a \ufb01nancial disincentive.\nThere are currently two currencies utilising Ethereum\naccording to coingecko as of July 24, 2019 [62]. Even though\nDagger algorithm is proven not to be ASIC resistant, it is\nbeing used in 6 currencies [63]. All of these are presented in\nTable 7.\n5) NEOSCRYPT. NeoScrypt, an extension of Scrypt, is a key\nderivation function that aims to increase the security and\nperformance on CPUs and GPUs while being strong ASIC\nresistant [146]. Internally it utilises a combination of Salsa\n20/20 [49] and ChaCha 20/20 [52] along with Blake2s [74].\nIts constructions impose larger memory segment size, and\nhence, larger temporal buffer requirements. This makes it\n1.25 times more memory intensive than Scrypt. The motiva-\ntion is that this higher requirement of memory will act as a\ndeterrent towards building ASICs for NeoScrypt.\nCurrently, there are 10 currencies utilising NeoScrypt\naccording to Coingecko as of 18 July, 2019 [147] which are\npresented in Table 8.\n5.1.3\nChained PoW\nA chained PoW utilises several hashing functions chained\ntogether in a series of consecutive steps. Its main motiv-\nation is to ensure ASIC resistance, which is achieved by\nthe underlying mechanisms by which the corresponding\nhashing functions are chained together. In addition to this,\nthe PoW algorithms belonging to this series aim to ad-\ndress one particular weakness of any compute-bound and\nmemory-bound PoW algorithm: their reliance on a single\nhashing function. With the advent of quantum computing,\nthe security of a respective hashing algorithm might be\nadversely affected, which undermines the security of the\ncorresponding blockchain system. If this happens, the old\nalgorithm needs to be discarded, and a new quantum res-\nistant hashing algorithm needs to be incorporated to the\nrespective blockchain using a mechanism called hard-fork.\nA hard-fork is a mechanism by which a major update is\nenforced in a blockchain system. This is quite a disruptive\nprocedure that has negative effect on any blockchain system.\nIn such scenarios, a chained PoW algorithm would continue\nto function until all its hashing functions are broken.\nThere are several chained PoW algorithms that are cur-\nrently available.\n1) X11/X13/X15. X11 is a widely-used hashing algorithm in\nmany crypto-currencies. In X11, eleven hashing algorithms\nare consecutively carried our one after another. The hash-\ning algorithms are blake, bmw, groestl, jh, keccak, skein, luffa,\ncubehash, shavite, simd, and echo.\nOne advantage of X11 is that it is highly energy ef\ufb01-\ncient: GPUs computing X11 algorithm requires approxim-\nately 30% less wattage and remains 30 \u221250% cooler in\ncomparison to Scrypt [54]. Even though the algorithm has\nbeen designed in such a way that it can only be used with\nCPUs and GPUs, the economic incentives have allowed the\ncreation of ASIC to be used during the mining process.\nIt has different variants where the number of chained\nhashing functions differs. For example, X13 utilises 13 hash-\ning functions, and X15 utilises 15 hashing functions.\nTable 9 presents the top 10 crypto-currencies utilising\nthese three algorithms, as per their market capitalisation as\nof July 24, 2019 according to CoinGecko.\n2) QUARK. Quark PoW algorithm relies on six different\nhashing functions: BLAKE [74], Blue Midnight Wish [64],\nGr\u00f8stl [65], [140], JH [66], Keccak and Skein [67]. These\nfunctions are implemented in mixed series with nine steps\n[138]. Within these nine steps, three functions are randomly\napplied in three steps depending on the value of a bit. The\nmain motivations of mixing these six functions in nine steps\nare as follows:\n\u2022 To alleviate the risk of a compromised system in light of\nits underlying single hashing algorithm being broken.\n\u2022 To impose restrictions so that Quark can only be\nmined using CPUs while making it dif\ufb01cult to mine\nusing GPUs and ASICs, because of the usage of ASIC-\nresistant mechanisms (e.g. Keccak).\nHowever, it did not take long before ASIC mining\nhardware for Quark appeared in the market, so that this\ncould be mined using a GPU and ASIC [68]. However,\nthe pro\ufb01tability and performance of such hardware are not\nobvious.\nThe currencies utilising Quark according to CoinGecko\nas per July 24, 2019 [139] are presented in Table 10.\n3) LYRA2RE. Lyra2RE is a class of chained PoW which util-\nises \ufb01ve hash functions: BLAKE, Keccak, Lyra2,[13] Skein,\nand Gr\u00f8stl. It has been developed by the developers of\nVertcoin, a currency based on Lyra2RE. It was designed\nto be CPU friendly, however, it was discovered in 2015\nthat the majority of the hashing power utilised for mining\nVertCoin in its network was facilitated by a botnet stealing\nCPU cycles from a large number of infected computers. This\nmotivated the Vertcoin developers to release Lyra2REv2,\nwhich utilises six hash functions, BLAKE, Keccak, Cube-\nHash, Lyra2, Skein, and Blue Midnight Wish with GPU\nonly PoW. Currently, there are only three currencies utilising\nLyra2REv2 according to CoinGecko as of 31 December 2017\nwhich are presented in Table 11.\n4) MAGNIFICENT 7. Magni\ufb01cent 7 (M7) is a class of chained\nPoW which utilises seven hash functions to generate the\ncandidate hash during the mining process of Cryptonite\ncoin (not to be confused with the Cryptonight PoW al-\ngorithm) [143]. The utilised hash functions are SHA-256,\nSHA-512, Keccak, RIPEMD, HAVAL, Tiger and Whirlpool.\nInternally, the header of the candidate block sequentially\nhashed by the corresponding functions and then multiplied\nto generate the \ufb01nal hash, which is then compared against\nthe dif\ufb01culty threshold. Even though it a not memory-\nbound PoW, it has been claimed that the multiplication\noperation enables it to run on a general purpose CPU easily,\nhowever, makes it dif\ufb01cult to run on GPUs and ASICs\n[143]. Even so, there are is at least one GPU miner available\n13\nTable 7: Crypto-currencies utilising Ethash algorithm. The block rewards are in the corresponding currencies.\nCurrency\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply\n(Million)\nBlock Time\nEthereum [98]\n30.07.2015\n2\nin\ufb01nite supply\n10-20s\nEthereum Clas-\nsic [99]\n30.07.2015\n3.88\n10-20s\nUbiq [100]\n28.01.2017\n6\nNA\n88s\nShift [101]\n01.08.2015\n1\nin\ufb01nite supply\n27s\nExpanse [102]\n13.09.2015\n4\n31.4 Million\n1.0m\nDubaiCoin-\nDBIX [103]\n27.03.2017\n6\nTotal supply\n1.5m\nSOILcoin [104]\n03.10.2015\n3.0\nTotal supply\n52s\nKrypton [105]\n15.02.2016\n0.25\n2.67 Million\n1m 44s\nTable 8: Crypto-currencies utilising NeoScrypt and Timetravel 10 algorithms. The block rewards are in the corresponding\ncurrencies.\nCurrency\nAlgorithm\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply\n(Million)\nBlock Time\nRed Pulse [106]\n17.10.2017\nNA\n1.36 Billion\nNA\nFeathercoin [107]\nNeoScrypt\n16.04.2013\n40\n336 Million\n1.0m\nGoByte [108]\nNeoScrypt\n17.11.2017\n3.71\n31.8 Million\n2.5m\nUFO Coin [109]\nNeoScrypt\n03.01.2014\n625\n4 Billion\n1.5m\nInnova [110]\nNeoScrypt\n19.10.2017\n2.64\n1.29 Million\n2m\nVivo [88]\nNeoScrypt\n20.08.2017\n4.5\n1.1 Million\n2m18s\nDesire [113]\nNeoScrypt\nGenesis date\n10.45\n1.17 Million\n2.5m\nOrbitcoin [114]\nNeoScrypt\n28.07.2013\n0.5\n3.77 Million\n6.0m\nPhoenixcoin [115]\nNeoScrypt\n08.05.2013\n12.5\n98 Million\n1.5m\nBitcore [116]\nTimetravel 10\nApril 24, 2017\n3.13\n21 Million\n2.5m\nTable 9: Crypto-currencies utilising X11/X13 algorithms. The block rewards are in the corresponding currencies.\nCurrency\nAlgorithm\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply\n(Million)\nBlock Time\nDash [117]\nX11\nJanuary 19, 2014\n1.55\n22 Million\n2.5m\nStratis [118]\nX13\nAugust 09, 2016\nNA\nNA\nNA\nCloakcoin [119]\nX13\nGenesis date\n496.00\n4.5 Million\n1.0m\nStealthcoin [120]\nX13\nJuly 04, 2014\nNA\n20.7 Million\n1.0m\nDeepOnion [121]\nX13\nJuly 13, 2017\n4\n18.9 Million\n4m\nHTMLcoin [122]\nX15\nSeptember 12, 2014\nNA\n90 Billion\n1.0m\nRegalcoin [123]\nX11\nSeptember 28, 2017\nNA\n7.2 Million\nNA\nMemetic [124]\nX11\nMarch 05, 2016\nNA\nNA\nNA\nExclusiveCoin [125]\nX11\nJune 12, 2016\nNA\nNA\nNA\nCreditbit [126]\nX11\nNovember 02, 2015\nNA\n100 Million\n1.0m\nTable 10: Crypto-currencies utilising Quark algorithm. The block rewards are in corresponding currencies.\nCurrency\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply\n(Million)\nBlock Time\nQuark [67]\nJuly 21, 2013\n1\n247 Million\n0.5s\nPIVX [128]\nNA\n5\nNA\n1.0m\nMonetaryUnit [129]\nJuly 26, 2014\n18\n1 Quadrillion\n0.67m\nALQO [130]\nOctober 30, 2017\n3\nNA\n1m\nBitcloud [131]\nAugust 15, 2017\n22.5\n200 Million\n6.5m\nZurcoin [132]\nNA\n12.5\nNA\n0.75m\nAmsterdamCoin [133]\nNovember 01, 2015\n10\n84 Million\n1.0m\nAnimecoin [134]\nNA\nNA\nNA\nNA\nTable 11: Crypto-currencies utilising Lyra2RE algorithm. The block rewards are in corresponding currencies.\nCurrency\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply\n(Million)\nBlock Time\nVertcoin [135]\nJanuary 10, 2014\n25\n84 Million\n2.5m\nMonacoin [136]\nJanuary 01, 2014\n25\n105 Million\n1.5m\nCrypto [137]\nApril 30, 2015\nNA\n65.8 Million\n0.5m\nfor M7 [144]. Its performance, though, is not known. The\ncorresponding information for Cryptonite is presented in\nTable 12.\n5.1.4\nPoW Limitations\nPoW (Nakamoto) consensus algorithm has been widely\naccoladed for its breakthrough in the distributed consensus\n14\nTable 12: Information regarding Cryptonite utilising M7 algorithm.\nCurrency\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply\n(Million)\nBlock Time\nCryptonite\nJuly 28, 2014\nDynamic\n1.84 Billion\n1 Minute\n0\n10\n20\n30\n40\n50\n60\n70\n80\n2017-02-10\u2026\n2017-03-27\u2026\n2017-05-11\u2026\n2017-06-25\u2026\n2017-08-09\u2026\n2017-09-23\u2026\n2017-11-07\u2026\n2017-12-22\u2026\n2018-02-05\u2026\n2018-03-22\u2026\n2018-05-06\u2026\n2018-06-21\u2026\n2018-08-05\u2026\n2018-09-19\u2026\n2018-11-03\u2026\n2018-12-18\u2026\n2019-02-01\u2026\n2019-03-18\u2026\n2019-05-02\u2026\n2019-06-16\u2026\nEstimated TWh per Year\nMinimum TWh per Year\nFigure 8: Bitcoin energy consumption over the last years.\nparadigm, starting with Bitcoin. It had laid down the\nfoundation for the subsequent advancement, which resul-\nted in different PoW algorithms and crypto-currencies as\ndiscussed in the earlier sections. Even so, there are some\nsigni\ufb01cant limitations. Next, we brie\ufb02y discuss these limita-\ntions:\n\u2022 Energy consumption: Each PoW algorithm needs to\nconsume electricity to compute the hash. As the dif-\n\ufb01culty of the network starts to increase, so does the\nenergy consumption. The amount of consumed energy\nis quite signi\ufb01cant when calculated over the whole net-\nwork consisting of ASIC/GPU mining rigs all around\nthe world. Digiconomist 3 website tracks the electricity\nconsumption of Bitcoin and Ethereum. According do\nit, the energy consumption of Bitcoin and Ethereum\nare around 40 TWh (Tera-Watt Hour) and 10 TWh,\nrespectively. Their energy consumption graphs for the\nlast one year are presented in Figure 8 [148] and Figure\n9 [149].\nFigure 9: Ethereum energy consumption over the last year.\n3. https://digiconomist.net/\nTo put this into perspective, we present Figure 10,\nwhose data has been collected from [148]. This \ufb01gure\nillustrates Bitcoin\u2019s energy consumption relative to the\nelectricity consumption of different countries. For ex-\nample, the electricity consumed by Bitcoin in a year\ncould power up 6, 770, 506 American households and\nis much more than what Czech Republic consumes in\na year [148]. The utilisation of this huge amount of\nelectricity has raised the question of sustainability of\nPoW-based crypto-currencies.\nFigure 10: Bitcoin energy consumption relative to different\ncountries.\n\u2022 Mining centralisation: With the ever-increasing dif\ufb01-\nculty rate, miners within a PoW-based crypto-currency\nnetwork need to upgrade the capability of their AS-\nIC/GPU mining rigs to increase their chance of cre-\nating a new block. Even so, it becomes increasingly\ndif\ufb01cult for a single miner to join in the mining process\nwithout substantial investment in the mining rigs. The\nconsequence is that the economies of scale phenomenon\nstrongly impacts the PoW algorithms. The economies\nof scale in economic theory is the advantage a pro-\nducer can gain by increasing its output [150]. This\nhappens because the producer can spread the cost of\nper-unit production over a larger number of goods,\nwhich increases the pro\ufb01t margin. This analogy also\napplies to PoW mining as explained next. A mining\npool can be created where the mining resources of\ndifferent miners are aggregated to increase the chance\nof creating a new block. Once a mining pool receives\na reward for creating the next block, the reward is\nthen proportionally divided among the participating\nminers. Unfortunately, this has led to the centralisation\nproblems where block creations are limited among a\nhandful of miners. For example, Figure 11 illustrates\nthe distribution of network hashrate among different\nminers in Bitcoin [152]. As evident from the \ufb01gure, only\n\ufb01ve mining pools control the 75% of hashrate of the\n15\nwhole network. There is a fear that they could collude\nwith each other to launch the 51% attack to destabilise\nthe whole bitcoin network.\nKnown Blocks.\nRelayed By\ncount\nBTC.com\n74\nUnknown\n41\nF2Pool\n39\nPoolin\n38\nAntPool\n37\nSlushPool\n27\nBTC.TOP\n26\nViaBTC\n16\nAn estimation of hashrate\ndistribution amongst the largest mining pools\nThe graph below shows the market share of the most popular bitcoin mining pools. It should only be used as a\nrough estimate and for various reasons will not be 100% accurate. A large portion of Unknown blocks does not\nmean an attack on the network, it simply means we have been unable to determine the origin.\n24 hours - 48 hours - 4 Days\n27/07/2019, 10:08 pm\nFigure 11: Bitcoin hashrate distribution of mining pools.\n\u2022 Tragedy of commons: Many PoW algorithms suffer an\neconomic problem called the Tragedy of the commons. In\neconomic theory, the tragedy of the commons occurs\nwhen each entity rushes to maximise its pro\ufb01t from a\ndepleting resource without considering the well-being\nof all that share the same resource [151]. This situation\noccurs in a crypto-currency if it is de\ufb02ationary in nature\nwith limited supply, e.g. Bitcoin. It has been argued\nwhen the reward of creating a new block in Bitcoin\nwill reach nearly zero; the miners will have to solely\nrely on the transaction fees to cover their expenses.\nThis might create an unhealthy competition among the\nminers to include as many transactions as possible, just\nto maximise one\u2019s pro\ufb01t. The consequence of this is\nthat transaction fees will keep decreasing, which might\nlead to a situation that miners cannot make enough\npro\ufb01t to continue the mining process. Eventually, more\nand more miners will leave the mining process, which\nmight lead toward 51% attacks or other scenarios that\nde-stabilise the Bitcoin network.\n\u2022 Absence of penalty: All PoW algorithms (both com-\npute and memory bound) are altruistic in nature in\nthe sense that they reward behaving miners, however,\ndo not penalise a misbehaving miner. One example is\nthat a miner can collude with a group of miners (a\nphenomenon known as sel\ufb01sh mining) to increase its\npro\ufb01tability in an illegitimate way [153]. In addition,\na miner can engage in Denial-of-Service attack by just\nnot forwarding any transaction or block within the\nnetwork. Furthermore, such malicious miners can join\nforces to engage in the spawn-camping attack, in which\nthey launch DoS attacks simultaneously over and over\nagain to render the network useless for the corres-\nponding crypto-currency [156]. A penalty mechanism\nwould disincentivize any miner to engage in any type\nof malicious misbehave.\n5.1.5\nAnalysis\nIn this section, we summarise the properties of different\nPoW algorithms in Table 13, Table 14 and Table 15 utilising\nthe taxonomies presented in Section 4. In these tables, a\n\u2018\n\u2019 symbol is utilised to indicate if a particular property is\nsupported by the corresponding algorithm. For other prop-\nerties, explanatory texts have been used for any particular\nproperty.\nAs presented in Table 13, different types of PoW al-\ngorithms share exactly similar characteristics. In these al-\ngorithms, they are mainly two types of nodes: clients and\nminers. Miners are responsible for creating a block using\na randomised lottery mechanism. Conversely, clients are\nthe nodes that are responsible for validating each block as\nwell as utilised to transact bitcoin between different users.\nCommittees in these algorithms represent the set of miners,\nexhibiting the property of a single open committee structure\nwhere anyone can join as a miner. The respective committee\nis formed implicitly in a dynamic fashion, indicating any\nminer can join or leave whenever they wish.\nAs per Table 14, none of the algorithms requires any\nnode to be authenticated to participate in the algorithm. All\nof them have strong support for non-repudiation in the form\nof digital signature as part of every single transaction. These\nalgorithms have a high level of censorship resistance, which\nmeans that it will be dif\ufb01cult for any regulatory agency\nto impose any censorship on these algorithms. As for the\nattack vector, each PoW algorithm requires every miner\nnode to invest substantially for mining hardware in order\nto participate in these consensus algorithms. This feature,\nthus, acts as a deterrent against any Sybil or DoS attack in\nany PoW algorithm. The adversary tolerance is based on the\nassumption that PoW suffers from 51% attacks, and thus,\nadversary nodes need to have less than 50% of the total\nhashing power of the network.\nAccording to Table 15, these algorithms have low\nthroughput, and unfortunately, do not scale properly. Fur-\nthermore, most of the algorithms require a considerable time\nto reach \ufb01nality, and their energy consumption is consider-\nably high, as explained in Section 5.1.4. The fault tolerance in\nthese algorithms is 2f + 1 like any BFT algorithm, implying\nthey can achieve consensus as long as more than 50% of\nnodes function correctly.\n5.2\nProof of Stake\nTo counteract the limitations of any PoW algorithm, another\ntype of consensus algorithm, called Proof of Stake (PoS) has\nbeen proposed. The earliest proposal of a PoS algorithm\ncan be found on the bitcointalk forum in 2011 [154]. Soon\nafter, several projects started experimenting with the idea.\nPeercoin [72], released in 2012, was the \ufb01rst currency to\nutilise the PoS consensus algorithm.\nThe core idea of PoS evolves around the concept that the\nnodes who would like to participate in the block creation\nprocess must prove that they own a certain number of coins\nat \ufb01rst. Besides, they must lock a certain amount of its\ncurrencies, called stake, into an escrow account in order to\nparticipate in the block creation process. The stake acts as\na guarantee that it will behave as per the protocol rules.\nThe node escrows its stake in this manner is known as the\n16\nTable 13: Structural properties of PoW consensus algorithms.\nSingle committee\nNode type\nType\nFormation\nCon\ufb01guration\nMechanism\nClients & Miners\nOpen\nImplicit\nDynamic\nLottery, Randomised\nTable 14: Security properties of PoW consensus algorithms.\nAttack Vectors\nAuthentication\nNon-repudiation\nCensorship\nresistance\nAdversary tolerance\nSybil protection\nDoS Resistance\nx\nHigh\n2f + 1\nTable 15: Performance properties of PoW consensus algorithms.\nFault tolerance\nThroughput\nScalability\nLatency\nEnergy consumption\n2f + 1\nLow\nLow\nMedium-High\nHigh\nstakeholder, leader, forger, or minter in PoS terminology.\nThe minter can lose the stake, in case it misbehaves.\nIn essence, when a stakeholder escrows its stake, it\nimplicitly becomes a member of an exclusive group. Only a\nmember of this exclusive group can participate in the block\ncreation process. In case the stakeholder gets the chance to\ncreate a new block, the stakeholder will be rewarded in one\nof the two different ways. Either it can collect the transaction\nfees within the block, or it is provided a certain amount of\ncurrencies that act as a type of interest against their stake.\nIt has been argued that this incentive, coupled with any\npunitive mechanism, can provide a similar level of security\nof any PoW algorithm. Moreover, it can offer several other\nadvantages. Next, we explore a few bene\ufb01ts of a PoS mech-\nanism [156].\n\u2022 Energy Ef\ufb01ciency: A PoS algorithm does not require\nany node to solve a resource-intensive hard crypto-\ngraphic puzzle. Consequently, such an algorithm is\nextremely energy ef\ufb01cient compared to their PoW coun-\nterpart. Therefore, a crypto-currency leveraging any\nPoS algorithm is likely to be more sustainable in the\nlong run.\n\u2022 Mitigation of Centralization: A PoS algorithm is less\nimpacted by the economies of scale phenomenon. Since\nit does not require to build up a mining rig to solve\nany resource-intensive cryptographic puzzle, there is\nno way to maximise gain by increasing any output.\nTherefore, it is less susceptible to the centralisation\nproblem created by the mining pool.\n\u2022 Explicit Economic Security: A carefully designed pen-\nalty scheme in a PoS algorithm can deter any misbe-\nhaving attack, including spawn-camping. Anyone en-\ngaging in such attacks will lose their stake and might\nbe banned from any block creation process in the fu-\nture, depending on the protocol. This eventually can\nstrengthen the security of the system.\nInitial supply: One of the major barriers in a PoS\nalgorithm is how to generate the initial coins and fairly\ndistribute them among the stakeholders so that they can be\nused as stakes. We term this barrier as the bootstrap problem.\nThere are two approaches to address the bootstrap problem:\n\u2022 Pre-mining: A set of coins are pre-mined, which are\nthen sold before the launch of the system in an IPO\n(Initial Public Offering) or ICO (Initial Coin Offering).\n\u2022 PoW-PoS transition: The system starts with a PoW\nsystem to fairly distribute the coins among the stake-\nholders. Then, it slowly transitions towards the PoS\nsystem.\nReward process: Another important aspect is the re-\nwarding process to incentivise the stakeholder to take part\nin the minting process. Unlike any PoW, where a miner is\nrewarded with new coins for creating a valid block, there is\nno reward for creating a valid block. Instead, to incentivise\na minter, two types of reward mechanisms are available\nwithin a PoS algorithm:\n\u2022 Transaction Fee: The minter can collect fees from the\ntransactions included within the minted block.\n\u2022 Interest rate: A lower interest rate is con\ufb01gured, which\nallows the currency to in\ufb02ate over time. This interest\nis paid to the minter as a reward for creating a valid\nblock.\nSelection process: A crucial factor in any PoS algorithm\nis how to select the stakeholder who can mint the next block.\nIn a PoW algorithm, a miner is selected based on who can\n\ufb01nd the resource-intensive desired hash. Since PoS does not\nrely on hind such a hash as the mechanism to \ufb01nd the\nnext block, there must be a mechanism to select the next\nstakeholder.\nCurrently, there three different approaches to Proof of\nStake: Chained, BFT, and Delegated.\nCHAINED POS. The general idea of a chained PoS is to\ndeploy a combination of PoW and PoS algorithms chained\ntogether to achieve any consensus. Because of this, there\ncan be two types of blocks, PoW and PoS blocks, within\nthe same blockchain system. To accomplish this, the cor-\nresponding algorithm relies on different approaches to se-\nlect/assign a particular miner for creating a PoW block or\nselect a set of validators for creating a PoS block in different\nepochs or after a certain number of blocks created. In\ngeneral, a chain based PoS can employ any of the following\nthree different approaches to select the miner/stakeholder:\n\u2022 Randomised PoW Mining: A miner who can solve the\ncorresponding cryptographic PoW puzzle is selected in\na random fashion.\n\u2022 Randomised Stakeholder Selection: A randomised PoS util-\nises a probabilistic formula that takes into account the\n17\nstaked currencies and other parameters to select the\nnext stakeholder. The other parameters ensure that a\nstakeholder is not selected only based on the number of\ntheir staked coins and act as a pseudo-random seed for\nthe probabilistic formula.\n\u2022 Coin-age based selection. A coin-age is de\ufb01ned as the\nholding period of a coin by its owner. For example, if\nan owner receives a coin from a sender and holds it for\n\ufb01ve days then the coin-age of the coin can be de\ufb01ned\nas \ufb01ve coin-days. Formally,\ncoin \u2212age = coin \u2217holdingperiod\nAlgorithms belonging to this class select the stake-\nholder using staked coins of the stakeholders and their\ncorresponding coin-age.\nIn general, a chained PoS algorithm favours towards\navailability over consistency when network partition occurs,\nas per the CAP theorem.\nBFT POS. BFT PoS is a multi-round PoS algorithm. In the\n\ufb01rst step, a set of validators are pseudo-randomly selected to\npropose a block. However, the consensus regarding commit-\nting this block to the chain depends on the > 2/3 quorum\nof super-majority among the validators on several rounds. It\ninherits the properties of any BFT consensus, and as such, it\ntolerates up to 1/3 of byzantine behaviour among the nodes.\nIn general, a BFT PoS algorithm favours towards con-\nsistency over availability when network partition occurs,\nwithin the setting of CAP theorem.\nDELEGATED PROOF OF STAKE. Delegated Proof of Stake\n(or DPoS in short) is a form of consensus algorithm in which\nreputation scores or other mechanisms are used to select the\nset of validators [184]. Even though it has the name Proof of\nStake associated with it, it is quite different from other PoS\nalgorithms.\nIn DPoS, users of the network vote to select a group\nof delegates (or witnesses) who are responsible for creating\nblocks. Users utilise reputations scores or other mechanisms\nto choose their delegates. Delegates are the only entities\nwho can propose new blocks. For each round, a leader is\nselected from the set of delegates who can propose a block.\nHow such a leader is chosen depends on the respective\nsystem. The leader gets rewards for creating a new block,\nand is penalised and de-listed from the set of validators if it\nmisbehaves.\nThe delegates themselves compete with each other to get\nincluded in the validator list. In such, each validator might\noffer different levels of incentives for the voters who vote for\nit. For example, if a delegate is selected to propose a block,\nit might distribute a certain fraction of its reward among the\nusers who have selected it. Since the number of validators\nis small, the consensus \ufb01nality can be fast.\nNext, we explore several crypto-currencies or mechan-\nisms that use the above mentioned PoS approaches.\n5.2.1\nChained PoS\nNext, we present two examples of a chained PoS algorithm\nto illustrate how this approach has been applied in practice.\n1) PEERCOIN (PPCOIN). Peercoin is the \ufb01rst crypto-\ncurrency to formalise the notion of PoS by utilising a hybrid\nPoW-PoS protocol [174]. The Peercoin protocol is based on\nthe assumption that coin-age can be leveraged to create a\nPoS algorithm which is as secure as any PoW algorithm\nwhile minimising the disadvantages associated with a PoW\nalgorithm.\nPeercoin protocol recognises two different kinds of\nblocks: PoW blocks and PoS blocks, within the same block-\nchain. These blocks are created by two separate entities:\nminers and minters. Miners are responsible for creating\nPoW blocks, similar to Bitcoin whereas minters are respons-\nible for creating PoS blocks. Irrespective of the last block\ntype, the next block either can be a PoW block or a PoS\nblock, and these entities compete with each other to create\nthe next block [175]. Miners compete with other miners to\n\ufb01nd a valid PoW block that matches the PoW dif\ufb01culty\ntarget, similar to Bitcoin. Similarly, minters compete among\nthemselves to \ufb01nd a valid PoS block that matches the PoS\ndif\ufb01culty target (similar to a PoW algorithm but requires\nmuch less computation). As soon as any PoW or PoS block\nis found, it is broadcast to the network, and other nodes\nvalidate it.\nWithin a PoS block, a minter utilise their holding coins\nas a stake, and the minter is rewarded approximately 1%\nper annum based on the coin-age of the staked coins. The\nreward is paid out for each block in a newly created special\ntransaction called the coinstake transaction. Each coinstake\ntransaction consists of the number of staked inputs and a\nkernel, containing the hash that meets the PoS dif\ufb01culty.\nThe hash itself is calculated over a small space and hence\nnot computationally intensive at all. It utilises the number\nof staked inputs and a probabilistic variable, whereas the\ndif\ufb01culty condition is calculated utilising the coin-age of\nthe staked inputs as well as a dif\ufb01culty parameter. This\nparameter is adjusted dynamically to ensure that one block\nis created in 10 minutes. In other words, the valid kernel\ndepends on the coin-age of the staked inputs, and the higher\nthe coin-age, the higher is the probability to match the\ndif\ufb01culty.\nThe coinstake transaction is paid to the minter, which\ncontains the coins staked along with the reward. Once a\nPoS block is added to the chain, the coin-age of the staked\ncoins is reset to zero. This indicates that all the stacked coins\nare consumed. This ensures that the same coins cannot be\nused over and over again to create a PoS block within a\nshort period of time. The main chain in Peercoin is selected\nbased on the highest total coin-age consumed in all blocks.\nThat means, if a PoW block and PoS block are received\nsimultaneously as the next block by a node, the algorithm\ndictates the PoS block to be selected over the PoW block.\nThe block reward for a PoW block in Peercoin decreases\nand will cease to be signi\ufb01cant after a certain period of time.\nIt is currently used for the coin generation and distribution\npurpose and will be completely phased out in the future\n[205]. It has no role whatsoever on securing the network,\nwhich is largely based on the PoS algorithm. Once the PoW\nalgorithm is phased out, it is suggested that the energy\nconsumption of Peercoin will be signi\ufb01cantly low while\nproviding similar security as any PoW algorithm.\nPeercoin is highly regarded for formalising the \ufb01rst\nalternative mechanism to PoW, however, it suffers from all\nthe attack vectors of PoS, as presented in Section 5.2.4. Two\n18\nother coins Black and Nxt removes age from the equation\nin order to avoid the exploitation of the system by the\ndishonest entities having a signi\ufb01cant amount of coins.\n2) CASPER FFG. Casper the Friendly Finality Gadget\n(CFFG) is a PoW-PoS hybrid consensus algorithm proposed\nto replace the Ethereum\u2019s PoW consensus algorithm [181]. In\nfact, CFFG provides an intermediate PoS overlay on top of\nits current PoW algorithm so that Ethereum is transformed\nto a pure PoS protocol called Casper the Friendly Ghost\n(CTFG) described below (Section 5.2.2).\nThe PoS layer requires the participation of validators.\nAny node can become a validator by depositing some Eth-\nereum\u2019s native crypto-currency called Ether to a designated\nsmart-contract, which acts as a security bond. The network\nitself will mostly consist of PoW miners who will mine\nblocks according to its current PoW algorithm. However,\nthe \ufb01nalisation/check-pointing of blocks will be carried out\nby PoS validators. The check-pointing/\ufb01nalisation is the\nprocess to ensure that the chain becomes irreversible up\nto a certain block and thus, short and low range attacks\n(particular types of PoS only attacks presented in Section\n5.2.4) as well as the 51% attack cannot be launched beyond\nthe check-pointing block.\nThe check-pointing occurs every 50 blocks, and this\ninterval of 50 blocks is called an epoch [158]. The \ufb01nalisation\nprocess requires two rounds of voting in two successive\nepochs. The process is as follows. In an epoch, the validators\nvote on a certain checkpoint c (a block). A super-majority\n(denoted as +2/3) occurs when more than 2/3 of the valid-\nators vote for the checkpoint c. In such a case, the checkpoint\nis regarded as justi\ufb01ed. If in the next epoch, (+2/3) of the\nvalidators vote on the next checkpoint c\u2032 (a block which\nis a child of the block belonging to C), c\u2032 is considered\njusti\ufb01ed whereas c is considered \ufb01nalised. A checkpoint\ncreated in this manner for each epoch is assumed to create\na checkpoint tree where c\u2032 is a direct child of c. The process\ncan be summarised in the following way: +2/3 Vote c \u2192\nJustify c \u2192+2/3 Vote c\u2032 \u2192Finalize c and Justify c\u2032\nOnce a checkpoint is \ufb01nalised, the validators are paid.\nThe payment is interest-based and is proportional to the\nnumber of ethers deposited. If it occurs that there are two\ncheckpoints, it signi\ufb01es that a fork has occurred. This can\nonly happen when a validator or a set of validators has de-\nviated from the protocol. In such cases, a penalty mechanism\nis imposed in which the deposit of the violating validator(s)\nis destroyed.\nIn essence, CGGF is a combination of Chained and BFT\nconsensus mechanisms with strong support for availability\nover consistency. Its properties ensure that block \ufb01nalisation\noccurs quickly, and the protocol is mostly secure against all\nPoS attacks except the cartel formation attack (a particular\ntype for PoS only presented in Section 5.2.4). However, it is\nto be noted that this consensus mechanism has not been\nimplemented yet. Therefore, it is yet to be seen how it\nperforms in reality.\n5.2.2\nBFT PoS\nIn this section we describe three notable BFT PoS algorithms\nthat have had signi\ufb01cant uptake in practice: Tendermint,\nCTFG and Ouroboros.\n1) TENDERMINT. Tendermint is the \ufb01rst to showcase how\nthe BFT consensus can be achieved within the PoS setting\nof blockchain systems [178], [179], [180]. It consists of two\nmajor components: a consensus engine known as Tender-\nmint Core and its underlying application interface, called\nthe Application BlockChain Interface (ABCI). The Tendermint\ncore is responsible for deploying the consensus algorithm,\nwhereas the ABCI can be utilised to deploy any blockchain\napplication using any programming language.\nThe consensus algorithm relies on a set of validators. It is\na round-based algorithm where a proposer is chosen from\na set of validators. In each round , the proposer proposes\na new block for the blockchain at the latest height. The\nproposer itself is selected using a deterministic round-robin\nalgorithm, which ultimately relies on the voting power of\nthe validators. The voting power, on the other hand, is\nproportional to the security deposit of the validators.\nThe consensus algorithm consists of three steps (pro-\npose, pre-vote, and pre-commit) in each round bound by\na timer equally divided among the three steps, thus making\nit a weakly synchronous protocol. These steps signify the\ntransition of states in each validator. Figure 12 illustrates the\nstate transition diagram for each validator. At the beginning\nof each round, a new proposer is chosen to propose a new\nblock. The proposed block needs to go through a two-stage\nvoting mechanism before it is committed to the blockchain.\nWhen a validator receives the proposed block, it val-\nidates the block at \ufb01rst, and if okay, it pre-votes for the\nproposed block. If the block is not received within the\npropose timer or the block is invalid, the validator submits\na special vote called Prevote nil. Then, the validator waits\nfor the pre-vote interval to receive pre-votes from the super-\nmajority (denoted as +2/3) of the validators. A +2/3 pre-\nvotes signi\ufb01es that the super-majority validators have voted\nfor the proposed block, implying their con\ufb01dence on the\nproposed block and is denoted as a Polka in Tendermint\nterminology. At this stage, the validator pre-commits the\nblock. If the validator does not receive enough pre-votes for\nthe proposed block, it submits another special vote called\nPrecommit nil. Then, the validator waits for the pre-commit\ntime-period to receive +2/3 pre-commits from the super-\nmajority of the validators. Once received, it commits the\nblock to the blockchain. If +2/3 pre-commits not received\nwithin the pre-commit time-period, the next round is initiated\nwhere a new proposer is selected, and the steps are repeated.\nTo ensure the safety guarantee of the algorithm, Tender-\nmint is also coupled with locking rules. Once a validator\npre-commits a block after a polka is achieved, it must lock\nitself onto that block. Then, it must obey the following two\nrules:\n\u2022 it must pre-vote for the same block in the next round\nfor the same blockchain height,\n\u2022 the unlocking is possible only when a newer block\nreceives a polka in a later round for the same blockchain\nheight.\nWith these rules, Tendermint guarantees that the con-\nsensus is secure when less than one-third validators exhibit\nbyzantine behaviour, meaning con\ufb02icting blocks will never\nbe committed at the same blockchain height. In other words,\nTendermint guarantees that no fork will occur under this as-\nsumption. Since Tendermint favours safety over availability,\n19\nPropose\nPre-Vote Nil\nPre-commit Nil\nPropose Block\nNew \nHeight\nWait for \npre-\ncommits \nfrom +2/3\nPropose Block\nCommit\nNew Round\nWait for \npre-vote \nfrom +2/3\nValid block\nNo +2/3 pre-vote \nfor block\n+2/3 pre-vote \nfor block\n+2/3 pre-commit \nfor block\nNo +2/3 \npre-commit \nfor block\nInvalid block \nor not \nreceived \nin time\nFigure 12: Tendermint consensus steps.\nit has one particular weakness. It requires 100% uptime of\nits +2/3 (super-majority) validators. If more than one-third\n(+1/3) are validators are of\ufb02ine or partitioned, the system\nwill stop functioning [178]. In such cases, out-of-protocol\nsteps are required to tackle this situation.\nUnlike PoW or other PoS algorithms that come with\nde\ufb01ned reward mechanisms and crypto-currency applica-\ntions, the latest version of Tendermint more likely acts as the\nconsensus plugin, which can be retro-\ufb01t to other blockchain\nsystems. For example, Tendermint has been integrated with\na private instantiation of Ethereum in a Hyperledger project\ncalled Burrows [209]. That is why there is no reward/pun-\nishment mechanism de\ufb01ned in Tendermint. However, it can\nbe easily introduced in the application layer via the ABCI.\nFor example, a reward mechanism can be introduced for\nthe proposer and the validator to motivate them to engage\nin the consensus process. A node can become a validator by\nbonding a certain amount of security deposit. The deposit is\ndestroyed, in case the corresponding validator misbehaves,\nand thus acts as a deterrent for the validator to launch\nany attack in the network. Together with the consensus\nalgorithm and a carefully designed reward and punishment\nmechanism, all PoS attacks can be effectively handled.\n2) CASPER THE FRIENDLY GHOST (CTFG). CTFG is a pure\nBFT PoS algorithm that aims to transform Ethereum to a\nPoS-only blockchain system in the future [182]. As described\nabove, CFFG is geared towards a gentle transition from a\nPoW to a PoS model for Ethereum, where CTFG will take\ncontrol of the consensus mechanism ultimately.\nCTFG is based upon a rigorous formal model called\nCorrection by Construction (CBC) that utilises the GHOST\n(Greedy Heaviest-Observed Subtree) primitive as its con-\nsensus rule during fork [183]. The idea is that the CTFG\nprotocol will be partially speci\ufb01ed at the initial stage along\nwith a set of desired properties. Then, the rest of the protocol\nis dynamically derived in such a way that it satis\ufb01es the de-\nsired properties - hence the name correction by construction.\nThis is in contrast to the traditional approach for designing\na protocol where a protocol is fully de\ufb01ned at \ufb01rst, and then\nit is tested to check if it satis\ufb01es the desired properties [156].\nTo achieve this, CTFG introduces a safety oracle, acting\nas an ideal adversary, which raises exceptions when a fault\noccurs and also approximates the probability of any future\nfailure. Based on this, the oracle can dynamically \ufb01ne-tune\nthe protocol as required to evolve it towards its completion.\nSimilar to CFFG, CTFG also requires a set of bonded\nvalidators that will bond ethers as a security deposit in a\nsmart-contract. However, unlike any other PoS mechanisms,\nthe validators will bet on the block, which has the highest\nprobability to be included in the main chain according to\ntheir own perspective. If that particular block is included in\nthe main chain, the validators receive rewards for voting in\nfavour of the block. Otherwise, the validators receive certain\npenalties.\nLike any PoW algorithm, CTFG favours availability over\nconsistency. This means that blocks are not \ufb01nalised in-\nstantly, like Tendermint. Instead, as the chain grows and\nmore blocks are added, a previous block is considered impli-\ncitly \ufb01nal. A major advantage of CTFG over Tendermint is\nthat it can accommodate dynamic validators. This is because\nthe \ufb01nality condition in Tendermint requires that its block\ninterval is short, which in turn demands a relatively lower\nnumber of pre-determined validators. Since CTFG does not\nrely on any instant \ufb01nality, it can theoretically accommodate\na higher number of dynamic validators.\nCTFG is currently is the most comprehensive proposal\nwhich addresses all PoS attack vectors. However, it is to be\nnoted that this is just a proposal at the current stage. There-\nfore, its performance in real settings is yet to be analysed.\n3) OUROBOROS. Ouroboros is a provably secure PoS al-\ngorithm [185], [186] utilised in the Cardano platform [187].\nCardano is regarded as third-generation blockchain system\nsupporting smart-contract and decentralised application\nwithout relying on any PoW consensus algorithm.\nIn Ouroboros, only a stakeholder can participate in the\nblock minting process. A stakeholder is any node that holds\nthe underlying crypto-currency of the Cardano platform\ncalled Ada. Ouroboros is based on the concept of epoch,\nwhich is essentially a prede\ufb01ned time period. Each epoch\nconsists of several slots. A stakeholder is elected for each\nslot to create a single block, meaning a block is created in\neach slot. The selected stakeholder is called a slot leader and\nis elected by a set of electors. An elector is a speci\ufb01c type of\nstakeholder which has a certain amount Ada in its disposal.\nIn each epoch, the electors select the set of stakeholders\nfor the next epoch using an algorithm called Follow the\n20\nSatoshi (FTS). The FTS algorithm relies on a random seed\nto introduce a certain amount of randomness in the elec-\ntion process. A share of the random seed is individually\ngenerated by all electors who participate in a multiparty\ncomputation protocol. Once the protocol is executed, all\nelectors posses the random seed, constructed with all of\ntheir shares. The FTS algorithm utilises the random seed\nto select a coin for a particular slot. The owner of the coin is\nthen elected as the slot leader. Intuitively, the more coins a\nstakeholder possesses, the higher is its probability of being\nselected as the slot leader.\nOuroboros is expected to provide a transaction fee based\nreward to incentivise stakeholders to participate in the\nminting process. However, the details are in the process\nof being \ufb01nalised. It has been mathematically proven to\nbe secure against almost all PoS attack vectors except the\ncartel formation [185]. Nevertheless, how it will perform\nonce deployed is yet to be seen.\n5.2.3\nDPoS\nThere are several mechanisms deployed by different crypto-\ncurrencies under the general category of DPoS. Next, we\npresent a few prominent approaches of some well-known\nDPoS based crypto-currencies. Our analysis of these crypto-\ncurrencies are summarised in Table 16.\n1) EOS. EOS is the \ufb01rst and the most widely known\nDPoS crypto-currency and smart-contract platform as of\nnow [188]. With the promise of greater scalability and\nhigher transactions per second than Ethereum, it raised 4\nbillion USD in the highest ever ICO event to date [190].\nInitial EOS currency was created on the Ethereum platform,\nand later migrated to their own blockchain network. The\nDPoS consensus algorithm of EOS utilises 21 validators,\nalso known as Block Producers (BPs). These 21 validators are\nselected with votes from EOS token (currency) holders. The\nnumber of times a particular BP is selected to produce a\nblock is proportional to the total votes received from the\ntoken holders.\nEvey DPoS currency must create an initial supply before\nthe network is operational. This supply is used to select 21\nBPs (with voting) as well as to reward the BPs for creating\nblocks, and thus, securing the network. EOS had an initial\nsupply of 1 Billion EOS tokens with an annual in\ufb02ation of\n5%. Among the in\ufb02ated currencies, 1% is used to reward\nthe block producers, whereas the rest of the 4% are kept\nfor future R&D for EOS [191]. Currently, an EOS block is\ncreated in 0.5s. Blocks in EOS are produced in rounds where\neach round consists of 21 blocks [192]. At the beginning of\neach round, 21 BPs are selected. Next, each of them gets a\nchance to create a block in pseduo-random fashion within\nthat particular round. Once a BP produces a block, other\nBPs must validate the block and reach into a consensus. A\nblock is con\ufb01rmed only when (+2/3) majority of the BPs\nreach the consensus regarding the validity of the block. Once\nthis happens, the block and the associated transactions are\nregarded as con\ufb01rmed or \ufb01nal, so no fork can happen.\n2) TRON. Tron is another popular DPoS based crypto-\ncurrency [193]. With an initial supply of 99 Billion Tron\ntokens (represented with TRX), it is another smart-contract\nsupported blockchain platform, very similar to Ethereum\nand EOS in functionality. Its consensus mechanism utilises\n27 validators, known as Super Representatives (SRs) [194].\nThe SRs are selected in every six hours with votes by TRX\nholders who must freeze a certain amount of TRX to vote for\nan SR. The deposits amount can be frozen back after three\ndays once the voting is cast [195]. A block in Tron is created\nin every 3s for the corresponding SR receives a reward of 32\nTRX. Another important feature of Tron is that there is no\nin-built in\ufb02ation mechanism in the protocol, which implies\nthat the total supply will remain constant throughout its\nlifespan.\n3) TEZOS. Tezos is, like EOS and Tron, a smart-contract plat-\nform which utilises a variant of DPoS consensus algorithm\n[196]. With a block reward of 16 XTZ (Tezos currency) and\nblock creation time of 60s, Tezos does not require any pre-\nde\ufb01ned number of stakeholders (or Bakers as de\ufb01ned in\nTezos) [197]. This differs Tezos from other DPoS currencies.\nInstead, the consensus mechanism utilises a dynamic range\nof stakeholders where anyone holding a substantial amount\nof XTZ can be a stakeholder. This limits general users\nto participate in the consensus mechanism. To rectify this\nproblem, Tezos provides a mechanism by which anyone can\ndelegate their XTZ to someone so that it can accumulate the\nrequired number of XTZ to be a baker. In return, the baker\nwould return a certain proportion of their received block\nreward to the delegating party. Tezos started with an initial\nsupply of 765 Million XTZ tokens. It relies on an annual\nin\ufb02ation of 5.51% and the in\ufb02ated currencies are used to\nreward the bakers.\n4) LISK. Lisk is a unique DPoS blockchain platform which,\nenables the development of DApps using JavaScript [200].\nAnother unique feature of Lisk is its ability to accommodate\nand then to operate with multiple blockchains, known as\nsidechains along with a central blockchain called mainchain.\nEach sidechain can be deployed and maintained by a\nparticular application provider, which needs to be synced\nwith the mainchain as per the Lisk\u2019s protocol rule. In this\nway, different applications can leverage different sidechains\nsimultaneously without burdening off the mainchain. Even\nthough the responsibility of maintaining a sidechain relies\non the particular application provider, the mainchain must\nbe maintained with the Lisk DPoS consensus protocol,\nwhich utilises 101 delegates [201]. Only these delegates can\nproduce a block. These delegates are selected using votes\nfrom Lisk currency (denoted with LSK) owners, where\neach holder has 101 votes. The weight of each vote is\nproportional to the amount of LSK owned by the respective\nowner. The selection of delegates happens before a round,\nwhere each round consists of 101 block generation cycle.\nThus, in a round, each delegate is randomly selected to\ncreate a block. It has a block creation time of 10 seconds\nand block reward of 5 LSK. Started with an initial supply\nof 100 million LSK, Lisk has a current supply of 132 million\nwith an annual in\ufb02ation of 5.65%.\n5) ARK. Ark is yet another DPoS based blockchain platform\n[202]. It utilises 51 delegates to create 51 blocks in each\nround [203]. With a block creation time of 8s, each round\nlasts for 408s. Each delegate receives 2 ARK (the native\ncurrency of the ARK platform) for creating a block. It had\n21\nan initial supply of 125 million. With an annual in\ufb02ation\nof 5.55, the supply was around 142 million (as of June\n2019). Like other DPoS blockchains, the delegates in Ark\nare also selected with votes by Ark currency owner, where\nthe weight of each is proportional to the amount of ARK\nowned by the voter.\n5.2.4\nLimitations of PoS\nEven though the variants of different PoS algorithms offer\nseveral signi\ufb01cant advantages, there are still a few disad-\nvantages in these classes of algorithms. We explore these\ndisadvantages below.\n\u2022 Collusion: If the number of validators is not large\nenough, it might be easier to launch a 51% attack on the\ncorresponding consensus algorithm by colluding with\nother validators.\n\u2022 Wealth effect: The sole reliance on coin-wealth in a\nconsensus algorithm or for the selection of validators\ncreates an environment where people with a large por-\ntion of coins can exert greater in\ufb02uence.\nIn addition to these disadvantages, there have been a few\nother attack vectors identi\ufb01ed for the PoS algorithms:\n\u2022 Nothing-at-stake (NAS) attack [157]: During a block-\nchain fork, an attacker might attempt to add its newly\ncreated block in all forked branches to increase their\nprobability to add their block as the valid block. Such\nscenario is unlikely to occur in any PoW algorithm.\nThis is because a miner would need to share their\nresources in order to mine at different branches. This\nwould eventually decrease their chance of \ufb01nding a\nnew block because of the resources shared in multiple\nbranches. Since it does not cost anything for a minter\nin a PoS algorithm to add blocks in multiple parallel\nbranches, the attacker is motivated to do so. Applying\na penalty for such misbehaviour could effectively tackle\nthis problem.\n\u2022 Bribing (short-range, SR) attack [157], [176]: In this\nattack, an attacker tries to double spend by creating a\nfork. An example of this attack would be as follows. The\nattacker pays to a seller to buy a good. The seller waits\nfor a certain number of blocks (e.g., six blocks) before\nthe good is delivered to the attacker. Once delivered,\nthe attacker forks the main chain at the block (e.g., six\nblocks back, which is relatively short and hence the\nname) in which the payment was made. Then, the at-\ntacker bribes other minters to mint on top of the forked\nbranch. As long as the bribed amount is lower than\nthe price of the delivered good, it is always pro\ufb01table\nfor the attacker. The colluding minter has nothing to\nlose if it is coupled with the nothing-at-stake attack on\ntheir part but can gain from the bribery. Again, it can\nbe tackled by introducing a penalty mechanism for all\nmisbehaving parties.\n\u2022 Long-range (LR) attack [157]: In this attack, the attacker\nattempts to build an alternative blockchain starting\nfrom the earliest blocks if the attacker can collude with\nthe majority of the stakeholders. The motivation might\nbe similar to double spending or related issues provid-\ning advantages to the attacker as well as the colluded\nstakeholders. As explained above, the colluded stake-\nholder has nothing to lose if it can be coupled with the\nnothing-at-stake attacks. Check-pointing is one of the\nmethods by which it can be tackled. The check-pointing\ncodi\ufb01es a certain length of the blockchain to make it\nimmutable up to that point, and thereby undermining\nthe attack. This is because the attacker cannot fork the\nblockchain before that check-point.\n\u2022 Coin-age accumulation (CAC) attack [157], [176]: The\nPoS algorithms that rely on the uncapped coin-age\nparameter are susceptible to this attack. In this attack,\nthe attacker waits for their coins to accumulate enough\ncoin-age to exploit the algorithm for launching double\nspends by initiating a fork. This attack can be tackled\nby introducing a cap on the coin-age which minimises\nthe attack vector.\n\u2022 Pre-computing (PreCom) attack [157], [155]: A pre-\ncomputing attack, also known as Stake-grinding attack,\nwould allow an attacker to increase the probability of\ngenerating subsequent blocks based on the information\nof the current block. If there is not enough randomness\nincluded in the PoS algorithm, the attacker can attempt\nto pre-compute subsequent blocks by \ufb01ne-tuning in-\nformation of the current block. For a particular set of\ninformation (e.g., a set of transactions), if the attacker\n\ufb01nds that the probability of minting a few subsequent\nblocks is less than desired, the attacker can update\nthe set of transactions to increase their probability of\ndetermining the next few blocks. It can be effectively\ntackled by introducing a secure source of randomness\nin the algorithm.\n\u2022 Cartel formation (CAF) attack [158]: In economic the-\nory, an oligopoly market is dominated by a small set of\nentities having greater in\ufb02uence or wealth than other\nentity. They can collude with one another by forming a\ncartel to control price or reduce competition within the\nmarket. It has been argued that \u201dBlockchain architecture\nis mechanism design for oligopolistic markets.\u201d [159] which\naffects both PoW and PoS algorithms. Such a cartel can\nlaunch 51% attacks on the PoS algorithm or exploit the\nstakes to monopolise the PoS algorithm.\n5.2.5\nAnalysis\nIn this section, we summarise the properties of different\nPoS algorithms utilising the taxonomies and PoS attack\nvectors in Table 17, Table 18, Table 19 and Table 20. Like\nbefore, a \u2018\n\u2019 symbol has been utilised to indicate if the\ncorresponding algorithm supports a particular property,\nand the \u2018X\u2019 symbol signi\ufb01es that the particular property\nis not supported. The \u2018-\u2019 symbol implies that the property\nis not applicable, whereas the symbol \u2018?\u2019 indicates that no\ninformation has been found for that particular feature. For\nother properties, explanatory texts have been used as well.\nFrom Table 17, only chained algorithms are based on\nmultiple committee utilising a \ufb02at topology with a dynamic\ncon\ufb01guration. These algorithms also use a probabilistic lot-\ntery to select a minter. Conversely, other PoS algorithms, ex-\ncept Tendermint, are based on the single committee having\nan open type and explicit formation with a dynamic con\ufb01g-\nuration and mostly rely on voting mechanisms. Tendermint\nuses a closed committee with a static con\ufb01guration.\nAs per Table 18, none of the algorithms, except Tender-\nmint requires any node to be authenticated to participate\n22\nTable 16: Comparison of DPoS Currencies with \u2018-\u2019 signifying not applicable.\nCurrency\nGenesis date\n(dd.mm.yyyy)\nInitial supply\nIn\ufb02ation\nCurrent supply\n(23.05.2019)\nBlock reward\nBlock Time\nValidator\nnos\nEOS\n01.07.2017\n1 Billion\n5%\n1.04 Billion\n1%\nof\nin\ufb02ated\ncurrency\ndivided\namong\n21\nvalidators\n0.5s\n21\nTron\n28.08.2017\n99 Billion\n-\n99 Billion\n32 TRX\n3s\n27\nTezos\n30.06.2018\n765 Million\n5.51%\n795 Million\n16 XTZ\n60s\nNot\npre-\nde\ufb01ned\nLisk\n24.05.2016\n100 Million\n5.67%\n132 Million\n5 LSK\n10s\n101\nArk\n21.03.2017\n125 Million\n5.55%\n142 Million\n2 ARK\n8s\n51\nin the algorithm. All of them have strong support for non-\nrepudiation in the form of digital signature as part of every\nsingle transaction. These algorithms have a high level of\ncensorship resistance, as do all PoW algorithms. As for\nthe attack vector, each PoS algorithm requires every miner\nnode to invest substantially to participate in this algorithm.\nThis feature, thus, acts as a deterrent against any Sybil or\nDoS attack in any PoS algorithm. The adversary tolerance\nfor Chained systems can be calculated using this formula:\nmin(2f + 1, 3f + 1) = 3f + 1. This is because a chained\nalgorithm utilises both PoW and PoS algorithms and thus\nneeds to consider the adversary tolerance for both of them.\nWe consider the minimum of these two (3f + 1). The\nsupported adversary tolerance for other algorithms is 3f +1\nexcept BFT Ouroboros whose adversary tolerance is 2f + 1.\nAccording to Table 20, all BFT, and DPoS algorithms\nhave considerably high throughput, low latency, and high\nscalability. Their energy consumption is negligible. How-\never, the chained algorithms have a comparatively lower\nthroughput, lower scalability, and higher latency with re-\nspect to their BFT and DPoS counterparts. The fault toler-\nance of chained and BFT algorithms is 2f + 1 like any BFT\nalgorithm, implying they can achieve consensus as long as\nmore than 50% of nodes function properly. However, DPoS\nalgorithm requires a 3f + 1 fault tolerance.\nTable 19 outlines a comparison of additional attack vec-\ntors with symbols representing the usual semantics. CTFG,\nTentermint, and Ouroboros have mitigation mechanisms\nagainst these attack vectors. However, Casper FFG, and\nany DPoS algorithms cannot successfully defend against\nthe cartel formation attack. Peercoin, on the other hand,\nhas mechanism against this cartel formation attack, unfor-\ntunately, suffers from all other attack vectors.\nFinally, a comparison of the selected DPoS crypto-\ncurrencies is presented in Table 16.\n6\nINCENTIVISED CONSENSUS: BEYOND POW AND\nPOS\nSome consensus algorithms take a different approach in\nwhich they do not solely rely on any PoW or PoS mech-\nanism. Instead, they use an approach in which a PoW/-\nPoS mechanism is combined with another approach. We\nconsider such algorithms as hybrid algorithms which are\npresented in Section 6.1. Other approaches adopt a more\ndrastic approach in which they do not leverage any\ntype PoW/PoS algorithm whatsoever. Such algorithms are\ntagged as N-POS/POW (to symbolise Non-PoS/PoW) al-\ngorithms and discussed in Section 6.2.\n6.1\nHybrid Consensus\nIn this section, we outline a new breed of consensuses\nalgorithms that combine either a PoW or PoS algorithm\nor both with another novel algorithm or mechanism, thus\ncreating a hybrid mechanism.\n1) PROOF OF RESEARCH (POR). Proof of research is a\nhybrid approach that combines proof-of-stake with the\nproof-of-BOINC [160]. BOINC stands for Berkeley Open\nInfrastructure for Network Computing [162]. It is a grid\ncomputing platform widely used by scienti\ufb01c researchers\nin different domains by allowing them to exploit the idle\ncomputing resources of personal computers around the\nworld. With the proof-of-BOINC, a researcher has to prove\nhis contribution for the BOINC research work.\nThe PoR mechanism is leveraged by Gridcoin [160],\n[161], a crypto-currency that can be earned by anyone by\nsharing their computing resources with the BOINC pro-\nject. The mechanism by which PoS and Proof-of-BOINC\nare tied together for the PoR is explained next [161]. The\nPoS mechanism is similar to the traditional PoS algorithm.\nAnyone can become a minter, known as Investor in Gridcoin\nterminology, by owning a certain amount of Gridcoin and\nparticipating in the minting process. In addition to this,\nother users, known as Researchers in Gridcoin terminology,\ncan also participate in the minting process. Interestingly, an\ninvestor can also be a researcher and thus, can increase their\namount of grid coin earned.\nFor this, a researcher installs the BOINC software and\nregisters a project from the BOINC whitelist with his email\naddress. The researcher is assigned a unique cross project\nidenti\ufb01er (CPID) and starts downloading the work share.\nOnce the computation is completed, the researcher returns\nthe result with a credit recommendation for the completed\nworkload. The recommendation is compared with that of\nanother researcher, and the minimum credit is rewarded.\nThis workload credit data is stored in the header of each\nblock and the researcher is rewarded with the corresponding\namount of Gridcoin. To summarise, the consensus mechan-\nism is mostly dominated by the PoS mechanism with Proof-\nof-BOINC acts as a reward mechanism for sharing unused\ncomputing resources available to the researchers. Hence, its\nsecurity is similar to that of the traditional PoS algorithm.\n2) SLIMCOIN\u2019S PROOF-OF-BURN (POB). The Proof-of-Burn\nis a consensus algorithm proposed by Ian Stewart as an\n23\nTable 17: Comparing structural properties of PoS Consensus Algorithms.\nSingle committee\nMultiple committee\nConsensus\n/System\nNode type\nType\nFormation\nCon\ufb01guration\nTopology\nCon\ufb01guration\nMechanism\nChained\n(PeerCoin)\nClients, Miners\n& Minters\n-\n-\n-\nFlat\nDynamic\nProbabilistic lottery\nChained\n(CFFG)\nClients, Miners\n& Validators\n-\n-\n-\nFlat\nDynamic\nProbabilistic lottery\nBFT\n(Tendermint)\nClients &\nValidators\nOpen (Close)\nExplicit\nDynamic (Static)\n-\n-\nVoting\nBFT (CTFG)\nClients &\nValidators\nOpen\nExplicit\nDynamic\n-\n-\n?\nBTFG\n(Ouroboros)\nClients,\nElectors &\nStakeholders\nOpen\nExplicit\nDynamic\nVoting\nDPoS\nClients &\nValidators\nOpen\nExplicit\nDynamic\n-\n-\nVoting\nTable 18: Comparing security properties of PoS Consensus Algorithms.\nAttack Vectors\nConsensus\n/System\nAuthentication\nNon-repudiation\nCensorship\nresistance\nAdversary tolerance\nSybil protection\nDoS Resistance\nChained\n(PeerCoin)\nX\nHigh\n3f + 1\nChained\n(CFFG)\nX\nHigh\n3f + 1\nBFT\n(Tendermint)\n(In close\ntype), X (In\nopen type)\nHigh\n3f + 1\nBFT (CTFG)\nX\nHigh\n3f + 1\nBFT\n(Ouroboros)\nX\nHigh\n2f + 1\nDPoS\nX\nHigh\n3f + 1\nTable 19: Comparison of additional attack vectors protection among PoS Consensus Algorithms\nConsensus\\System\nNothing-at-Stake\nBribing\nLong-range\nCoin-age\nPre-computing\nCartel formation\nChained (PeerCoin)\nX\nX\nX\nX\nX\nChained (Casper FFG)\nX\nBFT (Tendermint)\nBFT (CTFG)\nBFT (Ouroboros)\nDPoS\nX\nTable 20: Comparing performance properties of PoS Consensus Algorithms.\nConsensus\\System\nFault\ntolerance\nThroughput\nScalability\nLatency\nEnergy consumption\nChained (PeerCoin,\nCFFG)\n2f + 1\nMedium\nMedium\nMedium\nMedium\nBFT (Tendermint,\nCTFG, Ouroboros)\n2f + 1\nHigh\nHigh\nLow\nLow\nDPoS\n3f + 1\nHigh\nHigh\nLow\nLow\nalternative to PoW [163]. In PoW, miners need to invest in\nbuilding a mining rig in order to participate in the mining\nprocess. In PoB, miners need to burn their coins in order to\nparticipate in the mining process. Burning coins mean that\nsending coins to an address without the private key and\nthus never usable. Thus, burning coins is an analogous idea\nto the investment for building a mining rig. The amount\nof burning has a positive correlation with the possibility\nof being selected for mining the next block. This is similar\nto the PoW system, where the miners increasingly invest\nin modern equipment to maintain the hash power, as the\nincentive decays with the complexity.\nSlimcoin is a crypto-currency which utilises the idea of\nPoB in combination with PoW and PoS [164], [165], thus\ncreating a hybrid consensus mechanism. Algorithmically,\ntheir idea is similar to the chained PoS algorithm of Peercoin\nas presented in in Section 5.2.1 with additional PoB mech-\nanism sandwiched in between PoW and PoS algorithms.\nThe PoW is used to generate the initial coin supply using\nthe mechanism of Bitcoin. When the system has suf\ufb01cient\namount of money supply, it plans to switch to a hybrid of\nPoW and PoS mechanism similar to Peercoin where PoB will\nbe used to select the miner. As this happens, the minters\nwill need to burn their accumulated coins in order to be\neligible to participate in the PoS minting process. Since PoB\n24\nalgorithm is mostly used for minter selections, it has hardly\nany effect on the security of the system. Hence, its security\nand other properties are mostly similar to that of Peercoin.\n3) PROOF OF STAKE-VELOCITY (POSV). One of the major\nlimitations of coin-age based PoS is that there is no incentive\n(or lack of penalty thereof) for the minters to be online to\nparticipate in the staking process. This is because that the\ncoin-age increases linearly over time, without the need for\nthe stakeholders to be online and participate in the staking\nprocess. They can, therefore, choose to participate for a short\nperiod and then collect the reward and may go of\ufb02ine again.\nThe lack of participants may facilitate attacks at a certain\ntime.\nTo counteract this problem, a crypto-currency called\nReddcoin proposed a novel hybrid algorithm called Proof of\nStake-Velocity (PoSV) [166], [168]. The central to the PoSV is\nthe idea of a mechanism called the velocity of stakes coupled\nwith any traditional PoS algorithm. Conceptually, the velo-\ncity of stake mirrors the notion of the velocity of money,\na terminology from Economics implying the frequency of\nmoney \ufb02ow within the society [169]. Indeed, the velocity\nof stakes evolves around the idea of increasing the \ufb02ow of\nstakes during the PoS consensus mechanism [167]. This (the\n\ufb02ow of stakes) can be achieved if the minters are encour-\naged to actively participate in the consensus mechanism by\nstaking their crypto-currency, instead of holding their coins\nof\ufb02ine. This process in a way will also increase the overall\nsecurity of the system and counteract the lack of participant\nissue in PoS.\nTo facilitate this PoSV introduces a non-linear coin-\nageing function in which the coin-age of a particular coin\nis gained much faster in the \ufb01rst few days and weeks than\nthe gain in later weeks. For example, it has been estimated\nthat minters who stake their coins every two weeks or less,\ncan earn up to 20% more than people who do not participate\nin the staking process [167]. Such incentives encourage the\nminters to increase the velocity of stakes in the whole\nnetwork. Note that PoSV is similar to any PoS mechanism\nalong with its properties and hence, not explored in detail\nhere.\n6.2\nN-POS/POW\nThe consensuses algorithms presented in this category do\nnot rely any way on either PoW or PoS algorithms. Instead,\nthey rely on completely novel mechanisms. Therefore, we\ncall them N-POS/PoW algorithms for the convenience of\ngroup naming.\n1)\nPROOF-OF-COOPERATION\n(POC).\nThe\nProof-of-\nCooperation is a consensus algorithm introduced by the\nFairCoin\ncrypto-currency\n[170],\n[171].\nThis\nconsensus\nalgorithm relies on several special nodes known as Certi\ufb01ed\nValidating Nodes (CVNs). CVNs function similar to the way\nvalidators act in a DPoS consensus algorithm as utilised by\nEOS or Tron crypto-currencies, as they are nodes which can\ncreate blocks in Faircoin using the PoC consensus algorithm.\nHowever, unlike any DPoS validators, each CVN node is\nauthenticated by their corresponding Faircoin identi\ufb01er as\nwell as trusted following a set of community-based rules\nand technical requirements [171]. The community rules\nstate that a candidate node willing to be a CVN must\nparticipate in Faircoin community activities by performing\nsome tasks. Examples of these tasks are running a local\nnode or contributing to any technical or management issue\nrelated to Faircoin which must be con\ufb01rmed by at least two\nactive members of the community. Besides, the candidate\nnode must follow a set of technical requirements such\nas 24/7 network availability and a special cryptographic\nhardware used for signature generation.\nWith the involvement of CVNs selected in the previously\ndiscussed manner, the core mechanism for PoC consensus\nalgorithm is brie\ufb02y discussed next. Blocks in Faircoin are\ncreated in a round-robin fashion in every three minutes\nof epoch by one of the CVNs. To create a new block,\na CVN needs to be selected using a deterministic voting\nmechanism individually carried out by every single CVN in\nthe network. The steps of this mechanism are:\n\u2022 Each CVN \ufb01nds the CVN, which has created a block\nfurthest in the chain by traversing backwards through\nthe chain.\n\u2022 Next, it is checked if the found CVN has been active\nrecently in the network by looking for its signature in\nthe last few blocks. If so, this CVN will be selected as\nthe next CVN.\n\u2022 Then, each node creates a data set consisting of the hash\nof the last block, the ID of the selected CVN for the next\nblock, and its own CVN ID, which is then signed by the\nspeci\ufb01ed cryptographic hardware. The created dataset,\nalong with the signature, is then propagated through\nthe network.\n\u2022 The selected CVN receives this dataset along with their\nsignature from multiple CVNs and veri\ufb01es each signa-\nture. As soon as the selected CVN \ufb01nds that more than\n50% CVNs have selected it to be the next block creator,\nit can be certain that its turn is next at the end of the\ncurrent epoch, i.e., three minutes.\n\u2022 The selected CVN adds all pending transactions into a\nnew block, along with all the received signatures, and\npropagates the block in the network.\n\u2022 Upon receiving the block, other CVNs verify the block\nby checking the if the CVN who created the block is\nactually the one selected as the block creator as well\nas validating all signatures in it and its transactions. If\nthe veri\ufb01cation is successful, the block is added to the\nblockchain and the same mechanism continues.\n2) PROOF OF IMPORTANCE (POI). PoS gives an unfair\nadvantage to coin hoarders. The more coins they keep in\ntheir accounts, the more they earn. This means the rich get\nricher and everyone has an incentive to save coins instead of\nspending them. To solve these issues NEM has introduced\na novel consensus mechanism called \u201cProof of Importance\n(PoI)\u201d [172]. It functions similarly to PoS: nodes need to\n\u2019vest\u2019 an amount of currency to be eligible for creating blocks\nand are selected for creating a block roughly in proportion to\nsome score. In Proof-of-stake, this \u2019score\u2019 is one\u2019s total vested\namount, but in PoI, this score includes more variables. All\nthe nodes that have more than 10000 XEM (the correspond-\ning crypto-currency of XEM) are theoretically given equal\npositive importance and with 9B XEM coins there can be\nmaximum 900K such nodes. However, the actual number\nof such nodes and their importance vary with time and their\n25\namount of transaction in XEM.\nThe calculations borrow from the math of network clus-\ntering and page ranking. At a high level, the primary inputs\nare:\n\u2022 Net transfers: how much has been spent in the past\n30 days, with more recent transactions weighted more\nheavily.\n\u2022 Vested amount of currency for purposes of creating\nblocks.\n\u2022 Cluster nodes: accounts that are part of interlinked\nclusters of activity are weighted slightly more heavily\nthan outliers or hubs (which link clusters but not part\nof them).\nIn NEM, the importance of an account depends only\non the net transfers of XEMs from that account. To be\nconsidered for the importance estimation at a certain block\nheight, h , a node must have transferred at least 100 XEMs\nduring the last 30 days or 43, 200 blocks. The \u201cimportance\nscore\u201d addresses two primary criticisms of proof-of-stake.\nOne risk is that people hoard many coins as possible\nand reap the rewards from block creation. This concentrates\nwealth while discouraging transactions. The importance\nscore means that hoarding will result in a lower score while\nspreading XEM around will increase it. Being a merchant\npays better than having a hoard.\n6.3\nAnalysis\nIn this section, we summarise the properties of different Hy-\nbrid and N-Pow/PoS algorithms utilising the taxonomies in\nTable 21, Table 22, Table 23 and Table 24. Like before, \u2018-\u2019\nsigni\ufb01es that the corresponding property is not applicable\nfor the respective consensus algorithm, \u2018?\u2019 indicates that the\ninformation the property has not been found, a \u2018\n\u2019 is used\nto indicate an algorithm satis\ufb01es a particular property and\n\u2018X\u2019 is used to imply the reverse (not satis\ufb01ed).\nTable 21 presents the comparison of structural properties\nfor the corresponding consensus algorithms. Among them,\nPoR and PoB depend on a multiple committee formation\nwith a \ufb02at topology and dynamic con\ufb01guration. Conversely,\nPoSV and PoI use an open single committee with a dynamic\ncon\ufb01guration, and probabilistic lottery as their underlying\nmechanism. PoC has an implicit, open, and dynamic single\ncommittee, which relies on voting mechanism.\nAll these algorithms have an adversary tolerance of\n3f +1 with the support of non-repudiation, Sybil protection,\nDoS resistance, and high censorship resistance as reported\nin Table 22. Entities in PoB, PoSV, and PoI do no require to be\nauthenticated while PoC entities must be authenticated, and\nresearchers in PoR need to be authenticated. However, other\nentities in PoW can remain non-authenticated, as indicated\nwith the \u2018X\u2019 symbol in the table. All of them except PoC\nand PoI have 3f + 1 adversary tolerance because of their\nusage of PoS algorithms. We have not found any regarding\nadversary tolerance for PoC and PoI.\nTable 23 presents the comparison of some additional\nattack vectors for the Hybrid algorithms. As evident from\nthe table, since these algorithms utilise PoS as one of their\nconsensus algorithms, they suffer from the similar limita-\ntions of any PoS algorithm. For example, none of them has\nany guard against most of these additional attack vectors.\nThe only exception is PoB which is because of its use of\nPeercoin like functionality, can resist the cartel formation\nattack.\nThe comparison of the performance properties for these\nalgorithms is presented in Table 24. All of them have 2f + 1\nfault tolerance except PoC and PoI as we have not found\nany information fault tolerance for PoC and PoI. In terms of\nScalability, Latency and Energy, every algorithm except PoB\nexhibits similar characteristics: they have high throughput,\nconsume low energy, and have low latency, meaning they\nreach \ufb01nality quickly. Because of its reliance on PoW, PoB\nhas low scalability, low latency, and also consume meidum\nenergy. In terms of throughput, PoR, PoSV and PoI have\nhigh throughput, whereas PoC has a low throughput and\nPoB has a medium throughput.\nFinally, a comparison of the selected Hybrid and N-\nPoW/PoS crypto-currencies is presented in Table 25.\n7\nNON-INCENTIVISED CONSENSUS\nIn this section, we present non-incentivised consensus\nalgorithms that are used in private blockchain systems\nwell-suited for non-crypto-currency applications. These al-\ngorithms are mostly based on classical consensus algorithms\nwith special features added for their adoption for the corres-\nponding blockchain systems.\nOne of the major initiatives within the private blockchain\nsphere is the Hyperledger project, which is an industry-\nwide effort [206]. Founded by the Linux Foundation, it is\na consortium of some of the major tech vendors of the\nworld. It provides an umbrella to facilitate the development\nof different types of open source projects utilising private\nblockchains with a speci\ufb01c focus to address issues involving\nbusiness and governmental use-cases. Currently, there are\nsix major projects within Hyperledger: Hyperledger Fabric\n[207], Hyperledger Sawtooth [208], Hyperledger Burrow\n[209], Hyperledger Iroha [210] and Hyperledger Indy [211].\nEach of them is analysed below with a brief introduction.\n7.1\nHyperledger Fabric\nHyperledger Fabric is the \ufb01rst major private blockchain\nsystem that originated from the Hyperledger ecosystem\n[207]. It has been designed with strong privacy in mind\nto ensure that different businesses organisations, including\ngovernmental entities, can take advantage of a blockchain\nsystem in different use-cases. A crucial capability of Fabric\nis that it can maintain multiple ledgers within its ecosystem.\nThis is a useful feature, which separates Fabric from other\nblockchain systems consisting of only one ledger in each of\ntheir domains.\nA key strength of Fabric is its modular design and\npluggable features. For example, Fabric is not dependant\non a particular format of ledger data, which is useful in\nseveral use-cases. In addition, the consensus mechanism\nis fully pluggable. Therefore, different types of consensus\nalgorithms can be used in different situations.\nAs part of its consensus process, Fabric utilises a special\nentity called Orderer, which is responsible for creating a\nnew block and extending the ledger by adding the block\nin the appropriate order. In addition, there are other entit-\nies known as endorsers. Each endorser is responsible for\n26\nTable 21: Comparing structural properties of Hybrid and N-POS/POW Consensus Algorithms.\nSingle committee\nMultiple committee\nConsensus\n/System\nNode type\nType\nFormation\nCon\ufb01guration\nTopology\nCon\ufb01guration\nMechanism\nPoR\nClients\n(Researchers) &\nMinters\n-\n-\n-\nFlat\nDynamic\nProbabilistic lottery\nPoB\nClients, Miners\n& Minters\n-\n-\n-\nFlat\nDynamic\nProbabilistic lottery\nPoSV\nClients &\nMinters\nOpen\nImplicit\nDynamic\nProbabilistic lottery\nPoC\nClients & CVNs\nOpen\nExplicit\nDynamic\n-\n-\nVoting\nPoI\nClients &\ntransaction\npartners\nOpen\nImplicit\nDynamic\n-\n-\nProbabilistic lottery\nTable 22: Comparing security properties of Hybrid and N-POS/POW Consensus Algorithms.\nAttack Vectors\nConsensus\nAuthentication\nNon-repudiation\nCensorship\nresistance\nAdversary tolerance\nSybil protection\nDoS Resistance\nPoR\nX/\nHigh\n3f + 1\nPoB\nX\nHigh\n3f + 1\nPoSV\nX\nHigh\n3f + 1\nPoC\nHigh\n?\nPoI\nX\nHigh\n?\nTable 23: Comparison of additional attack vectors protection for Hybrid and N-POS/POW Consensus Algorithms\nConsensus\n/System\nNothing-at-Stake\nBribing\nLong-range\nCoin-age\nPre-computing\nCartel formation\nPoR\nX\nX\nX\nX\nX\nX\nPoB\nX\nX\nX\nX\nX\nPoSV\nX\nX\nX\nX\nX\nX\nTable 24: Comparing performance properties of Consensus Algorithms of Hybrid and N-POS/POW.\nConsensus\nFault\ntolerance\nThroughput\nScalability\nLatency\nEnergy\nPoR\n2f + 1\nHigh\nMedium\nLow\nLow\nPoB\n2f + 1\nMedium\nLow\nMedium\nMedium\nPoSV\n2f + 1\nHigh\nMedium\nLow\nLow\nPoC\n?\nLoW (10.6 TPS [173])\nMedium\nLow\nLoW\nPoI\n?\nHigh\nMedium\nLow\nLow\nTable 25: Hybrid & Non-PoW/PoS currencies\nCurrency\nGenesis date\n(dd.mm.yyyy)\nBlock reward\nTotal supply\nConsensus\nBlock Time\nGridcoin\n24 Mar 2016\nMinting\n42 Million\nPoR, PoS\n1 minute\nSlimcoin\nMay 2014\n50-250 coins\n133 Million\nPoB, PoW, PoS\n1.5 minutes\nReddcoin\nJanuary\n20,\n2014\nBlock reward\n2.8 Billion\nPoSV\n1 minute\nFaircoin\n6th\nof\nMarch,\n2014.\nBlock reward\n5.3 Million\nPoC\nDepends\non\nTime-weight\nParameter\nBurst\n11 August 2014\nReduces at a \ufb01xed rate\nof 5 percent each month\n204 Million\nPoC\n4 minutes\nNEM\nMarch\n31st,\n2015\ntransaction fees only +\nnode rewards\n899 Million\nPoI\n1 minute\nvalidating and endorsing a transaction where it checks if\nan entity is allowed to perform a certain action in a ledger\nencoded within the transaction. Other participating entities\nare general users who create transactions. All the entities,\nincluding the Orderer(s) and the endorsers, are registered\nand authenticated via a Fabric speci\ufb01c special entity called\nMembership Service Provider (MSP). The MSP is responsible\nfor managing the identities of all participants in the ledger.\nUsing this identity layer, it is possible to create security\npolicies that dictate which entities can perform what actions\nwithin a speci\ufb01c ledger. A simple \ufb02ow of a consensus\nprocess in Fabric is illustrated in Figure 13.\nThe number of Orderer can be increased to distribute the\nordering service. Currently, it supports SOLO and Kafka. A\nSOLO ordering service consists of just one single orderer\nand hence, cannot provide any type of fault tolerance. That\n27\nA All required entities are registered in the MSP.\nB A channel with a ledger is initiated. In addition, a\npolicy is created containing the endorsement criteria\nas well as other security and privacy criteria.\nC A chaincode (smart-contract written either in Java or\nGo) is deployed in the ledger.\nD When an entity wishes to invoke certain functions in\nthe chaincode to read data from the ledger or to write\ndata into the ledger, it submits a transaction proposal\nto all the required endorsers as dictated in the policy.\nE Each endorser validates the proposal, executes the\nchaincode and returns a proposal response consisting\nof other ledger data.\nF The proposal, its response, and other ledger data are\nencoded as a transaction and sent to the Orderer.\nG The Orderer creates a block using the transaction and\nreturns the block to the endorsers.\nH Each endorser validates the block and, if validated,\nextends the ledger by attaching the new block. This\nessentially updates the state of the ledger.\nFigure 13: A simple \ufb02ow of a consensus process in Fabric.\nis why it is not recommended to utilise the SOLO model\nin the deployed system and has only been provided for\ninitial testing. On the other hand, the Kafka Orderer utilises\na Kafka cluster for deploying distributed Orderers. Kafka\nis a distributed streaming platform with a pub-sub archi-\ntecture [212] and is coupled with Zookeeper, a distributed\ncoordination service [213]. At this point, the Kafka Orderer\nis the only recommended setting for achieving consensus\nin Fabric. An SBFT (Simpli\ufb01ed Byzantine Fault Tolerance)\nbased consensus algorithm is currently being developed and\nis to be released soon.\n7.2\nHyperledger Sawtooth\nHyperledger Sawtooth, initially developed by Intel, is a\nsoftware framework for creating distributed ledgers suitable\nfor a variety of use cases [208]. Sawtooth utilises a novel\nconsensus algorithm called Proof-of-Elapsed-Time (PoET),\nwhich depends on Intel SGX (Software Guard Extension).\nIntel SGX is a new type of Trusted Execution Environment\n(TEE) integrated into the new generation of Intel processors.\nSGX enables the execution of code within a secure enclave\ninside the processor, whose validity can be veri\ufb01ed using a\nremote attestation process supported by the SGX.\nPoET, similar to the Nakamoto consensus algorithm in\nBitcoin, relies on the concept of electing a leader in each\nround to propose a block to be added in the ledger. The\ndifference is that the Nakamoto algorithm and its variants\nselect a leader by a lottery mechanism, which utilises com-\nputing power to generate a proof, as described previously.\nHowever, PoET solely relies on the Intel SGX capability to\nelect a leader. During each round, every validator node\nin the network, requests for a wait time from a trusted\nfunction in the SGX enclave. The validator that is assigned\nthe shortest waiting time is elected as the leader for that\nround. The winning validator then can propose a block,\nconsisting of a series of transactions from the de\ufb01ned trans-\naction family. Other validators can utilise a trusted function\nsupported by SGX to assess whether a trusted function has\nassigned the shortest time to the winning validator, and\nthe winning validator has waited the speci\ufb01ed amount of\ntime. Furthermore, other validators verify the validity of\nthe block before it is included in the ledger. The inclusion\nof the PoET as a consensus algorithm enables Sawtooth to\nachieve massive scalability as it does not need to solve a\nhard, computationally intensive cryptographic puzzle. In\naddition, it allows Sawtooth to be used not only for a\npermissioned ledger, but also for a public ledger.\n7.3\nHyperledger Burrow\nHyperledger Burrow is a private (permissioned) deploy-\nment of the Ethereum platform [209]. It has been created\nand then deposited to the Hyperledger code-base by Monax\nIndustries Limited [214]. The core component in Burrow\nis a permissioned version of the EVM (Ethereum Virtual\nMachine) to ensure that only authorised entities can execute\ncode. Two additional components have been added: Byz-\nantine fault-tolerant Tendermint protocol [179], [221] and\nthe RPC gateway.\nThe Tendermint consensus falls under the category of\na Byzantine Fault Tolerance (BFT) algorithm, which can\nbe used to achieve consensus even under the Byzantine\nbehaviour of a certain number of nodes as presented in\nSection 5.2.2.\nBurrow depends on several validators, which are known\n(authorised) entities with the duty to validate each block\nutilising the Tendermint consensus algorithm. This al-\ngorithm allows consensus to be achieved in Burrow with\n1/3 nodes exhibiting Byzantine behaviour, either acting\nmaliciously or having been down due to network or system\nfailure.\nSince Burrow utilises the EVM, a wide-range of smart-\ncontracts and DApps (Decentralised Applications) could\nbe deployed. Using the Tendermint algorithm with a set\nof known validators allows Burrow to scale at a much\nfaster rate than Ethereum while preserving the privacy of\ntransactions by allowing only known entities to participate\nin the network.\n7.4\nHyperledger Iroha\nHyperledger Iroha is a private blockchain system initially\ndeveloped by Soramitsu, Hitachi, NTT Data, and Colu\nand is currently hosted by Linux foundation under the\nHyperledger Project [210], [215]. Iroha aims to create a\nsimple blockchain infrastructure which can be incorporated\ninto any system which requires a blockchain architecture\nunderneath to function. The major emphasis while design-\ning Iroha is on a simpler construction with a strong focus\non mobile-friendly application development using a novel\nconsensus mechanism called YAC (Yet Another Consensus)\n[215], [216]. One fundamental different of Iroha from other\nHyperledger project is its \ufb01ne-grained permission control\nmechanism which allows de\ufb01ning permissions for all relev-\nant commands, queries, and even joining in the network.\nThe core architecture consists of several components\n[216], [219]. A brief description of its major components is\npresented below:\n28\n\u2022 Troii represents the entry point of any application to\nthe Iroha network. It utilises gRPC (gRPC Remote Pro-\ncedure Calls [218]), an open source RPC framework,\nto interact with different peers and entities within the\nblockchain network.\n\u2022 Model represents how different entities are represented\nwithin the system and de\ufb01nes the mechanism to inter-\nact with them.\n\u2022 Network provides the network functionalities required\nto maintain the P2P network and to propagate transac-\ntions in the network.\n\u2022 Consensus facilitates the functionalities related to\nachieving consensus in the network using the YAC\nconsensus protocol, a practical byzantine fault-tolerant\nalgorithm (discussed below).\n\u2022 Simulator provides a mechanism to simulate the effects\nof transactions on the chain by creating a temporary\nsnapshot of the chain state.\n\u2022 Validator allows the validation of transactions by veri-\nfying its formats and signature along with the veri-\n\ufb01cation of business rules and policies involved in the\ntransactions. There are two types of validations in Iroha:\n\u2013 Stateless validation checks for transaction formats and\nsignature.\n\u2013 Stateful validation checks the business rules and\npolicies, e.g., if a certain action is allowed by an entity.\n\u2022 Synchroniser is a part of the consensus component and\nis responsible for synchronising the chain to a new or\ndisconnected node.\n\u2022 Ametsuchi is the storage component of Iroha and is\nused to store the blocks and the chain state known as\nWorld State View (WSV).\nThese components are used by three core entities within\nthe architecture [216]:\n\u2022 Clients are applications that they can query data from\nthe allowed Iroha chain as well as can perform certain\nactions, called commands, by which the state of the\nchain is updated. For each of these, clients need to\ninteract with the peer.\n\u2022 Peers are nodes that have the following two functional-\nities:\n\u2013 To maintain a copy of the ledger. Applications can\nthus interact with a peer to query a chain or to submit\ntransactions to update the chain.\n\u2013 To participate in the consensus process by maintain-\ning its address, identity and trust as a single entity in\nthe network.\n\u2022 Ordering service node(s): Like Fabric, ordering service\nnodes are responsible for ordering transactions and\ncreating a proposal of a block.\nWith these components and entities, a \ufb02ow of transac-\ntions in Iroha is brie\ufb02y presented in Figure 14 [216].\n7.5\nHyperledger Indy\nHyperledger Indy is a private blockchain system purpose-\nfully built for providing an ecosystem for blockchain-based\nself-sovereign identity [211], [222]. The concept of Self-\nSovereign Identity has been initially promoted by the Sovrin\nfoundation [223], a non-pro\ufb01t international entity consisting\nA A client prepares and sends a transaction to a peer\nusing Troii.\nB The peer performs stateless validation to the trans-\naction and forwards the transaction to the ordering\nservice using an ordering gate.\nC The ordering service combines and orders transac-\ntions from different peers in a transaction proposal\nwhich is then broadcast to the peers.\nD Each peer performs a stateful validation of the pro-\nposal using the simulator and creates a block con-\nsisting of only veri\ufb01ed transactions. Each peer signs\nthe block, generates a hash of the proposed block\nand \ufb01nally, creates a tuple containing the hash and\nthe signature. Such a tuple is called a vote. The block\nand the vote are then internally sent to the consensus\ngate to initiate the YAC mechanism.\nE The YAC mechanism in each peer prepares an\nordered list of voting peers utilising the hashes\ncreated in the previous step. The \ufb01rst peer in the\nlist is regarded as the leader and is responsible for\naggregating votes from other voting peers.\nF After aggregating all votes from the voting peers, the\nleader computes the supermajority (usually 2/3rd)\nof votes for a certain hash (signifying a block).\nG Once a supermajority for a proposed block is\nachieved, the leader propagates a commit message\nfor this particular block to all voting peers.\nH Each voting peer veri\ufb01es the commit message and\nadds the block to the blockchain.\nFigure 14: A \ufb02ow of transactions in Iroha.\nof several private organisations to promote the notion of\nSelf-sovereign Identity. The Indy project is closely associated\nwith the Sovrin foundation focusing on materialising this\nnotion of a self-sovereign identity system as a public identity\nutility.\nCurrently, Indy consists of the following two major com-\nponents:\n\u2022 Indy-plenum: Plenum is the underlying distributed\nledger (blockchain) construct of the Indy platform. Like\nany distributed ledger, the Plenum ledger is fundament-\nally an ordered log of transactions. In addition, it consists\nof several nodes, among which a single or a few chosen\nones act as the leader responsible for ordering the trans-\nactions. The nodes execute a consensus protocol which\nutilises a three-phase commit to reach agreement among\nthemselves regarding the order of the transactions.\n\u2022 Indy-SDK: This provides the required software APIs and\ntools to enable other software to interact with the Plenum\nledger. It hides all the intricate internals from the users of\nthe platform so that the platform can be utilised without\neven knowing the complexities of the ledger and its asso-\nciated consensus protocol.\nThe consensus protocol utilised in Indy is called RBFT\n(Redundant Byzantine Fault Tolerance) [224]. Like any other\nbyzantine fault tolerance protocol, it relies on 3f + 1 nodes\n(a participant in the consensus protocol) in order to handle\nf byzantine nodes [224], [225]. For example, it requires\n29\nfour deployed nodes in order to handle a single byzantine\nnode. Each participating node in RBFT deploys two (or\nmore) protocol instances, aptly called Master and Backup\nprotocol instance, each of which is executed in parallel. A\nseparate primary node (also called a leader) is selected from\nthe master and the backup protocol instance. The leader is\nresponsible for ordering the transactions. Its performances,\ni.e., latency and throughput, are periodically observed by\nthe other instances. If its performance degrades, a different\nleader is selected from the backup instance.\nIndy maintains a number of ledgers for different pur-\nposes, unlike many other blockchain systems which employ\na solo ledger. For example, separate ledgers are maintained\nfor node maintenance, for identity transactions and so on.\nClients (users via their appropriate software interfaces) can\ninteract with these ledgers via different nodes for updating\nthe ledger via transactions and for reading from the ledger\nvia queries. A \ufb01ne-grained permission mechanism can be\nused to dictate which client has to write permissions, how-\never, any client can read from the ledger.\nOnce a node receives a transaction from a client, it per-\nforms some validation and then broadcasts the transaction\nto other nodes in the network. When the transaction reaches\nenough nodes, the primary node starts a new consensus\nround using a three-phase commit mechanism. In the end,\nall nodes agree to the order proposed by the primary node\nand add the transaction into the corresponding ledger.\n7.6\nAnalysis\nIn this section, we analyse the non-incentive consensus pro-\ntocols against the criteria selected before. Block and reward\nproperties are not considered as they are not relevant for\nnon-incentivised consensus protocols. We use the notation\n\u2018\n\u2019 to indicate an algorithm satis\ufb01es a particular property\nand the notation \u2018-\u2019 to indicate that there is no informa-\ntion regarding that speci\ufb01c property. For other properties,\nexplanatory texts are added.\nSTRUCTURAL PROPERTIES. Tn Table 26, we present the\ncomparison\nof\nstructural\nproperties\namong\nthe\nnon-\nincentivised consensus algorithms discussed in this section.\nAs evident from the table, different algorithms use different\ntypes of nodes, and all algorithms are based on single com-\nmittee with closed committee type and explicit committee\nformation. Only YAC relies on a dynamic con\ufb01guration\nwhich utilises the reputations of the nodes from previous\ninteractions; all others have the static con\ufb01guration.\nVoting is the predominantly used underlying mechan-\nism, which is utilised by Tendermint Burrow, YAC, and\nRBFT, whereas PoET relies on a lottery mechanism. Fabric\ncurrently utilises the ordering services by the orderer. In\nthe future, it might utilise SBFT, which leverages the voting\nmechanism.\nSECURITY PROPERTIES. The comparison of security prop-\nerties among the non-incentivised consensus algorithms\nis presented in Table 27. All algorithms support non-\nrepudiation via digital signature and have a signi\ufb01cantly\nlow censorship resistance. This is because the identities of\nall participating nodes are known. In case any node starts\nmisbehaving, because of an attacker taking control of that\nnode, it can be easily identi\ufb01ed, and proper actions can be\ntaken. The same logic applies for the Sybil protection and\ntowards DoS resistance. Being mostly based BFT algorithms,\nall algorithms, except PoET, have 3f + 1 adversarial tol-\nerance. It has been found that PoET has an adversarial\ntolerance of \u0398\n\u0010\nlog log n\nlog n\n\u0011\n[220], where n is the number of\nnodes.\nPERFORMANCE PROPERTIES. The comparison of perform-\nance properties among the non-incentivised consensus al-\ngorithms is presented in Table 28. All algorithms can\nprovide a good throughput and do not require to consume\nany signi\ufb01cant amount of energy. PoET, utilising a lottery\nmechanism, can be scaled with a large number of valid-\nators, however, this will increase the latency (\ufb01nality) of\ntransactions [217]. All other algorithms employing a voting\nmechanism cannot be scaled with a large number of val-\nidators, providing low latency for the transactions. Fabric,\nYAC, and RBFT provide a 2f + 1 fault tolerance, whereas\nthe information regarding the fault tolerance for PoET and\nTendermint Burrow is not speci\ufb01ed formally.\n8\nDISCUSSION\nAs per our analysis in different sections, it is clear that PoW\nconsensus algorithms have major limitations, speci\ufb01cally in\nterms of power consumption and scalability. Many regard\nPoS, and it is variant DPoS, to be the most suitable altern-\natives. To understand the applications of these algorithms\nin public blockchain systems, we have analysed the top 100\ncrypto-currencies, as reported on CoinMarketCap 4 as of 18\nJuly, 2019.\nIn the \ufb01rst analysis, we have calculated the number\nof consensus algorithms used in these (top 100) crypto-\ncurrencies. The distribution of consensus algorithms is\npresented in Figure 15 . As per our analysis, PoW is still\nthe most widely used (57%) consensus algorithms to date,\nwhereas DPoS is the second most with 11%, and PoS is the\nthird most with 6% used consensus algorithms. All other\nconsensus algorithms represent the remaining 26%. This\nmeans that, even though many consider that PoS and DPoS\nare the best alternatives to PoW, their adoption is still far\nbehind PoW.\nTo investigate it further, we have analysed a year-\nwise distribution of the genesis dates of different crypto-\ncurrencies. It is to understand if there is any inclination\ntowards an alternative consensus algorithm over PoW in\nrecent years. The distribution is illustrated in Figure 16,\nwhich represents a surprising observation: PoW is still the\nmost widely used algorithms for crypto-currencies which\nhave been created in recent years. For example, the numbers\nof crypto-currencies created with PoW algorithms in last\nthree years (2017, 2018 & 2019) are 11, 19 and 4 respectively,\nin comparison to 4, 2 and 2 for PoS and DPoS combinedly.\nThis implies that PoW is still the most popular consensus\nalgorithm among the crypto-currency community. A deeper\ninvestigation reveals another insight though. The top 100 list\nretrieved from Coinmarketcap also contains crypto-tokens\ngenerated on top of any smart-contract platform such as\nEthereum, EOS and Tron with majority tokens are built on\n4. https://coinmarketcap.com/\n30\nTable 26: Comparing structural properties of Consensus Algorithms of Hyperledger Systems.\nSingle committee\nConsensus\n/System\nMechanism\nNode type\nType\nFormation\nCon\ufb01guration\nFabric\nOrdering/Voting (SBFT)\nClient (Regular peer), En-\ndorsing peer & Orderer\nClose\nExplicit\nStatic\nPoET\nLottery\nClient,\nTransaction\nprocessor & Validator\nClose\nExplicit\nStatic\nTendermint Burrow\nVoting\nAs Tendermint (3)\nClose\nExplicit\nStatic\nYAC\nVoting\nClient, Peer & Ordering Ser-\nvice node\nClose\nExplicit\nDynamic\nRBFT\nVoting\nClient & Node\nClose\nExplicit\nStatic\nTable 27: Comparing security properties of Consensus Algorithms of Hyperledger Systems.\nAttack Vectors\nConsensus\nNon-repudiation\nCensorship resistance\nAdversary tolerance\nSybil protection\nDoS Resistance\nFabric\nLow\n3f + 1\nPoET\nLow\n\u0398\n\u0010\nlog log n\nlog n\n\u0011\nTendermint Burrow\nLow\n3f + 1\nYAC\nLow\n3f + 1\nRBFT\nLow\n3f + 1\nTable 28: Comparing performance properties of Consensus Algorithms of Hyperledger Systems.\nConsensus\nFault tolerance\nThroughput\nScalability\nLatency\nEnergy\nFabric\n2f + 1\nGood\nMedium\nLow\nLow\nPoET\n-\nGood\nGood\nMedium\nLow\nTendermint Burrow\n-\nGood\nMedium\nLow\nLow\nYAC\n2f + 1\nGood\nMedium\nLow\nLow\nRBFT\n2f + 1\nGood\nMedium\nLow\nLow\ntop of Ethereum. Most of these tokens have emerged after\n2016 with Ethereum utilising PoW . This could be the reason\nwhy the most recent crypto-currencies have been found to\nutilise PoW.\nAnother indication of PoW domination over other al-\ngorithms is the market-cap distribution of their correspond-\ning crypto-currencies. The distribution is presented in Table\n29 and illustrated in Figure 17. Not surprisingly, PoW cur-\nrencies with a market-cap of around 221 Billion USD have\na massive 93% dominance over other currencies. DPoS and\nPoS currencies are the nearest rivals with a market-cap of\naround 6 Billion USD and dominance of only 3% for each\ngroup.\nTable 29: Market capitalisation of major consensus al-\ngorithms in top 100 Crypto-currencies\nConsensus Algorithms\nMarket-cap (USD)\nPoW\n221, 238, 526, 412\nDPoS\n6, 483, 606, 020\nPoS\n6, 287, 224, 485\nPoW+PoS\n2, 436, 683, 929\nProof of Authority\n572, 188, 935\nProof of Activity\n274, 066, 240\nFrom our investigation, it is clearly evident that PoW\nalgorithm, even with its major limitations, is still the most\npopular consensus algorithm to be utilised in different\ncrypto-currencies. Currencies which utilise PoW algorithms\nconsume a signi\ufb01cant amount of energy as illustrated in\nSection 5.1.4. Besides, they have a reduced throughput (in\nterms of transaction number) compared to PoS and DPoS\ncurrencies. For example, the reported TPS (Transactions Per\nSecond) for Bitcoin and Ethereum are 7 and 15\u221225, respect-\nively [226], while DPoS currencies EOS has a reported and\nestimated TPS of 50 and 4000 respectively [226] and Tron\nhas a claimed TPS of 2000 [227]. Clearly, DPoS currencies\nhave better performance, at least in terms of TPS, over\nany PoW currency. Therefore, one might ask the underlying\nreason behind this counter-intuitive trend of PoW being the\nmost popular consensus algorithm. We have identi\ufb01ed a few\nreasons behind this as presented below:\n\u2022 Bitcoin is the most dominant crypto-currency in terms\nof market-cap. As of 18 July, it has a market cap of\naround 171 Billion USD. In addition to this, its different\nforked variants (Bitcoin Cash\n5 and Bitcoin Satoshi\nVision 6) also have a combined market-cap of 8 Billion\nUSD. If we exclude Bitcoin and its variants, we have\na slightly different distribution of market-cap, as illus-\ntrated in Figure 18. Here, the market-cap percentage of\nPoW algorithm is reduced from 93% to 71% percent,\nwhich is still signi\ufb01cant in comparison to DPoS and\nPoS, its nearest rivals.\n\u2022 PoW has the \ufb01rst-mover advantage because of Bit-\ncoin and Ethereum, both being the pioneer in their\nrespective domain. Bitcoin has been the \ufb01rst successful\ncrypto-currency, while Ethereum is the \ufb01rst blockchain-\nbased smart-contract platform. Other crypto-currencies,\nbeing motivated by their success, might have adopted\nthe approach of utilising PoW as their corresponding\nconsensus algorithm.\n5. https://www.bitcoincash.org/\n6. https://bitcoinsv.io/\n31\nPoW\n58%\nDPoS\n9%\nPoS\n8%\nPoW+PoS\n4%\nProof of Activity (PoA)\n1%\nDelegated Byzentine Fault \nTollerance (dBFT)\n3%\nPractical Byzentine Fault Tollerance \n(PBFT)\n2%\nLoop Fault Tolerance (LFT)\n1%\nXRP Ledger \nProtocol\n1%\nStellar \nConsens\nus \nProtocol \n(SCP)\n1%\nTangle\n1%\nVBFT \n(verifiabl\ne random \nfunction)\n1%\nProof of authority\n2%\nProof-of-Service (PoS)\n1%\nOther\n1%\nPOI\n1%\nProof of retrivility\n1%\nBFT\n3%\nProof-of-Believability (PoB)\n1%\nOther\n10%\nPoW\nDPoS\nPoS\nPoW+PoS\nProof of Activity (PoA)\nDelegated Byzentine Fault Tollerance (dBFT)\nPractical Byzentine Fault Tollerance (PBFT)\nLoop Fault Tolerance (LFT)\n XRP Ledger Protocol\nStellar Consensus Protocol (SCP)\nTangle\nVBFT (verifiable random function)\nProof of authority\nProof-of-Service (PoS)\nOther\nPOI\nProof of retrivility\nBFT\nProof-of-Believability (PoB)\nFigure 15: Consensus algorithms in Top 100 Crypto-currencies\n\u2022 Another strong argument in favour of PoW is its un-\nderlying security. The number of miners is far greater\nin Bitcoin than the number of validators in PoS and\nDPoS. This implies a better decentralisation in Bitcoin\nthan PoS or DPoS. For example, EOS has only 21 valid-\nators, while Tron has 27 validators. The probability of\ncollusion among these validators is far greater than that\nof any popular PoW currency. For this reason, many in\nthe blockchain community have been doubtful of the\nsecurity of any PoS/DPoS currency. However, there is\na counter argument against this. Because of the mining\ncentralisation issue ( highlighted in Section 5.1.4), many\npoint out that a PoW algorithm might also be prone\nto centralisation. Therefore, a PoW currency might also\nsuffer from collusion attack.\nWith the dominance of PoW over other consensus al-\ngorithms, one might wonder what lies ahead and might ask\nif there will be any shift of balance among the consensus\nalgorithms. We believe that we will most de\ufb01nitely experi-\nment with a shifting of balance in the near future. In this\nregard, the PoS transformation process of Ethereum will\nbe a crucial factor. The proposed Ethereum PoS consensus\nmechanisms, both CFFG and CTFG, are highly regarded\nby the academics and industrial enthusiasts for their strong\nguarantee of security. With their strong focus on economic\nincentive and game-theoretic based approach, it is believed\nthat their security will be as close as PoW and much better\nthan any current PoS/DPoS algorithm can provide. In par-\nticular, the number of validators will be much higher than\nany number leveraged in the current PoS/DPoS algorithms.\nHowever, it is yet to be seen how they will perform once\ndeployed in real-life settings.\nThe existence of numerous algorithms and wide vari-\nations in their properties impose a major challenge to com-\nprehend them properly. In particular, it is often dif\ufb01cult to\ntest the suitability of a particular algorithm under certain\ncriteria. A visual tool would be a great help in this regard.\nTowards this aim, we present a decision tree in Figure 19,\nwhich can be used to determine the suitable consensus\nalgorithms under certain criteria in different scenarios. For\nexample, such a decision tree diagram can be leveraged\nto select a particular consensus algorithm while design-\ning/developing a new blockchain system.\nThe tree utilises \ufb01ve critical criteria to achieve its goal:\nincentives, energy consumption, scalability, security (with\nrespect to adversary tolerance), and ASIC-resistance. If the\nsystem needs to incentivise the miner/validating nodes,\nthen proof-of-work(PoW) and proof-of-stake (PoS) con-\nsensus are appropriate choices. Because of their underlying\nincentives mechanisms, the primary applications of these\nconsensus algorithms are public crypto-currencies. On the\nother hand, a private blockchain network usually does not\nrely on any crypto-currencies to motivate or incentivise\nany validators to run the blockchain network. In addition\nto incentives, energy consumption is another determining\nfactor in choosing appropriate consensus algorithms. PoW-\ntype algorithms consume high energy, whereas PoS al-\ngorithms and their derivatives consume a moderate amount\nof energy. PoW-types algorithms are very slow as of now\nand can process only a limited number of transactions.\n32\nPoW\nDPoS\ndBFT\nPoW + PoS\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\n2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\nPoW\nPoS\nDPoS\nProof of Activity\ndBFT\nProof of Authority\nPoW + PoS\nFigure 16: Year-wise distribution of consensus algorithms in Top 100 Crypto-currencies\n93%\n3%\n1%\n0%\n0%\n0%\n3%\n3%\nPoW\nDPoS\nPoW+PoS\nProof of Activity\ndBFT\nProof of Authority\nPoS\nFigure 17: Percentage of market capitalisation of consensus algorithms in top 100 Crypto-currencies\nHowever, compromising a popular PoW-based blockchain\nnetwork is very dif\ufb01cult, and therefore, they are more secure\nthan their counterparts. PoW-based algorithms can also be\nclassi\ufb01ed based on computational complexity. As discussed\nearlier, ASIC is a specialised hardware, designed and used\nto solve hash-based computational problems. ASIC is ex-\npensive and hinders common people from participating\nin the blockchain network. Therefore, memory-based PoW\nhas been designed. Now it is widely used in different\ncrypto-currencies. Non-incentivised consensus algorithms\nare mostly used in private blockchain systems. They con-\nsume a very low amount of energy compared to other types\nof consensus algorithms and are also very scalable. That\nmeans the miners can verify the transactions and create\nblocks really fast. However, a comparatively low number of\nvalidating nodes makes these algorithms more vulnerable\nto attacks.\nFor clarity, we provide a few examples to utilise the\ndecision tree diagram presented in Figure 19. If an incentiv-\nised algorithm is required for a highly scalable blockchain\nsystem that aims to consume low energy DPoS and BFT\nderivatives such as Tendermint, CTFG, and Ouroboros are\nthe preferred options. However, they will have moderate\nsecurity as described earlier. On the other hand, if security\nis of the highest priority, PoW algorithms are more suitable.\nIn this scenario, there are two options: memory-bound or\nCPU bound. If ASIC resistance is desired, one should opt\nfor memory-bound PoW algorithms. However, in such a\ncase, one has to sacri\ufb01ce scalability, and such algorithms\nwill consume high energy.\n33\n71%\n11%\n4%\n0%\n2%\n1%\n11%\n14%\nPoW\nDPoS\nPoW+PoS\nProof of Activity\ndBFT\nProof of Authority\nPoS\nFigure 18: Percentage of market capitalisation excluding Bitcoin and its variants\nNote that this is just an example of how such a diagram\ncan be developed using our selected four criteria. Other\ncriteria can be utilised to generate a different diagram which\nmight be suitable for other speci\ufb01c scenarios. Whenever\nsuch a diagram is to be developed, the tables (Table 13, Table\n14, Table 15, Table 17, Table 18, Table 19, Table 20, Table 21,\nTable 22, Table 23, Table 24, Table 26, Table 27 and Table 28)\nutilised to compare different consensus algorithms against\nthe de\ufb01ned properties in the taxonomy will be crucial as\nthe these tables will provide the required template by which\nsuch a diagram can be created.\n9\nCONCLUSION\nWith the popularisation of crypto-currencies, and block-\nchain in general, there has been a renewed interest in the\npractical implications of different distributed consensus al-\ngorithms. Most of the existing systems struggle to properly\nsatisfy the need for any wide-scale real-life deployment as\nthey have serious limitations. Many of these limitations are\ndue to the underlying consensus algorithm used in a partic-\nular system. Therefore, in the quest to create more suitable\npractical blockchain systems, the principal focus has been\non distributed consensus. This has led to the explorations;\neither existing consensus algorithms have been exploited\nor novel consensus mechanisms have been introduced. The\nultimate consequence of this phenomenon is a wide-range\nof consensus algorithms currently in existence. To advance\nthe knowledge of this domain, it is essential to synthesise\nthese consensus algorithms under a systematic study, which\nis the main motivation of this article.\nEven though there have been several similar works, this\nis the \ufb01rst paper to introduce a taxonomy of properties\ndesirable for a consensus algorithm and then utilise that\ntaxonomy to analyse each algorithm in a detailed fash-\nion. In addition, different consensus algorithms have been\ngrouped into two major categories: Incentivised and Non-\nincentivised consensus algorithms. An incentivised con-\nsensus algorithm, exclusively utilised by public blockchain\nsystems and crypto-currencies, relies on incentives for the\nparticipants in order to motivate them to behave as inten-\nded. On the other hand, in any non-incentivised algorithm,\nthe participants are considered as trusted, and hence, it is\nassumed that no incentives are required to ensure intended\nbehaviour. As such, these algorithms are mostly used in the\nprivate blockchain sphere. We have again grouped incentiv-\nised algorithms into three major sub-categories: PoW (Proof\nof Work), Proof of Stake (PoS) and consensus algorithms\nbeyond PoW and PoS.\nA PoW algorithm relies on computational complexit-\nies or memory size/performance to solve a cryptographic\npuzzle. There are three major approaches followed by PoW\nconsensus algorithms: i) a compute-bound PoW leveraging\nthe capabilities of the processing unit, ii) a memory-bound\nPoW which is more reliant on the size and performance of\nthe main memory, and iii) a chained PoW utilises a num-\nber of hashing algorithms executed consecutively one after\nanother. Blockchain systems utilising such a mechanism has\nspecial nodes, called miner nodes, who are responsible for\nsolving this puzzle and creating a new and valid block\nand extending the chain by appending this block in the\nexisting chain. The probability to solve this puzzle depends\non a network parameter, called dif\ufb01culty, which is adjusted\nautomatically after a certain period of time. As more miners\nparticipate in the network, the network parameters are\nadjusted in such a manner that requires more computa-\ntional power to mine a new block. As the corresponding\nsystems become more popular, it attracts more miners,\nwhich increases the security of the system. However, the\nincreased computational power results in more energy being\nconsumed. Apart from this, PoW systems generally have a\nlow throughput and do not scale properly. PoS algorithms\nand their corresponding mechanisms have been analysed in\ngreater detail in Section 5.1.\nTo alleviate the major issues of PoW, Proof of Stake (PoS)\nhas been proposed. In PoS, the nodes who would like to\nparticipate in the block creating process are called minters,\nand they need to own and lock a certain amount of the\ncorresponding crypto-currency, called stake. Such a stake is\nused to ensure that the minters will act as required since\nthey will lose their stakes when acting maliciously. PoS has\nseveral variants: Chained PoS, BFT PoS and DPoS. The core\nidea of a chained PoS is to leverage a combination of PoW\nand PoS algorithms chained together to achieve consensus.\n34\nConsensus\nalgorithm\nYes\nHigh\nLow\nNo\nLow\nLow\nHigh\nMedium\nMedium\nHigh\nYes\nNo\nMedium\nIncentivised\nEnergy\nScalable\nSecurity\nAISC\n Resistant\nRBFT\nSBFT\nYAC\nPoET\nBurrow\nChained\nPoW\nMemory Bound PoW (e.g, Cryptonight, Scrypt, and \nNeoScrypt consensus)\nChained PoW (e.g, X11/X13/X15, Quark, and Lyra2RE \nconsensus)\nCPU-Bound PoW (e.g, Nakamoto consensus)\nDPoS\nTendermint \nCTFG \nOuroboros\nLow\nPoR\nPoSV\nPoC\nPoI\nMedium\nMedium\nLow\nMedium\nFigure 19: Decision tree to choose appropriate consensus algorithms\nBFT PoS uses a multi-round PoS mechanism in which a\nvalidator (minter) is selected, from a set of validators, by\nthe agreement of super-majority quorum among other val-\nidators. On the other hand, DPoS selects a minter, from a\nset of minters, using votes from other clients of the network.\nPoS algorithms are generally fast and scalable, having high\nthroughput. However, they also need to consider several\nother attack vectors such as Nothing-at-stake, bribing, long-\nrange attack, cartel formation, and so on. Detailed analysis\nof different aspects of PoS algorithms has been presented in\nSection 5.2.\nThere are also some Hybrid consensus algorithms that\ncombine the mechanisms of PoW and/pr PoS with another\nnovel algorithm. Proof of Research, Proof of Burn, Proof of\nStake-Velocity are examples of such an algorithm. Again,\nthere are mechanisms that are novel and have no reliance\non PoW/PoS whatsoever. Proof of Cooperation and Proof\nof Importance are examples of such novel algorithms. The\ndiscussion and analysis of these consensus algorithms have\nbeen presented in Section 6.\nFinally, there are also a few non-incentivised consensus\nalgorithms which are exclusively utilised in private block-\nchain systems. Hyperledger is the leading private block-\nchain foundation under which different private blockchain\nsystems such as Hyperledger Fabric, Hyperledger Sawtooth,\nHyperledger Burrow, Hyperledger Iroha, Hyperledger Indy,\nand so on. These systems rely on different other consensus\nmechanisms such as SBFT, PoET, Tendermint Burrow, YAC,\nand RBFT. Key characteristics of these consensus algorithms\nare high throughput and low latency with acceptable scalab-\nility. Also, the algorithms require that every entity that\nparticipates in the network must be properly authenticated.\nA detailed analysis of these algorithms has been presented\nin Section 7.\nOur analysis in Section 8 suggests that PoW, with its\nmany disadvantages, still is the most dominant in terms of\nmarket capitalisation (indicating its adoption) and crypto-\ncurrency in the world. As discussed earlier, DPoS and PoS\nalgorithms, PoW\u2019s closest rivals, aim to tackle many of\nPoW\u2019s limitations. However, their adoption is still limited.\nIn addition to this analysis, we have presented an exemplary\n35\ndecision tree-based \ufb01gure which can be utilised to \ufb01lter out\nor select consensus algorithms that \ufb01t certain criteria. Such\na \ufb01gure will be a useful tool for any who would like to test\nthe suitability of a certain consensus algorithm under certain\ncriteria.\nThere is one issue that must be highlighted before we\nconclude this article. The principal focus of this article has\nbeen to explore and synthesise the consensus algorithms\navailable in different blockchain systems. However, there\nare other distributed ledger systems, which do not rely on\nany blockchain-type structure. Instead, they utilise other\nstructures to represent their respective ledgers. Examples\nof two such prominent crypto-currencies are IoTA 7 and\nNANO 8. Both of their ledgers are based on DAG (Directed\nAcyclic Graph), a speci\ufb01c type of directed graph with no\ncycle. However, IoTA uses a novel consensus algorithm\ncalled Tangle [229] while NANO utilises a representative\nbased consensus mechanism [228]. These two systems have\nreceived signi\ufb01cant attention because of their fee-less struc-\nture and fast transaction rates. However, we do not consider\nthese systems any further as they are out of scope for this\narticle. We plan to investigate such novel systems in the\nfuture in a different exploration.\nThere is high anticipation among the blockchain enthu-\nsiasts that blockchain technology will disrupt many existing\napplication domains. However, to unlock its true potential, a\nblockchain system must adopt a suitable consensus that can\nenable it to satisfy its intended properties. This is because\na consensus algorithm is the core component of any block-\nchain system, and it dictates how a system behaves and the\nperformance it can achieve. However, as our analysis in this\narticle suggests, an ideal consensus algorithm is still elusive\nas almost all algorithms have signi\ufb01cant disadvantages in\none way or another with respect to their security and\nperformance. Until a consensus algorithm \ufb01nds the correct\nbalance between these crucial factors, we might not see the\nwide-scale adoption as many crypto-currency enthusiasts\nare hoping.\nREFERENCES\n[1] Nakamoto, Satoshi \u201cBitcoin: A peer-to-peer electronic cash system\u201d.\n2008. [online] Available: https://bitcoin.org/bitcoin.pdf.\n[2] Pilkington, Marc \u201c11 Blockchain technology: principles and applic-\nations\u201d. Research handbook on digital transformations, 225, 2016.\n[3] Crosby, Michael and Pattanayak, Pradan and Verma, Sanjeev and\nKalyanaraman, Vignesh and others \u201cBlockchain technology: Bey-\nond bitcoin\u201d. Applied Innovation, 2(6-10), p. 71, 2016.\n[4] Cachin, C., and Vukoli, M. \u201cBlockchains Consensus Protocols in the\nWild\u201d. arXiv preprint arXiv:1707.01873, 2017.\n[5] Bano, S., Sonnino, A., Al-Bassam, M., Azouvi, S., McCorry, P.,\nMeiklejohn, S., and Danezis, G. \u201cConsensus in the Age of Block-\nchains.\u201d. arXiv preprint arXiv:1711.03936, 2017.\n[6] Wang, W., Hoang, D.T., Hu, P., Xiong, Z., Niyato, D., Wang, P., Wen,\nY. and Kim, D.I. \u201cA survey on consensus mechanisms and mining\nstrategy management in blockchain networks\u201d.\nIEEE Access, 7,\npp.22328-22370, 2019.\n[7] Baliga,\nA.\n\u201cUnderstanding\nBlockchain\nConsensus\nModels\u201d.\nApril,\n2017.\n[Online]\nAvailable:\nhttps:\n//www.persistent.com/wp-content/uploads/2017/04/\nWP-Understanding-Blockchain-Consensus-Models.pdf.\n7. https://www.iota.org/\n8. https://nano.org/en\n[8] Sankar, Lakshmi Siva and Sindhu, M and Sethumadhavan, M\n\u201cSurvey of consensus protocols on blockchain applications\u201d\n4th\nInternational Conference on Advanced Computing and Commu-\nnication Systems (ICACCS). IEEE, 1\u20135, 2017.\n[9] Seibold,\nSigrid\nand\nSamman,\nGeorge\n\u201cConsensus:\nImmutable\nagreement\nfor\nthe\nInternet\nof\nvalue\u201d.\nhttps://assets.kpmg.com/content/dam/kpmg/pdf/2016/06/\nkpmgblockchain-consensus-mechanism.pdf KPMG. 2016.\n[10] Mukhopadhyay, Ujan and Skjellum, Anthony and Hambolu,\nOluwakemi and Oakley, Jon and Yu, Lu and Brooks, Richard. \u201cA\nbrief survey of cryptocurrency systems.\u201d In Proceedings of the 14th\nannual conference on privacy, security and trust (PST). IEEE, 745\u2013\n752, 2016.\n[11] Schneider, F. B. \u201cImplementing fault-tolerant services using the\nstate machine approach: A tutorial\u201d.\nACM Computing Surveys\n(CSUR), 22(4), 299-319, 1990.\n[12] C. Cachin, R. Guerraoui, and L. Rodrigues.\n\u201cIntroduction to\nReliable and Secure Distributed Programming\u201d. (Second Edition).\nSpringer, 2011.\n[13] V. Hadzilacos and S. Toueg. \u201cFault-tolerant broadcasts and related\nproblems.\u201d.\nIn S. J. Mullender, editor, Distributed Systems (2nd\nEd.). New York, 1993.\n[14] Lamport, L., Shostak, R., and Pease, M. \u201cThe Byzantine generals\nproblem\u201d.\nACM Transactions on Programming Languages and\nSystems (TOPLAS), 4(3), 382-401, 1982.\n[15] Lamport, L. \u201cThe part-time parliament\u201d. ACM Transactions on\nComputer Systems, 16(2):133169, May 1998.\n[16] Lamport, L.\n\u201cPaxos made simple\u201d.\nSIGACT News, 32(4):5158,\n2001.\n[17] B. M. Oki and B. Liskov.\n\u201cViewstamped replication: A new\nprimary copy method to support highly- available distributed sys-\ntems\u201d. In Proc. 7th ACM Symposium on Principles of Distributed\nComputing (PODC), pages 817, 1988.\n[18] P. Hunt, M. Konar, F. P. Junqueira, and B. Reed. \u201cZooKeeper: Wait-\nfree coordination for internet- scale systems\u201d.\nIn Proc. USENIX\nAnnual Technical Conference, 2010.\n[19] D. Ongaro and J. K. Ousterhout. \u201cIn search of an understandable\nconsensus algorithm\u201d. In Proc. USENIX Annual Technical Confer-\nence, pages 305319, 2014.\n[20] M. Castro and B. Liskov. \u201cPractical Byzantine fault tolerance and\nproactive recovery\u201d.\nACM Transactions on Computer Systems,\n20(4):398461, Nov. 2002.\n[21] Bessani, A., Sousa, J., and Alchieri, E. E. \u201cState machine replication\nfor the masses with BFT-SMaRt\u201d.\nIn 44th Annual IEEE/IFIP\nInternational Conference on Dependable Systems and Networks\n(DSN), pp. 355-362, June 2014.\n[22] C. Dwork, N. Lynch, and L. Stockmeyer\n\u201cConsensus in the\npresence of partial synchrony\u201d.\nJournal of the ACM (JACM),\n35(2):288323, 1988.\n[23] M. J. Fischer, N. A. Lynch, and M. S. Paterson. \u201cImpossibility of\ndistributed consensus with one faulty process\u201d. Journal of the ACM\n(JACM), 32(2):374382, 1985.\n[24] Brewer, E. A. \u201cTowards robust distributed systems.\u201d. In PODC\n(Vol. 7), July 2000.\n[25] M. J. M. Chowdhury and M. S. Ferdous and K. Biswas and N.\nChowdhury and A. S. M. Kayes and M. Alazab and P. Watters\n\u201cA Comparative Analysis of Distributed Ledger Technology Plat-\nforms\u201d. IEEE Access, 7:167930-167943, 2019.\n[26] Iot, Joi \u201cThe Fintech Bubble\u201d. 2018 [Online] Available: https:\n//joi.ito.com/weblog/2016/06/14/-the-\ufb01ntech-bu.html. June 14,\n2016. Accessed on May 12, 2019\n[27] Xiao,\nDavid\n\u201cThe\nFour\nLayers\nof\nthe\nBlockchain\u201d.\n2018\n[Online]\nAvailable:\nhttps://medium.com/@coriacetic/\nthe-four-layers-of-the-blockchain-dc1376efa10f. June 22, 2016. Ac-\ncessed on April 12, 2019\n[28]\nNamecoin.\n2018\n[Online]\nAvailable:\nhttps://namecoin.org/.\nAccessed on May 20, 2019.\n[29]\nProof of Existence.\n2018\n[Online]\nAvailable:\nhttps://\nproofofexistence.com. Accessed on May 20, 2019.\n[30] Fromknecht, C., Velicanu, D., and Yakoubov, S.\nCertCoin: A\nNameCoin Based Decentralized Authentication System.\nMay\n14,\n2014.\n6.857\nUnpublished\nclass\nproject.\n2018\n[On-\nline]\nAvailable:\nhttp://courses.csail.mit.edu/6.857/2014/\ufb01les/\n19-fromknecht-velicann-yakoubov-certcoin.pdf. Accessed on May\n20, 2019.\n[31] Ferdous, Md Sadek and Biswas, Kamanashis and Chowdhury,\nMohammad Jabed Morshed and Chowdhury, Niaz and Muthukku-\n36\nmarasamy, Vallipuram \u201dIntegrated platforms for blockchain enable-\nment\u201d. Advances in Computers, Elsevier, 2019.\n[32] Seigen, Max Jameson, Tuomo Nieminen, Neocortex and Antonio\nM. Juarez \u201cCryptoNight Hash Function\u201d. March, 2013. [Online]\nAvailable: https://cryptonote.org/cns/cns008.txt.\n[33] Dwork, Cynthia and Naor, Moni \u201cPricing via processing or com-\nbatting junk mail\u201d. Annual International Cryptology Conference,\n139\u2013147, 1992.\n[34] Douceur, J. R. \u201cThe sybil attack\u201d. In International workshop on\npeer-to-peer systems (pp. 251-260), 2002.\n[35] Bentov, Iddo and Lee, Charles and Mizrahi, Alex and Rosenfeld,\nMeni\n\u201cProof of Activity: Extending Bitcoin\u2019s Proof of Work via\nProof of Stake [Extended Abstract]\u201d. SIGMETRICS Perform. Eval.\nRev., Volume 43, issue 3.\n[36] Andrew Miller, Yu Xia, Kyle Croman, Elaine Shi, and Dawn Song.\n\u201cThe Honey Badger of BFT Protocols.\u201d\nIn Proceedings of the\n2016 ACM SIGSAC Conference on Computer and Communications\nSecurity (CCS \u201916). ACM, New York, NY, USA, 31-42.\nDOI: ht-\ntps://doi.org/10.1145/2976749.2978399\n[37] Athanasios\nN.\nNikolakopoulos\nand\nJohn\nD.\nGarofalakis.\n\u201cNCDawareRank: a novel ranking method that exploits the decom-\nposable structure of the web.\u201d\nIn Proceedings of the sixth ACM\ninternational conference on Web search and data mining (WSDM\n\u201913). ACM, New York, NY, USA, 143-152.\n[38] Stefan Dziembowski, Sebastian Faust, Vladimir Kolmogorov and\nKrzysztof Pietrzak \u201cProofs of Space\u201d. Cryptology ePrint Archive,\nReport 2013/796. [Online] Available: https://eprint.iacr.org/2013/\n796\n[39] Ren, Ling and Devadas, Srinivas \u201cProof of Space from Stacked Ex-\npanders\u201d Proceedings, Part I, of the 14th International Conference\non Theory of Cryptography - Volume 9985, 2016\n[40] Sunoo Park, Krzysztof Pietrzak, Albert Kwon, Jo\u00a8e l Alwen and\nGeorg Fuchsbauer and Peter Ga\u02c7zi \u201cSpaceMint: A Cryptocurrency\nBased on Proofs of Space\u201d\nCryptology ePrint Archive, Report\n2015/528 [Online] Available: https://eprint.iacr.org/2015/528\n[41] Hamza Abusalah and Jo\u00a8el Alwen and Bram Cohen and Danylo\nKhilko and Krzysztof Pietrzak and Leonid Reyzin \u201cBeyond Hell-\nman\u2019s Time-Memory Trade-Offs with Applications to Proofs of\nSpace\u201d\nCryptology ePrint Archive, Report 2017/893\n[Online]\nAvailable: https://eprint.iacr.org/2017/893\n[42] Weichbrodt, Nico and Kurmus, Anil and Pietzuch, Peter and\nKapitza, R\u00a8udiger \u201cComputer Security ESORICS 2016\u201d Pages 440\u2013\n457 Springer International Publishing\n[43] Brasser F, M\u00a8uller U, Dmitrienko A, Kostiainen K, Capkun S,\nSadeghi A-R\n\u201cSoftware Grand Exposure: SGX Cache Attacks\nAre Practical\u201d In proceedings of the 11th USENIX Workshop on\nOffensive Technologies (WOOT 17) USENIX Association\n[44] Keir Finlow-Bates\n\u201cA Lightweight Blockchain Consensus Pro-\ntocol\u201d. August, 2017. [Online] Available: http://www.chainfrog.\ncom/wp-content/uploads/2017/08/consensus.pdf.\n[45] Back, Adam Hashcash-a denial of service counter-measure. 2002.\n[46] Bertoni, Guido and Daemen, Joan and Peeters, Micha\u00a8el and Van\nAssche, Gilles \u201cKeccak\u201d In Annual International Conference on the\nTheory and Applications of Cryptographic Techniques pp. 313\u2013314,\n2013.\n[47] Percival, C. and Josefsson, S. \u201cThe scrypt Password-Based Key\nDerivation Function\u201d. [Online] Available:\nhttps://tools.ietf.org/\nhtml/rfc7914 August, 2016.\n[48]\n\u201cWikipedia entry on Custon Hardware Attack\u201d. [Online] Avail-\nable:\nhttps://en.wikipedia.org/wiki/Custom hardware attack\nAccessed on 21 May, 2019.\n[49] Bernstein, Daniel J \u201cThe Salsa20 family of stream ciphers\u201d New\nstream cipher designs pp. 84\u201397, Springer, 2008.\n[50] \u201cSThe Scrypt Mining Algorithm: Everything You Need to Know\u201d.\n[Online]\nAvailable:\nhttps://www.easypc.io/crypto-mining/\nscrypt-hardware/ Accessed on 21 May, 2019.\n[51] Buntinx, JP\n\u201cScrypt vs X11 vs SHA-256\u201d.\n[Online]\nAvail-\nable:\nhttps://themerkle.com/scrypt-vs-x11-vs-sha-256/\nMarch\n23, 2017.\n[52] Bernstein, Daniel J ChaCha, a variant of Salsa20 \u201cNew stream\ncipher designs\u201d Vol. 8, pp. 3\u20135, 2008.\n[53]\n\u201cAnnouncement of Aiden - Scrypt-OG crypto-currency\u201d.\n[On-\nline] Available: https://bitcointalk.org/index.php?topic=558414.0\nAccessed on July 24, 2019.\n[54]\n\u201cCryptocurrency Mining Hash Algorithms\u201d.\nhttp://www.\nbitcoinlion.com/cryptocurrency-mining-hash-algorithms/\n[On-\nline] Available: July 24, 2019. Accessed on July 24, 2019.\n[55] Biryukov, Alex and Khovratovich, Dmitry\n\u201cEquihash: Asym-\nmetric proof-of-work based on the generalized birthday problem\u201d.\nLedger(2). 2017.\n[56] Wagner, David \u201cA generalized birthday problem\u201d. Cryptor(2442).\npages 288\u2013303. 2002.\n[57] \u201cCrypto-currencies utilising Equihash\u201d. [Online] Available: https:\n//www.coingecko.com/en?hashing algorithm=Equihash\nAc-\ncessed on July 24, 2019.\n[58]\n\u201cEthash\u201d. [Online] Available:\nhttps://github.com/ethereum/\nwiki/wiki/Ethash Accessed on July 24, 2019.\n[59] \u201cDagger-Hashimoto\u201d. [Online] Available:\nhttps://github.com/\nethereum/wiki/blob/master/Dagger-Hashimoto.md Accessed on\nJuly 24, 2019.\n[60] Buterin, Vitalik \u201cDagger: A Memory-Hard to Compute, Memory-\nEasy to Verify Scrypt Alternative\u201d.\nhttp://www.hashcash.org/\npapers/dagger.html Accessed on July 24, 2019.\n[61] Lerner, Sergio\n\u201cEthereum Dagger PoW function is \ufb02awed\u201d.\n[Online] Available:\nhttps://bitslog.wordpress.com/2014/01/17/\nethereum-dagger-pow-is-\ufb02awed/ 17 January, 2017. Accessed on\nJuly 24, 2019.\n[62] \u201cCrypto-currencies utilising Ethash\u201d. [Online] Available: https://\nwww.coingecko.com/en?hashing algorithm=Ethash Accessed on\nJuly 24, 2019.\n[63] \u201cCrypto-currencies utilising Dagger\u201d. [Online] Available: https:\n//www.coingecko.com/en?hashing algorithm=Dagger\nAccessed\non July 24, 2019.\n[64] Gligoroski, Danilo and Klima, Vlastimil and Knapskog, Svein\nJohan and El-Hadedy, Mohamed and Amundsen, J\u00f8rn\n\u201cCryp-\ntographic hash function blue midnight wish\u201d\nIn Proceedings of\nthe 1st International Workshop on Security and Communication\nNetworks pp. 1\u20138, 2009\n[65] Gauravaram, Praveen and Knudsen, Lars R and Matusiewicz,\nKrystian and Mendel, Florian and Rechberger, Christian and\nSchl\u00a8affer, Martin and Thomsen, S\u00f8ren S \u201cGr\u00f8stl-a SHA-3 candid-\nate\u201d Dagstuhl Seminar Proceedings 2009\n[66] Wu, Hongjun \u201cThe hash function JH\u201d Submission to NIST (round\n3) Vol. 6, 2011\n[67] \u201cQuark Coin\u201d. [Online] Available: http://www.quarkcoins.com/\nAccessed on July 24, 2019.\n[68]\n\u201cFirst\nImpressions\nfrom\nthe\nBaikal\nMini\nMiner\nASIC\u201d.\n[Online]\nAvailable:\nhttps://cryptomining-blog.com/tag/\nquark-asic-miner/ July 24, 2019 Accessed on July 24, 2019.\n[69] \u201cBitcoin\u201d. [Online] Available: http://www.bitcoin.org/ Accessed\non April 24, 2019.\n[70]\n\u201cBitcoin Cash\u201d. [Online] Available:\nhttps://www.bitcoincash.\norg/ Accessed on July 24, 2019.\n[71] \u201cSyscoin\u201d. [Online] Available: http://syscoin.org/ Accessed on\nJuly 24, 2019.\n[72] \u201cPeer Coin\u201d. [Online] Available: https://peercoin.net Accessed\non July 24, 2019.\n[73]\n\u201cCounterparty\u201d.\n[Online]\nAvailable:\nhttps://counterparty.io\nAccessed on July 24, 2019.\n[74] Aumasson, Jean-Philippe and Neves, Samuel and Wilcox-OHearn,\nZooko and Winnerlein, Christian \u201cBLAKE2: simpler, smaller, fast\nas MD5\u201d International Conference on Applied Cryptography and\nNetwork Security. pp. 119\u2013135, 2013.\n[75] \u201cEmercoin. [Online] Available: https://emercoin.com/ Accessed\non July 24, 2019.\n[76]\n\u201cNamecoin\u201d.\n[Online]\nAvailable:\nhttps://namecoin.org/\nAccessed on July 24, 2019.\n[77] \u201cSteem Dollars\u201d. [Online] Available: https://steem.io/ Accessed\non July 24, 2019.\n[78] \u201cCrown\u201d. [Online] Available: https://crown.tech/ Accessed on\nJuly 24, 2019.\n[79]\n\u201cOmmi (Mastercoin)\u201d.\n[Online]\nAvailable:\nhttp://www.\nomnilayer.org/ Accessed on July 24, 2019.\n[80]\n\u201cLitecoin\u201d.\n[Online]\nAvailable:\nhttp://www.omnilayer.org/\nAccessed on July 24, 2019.\n[81]\n\u201cBitconnect\u201d. [Online] Available:\nhttps://bitconnect.co/ Ac-\ncessed on May 24, 2019.\n[82] \u201cVerge\u201d. [Online] Available: https://vergecurrency.com Accessed\non July 20, 2019.\n[83] \u201cBitmark\u201d. [Online] Available: https://bitmark.com/ Accessed\non July 20, 2019.\n[84] \u201cDogecoin\u201d. [Online] Available: http://dogecoin.com/ Accessed\non July 20, 2019.\n37\n[85]\n\u201cGamecredit)\u201d. [Online] Available:\nhttps://gamecredits.com/\nAccessed on July 20, 2019.\n[86]\n\u201cEinsteinnium\u201d.\n[Online]\nAvailable:\nhttps://www.emc2.\nfoundation/ Accessed on July 20, 2019.\n[87] \u201cVoxels\u201d. [Online] Available: http://thevoxel.com/ Accessed on\nJuly 20, 2019.\n[88] \u201cViacoin\u201d. [Online] Available: https://viacoin.org/ Accessed on\nJuly 10, 2019.\n[89]\n\u201cHempcoin\u201d. [Online] Available:\nhttp://hempcoin.org/ Ac-\ncessed on July 10, 2019.\n[90] \u201cZcash\u201d. [Online] Available:\nhttps://z.cash/ Accessed on July\n10, 2019.\n[91]\n\u201cBitcoin Gold\u201d. [Online] Available:\nhttps://bitcoingold.org/\nAccessed on July 10, 2019.\n[92] \u201cKomodo\u201d. [Online] Available:\nhttps://komodoplatform.com/\nen Accessed on July 10, 2019.\n[93] \u201cZclassic\u201d. [Online] Available: http://zclassic.org/ Accessed on\nJuly 10, 2019.\n[94] \u201cZenCash\u201d. [Online] Available: https://zensystem.io/ Accessed\non July 10, 2019.\n[95] \u201cHush\u201d. [Online] Available: https://myhush.org/ Accessed on\nJuly 10, 2019.\n[96] \u201cbitcoinz\u201d. [Online] Available: https://btcz.rocks/en/ Accessed\non July 10, 2019.\n[97] \u201cVote Coin\u201d. [Online] Available: https://votecoin.site/ Accessed\non July 10, 2019.\n[98]\n\u201cEthereum\u201d. [Online] Available:\nhttps://www.ethereum.org/\nAccessed on July 10, 2019.\n[99] \u201cEthereum Classic\u201d. [Online] Available: https://ethereumclassic.\ngithub.io/ Accessed on July 10, 2019.\n[100] \u201cUbiq\u201d. [Online] Available: https://ubiqsmart.com/ Accessed\non July 10, 2019.\n[101] \u201cShif\u201d. [Online] Available: http://www.shiftnrg.org/ Accessed\non July 10, 2019.\n[102]\n\u201cExpanse\u201d.\nhttps://www.expanse.tech/ Accessed on July 10,\n2019.\n[103]\n\u201cDubaiCoin\u201d. [Online] Available:\nhttp://www.arabianchain.\norg/ Accessed on July 10, 2019.\n[104]\n\u201cSOILcoin\u201d. [Online] Available:\nhttps://github.com/Soilcoin\nAccessed on July 10, 2019.\n[105] \u201cKrypton\u201d. [Online] Available: http://krypton.rocks/ Accessed\non July 10, 2019.\n[106] \u201cRed Pulse\u201d. [Online] Available: https://www.red-pulse.com/\nlanding Accessed on July 10, 2019.\n[107]\n\u201cFeathercoin\u201d. [Online] Available:\nhttps://www.feathercoin.\ncom/ Accessed on July 10, 2019.\n[108]\n\u201cGoByte\u201d.\n[Online]\nAvailable:\nhttps://gobyte.network/\nAccessed on July 10, 2019.\n[109] \u201cUFO Coin\u201d. [Online] Available: https://ufocoin.net/ Accessed\non July 10, 2019.\n[110]\n\u201cInnova\u201d.\n[Online]\nAvailable:\nhttps://innovacoin.info/\nAccessed on July 10, 2019.\n[111]\n\u201crowdCoin\u201d.\n[Online]\nAvailable:\nhttp://crowdcoin.site/\nAccessed on July 10, 2019.\n[112]\n\u201cVivo\u201d.\n[Online]\nAvailable:\nhttps://www.vivocrypto.com/\nAccessed on July 10, 2019.\n[113] \u201cDesire\u201d. [Online] Available: https://www.desire-crypto.com/\nAccessed on July 10, 2019.\n[114]\n\u201cOrbitcoin\u201d. [Online] Available:\nhttps://www.orbitcoin.org/\nAccessed on July 10, 2019.\n[115]\n\u201cPhoenixcoin\u201d. [Online] Available:\nhttp://phoenixcoin.org/\nAccessed on July 10, 2019.\n[116] \u201cBitcore\u201d. [Online] Available: https://bitcore.cc/ Accessed on\nJuly 10, 2019.\n[117] \u201cDash\u201d. [Online] Available: https://www.dash.org/ Accessed\non July 10, 2019.\n[118]\n\u201cStratis.\n[Online]\nAvailable:\nhttps://stratisplatform.com/\nAccessed on July 10, 2019.\n[119] \u201cCloakcoin\u201d. [Online] Available: https://www.cloakcoin.com/\nAccessed on July 10, 2019.\n[120]\n\u201cStealthcoin\u201d. [Online] Available:\nhttps://www.stealthcoin.\ncom/ Accessed on July 10, 2019.\n[121]\n\u201cDeepOnion\u201d.\n[Online]\nAvailable:\nhttps://deeponion.org/\nAccessed on July 10, 2019.\n[122]\n\u201cHTMLcoin\u201d.\n[Online]\nAvailable:\nhttps://htmlcoin.com/\nAccessed on July 10, 2019.\n[123]\n\u201cRegal Coin\u201d.\n[Online]\nAvailable:\nhttps://regalcoin.co/\nAccessed on July 10, 2019.\n[124] \u201cMemetic\u201d. [Online] Available: https://memetic.ai/ Accessed\non July 10, 2019.\n[125]\n\u201cExclusive Coin\u201d. [Online] Available:\nhttps://exclusivecoin.\npw/ Accessed on July 10, 2019.\n[126]\n\u201cCreditbit\u201d. [Online] Available:\nhttps://www.creditbit.org/\nAccessed on July 10, 2019.\n[127]\n\u201cQuark\u201d. [Online] Available:\nhttp://www.qrknet.info/ Ac-\ncessed on July 10, 2019.\n[128] \u201cPIVX\u201d. [Online] Available: https://pivx.org/ Accessed on July\n10, 2019.\n[129]\n\u201cMonetaryUnit\u201d.\n[Online]\nAvailable:\nhttps://www.\nmonetaryunit.org/ Accessed on July 10, 2019.\n[130]\n\u201cALQO\u201d. [Online] Available:\nhttps://alqo.org/ Accessed on\nJuly 10, 2019.\n[131]\n\u201cBitcloud\u201d. [Online] Available:\nhttps://bit-cloud.info/ Ac-\ncessed on July 10, 2019.\n[132]\n\u201cZurcoin\u201d. [Online] Available:\nhttp://zurcoin.org/ Accessed\non July 10, 2019.\n[133] \u201cAmsterdamCoin\u201d. [Online] Available: https://amsterdamcoin.\ncom/ Accessed on July 10, 2019.\n[134]\n\u201cAnimecoin\u201d.\n[Online]\nAvailable:\nhttps://github.com/\ntestzcrypto/Animecoin/releases/tag/0.8.3.2 Accessed on July 10,\n2019.\n[135] \u201cVertcoin\u201d. [Online] Available: https://vertcoin.org/ Accessed\non July 10, 2019.\n[136]\n\u201cMonacoin\u201d.\n[Online]\nAvailable:\nhttps://monacoin.org/\nAccessed on July 10, 2019.\n[137]\n\u201cCrypto\u201d.\n[Online]\nAvailable:\nhttp://tail\ufb02ick.wixsite.com/\nof\ufb01cial-crypto Accessed on July 10, 2019.\n[138] \u201cQuark Coin Wiki\u201d. [Online] Available:\nhttp://coinwiki.info/\nen/Quark Accessed on July 10, 2019.\n[139] \u201cCrypto-currencies utilising Quark\u201d. [Online] Available: https:\n//www.coingecko.com/en?hashing algorithm=Quark\nAccessed\non July 10, 2019.\n[140]\n\u201cLyra2RE-A new PoW algorithm for an ASIC-free future\u201d.\n[Online]\nAvailable:\nhttps://vertcoin.org/wp-content/uploads/\n2017/10/Vertcoin Lyra2RE Paper 11292014.pdf Accessed on July\n10, 2019.\n[141] \u201cWikipedia entry on Vertcoin\u201d. [Online] Available: https://en.\nwikipedia.org/wiki/Vertcoin Accessed on July 10, 2019.\n[142] \u201cCrypto-currencies utilising Lyra2RE\u201d. [Online] Available: https:\n//www.coingecko.com/en?hashing algorithm=Lyra2RE Accessed\non July 10, 2019.\n[143] \u201cWiki entry on M7\u201d. [Online] Available: http://cryptonite.info/\nwiki/index.php?title=M7 PoW Accessed on July 10, 2019.\n[144]\n\u201cCudaMiner - a multi-threaded GPU miner for Cryptonite\u201d.\n[Online] Available:\nhttps://github.com/MiniblockchainProject/\nCudaMiner Accessed on July 10, 2019.\n[145]\n\u201cBitcore announcement on Bitcointalk\u201d.\n[Online]\nAvailable:\nhttps://bitcointalk.org/index.php?topic=1883902.0\nAccessed on\nJuly 10, 2019.\n[146] Doering, John \u201cNeoScrypt, a Strong Memory Intensive Key De-\nrivation Function\u201d.\nhttp://phoenixcoin.org/archive/neoscrypt\nv1.pdf [Online] Available: July 26, 2014. Accessed on July 10, 2019.\n[147]\n\u201cCrypto-currencies utilising NeoScrypt\u201d.\n[Online]\nAvail-\nable:\nhttps://www.coingecko.com/en?hashing algorithm=\nNeoScrypt Accessed on July 10, 2019.\n[148]\n\u201cBitcoin energy consumption\u201d.\n[Online]\nAvailable:\nhttps:\n//digiconomist.net/bitcoin-energy-consumption Accessed on July\n10, 2019.\n[149] \u201cEthereum energy consumption\u201d. [Online] Available: https://\ndigiconomist.net/ethereum-energy-consumption Accessed on July\n10, 2019.\n[150]\n\u201cWikipedia entry on Economies of scale\u201d. [Online] Available:\nhttps://en.wikipedia.org/wiki/Economies of scale\nAccessed on\nJuly 10, 2019.\n[151] \u201cWikipedia entry on Tragedy of the commons\u201d. [Online] Avail-\nable:\nhttps://en.wikipedia.org/wiki/Tragedy of the commons\nAccessed on July 10, 2019.\n[152]\n\u201cBitcoin hashrate distribution\u201d. [Online] Available:\nhttps://\nblockchain.info/pools Accessed on July 10, 2019.\n[153] Eyal, I. and Sirer, E.G. \u201cMajority is not enough: Bitcoin mining is\nvulnerable\u201d. International Conference on Financial Cryptography\nand Data Security pages 436\u2013454. March, 2014.\n38\n[154] QuantumMechanic \u201cProof of stake instead of proof of work\u201d.\n[Online]\nAvailable:\nhttps://bitcointalk.org/index.php?topic=\n27787.0 July 11, 2011. Accessed on May 11, 2019.\n[155] \u201cProof of Stake FAQ\u201d. [Online] Available: https://github.com/\nethereum/wiki/wiki/Proof-of-Stake-FAQ Accessed on August 5,\n2019.\n[156] Choi, Jon \u201cEthereum Casper 101\u201d. [Online] Available:\nhttps:\n//medium.com/@jonchoi/ethereum-casper-101-7a851a4f1eb0 Oc-\ntober 22, 2017. Accessed on July 10, 2019.\n[157]\n\u201cProof\nof\nStake\nversus\nProof\nof\nWork\u201d.\n[Online]\nAvailable:\nhttp://bitfury.com/content/5-white-papers-research/\npos-vs-pow-1.0.2.pdf September 13, 2015. Accessed on August 5,\n2019.\n[158]\n\u201cConsensus\nCompare:\nCasper\nvs.\nTendermint\u201d.\n[Online]\nAvailable:\nhttps://blog.cosmos.network/\nconsensus-compare-casper-vs-tendermint-6df154ad56ae\nNovember 16, 2017. Accessed on July 10, 2019.\n[159] Zam\ufb01r,\nVlad\n\u201cThe\nHistory\nof\nCasper\n-\nChapter\n4\u201d.\n[Online]\nAvailable:\nhttps://medium.com/@Vlad Zam\ufb01r/\nthe-history-of-casper-chapter-4-3855638b5f0e December 12, 2016.\nAccessed on July 10, 2019.\n[160]\n\u201cGridcoin\u201d.\n[Online]\nAvailable:\nhttps://github.com/\ngridcoin-community/Gridcoin-Wiki/wiki\nAccessed on June 22,\n2019.\n[161]\n\u201cGridcoin Whitepaper. [Online] Available:\nhttps://gridcoin.\nus/assets/img/whitepaper.pdf Accessed on 24 June, 2019.\n[162]\n\u201cWikipedia\nentry\non\nBerkeley\nOpen\nInfrastructure\nfor\nNetwork\nComputing\n(BOINC)\u201d.\n[Online]\nAvailable:\nhttps://en.wikipedia.org/wiki/Berkeley Open Infrastructure\nfor Network Computing Accessed on 21 June, 2019.\n[163] \u201cProof of Burn\u201d. [Online] Available: https://en.bitcoin.it/wiki/\nProof of burn Accessed on 21 June, 2019.\n[164] \u201cSlimcoin\u201d. [Online] Available: http://slimco.in/ Accessed on\n24 June, 2019.\n[165]\n\u201cSlimcoin\nWhitepaper\u201d.\n[Online]\nAvailable:\nhttps://www.doc.ic.ac.uk/\u223cids/realdotdot/crypto papers etc\nworth reading/proof of burn/slimcoin whitepaper.pdf Accessed\non 24 June, 2019.\n[166] \u201cReddcoin\u201d. [Online] Available:\nhttps://www.reddcoin.com/\nAccessed on 24 June, 2019.\n[167]\n\u201cReddcoin Whitepaper.\n[Online]\nAvailable:\nhttps://www.\nreddcoin.com/papers/PoSV.pdf Accessed on 24 June, 2019.\n[168]\n\u201cReddcoin Wiki\u201d. [Online] Available:\nhttps://wiki.reddcoin.\ncom/Proof of Stake Velocity (PoSV) Accessed on 24 June, 2019.\n[169]\n\u201cThe\nVelocity\nof\nMoney\nfor\nBeginners\u201d.\n[On-\nline]\nAvailable:\nhttps://www.joshuakennon.com/\nthe-velocity-of-money-for-beginners/\nAccessed\non\n25\nJune,\n2019.\n[170]\n\u201cFaircoin Crypto-currency\u201d.\n[Online]\nAvailable:\nhttps:\n//fair-coin.org Accessed on 24 June, 2019.\n[171] \u201cFaircoin Whitepaper, Version 1.2\u201d. [Online] Available: https://\nfair-coin.org/sites/default/\ufb01les/FairCoin2 whitepaper V1.2.pdf\nJuly, 2018. Accessed on 24 June, 2019.\n[172]\n\u201cNEM Technical Reference, Version 1.2.1\u201d.\n[Online]\nAvail-\nable:\nhttps://nem.io/wp-content/themes/nem/\ufb01les/NEM\ntechRef.pdf February 23, 2018. Accessed on 24 June, 2019.\n[173] \u201cFaircoin FAQ\u201d. [Online] Available:\nhttps://fair-coin.org/en/\nfaircoin-faqs Accessed on 24 June, 2019.\n[174] King, Sunny and Nadal, Scott\n\u201cPPCoin: Peer-to-Peer Crypto-\nCurrency with Proof-of-Stake\u201d.\n[Online]\nAvailable:\nhttps:\n//peercoin.net/assets/paper/peercoin-paper.pdf August 19, 2012.\nAccessed on May 5, 2019.\n[175]\n\u201cPeercoin\ndiscussion\nforum,\ndiscussion#3043\u201d.\n[Online]\nAvailable:\nhttps://talk.peercoin.net/t/\nppc-switching-between-pos-and-pow/3043\nNovember 4, 2014.\nAccessed on May 5, 2019.\n[176] Bentov, Iddo and Gabizon, Ariel and Mizrahi, Alex\n\u201cCrypto-\ncurrencies without proof of work\u201d.\nInternational Conference on\nFinancial Cryptography and Data Security pages 142\u2013157. 2016\n[177]\n\u201cDecred Platform\u201d.\n[Online]\nAvailable:\nhttps://decred.org/\nAccessed on June 23, 2019.\n[178]\n\u201cTendermint\nintroduction\u201d.\n[Online]\nAvailable:\nhttp://tendermint.readthedocs.io/projects/tools/en/master/\nintroduction.html Accessed on July 30, 2019.\n[179] Kwon, Jae \u201cTendermint: Consensus without Mining\u201d. [Online]\nAvailable:\nhttps://tendermint.com/static/docs/tendermint.pdf\n2014. Accessed on July 30, 2019.\n[180]\n\u201cTendermint wiki\u201d. [Online] Available: https://github.com/\ntendermint/tendermint/wiki/Byzantine-Consensus-Algorithm\nAccessed on July 30, 2019.\n[181] Buterin, Vitalik and Grif\ufb01th, Virgil \u201cCasper the Friendly Finality\nGadget\u201d.\n[Online]\nAvailable:\nhttps://github.com/ethereum/\nresearch/blob/master/papers/casper-basics/casper basics.pdf\nAccessed on August 1, 2019.\n[182] Zam\ufb01r,\nVlad\n\u201cCasper\nthe\nFriendly\nGhost-A\nCorrect-by-\nConstruction Blockchain Consensus Protocol\u201d.\n[Online]\nAvail-\nable:\nhttps://github.com/ethereum/research/blob/master/\npapers/CasperTFG/CasperTFG.pdf Accessed on August 1, 2019.\n[183] Sompolinsky, Y. and Zohar, A.\n\u201cSecure high-rate transaction\nprocessing in bitcoin\u201d. International Conference on Financial Cryp-\ntography and Data Security pp. 507-527. January, 2015.\n[184] JP Buntinx \u201cWhat is Delegated Proof-of-Stake?\u201d. [Online] Avail-\nable:\nhttps://themerkle.com/what-is-delegated-proof-of-stake/\nApril 20, 2017. Accessed on August 1, 2019.\n[185] Kiayias, A., Russell, A., David, B., and Oliynykov, R. \u201cOuroboros:\nA provably secure proof-of-stake blockchain protocol\u201d.\nAnnual\nInternational Cryptology Conference pp. 357-388. August, 2017.\n[186]\n\u201cOUROBOROS PROOF OF STAKE ALGORITHM\u201d.\n[Online]\nAvailable:\nhttps://cardanodocs.com/cardano/proof-of-stake/\nAccessed on August 2, 2019.\n[187]\n\u201cCardano Platform\u201d.\n[Online]\nAvailable:\nhttps://www.\ncardanohub.org/en/home/ Accessed on August 2, 2019.\n[188] \u201cEOS Platform\u201d. [Online] Available: https://eos.io/ Accessed\non 24 May, 2019.\n[189]\n\u201cEOS Whitepaper\u201d. [Online] Available:\nhttps://github.com/\nEOSIO/Documentation/blob/master/TechnicalWhitePaper.md\nAccessed on 24 May, 2019.\n[190] Kim, Jonathan\n\u201cEOS Raises Record-Breaking $4 Billion from\nCrowdsale\u201d.\n[Online]\nAvailable:\nhttps://cryptoslate.com/\neos-raises-record-breaking-4-billion-from-crowdsale/\n29 May,\n2018. Accessed on 24 May, 2019.\n[191]\n\u201cWhat is EOS? Most Comprehensive Guide Part 2\u201d. [Online]\nAvailable:\nhttps://blockgeeks.com/guides/what-is-eos-part-2/\nAccessed on 24 May, 2019.\n[192] Rosic, Ameer \u201cWhat is EOS Blockchain: Beginners Guide\u201d. [On-\nline] Available: https://blockgeeks.com/guides/eos-blockchain/\nAccessed on 24 May, 2019.\n[193]\n\u201cTron Platform\u201d. [Online] Available:\nhttps://tron.network/\nAccessed on 24 May, 2019.\n[194] \u201cTron Whitepaper\u201d. [Online] Available: https://tron.network/\nstatic/doc/white paper v 2 0.pdf Accessed on 24 May, 2019.\n[195]\n\u201cTRONs\nConsensus,\n\u201cHow\nit\nworks\u201d\u201d.\n[On-\nline]\nAvailable:\nhttps://medium.com/@TRONNews/\ntrons-consensus-how-it-works-6fd231b63715\n11\nNovember,\n2018. Accessed on 24 May, 2019.\n[196]\n\u201cTezos Platform\u201d.\n[Online]\nAvailable:\nhttps://tezos.com/\nAccessed on 24 May, 2019.\n[197] Goodman,\nL.M.\n\u201cTezos\nWhitepaper\u201d.\n[On-\nline]\nAvailable:\nhttps://tezos.com/static/white\npaper-2dc8c02267a8fb86bd67a108199441bf.pdf\n2\nSeptember,\n2014. Accessed on 24 May, 2019.\n[198] Arluck,\nJacob\n\u201cLiquid\nProof-of-Stake\u201d.\n[Online]\nAvailable:\nhttps://medium.com/@TRONNews/\ntrons-consensus-how-it-works-6fd231b63715\n31\nJuly,\n2018.\nAccessed on 24 May, 2019.\n[199] Arluck, Jacob \u201cOverview of Tezos Economics Model\u201d. [Online]\nAvailable:\nhttps://www.in\ufb01nitystones.io/tezos/ Accessed on 24\nMay, 2019.\n[200] \u201cLisk Platform\u201d. [Online] Available: https://lisk.io/ Accessed\non 1 June, 2019.\n[201]\n\u201cLisk Whitepaper\u201d. [Online] Available:\nhttps://github.com/\nslasheks/lisk-whitepaper/blob/development/LiskWhitepaper.md\nAccessed on 1 June, 2019.\n[202] \u201cArk Platform\u201d. [Online] Available:\nhttps://ark.io/ Accessed\non 1 June, 2019.\n[203]\n\u201cArk Whitepaper\u201d.\n[Online]\nAvailable:\nhttps://ark.io/\nWhitepaper.pdf Accessed on 1 June, 2019.\n[204] Ateniese, Giuseppe and Bonacina, Ilario and Faonio, Antonio and\nGalesi, Nicola \u201cProofs of Space: When Space Is of the Essence\u201d.\nIn proceedings of 9th International Conference on Security and\nCryptography for Networks: , SCN 2014, Amal\ufb01, Italy, September\n3-5, 2014.\n39\n[205]\n\u201cPeercoin discussion forum, discussion#2524\u201d. [Online] Avail-\nable: https://talk.peercoin.net/t/the-complete-guide-to-minting/\n2524 June 15, 2014. Accessed on May 5, 2019.\n[206] \u201cHyperledger\u201d. [Online] Available: https://www.hyperledger.\norg/ Accessed on July 10, 2019.\n[207]\n\u201cHyperledger Fabric\u201d.\n[Online]\nAvailable:\nhttps://www.\nhyperledger.org/projects/fabric Accessed on July 10, 2019.\n[208]\n\u201cHyperledger Sawtooth\u201d. [Online] Available:\nhttps://www.\nhyperledger.org/projects/sawtooth Accessed on July 10, 2019.\n[209]\n\u201cHyperledger Burrow\u201d.\n[Online]\nAvailable:\nhttps://www.\nhyperledger.org/projects/hyperledger-burrow\nAccessed on July\n10, 2019.\n[210]\n\u201cHyperledger Iroha\u201d.\n[Online]\nAvailable:\nhttps://www.\nhyperledger.org/projects/iroha Accessed on July 10, 2019.\n[211]\n\u201cHyperledger Indy\u201d.\n[Online]\nAvailable:\nhttps://www.\nhyperledger.org/projects/hyperledger-indy Accessed on July 10,\n2019.\n[212] \u201cApache Kafka\u201d. [Online] Available: https://kafka.apache.org\nAccessed on July 10, 2019.\n[213]\n\u201cApache Zookeeper\u201d. [Online] Available:\nhttps://zookeeper.\napache.org/ Accessed on July 10, 2019.\n[214]\n\u201cMonax Industries Limited\u201d.\n[Online]\nAvailable:\nhttps:\n//monax.io/ Accessed on July 10, 2019.\n[215]\n\u201cIroha Codebase\u201d. [Online] Available:\nhttps://github.com/\nhyperledger/iroha Accessed on July 10, 2019.\n[216] Palanivel,\nC.\n\u201cHyperledger\nIroha\n-\nArchitecture,\nFunctional/Logical\nFlow\n&\nConsensus(YAC)\nMechanism\u201d.\n[Online]\nAvailable:\nhttps://www.linkedin.com/pulse/\nhyperledger-iroha-architecture-functionallogical-chandrasekaran/\nApril 30, 2018. Accessed on July 10, 2019.\n[217]\n\u201cHyperledger Architecture, Volume 1\u201d.\n[Online]\nAvail-\nable:\nhttps://www.hyperledger.org/wp-content/uploads/2017/\n08/Hyperledger Arch WG Paper 1 Consensus.pdf August, 2017.\nAccessed on July 10, 2019.\n[218] \u201cgRPC\u201d. [Online] Available: https://grpc.io/ Accessed on July\n10, 2019.\n[219]\n\u201cIroha Documentation\u201d.\n[Online]\nAvailable:\nhttps://iroha.\nreadthedocs.io/en/latest/index.html Accessed on July 10, 2019.\n[220] Chen, L., Xu, L., Shah, N., Gao, Z., Lu, Y., & Shi, W. \u201cOn Se-\ncurity Analysis of Proof-of-Elapsed-Time (PoET)\u201d. In International\nSymposium on Stabilization, Safety, and Security of Distributed\nSystems, pp. 282-297, November, 2017.\n[221]\n\u201cBurrow Codebase on Github\u201d.\n[Online]\nAvailable:\nhttps:\n//github.com/hyperledger/burrow Accessed on July 10, 2019.\n[222] Ferdous, M.S., Chowdhury, F. and Alassa\ufb01, M.\n\u201cIn Search of\nSelf-Sovereign Identity Leveraging Blockchain Technology\u201d. IEEE\nAccess, 7, pp.103059-103079, 2019.\n[223]\n\u201cSovrin Foundation\u201d. [Online] Available:\nhttps://sovrin.org/\nAccessed on March 27, 2018.\n[224] Aublin, P. L., Mokhtar, S. B., and Quma, V. \u201cRbft: Redundant\nbyzantine fault tolerance\u201d. In IEEE 33rd International Conference\non Distributed Computing Systems (ICDCS), 2013, pp. 297-306, July\n2013.\n[225]\n\u201cIroha\nConsensus\nDiscussion\u201d.\n[Online]\nAvailable:\nhttps://github.com/hyperledger/indy-plenum/blob/master/\ndocs/main.md Accessed on July 10, 2019.\n[226] Dogan, T.\n\u201cWho Scales It Best? Blockchains\u2019 TPS Ana-\nlysis\u201d.\n[Online]\nAvailable:\nhttps://hackernoon.com/\nwho-scales-it-best-blockchains-tps-analysis-pv39g25mg Accessed\non July 27, 2019.\n[227] O\u2019Neal,\nS.\n\u201cWho\nScales\nIt\nBest?\nInside\nBlock-\nchains\nOngoing\nTransactions-Per-Second\nRace\u201d.\n[On-\nline]\nAvailable:\nhttps://cointelegraph.com/news/\nwho-scales-it-best-inside-blockchains-ongoing-transactions-per-second-race.\nJanuary 22, 2019. Accessed on July 27, 2019.\n[228] LeMahieu, C.\n\u201cNano: A Feeless Distributed Cryptocurrency\nNetwork\u201d. [Online] Available: https://nano.org/en/whitepaper.\nAccessed on July 27, 2019.\n[229] Popov, S.\n\u201cThe Tangle\u201d.\n[Online]\nAvailable:\nhttps:\n//assets.ctfassets.net/r1dr6vzfxhev/2t4uxvsIqk0EUau6g2sw0g/\n45eae33637ca92f85dd9f4a3a218e1ec/iota1 4 3.pdf. April 30, 2018.\nAccessed on July 27, 2019.\n",
    "2203.00398": "1\nWeb3: A Decentralized Societal Infrastructure for\nIdentity, Trust, Money, and Data\nJ.W. Bambacht and J.A. Pouwelse\nJ.W.Bambacht@student.tudelft.nl, J.A.Pouwelse@tudelft.nl\nDistributed Systems, Delft University of Technology\nMarch 4, 2022\nAbstract\u2014A movement for a more transparent and decen-\ntralized Internet is globally attracting more attention. People\nare becoming more privacy-aware of their online identities and\ndata. The Internet is constantly evolving. Web2 focused on\ncompanies that provide services in exchange for personal user\ndata. Web3 commits to user-centricity using decentralization and\nzero-server architectures. The current digital society demands a\nglobal change to empower citizens and take back control. Citizens\nare locked into big-tech for personal data storage and their\nfor-pro\ufb01t digital identity. Protection of data has proven to be\nessential, especially due to increased home Internet traf\ufb01c during\nthe COVID pandemic. Citizens do not possess their own travel\ndocuments. The European Commission aims to transition this\ngovernmental property towards self-sovereign identity, introduc-\ning many new opportunities. Citizens are locked into banks with\nnon-portable IBAN accounts and unsustainable legacy banking\ninfrastructures. Migration to all-digital low-fraud infrastructures\nand healthier competitive ecosystems is essential. The overall\nchallenge is to return the power to citizens and users again. The\ntransition to a more decentralized Internet is the \ufb01rst crucial\nstep in the realization of user-centricity. This thesis presents the\n\ufb01rst exploratory study that integrates governmental-issued travel\ndocuments into a (decentralized) societal infrastructure. These\nself-sovereign identities form the authentic base to a private\nand secure transfer of money and data, and can effectively\nprovide trust in authenticity that is currently missing in online\nconversations. A fully operational zero-server infrastructure that\nincorporates all our requirements has been developed for An-\ndroid using the P2P network overlay IPv8 [1], and a personalized\nblockchain called TrustChain [2]. It contributes to a reformed\ntech and \ufb01nancial sector that is more ef\ufb01cient and effective in\nserving the wider economy, and more resistant to bad behavior\nof all kinds. Creating such an infrastructure that is decentralized\nand anti-fragile is deemed crucial for the future.\nI. INTRODUCTION\nThe online world is dominated by big-tech monopolies.\nThese companies hold a relatively large amount of power\nin relation to citizens. As a result, citizens have dif\ufb01culty\nprotecting their data. The WhatsApp messaging platform is\na motivating example of market failure as it violates terms\nof service over a long period [3]. An update of their terms\nof service [4], providing mother company Facebook access\nto more user data, initiated a migration to other platforms.\nCompetitors focused on privacy and openness have barriers\nto market entry, no network effect, and compete against long\nexistent closed protocols. Citizens and small(er) competitors\n[5] are powerless in this uncompetitive market.\nDigitization generally weakens the privacy of citizens. The\nEuropean Union started an ongoing effort into the General\nData Protection Regulation (GDPR) [6] in 2016, targeting the\nmisuse of privacy-sensitive data by companies. Many compa-\nnies and platforms failed to comply to personal data protection,\nresulting in over 900 \ufb01led cases of GDPR complaints, with a\ntotal value over 1.3 billion euros [7]. Due to such efforts,\ncitizens have become more privacy-aware of their online\ndata and identities [8]. Commercial entities have an incentive\nto minimize spending on cybersecurity [9]. The storage of\npersonal data and weak security mechanisms of platforms\nare both at the expense of the user. These companies often\ngain revenue and value by selling user data for personalized\nadvertisements. Users have no other option but to rely on the\nbest intentions of the platform owner on their data.\nIn many situations, personally identi\ufb01able information of\ncitizens is unnecessarily exposed. Government-issued docu-\nments are often required for institutions or organizations like\nbanks, insurance companies, hotels, and employers, but lack\nsecure handling and storage. Online governmental authentica-\ntion mechanisms for digital identities are widely deployed by\nauthorized institutions but have equal concerns. The owners of\nthese identities are forced to accept and transfer all personal\ninformation. Both citizens and governments could bene\ufb01t\nfrom the use of self-sovereign identities (SSI). As a result,\ncitizens will be given the control over their own identities.\nFurthermore, external dependencies on authentication and\nstorage can be eliminated. Of\ufb02ine identity authentication and\nidentity attestations in a user-centric fashion can still offer\nthe required identity authenticity. The possibilities of the SSI\nare additionally suited to a wide range of applications. We\ncan pro\ufb01t from the self-sovereign identity within our societal\ninfrastructure for the enforcement of authentic trust between\nidentities in online conversations with the goal to reduce\nphishing or impersonating attacks. Other applications may in-\nclude authenticated signing of digital documents, and validated\nstorage of diplomas and COVID vaccination certi\ufb01cates.\nGovernments, banks, and tax of\ufb01ces have general insight\ninto the bank accounts and transactions of citizens, often\nusing big-tech cloud services. Not only is this a violation\nof citizens\u2019 privacy, but these banking services also have\nseveral de\ufb01cits. The transaction costs are disproportional\nas debit card transactions range from e0,05 to e0,20 per\ntransaction [10], and even bigger numbers for external\npayment services like iDEAL [11]. Cross-border payments\neven have increased costs and settlements. Cash is only\napplicable in of\ufb02ine payments and still serves as a store of\nvalue for some. It offers respectable privacy but is (slowly)\nfading away [12]. The current \ufb01nancial system can bene\ufb01t\nfrom the adoption of blockchain technology. Central Bank\nDigital Currencies (CBDC) aims to provide a faster, more\nef\ufb01cient, and cheaper alternative to electronic payments. With\ncharacteristics as privacy-awareness, pseudo-anonymity, and\narXiv:2203.00398v2  [cs.DC]  3 Mar 2022\n2\nunrestricted cross-border payments, CBDC can transform the\n\ufb01nancial system into a sustainable and frictionless system.\nThis research contributes the following: (I) design of a novel\ndecentralized infrastructure that incorporates a self-sovereign\nidentity, (II) applicance of the self-sovereign identity for\nidentity attestations and authentic trust enforcement between\nparticipants of communication, (III) generic transfer of money,\n(IV) generic transfer of data using a custom-designed P2P data\ntransfer protocol.\nII. PROBLEM DESCRIPTION\nThe goal of this study is to design a novel decentralized so-\ncietal infrastructure that incorporates a self-sovereign identity\nas an authentic base. We can additionally apply this identity\nin a useful way to facilitate authentic trust between users, and\nto privately transfer money and data with other identities. In\na centralized infrastructure, platform owners are still able to\ncollect metadata belonging to encrypted data. Removing these\nsingle points of failure reduces the violation of privacy and\nsecurity of users.\nThe key aspect of our research is the application of citizens\u2019\nself-sovereign identities. Self-sovereign identity is character-\nized by the ten principles of Allen [13, 14], that try to\nassure the users\u2019 control within its own SSI, with a balance\nbetween transparency, fairness, and protection. Governments\ncurrently have ownership and control of these identities.\nVarious opportunities arise by moving the power back to the\nuser. Firstly, the user is the owner of their own identity and\ncan view and decide what information to share. Secondly,\nas governments don\u2019t have control anymore, less personal\ndata management is required, less bureaucracy, and a cost\nreduction for facilitating the heavily secured infrastructure and\nauthentication mechanisms. Thirdly, the decrease of personal\ndata on central servers reduces the possibility of data breaches\nand theft. And \ufb01nally an opportunity arises to replace visual\nidentity document checks. Currently, identity documents are\nexposed upon request of some authority. Not only does the\nrequested information become visible, but also the complete\ndocument. By using identity attestations, authorities are able\nto verify information of the identity without exposing the\nactual value, e.g. age validation of a bouncer in the pub.\nCommunication channels lack trust in the authenticity of other\nparticipants\u2019 online identities. Since we have access to an\nof\ufb01cial SSI, we can even apply this information to build\ntrust. No social platform currently integrates government-\nissued identity information in such a fashion. Generally, online\nidentities consist of a name, picture, phone number, or email,\nthat altogether contribute to con\ufb01dence in the authenticity\nof the other user\u2019s identity. However, these attributes are\nmanually forgeable and can be impersonated. Malicious actors\ntry to make their fake identities look as genuine as possible to\nmimic someone\u2019s identity. Without these editable components\nand with automatic acquiring of information from the SSI, we\ncan enforce authentic trust to other participants.\nThe global \ufb01nancial infrastructure is failing to provide real-\ntime cross-border payments and is dominated by monopoly\nplayers with high pro\ufb01ts and near-zero innovation. Financial\nprivacy disappeared in the last decade(s). Governments, banks,\nand tax of\ufb01ces heavily supervise the bank accounts and\ntransactions of users, albeit using automatic cloud services, re-\nmoving the option to privately exchange money digitally. The\ntransfer of money comes with disproportional costs, adverse\ncross-border payments in terms of speed and additional costs,\nand unwanted transparency. Many of these issues can be solved\nby the use of blockchain technology, and speci\ufb01cally Central\nBank Digital Currencies (CBDC). With (almost) zero costs,\ntransactions are executed between wallets anywhere in the\nworld in a matter of seconds. Even internal use of blockchain\nfor banks themselves will save about 10 billion dollars globally\n[15]. Despite the openness of blockchain transactions to prac-\ntically anyone, pseudo-anonymity is maintained as the identity\nis not revealed.\nCentralized platforms inherently lack the self-sovereignty of\ndata of their users. As the use of central servers is pro\ufb01table\nin terms of availability and synchronization, personal data\nand metadata of users are stored. Although the data itself is\noften encrypted, the metadata contains valuable information\n(sender, recipient, time, location). WhatsApp is the most\nused messaging app [16] and promises its users end-to-end\nencryption. That does not withhold them to store a vast amount\nof metadata. Even though these platforms make us think\nthat they prioritise security and privacy, not giving up their\ncentralized nature is the primary reason for the existence of\ncyber attacks [17].\nDecentralization as part of a societal infrastructure with a\nself-sovereign identity introduces many new opportunities and\nadvantages. The user obtains a more centric position, has more\nprivacy, and remains in control and in possession of their own\ndata and identity. A self-sovereign identity can even serve a\nwider range of applications such as building authentic trust\nwith others in online conversations. Communication no longer\nincludes the storage of personal metadata on servers. Gov-\nernments require less highly-secured infrastructures, which\nreduces the overall costs for both governments and citizens.\nThe transfer of digital money between identities has major\nadvantages. A reformed \ufb01nancial system is more ef\ufb01cient,\nfaster, and optimal for cross-border payments while preserving\nthe privacy of citizens. In the following sections, we discuss\nthe related work in III, the design and implementation of the\n\ufb01rst user- and identity-centric infrastructure is presented in\nsections IV, V, and VI. Our custom-designed P2P data transfer\nprotocol is analyzed and evaluated in Section VII.\nIII. RELATED WORK\nSelf-sovereign identity provides citizens the control of their\nown identity. Citizens currently authenticate their identity\nto organizations and institutions, stored on the governments\ncentral server. DigiD1 is the primary identity authenticator\nin the Netherlands and enables citizens to authenticate. Per-\nsonal data is transferred from the government\u2019s server to\nthe organization\u2019s server. This requires a perfectly secure\nconnection and infrastructure on both sides. The citizen has\n1https://www.digid.nl\n3\nTABLE I: Comparison with related works\nP2P\nopen source\nE2E Encryption\nmetadata\nrequirements\nattributes\nused for trust\nenforcement\nwallet\nmaturity a\nnote\nCentralized\nWhatsApp [18]\n\u0017\n\u0017\ncurve25519\n\u0013\nphone number\nphone number, name,\npro\ufb01le picture and status\n\u0017\nhigh\nFacebook Messenger [19]\n\u0017\n\u0017\ncurve25519\n\u0013\nFacebook pro\ufb01le\nFacebook pro\ufb01le,\nname, pro\ufb01le picture\n\u0017\nhigh\nb\nWeChat (QQ) [20]\n\u0017\n\u0017\n\u0017\n\u0013\nphone number\nphone number, name,\npro\ufb01le picture and ID\nmoney\nhigh\nTelegram [21]\n\u0017\n\u0017\nMTProto\n\u0013\nphone number\nphone number, name, username,\npro\ufb01le picture and status\n\u0017\nhigh\nb\niMessage [22]\n\u0017\n\u0017\nNIST P-256 curve\n\u0013\nApple pro\ufb01le\nphone number, name,\nemail, pro\ufb01le picture\n\u0017\nhigh\nSignal Messenger [23]\n\u0017\n\u0013\ncurve25519,\ncurve448\nminimum c\nphone number\nphone number, name,\npro\ufb01le picture and status\ncrypto\nhigh\nDecentralized\nSession Messenger [24]\n\u0017\n\u0013\ncurve25519,\ncurve448\nminimum c\n\u0017\nname,\npro\ufb01le picture\n\u0017\nmedium\nd\nStatus.im [25]\n\u0013\n\u0013\ncurve25519\nminimum c\n\u0017\nusername,\npro\ufb01le picture\ncrypto\nhigh\nSylo [26]\n\u0013\n\u0017\ncurve25519\n\u0013\n\u0017\nname,\npro\ufb01le picture\ncrypto\nhigh\ne\nBerty [27]\n\u0013\n\u0013\ncurve25519\nminimum c\n\u0017\nname,\npro\ufb01le picture\n\u0017\nmedium\nOur design (Section V)\n\u0013\n\u0013\ncurve25519\nminimum c\nof\ufb01cial Identity\nidentity name and veri\ufb01cation\nstatus, pro\ufb01le picture\ncrypto\nmedium\nathe current state of development in terms of completeness and usefulness\nbE2E encryption not enabled by default\ncno storage of metadata, only required for routing\ndfork of Signal Messenger, onion routing for metadata anonymity, undelivered messages stored one of the distributed service nodes\neeveryone can set up node and will be rewarded in crypto token SYLO\nno control over what information is shared. Additionally, these\nauthentication mechanisms are disproportionately expensive\nand credited e0, 13 for all 545 million successful authentica-\ntions in 2021 [28, 29], especially due to increase of COVID-\nrelated authentications. Self-sovereign identities can be applied\nto mobile applications that replace authentication services like\nDigiD at a fraction of the cost. The \ufb01rst example is IRMA2,\nan operational mobile platform that fetches the identity from\nthe governmental servers once and stores the SSI and other\npersonal information locally on the phone. The authentica-\ntion to organizations can instead be performed of\ufb02ine using\nthe stored SSI. The user remains in control by seeing the\nrequested and shared information. Sovrin Network3 uses the\nsame methodologies but instead enables other developers to\nbuild their own SSI application on top of their blockchain-\nbased ecosystem. Some situations require the option to revoke\nthe self-sovereign identity, for example when the identity\ndocument is lost or stolen. Both IRMA and Sovrin apply\n(centralized) authorities to revoke identities. This is a violation\nof the principles of SSI as it should be an authority-free\nsystem. The work of Chotkan [30] incorporates distributed\nattestations for self-sovereign identities that includes of\ufb02ine\nrevocation. Of\ufb02ine veri\ufb01cation of attestations offers increased\nprivacy and robustness.\nAs mentioned before, this paper presents a novel decentral-\nized infrastructure and incorporates a government-issued iden-\ntity within a messaging platform. Many other platforms exist,\n2https://irma.app\n3https://sovrin.org\nboth centralized and decentralized, that apply at least some of\nthe key points of this paper. Table I portrays a (non-exhaustive)\nlist of signi\ufb01cant competitors in the market. The difference\nbetween the centralized and decentralized platforms shows a\nclear clustering. All centralized platforms require a privacy-\nsensitive asset and attributes that are shared with contacts\nto identity and enforce trust. The decentralized platforms are\nexamples of Privacy by Design [31] as they try to minimize the\n(centralized) storage of data and leakage of privacy-sensitive\ninformation. Decentralized platforms have not explicit initial\nrequirements and the trust attributes are limited to manually\nchosen names and pro\ufb01le pictures.\nWhatsApp [18], Facebook Messenger [19], and WeChat\n[20], are fully centralized platforms that store metadata of\ntheir users. The industry-standard E2E encryption curves are\nused by all platforms but Telegram [21], that uses their self-\ndesigned protocol, and the unencrypted WeChat. WeChat,\nwhich is monitored by the Chinese government, incorpo-\nrates strong censorship and interception protocols for data\nexchanged by its citizens. This degree of monitoring is not\npresent in other (centralized) platforms. Governments even\noblige these centralized platforms to share their stored meta-\ndata or apply censorship in some situations [32, 33]. Signal\nMessenger [23], which is centralized but speci\ufb01cally designed\nwith privacy in mind, does not store any personal informa-\ntion. However, central servers are necessary for routing and\nfunctionalities like account recovery. Account activation is\nvalidated using the phone number or email address of the\nuser. Characteristically, most of the centralized platforms don\u2019t\nprovide full transparency and do not disclose the complete\n4\nFig. 1: General overview of the infrastructure\nstructure of their platform.\nDecentralized infrastructures try to realize anonymity by\nminimizing the metadata in the network. Session Messenger\n[24], a decentralized fork of Signal Messenger, attempts to\nprovide anonymity and preservation of privacy using onion\nrouting [34]. It makes it nearly impossible for any intermediary\n(node) to derive both the sender and receiver of the message.\nOnion routing is not suitable in a (fully) P2P network as peers\nonly know a limited number of other peers and do not (nec-\nessarily) communicate with nodes. Status [25], Sylo [26], and\nBerty [27] are decentralized, P2P, secure, minimize leakage of\nprivacy-sensitive information, and have no initial requirements.\nStatus is build on the Ethereum network and incorporates its\nown utility network token to provide paid features to users.\nLike Session Messenger, undelivered messages are stored on\nnodes that obtain your IP address to deliver it later. This\ncharacteristic contradicts the principles of privacy. Sylo is a\nfully operational platform that is not protected against possible\nleakage of metadata and does not provide full transparency to\nits users. Berty is secure and transparent, minimizes leakage\nof privacy-sensitive information in terms of metadata and\nrequirements, and therefore suits our requirements best, but\nis currently still underdeveloped.\nThere are many implementations with the same design\ncharacteristics. The idiomatic platform is decentralized, does\nnot require temporary storage of messages on nodes due\nto its P2P nature, incorporates trusted encryption, does not\nrequire and store metadata, and has no redundant identi\ufb01-\nable requirements. Our design uniquely adds a self-sovereign\nidentity, providing various functionalities. To achieve higher\ntrustworthiness, trust enforcement attributes must not only\nconsists of manually forge-able components. Furthermore, the\nplatform must contain private and secure mechanisms for the\ntransfer and storage of data and digital money.\nIV. INFRASTRUCTURE\nThe dominant problem of market-leading societal platforms\nis their centralized nature. Decentralization targets many weak\nspots of centralization, such as providing private and secure\nstorage of data in a distributed way. Even a decentralized\nnetwork allows the storage of metadata by the nodes that are\ntraversed on its path to the destination. Some nodes may even\nsell metadata to third parties. A P2P network enables direct\ncommunication with peers without any intermediary. As no\nintermediary is able to act as a middle-man or adversary, it\nserves as an extra layer of protection against malicious or\nintentional behavior. The communication is only secure if the\nmessage, or data, is encrypted.\nWe also require a component to store and exchange data in\na distributed manner. One of the requirements of distributed\nsystems is synchronization across many independent nodes.\nThis is dif\ufb01cult to realize in systems that include peers that\nare not connected at all times. To enable the transfer of\n(digital) money, the infrastructure requires a persistent and\ndecentralized storage of data that does not require continuous\nsynchronization for all peers. Blockchains store transactions\nbetween two wallets in a permanent and uneditable manner.\nEvery transaction on the blockchain is entangled to its previous\nblock, making it a reliable chain of tamper-proof assets.\nThis form of storage is a fast, lightweight, and structured\nalternative to conventional storage, albeit visible to everyone.\nEvery transaction can be back-traced to create a well-organized\noverview, which is well suited to serve as a wallet. The\ninfrastructure additionally requires data transfer protocols to\nexchange data. Figure 1 portrays a low-level overview of our\ninfrastructure.\nPeers constantly observe other peers in the network. The in-\nfrastructure requires anonymous peer identi\ufb01cation as it is not\ndesirable to spread personal information to (unknown) peers\nin the network. To ensure a secure communication channel,\nthe principles of the CIA Triad [35] must be in place. The\nobjectives of a secure system include Con\ufb01dentiality, Integrity,\nand Availability. Con\ufb01dentiality ensures that information is\nonly accessible to authorized parties. Digital signatures ensure\nthe integrity of the information by providing proof that it\noriginates from the sender and has not been altered by any\nthird party. Availability ensures that information is available to\nauthorized parties at any point in time. In P2P networks, only\nthe last principle is dif\ufb01cult to realize due to its dependence\non the connectivity of individual peers.\nCon\ufb01dentiality requires the encryption of information.\nPublic-key cryptography [36] is the most commonly-used\nmechanism for secure communication. Con\ufb01dential exchange\nof messages and data additionally enables the identi\ufb01cation\n5\nof peers exposing private information. Each peer has a public-\nprivate key pair. The private key is cryptographically generated\nonce and only be known to the owner. The private key decrypts\nthe encrypted data. The public key is mathematically derived\nfrom the private key and may be public as it is computationally\ninfeasible to derive the private key from the public key. The\npublic key provides several applications in our infrastructure.\nForemost, the public key of the intended recipient is used for\nthe encryption of the data. Secondly, digital signatures prove\nthe authenticity of data and can be veri\ufb01ed using the public\nkey of the signatory/sender. And lastly, peers can be identi\ufb01ed\nand distinguished using their public key.\nA. Networking Layer\nOur infrastructures requires a networking layer to handle\noutgoing and incoming communication with peers. A P2P\nnetworking layer that is authenticated and privacy-aware is\nIPv8 [1]. IPv8 is developed as an academic successor of\nIPv4 and attempts to overcome IPv4\u2019s weak characteristics\nand growing number of problems. The objective of IPv8\nis to provide communication in a zero-server infrastructure,\nequal status and power within the network for everyone,\nand perfect secrecy with E2E encryption. IPv8 can establish\nconnections to peers, even for devices connected behind NAT\nor a (strong) \ufb01rewall. The endpoints of the networking layer\nare independent of any central infrastructure.\nThe aim is to minimize the exposed metadata. For this\nreason, data packets can\u2019t be broadcasted on the network, in\nthe hope that other peers can deliver the packet to the intended\nrecipient. Some P2P systems employ distributed nodes to\ndeliver the data in this situation. These nodes temporarily store\ndata and metadata until delivered. Although this addresses\nthe availability of information in the network, it exposes\nthe storage and possible leakage of metadata. The metadata\nof a packet should (ideally) only contain information about\ndelivery, that is, the receiver\u2019s public key or IP address.\nThe metadata that is not relevant for delivery should be\nencrypted with the data. The risk of exposing privacy-sensitive\ninformation in our P2P network is minimized as peers directly\ncommunicate without serviceable nodes or peers. Peers change\nconnectivity status or change their network address regularly.\nIn these situations the peers announce their new address to\nall former peers to keep the previous connections alive. Peers\nalso connect to random peers to broaden their network reach.\nWhile this may sound contradictory, it does not violate their\nprivacy. No personal information, including the intentions and\nprevious communication histories, can be deduced.\nIPv8 applies the concept of network overlay or community.\nThis enables developers to build applications on top of the\nbase networking layer by creating their own community. We\nneed several communities in our infrastructure to satisfy our\nrequirements. The base community includes all functionalities\nrelated to peer connectivity, communication, data serializa-\ntion, and encryption. The IPv8 networking layer combines\nresponsibilities from several layers of the OSI model [37].\nCommunities that require the storage of data, can use an\nadditional store that handles the interaction with a database. A\ndiscovery community handles the discovery and connection of\n(new) peers present in the same community. Every community\nand peer may have a different list of connected peers. The\ncommunication between peers in the network and commu-\nnity is handled by endpoints/sockets. IPv8 provides support\nfor both online and of\ufb02ine communication using UDP and\nBluetooth endpoints. The support for of\ufb02ine communication\nincreases the reliability and applicability of the platform,\nespecially in areas with low network coverage.\nB. Distributed Ledger\nThe infrastructure requires a distributed ledger that han-\ndles and stores the \ufb01nancial transactions. The permission-\nless and scalable distributed ledger TrustChain [2] is already\nintegrated as a community in IPv8. TrustChain is capable of\nsending and receiving trusted transactions between peers. The\nblockchain-based data structure is a tamper-proof immutable\nchain of transactions. No central authority has control over\nthe transactions. Every peer implements a personalized chain\nthat contains only blocks related to that peer, i.e. either sent or\nreceived by the peer. TrustChain has three basic functionalities:\ntransmit/receive blocks, broadcast blocks, and chain crawling.\nThe transmit and receive process merges both parties in one\ntransaction, see Figure 2. The initiator (p0) creates, signs,\nFig. 2: Transaction in the ledger\nand sends the proposal block to the counterparty (p1). On\nreceipt of the proposal block, (p1) creates, signs, and sends\nthe agreement block back to p0. Both blocks are linked by the\npublic key of the counterparty and can be considered as half\nblocks that together form a transaction. During the process, the\nintegrity of the received blocks is validated and both parties\nadd the half blocks to their chains. The transaction is complete\nwhen both parties received and signed both half blocks, i.e.\nboth acknowledged and accepted its contents. The broadcast\nfunctionality enables to transmit the block to all connected\npeers. Chain crawling is the retrieval of a peer\u2019s chain using\nits public key.\n6\nV. DESIGN\nWe can divide the design of the platform into four pil-\nlars: identity, trust, money, and data. These elements are\nintegrated within the infrastructure of Section IV to create\nan ecosystem that combines these elements seamlessly. The\nelements, described in the following sections, must satisfy\nthe requirements and functionalities that are deemed necessary\nfor a self-sovereign, secure, and privacy-aware communication\nplatform.\nA. Identity\nIdentity is an integral part of citizens when it comes to\nownership over their self-sovereign identity. Integration of\ngovernment-issued travel documents in a self-sovereign man-\nner introduces various new opportunities. One of the major\napplications is the authentication to online organizations. The\ncitizen controls the exchange of its own identity information to\norganizations instead of the conventional online governmental\nauthentication that blindly transfers all available information.\nAuthentication can only serve its purpose if the information\nwithin the self-sovereign identity is authentic. IRMA, the\napplication mentioned in Section III, achieves authenticity by\nfetching the identity information from the government\u2019s central\nserver once. As we desperately want to eliminate external\ndependencies, this method is not suited to our system. Every\n(adult) citizen is obliged to legitimate himself with a passport\nor identity card upon request by the authorities. As it is\nmandatory to posses such a document we can apply these\ndocuments as an authentic base for our platform. The identity\nwritten in the machine-readable zone (MRZ) of the document,\ncontains the same personal information as on the government\u2019s\nserver.\nThe identity document onboarding process is executed in\ntwo consecutive steps as in Figure 3. In the \ufb01rst step the\nuser must scan the text in the MRZ of the document using\nthe camera of the device, as in \ufb01g. 3a. A combination\nof AI and check digits (embedded in the MRZ) ensure a\nsyntactically valid, not necessarily correct, recognition of the\nidentity information that is saved on the device. The second\nstep is extremely important as it proves the authenticity of\nthe document digitally. This validation step determines the\ncorrectness of the scanned attributes. Most current documents\nare equipped with a built-in biometric chip in which the\ninformation is embedded. The NFC chip of devices enables\nthem to communicate with the document. The device must\nsteadily be placed with its back to the document until all\ninformation has been transferred, see Figure 3b. The biometric\nchip contains multiple layers of protection against for example\neavesdroppers and modi\ufb01cation. The protection prevents the\nunauthorized reading of the document using for example NFC\nskimmers. The authentication requires the document number,\ndate of birth, and date of expiry as passwords, as obtained in\nthe initial step. After the connection has been established, the\nbiometric chip transfers all requested attributes to the device.\nAll stored attributes together form the self-sovereign identity\nof the user. The onboarding process is deemed authentic and\nsecure because (I) a physical document is required and the\n(a) Scan MRZ zone of document\nusing the camera of the phone\n(b) Reading biometric chip using the\nNFC chip of the phone\nFig. 3: Identity document onboarding process\nattributes displayed on the card must match the content in the\nbiometric chip of the card, and (II) the biometric document\nis widely applied for governmental purposes and international\ntraveling, without excessive vulnerabilities [38]. One issue that\nremains is the possibility to revoke access to a self-sovereign\nidentity. Millions of documents get stolen or lost yearly [39],\nand risk of being used by others. There is no way to recognize\nand revoke access without knowledge from a central server.\nThe self-sovereign identity must be valid, just like physical\ndocuments, until the expiration date of the document.\nA different situation arises when the phone has no support\nfor the NFC chip, defectively or physically. There does not\nexist an (of\ufb02ine) method to obtain the identity authentically\nby only scanning the document. As the biometric chip per-\nforms the validation of the document, a malicious actor can\nforge the complete MRZ to its preference. No identity-related\nfunctionalities can be trusted to contain truthful and authentic\ninformation. There is no other option to either disable all\nthese identity-related functionalities for these devices or to be\ndependent on the government\u2019s central server to obtain the\nidentity.\nIn real-world situations, it is sometimes mandatory to show\nor even make a copy of your physical identity document to\nverify your identity or to serve as insurance. The authority\nis not only capable of unnecessarily viewing the requested\nattribute(s), but also other attributes on the document. This is\na direct violation of citizens\u2019 privacy and can even lead to\nidentity theft or misuse of a person\u2019s integrity. Citizens are\nforced to trust this authority to handle and store their identity\nsecure and with care. Self-sovereign identities introduce the\nopportunity to use veri\ufb01able claims. Veri\ufb01able claims are\nclaims about information that can be veri\ufb01ed using attestations.\nChotkan [30] designed a framework that incorporates revoca-\nble veri\ufb01able claims without revealing the actual requested\npiece of information using zero-knowledge proofs. To apply\nvariable claims in a trustworthy manner, the information from\nthe self-sovereign identity must, again, be authentic.\n7\nThe focus should not only be on data in transit, but also\non data at rest. In the latter, the data is stored somewhere\nwithout anyone currently accessing it. The data is often stored\nas a \ufb01le or in a database. In our case, the identity must be se-\ncured signi\ufb01cantly without risking identity theft. As mentioned\nbefore, our design applies public-private keys for encryption.\nThe storage of the identity can easily be encrypted using the\nprivate key of the user, while only allowing the application to\ndecrypt when absolutely required. That means that no one is\nable to access the contents outside the application environment\nas long as the private key is insusceptible. Biometric protection\n(face recognition or \ufb01ngerprint) or the use of passcodes, can\nbe applied as another layer of protection against unauthorized\naccess to sensitive data. It can also serve as con\ufb01rmation for\nirreversible actions like the transfer of sensitive information or\nmoney.\nB. Trust\nPlatforms have to deal with several types of trust. The \ufb01rst\nnatural form is trust in a system or platform. This is the case\nfor nontransparent centralized platforms. As a user, you want\nto have faith that your personal data is handled and stored\nwith care. This is often one of the primary problems with\ncentralization. As all user data is stored on the platform\u2019s\nservers, you must have con\ufb01dence that the data, including\nmetadata, is protected with the highest security standards,\nexchanged in encrypted form, and not sold to any third parties.\nIf no good alternative platform exists, or because no friends\nuse other platforms, the user has to decide whether to continue\nto use the platform and neglect the privacy-related issues,\nor not use the platform anymore. Often the \ufb01rst choice is\nselected as people value the use of the service more than their\nown privacy. Decentralization (almost) completely eliminates\nthis trust, or distrust, as there is no central component or\nauthority that decides over you and your data. Also, a platform\nthat is open source is generally more trusted as there are\nno hidden surprises due to the reviews of experts. We must\ntake notice that in some networks, malicious actors actively\ncrawl metadata in order to gain knowledge about con\ufb01dential\ninformation. Communication in P2P networks, in the form of\nnetwork packets, is directly transmitted to the network address\nof the recipient, making this problem almost redundant.\nIn messaging and societal applications another form of trust\narises: the trust in the real identity of the other participant. The\ncon\ufb01dence in the authenticity of the contact is determined\nbased on various factors like the (online) identity of the\ncontact, the (dis)similarity in the way they communicate,\nand the discussed topics. The style of writing and difference\nin for example punctuation and the use of capital letters\nmay also play a role in recognition. Unfortunately in most\napplications, personal information can easily be forged or\nstolen from people\u2019s (real) online identities. If we again look\nat Table I, most attributes for trust enforcement of centralized\nplatforms are forgeable. Spear phishing [40] is an cyber attack\nin which individuals are targeted with the explicit use of\npersonal information to gain knowledge or access to (more)\nsensitive information. In applications like WhatsApp, it is\npossible to migrate from one phone to another. As this is a\nconvenient feature, it also exposes the risk that hackers can\ntake over your account on their phone and communicate with\nyour contacts instead. This has the de\ufb01cit that hackers are\nable to use these accounts to steal con\ufb01dential information or\neven request money from trusted unsuspecting contacts. These\nhackers attempt to mimic as much con\ufb01dential information of\nthe hacked person to not arouse suspicion or to simply gain\ntrust with their new victims. For this reason we did not include\nmigration in our platform (yet). Another situation arises when\nthe phone is stolen or lost. As we don\u2019t have control anymore,\nit is (similarily to other platforms) possible to impersonate\nsomeone on a lost or hacked phone.\nFig. 4: Building trust using the self-sovereign identity\nThe challenge is to exchange the right amount of trust to\nthe recipient of your message without excessively exposing\nprivate information. In the initial phase of the conversation,\nespecially if the users connected in some online way, trust\n(or distrust) can play a major role. As valid self-sovereign\nidentities are incorporated in our design, we can access and\napply this authentic information. In a normal, physical \ufb01rst\nmeeting, one would introduce themselves by their (\ufb01rst) name,\nand indirectly with facial expressions, the sound of their voice,\nand the overall atmosphere. These aspects are not available in\nthe digital world without extra efforts. The only identi\ufb01able\ninformation that we can exchange is a person\u2019s name and photo\nas embedded in the self-sovereign identity. These attributes can\nprovide the authenticity that our system requires by sending it\nto the other contact. To provide proof of its authenticity, we\ncan include the identity veri\ufb01cation status. The veri\ufb01cation\nstatus formally denotes the trustworthiness of the name and\nphoto, while it technically denotes the use of the biometric\nand NFC chip. A different situation arises when users can\u2019t\nuse the NFC chip. These users can\u2019t be veri\ufb01ed as a result,\nand are able to choose their own name and photo to allow\nthem access and use of the platform. The contacts will in turn\nbe noti\ufb01ed of the unveri\ufb01ed status, implicating they should act\ncautiously.\nTABLE II: Trust enforcement combinations for identity name\nCombination\nExample\nI\n{First Name}\nTimothy John\nII\n{Last Name}\nBerners-Lee\nIII\n{First Name} {Surname[0]}\nTimothy John B.L.\nIV\n{First Name[0]} {Surname}\nT.J. Berners-Lee\nV\n{First Name} {Surname}\nTimothy John Berners-Lee\n8\nOf all information in the self-sovereign identity only the\nname and picture, and possibly the age and gender, are suitable\nto enforce trust. The transfer of too much con\ufb01dential infor-\nmation can lead to malicious misuse of them or their contacts.\nWe should therefore limit the exchange of information. We can\ncompose various combinations of the given and last name that\naim to provide trust, see Table II. While combination I and\nII are too general and unidenti\ufb01able, the use of the full name\nin V, as identically embedded in the self-sovereign identity,\nis an easy source for malicious actors to take advantage of.\nThe combinations III and IV include both the \ufb01rst and\nlast name in a modi\ufb01ed form and provide a more personal\nand identi\ufb01able view without exaggerating. The identity of a\nperson is more decisive by its last name due to its uniqueness,\nand therefore combination IV \ufb01ts our purpose best for the\nuse as the trust enforcement attribute along with the picture.\nThe exchange of the age and gender has been considered, but\nincreases the risk of impersonating.\nThe name and photo attributes of the peer\u2019s identity are\nsent encrypted along with every message. Upon receipt, the\nsystem is able to detect differences with the information of\nthe currently stored state. Initially, the state is empty. The\nrecipient of the \ufb01rst message will be noti\ufb01ed in a recognizable\nmanner that the identity of the contact has been determined.\nFor every other message, if at some point the state changes,\nthe user will receive similar noti\ufb01cations stating that the\ninformation has been updated. This mechanism makes sure\nthe user always has knowledge of the sender\u2019s formal identity.\nIt is, however, impossible to notice difference in case a phone\nis stolen or accessed unauthorizedly without an alteration of\nthe identity. On-device authorization is desirable using for\nexample biometric protection. As long as biometric protection\nis in place, it should be dif\ufb01cult to impersonate. Also, a\nmechanism that requires the user to regularly verify its identity\nusing their physical document could help to reduce misuse.\nBoth options are currently not part of our initial design but\nserve as improvements on authentic communication. It is\nequally important to not only focus on building trust but to\npreserve the privacy of the receiver as well. The platform\nwill never share identity information without having sent a\nmessage or transaction \ufb01rst. This reduces the risk of malicious\nactors purposely attempting to fetch names and photos linked\nto particular public keys.\nC. Money\nAs the need for \ufb01nancial privacy grows, many Web3 ap-\nplications integrate the transfer of some sort of value in the\nform of cryptocurrencies or NFT\u2019s. Governments of nations\nand unions are currently exploring the economic and tech-\nnical feasibility of Central Bank Digital Currencies (CBDC)\n[41, 42, 43, 44]. Money in the form of digital currencies\nthat re\ufb02ect on their native currency, often also referred to as\nstable coins, could provide a fast, cheap, and private exchange\nbetween participants. Other cryptocurrencies are not suited for\nthis purpose as they appear to be extremely volatile, therefore\nlacking the consistency for a safe store of value. CBDC has\nthree main characteristics: it is a digital currency, it is issued\nby a central bank, and it must be universally accessible. As\nthese currencies will be legally recognized and backed by their\ngovernments and central banks, their introduction and effect\non the \ufb01nancial system are heavily tested. If somewhere in the\nfuture, countries decide to become cashless, these currencies\nmust be creditable to replace coins and banknotes. China\nis already in the advanced stages of the development of its\nCBDC and is testing the implementation of its digital Yuan\nwallet in a second pilot [45]. The Bank of China will still\ninclude regulation for larger transactions and seek only to\ncollect personal information that is legally required. Compared\nto the principle of cryptocurrencies, which strives for pseudo-\nanonymous transactions, China doesn\u2019t make an effort to give\nup its (\ufb01nancial) regulation.\nGovernments, banks, and tax of\ufb01ces shouldn\u2019t have implicit\ninsights into transactions of CBDC\u2019s. The privacy of the users\nwill be preserved up to a certain level. As most ledgers\nand blockchains are transparent, transactions on the chain\nare visible to others, and can even view or attempt to trace\nback the wallet balance. Blockchain still provides pseudo-\nanonymity because participants of transactions are often only\nidenti\ufb01ed by a public key. No further personal information is\nattached to transactions apart from the sender and recipient\nand some unidenti\ufb01able transaction contents, statistics, and\npossibly some other (encrypted) data. Governments will not\nattempt to regulate and gain insight into these transactions be-\ncause, similarly to cash, it is simply not feasible to do so. If we\ncompare blockchain transactions with current digital payment\nsolutions, it is de\ufb01nitely a step forward, while conventional\ncash remains the most private and anonymous form of payment\nand store of value. Not only would the use of CBDC\u2019s\ncontribute to new innovations and direct accessibility of money\nwithout any external dependence, it may even serve some\nof the fundamental \ufb01nancial primitives (lending, borrowing,\nliquidity).\nCurrently, many external services or banks provide the\nfunctionality to create payment requests. Its creator shares a\nlink to all participants that redirects to the payment portal of\nthe service. This not only creates an additional dependency on\nthe use of a centralized (paid) service but also opens abusive\nopportunities for malicious actors. Many fraud cases [46] using\npayment requests make the service vulnerable, especially for\nunsuspecting persons or the elderly. P2P digital payments\ncan solve this problem by eliminating the dependence on the\nmiddle-man. The transaction or payment request is instead\ndirectly sent to the other peer, in an online or of\ufb02ine fashion.\nThis not only makes it faster and cheaper but also offers a\nmore private exchange of value.\nOur design incorporates an existing implementation of an\nof\ufb02ine-capable euro CBDC called EuroToken [47]. It utilizes\nthe distributed ledger TrustChain [2] that builds upon the\ntechnologies of the IPv8 network [1]. The EuroToken protocol\ntries to offer a scalable, privacy-aware, and cheating-resistant\nsystem for the exchange and storage of transactions. Every\nblock stored on the ledger contains a single transaction that\nstates the transfer of funds from one to another. A block is\ncryptographically linked to its predecessor and therefore pre-\nserving a chain of chronological and valid blocks. Transactions\n9\nare generally settled within seconds, independent of within-\nor cross-border payments, but require the connectivity of both\nparties to completely settle the transaction.\nOne of the aspects of a tokenized system is the acquisition\nof tokens. For the system to be useful, it requires at least one\noption to buy and sell these tokens. EuroToken incorporates a\ncentral exchange portal that allows users to exchange money\non their bank account with EuroTokens, in both directions.\nThe user and portal included in the exchange have to an-\nnounce themselves to each other using their public key and\nadditionally the transfer amount. The portal creates a request\nto the user that is automatically handled and stored by the\nprotocol. Although it is not desirable to integrate centralized\ncomponents in the system, it is considered an exception for the\nsystem to be functional. Improvements on the protocol could\ninclude distributed portals that are managed by random peers\ninstead of a single entity.\nAfter the initialization of the application, the wallet is ready\nto send and receive tokens. A balance is obviously required\nto send tokens. Tokens are either received by other peers or\nacquired using the exchange portal. The balance of a wallet is\ndetermined and validated using the blocks on the ledger. Our\ndesign fully integrates and stimulates the transfer of money\nbetween peers as it can be transferred directly from the wallet\nor indirectly from within a conversation with another peer. The\nintegration of internal payment requests conveniently enables\npeers to request tokens from other peers. A transfer request\ndiffers from a transaction as is not formal and binding, and\nonly contains the amount and the public key of the requestor.\nD. Data\nOne of the key applications of secure and private communi-\ncation is the decentralized transfer of data. Data is the collec-\ntive name for everything that can be expressed in the form\nof human-unreadable blobs, a Binary Large Object. These\nblobs can in turn be deserialized into a format that is readable\nfor humans, e.g. images or text documents. Messages, and\neven transactions, can thus be classi\ufb01ed as data as well. The\ncurrent implementation of IPv8 contains a basic data transfer\nprotocol. This protocol is able to send blobs to other peers,\ncontaining metadata and data. The transfer of data in form\nof messages and small blobs is fast but unreliable. However,\nthe protocol has proven to be limited in terms of performance\nfor larger-sized blobs. For proper use of our platform, it was\ndeemed necessary to design a custom data transfer protocol\nthat provides performance and reliable exchange of data, in a\nsecure and private fashion.\nThe designed data transfer protocol aims to provide reliable\nand optimal performance for everybody in a progressive and\nadaptive fashion. The protocol is fully integrated into IPv8 and\navailable to every community if necessary. Due to limitations,\nIPv8 (currently) only allows one concurrent transfer between\ntwo peers. The protocol is based on the principles of TFTP\n[48], the Trivial File Transfer Protocol. TFTP is a simple and\nconnection-less data transfer protocol, with the consequence\nthat it is unauthenticated and no security mechanisms are\nprovided. The transfer of con\ufb01dential data in (external) net-\nworks is unsafe, and therefore not recommended. Dedicated\nconnections with other peers cannot be established in P2P\nnetworks due to the lack of end-to-end connectivity. The long-\nexistent TCP protocol is connection-oriented and much more\nreliable, but is not suitable for that reason. For a connection-\nless protocol, the application of the User Datagram Protocol\n(UDP) [49] is an obvious choice. The question is how to\neffectively integrate the unreliable UDP in the design of a\nreliable data transfer protocol. For some purposes, for instance\nlive video streaming, the loss of single packets does not\nimpact the result as single video frames or pixels are simply\nskipped. In the case of our platform, the loss of packets would\nhave the de\ufb01cit of distorted and unusable data. Our protocol\nmust therefore keep track of unreceived packets and request\nretransmission. The operation of the protocol is very basic\nand only consists of four different packet types. All packets\nare encrypted and in principle only decryptable to the intended\nreceiver. The normal operation of the protocol is portrayed in\nFigure 5. The sender of the transfer \ufb01rst has to request to write\nFig. 5: Normal operation of the data transfer protocol\ndata by sending a WriteRequest payload/packet to the\nreceiver. With this packet, the sender additionally announces\nall transfer- and data-speci\ufb01c details to make sure both parties\nhave the same understanding. The receiver con\ufb01rms this\nrequest by returning an Acknowledgement packet. This\nacknowledgment triggers the sender to start the transmission\nof data with Data packets. The data cannot be sent in one\npiece for multiple reasons. Firstly, the maximum UDP packet\nsize is strictly limited to 1500 bytes due to the Maximum\nTransmission Unit (MTU) of the Ethernet [50]. The IPv8\nprotocol additionally requires a header of approximately 177\nbytes to each block for routing, identi\ufb01cation, and security\npurposes. Our Data payload header also requires identi\ufb01able\ninformation in the form of a block number, nonce, and\nsome other attributes. This means that the data inside the\npacket can be roughly somewhere between 1200 and 1250\nbytes. Secondly, since UDP is unreliable and packets are not\nguaranteed to be delivered, the transmission of the data at\nonce (if technically feasible) would be too much of a gamble\nto arrive, especially for large blobs. The protocol is required to\nsplit the data into small(er) pieces to \ufb01t the packets, creating\nblocks. Each of the blocks has a particular size in bytes and\nall blocks concatenated in the correct order represents the\ndata. To reliably transfer data from one to another, we have\n10\nto con\ufb01rm the receipt of the data packets by again sending\nan Acknowledgement packet. To not unnecessarily wait\nfor con\ufb01rmation and delay the transfer, the acknowledgment\n(and any other packet) must be received within a certain\ninterval before the previously sent packet is retransmitted. The\nprinciple of windowing allows multiple packets to be sent at\nonce without requiring an acknowledgment for every single\npacket. This increases the performance majorly as most of\nthe idle time of the sender is spent waiting for con\ufb01rmation.\nThe window size of the transfer de\ufb01nes the hard limit on how\nmany bytes or, equivalently, the number of blocks if we take\nthe block size out of the equation, can be sent within every\nwindow without intermediate acknowledging. After the last\nblock of the window has been received, the protocol sends an\nacknowledgment to the sender. It does not necessarily mean\nthat all blocks within that window have been received, as\nsome arrive later and some will not be delivered at all. In that\nacknowledgment, the receiver includes the block numbers that\nhave not been received (yet). The protocol could decide to only\ntransmit individual packets and wait for the con\ufb01rmation of\nreceipt. This, however, has several disadvantages. Firstly, the\ntransfer speed is signi\ufb01cantly decreased as additional transmit\nand acknowledge stages are added, including waiting time.\nRegularly UDP packets arrive late or not at all, meaning that\nfor a good part of the windows the unreceived blocks have to\nbe retransmitted, even for single unreceived blocks. Secondly,\nby staying at the current window, it may occur that some of\nthese packets have trouble being delivered, and the transfer\nmay not progress further for a longer period (in terms of\ntransfer time). To account for these drawbacks, the protocol\nwill always try to progressively continue its normal operation.\nThis means that these unreceived blocks will piggyback with\nthe next transfer window in the hope to be delivered without\ncausing an overall delay. For every next window that passes,\nthe con\ufb01dence in these blocks being delivered increases. If all\nwindows are sent, it may occur that there are some unreceived\nblocks left. In this case, the protocol will remain in the transmit\nphase of the last window until all blocks have been con\ufb01rmed.\nThe transfer is considered complete, for both the sender and\nreceiver, after receipt of the acknowledgment (sender) and last\nblock (receiver).\nThe receiver may not be able to adhere to the write request\nbecause either the data does not comply with the allowed\nsize between zero and a prede\ufb01ned limit, or both peers try to\nstart a transfer at the exact same time. In these situations an\nError packet is returned that contains the reason of refusal.\nBoth the sender and receiver have no other option but to\nterminate the transfer. During the transfer, it regularly happens\nthat no response is received for sent packets. Both the sender\nand receiver therefore use their own retransmit interval and\nretransmit attempt count. A retransmit is scheduled if the time\nbetween the last transmit and the allowed interval is exceeded.\nWe don\u2019t want the protocol to retransmit in\ufb01nitely during\ndisconnectivity. This is prevented using the attempt count that\nonly allows a maximum number of consecutive retransmits.\nIf after retransmission the other peer suddenly responds, the\ncount is reset and the protocol continues normal operation.\nIf the peer appears to be unresponsive, and the number of\nconsecutive retransmits exceeds the attempt count, the transfer\nis considered timed out and will be terminated. In worst-\ncase scenarios, often where the connection is unreliable or\nslow, the transfer of packets and con\ufb01rmations may take too\nmuch time and can timeout the transfer. These connections\ncould probably bene\ufb01t from a lower window size as fewer\nblocks have to be transmitted and con\ufb01rmed within the same\ntime. The protocol adaptively downscales the window size\nof a transfer after every timeout to give slower connections\na better chance of success. Although it is important that\nthe protocol is suitable for everyone in every situation, it is\nundesirable to lower the performance for everyone, due to\na minor number of failures. We, therefore, chose to initially\napply the optimal transfer settings for every transfer and lower\nthe performance when required. The default parameters of the\nprotocol that provide an optimal performance are analyzed\nin Section VII. An optimization to the protocol can include\nthe application of sliding windows for a more dynamic and\noptimal performance.\nVI. IMPLEMENTATION\nIn Sections IV and V we\u2019ve discussed the infrastructure\nand design of the main components that form the basis of\nour novel platform. The use of both IPv8 and TrustChain has\nproven to be a valuable \ufb01t for our infrastructure. The already\nexisting implementations are applicable to a certain level\nas they have primarily been developed to serve as separate\nproofs-of-concept. These implementations additionally lack\nre\ufb01nement and general cooperability and applicability with the\nother functionalities. In this section, the contributions to our\ncomplete infrastructure are discussed, as well as the changes to\nthe existing implementations, and how they are integrated into\nour platform to provide a well-designed and well-functioning\nplatform. The implementation is additionally concerned with\nthe UX and UI design of the platform. The platform has\nbeen integrated within the TrustChain superapp4, an Android\nmobile application developed in Kotlin that contains many\ndifferent small applications built on IPv8 and TrustChain. The\ndata transfer protocol is integrated into the IPv8 stack5 and is\navailable to every community.\nThe platform consists of \ufb01ve general views that are intercon-\nnected using a navigation bar and direct links. The initial view,\nthe wallet overview, as in Figure 8b, provides a widget-like\noverview of the identity, exchange, and chats components. For\neach widget, there is a separate view that includes all related\naspects. The information in these widgets is carefully selected\nto not over\ufb02ow the user with information.\nThe base functionality of the designed platform is obviously\nthe societal component. The implementation of a simple\nchat functionality is present in the form of PeerChat [51],\nimplemented as a community of IPv8. Its core functionality\nis the exchange of text messages and photos over the P2P\nnetwork. Many more functionalities had to be implemented to\nbe able to match the market-leading big-tech platforms. The\nability to exchange \ufb01les, locations, contacts, identity attributes,\n4https://github.com/Tribler/trustchain-superapp\n5https://github.com/Tribler/kotlin-ipv8\n11\nmoney, and payment requests has been integrated. The chat\nis an ordered list of the communication between two peers,\nand every type of message or attachment has its own view.\nIt is again important to not display too much information for\nthe attachments. Detail views display all available informa-\ntion about the attachment. Users have additional access to\nvarious convenient chat-related features to improve usability\nlike searching and \ufb01ltering, muting, archiving, or blocking.\nTo reduce the receipt of unwanted spam the platform discards\ncommunication with blocked peers. Large attachments, in par-\nticular photos and \ufb01les, are exchanged using our designed data\nprotocol of Section V-D. All other attachments are exchanged\nas single UDP packets and will be delivered using IPv8\u2019s\ndefault method. If the recipient of a message (or data) is\ncurrently not connected, the message cannot be delivered.\nTo track the delivery status of messages, peers are required\nto acknowledge its receipt. That enables the community to\nperiodically check if the peer is connected and retransmit\nthe unacknowledged messages. In a P2P network it regularly\nhappens that messages can\u2019t be delivered as there is no central\nor distributed component temporarily storing the message. As\na consequence, it may happen that two peers are unable to\ncommunicate when they are never connected at the same time.\n(a) Original PeerChat implementation\n(b) Our chat implementation [52]\nFig. 6: Difference between old and new implementation\nIn Figure 6 both the existing PeerChat implementation and\nour implementation are displayed. Not only is our implemen-\ntation equipped with much more functionalities, but the design\nis also concerned about the user experience and ease of use.\nWe\u2019ve placed options and functionalities behind additional\nbuttons, carefully selected required information to display and\nprovided our platform with full integration and support for\nQR-codes. The use of QR-codes has many advantages. A\nlot of information can be embedded in these codes without\nhaving to worry about human errors. Inter-platform and of\ufb02ine\ncommunication still enable users to exchange the embedded\ninformation, even when disconnected from the Internet. These\ncodes can additionally provide direct navigation within the\nplatform, based on the contents of the scanned code. This\nall combined improves the user experience as less time and\neffort is required from the user. Example applications of the\nQR-codes include of\ufb02ine scanning and adding public keys,\nunspeci\ufb01ed payments requests, transfer announcements to and\nfrom the exchange portal, and creating and validating identity\nattestations. Currently, all QR-codes contain unencrypted data\nas it is not deemed necessary for of\ufb02ine communication.\nHowever, future functionalities may for instance include the\nexchange of information of the self-sovereign identity and\nwould require additional security. QR-codes are perfectly\nsuited to embed encrypted data, but requires the recipient\u2019s\npublic key to be known in advance.\n(a) Identity implementation\n(b) Attestation integration\nFig. 7: Implementation of self-sovereign identity\nThe integration of the identity component had to be de-\nsigned from scratch. The identity community handles anything\nrelated to the functionalities of the self-sovereign identity,\nincluding its storage. Compared to other communities, the\nidentity community does not support communication over the\nIPv8 network. There is currently no need to additionally share\ninformation from the self-sovereign identity, as it may only\nform a privacy vulnerability. To use the platform, the users are\nrequired to onboard their identity as explained in Section V-A.\nAny device with NFC support is required to verify its identity\ndocument, as it reduces misuse and provides authenticity. An\nextra layer of protection makes sure that the identity details\nare not visible for eavesdroppers, see Figure 7a. Apart from\nthe self-sovereign identity itself, we\u2019ve also integrated identity\nattributes and identity attestations. Identity attributes contain\nconvenient information that serve as an unauthentic extension\nto the identity. These attributes are for example a phone\n12\n(a) Old exchange implementation\n(b) Our wallet overview (initial view)\ncontaining exchange widget [52]\n(c) Our exchange implementation and\ntransfer options\n(d) Our transaction detail view\ntransaction [52]\nFig. 8: Screenshots of implementation\nnumber, email address, or home address. These attributes are\nshareable with other peers and solely serve to extend the use of\nthe self-sovereign identity. Validation mechanisms to verify the\nidentity attributes\u2019 authenticity are currently not included. The\nidentity attestations are incorporated in unmodi\ufb01ed form using\nthe attestation community, as a result of the work of Chotkan\n[30]. An example QR-code of an 18+ attestation is portrayed\nin Figure 7b. Currently, only the age-related attestation types\nobtain the age directly from the self-sovereign identity. Future\nattestation types could embed more con\ufb01dential information\nfrom the identity as it can serve additional purposes.\n(a) initial state\n(b) updated state\nFig. 9: Detection in alteration of received trust attributes\nThe trust attributes, as explained in Section V-B, are directly\ndeduced from the self-sovereign identity. These attributes are\nautomatically added to every form of communication with\nother peers. The user is unable to choose to communicate\nwithout sending the trust attributes along, as this damages\nthe integrity of our platform. Changes to the state as a result\nof the received trust attributes are noti\ufb01ed in the chat as in\nFigure 9. The veri\ufb01cation status of the contact is explicitly\ndisplayed at several different locations with the sole purpose to\ndraw attention and recognition, especially when unveri\ufb01ed. A\nrecognizable blue check star indicates successful veri\ufb01cation\nwhile a red cross star, that is missing in existing platforms,\nindicates an unveri\ufb01ed peer. Both veri\ufb01cation statuses can be\nseen in Figure 8b.\nFig. 10: \u2019Slide-to-Transfer\u2019 protection\nAn implementation to transfer digital money was already\nintegrated in the superapp, see Figure 8a. The eurotoken\ncommunity handles the wallet and transfer of the CBDC Eu-\nrotoken [47] with other peers, while the trustchain community\nhandles the functionalities of the transactions in the distributed\nledger. In our platform, the wallet balance is displayed and\nprotected from eavesdroppers by initially hiding the balance,\nsee for example Figure 8b. Various options to exchange money\nhave been integrated as in Figure 8c. Firstly, QR-codes are\nused to deposit or withdraw tokens from and to the exchange\nportal. Secondly, users have the option to scan a QR-code\npayment request to transfer tokens, create a direct transfer to\nanother contact, create and send payment requests to contacts\nover the network or create an unspeci\ufb01ed payment request\n13\nusing a QR-code. The latter three are accessible from the\nchat with the corresponding contact as well. An extra layer of\nprotection, in the form of a \u2019slide-to-transfer\u2019 element as seen\nin Figure 10, withholds the accidental exchange of tokens.\nFor convenience, transactions are not only visible in the list\nof transactions in the exchange view, but also in chats. In\nFigure 8d a detailed view of a transaction and its contents is\ndisplayed. As payment requests are attachments and not formal\ntransactions, they are only included and visible in the chats.\nAs explained in Section V-D, our custom data transfer\nprotocol handles the exchange of (large) data blobs. The pro-\ntocol technically contains an entry point for peers to directly\ntransmit data to another peer, or in some situations to be\nscheduled. Scheduled transfers are periodically checked and\nstarted if the following requirements are satis\ufb01ed: (I) the peer\nis connected, (II) there\u2019s no other current transfer with the peer,\nand (III) the size of the transfer does not exceed the maximum\nallowed size. The protocol exploits packet listeners to be\nable to directly respond to each of the received packets. The\ntransfer is initiated by announcing the transfer and transfer-\nspeci\ufb01c settings. As (many) other communities may employ\nthe protocol as well, it is convenient to annotate the destined\ncommunity. As there may be various concurrent transfers with\ndifferent peers, every transfer must contain a unique identi\ufb01er\nto distinguish the transfers from one another. To make sure\nthat both the sender and receiver are in agreement with the\ntransfer parameters, and additionally allow other communities\nto use different parameters, these parameters are included\nwithin the transfer announcement. The transfer announcement\nand the last data packet of its window must be acknowledged.\nThis acknowledgment either con\ufb01rms the start of the transfer\nor receipt of a window of data blocks. In addition to the\nlatter, the current window number and lost packets must\nbe reported. This con\ufb01rmation consecutively results in the\ntransmission of the next window of blocks until all blocks\nhave been transmitted and received. To be able to stitch all\nblocks together, the protocol additionally transmits the block\nnumber with the packet. The transfer is completed when all\nblocks have been received.\nTo realize a quick response to the transmitted packets, the\nrecurrent packets must contain the minimal required informa-\ntion. The transfer announcement is only transmitted once and\nis therefore allowed to contain more information. As the data\nand acknowledgment packets are transmitted numerous times,\nwe\u2019ve made sure that no redundant information is transmitted.\n(a) scheduled status\n(b) progress status\n(c) stopped status\nFig. 11: Download progress indicators in chat\nTo accommodate communities and users with convenient\ninformation during and after the transfer, the protocol has\nbuilt-in support for callbacks. These callbacks enable the\nexecution of speci\ufb01c tasks after the transfer progressed to\nanother state. These tasks differ for each application and are\ntherefore outside the scope of the protocol. The sender is able\nto execute speci\ufb01c code after the data has been successfully\nsent or upon receipt of an error. The receiver has access to the\ntransfer progress, transfer completion, and erroneous updates.\nSpeci\ufb01cally, the former two are important to our platform.\nTransfer progress updates enable the application to display\nthe current download status to the user, see Figure 11. For\nconvenience in certain situations, the user is able to stop and\nrestart the transfer at a later time. The transfer complete update\ntriggers the conversion of the raw binary data to the correct\nformat, creates an external \ufb01le on the phone storage, and\nvisually embeds it in the chat. The protocol is dependent on\nmany parameters that may have an impact on the performance.\nIn Section VII these parameters are analyzed to obtain the\noptimal performance during normal operation.\n(a) Unit tests\n(b) Code coverage\nFig. 12: Code quality\nWe\u2019ve additionally analyzed the code quality of the pro-\ntocol. A high code coverage is required to reduce bugs\nand ensure correctness. The protocol, including all associated\nmethods and classes, is tested using 85 unit-tests that cover\nabout 77% of the code (Figure 12).\nVII. EXPERIMENTAL ANALYSIS AND EVALUATION\nIn the previous sections, we have discussed the design and\nimplementation of our data transfer protocol. In this section,\nan experimental analysis is performed to derive the optimal\nprotocol settings under normal operation. We\u2019ve only consid-\nered normal cases in this analysis due to missing theoretical\nand applied expertise. We also performed an evaluation of a\nlarge-sized transfer with these optimal settings to prove its\ncontribution and applicability to our platform.\nA. Experimental Analysis\nTo exploit the best possible performance, the designed\nbinary data transfer protocol requires its settings to be optimal.\nWe de\ufb01ne the protocol to be optimal if (I) the transfer speed\nis as high as possible, (II) the number of lost packets/blocks\n(as explained in Section V-D) is as low as possible, and\n(III) the number of retransmitted windows of blocks (by the\nsender) and acknowledgments (by the receiver) is as low as\npossible. The second constraint does not necessarily contribute\nto higher transfer speeds as lost packets are embedded in the\nnext window of blocks. The last constraint should contribute\nto higher transfer speeds because no windows of blocks have\nto be retransmitted and there\u2019s no additional idle time waiting\nfor an acknowledgment. The analysis is performed in ideal\n14\nsituations and focuses on the general picture, i.e. aspects as\ndelays due to latency and packet loss are not included.\nAs mentioned before, the UDP packet size is limited due\nto Ethernet constraints. As two packets with a payload of\n500 bytes carry twice as much redundant information as one\npacket of 1000 bytes, a transfer using a greater block size B\nis preferred and should theoretically have a positive impact\non the runtime. The maximum data size of UDP packets\nfor IPv8 has been determined (through trial-and-error) to\nbe around 1241 bytes. The exact size may depend on each\npeer, the chosen packet header options (encryption, signature,\npublic key, etc.), and the data packet metadata. To keep a\nsafe margin we\u2019ve decided to allow data of at most 1200\nbytes in each packet. The window size W is de\ufb01ned as the\nnumber of bytes (nblocks\u00d7 block size) the sender can transmit\nwithout having to wait for an acknowledgment of receipt\nfrom the receiver. Theoretically, a greater window size would\ndirectly contribute to larger transfer speeds as there are less\nwindows of blocks to be transmitted. Also, a smaller number\nof acknowledgments has to be sent and received, reducing the\noverall idle time of both participants. Greater window sizes\nalso increase the existence of late or lost blocks, speci\ufb01cally\nin imperfect or congested networks, with an increased number\nof retransmissions of windows of blocks as a result. The\nimportance of this analysis is to \ufb01nd the best trade-off between\na great window size and low delay due to lost packets.\nThe\nother\nparameters\ndo\nnot\ndirectly\nimpact\nthe\nperformance,\napart\nfrom\nthe\nblock\nand\nwindow\nsize.\nThe retransmit interval may affect the performance when it\nis either too tight or loose, but it will only play a role in a\nsmall part of the cases. A tight interval can force windows\nof blocks or acknowledgments to be retransmitted while\nthey are still in transit and may arrive shortly after. For a\nloosely set interval, the protocol may unnecessarily have to\nwait for a window or acknowledgment. The transfer timeout\ninterval is less critical and will only affect the performance\nwhen a window or acknowledgment has abused all retransmit\nattempts. The retransmit attempt count likewise has little\nin\ufb02uence on the performance.\nExperimental Setup: The experimental setup is equipped\nwith two phones, a Xiaomi Redmi 9T with Android 10 and a\nHuawei P20 Lite with Android 9, both 4GB RAM. The phones\nhave installed the same version of the app and are connected to\nthe same WiFi-6 mesh network (NETGEAR Orbi RBK753).\nTo obtain more accurate results, each experiment is executed\n\ufb01ve times. Also, to verify the independence of the \ufb01le size on\nthe transfer, the experiment is executed for multiple \ufb01le sizes.\nEach important step of the protocol is captured in a log to be\nprocessed in Python. An automatic Kotlin script makes sure\nthat every combination of parameters and the \ufb01ve iterations\nare executed consecutively. Table III gives an overview of the\nanalyzed parameter values. The maximum parameter settings\nare windows of 128 blocks of 1200 bytes each, equivalent to\n150kB of unacknowledged data that is the fundamental limit to\nthe data transfer performance. With a certain unknown latency\nthis results in an exact transfer speed limit. As no a packet\nloss and latency emulation has been performed, we cannot\ndetermine this theoretical limit.\nTABLE III: Parameters that are being tested for optimal\nexecution. The number of iterations have only been used for\nconsistency. In total 56 combinations of parameters have been\nexecuted 5 times.\nParameter\nValues\nBlock size (B)\n600, 700, 800, 900, 1000, 1100, 1200\n[bytes]\nWindow size (W)\n16, 32, 48, 64, 80, 96, 112, 128\n[blocks]\nIteration\n0, 1, 2, 3, 4\n[-]\nExperimental Results: The optimality of the performance of\nthe protocol can be determined in combination with the before\nmentioned requirements.\nThe results of the \ufb01rst requirement, the transfer speed of the\nprotocol, is displayed in Figure 13a. We can clearly see the\neffect of the variation of the block and window size. Higher\nblock sizes increases the transfer speed. The window size\nfollows a parabolic curve and the transfer speed is optimal\nfor a window size W = 80 and W = 96 blocks. We cannot\nyet determine the optimal value for the window size as these\nvalues are very similar and are less pronounced than the block\nsize. To decide on the optimal sizes, we have to include the\nrequirements as well.\nThe results for the second requirement, the number of lost\npackets/blocks during a transfer, is visualized in the plots\nof Figure 13b. The block size shows a slightly decreasing\npattern and overall contains the lowest number of lost packets\nfor greater block sizes. There is no consensus on the block\nsize within each window size, as there are small deviations\nand not consistently decreasing or increasing. The trendline,\na combined average of all block sizes within each window,\nshows a minimum for the same window sizes as of the \ufb01rst\nrequirement, but slightly favors W = 96 blocks. For window\nsizes greater than W = 96 blocks the number of lost packets\nagain increases. The protocol is behaving more unreliable as\nmore lost blocks have to be added to the next window. Every\nlost block will cause a marginal decrease of the transfer speed\nas more blocks have to be delivered in the next window. The\naim remains to reduce these lost blocks as much as possible.\nEspecially for more unreliable connections, the impact of\nlost blocks may become more pronounced as the transfer\nprogresses further.\nThe last requirement, the number of retransmitted windows\nof blocks and the number of retransmitted acknowledgments,\nare entangled as it takes both the sender and receiver in the\nequation for the same transfers. In Figure 13c and 13d the\nresults for the sender and receiver are visualized, respectively.\nBoth diagrams show the same pattern. The optimal block size\nagain shows no notable preference within each window size.\nThe results for the window sizes are a strong indicator that we\ndon\u2019t want them to be oversized. The number of retransmitted\nwindows and acknowledgments is of neglectable proportion\nfor a window size less than W = 112 blocks, or even W = 96\nblocks if we would be really strict. As the protocol has to\nwait for a full interval for every retransmission, it has a big\nimpact on the overall performance. It is crucial to reduce the\nnumber of retransmissions to an absolute minimum. For the\nlargest three window sizes, a small experiment was executed\n15\n(a)\n(b)\n(c)\n(d)\nFig. 13: The results of all executed tests for each variable window and block size, averaged over \ufb01ve iterations.\nthat veri\ufb01ed if the large increase of retransmissions were the\nresult of a too tightly set retransmit interval. The interval\nwas increased majorly, just for veri\ufb01cation purposes, and\nsolely served for additional analysis of the third requirement,\nwithout including the results of the other requirements. The\nresults showed that the number of retransmissions slightly\nimproved, but the pattern was equally in place. It was deemed\nunnecessary to investigate it further.\nWe must take into account that the experiments have been\nperformed under somewhat optimal circumstances: phones\nonly running system services and the platform itself, and both\nconnected to the same local WiFi network. From this, we could\nargue that for worsened conditions, the transfer speed and the\nnumber of lost packets and retransmissions would logically\nincrease. We can combine and summarize our \ufb01ndings based\non the results of the experiments and analysis. The perfor-\nmance of the transfer speed (continuously) increases with\ngreater block sizes, with the optimal block size of B = 1200\nbytes. For the other requirements, the difference in block size\nwas less de\ufb01nite. The transfer speed found an inconclusive\noptimal for window sizes of W\n= {80, 96} blocks. The\nsecond requirement showed similar results, although slightly\nin favor of the latter. Both types of retransmissions for the\nthird requirement indicated an increase of retransmissions for\ngreater window sizes, speci\ufb01cally above W = 80 blocks.\nTo obtain the optimal performance, in combination with the\nminimal number of lost blocks and retransmissions, we can\nconclude that a window size of W = 80 blocks is optimal\n16\nFig. 14: Evaluation of the performance of a transfer of 250MB using the optimal window size of 96kB, executed 10 times.\nunder normal operation. The optimal window size based on our\n\ufb01ndings is thus W = 96000 bytes or 96kB. We\u2019ve deduced\nthese optimal parameters for ideal situations, and therefore\ndoes not include lateness and loss of blocks.\nWe\u2019ve additionally executed the same experiments using\nmultiple \ufb01le sizes to verify its independence on the per-\nformance. All results are similar and seem to indicate that\nthe \ufb01le size is independent on the performance. We\u2019ve also\nconcluded that an increase of the retransmit interval does not\nnecessarily give a signi\ufb01cant overall reduction of the number\nof retransmissions, and therefore not contributes to better\nperformance.\nB. Performance Evaluation\nNow that we\u2019ve determined the optimal parameters for the\nprotocol, we want to see how it performs in the wild for a\nlarge-sized transfer of 250MB. This enables us to evaluate\nthe performance more consistently over a longer period of\n(transfer) time. In most cases, phones are not connected to\nthe same local WiFi network. We have to consider three\ncommonly-used situations (I) WiFi to WiFi, (II) WiFi to\n4G+, and (III) 4G+ to 4G+. For the connections of 4G+, we\nuse the telecom providers Vodafone and KPN on the same\nphones as before. Our evaluation includes the same aspects\nas the experimental analysis. Instead of \ufb01nding the optimal\nparameters, we this time evaluate the applicability and the\ndifference between the three situations. Each experiment is\nexecuted 10 times to obtain more consistent results. We expect\nthe \ufb01rst situation to offer the highest transfer speed and least\nnumber of lost packets and retransmissions as the packets are\nonly exchanged within the local network.\nThe performance results for each of the connection types\nare portrayed in Figure 14. The transfer speed shows a clear\ndivision in performance, in favor of the inter-WiFi transfer of\nabout 260kB/s. The transfer speeds for the two situations using\na mobile connection have very similar speeds of about 213kB/s\nand 210kB/s. It\u2019s a good indication that there is no extreme\nperformance difference between an exchange using one WiFi-\nconnected device and a complete mobile network exchange.\nThe transfer speed of the inter-WiFi transfer is executed on a\nlocal network and therefore sketches a slightly biased image.\nThe transfer speed of an exchange between two non-local\nWiFi networks would theoretically be lower, and possibly be\nmore similar to the other situations. However, we do notice\na bigger spread in terms of lower speeds for the complete\nmobile network exchange. If we look at the absolute speed, we\nmust conclude that our protocol is nowhere near the download\nspeeds of current network infrastructures. The exact reason is\nunknown, but it is expected to be some limitation in IPv8 and\npossibly sub-optimal UDP socket buffering.\nThe number of lost packets contradicts our expectation.\nThe number of lost packets is on average larger for an inter-\nWiFi transfer in comparison with the other two situations. In\nabsolute numbers though, we can conclude that the total loss\nof about 50 packets in a transfer of over 200.000 packets,\nequivalent to one lost packet within every \ufb01fty windows, is ne-\nglectable. This number would be much higher for sub-optimal\nconnections. No retransmission of windows of blocks were\nencountered, and therefore left out of the \ufb01gure. The number of\nretransmissions of acknowledgments are very equivalent for all\nthree situations, and only allows one acknowledgment retrans-\nmission per transfer on average as result of unresponsiveness.\n17\nFrom these results we can conclude that our protocol\nhas been performing at the top of its abilities in normal\noperation. The absolute transfer speed is disappointing. During\nthe experiments, it was noticed that larger-sized transfers ex-\nperienced memory allocation issues on the phones. Currently,\nthe protocol stores the sent and received data in memory for\nreconstruction purposes. The current maximum \ufb01le size has\ntherefore been limited to 250MB, but can differ from phone\nto phone.\nVIII. TIME MANAGEMENT\nThe research, design, implementation, analysis, and doc-\numentation have been an effort of one person in roughly\nnine full-time months. The research phase required about\ntwo months to study the literature and existing platforms,\nincluding the basics and characteristics of IPv8, TrustChain,\nand other components. The design and implementation phase\nwere entangled as the scope of the research widened several\ntimes along the way. You could say that it was a repeating\nprocess of invent-design-implement for most of the features.\nAn initial layout of the application was designed and im-\nplemented to provide a basic platform that slowly evolved\nto its \ufb01nal state. This included familiarizing the style and\ncoding within the Trustchain superapp and the Kotlin\nlanguage. The design and implementation of features were not\nonly concerned with the features themself, but also the UX\nand UI design of the platform. In total, about six months have\nbeen allocated to the design, implementation, and analysis of\nthe platform. The data transfer protocol is the only component\nthat has additionally been analyzed as part of experimental\nanalysis and evaluation. Of these six months, about one month\nof work was required to optimize and analyze the data transfer\nprotocol. The last month, and also some time earlier in the\nprocess, was dedicated to documenting and \ufb01nalizing this\npaper.\nIX. CONCLUSION\nOwnership and exchange of sensitive or private information\nhas never been a more relevant topic, also due to the COVID\npandemic. This paper has presented a novel Web3 platform\nfor identity, trust, money, and data. Decentralization partially\nsolves the lack of self-sovereignty for identity, money, and data\nin the current online world. We performed the \ufb01rst exploratory\nstudy that shows the viability of the integration of a self-\nsovereign identity in a social platform in a useful, secure, and\nprivate fashion. The application of self-sovereign identities has\nadditionally shown to be effective in providing trust to peers in\nthe P2P network. Governments may change their mind about\ntheir identity management systems in the near future. Many\ncentralized tasks can be replaced, providing their citizens\nmore power and ownership over their data, while retaining\nauthenticity and majorly reducing costs. Central banks have\nstarted designing Central Bank Digital Currencies globally.\nOur platform incorporates the exchange of digital money in a\nprivate and informal way, similar to what cash once was. Data\nand personal information has been owned and managed by big-\ntech companies for far too long. The centralized structure is\nthe core of the problem in online communication. Our P2P\ndata transfer protocol enables peers to securely and privately\nexchange messages and data while reducing the leakage of\nmetadata to a minimum.\nUnfortunately, we cannot neglect some major disadvantages\nin our platform as well. Firstly, the availability and connec-\ntivity of peers remain an open issue as it introduces lateness\nin the delivery of messages and data. People are currently not\nused to lateness in existing platforms which use central servers\nor nodes. Secondly, peers in a fully P2P network must keep\nthemselves online by constantly discovering and connecting\nto peers with the consequence of draining the phone\u2019s battery.\nImprovements could be made, but it will always remain a weak\nspot of P2P systems. Finally, the implementation of the CBDC\nEuroToken is dependent on central components and not yet\nreliable enough.\nOverall, we conclude that we\u2019ve designed a well-functioning\nplatform that incorporates all aspects of our research in a\nvaluable, private, and secure manner. There is still a lot to\ndiscover and we\u2019re curious to see what direction big-tech\ncompanies, governments, and banks will pursue in the near\nfuture.\nREFERENCES\n[1] Tribler.\nIpv8 documentation.\n2021.\nURL https://py-\nipv8.readthedocs.io/_/downloads/en/latest/pdf/.\n[2] Pim\nOtte,\nMartijn\nde\nVos,\nand\nJohan\nPouwelse.\nTrustchain:\nA\nsybil-resistant\nscalable\nblockchain.\nFuture\nGeneration\nComputer\nSystems,\n107:\n770\u2013780,\n2020.\nISSN\n0167-739X.\ndoi:\nhttps://doi.org/10.1016/j.future.2017.08.048.\nURL\nhttps://www.sciencedirect.com/science/article/pii/\nS0167739X17318988.\n[3] Nicolo Zingales. Between a rock and two hard places:\nWhatsapp at the crossroad of competition, data protection\nand consumer law. Computer Law & Security Review,\n33(4):553\u2013558, 2017.\n[4] The\nGuardian.\nWhatsapp\nloses\nmillions\nof\nusers\nafter\nterms\nupdate.\n[Online]\nAvailable:\nhttps://www.theguardian.com/technology/2021/jan/\n24/whatsapp-loses-millions-of-users-after-terms-update,\n2021.\n[5] \"Wall\nStreet\nJournal\".\nBig\ntech\nbraces\nfor\na\nwave\nof\nregulation.\n[Online]\nAvailable:\nhttps://www.wsj.com/articles/big-tech-braces-for-\nwave-of-regulation-11642131732, 2022.\n[6] Of\ufb01cial Journal of the European Union.\nRegulation\n(eu) 2016/679 of the european parliament and of\nthe council on the protection of natural persons with\nregard to the processing of personal data and on the\nfree movement of such data, and repealing directive\n95/46/ec (general data protection regulation). [Online]\nAvailable:\nhttps://eur-lex.europa.eu/legal-content/EN/\nTXT/PDF/?uri=CELEX:32016R0679&from=EN, 2016.\n[7] Gdpr enforcement tracker.\n[Online] Available: https://\nwww.enforcementtracker.com.\n[8] Aikaterini Soumelidou and Aggeliki Tsohou. Towards\nthe creation of a pro\ufb01le of the information privacy aware\n18\nuser through a systematic literature review of information\nprivacy awareness.\nTelematics and Informatics, 61:\n101592, 2021.\n[9] ZDNet.\nThe biggest data breaches, hacks of 2021.\n[Online] Available: https://www.zdnet.com/article/the-\nbiggest-data-breaches-of-2021/, Dec 2021.\n[10] PinDirect.\nWat\nkost\neen\npintransactie?\n[On-\nline] Available: https://pindirect.nl/kennisbank/uw-eigen-\npinautomaat/wat-kost-een-pintransactie/, 2020.\n[11] ZakelijkBankieren.nl.\nVergelijk\nideal\nkosten\nper\naanbieder\nin\nnl.\n[Online]\nAvailable:\nhttps://www.zakelijkbankieren.nl/kosten-ideal/, 2021.\n[12] Dutch Payments Association. Facts and \ufb01gures on the\ndutch payment system in 2020. [Online] Available: https:\n//factsheet.betaalvereniging.nl/en/, 2020.\n[13] Christopher Allen. The path to self-sovereign identity.\n[Online]\nAvailable:\nhttp://www.lifewithalacrity.com/\n2016/04/the-path-to-self-soverereign-identity.html,\n2016.\n[14] Quinten Stokkink and Johan Pouwelse.\nDeployment\nof a blockchain-based self-sovereign identity. In 2018\nIEEE International Conference on Internet of Things\n(iThings) and IEEE Green Computing and Communica-\ntions (GreenCom) and IEEE Cyber, Physical and Social\nComputing (CPSCom) and IEEE Smart Data (Smart-\nData), pages 1336\u20131342, 2018.\n[15] \"Computer\nWeekly\".\n\"blockchain\ntechnology\nwill\nhelp\nbanks\nwill\ncut\ncross-border\npayment\ncosts\nby\n$10bn\nin\n2030\".\n[Online]\nAvailable:\nhttps://www.computerweekly.com/news/252509262/\nBlockchain-technology-will-help-banks-will-cut-cross-\nborder-payment-costs-by-10bn-in-2030, 2021.\n[16] Statista.\nMost\npopular\nglobal\nmobile\nmessenger\napps\nas\nof\noctober\n2021,\nbased\non\nnumber\nof\nmonthly\nactive\nusers.\n[Online]\nAvailable:\nhttps://www.statista.com/statistics/258749/most-popular-\nglobal-mobile-messenger-apps/, 2021.\n[17] Roman Zaikin and Oded Vanunu. Reverse engineering\nwhatsapp encryption for chat manipulation and more.\n[Online] Available: , August 3-8, 2019.\n[18] WhatsApp.\nWhatsapp\nencryption\noverview.\ntechnical\nwhite\npaper.\nNov\n2021.\nURL\nhttp://www.cdn.whatsapp.net/security/WhatsApp-\nSecurity-Whitepaper.pdf.\n[19] FaceBook\nInc.\nMessenger\nsecret\nconversations.\ntechnical\nwhitepaper.\nMay\n2017.\nURL\nhttps:\n//about.fb.com/wp-content/uploads/2016/07/messenger-\nsecret-conversations-technical-whitepaper.pdf.\n[20] WeChat.\nWechat - free messaging and calling app.\n\"[Online] Available: https://weixin.qq.com\", Jan 2022.\n[21] Telegram.\nTelegram messenger.\n\"[Online] Available:\nhttps://telegram.org\", Jan 2022.\n[22] Apple.\nimessage\nsecurity\noverview.\n\"[Online]\nAvailable:\nhttps://support.apple.com/en-au/guide/\nsecurity/secd9764312f/web\", May 2021.\n[23] Katriel Cohn-Gordon, Cas Cremers, Benjamin Dowling,\nLuke Garratt, and Douglas Stebila.\nA formal security\nanalysis of the signal messaging protocol. In 2017 IEEE\nEuropean Symposium on Security and Privacy (EuroS P),\npages 451\u2013466, 2017. doi: 10.1109/EuroSP.2017.27.\n[24] Kee Jefferys, Maxim Shishmarev, and Simon Harman.\nSession: A model for end-to-end encrypted conversations\nwith minimal metadata leakage. CoRR, abs/2002.04609,\n2020. URL https://arxiv.org/abs/2002.04609.\n[25] Status.\nThe status network. a strategy towards mass\nadoption of ethereum. June 2017. URL https://status.im/\nwhitepaper.pdf.\n[26] Felix Schlitter, John Carlo San Pedro, Paul Freeman, and\nCallum Lowcay. Sylo protocol: Secure group messag-\ning.\n2020.\nURL https://www.sylo.io/whitepaper/sylo-\nprotocol.pdf.\n[27] Berty.\nBerty protocol.\n\"[Online] Available: https://\nberty.tech/docs/protocol/\", Oct 2020.\n[28] Logius. Tarieven 2022 voor digid, digid machtigen en\nmijnoverheid. [Online] Available: https://logius.nl/onze-\norganisatie/zakendoen-met-logius/doorbelasting, 2021.\n[29] Logius.\nLack.\n[Online] Available: https://logius.nl/\nactueel/gebruik-digid-de-lift, 2022.\n[30] R. Chotkan. Industry-grade self-sovereign identity, on the\nrealisation of a fully distributed self-sovereign identity\narchitecture. Master\u2019s thesis, Delft University of Tech-\nnology, 2021.\n[31] Ann Cavoukian. Privacy by design: The 7 foundational\nprinciples. May 2010.\n[32] Tweakers. Belgische overheid verplicht chatapps zoals\nwhatsapp metadata op te slaan.\n[Online] Available:\nhttps://tweakers.net/nieuws/183702/belgische-overheid-\nverplicht-chatapps-zoals-whatsapp-metadata-op-te-\nslaan.html, 2021.\n[33] RollingStone.\nFbi\ndocument\nsays\nthe\nfeds\ncan\nget your whatsapp data \u2014 in real time.\n[Online]\nAvailable:\nhttps://www.rollingstone.com/politics/\npolitics-features/whatsapp-imessage-facebook-apple-\nfbi-privacy-1261816/, 2021.\n[34] M.G. Reed, P.F. Syverson, and D.M. Goldschlag. Anony-\nmous connections and onion routing. IEEE Journal on\nSelected Areas in Communications, 16(4):482\u2013494, 1998.\ndoi: 10.1109/49.668972.\n[35] Wikipedia.\nInformation security.\n\"[Online] Available:\nhttps://en.wikipedia.org/wiki/Information_security\",\n2022.\n[36] Whit\ufb01eld Dif\ufb01e and Martin E. Hellman. New directions\nin cryptography. Nov 1976. URL https://ee.stanford.edu/\n~hellman/publications/24.pdf.\n[37] International Telecommunication Union (ITU).\nData\nnetworks\nand\nopen\nsystem\ncommunications.\nopen\nsystems interconnection - model and notation. July 1994.\nURL\nhttps://www.itu.int/rec/dologin_pub.asp?lang=\ne&id=T-REC-X.200-199407-I!!PDF-E&type=items.\n[38] Keesing\nTechnologies.\nSecurity\nvulnerabilities\nassociated with e-passports.\n[Online] Available: https:\n//platform.keesingtechnologies.com/e-passport-security/,\nFeb 2020.\n[39] Fortunly.\n20 worrying identity theft statistics for\n2022. [Online] Available: https://fortunly.com/statistics/\nidentity-theft-statistics/, Feb 2022.\n19\n[40] Europol EC3.\nSpear phishing, a law enforcement\nand\ncross-industry\nperspective.\nNov\n2019.\nURL\nhttps://www.europol.europa.eu/sites/\ndefault/\ufb01les/documents/report_on_phishing_-\n_a_law_enforcement_perspective.pdf.\n[41] BOARD OF GOVERNORS OF THE FEDERAL RE-\nSERVE SYSTEM.\nMoney and payments: The u.s.\ndollar in the age of digital transformation.\nJan\n2022. URL https://www.federalreserve.gov/publications/\n\ufb01les/money-and-payments-20220120.pdf.\n[42] European Central Bank (ECB). Central bank digital cur-\nrency: functional scope, pricing and controls. 286, Dec\n2021.\nURL https://www.ecb.europa.eu/pub/pdf/scpops/\necb.op286~9d472374ea.en.pdf.\n[43] Bank of England.\nCentral bank digital currency,\nopportunities, challenges and design. Mar 2020. URL\nhttps://www.bankofengland.co.uk/-/media/boe/\ufb01les/\npaper/2020/central-bank-digital-currency-opportunities-\nchallenges-and-design.pdf.\n[44] Working Group on E-CNY Research and Develop-\nment of the People\u2019s Bank of China.\nProgress\nof\nresearch\n&\ndevelopment\nof\ne-cny\nin\nchina.\nJuly 2021.\nURL http://www.pbc.gov.cn/en/3688110/\n3688172/4157443/4293696/2021071614584691871.pdf.\n[45] Reuters.\nChina central bank launches digital yuan\nwallet apps for android, ios.\n[Online] Available:\nhttps://www.reuters.com/markets/currencies/china-\ncbank-launches-digital-yuan-wallet-apps-android-ios-\n2022-01-04/, Jan 2022.\n[46] Het\nParool.\nVier\namsterdammers\nvast\nvoor\n\u2018tikkiefraude\u2019 honderden mensen. \"[Online] Available:\nhttps://www.parool.nl/amsterdam/vier-amsterdammers-\nvast-voor-tikkiefraude-honderden-mensen~b33baf1a\",\nNov 2020.\n[47] R.W. Blokzijl.\nA central bank digital currency (cbdc)\nwith offline transfers. Master\u2019s thesis, Delft University\nof Technology, 2021.\n[48] Network Working Group. The tftp protocol (revision 2).\nJune 1981.\nURL https://www.rfc-editor.org/rfc/pdfrfc/\nrfc783.txt.pdf.\n[49] J. Postel.\nUser datagram protocol.\nAug 1980.\nURL\nhttps://www.rfc-editor.org/rfc/pdfrfc/rfc768.txt.pdf.\n[50] Andrew S. Tanenbaum and David Wetherall. Computer\nnetworks, 5th Edition. 2011.\n[51] M. Sk\u00e1la.\nTechnology stack for decentralized mobile\nservices. Master\u2019s thesis, Delft University of Technology,\n2020.\n[52] Paul Clarke. Wikimedia commons, the free media reposi-\ntory. [Online] Available: https://commons.wikimedia.org/\nwiki/File:Sir_Tim_Berners-Lee_(cropped).jpg,\nSep\n2014.\n",
    "2210.05903": "arXiv:2210.05903v3  [cs.SE]  16 Oct 2023\nTowards Web3 Applications: Easing the Access and\nTransition\nGUANGSHENG YU, Data61, CSIRO, Australia\nXU WANG, GBDTC, University of Technology Sydney, Australia\nQIN WANG, Data61, CSIRO, Australia\nTINGTING BI, Data61, CSIRO, Australia\nYIFEI DONG, GBDTC, University of Technology Sydney, Australia\nREN PING LIU, GBDTC, University of Technology Sydney, Australia\nNEKTARIOS GEORGALAS, Applied Research, British Telecom, UK\nANDREW REEVES, Applied Research, British Telecom, UK\nWeb3 is leading a wave of the next generation of web services that even many Web2 applications are keen\nto ride. However, the lack of Web3 background for Web2 developers hinders easy and e\ufb00ective access and\ntransition. On the other hand, Web3 applications desire encouragement and advertisement from conventional\nWeb2 companies and projects due to their low market shares. In this paper, we propose a seamless transition\nframework that transits Web2 to Web3, named WebttCom1, after exploring the connotation of Web3 and\nthe key di\ufb00erences between Web2 and Web3 applications. We also provide a full-stack implementation as a\nuse case to support the proposed framework, followed by performance evaluation and surveys with \u223c1,000\nparticipants that show \u223c80% positive and \u223c20% neutral responses. We con\ufb01rm that the proposed framework\nWebttCom addresses the de\ufb01ned research question, and the implementation well satis\ufb01es the framework\nWebttCom in terms of strong necessity, usability, and completeness based on the survey results.\nCCS Concepts: \u2022 Information systems \u2192Web interfaces;\nAdditional Key Words and Phrases: Web3, Web2, DApp, Blockchain, Service Mannagement System\n1\nINTRODUCTION\nWeb3 has drawn intensive attention from communities and investors. As an umbrella term,\nWeb3 covers a series of blockchain-based decentralized applications (DApps), services, and eco-\nnomics [1\u20135] that bring signi\ufb01cant impacts on both traditional \ufb01nance and cryptocurrency mar-\nkets. To date (as of Mar 2023), over 12, 143 DApps2 have been developed on-chain and 285, 152\nsmart contracts are deployed across 48 protocols. A total of 1.67M users are actively interacting\nwith the smart contracts within 24 hours, as evidenced by their wallet addresses. In this sense,\nWeb3 impresses users by providing such a connect the wallet button on the upper-right corner of\neach webpage. Users can use DApps through embedded wallet entries by invoking speci\ufb01c func-\ntions that are deployed on blockchain-engined platforms (e.g., Ethereum [6]). The shift of backend\nservers from centralized clouds to decentralized chains has mostly distinguished Web3 and previ-\nous web styles.\n1WebttCom stands for Web2 (Two)\u2013Web3 (Three) Communicator.\n2Data source [Mar 2023]: DappRadar https://dappradar.com/industry-overview.\nAuthors\u2019 addresses: Guangsheng Yu, Data61, CSIRO, Sydney, NSW, Australia, 2121, Saber.Yu@data61.csiro.au; Xu Wang,\nGBDTC, University of Technology Sydney, Sydney, NSW, Australia, 2007, Xu.Wang-1@uts.edu.au; Qin Wang, Data61,\nCSIRO, Sydney, NSW, Australia, 2121, qinwangtech@gmail.com; Tingting Bi, Data61, CSIRO, Melbourne, VIC, Australia,\n3168, Tingting.Bi@data61.csiro.au; Yifei Dong, GBDTC, University of Technology Sydney, Sydney, NSW, Australia, 2007,\nYifei.Dong@uts.edu.au; Ren Ping Liu, GBDTC, University of Technology Sydney, Sydney, NSW, Australia, 2007, RenP\ning.Liu@uts.edu.au; Nektarios Georgalas, Applied Research, British Telecom, Martlesham, Woodbridge, UK, IP5 3RE, ne\nktarios.georgalas@bt.com; Andrew Reeves, Applied Research, British Telecom, Martlesham, Woodbridge, UK, IP5 3RE,\nandrew.reeves@bt.com.\n, Vol. 1, No. 1, Article . Publication date: October 2023.\nFollowing its narrative connotation, we observe that Web3 users still occupy a pretty small per-\ncentage (appr. 0.03% of 4.95B3 Internet users) over the Internet. The constraints majorly come from\nits incompatibility: (i) a typical Web3 application cannot be smoothly applied in a traditional web\ncontext due to the absence of blockchain engines; conversely, (ii) a traditional Web2 application\ncan hardly be integrated with blockchain due to the lack of proper Application Programming In-\nterfaces (APIs). Rational developers would start their work on wide-adoption applications, namely\nWeb2 Apps, for higher user exposure and more potential revenues rather than sparing e\ufb00orts on\nWeb3 applications that are uncertain. Such concerns motivate this work:\nHow to ease the usage of Web3 applications and achieve a smooth transition of applications between\nthe Web2 and Web3 space?\nWe investigate the bottlenecks of the transition between Web2 and Web3 by diving into their dis-\ntinctions in design and implementation. For most Web2 applications, user management, data ma-\nnipulation, and private-preserving policies are constructed upon centralized databases in a closed\nmanner. In contrast, Web3 DApps usually apply asymmetric-encryption-based identity to estab-\nlish more secure and robust user management in a decentralized manner among many parties\nwithout prior trustworthiness [7\u201310]. Data manipulation di\ufb00ers from that of Web2 applications\ndue to the immutability of data storage in Web3, and access control also requires new approaches\nto partition the visibility. In addition, existing Web3 DApps lack \ufb02exible mechanisms to smooth\nthe work\ufb02ow of documenting Restful APIs and test suites during the development phase. There-\nfore, the incompatible user management strategies, execution procedures for data manipulation,\nprivate-preserving policies, and the lack of Web3-compatible API tools have greatly retarded the\nsmooth transition of applications in di\ufb00erent domains.\nTo \ufb01ll the above gaps, in this work, we propose a practical solution to integrate both Web3\nand Web2 applications and related services seamlessly. We deconstruct the Web2 architecture and\nextract three major components: frontend APIs, backend servers, and supplementary databases.\nAligning with the core principles of Web3, we accordingly modify these components to enable\nseamless integration with blockchain engines. Speci\ufb01cally, we design three types of adjustable\ncomponents: a SaaS module for integrating Web2 software by providing generalized APIs, a back-\nend interpreter that interprets and forwards requests from Web2 to Web3, a blockchain layer that\ncon\ufb01gures self-governed policies via smart contracts as well as computes on-chain calculations\nthrough chain Software Development Kits (SDKs). Our proposed solutions can greatly promote\nthe transition from classic Web2 applications to the Web3 space without redundant development\nor complicated middleware. In short, we highlight the contributions as follows.\n\u2022 We explore the connotation of Web3 by investigating plenty of in-the-wild Web3 projects. As a\nnew concept, we compare existing Web2 solutions and so-claimed Web3 projects to deter-\nmine the root features of Web3 applications and their dependencies, extracting their di\ufb00er-\nences from classic Web2 applications.\n\u2022 Based on comprehensive investigation, we propose a seamless transition framework that tran-\nsits Web2 to Web3, named WebttCom. Our proposed solution establishes an interpreter to\nbridge the Web2 applications and the Web3 backend engines. In particular, the proposed\nframework WebttCom can o\ufb00er e\ufb00ective and reliable access control and user management\nacross the decentralized Web3 and centralized Web2 and provide an approach to conduct\ntransition with existing popular SaaS and the framework. While operating, WebttCom can\nalso e\ufb00ectively improve production by automatically generating API documents for devel-\nopers and communities.\n3Data source: Digital 2022: Global OverviewReport https://datareportal.com/reports/digital-2022-global-overview-report.\n2\n\u2022 We provide a full-stack implementation ranging from front and backend APIs, structure design,\nand smart contract programming to the on-cloud dockerized deployment. Code size reaches up\nto 11,351 lines4. The system is applied to daily service management processes and promotes\nthe establishment of e\ufb00ective, \ufb02exible, reliable, and trustworthy Web3-driven applications.\nOur prototype has been inspected by British Telecom (BT) in practice.\n\u2022 We further conducted a quantitative performance evaluation and a qualitative evaluation from\nthe perspectives of managers, investors, and developers through surveys targeting 1,000 practi-\ntioners. The survey feedback shows that the research question is well satis\ufb01ed by the pro-\nposed framework WebttCom, and the presented full-stack implementation proves its strong\ncapability of smoothing the transition in terms of necessity, usability, and completeness.\nThe remainder of this paper is organized as follows. Section 2 provides the Web3 basics. Section 3\nproposes the research methodology and presents our research question. Section 4 introduces a use\ncase that implements the new pattern, followed by discussions about the implementation notices\nand limitations shown in Section 5. Section 6 provides existing studies related to this work. Sec-\ntion 7 concludes this paper and highlights our contributions.\n2\nAPPROACHING WEB3: A PRELIMINARY\nIn this section, we show the Web3 basics by comparing with Web2 and providing a typical Web3\ninstance.\n2.1\nDi\ufb00erences between Web 1/2 and Web3\nTraditional Internet, including so-claimed Web1 and Web2, has been developed for decades.\nWeb1 is regarded as a suite of read-only protocols that contain static sites to present images, text,\nand videos. Users search for the targets by accessing web portals. Web2 changes the way of interac-\ntion by enabling user-generation content (UGC). Users can publish their original content, such as\nimages, reviews, testimonials, or even podcasts, on social media websites (e.g., Facebook, Twitter).\nIn this sense, Web2 is regarded as read-write. Web3 di\ufb00ers from previous styles by adding features\nof ownership and transfer. Users will create self-controlled accounts, generally in the forms of\nwallets, to manage digital assets and virtual data. Rather than relying on centralized servers, Web3\nusers can freely transfer their assets under the governance of smart contracts, which brings the ad-\nvantages of auto-execution, being accountable, and being globally veri\ufb01ed. These smart contracts\nconnect both upper-layer DApps and underlying blockchain platforms.\nTable 1. Comparisons among Web1/Web2/Web3 and Our Work\nFunctions\nArchitecture\nInstance\nWeb1\nread\nclient-server\nYahoo\nWeb2\nread/write\nclient-server\nFacebook, Google\nWeb3\nread/write/own/transfer\nclient-SC-chain\nEthereum, BSC\nWeb2\u21923\nread/write/own/transfer\nclient-Int.-SC-chain\nWebttCom\n4Speci\ufb01cally, we present the detailed size distribution. The front end takes 4 MB with image resources, while 253 KB with\ncode only (5367 lines). The backend is a 1.3 MB project and 249 KB for codes (4831 lines). Web3 takes 265KB (1153 lines).\nNote that the source code is set con\ufb01dential due to the non-disclosure agreement with British Telecom (BT).\n3\n2.2\nTypical Web3 Architecture\nTradition web architecture is based on a client-server model. The client is used for sending and\nreceiving requests, while the server is used to process these requests and corresponding logic. The\nserver side, also known as the backend, covers many fundamental aspects like operating systems\n(Windows, Linux), platforms (.Net, LAMP), and storage. API is to connect the application tier to\nservers. In contrast, the Web3 architecture replaces centralized backend servers with distributed\nledgers. The backend contains two sectors, smart contracts (SC) for de\ufb01ning logic and rules, and\nblockchain platforms for processing transactions and achieving consensus. Web3 is more complex\nthan traditional Web2 due to its complete decentralization, which requires dealing with the con-\nsistency problem [11]. In this work, we aim to ease the transition between the Web2 application\ntier and blockchain-backend systems. We establish an interpreter (short for Int.) to connect them\nseamlessly.\n2.3\nEssential Component\nWe provide basic building blocks to construct Web3 applications: a series of blockchain-speci\ufb01c\ncomponents covering blockchain, smart contracts, on-chain applications, and clients.\nBlockchain. Blockchain is a digital ledger that operates in a decentralized manner to securely\nand transparently record transactions [12]. Transactions are recorded as blocks, which are subse-\nquently organized into a hierarchical structure. The blocks are arranged in a chronological and\nunalterable sequence to form the blockchain. To add a new block to the chain, a process called\n\"mining\" is used, which involves solving complex mathematical problems to validate transactions\nand add new blocks to the blockchain. This mining process is regulated by a consensus mechanism,\nwhich sets rules to ensure that all participants in the blockchain network agree on the validity of\nthe transactions and their order in the blockchain.\nSmart contract. Smart contracts are computer programs that automatically enforce the terms of\nan agreement between parties. They are used to speed up, verify, or execute digital negotiations.\nEthereum developed smart contracts on the blockchain system by using Turing-complete scripting\nlanguages to achieve complex functionalities and execute thorough state transitions via consensus\nalgorithms, resulting in \ufb01nal consistency. Smart contracts enable unfamiliar parties to conduct fair\nexchanges without the need for a trusted third party. They have a broad range of applications,\nincluding \ufb01nancial services [13][14], security protocols [15], and decentralized governance [16].\nSmart contracts are viewed as a disruptive technology that could revolutionize many industries\nby improving e\ufb03ciency, reducing costs, and eliminating the need for intermediaries.\nOn-chain application. On-chain applications, also known as DApps, are applications that run\non blockchain systems [17]. Unlike traditional applications, which are centralized and controlled\nby a single entity, on-chain applications are decentralized and operate on distributed networks.\nThe applications are designed to be transparent, secure, and trustless. They use smart contracts\nto execute code and transactions, and the consensus mechanism of the underlying blockchain\nnetwork to verify and validate these transactions. Thanking the nature of decentralization, they\nare resistant to censorship, tampering, and other forms of malicious activity [18]. For speci\ufb01c usage,\non-chain applications include various types such as NFT [19], gaming, social networking, etc.\nLight client. A light client [20] plays a crucial role in the world of Web3 and blockchain technol-\nogy, acting as an intermediary between user requests and the back-end servers or blockchains. Its\nprimary function is to forward user requests to their appropriate destination without engaging\nin any logic processes. Generally, a light client is represented by a wallet [21] in the context of\nWeb3 or blockchain. It is supported by locally running light nodes, which synchronize informa-\ntion with full nodes. This makes using a light client highly advantageous in resource-constrained\n4\nenvironments, such as di\ufb00erent hardware devices, as it can reduce the costs of performing com-\nplex computations on-chain [22\u201324]. In the Web3 ecosystem, it is typical for users to connect their\nwallets to perform interactive actions on the website. By understanding the role of a light client,\nusers can navigate the complexities of Web3 and blockchain technology with ease.\n3\nRESEARCH DESIGN\nIn this section, we conduct an exploratory study [25], which proposes a new Web3 driven frame-\nwork, named WebttCom, for implementing applications; and we de\ufb01ne the research question (RQ)\nfor identifying and extracting the evidence (e.g., the bene\ufb01ts of Web3 applications) for evaluating\nour proposed Web3 framework.\n3.1\nResearch Qestion\nThis study aims to design and analyze whether our Web3 framework is e\ufb00ective and practical\nregarding quality attributes (i.e., smooth transition) and development productivity. Such charac-\nterization of Web3 will shed light on future Web3 applications and developments. Speci\ufb01cally, this\nwork aims to address the Research Question (RQ) as:\nGiven the proposed Web3 framework (i.e., WebttCom), is it e\ufb00ective, regarding the transi-\ntion of Web2 to Web3 application development?\n\u2022 Web2 to Web3 transition: Given that many developers do not have relevant development\nbackground for Web3 applications, is the proposed framework practical and helpful for them\nto transit the Web2 to Web3 applications for meeting and implementing the speci\ufb01c require-\nments?\n\u2022 Data privacy and governance: In the evolution from Web2 to Web3, various issues related\nto data privacy and security, data privacy and governance in Web3 is one of the most dis-\ncussed challenges for di\ufb00erent stakeholders. As such, to address this concern, our RQ can\nexplore whether the proposed Web3 framework (i.e., WebttCom) ensures data privacy and\ngovernance.\n\u2022 Development productivity: If the proposed Web3 framework impacts developers\u2019 pro-\nductivity? For example, (1) practitioners\u2019 daily development tasks and documentation. (2)\nproblem-solving for Web3 application development.\n3.2\nStudy Design Process\nOur research methodology consists of three stages, as depicted in Fig. 1. In the \ufb01rst stage, we\nproposed a Web3 transition framework (i.e., WebttCom), which includes an interpreter to help\npractitioners transit and bridge the Web2-based to Web3-based applications. We implemented a\nfull-stack project based on the proposed WebttCom in the second stage. In the last stage, to eval-\nuate the e\ufb00ectiveness of the proposed WebttCom and the feasibility of the full-stack project, we\nconducted a quantitative performance evaluation and carried out a qualitative survey with 1,000\npractitioners, including Venture Capitals (VCs), business managers, and developers, to gather their\nfeedback and opinions.\nPhase 1: Web3 driven framework. We proposed a Web3 framework (WebttCom), which allows\ndevelopers to implement e\ufb00ective and reliable applications. The framework guarantees:\n\u2022 Web2 to Web3 smooth transition: our framework provides a trustworthy transition.\n\u2022 Blockchain backend: the framework ensures the decentralization of Web3-driven applica-\ntions.\nThe details of the framework are described in Section 4.1.\n5\nWeb3 Driven Framekwork\nUse Case Exploration \n!\"#$%&'()*\"\"$&+\n,-$.&#/%*#0$\n1*0&#2#3*%&.\n4$56'&/'4$57\n8*&*'10#9*2:'\n8*&*'8$2$%&0*\"#;*&#/%\n<1='8/2'>$%$0*&#/%\n8<33.\n?@*0&'2/%&0*2&A\nB\"/2C2D*#%.\nStage1\nStage2\nStage3\nEvaluation\nImplementation\nQuantitative: Performance\nQualitative: Survey\nFig. 1. Overview of the study design\nPhase 2: Web3 application implementation. In this phase, we implemented a full-stack appli-\ncation, which is based on the Web3 framework that we proposed. The details of the application\nare described in Section 4.2.\nPhase 3: Performance evaluation and surveys. As depicted in Fig. 1, in this phase, we gave the\noverall quantitative performance evaluation. At the same time, we invited 1,000 practitioners\nto participate in qualitative surveys to con\ufb01rm the e\ufb00ectiveness of our proposed Web3-driven\nframework and implementation.\n\u2022 We invited 1,000 practitioners from BT, universities, and VC members in Australia and China,\nas well as developers from GitHub and those on the mailing list, to participate in our surveys.\nThese surveys were anonymous and the survey results were based on the valid respondents.\n\u2022 We designed a questionnaire consisting of three main questions (see Section 4.4.1) to get de-\nvelopers\u2019 opinions on the e\ufb00ectiveness of our proposed framework and the implementation\nwe developed.\n\u2022 We applied qualitative data analysis and consistent comparison to summarize the statements\nfrom the survey result regarding the productivity of using our framework and application.\nThe questionnaire consists of three parts of questions:\n\u2022 Part 1: We asked demographic questions, such as the surveyees\u2019 experience in Web3 devel-\nopment and management.\n\u2022 Part 2: We asked open-ended questions to understand their opinions on Web3 design and\ndevelopment in practice.\n\u2022 Part 3: We prepared candidate topics by carefully reading the contents of representative\ntextbooks. We picked a list of topics not explicitly mentioned in the open discussion and\nasked the participants to discuss those topics further. At the end of each survey, we thanked\nthe participants and brie\ufb02y informed them what we planned to do with his/her response.\n4\nRESEARCH RESULT\nIn this section, we propose a new framework, named WebttCom, which not only smooths\nthe transition between Web2 and Web3 but also achieves high data privacy and data governance\nand improves development productivity. A full-stack implementation is presented as a use case to\n6\nPolicy\nResolver\nWrite \nControl\nUpdate\nControl\nRead\nControl\nP2L\nMapping\nBlockchain\nLayer\nSmart Contract\nData\nCollection 1 \nData\nCollection 2 \nData\nRepository\nPrivate Data\nMeta Data\nRepository\nPolicy\nRules\nData\nHash\nPublic Data\nData Provisioning\nSoftware as a Service \n(SaaS)\nBackend\nInterpreter\nStart\nAsset\nService\nStyle\nService\nJS\nService\n!\"#$\n!%&&\n!\"&\nReact \nContainer \nCreation File\n!'()*\ncreate\ndeploy\ndeploy\nREST \nAPI\nInterpret\n& Forward\nBlockchain\nSDK\nStorage\nStorage\nFrontend\nBackend\nService \nProvider\nSaaS\nPlatform\nOur case: ServiceNow\n\u2026\nUser \nManagement\nWeb2-Web3 \nTransition\n\u2026\nService \nManagement\nAutomated \nDevelopment\nReturn \nResults\nFig. 2. Overview of the instantiated service management platform.\nsupport the framework. We also conducted surveys where the intended 1,000 practitioners were\ninvited to con\ufb01rm the e\ufb00ectiveness of the proposed framework and implementation.\n4.1\nA New Framework: WebttCom\nA new framework, named WebttCom (Web2 to Web3 Communicator), is proposed as a result.\nWebttCom provides trusted and reliable service management across multiple organizations in a\ndecentralized manner and promotes the transition from the existing Web2 form to Web3. Note\nthat \u201ctransition\u201d does not mean the existing Web2 applications must be completely reconstructed.\nInstead, a new interpreter is attached in the middle to o\ufb00er reliable communication, smoothly\nintegrating Web2 applications to Web3 platforms and transiting Web2 applications that would have\nbeen slowly drifting apart from decentralization into a Web3-empowered structure. In particular,\nthe structure of WebttCom consists of a blockchain layer, a backend interpreter, and a Web2\nSoftware as a Service (SaaS), as in Fig.2.\nThe blockchain layer stores service management data and supportive data and controls access\nto the service data. To this end, the blockchain layer contains a smart contract for data provi-\nsioning, a private data repository for service data, and a public data repository for data access\npolicies and data hash checksum. In the smart contract, the policy resolver module extracts at-\ntributes of requests, such as requested data, request location, and user a\ufb03liation, and identi\ufb01es\ne\ufb00ective access control policies. The write control module enforces data storage policies, such as\ndata storage location and data expiration. The update control module takes charge of data updates,\nwhile the read control module enforces data access policies. The Physical-to-Logical (P2L) mapping\nmodule updates data presentation according to pre-de\ufb01ned physical data formats for data storage\nand logical data formats required by the SaaS. Note that the blockchain layer is designed to be\nblockchain-agnostic, allowing for seamless integration with any blockchain platform empowered\nby automated smart contracts and applicable functionalities such as user management, access con-\ntrols, external integration, etc. This design ensures \ufb02exibility and adaptability, as the system can\nleverage the strengths of various blockchain platforms without being constrained by any single\nplatform.\nThe backend, functioning as a Web2-Web3 interpreter, bridges the gap between traditional Web2\nSaaS platforms and the emerging Web3 ecosystem by facilitating seamless communication be-\ntween the two. This is achieved through the Web2-Web3 transition module, which is responsible\nfor forwarding requests originating from Web2 SaaS applications to Web3 smart contracts and\nsubsequently formatting the resulting Web3 responses in a manner that can be easily understood\n7\nby Web2 SaaS applications. In order to e\ufb00ectively manage users during the transition phase, the\nbackend interpreter maintains separate user management systems for both Web2 and Web3 users,\nwith a completed synchronization at the end. This ensures that each user category\u2019s unique at-\ntributes and requirements are adequately addressed while preserving the overall user experience.\nFor the Web2 side, the backend interpreter o\ufb00ers a comprehensive REST API for SaaS applica-\ntions to interact with. This API enables SaaS platforms to send requests and receive responses\nfrom the Web3 environment without directly interacting with Web3 technologies. This simpli\ufb01es\nthe integration process and allows developers to focus on their core application logic. To further\nstreamline the development process, the backend interpreter incorporates automated development\ntechnology that automatically generates routes and documentation. This signi\ufb01cantly reduces the\ntime and e\ufb00ort required by developers to create, maintain, and update their APIs, allowing them to\nconcentrate on delivering high-quality services to their users. When it comes to communicating\nwith blockchain networks, the backend interpreter leverages blockchain Software Development\nKits (SDKs). These SDKs provide a set of pre-built tools and libraries that make it easier for devel-\nopers to interact with various blockchain protocols and smart contracts. By utilizing these SDKs,\nthe backend interpreter can e\ufb03ciently query, submit transactions to, and retrieve data from the\nblockchain while maintaining high security and reliability. In other words, the backend interpreter\nplays a crucial role in bridging the divide between Web2 SaaS applications and the emerging Web3\necosystem. By o\ufb00ering a seamless communication channel between the two environments, man-\naging user transitions e\ufb00ectively, and providing robust development tools, the backend interpreter\nenables the integration of Web3 technologies into existing Web2 applications, paving the way for\na decentralized and interconnected digital landscape.\nWeb2 SaaS platforms o\ufb00er sophisticated service management interfaces that allow users to eas-\nily submit, view, and process service tickets after authenticating themselves on the platform. These\ninterfaces are designed to provide a seamless user experience, making it simple for users to access\nand manage their service requests. To ensure adaptability and compatibility with the emerging\nWeb3 technologies, the service management functionality is implemented as a modular, plug-and-\nplay component. This design approach enables the service management module to be easily in-\ntegrated with popular service management platforms, such as ServiceNow React Container [26],\nwhile allowing for incorporating Web3-enhanced features.\n4.2\nImplementing WebttCom: A Use Case in a Service Management System\nAn implementation of the proposed framework WebttCom is discussed in which a trusted and\nreliable service management platform across BT Global, BT Australasia, and BT Australasia cus-\ntomers is demonstrated. Managing the services (e.g., inventory/ordering/ticketing) that BT deploys\nis challenging due to a lack of trust in the data to execute these processes. Con\ufb02icting information,\nlack of real-time parameters of the state of the various devices, and complex disputes between\ntwo or more parties are just a few ingredients of these challenges. BT\u2019s services can consist of\nequipment from di\ufb00erent manufacturers deployed in di\ufb00erent countries, managed by di\ufb00erent\nsecondary service providers, operating under di\ufb00erent SLAs, and serving di\ufb00erent customers. Cor-\nrect management of these complex services has proven to be one of the key challenges for BT\u2019s\nengineering teams and is one of the key factors for the company\u2019s international reputation and\nsuccess. Currently, these services are managed by legacy and non-integrated systems that often\ncannot operate in real-time to meet global customers\u2019 demands.\n8\n<< Interface >>\nWeb3Con\ufb01g\nconnection: String \nwalletPath: String \nwalletID: String \nchannelID: String \ncontractID: String \ncollection: String \ntransientID: String\nAutoOpenAPIGenerator\nrouteGenerate(func[]) \ndocGenerate(path, docType, \n         Dictionary<registry, <attributes[], func[]>>) \nuiSetup(ip, port)\nSmart Contract\nentryPoint : String\nOperations(params): returnType\nWeb3 (Blockchain)\nblock: String\nconsensus: String\nuser: Web3User\nsmart contract: contract\nconsensus(params):block \ndeplyContract(contract):  entryPoint \nupdateContract(contract): String \nrunContract(Web3User, request): String\nRecord\nID: String \nattributeName: String \nattribute: Type (user-de\ufb01ned attributes)\nquery(ip, id, Web3Con\ufb01g):Record \ndelete(ip, id, Web3Con\ufb01g) \ncreate(ip, record, Web3Con\ufb01g) \nupdate(ip, record, Web3Con\ufb01g)\nWeb3PolicyRegistry\nrecord: Record \nwritePolicy: String \nreadPolicy: String \nupdatePolicy: String\ncreate(Web3User,payload)\nupdate(Web3User,payload)\nread(Web3User,payload)\nWeb3ObjectRegistry\nrecord: Record object\nInformation: String \naccessPolicy: jsonString\ncreate(Web3User,payload)\nupdate(Web3User,payload)\nread(Web3User,payload)\nWeb2UserRegistry\nrecord: Record \nWeb2Identity: String \nWeb2Credential: type \nWeb2UserType: type \nWeb3Identity: type \nWeb3Credential: type\nnew():returnType \nlogin(): returnType \ninvokeContract(\n    loginToken, \n    Web3Identity, \n    Web3Con\ufb01g, \n    contractEntryPoint, \n    contractRequest\n): returnType\nBlock i-1\nBlock i\nWeb3UserRegistry\nrecord: Record\nWeb3Identity:type \nWeb3Credential: type\nnew():returnType \ninvokeContract( \n    Web3Con\ufb01g, \n    contractEntryPoint, \n    contractRequest\n): returnType\nBlockchain\nLayer\nRepresentative\n Layer\n1\n1\n1\n0\u2026!\nFig. 3. The class diagram of the instantiated service management platform.\nThe HyperLedger Fabric [27] is set up with one Fabric ordering service5, and organizations\nrepresenting BT Global, BT Australasia, and BT Australasia customers in the same channel6 for\nthe Web3 service. Each ordering service and organization has one Certi\ufb01cate Authority (CA) node\nand one peer node. Service ticket data are recorded in the Hyperledger Fabric in real time and are\ncerti\ufb01ed by the data hash. With Web3 technology, all organizations have a consistent view of the\nservice data. The platform is developed in TypeScript 4.4 using Visual Studio Code 1.69.1 and runs\non the elastic servers of Amazon Web Service (AWS). MySQL 5.7 is selected to handle the Web2-\nbased registries, whereas the Web3-based registries rely on the native CouchDB of HyperLedger\nFabric 1.4.\nThe implementation design of a service management system, as a use case of the proposed\nWebttCom, is illustrated in Fig.3 using the class diagram. Blockchain maintains a blockchain\nnetwork with several registered SmartContract. SmartContract is inherited by three classes, i.e.,\nWeb3UserRegistry, Web3ObjectRegistry, and Web3PolicyRegistry. The Web3UserRegistry registers\nthe user Web3 information in Hyperledger Fabric CAs and interacts with the corresponding cus-\ntomizable o\ufb00-chain-stored Web2UserRegistry in which the local user management is conducted. All\nobjects, including the product inventory, product order, service inventory, and trouble ticket ser-\nvice, are on-chain-stored in Web3ObjectRegistry with dedicated policies of access control stored in\nWeb3PolicyRegistry. All registries comprise Record in which the user-de\ufb01ned data record attributes\nare stored. Accessing the attribute values in Record relies on Web3Con\ufb01g in which the settings of\nBlockchain are de\ufb01ned. AutoOpenAPIGenerator auto-generates the OpenAPI standard [28] docu-\nmentation for modules including Web2UserRegistry, Web3UserRegistry, Web3ObjectRegistry, and\nWeb3PolicyRegistry.\n4.2.1\nAtribute-based Access Control in Web3. In the Hyperledger Fabric, each organization has\none private data collection [29], which excludes other organizations, such that private business\ndata are only saved and managed by the permitted organization. All blockchain members can\n5The ordering service validates transactions and assembles valid transactions into ordered blocks.\n6A Fabric channel is a private sub-network for permitted members.\n9\naccess public on-chain data. Web3 users are registered to CAs with their attributes, including or-\nganizations, departments, and user types. The attributes are used for the attribute-based access\ncontrol to the service data. Each Web3 user has a unique private key to sign Web3 transactions\nand access Web3 services.\nSmart Contract: A service smart contract is developed to manage service tickets. The exposed\nentry points of the smart contract are shown in Listing 1. The smart contract extends the Fabric\nContract class and exports functions as APIs.\nIn the smart contract, create/update/read functions are developed for Web3PolicyRegistry and\nWeb3ObjectRegistry, as shown in Fig.3. Web3PolicyRegistry is implemented with the Fabric public\ndata scheme where all blockchain peers have a copy of the public data, while Web3ObjectRegistry\nis realized with the Fabric private data scheme where only authorized peers have data copies. Vari-\nable ctx collects the context of the transaction calling the smart contract, including user attributes\nand timestamp for access control and transient service data7. Variable attributes provides Web2\nattributes for access control, such as geolocation information. Variable publicPayload gives the\ndata requested by smart contracts and recorded on the Fabric blockchain, such as access control\npolicies.\nAccess Control: The smart contract enables attribute-based access control (ABAC), where ac-\ncess control policies are designed based on user and environment attributes and organized as the\nWeb3PolicyRegistry. A policy is either writePolicy, readPolicy, or updatePolicy, and each of them has\nunique \ufb01elds describing access control requirements. All the policy types also have general meta-\ndata, including an updated time, an e\ufb00ective time, and a priority level, for policy con\ufb02ict resolver.\nAll policies are created by organization admins and saved in the public data repository such that\npolicies can be accessed by all Web3 users and applied to all private data collections.\nThe policy resolving process is shown in Listing 2. The policy resolver \ufb01rst extracts the Web3\nuser attributes and environment attributes of the transaction, such as transaction timestamp, from\nthe ctx variable. Next, the policy resolver module retrieves all related policies according to the\npolicy IDs embedded in the request data. Then, the policy resolver identi\ufb01es e\ufb00ective policies\nby checking Web3 user roles, e\ufb00ective timestamps, policy priority, and geolocations. At last, the\npolicy resolver returns e\ufb00ective policies for the request.\nThe write control, update control and read control modules then process the request according\nto the request data in the request transactions and e\ufb00ective policies. The request is rejected if no\ne\ufb00ective policy is returned from the policy resolver module. For a data write/update request, the\nwrite control and update control modules \ufb01rst identify the right private data collection from e\ufb00ec-\ntive writePolicy and updatePolicy. The modules also check request attributes against the require-\nments speci\ufb01ed in the e\ufb00ective policies and terminate the request for failed checks. The modules\nthen extract transactional data and transient data from the request transaction and create a Web3\nobject with object information and related access policy IDs. Then, the modules can write/update\nthe Web3 object to the data collection. For a data read request, the read control module gets the\nprivate data collection from the request transaction and reads the requested data out following the\ne\ufb00ective readPolicy. The read control module also implements the P2L mapping on the data keys\nfollowing the mapping rules stated in e\ufb00ective readPolicy.\n4.2.2\nWeb2-Web3 Transition. Recall that \u201ctransition\u201d does not lead to a completed reconstruc-\ntion of existing Web2 applications. It is the interpreter that establishes the communication and\nsmoothly makes the Web2 applications empowered by Web3. Each organization has an interpreter\nto convert Web2 requests to Web3 requests and forward requests to speci\ufb01c Web3 nodes according\n7Transient data is a type of data for Fabric private data collection, which can be read by smart contracts but does not be\nrecorded in on-chain transactions.\n10\nto request attributes for Web3 processing. The interpreter then monitors Web3 processing results\nand creates returns for Web2 requests.\nWeb2 APIs: The interpreter provides REST APIs supporting create, read, and update operations\nin Web2 applications and implements the Bearer Authentication scheme [30].\nA Web2 request includes payloads describing create, read, and update operations on Web3 ob-\njects and policies. Besides that, the Web2 request contains a bearer token for authentication by\nthe interpreter. The bearer token also allows the interpreter to identify the corresponding Web3\nidentity and private key for signing Web3 transactions. The Web2 request also gives details for\nthe corresponding Web3 request, including the channel name, smart contract name, and targeted\nprivate data collection, such that the interpreter can create correct Web3 request transactions and\nsend them to the right Web3 node for processing.\nWeb3 Interaction: Interpreters manage user identities and interact with the service smart con-\ntract using the Hyperledger Fabric SDK [31], as shown in Listing 3. The channel and service smart\ncontract is speci\ufb01ed by variables channelName and scName in lines 10-11.\nFor every Web3 request, the interpreter needs to create a request transaction and sign the trans-\nactions with a valid Web3 user identity. To this end, the interpreter saves the Web3 user identities of\nall Web2 users in the organization, i.e., walletPath and walletID in Listing 3, and maintains the map-\nping between Web2 and Web3 identities. The interpreter is an organization admin user who can\nregister and revoke users. During the user registration process, a user provides user information\nand credentials to the interpreter, like general Web2 user registration. The interpreter \ufb01rst creates\na new user record on itself and then sends the registration information to the organizational CA\nnode to create a Web3 identity. Then, the interpreter keeps the user\u2019s Web3 wallet, including a\nprivate key, and records the mapping between the Web2 identity and Web3 identity.\nThe interpreter needs to connect speci\ufb01c Web3 nodes that have requested private data collec-\ntions. To this end, the interpreter maintains connection pro\ufb01les8 to Web3 nodes from di\ufb00erent\norganizations and records the mapping between private collections and the hosting Web3 nodes.\nWhen the interpreter receives a Web2 request, the interpreter identi\ufb01es the data collection related\nto the request. The interpreter forwards the request to any Web3 node if the requested data is\npublic. If the request points to some private data collection, the interpreter \ufb01rst identi\ufb01es the host-\ning Web3 node and then forwards the request to the Web3 node using pre-con\ufb01gured connection\npro\ufb01les.\n4.2.3\nTransition with SaaS: ServiceNow-based Web Application. ServiceNow is a popular cloud-\nbased work\ufb02ow automation platform for enterprises by streamlining and automating routine work\ntasks. Companies often seek a simple solution for connecting their existing ServiceNow applica-\ntions to Web3 systems. As a result, we chose ServiceNow as our front-end system. We intend to\nsolve the following problems with our scheme:\n\u2022 ServiceNow\u2019s existing system could be transformed in an e\ufb03cient manner.\n\u2022 Programmers\u2019 coding can be made easier by following a few simple steps.\nTo resolve these issues, we implement a ServiceNow container as shown in the left part of Fig.2.\nWe develop a web application using React and embedded it in ServiceNow. By using REST APIs,\nthe embedded application can smoothly communicate with the backend and the interpreter.\nThe web application was developed using React, an open-source JavaScript library for creating\nuser interfaces with a large fan community. Therefore, most programmers are familiar with it and\ncan easily obtain assistance from other community members.\n8A connection pro\ufb01le describes the Web3 node to be connected, such as ID and IP/port.\n11\nA modern website deployment method - Webpack - is used to deploy this web application. In-\nstead of deploying all resource \ufb01les directly to the web server, Webpack binds multiple \ufb01les into\na single deployment \ufb01le. Multiple HTML \ufb01les are combined into one HTML \ufb01le, and multiple\nJavascript \ufb01les are combined into one Javascript \ufb01le. This deployment method simpli\ufb01es the re-\nsource access path, which is exactly what we require.\n\u2022 The deployment utilizes two ServiceNow concepts: the UI page and the web service.\n\u2022 The ServiceNow UI page allows developers to customize web pages using HTML or XML.\nIn this case, we create one UI Page and insert the combined HTML code using Webpack.\nThe ServiceNow web services provide access to resources through REST APIs. Three web ser-\nvices have been developed: the Asset Service, the Style Service, and the JS Service. All images are\naccessible through the asset service. The styling service provides all CSS access. The JS service\nprovides access to JavaScript code.\nThe web application has three functions: user login, policy management, and ticket manage-\nment. As part of implementing these functions, the embedded application communicates with the\ninterpreter using HTTP REST APIs.\n4.2.4\nBackend and Automated Development Tools. The Express framework o\ufb00ers a \ufb02exible Node.js\nweb application with MySQL being used for Web2UserRegistry and Web3Con\ufb01g. Sequelize is used\nto provide e\ufb00ective connections to the Web2 local registry in the manner of an Object-relational\nMapper (ORM). The platform is docker-based by default, and docker-compose o\ufb00ers an orchestra-\ntion service for distributed and \ufb02exible docker containers.\nThe system also o\ufb00ers automated generation and documentation of OpenAPI-compliant REST\nAPIs [28] for Web2UserRegistry, Web3UserRegistry, Web3ObjectRegistry, and Web3PolicyRegistry\nvia TSOA 3.11 [32]. The TSOA framework integrates the OpenAPI compiler to construct Node.js\nserver-side applications in type-safe TypeScript at runtime, as TypeScript is used for programming\nsmart contracts at the Web3 side and backend/frontend at the Web2 side. The function, routeGen-\nerate, can easily generate the API routes automatically with no pain based on the de\ufb01nition of\ncontrollers of all registries above; see the lower half of each registry in Fig.3. At the same time,\nthe YAML-based OpenAPI documentation and test suite are also generated to ease API testing and\nsmooth the development of transition via docGenerate.\n4.3\nPerformance at a Glance\nThe developed WebttCom and Hyperledger Fabric 1.4.6 have been deployed on a Mac mini,\nequipped with a 3.2 GHz 6-Core Intel Core i7 and 32 GB 2667 MHz DDR4 memory, utilizing Docker.\nWebttCom operates with Fabric SDK fabric-network version 1.4.0, while the Hyperledger Fabric\nconnection pro\ufb01les and the wallets of associated users are integrated into WebttCom. Within\nHyperledger Fabric, the BatchTimeout is con\ufb01gured to 2 seconds, establishing the maximum dura-\ntion a blockchain node should wait for transactions to be mined into a block. Consequently, write\noperations can be con\ufb01rmed in a maximum of 2 seconds.\nFor the performance evaluation, \ufb01ve APIs have been selected, encompassing read/write opera-\ntions and public/private data, as detailed in Table 2. The two data objects, i.e., policy and ticket, are\nstored as public and private data on the blockchain, respectively. The API Get a policy retrieves a\nsingle policy, approximately a 1KB JSON object, based on the policy ID. Get all policies retrieves all\npolicies, totaling 91 policies and 56.97KB. Get all tickets fetches all accessible tickets, which include\neight tickets and amount to 5.67KB. It is noteworthy that read access control is enabled in the smart\ncontract. Upon receiving the read request, the smart contract initially retrieves all valid readPolicy\naccording to the user and policy metadata, subsequently identi\ufb01es accessible tickets, and returns\n12\nTable 2. APIs in the Performance Evaluation\nAPI\nR/W\nPublic/Private\nPayload\nSize\nGet a policy\nRead\nPublic\n1 policy\n1KB\nGet all policies\nRead\nPublic\n91 policies\n56.97KB\nGet all tickets\nRead\nPrivate\n8 tickets\n5.67KB\nCreate a policy\nWrite\nPublic\n1 policy\n1KB\nCreate a ticket\nWrite\nPrivate\n1 ticket\n2KB\nthem to WebttCom. Create a policy generates a single writePolicy of about 1KB, while Create a\nticket creates a single ticket, approximately 2KB, adhering to the write access control.\n(a) Web2 response time and Web3 processing time\n(b) Processing time on WebttCom\nFig. 4. Time performance of WebttCom\nFig. 4 illustrates the overall response time and Web3 processing time of the APIs, labeled as\nWeb2 and Web3, respectively. During the test, each API is executed independently 20 times in a\nsequence, with the overall response time derived from the HTTP response and the Web3 process-\ning time extracted from the blockchain peer log. Therefore, the overall processing encompasses\nHTTP request handling in WebttCom, user authentication in WebttCom, transaction generation\nin WebttCom, communication between WebttCom and the blockchain, and Web3 processing\ntime. As depicted in Fig. 4(a), the three read APIs require less than 600 ms, and both the overall\nresponse and Web3 processing time increase with the complexity and data size of the applications.\nThe two write APIs take approximately 2.5 seconds, attributable to the BatchTimeout of 2 seconds,\nwhich could be expedited with a reduced BatchTimeout. Operations on private data necessitate\na longer processing time than those on public data. Fig. 4(b) demonstrates the processing time\non WebttCom, i.e., the discrepancy between the overall response time and Web3 processing time.\nWebttCom takes about 150 ms for the APIs, while Get all policies takes roughly 200ms and exhibits\nthe largest variance due to the substantial data transmission and resolution of a large number of\npolicies. The evaluation results a\ufb03rm that WebttCom can e\ufb03ciently transition Web2 to Web3\napplications.\n13\nPositive\nNeutral\nNegative\nCategories\n0\n10\n20\n30\n40\nNumbers\n78.33%\n18.33%\n3.33%\n(a) Sentiment analysis regarding each category of responses\nBT company\nUniversities\nVCs\nOther developers\nCategories\n4\n2\n0\n2\n4\n6\n8\n10\nSentiment Value\n(b) Sentiment analysis regarding each response from di\ufb00er-\nent organizations\nFig. 5. Sentiment analysis of the survey results\n4.4\nSurvey Results\nWe followed the same benchmarks in [33] by conducting a set of surveys to assess the Necessity,\nUsability, and Completeness of the proposed framework WebttCom and the implementation.\n4.4.1\nSurvey Qestions. The technical background and Web3 experience were asked, followed by\nthe following questions from the domain experts to ensure the Necessity of the new proposed\nframework WebttCom:\n\u2022 What do you think of the pros and cons of Web2 and Web3 by now under your background?\n\u2022 What do you think of the necessity of a smooth transition between Web2 and Web3 (both\nWeb2 to Web3 and Web3 to Web2) from your organizational and personal perspectives?\n\u2022 What are the possible challenges during the transition that you think are required to be\nresolved immediately?\nFurther, we asked the following questions for feedback on WebttCom and overall Usability and\nCompleteness of the implementation.\n\u2022 To what extent does the Service Management System developed by UTS and BT, the imple-\nmentation of the proposed framework WebttCom, match the principles of WebttCom and\naddress the challenges above?\n\u2022 What are your suggestions to enhance the suitability of the new framework WebttCom and\nits implementation?\n4.4.2\nKey Findings. We summarized key \ufb01ndings from the surveys that can support the proposed\nframework WebttCom and implementation as a use case. Out of the 1,000 practitioners we invited,\nwe received feedback from 58 valid respondents. Approximately 80% of the responses were posi-\ntive, and around 20% were neutral; see Fig. 5. For clarity, we referenced \ufb01ve highly representative\nresponses in Appendix-B during our discussion of the key \ufb01ndings, listed as follows:\n1) Necessity - enable guided and structured design: Building Web3 technology into Web2\nsystems can solve critical security and trust issues in Web2 systems, especially for businesses\nacross multi-organizations. Web2 systems are centralized and can hardly achieve trust across or-\nganizations, while the inherent consensus mechanism of Web3 technology can provide veri\ufb01ed\nsingle-ground truth and thus build trust across parties. The second surveyee stated, \u201cA transition\nfrom Web2 to Web3 will bring the data trustworthiness and cybersecurity guarantee from Web3 to\nWeb2 systems. \u201d.\nIt is important to have a smooth transition between Web2 and Web3. This is because Web2\nis a mature technology, but developing Web3 applications could be challenging. As stated by the\n14\nfourth surveyee with limited Web3 knowledge \u201cThe modi\ufb01cation of the existing Web2 system should\nnot be di\ufb03cult. To avoid overloading the programmers with Web3 knowledge, they should not learn\ntoo much.\u201d, and the \ufb01fth surveyee stated, \u201cWeb2 and Web3 should be able to coexist and interact\nsmoothly.\u201d Detailed challenges during the transition between Web2 and Web3 include\n\u2022 The transition of two di\ufb00erent technologies, as stated by the fourth surveyee \u201cDue to the\ndi\ufb00erences in concept, technology, and tools between Web2 and Web3, it is di\ufb03cult to integrate\nthe Web2 system with the Web3 system.\u201d\n\u2022 New access control schemes in Web3. The \ufb01rst surveyee stated \u201cWeb3 is transparent, how\nto apply \ufb02exible and feasible access control becomes important for cases where data privacy is\nconsidered\u201d, and the third surveyee stated \u201cDLTs are a promising solution due to the ability\nof smart contracts to ensure that the required country-speci\ufb01c data management policies are\nagreed and enforced.\u201d\n\u2022 Heterogeneous user management across Web2 and Web3. The \ufb01rst surveyee stated, \u201cAp-\nproach to apply the user management in a shared ledger may be a challenge as Web2 parties\ntend to have separate user management systems locally.\u201d\n\u2022 High development and transition cost. The \ufb01rst and the \ufb01fth surveyees stated \u201cEasing the\ntransition by using automated tools is normal in Web2 applications and is also essential during\nthe transition between Web2 and Web3.\u201d and \u201cChallenges include lack of experienced developers,\nlack of available development resources, tools.\u201d\n2) Usability - flexible access control: The developed \ufb02exible access control can implement ac-\ncess control policies as designed. The service provider can de\ufb01ne access control policies, including\ndata storage and write and read policies. The smart contract on the Hyperledger Fabric enforces\nall the policies and controls access to on-chain data. All surveyees have con\ufb01rmed the developed\naccess control mechanism. The second surveyee stated, \u201cThe system can enforce all the expected\ndata governance and access control policies.\u201d, and the third surveyee stated \u201cIn evaluating the so-\nlution we have demonstrated that a DLT Hyperledger layer can meet the required success criteria\nrelated to cross-country access control and user-management; as well as connecting to a traditional\nSaaS work\ufb02ow management layer.\u201d\n3) Usability - compatible user management: The developed user management compatibly\nmanages Web2 and Web3 users. When a user submits a Web2 registration request, Web2 and Web3\naccounts are simultaneously created and managed by the developed framework. When users log in\nand submit requests, the framework can perform authentication with the users\u2019 Web2 credentials\nand process Web3 requests and responses in the representation of the users. All chosen surveyees\nare satis\ufb01ed with the developed user management. The second and fourth surveyees stated, \u201cA user\ncan use one identity to access Web2 and Web3 services.\u201d and \u201cWeb2 programmers are not required to\ntouch too much.\u201d\n4) Usability - easy integration with existing platforms and services: The developed sys-\ntem seamlessly integrates with existing service management on ServiceNow. All operations are\nconducted in ServiceNow, including login, access control policy management, and service ticket\nmanagement. The work\ufb02ow remains the same with the Web2 version. Nevertheless, all data are\nsecurely saved on the Hyperledger rather than disconnected databases and can be veri\ufb01ed with\nthe Web3-certi\ufb01ed data hash. As the second surveyee stated, \u201cUsers can access Web3-certi\ufb01ed data\nservices from the SaaS. The complicated Web3 details are transparent to users.\u201d\n5) Usability - highly automated development tools: Highly automated development tools\nare implemented to generate and document OpenAPI-compliant REST APIs of both Web2 and\nWeb3 registries. This signi\ufb01cantly improves programming e\ufb03ciency by sharing the same develop-\nment work\ufb02ows and schema formats between Web2 and Web3. As the 1st, 2nd, and 4th surveyees\n15\ngave positive feedback by stating \u201cAutomated development tools signi\ufb01cantly reduce the program-\nmers\u2019 workload and has almost become a must-use tool during the current work\ufb02ow.\u201d.\n6) Completeness - su\ufb03cient decentralization with robust data privacy and governance:\nThe surveyees satisfy the framework WebttCom and the use case regarding achieving su\ufb03cient\ndecentralization level while ensuring strong data privacy and governance; as the \ufb01rst surveyee\nstated \u201cThe framework appears to be covering most perspectives including the access control, data\nprivacy, data governance, user management, connections to existing SaaS, and development produc-\ntivity.\u201d. This is done by successfully applying the \ufb02exible access control in a decentralized manner,\ni.e., smart contracts on the Hyperledger Fabric. Robust data privacy and governance can thus be of-\nfered to ensure secure and transparent data management while fostering trust among participants\nin a distributed and tamper-resistant manner.\n7) Completeness - limited cases: The fourth and \ufb01fth surveyees stated \u201cMore commercial Web2\nsystems should be integrated with Web3.\u201d and \u201cNeed to \ufb01nd suitable business use cases to demon-\nstrate the bene\ufb01t of Web3\u201d. Three surveyees noted that the proposed framework WebttCom re-\nquires more business use cases to support by potentially integrating the existing commercial Web2\nprojects. While we admit this limitation at the time of writing, this work originates from solving\nthe transition issue from Web2 to Web3, which came across by our business partner proceeding\nwith their latest strategy. This work is new and lacks su\ufb03cient existing use cases. Therefore, this\nwork focuses on demonstrating how WebttCom solves the research question, and we postpone\nextending use cases to improvements and future works.\n8) Potential Improvements: Among the chosen representative respondents, four indicated\nthat the framework and the provided use case seem limited to permissioned blockchain platforms\nsuch as HyperLedger Fabric. They suggested implementing this framework on other prominent\nplatforms, such as Ethereum, and with more advanced scalability solutions such as blockchain\nsharding [34\u201336] and cross-chain designs [37], necessitates additional testing. Another highlighted\nrespondent noted that while the integration with ServiceNow is commendable, there\u2019s a need to\nfurther test its compatibility with services and functionalities o\ufb00ered by Platform as a Service\n(PaaS) or Infrastructure as a Service (IaaS) platforms, such as AWS and Azure. Notably, these rep-\nresentative insights align with the general sentiment expressed in the 58 valid responses we re-\nceived.\n5\nLIMITATIONS AND VALIDITY\nWe apply the guidelines [38] to discuss key threats to the validity (construct, internal, external)\nof this work.\nConstruct validity re\ufb02ects what extent the research questions and methodology are appropri-\nately used in a study. A threat in Stage 3 (i.e., the surveys) is whether or not our surveyees are\nrepresentative. To reduce this threat, we invited 1,000 practitioners who come from the company,\nuniversities, and VC members who are applying for our Web3 implementation. In addition, the\nareas that the participants have worked on cover a wide range of domains (e.g., blockchain and AI\napplications). However, they may not be representative of all practitioners, and not all the intended\nsurveyees are expected to respond in time. To mitigate this potential bias, we have carefully cho-\nsen questions and topics. Our survey respondents completed the surveys based on their opinions\nand perceptions. It is possible that they con\ufb02ate the skills that are very important and the skills\nthat are very relevant to their projects or industrial contexts.\nInternal validity focuses on factors that may in\ufb02uence the validity of the results. The main\nthreat in our study is whether the study process we designed and the Web3 framework and appli-\ncation that we proposed can answer our research questions. It is also possible that we draw the\nwrong conclusions about respondents\u2019 perceptions from their comments. To minimize this threat,\n16\nwe read transcripts many times and checked the survey results and the corresponding comments\nseveral times.\nThe selection of statements produced at the end of the surveys may not be comprehensive and\nmay be biased to the background of experts\u2014who may not be able to articulate their own opinions.\nTo mitigate this bias, we have taken the following steps:\n\u2022 Aside from asking direct questions about their opinions about Web3 and applications that we\ndesigned and implemented, we also asked them to discuss general topics that they had not\nexplicitly mentioned. The topics were selected from Web3 textbooks and online resources;\nthey include concepts, comprehension, programming language, requirements, design imple-\nmentation, testing, and tool usage.\n\u2022 Three authors have performed data analysis to cross-check their answers by using card sort-\ning [39], and we carefully examined and only included relevant statements.\nExternal validity concerns the generality of our study results to other settings. Our results\nand summaries are based on the Web3 framework and application and survey participants\u2019 opin-\nions instead of a rigorous analysis of participants\u2019 claims. It is possible that opinions regarding\nthe Web3 framework and application di\ufb00er from one participant to another. To improve the gen-\neralizability of our results, we invited 1,000 practitioners and obtained 58 respondents. Still, our\n\ufb01ndings may not generalize or represent the perception of all software engineers. For example, the\nrespondents are from one company and VCs that are interested in Web3 technologies and closed\nuniversities. It can be noticed in Fig. 5(b) that a sentiment bias in certain categories. The frame-\nwork was initially designed for BT Company, leading to skewed positive feedback. A similar bias\nexists in the Universities category, potentially due to some participants being a\ufb03liated with the\nauthors\u2019 institution. In contrast, feedback from VCs and other developers, sourced from GitHub\nand mailing lists, appears more balanced and free from con\ufb02icts of interest. It would be interesting\nto perform another study to investigate more software engineers to perceive the future bene\ufb01ts\nand limitations of the Web3 framework and application.\nPlatform validity refers to the extent to which the proposed framework can be universally ap-\nplied across multiple blockchain platforms. While our design principle for the blockchain layer is\ninherently blockchain-agnostic, our case study predominantly used Hyperledger for illustration.\nThis choice was primarily to demonstrate the capabilities of our framework in a clear and spe-\nci\ufb01c manner. However, it is essential to stress that the architecture and design of our framework,\nWebttCom, do not restrict its applicability. The core principles and mechanisms of WebttCom\ncan be e\ufb00ectively translated to other blockchain platforms with the necessary con\ufb01guration ad-\njustments. The foundation remains consistent, versatile, and designed for broad adaptability.\nTo elucidate further on the adaptability of WebttCom with other platforms such as Ethereum:\nThe crux of our framework lies in its modular design. The blockchain layer, which is designed\nto be blockchain-agnostic, can interface with Ethereum\u2019s smart contract system just as it does\nwith Hyperledger. Ethereum, with its robust smart contract capabilities, can e\ufb00ectively replace\nthe smart contract for data provisioning and the modules for write, update, and read controls\npresent in our framework. Furthermore, Ethereum\u2019s dynamic storage system can be leveraged\nto handle service data storage in our blockchain layer, substituting for private and public data\nrepositories. The backend interpreter, which serves as the bridge between Web2 and Web3, remains\nconsistent. Its Web2-Web3 transition module can be con\ufb01gured to forward requests to Ethereum\u2019s\nsmart contracts, ensuring seamless communication. Similarly, user management for Web2 and\nWeb3 users in the backend would work harmoniously with Ethereum, ensuring an integrated user\nexperience.\n17\n6\nRELATED WORK\nIn this section, we give a quick overview of the notion of Web3 and then introduce ways of\nbuilding DApps on top of blockchains.\nNotion of Web3. The concept of Web3 was \ufb01rst proposed by Wood [40] with an initial discus-\nsion focusing on blockchain-based digital infrastructure. Later, Weyl et al. [1] illustrate the ways\nof building a decentralized society by exploring Web3-related applications, requirements, oppor-\ntunities, and challenges. Wang et al. [3] provide the discussion between Web3 and blockchain\nfrom the perspective of architecture design. The work has identi\ufb01ed a total of 12 types of de-\nsigns according to the data work\ufb02ow of access, computation, and storage. A series of reports from\nConsensys [41] investigates the economic performances created by decentralized networks. Web3\neconomy covers many on-chain DeFi protocols [14] such as stablecoins, borrowing, lending, and\nleverage, distributed governance protocols (e.g., DAO) [42][43] and many innovations combined\nwith other technologies [44, 45]. These protocols are built on top of smart contracts. Liu et al. [46]\nexplore three types of infrastructural enablers, including the single smart-contract powered chain,\nfederated contracts, and interoperable blockchain platforms. However, Web3 sofar still confronts\nhigh-level controversies in terms of its de\ufb01nition and application. We, in this paper, extend our ex-\nploration by complying with its core decentralization nature guaranteed by underlying blockchain\nservices.\nConstructing Web3 Applications. Traditional Web1 and Web2 applications rely on centralized\nbackend servers for computations and storage. Web3 applications [3] replace these servers with\ndecentralized blockchain platforms [6][47]. Building a Web3 application requires three phases: (i)\nembedding the wallet for access, (ii) connecting frontend with blockchain platforms, and (iii) operating\nexecutions on-chain. A wallet [20][21] is backed by locally running lightweight nodes and helps\nWeb3 users to create on-chain accounts (in the form of address [12]) as their identities. A user\ncan initiate a request by sending a transaction from wallets to the transaction pool. Smoothly pro-\ncessing the received requests from the front end requires a suite of standard protocols, including\ntoken standards (e.g., EIP [48], BEP [49] or even BRC [50]) and uni\ufb01ed APIs. All the compiled byte-\ncodes will be executed on-chain by iterative state transitions. The consensus mechanism is critical\nin maintaining state consistency and chain stability [51]. In some cases, external techniques are\nneeded for supportive functionalities such as distributed storage [52], layer-two computations [53],\ncross-chain bridges [54][55] or on-chain oracles [56]. Our work achieves more than building a sim-\nple DApp that is independent of operating blockchains. We, instead, develop a general interpreter\nto connect Web2 applications to the current leading Web3 platforms from the access layer to the\nchain layer. This gives an educational study for the community.\n7\nCONCLUSION\nIn this paper, we gave a research question by exploring the connotation of Web3 and the key dif-\nferences between Web2 and Web3 applications. We proposed a new framework, named WebttCom,\nto enable a seamless transition from Web2 to Web3. In particular, WebttCom can smoothly con-\nnect traditional Web2 applications to mainstream Web3 blockchain platforms while additionally\nensuring high data privacy and governance, and improving development productivity. Our de-\nsign innovative introduces an interpreter mechanism that can aggregate and deal with requests\nbetween Web2 and Web3 spaces. Accordingly, we implemented a full-stack system consisting of\nover 11,351 lines of code, conducted a performance evaluation, and launched a survey to assess the\ne\ufb00ectiveness of our framework. Corresponding surveys with experienced participants con\ufb01rmed\nWebttCom satis\ufb01es our research question with a few possible limitations of the framework and its\n18\nrelated business cases. We further provide our recommended improvements, including the exten-\nsion of the framework to involve more blockchain platforms and search for more business cases.\nREFERENCES\n[1] E Glen Weyl, Puja Ohlhaver, and Vitalik Buterin. Decentralized society: Finding web3\u2019s soul. Available at SSRN\n4105763, 2022.\n[2] Xu Wang, Xuan Zha, Wei Ni, Ren Ping Liu, et al. Survey on blockchain for internet of things. Computer Communica-\ntions, 136:10\u201329, 2019.\n[3] Qin Wang, Rujia Li, Qi Wang, Shiping Chen, et al. Exploring web3 from the view of blockchain. arXiv preprint\narXiv:2206.08821, 2022.\n[4] Guangsheng Yu, Xuan Zha, Xu Wang, Wei Ni, Kan Yu, Ping Yu, J. Andrew Zhang, Ren Ping Liu, and Y. Jay Guo. En-\nabling attribute revocation for \ufb01ne-grained access control in blockchain-iot systems. IEEE Transactions on Engineering\nManagement, 67(4):1213\u20131230, 2020.\n[5] Guangsheng Yu, Litianyi Zhang, Xu Wang, Kan Yu, Wei Ni, J. Andrew Zhang, and Ren Ping Liu. A novel dual-\nblockchained structure for contract-theoretic lora-based information systems. Information Processing & Management,\n58(3):102492, 2021.\n[6] Gavin Wood et al. Ethereum: A secure decentralised generalised transaction ledger. Ethereum project yellow paper,\n151(2014):1\u201332, 2014.\n[7] Yue Liu, Qinghua Lu, Guangsheng Yu, Hye-Young Paik, and Liming Zhu. A pattern-oriented reference architecture\nfor governance-driven blockchain systems. In IEEE International Conference on Software Architecture (ICSA), pages\n23\u201334, 2023.\n[8] Yue Liu, Qinghua Lu, Guangsheng Yu, Hye-Young Paik, Harsha Perera, and Liming Zhu. A pattern language for\nblockchain governance. In Proceedings of the 27th European Conference on Pattern Languages of Programs, EuroPLop\n\u201922, New York, NY, USA, 2023. Association for Computing Machinery.\n[9] Yue Liu, Qinghua Lu, Guangsheng Yu, Hye-Young Paik, and Liming Zhu. De\ufb01ning blockchain governance principles:\nA comprehensive framework. Information Systems, 109:102090, 2022.\n[10] Yue Liu, Qinghua Lu, Guangsheng Yu, Hye-Young Paik, and Liming Zhu. Bgra: A reference architecture for blockchain\ngovernance, 2022.\n[11] Xu Wang, Wei Ni, Xuan Zha, Guangsheng Yu, et al. Capacity analysis of public blockchain. Computer Communications,\n177:112\u2013124, 2021.\n[12] Joseph Bonneau, Andrew Miller, Jeremy Clark, Arvind Narayanan, Joshua A Kroll, and Edward W Felten. SoK: Re-\nsearch perspectives and challenges for bitcoin and cryptocurrencies. In 2015 IEEE Symposium on Security and Privacy\n(SP), pages 104\u2013121. IEEE, 2015.\n[13] Sam M Werner, Daniel Perez, Lewis Gudgeon, Ariah Klages-Mundt, Dominik Harz, and William J Knottenbelt. SoK:\nDecentralized \ufb01nance (DeFi). ACM Advances in Financial Technologies (AFT), 2022.\n[14] Erya Jiang et al. Decentralized \ufb01nance (DeFi): A survey. arXiv preprint arXiv:2308.05282, 2023.\n[15] Rujia Li et al. How do smart contracts bene\ufb01t security protocols? arXiv preprint arXiv:2202.08699, 2022.\n[16] Aggelos Kiayias and Philip Lazos. SoK: Blockchain governance. ACM Advances in Financial Technologies (AFT), 2022.\n[17] Bhabendu Kumar Mohanta, Debasish Jena, Soumyashree S Panda, and Srichandan Sobhanayak. Blockchain technol-\nogy: A survey on applications and security privacy challenges. Internet of Things, 8:100107, 2019.\n[18] Sin Kit Lo, Yue Liu, Guangsheng Yu, Qinghua Lu, Xiwei Xu, and Liming Zhu. Distributed Trust Through the Lens of\nSoftware Architecture. arXiv e-prints, May 2023.\n[19] Qin Wang, Rujia Li, Qi Wang, and Shiping Chen. Non-fungible token (NFT): Overview, evaluation, opportunities and\nchallenges. arXiv preprint arXiv:2105.07447, 2021.\n[20] Panagiotis Chatzigiannis, Foteini Baldimtsi, and Konstantinos Chalkias. SoK: Blockchain light clients. In Ittay Eyal and\nJuan Garay, editors, Financial Cryptography and Data Security (FC), pages 615\u2013641, Cham, 2022. Springer International\nPublishing.\n[21] Kostis Karantias. SoK: A taxonomy of cryptocurrency wallets. Cryptology ePrint Archive, 2020.\n[22] Xu Wang, Guangsheng Yu, Xuan Zha, Wei Ni, Ren Ping Liu, Y. Jay Guo, Kangfeng Zheng, and Xinxin Niu. Capacity\nof blockchain based internet-of-things: Testbed and analysis. Internet of Things, 8:100109, 2019.\n[23] Xu Wang, Ping Yu, Guangsheng Yu, Xuan Zha, Wei Ni, Ren Ping Liu, and Y. Jay Guo. A high-performance hybrid\nblockchain system for traceable iot applications. In Joseph K. Liu and Xinyi Huang, editors, Network and System\nSecurity, pages 721\u2013728, Cham, 2019. Springer International Publishing.\n[24] Xu Wang, Guangsheng Yu, Ren Ping Liu, Jian Zhang, Qiang Wu, Steven W. Su, Ying He, Zongjian Zhang, Litao Yu,\nTaoping Liu, Wentian Zhang, Peter Loneragan, Eryk Dutkiewicz, Erik Poole, and Nick Paton. Blockchain-enabled \ufb01sh\nprovenance and quality tracking system. IEEE Internet of Things Journal, 9(11):8130\u20138142, 2022.\n19\n[25] Steve Easterbrook, Janice Singer, et al. Selecting empirical methods for software engineering research. In Guide to\nadvanced empirical software engineering, pages 285\u2013311. Springer, 2008.\n[26] Servicenow. https://www.servicenow.com/.\n[27] Elli Androulaki, Artem Barger, et al. Hyperledger fabric: a distributed operating system for permissioned blockchains.\nIn Proceedings of the Thirteenth EuroSys Conference (EuroSys), pages 1\u201315, 2018.\n[28] OpenAPI. The openapi speci\ufb01cation. https://github.com/OAI/OpenAPI-Speci\ufb01cation, 2022.\n[29] Hyperledger Fabric. Private Data. https://hyperledger-fabric.readthedocs.io/en/release-2.2/private-data/private-data.html?highligh\n2022.\n[30] SmartBear.\nBearer Authentication.\nhttps://swagger.io/docs/specification/authentication/bearer-authentication/,\n2022.\n[31] Hyperledger Fabric. Hyperledger Fabric SDK for node.js. https://hyperledger.github.io/fabric-sdk-node/release-1.4/index.html,\n2022.\n[32] Lukeautry. Openapi-compliant rest apis using typescript and node. https://github.com/lukeautry/tsoa, 2022.\n[33] Xiwei Xu, H.M.N. Dilum Bandara, Qinghua Lu, Ingo Weber, Len Bass, and Liming Zhu. A decision model for choosing\npatterns in blockchain-based applications. In 2021 IEEE 18th International Conference on Software Architecture (ICSA),\npages 47\u201357, 2021.\n[34] Guangsheng Yu, Xu Wang, Kan Yu, Wei Ni, J. Andrew Zhang, and Ren Ping Liu. Survey: Sharding in blockchains.\nIEEE Access, 8:14155\u201314181, 2020.\n[35] Guangsheng Yu, Xu Wang, Kan Yu, Wei Ni, J. Andrew Zhang, and Ren Ping Liu. Scaling-out blockchains with sharding:\nan extensive survey. In Blockchains for Network Security: Principles, technologies and applications, Computing, pages\n225\u2013270. Institution of Engineering and Technology, 2020.\n[36] Zixu Zhang, Xu Wang, Guangsheng Yu, Wei Ni, Ren Ping Liu, Nektarios Georgalas, and Andrew Reeves. A community\ndetection-based blockchain sharding scheme. In Shiping Chen, Rudrapatna K. Shyamasundar, and Liang-Jie Zhang,\neditors, Blockchain \u2013 ICBC 2022, pages 78\u201391, Cham, 2022. Springer Nature Switzerland.\n[37] Guangsheng Yu, Xu Wang, and Ren Ping Liu. Cross-chain between a parent chain and multiple side chains, 2022.\n[38] Claes Wohlin, Per Runeson, et al. Experimentation in software engineering. Springer Science & Business Media, 2012.\n[39] Sally Fincher and Josh Tenenberg. Making sense of card sorting data. Expert Systems, 22(3):89\u201393, 2005.\n[40] Gavin Wood. Why we need web 3.0. https://gavofyork.medium.com/why-we-need-web-3-0-5da4f 2bf95ab, 2021.\n[41] Consensys. Web3 report q3. https://consensys.net/reports/web3-report-q3-2021/ , 2021.\n[42] Guangsheng Yu et al. Leveraging architectural approaches in web3 applications-a dao perspective focused. In IEEE\nInternational Conference on Blockchain and Cryptocurrency (ICBC), pages 1\u20136. IEEE, 2023.\n[43] Qin Wang, Guangsheng Yu, Yilin Sai, Caijun Sun, Lam Duc Nguyen, Sherry Xu, and Shiping Chen. An empirical\nstudy on snapshot daos. arXiv preprint arXiv:2211.15993, 2022.\n[44] Guangsheng Yu et al. Predicting nft classi\ufb01cation with gnn: A recommender system for web3 assets. In IEEE Interna-\ntional Conference on Blockchain and Cryptocurrency (ICBC), pages 1\u20135. IEEE, 2023.\n[45] Qin Wang, Guangsheng Yu, Shange Fu, Shiping Chen, Jiangshan Yu, and Xiwei Xu. A referable nft scheme. In 2023\nIEEE International Conference on Blockchain and Cryptocurrency (ICBC), pages 1\u20136. IEEE, 2023.\n[46] Zhuotao Liu, Yangxi Xiang, et al. Make web3. 0 connected. IEEE Transactions on Dependable and Secure Computing,\n2021.\n[47] Binance smart chain. Accessible at https://www.bnbchain.org/en/smartChain, 2022.\n[48] Ethereum improvement proposals. Accessible at https://eips.ethereum.org/, 2022.\n[49] Instance: Bep-20. Accessible at https://academy.binance.com/en/glossary/bep-20, 2022.\n[50] Qin Wang and Guangsheng Yu. Understanding brc-20: Hope or hype.\nhttps://hal.science/hal-04216335/document,\n2023.\n[51] Juan Garay, Aggelos Kiayias, and Nikos Leonardos. The Bitcoin backbone protocol: Analysis and applications. In\nAnnual International Conference on the Theory and Applications of Cryptographic Techniques (EUROCRYPT), pages\n281\u2013310. Springer, 2015.\n[52] Juan Benet. Ipfs-content addressed, versioned, p2p \ufb01le system. arXiv preprint arXiv:1407.3561, 2014.\n[53] Lewis Gudgeon, Pedro Moreno-Sanchez, Stefanie Roos, Patrick McCorry, and Arthur Gervais.\nSoK: Layer-two\nblockchain protocols. In International Conference on Financial Cryptography and Data Security (FC), pages 201\u2013226.\nSpringer, 2020.\n[54] Alexei Zamyatin et al. SoK: Communication across distributed ledgers. In International Conference on Financial\nCryptography and Data Security (FC), pages 3\u201336. Springer, 2021.\n[55] Gang Wang et al. Exploring blockchains interoperability: A systematic survey. ACM Computing Surveys, 2023.\n[56] Lorenz Breidenbach, Christian Cachin, et al. Chainlink 2.0: Next steps in the evolution of decentralized oracle net-\nworks. Chainlink Labs, accessible at https://naorib.ir/white-paper/chinlink-whitepaper.pdf , 2021.\n20\nAPPENDIX\nAPPENDIX-A\nThe entrance of the implemented service management contract is shown in Listing 1. The ser-\nvice management contract extends the Hyperledger Fabric Contract class. Users can invoke the\nfunctions by sending transactions containing the function names and parameters. Users can create,\nupdate, and readWithFilter objects saved on the Hyperledger Fabric. Functions are implemented\nin controller \ufb01les.\n1 import { Context, Contract, Info, Returns, Transaction } from 'fabric-contract-api';\n2 import { Controller } from 'web3-controller';\n3\n4 export class ServiceContract extends Contract {\n5\n@Transaction(true)\n6\n@Returns('string')\n7\npublic async create(ctx: Context, attributes: string, publicPayload:string): Promise<string> {\n8\nreturn await new Controller(<'policy'|'object'|'user'>).createRegistry(ctx, ctx.stub.getTxID(),\nattributes, publicPayload);\n9\n}\n10\n@Transaction(true)\n11\n@Returns('string')\n12\npublic async update(ctx: Context, dataId: string, attributes: string, publicPayload:string): Promise<\nstring> {\n13\nreturn await new Controller(<'policy'|'object'|'user'>).updateRegistry(ctx, dataId, attributes,\npublicPayload);\n14\n}\n15\n@Transaction(false)\n16\n@Returns('string')\n17\npublic async readWithFilter(ctx: Context, publicPayload:string): Promise<string> {\n18\nreturn await new Controller(<'policy'|'object'|'user'>).readRegistryWithFilter(ctx, publicPayload\n);\n19\n}\n20 }\nListing 1. Entry Point of the Ticket Management Contract.\nThe read and update policy checking is shown in Listing 2. The function checks all policies\nlinked to the corresponding objects, which are given by the parameter policyIDs. The function\nfetches the policies with the policyIDs, checks user, location, validTime, updateTime, and priority,\nand returns the e\ufb00ective policy.\n1\npublic async getActiveReadAndUpdatePolicy(ctx: Context, location: string, policyIDs: string[]):\nPromise<any> {\n2\nlet effectivePolicy: any = {};\n3\nlet user = lla.getUserInfo(ctx);\n4\nlet ts = ctx.stub.getTxTimestamp().getSeconds() * 1000;\n5\nlet latestTimestamp = 0;\n6\nlet highestPriority = 0;\n7\nfor (let policyID of policyIDs){\n8\nlet policyObj: any = await new pc.policy().loadPolicyFromID(ctx, policyID);\n9\nlet updateTime = await lla.getLastUpdateTime(ctx,policyID);\n10\nlet permittedUser = new userInfo(policyObj.privilege.rowPolicy.userAffiliation)\n11\nif (user.match(permittedUser)) {\n12\nif (location == policyObj.privilege.rowPolicy.location.countryName) {\n13\nlet startStamp = new Date(policyObj.validFor.startDateTime).valueOf();\n14\nlet endStamp = new Date(policyObj.validFor.endDateTime).valueOf();\n15\nif (ts >= startStamp && ts <= endStamp) {\n16\nif (policyObj.priority > highestPriority) {\n17\neffectivePolicy = policyObj;\n18\nlatestTimestamp=updateTime;\n19\nhighestPriority=policyObj.priority;\n20\n}\n21\nif (policyObj.priority == highestPriority) {\n22\nif (updateTime > latestTimestamp) {\n23\neffectivePolicy = policyObj;\n24\nlatestTimestamp=updateTime;\n25\n}}}}}}\n21\n26\nreturn effectivePolicy;\n27\n}\nListing 2. Read and Update Policy Checking Function.\nThe Web2-Web3 interpreter is shown in Listing 3. When receiving a Web2 request, the inter-\npreter creates a Hyperledger Fabric connection, including the connection pro\ufb01le, Fabric user, chan-\nnel name, and contract name, according to the payload of the Web2 request. The interpreter then\nforwards the Web2 request and parameters to the corresponding functions in the Web3 contract.\nWhen receiving Web3 results, the interpreter returns them to the Web2 request.\n1\nexport async function Trans(\n2\n_fabric: ITransient, context?: Required<Pick<IUserManagement, \"userID\" | \"userPWD\">>, fnc: string,\n...args: string[]\n3\n): Promise<string> {\n4\nlet promise: Promise<string> = new Promise(async (resolve, reject) => {\n5\ntry {\n6\nconst fabricConCof: FabricConfiguration = new FabricConfiguration(\n7\n_fabric.connection,\n/* The Fabric connection profile */\n8\n_fabric.walletPath,\n/* The path to Web3 credentials */\n9\n_fabric.walletID,\n/* The Web3 user */\n10\n_fabric.channelName,\n/* The Fabric channel name\n*/\n11\n_fabric.scName,\n/* The smart contract name */\n12\n_fabric.listen\n/* Fabric event listener*/\n13\n);\n14\nconst [gateway, connectionProfile, connectionOptions] = await getFabricConfig(context, _fabric)\n;\n15\nawait gateway.connect(connectionProfile, connectionOptions);\n16\nlet network = gateway.getNetwork(fabricConCof.channelName);\n17\nlet contract = (await network).getContract(fabricConCof.scName);\n18\nconst channel = (await network).getChannel();\n19\nlet result: Buffer | any;\n20\nresult = await contract.submitTransaction(fnc, ...args);\n21\nawait gateway.disconnect();\n22\nif (result) { resolve(result.toString()); }\n23\nelse { resolve(\"Invoking ${fnc} succeeds.\"); }\n24\n} catch (error) { reject(error); }\n25\n});\n26\nreturn promise;\n27\n}\nListing 3. Web2-Web3 Interpreter.\nAPPENDIX-B\nIn the pursuit of gathering comprehensive insights on the topic, we reached out to a diverse\ngroup encompassing 1,000 individuals and institutions through various channels including GitHub,\nmailing lists, corporations, and academic universities. Despite this extensive outreach, we received\na total of 58 valid responses by the stipulated deadline. While the response rate might appear\nlimited given the vast initial pool, it\u2019s imperative to underscore the rigor and validity of the data\ncollected. Every response underwent meticulous validation to ensure its relevance and accuracy.\nOut of these valid contributions, \ufb01ve responses were handpicked to be showcased in this appendix\ndue to their exemplary representativeness of the collective sentiments and insights. These \ufb01ve\nchosen responses stand as testament to the varied perspectives and depth of knowledge within\nour respondent pool, further bolstering the credibility of our methodologies and the consequent\n\ufb01ndings.\n22\nFirst response\n1. What is your job in the organization? Technical or non-technical?\nI am a software developer in my organization.\n2. What is your Web3 background?\nI have 4-year developing experience on Web3 (expert)\n3. What do you think of the pros and cons of Web2 and Web3 at present?\nWeb2:\nPros: mature, design patterns, tools, and work\ufb02ows have been thoroughly explored and\ndeveloped, and have been proven applicable for many huge and complicated tasks.\nCons: heavily relies on trustworthy centralized entities. Building trust among parties heav-\nily relies on social engineering, which often causes interests dispute.\nWeb3:\nPros: achieve trustworthy relationships among parties without centralized entities in a\ndecentralized manner.\nCons: immature, lacks design patterns, tools, and work\ufb02ows. Popularity is not as good as\nWeb2.\n4. What do you think of the necessity of a smooth transition between Web2 and\nWeb3 from your organization and your personal perspectives? Web2 to Web3 and\nWeb3 to Web2?\nIt is of importance to have a smooth transition between Web2 and Web3.\nWeb2 project sometimes not only needs to focus on the trust issue but also needs to have\nan e\ufb03cient incentive mechanism to encourage the public to use the services. And Web3\n\ufb01ts the requirement by applying decentralized ledger technology.\nMany Web3 applications have proven their potential in many areas including \ufb01nance,\nasset trading, gaming, law... However, Web3 is still new to the market and needs to\nincrease its popularity by collaborating with those giant companies and their mature\nproducts.\n5. What possible challenges during the transition do you think are required to be\nresolved?\n(1) Web3 is transparent, and how to apply \ufb02exible and feasible access control becomes\nimportant for cases where data privacy is considered.\n(2) Approach to applying user management in a shared ledger may be a challenge be-\ncause in Web2 parties tend to have separate user management systems local.\n(3) How to connect with existing mature products, such as SaaS, may be a challenge.\n(4) Easing the transition by using automated tools is normal in Web2 applications and\nis also essential during the transition between Web2 and Web3. Having such tools\nthat can also be seamlessly integrated into existing Web2 and Web3 frameworks\n23\nmay be a challenge.\n6. To what extent the Service Management System developed by UTS and BT UK\nmatches the framework and solve the questions?\na. Access control\nSatis\ufb01ed, the data-driven policy is smart.\nb. User management\nSatis\ufb01ed\nc. Connection with SaaS\nSatis\ufb01ed with the combination with ServiceNow which has been widely used in many\nexisting products.\nd. Automated development tools\nTSOA is an interesting tool as Typescript is very popular and the OpenAPI standard has\nalmost been a must-use tool during the current work\ufb02ow in Web2 development.\n7. What are your suggestions to enhance the suitability of the new framework\nWebttCom and its implementation?\nThe framework appears to be covering most perspectives including access control,\ndata privacy, data provenance, user management, connections to existing SaaS, and\ndevelopment productivity. And the implementation also shows a good match to the\nframework. One point that could be improved is the extension of Web3 platforms where\nother platforms can be involved other than HyperLedger. Then any possible changes to\nthe implementation to match the framework should be considered.\nSecond response\n1. What is your job in the organization? Technical or non-technical?\nI am a researcher and software developer in my organization.\n2. What is your Web3 background?\nI have 4-year research and development experience on Web3.\n3. What do you think of the pros and cons of Web2 and Web3 at present?\nWeb2:\nPros: Web2 technology has been developed for decades. There are many mature solutions\nfor various requirements and development tools for rapid development and simple man-\nagement. Consumers have been well educated on the Web2 service pattern.\nCons: The biggest challenge of Web2 systems is the trust issue. For a single Web2 service,\nconsumers have to trust Web2 service providers, and the service providers need to trust\ndevelopers, infrastructure providers, etc. When multiple Web2 systems are connecting to\n24\neach other, they need to trust the services and data from others. In the case of untrusted\nrelations or inconsistent data, it is challenging to solve disputes and provide services as a\nwhole.\nWeb3:\nPros: Web3 can provide single ground truth to all participants in a trustless way. Di\ufb00erent\nparties do not have to build trust with each other.\nCons: Web3 is a new technology. The architecture and process of Web3 services are\nvery di\ufb00erent from those of Web2. Deploying and maintaining Web3 infrastructure and\napplications could be very time-consuming and risky. Consumers need to be educated\nabout changes from Web3.\n4. What do you think of the necessity of a smooth transition between Web2 and\nWeb3 from your organization and your personal perspectives? Web2 to Web3 and\nWeb3 to Web2?\nWe are aware of the bene\ufb01t of Web3 and have plan to employ Web3 technology in our\nbusiness to provide trusted services and reduce business loss.\nA transition from Web2 to Web3 will bring the data trustworthiness and cybersecurity\nguarantee from Web3 to Web2 systems. The Web3 token mechanism can support incentive\nschemes in Web2 applications.\nThe smooth transition from Web3 to Web2 applications will promote Web3 technology\nand applications. There have been many Web3 applications, like tokens and contracts.\nHowever, Web3 applications are only popular among the Web3 community because the\nrequirements and access to Web3 applications are very di\ufb00erent from widely-used Web2\napplications and can be hard for general users. A Web3 to Web2 transition will simplify\naccess and encourage more users to try Web3 technology and applications.\n5. What possible challenges during the transition do you think are required to be\nresolved?\n1) How to seamlessly integrate Web3 services into existing Web2 systems\n2) How to implement data governance and privacy policies in Web3\n3) How to manage Web2 and Web3 user identities simultaneously\n4) How to reduce integration and development cost\n5) How to e\ufb03ciently manage Web3 infrastructure\n6) Can Web3 technology support large-scale applications\n6. To what extent the Service Management System developed by UTS and BT UK\nmatches the framework and solve the questions?\na. Access control\nSatis\ufb01ed. The system can enforce all the expected data governance and access control poli-\ncies.\nb. User management\nSatis\ufb01ed. A user can use one identity to access Web2 and Web3 services.\nc. Connection with SaaS\n25\nSatis\ufb01ed. Users can access Web3-certi\ufb01ed data services from the SaaS. The complicated\nWeb3 details are transparent to users.\nd. Automated development tools\nSatis\ufb01ed. The automatic document generation technology can save 20\n7. What are your suggestions to enhance the suitability of the new framework\nWebttCom and its implementation?\nThe developed WebttCom is a good start for transiting Web2 to Web3. I suggest the team\ndevelop more service functions to the framework, such as managing ticket \ufb01les across\nmultiple departments and organizations, such that the system usability could be improved.\nThe framework can also be integrated with other Web2 businesses, such as work\ufb02ow man-\nagement. Besides new functions, comprehensive trials need to be conducted to verify the\nstability and capacity.\nThird response\nHence, there are two options for the paper: 1) The survey section could provide an aggre-\ngated view from the project team\u2019s view on how well the prototype addresses the needs\nof Web3, without attributing views to individual organizations. Or 2) On the BT side we\ncould write a section for the evaluation part of the paper.\nTo give you a \ufb02avor of what a BT-authored section would look like: It would explain that\nWeb3 is not well de\ufb01ned at the moment and is currently often linked to ideological aims\naround openness and decentralization, compared to the current internet which is seen, by\nthe Web3 community, as dominated by \u201cbig tech\u201d. The Web3 concept is a very nascent area\nat the moment where it will be interesting to see how it evolves and \ufb01ts with the current\nWeb2 world in which we live.\nWeb3 needs to answer a number of core questions related to complexity, scalability cost;\nand, critically, also cost-e\ufb00ectiveness and accountability, which are often more important\nto commercial organizations than adherence to decentralization principles. However, the\nlack of well-formed answers to these high-level generic considerations should not prevent\nus from identifying use cases and prototyping solutions to further our knowledge of the\nopportunities.\nLooking at the Web3 technology portfolio it already includes some useful enabling tech-\nnologies, including distributed ledger technologies (DLTs) which, with their inherently\ndecentralized architecture, can be useful for speci\ufb01c applications. On their own they are\nunlikely to form the universal technology base for the next generation of the Internet;\nhowever, there are real use cases that exist today where DLTs may have an important role\nto play. The work with UTS is an example of this and examines a real-world use case re-\nlated to IT service management across di\ufb00erent country boundaries where di\ufb00erent data\nprivacy regulations apply.\nIn this context, DLTs are a promising solution due to the ability of smart contracts to\nensure that the required country-speci\ufb01c data management policies are agreed upon and\nenforced. For the current prototyping project, it was assumed that the transition to a DLT-\nbased solution will require interworking with the more traditionally architected solutions\nwhich are already in common usage in commercial ecosystems. In evaluating the solution\n26\nwe have demonstrated that a DLT Hyperledger layer can meet the required success criteria\nrelated to cross-country access control and user management; as well as, connecting to a\ntraditional SaaS work\ufb02ow management layer.\nIn meeting these criteria the prototype has demonstrated su\ufb03cient promise that we are\nexamining the next stage in research and development, which is to run test scenarios, uti-\nlizing realistic commercial data \ufb02ows, through the prototype. This measured exploration\nand transition to DLT technologies show the path which we believe many established com-\nmercial organizations will follow as they gain con\ufb01dence that the decentralized approach\ncan meet the required business requirements. The approach of monitoring the evolving\nWeb3 concepts, and engaging with the core technology developments, to experiment and\nbuild early insight on use cases for these emerging capabilities (e.g. DLT, smart contracts)\nis a pragmatic approach for ensuring that value can be gained.\nFourth response\n1. What is your job in the organization? Technical or non-technical?\nI am a software developer in my organization. Technical.\n2. What is your Web3 background?\nI have a half year of Web3 background. My Web3 knowledge is limited.\n3. What do you think of the pros and cons of Web2 and Web3 at present?\nWeb2:\nPros: Web2 has a large development community including programmers, tools, and solu-\ntions. Web2 has been widely applied to many organizations and it has been veri\ufb01ed as a\nstable technology.\nCons: In the case of multiple organizations, it is not used for cross-validation and trust in\nthe scenario.\n4. What do you think of the necessity of a smooth transition between Web2 and\nWeb3 from your organization and your personal perspectives? Web2 to Web3 and\nWeb3 to Web2?\nSince most systems are based on Web2, we must focus on the transition from Web2 to\nWeb3.\nThe modi\ufb01cation of the existing Web2 system should not be di\ufb03cult.\nIn order to avoid overloading the programmers with Web3 knowledge, they should not\nlearn too much.\nIt is also possible to apply the existing Web2 technology to Web3-based systems.\nIt is not necessary for normal users to recognize the transition.\n5. What possible challenges during the transition do you think are required to be\nresolved?\n27\n1) Because of their limited understanding of Web3, programmers are reluctant to transfer\ntheir existing Web2 systems to Web3.\n2) Due to the di\ufb00erences in concept, technology, and tools between Web2 and Web3, it is\ndi\ufb03cult to integrate the Web2 system with the Web3 system.\n6. To what extent the Service Management System developed by UTS and BT UK\nmatches the framework and solve the questions?\na. Access control\nSolved. Web3 implements access control, which means that Web2 programmers are not\nrequired to touch too much.\nb. User management\nSolved. It\u2019s similar to the above. Web3 implements access control, which means that Web2\nprogrammers are not required to touch too much.\nc. Connection with SaaS\nSolved, the modi\ufb01cation of the existing Web2 system is not too extensive. It is also possible\nto apply the existing Web2 development method and architecture to the transition.\nd. Automated development tools\nSolved, automated development tools signi\ufb01cantly reduce the programmers\u2019 workload.\n7. What are your suggestions to enhance the suitability of the new framework\nWebttCom and its implementation?\nAttempts to integrate the existing commercial Web2 system\u2019s functionality with Web3.\nMore commercial Web2 systems should be integrated with Web3.\nProvides more Web3 services.\nFifth response\n1. What is your job in the organization? Technical or non-technical?\nI am a developer, technical\n2. What is your Web3 background?\n3 years of exposure to Web3 development\n3. What do you think of the pros and cons of Web2 and Web3 at present?\nWeb2: pros \u2013 mature technology, plenty of resources available; cons \u2013 being a centralized\nsystem, trust can be an issue Web3: pros \u2013 has built-in trust mechanisms; cons \u2013 new tech,\nnot many resources for developers\n4. What do you think of the necessity of a smooth transition between Web2 and\nWeb3 from your organization and your personal perspectives? Web2 to Web3 and\nWeb3 to Web2?\n28\nCertain businesses require the trusted services provided by web3, but not all. Many\nexisting services are \ufb01ne with Web2. Only services that deal with multi-organizations\nrequire web3. Web2 and web3 should be able to coexist and interact smoothly.\n5. What possible challenges during the transition do you think are required to be\nresolved?\nChallenges include a lack of experienced developers, a lack of available development\nresources, and tools.\n6. To what extent the Service Management System developed by UTS and BT UK\nmatches the framework and solve the questions?\na. Access control\nCompleted.\nb. User management\nCompleted.\nc. Connection with SaaS\nA good start in connection with ServiceNow\nd. Automated development tools\nSome tools were developed.\n7. What are your suggestions to enhance the suitability of the new framework\nWebttCom and its implementation?\nNeed to \ufb01nd suitable business use cases to demonstrate the bene\ufb01t of web3.\n29\n",
    "2305.11911": "1\nA Unified Framework for Integrating Semantic\nCommunication and AI-Generated Content in\nMetaverse\nYijing Lin, Zhipeng Gao, Hongyang Du, Dusit Niyato, Fellow, IEEE\nJiawen Kang, Abbas Jamalipour, Fellow, IEEE, and Xuemin Sherman Shen, Fellow, IEEE\nAbstract\u2014As the Metaverse continues to grow, the need for\nefficient communication and intelligent content generation be-\ncomes increasingly important. Semantic communication focuses\non conveying meaning and understanding from user inputs, while\nAI-Generated Content utilizes artificial intelligence to create\ndigital content and experiences. Integrated Semantic Commu-\nnication and AI-Generated Content (ISGC) has attracted a lot\nof attentions recently, which transfers semantic information from\nuser inputs, generates digital content, and renders graphics for\nMetaverse. In this paper, we introduce a unified framework\nthat captures ISGC\u2019s two primary benefits: integration gain for\noptimized resource allocation and coordination gain for goal-\noriented high-quality content generation to improve immersion\nfrom both communication and content perspectives. We also\nclassify existing ISGC solutions, analyze the major components\nof ISGC, and present several use cases. We then construct a\ncase study based on the diffusion model to identify a near-\noptimal resource allocation strategy for performing semantic\nextraction, content generation, and graphic rendering in the\nMetaverse. Finally, we discuss several open research issues,\nencouraging further exploring the potential of ISGC and its\nrelated applications in the Metaverse.\nIndex Terms\u2014Metaverse, Semantic Communication, AIGC,\nResource Allocation, Diffusion\nI. INTRODUCTION\nT\nHE concept of Metaverse, originally introduced in the\nscientific novel Snow Crash, has attracted considerable\ninterest from academia and industries. Metaverse refers to\na virtual environment that seamlessly integrates with the\nphysical world, allowing for the existence of digital avatars\nto engage in various activities, interact with other users, and\naccess virtual objects and experiences. The construction of\nMetaverse is supported by all virtual reality (VR), augmented\nreality (AR), and the Internet of Things to create a compre-\nhensive and interconnected digital ecosystem.\nThis\nwork\nis\nsupported\nby\nNational\nNatural\nScience\nFoundation\nof\nChina\n(62072049).\nCorresponding\nauthor:\nZhipeng\nGao\n(e-mail:\ngaozhipeng@bupt.edu.cn). Yijing Lin and Zhipeng Gao are with the State\nKey Laboratory of Networking and Switching Technology, Beijing Univer-\nsity of Posts and Telecommunications, China (e-mail: yjlin@bupt.edu.cn;\ngaozhipeng@bupt.edu.cn). Hongyang Du and Dusit Niyato are with the\nSchool of Computer Science and Engineering, Nanyang Technological Univer-\nsity, Singapore (e-mail: hongyang001@e.ntu.edu.sg; dniyato@ntu.edu.sg). Ji-\nawen Kang is with Guangdong University of Technology, 510006, Guangzhou,\nChina (e-mail: kjwx886@163.com). Abbas Jamalipour is with The University\nof Sydney, Sydney NSW 2006, Australia (e-mail: a.jamalipour@ieee.org).\nXuemin Sherman Shen is with the Department of Electrical and Computer\nEngineering, University of Waterloo, Canada (e-mail: sshen@uwaterloo.ca).\nThe continuous advancement of technologies such as se-\nmantic communication (SemCom) and AI-Generated Content\n(AIGC) has prompted the Metaverse to increase demands\nfor efficient communication and intelligent content gener-\nation. Semantic communication refers to focusing on the\nassociated meanings rather than simply transmitting raw data\nto enable effective communication. AIGC generates digital\ncontent automatically with the assistance of AI technologies\nto improve efficiency and provide personalized and relevant\ncontent tailored to the preferences and needs of the users.\nThese technologies lead to the emergence of a new integra-\ntion technology: integrated SemCom and AIGC (ISGC) for\nimproving immersion from both communication and content\nperspectives. ISGC combines the benefits of SemCom and\nAIGC to extract autonomously relevant information from raw\ndata, enabling the generation of high-quality digital content in\nthe Metaverse without direct human intervention. Additionally,\nThere are certain difficulties that may arise without tight\nintegration between SemCom and AIGC for Metaverses:\n\u2022 Inefficient Use of Resources: Recognizing the chal-\nlenges of the collaborative execution of AIGC tasks\nacross a multitude of devices and the diverse access\nrequirements of users [1], there is a lack of integration in\nthe allocation of computing and communication resources\nfor semantic extraction, AIGC, and graphic rendering\ntasks, leading to near-optimal resource utilization and\nperformance.\n\u2022 Low-quality of Content: Without effective coordination\nbetween SemCom and AIGC, the generated content may\nnot meet the desired quality standards [2]. This can lead\nto poor user experiences and dissatisfaction, ultimately\naffecting the adoption and success of Metaverse.\nAs a consequence, ISGC has emerged as a promising\ntechnology that combines the advantages of the aforemen-\ntioned technologies. By combining AIGC and SemCom, ISGC\nenables the production of content that is not only visually\nappealing but also contextually relevant and meaningful, en-\nhancing user experiences in the Metaverse. It also ensures\nthat the right resources are allocated to the right tasks at\nthe right time through joint computing and communication\nresource optimization. Additionally, it can adapt to user pref-\nerences, contextual information, and real-time interactions. In\nsummary, ISGC can provide two main benefits over the above\nfunctionalities by obtaining the integration and coordination\narXiv:2305.11911v2  [cs.HC]  23 Jul 2023\n2\ngains [3] for optimized resource allocation and high-quality\ncontent generation.\nThis paper provides a conceptual overview and concrete use\ncases of ISGC as well as its role in the Metaverse. Specifically,\nwe present the related works and the key benefits of ISGC.\nWe propose a unified framework for ISGC that utilizes the\nadvantages of integration and coordination gains. Furthermore,\nwe provide a case study employing the diffusion model to\ndetermine the near-optimal strategy for resource allocation\nin ISGC. It is shown that the diffusion model is capable of\nhandling the effects of randomness and noise, and promoting\nexploration to enhance policy flexibility. To the best of our\nknowledge, this work is the first to comprehensively explore\nthe potential integration and coordination benefits of ISGC for\nimproving the efficiency and intelligence of the Metaverse.\nOur main contributions are summarized as follows:\n\u2022 We propose a comprehensive overview of ISGC, includ-\ning an investigation of related works, an explanation of\nwhy SemCom and AIGC integration is necessary, and the\nreasons why ISGC is needed in the Metaverse.\n\u2022 We present a unified framework for ISGC, which includes\na step-by-step workflow for capturing the integration and\ncoordination gains, as well as several potential use cases.\n\u2022 To further explore the benefits of integration gains, we\nconduct a case study that analyzes the effects of ISGC\non resource allocation. Specifically, we use the diffusion\nmodel to derive and promote near-optimal strategies for\nutilities of resource allocation.\nII. WHY INTEGRATE SEMCOM AND AIGC\nISGC is a design paradigm in which SemCom and AIGC\nare integrated to provide efficient communication and goal-\noriented content generation. A notable surge in research activ-\nities pertaining to ISGC has been observed, as shown in Fig.\n1. We collect several papers from IEEE Xplore and arXiv in\nApril 2023 and identify research trends and directions from\nFig.1 that depict the current research of ISGC.\n1) SemCom and AIGC. The integration of SemCom and\nAIGC primarily aims to leverage AIGC technologies such\nas Generative Adversarial Networks to develop semantic de-\ncoders that address the out-of-distribution problem between\ntransmitters and receivers [4]. To compute the loss function,\na variational autoencoder is employed to calculate the lower\nbound of semantic distortion, while diffusion models are\ncombined with deep reinforcement learning to determine the\nnear-optimal decisions in semantic communication [5].\n2) SemCom and Metaverse. The integration of SemCom\nand Metaverse aims to circulate meaningful information with\nfewer symbols within the Metaverse, thereby reducing com-\nmunication overheads. In order to mitigate privacy concerns\narising from this integration, federated learning is introduced\nto preserve user data privacy [6].\n3) AIGC and Metaverse. To improve the integration of\nAIGC and Metaverse, the focus is on generating high-quality\ndigital content to create immersive virtual environments and\nconstruct economic systems, such as autonomous driving sim-\nulations and customized content. Additionally, the integration\nutilizes diffusion models to efficiently manage and optimize\nnetwork and resource allocation [7].\n4) SemCom, AIGC and Metaverse. The integration of Sem-\nCom, AIGC, and Metaverse is still in its early stages and is\nprimarily focused on improving the efficiency of Metaverse\nthrough the application of SemCom and AIGC. GAN is\nutilized for the extraction of semantic information to improve\nthe transmission efficiency in Metaverse [8].\nLayers of Integration. Fig. 2 depicts the various layers in-\nvolved in the integration of ISGC. Data collected from sensors\nis extracted and transformed into semantic information such as\nimage segments or model features, which is transmitted using\nsemantic communication. AIGC inference is then applied to\ngenerate digital content from this information. The generated\ncontent is then fused through rendering graphics to create\nvirtual environments that can be used by various applications\nand users within the Metaverse ecosystem.\nResearch Trends. To identify research trends related to\nISGC, the research activities are classified into different layers\nbased on their integration, as shown in Table I. The figure\nhighlights that current research solutions predominantly focus\non addressing issues caused by individual layers, such as the\nout-of-distribution problem between the semantic encoder and\ndecoder, efficient incentive mechanism for sharing semantic\ninformation, decentralized semantic sharing, and resource al-\nlocation for tasks within the same layers. However, these\nsolutions may not fully reflect the benefits of the integration,\nand there is a need for more research efforts to explore the\npotential of ISGC as a whole.\nIII. ISGC UNIFIED FRAMEWORK\nA. Framework Overview\nISGC includes semantic, inference, and rendering modules\nto capture the benefits of the integration of SemCom, AIGC,\nand Metaverse.\n1) Semantic Module: To optimize the data processing stage\nand reduce communication overhead, data collection, data\nprocessing, and semantic extraction should be performed at the\nedge devices. The semantic module is specifically designed to\nprocess data generated by edge devices and extract semantic\ninformation from raw data simultaneously. The extracted se-\nmantic information is then transmitted to MSPs that control\nthe AIGC and render modules via edge servers.\n2) Inference Module: Semantic information is fed into\nsemantic decoder to recover useful information. Since the\nrecovered images are low-quality or incomplete, MSPs should\nutilize AIGC to generate high-quality digital content to im-\nprove user experiences. The inference module employs pre-\ntrained models to generate high-quality images with depth\nmaps from multiple angles via the latent diffusion model,\nwhich employs forward and reverse diffusion processes to add\nand remove noise from images.\n3) Rendering Module: Empowered by the above modules,\nthe render module can synthesize massive and conditioned\ninformation from real-world or imaginary scenarios to enable\nimmersive and interactive virtual environments.\n3\nSemCom\nMetaverse\nAIGC\n1\nDiffusion Model (DM)\nGenerative Adversarial Network (GAN)\nVariational Autoencoder (VAE)\nCycle GAN-based semantic communication \nsystems with task-unaware transmitter and \ndynamic data \nSemantic diffusion model \nbased on DDPMs\nTransmission Channel\nVariable-length semantic encoder\nContest theory based semantic\ntransmission\nDecentralized Economic systems\nto encourage AIGC services\nAutonomous driving simulation\nGAN based highly efficient semantic \ncommunication approach for image \ntransmission\nAugmented Reality & Virtual Reality\nBlockchain & Cryptocurrency\nAI-Generated Content\nAI & Machine Learning\nSemantic Decoder\nSemantic Encoder\nSemCom enabled by deep learning\nSemantic Communication\n3D Graphics and Animation\n1\n1\n2\n3\n5\n4\n2\n3\n4\n5\n2\n3\n4\n5\nDiffusion model for incentive design to\npromote semantic information sharing\nWireless End-to-End Image \nTransmission System using Semantic \nCommunications\nDiffusion models for wireless\nnetwork management\nSemCom for B5G networks with \ndistributed signal processing\nPrivacy and Security in AIGC\nProof of semantic-based semantic\ninformation sharing\n1\n2\n3\n4\n5\nW. Wang, et al., Semantic Image Synthesis via Diffusion Models\nH. Du, et al., Ai-generated incentive mechanism and full-duplex semantic communications for information sharing \nT. Han, et al., Generative model based highly efficient semantic communication approach for image transmission \nH. Zhang, et al., Deep learning-enabled semantic communication systems with task-unaware transmitter and dynamic data \nM. Lokumarambage, et al., Wireless End-to-End Image Transmission System using Semantic Communications\n1\n2\n3\n4\n5\nM. Xu, et al., Generative ai-empowered simulation for autonomous driving in vehicular mixed reality metaverses \nH. Huang, et al., Economic Systems in Metaverse: Basics, State of the Art, and Challenges \nY. Liu, et al., Deep Generative Model and Its Applications in Efficient Wireless Network Management: A Tutorial and Case Study \nC. Chen, et al., Challenges and Remedies to Privacy and Security in AIGC: Exploring the Potential of Privacy Computing, \nBlockchain, and Beyond\nM. Xu, et al., Unleashing the Power of Edge-Cloud Generative AI in Mobile Networks: A Survey of AIGC Services\n1\n2\n3\n4\n5\nJ. Wang, et al., Semantic-aware sensing information transmission for metaverse: A contest theoretic approach \nB. Zhang, et al., Semantic communications with variable-length coding for extended reality \nW. Xu, et al., Edge Learning for B5G Networks With Distributed Signal Processing: Semantic Communication, Edge Computing, \nand Wireless Sensing\nY. Lin, et al., A unified blockchain-semantic framework for wireless edge intelligence enabled web 3.0 \nZ. Qin, et al., Semantic Communications: Principles and Challenges\nAIGC in mobile networks\nFig. 1: A review of recent research studies and emerging trends across SemCom, AIGC, and Metaverse, inspiring a unified\nframework for integrated SemCom and AIGC in the Metaverse\nLayers\nDescriptions\nSolutions\nOpen challenges\nSemantic\nLayer\nA classifier-free guidance strategy is used to improve semantic image synthesis, which involves \ninterpolating scores with and without the semantic mask. \nA proof of semantic mechanism is used to verify authenticity and prevent spam while \ntokenizing the value of semantic information.\nTo improve transmission efficiency, a variable-length semantic encoder is used to discard \nunimportant information. \nContest theory based semantic transmission\nTraining-based targeted \nsemantic attacks and defenses.\nTask-relevant semantic \nextraction.\nInvariant semantic extraction \nacross virtual environments.\nUnified evaluation metrics.\nMulti-user cooperative \napproaches.\nVariable-length semantic encoder\nSemCom for B5G networks with distributed \nsignal processing\nProof of semantic-based semantic\ninformation sharing\nSemCom enabled by deep learning\nAIGC Layer\nAIGC is used to synthesize information, and an auction-based incentive mechanism is \ndesigned to support autonomous driving simulation.\nAn optimization algorithm has been designed to select efficient AIGC service providers who \ncan execute user tasks due to the significant resource.\nA deep generation model-based framework is proposed to generate effective incentive\nsolutions for wireless network management.\nAutonomous driving simulation\nContent generation from \nmultimodal inputs.\nContent authenticity and \nincentives.\nContent regulation and \nprovenance.\nContent caching and privacy.\nInteroperability standards.\nDecentralized economic systems to encourage\nAIGC services\nDiffusion models for wireless network\nmanagement\nPrivacy and security in AIGC\nAIGC in mobile networks\nRendering\nLayer\nIn goal-oriented communication where background knowledge is out-of-distribution between \ntransmitter and receivers, CycleGAN/StyleGAN is used to extract semantic information and \ngenerate similar empirical data. \nContest/contract theory is being used to incentivize the sharing of semantic information \namong users to improve the overall service quality of Metaverse. \nA generative model exploiting the GAN inversion method is utilized to extract the\ninterpretable latent representation from the original image \nSemantic diffusion model based on DDPMs\nIdentity authentication.\nEconomic systems and\ndecentralized autonomous.\nRedefine quality of experience \nand quality of service metrics.\nFraud, financial risks and \ncrimes.\nDiffusion model for incentive design to\npromote semantic information sharing\nGAN based highly efficient semantic \ncommunication approach for image \ntransmission\nCycle GAN-based semantic communication \nsystems with task-unaware transmitter and \ndynamic data \nWireless end-to-end image transmission \nsystem using semantic communications\nTABLE I: ISGC-aided Metaverse: solutions, descriptions, and their integration challenges\nB. Major Issues in Separated Functionalities\nWhen the functionalities of SemCom, AIGC, and Metaverse\nare separated without ISGC, several significant issues may\narise.\n1) Resource Underutilization: Current resource allocation\nsolutions tend to focus on individual modules, rather than\nconsidering the integrated ISGC as a whole. For instance, J.\nWang et al. [9] proposed using contest theory to incentive\nusers in the semantic module to contribute more valuable\ninformation. However, this approach may lead to the overuse\nof certain resources in one module while leaving others\nidle, resulting in inefficient resource allocation and decreased\nperformance.\n2) Limited Flexibility: The information provided by indi-\nvidual modules may suffer from high transmission latency\nor be affected by noise from the communication channel,\nleading to a decrease in the quality of user experience in\nMetaverse. For instance, B. Zhang et al. [10] proposed a\nvariable-length channel coding method to highly compress\nunimportant semantic information to improve transmission\nefficiency. However, this approach may generate low-quality\ncontent in Metaverse. Additionally, the content generated by\nAIGC within Metaverse may require meaningful information\nfrom users to enhance the quality of particular applications.\nC. Technical Gains of ISGC in Metaverse\nIntegration Gain. It can be achieved through resource\nallocation and sharing, specifically in terms of computing,\ncommunication, and dataset sharing among SemCom, AIGC,\nand Metaverse. A strategic allocation or balance of resources\n4\nRendering Layer\nAIGC Layer\nSemantic Layer\nGraphic Rendering\nCallback Results\nAIGC Inference\nAIGC Training\nSemantic Extraction\nSemantic Recovery\nDigital contents\nEdge servers\nApplications\nEdge devices\nSemantic Information\nEdge devices\n!!\" = #!\"/(&!\"/'!\")\n!\"# = '\"#log(1 + +\"#,\"#/-\"$)\n!#\n! = '#!log(1 + +#\n! ,#\n! /-#$ )\nM1234356 :!\"log 1 + !!\" + :\"#;<+(1 + !\"#) + :#\n! ;<+(1 + !#\n! )\ns.t. /!\n/012 + /\"\n/011 + /\"\n/012 + /#,-\n/011 + /#,.\n/011 + /#\n/012 \u2264/max,\n'\"# + '!\" + '#! \u2264'max\nRendering\nResults\n3!\n\", 3\"\n#, 3#\n! : prices\n4!\n\", 4\"\n#, 4#\n! : transmit rates\n5\"\n#, 5!\n\", 5#\n!: available bandwidths\n6!\n$%&', 6\"\n$%&', 6#\n$%&': computation time\n6\"\n$%&&, 6#,)\n$%&&, 6#,*\n$%&&:communication time\nFig. 2: A layered view of ISGC-aided Metaverse: Semantic,\nAIGC, and Rendering layers\ncan be implemented based on environmental conditions and\nuser requirements to maximize overall utilities. In cases where\nthe channel conditions are unfavorable, it becomes impractical\nto allocate excessive resources to AIGC and the Metaverse,\nas they would be limited by the performance of SemCom.\nInstead, allocating more resources to SemCom can yield\noptimal utilities. This process can be seen as maximizing\nminimum utilities among SemCom, AIGC, and Metaverse.\nThe workflow for dynamically coupling resources of ISGC\nconsists of the following three steps. More details are shown\nin the next section.\n\u2022 Step 1: Design the joint optimization problem. Given\ncomputing and communication resources, ISGC needs\nto consider both the usage of resources and latency in\neach module. To achieve this, ISGC can construct joint\nresource allocation optimization problems to maximize\nutility.\n\u2022 Step 2: Learn the policy via training. Diffusion model-\nbased Deep Reinforcement Learning (DRL) is utilized to\nsolve the joint optimization problem and learn the policy\nsince the diffusion model could mitigate the effect of\nrandomness and noises [11].\n\u2022 Step 3: Generate the near-optimal strategy via in-\nference. The trained model can generate near-optimal\nstrategies based on dynamic inputs to improve efficiency\nof the integration.\nCoordination Gain. The coordination gain achieved by\nISGC is essential in achieving goal-oriented content generation\nwithin Metaverse, which can couple the functionalities of\nsemantic communication, AIGC inference, and graphic ren-\ndering more tightly. For coordination gain, we can customize\nSemCom based on the AIGC algorithm and Metaverse user\nrequirements. For example, if a user is participating in virtual\ndriving, SemCom should focus on vehicular network semantic\ninformation. By integrating SemCom, AIGC, and Metaverse,\nISGC can extract semantic information efficiently, generate\nhigh-quality content with AI, and seamlessly integrate it into\nthe Metaverse ecosystem. Unlike separate functionalities, the\nintegration of ISGC ensures to perform mutual assistance. To\nprovide a more concrete illustration of the coordination gain\nachieved by ISGC, a use case involving a virtual campus is\npresented in Fig. 3.\n\u2022 Step 1: Capture the environment. In the scenario of\na university campus, sensors, e.g., camera sectors of\nVR/AR/XR devices, capture the environmental settings\nfrom the real campus, like animals running around or\nairplane flying in the sky.\n\u2022 Step 2: Learn useful representations of input data.\nSemantic information, e.g., feature vectors, is extracted\nfrom images in the semantic modules and transmitted to\nthe inference module controlled by MSPs.\n\u2022 Step 3: Generate depth maps from representations.\nMSPs first use feature vectors to reconstruct low-quality\nimages and then generate depth maps with multiple\nangles of the environmental settings in the inference\nmodule.\n\u2022 Step 4: Render virtual campus with personalized\nfeedback from depth maps. The rendering model could\nprovide personalized feedback to devices based on the\nabove depth maps to simulate real-world settings.\nIV. CASE STUDY: EXPLORING INTEGRATION GAIN\nWithin the ISGC framework, to explore the integration\ngain, given limited available computing and communication\nresources, they need to be allocated to semantic extraction,\nAIGC inference, and graphic rendering modules to maximize\nthe end-to-end utility. In this section, we first formulate the\nutility joint optimization problem of ISGC, as shown in Fig.\n2, then achieve an effective resource allocation mechanism to\nobtain near-optimal strategies, and depict the simulation results\nof the proposed mechanism.\nA. Problem Formulation\nTo simplify the notation, we use subscripts and superscripts\nof s, a, and m to represent the semantic, AIGC, and render-\ning modules, respectively. Additionally, comm represents the\ncommunication time, and comp represents the computation\ntime.\n1) Semantic Extraction. Edge devices employ the semantic\nmodule to extract semantic information from raw data, which\nreduces the amount of data transmitted by using fewer sym-\nbols. As mentioned in [12], the computation time T comp\ns\nfor\nsemantic extraction depends on the available computational\nresources of edge devices. Specifically, it is determined by the\nratio of the required computational resources Zs of semantic\nextraction to the total resources available Cs on edge devices.\n2) Semantic Module to Inference Module. The semantic rate\nRa\ns refers to the amount of semantic information transmitted\n5\nStep 1: Capture the environment\nObtain surrounding images\nStep 2: Learn useful \nrepresentations of input data\nExtract vehicular\nsemantic information\nStep 3: Generate fancy cars\nfrom representations\nGenerate fancy virtual\ncars according to\nsemantic information\nStep 4: Render virtual world according\nto the generated content.\nFig. 3: An illustration of the coordination gain of ISGC\nper second [13]. It is determined by considering the proportion\nof the approximate semantic entropy Ha\ns , a measure of the\nuncertainty or randomness associated with semantic informa-\ntion, to the available bandwidth W a\ns between edge devices and\nMSPs and the average number of transmitted symbols Ka\ns .\nConsequently, the time T comm\na\nrequired to transmit semantic\ninformation Ds from the semantic module on edge devices\nto the inference module on edge servers is the ratio of the\nextracted semantic information to the semantic rate Ra\ns.\n3) AIGC Inference. Upon receiving semantic information\nfrom edge devices, MSPs carry out AIGC inference tasks\nthat are guided by the semantic information to conditionally\ngenerate digital content in edge servers. The time required\nfor AIGC inference T comp\na\nis influenced by the computational\nresources available on edge servers containing the inference\nmodule. In particular, this time is dictated by the proportion of\nthe necessary computational resources Za for AIGC inference\nto the overall resources Cs\na present on edge servers managed\nby MSPs.\n4) Inference module to Rendering module. The transmission\nrate Rm\na from the inference module to the rendering module\nis computed as the product of the bandwidth available W m\na\nbetween edge servers and MSPs and the channel capacity,\nreferring to [7]. The channel capacity is influenced by the\nchannel gain gm\na , transmit power pm\na , and the additive Gaussian\nnoise \u03c32\na. The transmission time T comm\nm,u\nis determined by the\nratio of the data size of the generated AIGC digital content to\nthe transmission rate.\n5) Graphics Rendering. Once the digital content is received\nfrom the corresponding edge servers running the inference\nmodule, MSPs equipped with the rendering module undertake\ngraphics rendering tasks. These tasks involve leveraging digital\ncontent to augment and enrich virtual environments. The\ncomputation time T comp\nm\nrequired for graphics rendering is\ncontingent upon the available computational resources of the\nedge servers deploying the rendering module. Precisely, this\ntime is derived from the proportion of the required computing\nresources Zm to the aggregate resources accessible Ca\nm on\nthese edge servers.\n6) Rendering module to Users. The transmission rate Rs\nm\nbetween the rendering module and the semantic module can\nbe analogous to that between the AIGC and rendering module\nwith the bandwidth available W s\nm, channel gain gs\nm, transmit\npower ps\nm, and the additive Gaussian noise \u03c32\nm. The transmis-\nsion time T comm\nm,d\nis determined by the ratio of the data size of\nthe rendering feedback to the transmission rate.\n7) MSP Utility. MSPs impose charges on edge devices\nfor the transmission and execution of tasks on edge servers.\nReferring to [12][13], the utility of MSPs can be determined\nby the products of the price qa\ns, qm\na , qs\nm and transmit rate\nRa\ns, Rm\na , Rs\nm of semantic, AIGC, and rendering modules. The\nutility is limited by the tolerable transmission time and the\ngiven bandwidth resources among the three modules, as shown\nin Fig. 2.\nB. Diffusion Model-Based Joint Resource Allocation\nInspired by [14], in this paper, we present the diffusion\nmodel-based joint resource allocation mechanism. This mech-\nanism is characterized as a Markov decision process consisting\nof state spaces, action spaces, environment dynamics, a reward\nfunction, a discount factor, and an initial state distribution.\nThe reward is calculated by the utility function. The primary\nobjective of this mechanism is to learn a policy that maximizes\nthe cumulative discounted reward, thereby optimizing the\nutilities for MSPs within the ISGC framework.\nAI-Generated Resource Allocation: The resource (i.e.,\nbandwidth) allocation problem is solved by the diffusion\nmodel, which is composed of forward and reverse processes.\nThe processes are designed to add and remove noises from\nsamples, ultimately yielding generative outputs. The diffusion\nmodel can be further extended to include conditional models to\nrepresent the policy that optimizes the rewards for MSPs [14].\nThe conditional diffusion model is integrated with DRL to\niteratively denoise the initial distribution and produce a near-\noptimal utility function for MSPs.\n\u2022 Step 1: Design state spaces. Based on the MSPs\u2019\nutility derived in the previous section, the near-optimal\nstrategy \u03c0(a0|s \u2208S) is influenced by a variety of\nfactors, denoted as state spaces S. These state spaces\n[Ha\ns , \u03c3a, \u03c3m, gm\na , pm\na , gs\nm, ps\nm, Ka\ns , Cs\na, Ca\nm] include the\napproximate semantic entropy and the average trans-\nmitted symbols of the semantic module, channel gains\nand transmit power from the inference module to the\nrendering module, channel gains and transmit power from\nthe rendering module to the inference module, as well\nas the computing resources and additive Gaussian noises\npresent at the AIGC and rendering modules.\n\u2022 Step 2: Construct action spaces. Given the state spaces,\nthe action spaces a0 \u2208A are associated with several\nfactors, including the available bandwidth from the se-\nmantic, AIGC, and rendering modules, respectively. Con-\nsequently, the diffusion model that establishes a mapping\nbetween states S as the condition and action A as outputs\n6\nrepresent the near-optimal policy \u03c0(a0|s \u2208S). This\npolicy yields a deterministic resource allocation strategy,\nwhich aims to maximize the expected cumulative reward\nover a series of steps.\n\u2022 Step 3: Explore the training policy in the forward pro-\ncess. Initiating the training step involves providing hyper-\nparameters, including diffusion steps T, batch size, and\nexploration noise. The diffusion model is then initialized,\nincorporating two critic networks along with their corre-\nsponding target networks with different weights. In each\niteration, the method initializes a random Gaussian dis-\ntribution cT for resource allocation exploration, followed\nby entering a loop of multiple steps. During each step,\nthe method initially observes the current environment\nand its associated states, then sets the current actions as\nGaussian noise. Subsequently, it generates the next action\nby denoising the current action p(ai|ai+1, s) through the\nreverse diffusion process and adds exploration noise to\nthe generated action. Once the action is executed, the\nmethod obtains the corresponding reward based on the\nutility function and stores the environment record in the\nreplay buffer. To further refine the model, it samples a\nrandom mini-batch of records from the replay buffer,\nupdates the critic networks by computing the loss and\npolicy gradient, and finally updates the target networks.\n\u2022 Step 4: Generate near-optimal resource allocation\nstrategy in the reverse process. In the inference step,\nthe environment with its associated states is input into\nthe networks. Subsequently, the near-optimal resource\nallocation strategy \u03c0(a0|s \u2208S) is generated by denoising\nGaussian noise through the reverse diffusion process. This\nstep focuses on utilizing the trained model to produce\neffective resource allocation strategies based on the given\nenvironmental conditions.\nC. Simulation Results\nThe experimental platform utilized for executing the band-\nwidth resource allocation is built on a generic Ubuntu 20.04\nsystem, featuring an AMD Ryzen Threadripper PRO 3975WX\n32-Core CPU and an NVIDIA RTX A5000 GPU. The approx-\nimate semantic entropy, average transmitted symbols, channel\ngain and transmit power between the AIGC and rendering\nmodules, as well as channel gain and transmit power between\nedge servers and devices, are randomly sampled from uniform\ndistributions (1, 2), (0, 0.8), (0, 1), (3, 5), (0, 1), and (3,\n5), respectively. The additive Gaussian noise at the AIGC\nand rendering modules is randomly sampled from normal\ndistributions (0, 1) and (0, 1), respectively. The constraints\nof the total interaction time, the available bandwidth between\nthe semantic, AIGC, and rendering modules, respectively. The\nabove parameters are set as indicated in [7, 12, 13].\nIn the simulation experiment, the diffusion model (Diffu-\nsion) and the Proximal Policy Optimization (PPO) [15] algo-\nrithm with learning rates, 3e-7 and 3e-6 are used to determine\nthe near-optimal allocation of the available bandwidth among\nthe semantic module, AIGC module, and rendering module.\nUnless otherwise specified, these methods are assumed to\n0\n500\n1000\n1500\n2000\n2500\n3000\nEpoch\n6\n7\n8\n9\n10\n11\n12\n13\nReward\n#104\nDiffusion\nPPO\nFig. 4: Training curves of the joint resource allocation\noperate under identical parameters and environments. PPO\nis a model-free, on-policy actor-critic algorithm that uses\nthe clipped surrogate objective to improve the stability and\nefficiency of learning. The training process is set to run for\n3,000 epochs with buffer size 1,000,000, exploration noise\n0.01, 10 steps per epoch, and 100 steps per collect, providing\nsufficient iterations for these methods to learn and adapt to the\ngiven environment and parameters.\nFig. 4 illustrates the reward comparison among our pro-\nposed mechanism and PPO. The training process demon-\nstrates the reward values of Diffusion are significantly higher\nthan those of PPO. Fig. 5 compares the utilities computed\nby the near-optimal actions under different network states\n[Ha\ns , \u03c3a, \u03c3m, gm\na , pm\na , gs\nm, ps\nm, Ka\ns , Cs\na, Ca\nm], i.e., PPO1 with\n[1.17, 0.66, 1.97, 0.30, 0.24, 4.76, 4.46, 0.91, 8.03, 15.28],\nPPO2 with [1.40, 0.30, 0.65, 0.58, 0.16, 3.42, 4.69, 0.89,\n7.49, 15.24], Diffusion1 with [1.80, 1.05, 0.47, 0.05, 0.0004,\n4.23, 4.58, 0.91, 5.02, 19.73], and Diffusion2 with [1.52,\n0.12, 1.23, 0.03, 0.14, 4.83, 3.86, 0.96, 9.93, 18.42], in the\nDiffusion and PPO methods. The near-optimal strategy found\nby Diffusion is better than that of PPO. The underlying cause\nfor these outcomes is that the diffusion model-based resource\nallocation mechanism can adapt outputs by fine-tuning given\nthe diffusion steps and promoting exploration, thereby enhanc-\ning flexibility and mitigating the impact of uncertainty and\nnoise encountered during the training process. This allows the\nproposed mechanism to achieve superior results in comparison\nto the other tested algorithms.\nV. FUTURE DIRECTIONS\nSeveral open challenges arise from the use of ISGC in the\nMetaverse as shown in Table I. We elaborate on several of\nthem in this section.\na) Invariant Semantic Extraction Across Virtual Envi-\nronments: Because Metaverse may involve multiple hetero-\ngeneous devices deployed in different virtual environments,\nsemantic extraction may unintentionally absorb irrelevant en-\nvironmental information, resulting in the extraction of useless\n7\n1140\n1150\n1160\n1170\n1180\n1190\n1200\n1210\nPPO1\nPPO2\nDiffusion1\nDiffusion2\n0\n10\n20\n30\n40\n50\n60\n70\n80\nBandwidth\nWs\na\nWa\nm\nWm\ns\nUtility\nFig. 5: Generated utility of Diffusion compared with PPO\ninformation that can cause inaccurate content generation in\nMetaverse. Therefore, it is crucial to consider the impacts of\nout-of-distribution data and extract invariant semantic infor-\nmation across virtual environments.\nb) Content Authenticity and Incentives: The limited\ncomputation resources of Metaverse devices necessitate their\nreliance on MSPs to generate content and enable the creation\nof complex and resource-intensive experiences. Therefore, it is\nnecessary to design fair incentive mechanisms to verify content\nauthenticity and incentivize MSPs.\nc) Practical\nImplementation\nDifficulties:\nAchieving\nmanagement of computing and communication functions\nacross different layers and service providers, poses practical\nchallenges. Implementing even simple techniques in practice\nis exceedingly difficult due to limited infrastructure access, di-\nverse deployment environments, and requirements. Overcom-\ning these challenges necessitates addressing interoperability,\nresource allocation, and performance management, highlight-\ning the complexity of integrating compute and communication\nfunctions in real-world scenarios.\nd) Communication Security and Privacy Preserving:\nSince users should upload their semantic information for the\ncustomized AIGC-based immersive Metaverse, it is important\nto achieve communication security and privacy preserving.\nExploring privacy-preserving AI techniques, such as federated\nlearning, differential privacy, and secure multi-party computa-\ntion, can allow for collaborative semantic extraction without\nexposing users\u2019 sensitive information [6].\nVI. CONCLUSION\nIn conclusion, this paper has provided a comprehensive\noverview of ISGC in the context of the growing Metaverse.\nBy integrating SemCom and AIGC, ISGC offers significant\nbenefits in terms of efficient communication and intelligent\ncontent generation. The proposed unified framework captures\nthe integration and coordination gains of ISGC, optimizing\nresource allocation and enhancing the quality of digital content\nin the Metaverse. The case study utilizing the diffusion model\ndemonstrates an improvement of 8.3% in rewards compared\nto PPO. However, there are still open research issues that\nneed to be explored, such as privacy concerns and advanced\ntechniques for resource allocation optimization. Overall, this\npaper contributes to the understanding and potential of ISGC,\npaving the way for immersive and intelligent experiences in\nthe Metaverse.\nREFERENCES\n[1] H. Du, R. Zhang, D. Niyato, J. Kang, Z. Xiong, D. I.\nKim, X. S. Shen, and H. V. Poor, \u201cExploring collab-\norative distributed diffusion-based ai-generated content\n(aigc) in wireless networks,\u201d IEEE Network, no. 99, pp.\n1\u20138, 2023.\n[2] D. Huang, X. Tao, F. Gao, and J. Lu, \u201cDeep learning-\nbased image semantic coding for semantic communica-\ntions,\u201d in 2021 IEEE Global Communications Conference\n(GLOBECOM).\nIEEE, 2021, pp. 1\u20136.\n[3] Y. Cui, F. Liu, X. Jing, and J. Mu, \u201cIntegrating sensing\nand communications for ubiquitous iot: Applications,\ntrends, and challenges,\u201d IEEE Network, vol. 35, no. 5,\npp. 158\u2013167, 2021.\n[4] H. Zhang, S. Shao, M. Tao, X. Bi, and K. B. Letaief,\n\u201cDeep learning-enabled semantic communication sys-\ntems with task-unaware transmitter and dynamic data,\u201d\nIEEE Journal on Selected Areas in Communications,\nvol. 41, no. 1, pp. 170\u2013185, 2022.\n[5] A. A. Alemi, I. Fischer, J. V. Dillon, and K. Murphy,\n\u201cDeep variational information bottleneck,\u201d arXiv preprint\narXiv:1612.00410, 2016.\n[6] J. Chen, J. Wang, C. Jiang, Y. Ren, and L. Hanzo, \u201cTrust-\nworthy semantic communications for the metaverse rely-\ning on federated learning,\u201d IEEE Wireless Communica-\ntions, 2023.\n[7] M. Xu, D. Niyato, J. Chen, H. Zhang, J. Kang, Z. Xiong,\nS. Mao, and Z. Han, \u201cGenerative ai-empowered simula-\ntion for autonomous driving in vehicular mixed reality\nmetaverses,\u201d arXiv preprint arXiv:2302.08418, 2023.\n[8] T. Han, J. Tang, Q. Yang, Y. Duan, Z. Zhang, and\nZ. Shi, \u201cGenerative model based highly efficient semantic\ncommunication approach for image transmission,\u201d arXiv\npreprint arXiv:2211.10287, 2022.\n[9] J. Wang, H. Du, Z. Tian, D. Niyato, J. Kang, and X. Shen,\n\u201cSemantic-aware sensing information transmission for\nmetaverse: A contest theoretic approach,\u201d IEEE Trans-\nactions on Wireless Communications, 2023.\n[10] B. Zhang, Z. Qin, and G. Y. Li, \u201cSemantic communica-\ntions with variable-length coding for extended reality,\u201d\narXiv preprint arXiv:2302.08645, 2023.\n[11] H. Du, J. Wang, D. Niyato, J. Kang, Z. Xiong, and D. I.\nKim, \u201cAi-generated incentive mechanism and full-duplex\nsemantic communications for information sharing,\u201d IEEE\nJournal on Selected Areas in Communications, 2023.\n[12] Y. Liu, H. Yu, S. Xie, and Y. Zhang, \u201cDeep reinforcement\nlearning for offloading and resource allocation in vehicle\nedge computing and networks,\u201d IEEE Transactions on\nVehicular Technology, vol. 68, no. 11, pp. 11 158\u201311 168,\n2019.\n[13] L. Yan, Z. Qin, R. Zhang, Y. Li, and G. Y. Li, \u201cQoE-\nAware Resource Allocation for Semantic Communication\n8\nNetworks,\u201d in GLOBECOM 2022-2022 IEEE Global\nCommunications Conference.\nIEEE, 2022, pp. 3272\u2013\n3277.\n[14] Z. Wang, J. J. Hunt, and M. Zhou, \u201cDiffusion policies\nas an expressive policy class for offline reinforcement\nlearning,\u201d arXiv preprint arXiv:2208.06193, 2022.\n[15] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and\nO. Klimov, \u201cProximal policy optimization algorithms,\u201d\narXiv preprint arXiv:1707.06347, 2017.\n",
    "2308.04942": "1\nSemantic Communications for Artificial Intelligence\nGenerated Content (AIGC) Toward Effective\nContent Creation\nGuangyuan Liu, Hongyang Du, Dusit Niyato, Fellow, IEEE, Jiawen Kang, Zehui Xiong,\nDong In Kim, Fellow, IEEE, and Xuemin (Sherman) Shen, Fellow, IEEE\nAbstract\u2014Artificial Intelligence Generated Content (AIGC)\nServices have significant potential in digital content creation. The\ndistinctive abilities of AIGC, such as content generation based on\nminimal input, hold huge potential, especially when integrating\nwith semantic communication (SemCom). In this paper, a novel\ncomprehensive conceptual model for the integration of AIGC\nand SemCom is developed. Particularly, a content generation\nlevel is introduced on top of the semantic level that provides\na clear outline of how AIGC and SemCom interact with each\nother to produce meaningful and effective content. Moreover, a\nnovel framework that employs AIGC technology is proposed as\nan encoder and decoder for semantic information, considering\nthe joint optimization of semantic extraction and evaluation\nmetrics tailored to AIGC services. The framework can adapt to\ndifferent types of content generated, the required quality and the\nsemantic information utilized. By employing a Deep Q Network\n(DQN), a case study is presented that provides useful insights into\nthe feasibility of the optimization problem and its convergence\ncharacteristics.\nIndex\nTerms\u2014Semantic\ncommunications,\ngenerative\nAI,\nThis research is supported by the National Research Foundation, Singapore,\nand Infocomm Media Development Authority under its Future Communica-\ntions Research & Development Programme, DSO National Laboratories under\nthe AI Singapore Programme (AISG Award No: AISG2-RP-2020-019 and\nFCP-ASTAR-TG-2022-003), Energy Research Test-Bed and Industry Part-\nnership Funding Initiative, Energy Grid (EG) 2.0 programme, DesCartes and\nthe Campus for Research Excellence and Technological Enterprise (CREATE)\nprogramme, and MOE Tier 1 (RG8722).\nThe work is also supported by NSFC under grant No. 62102099,\nU22A2054, and the Pearl River Talent Recruitment Program under Grant\n2021QN02S643, and Guangzhou Basic Research Program under Grant\n2023A04J1699\nThe research is also supported by the National Research Foundation (NRF)\nand Infocomm Media Development Authority under the Future Communica-\ntions Research Development Programme (FCP). The research is also supported\nby the SUTD SRG-ISTD-2021-165, and the Ministry of Education, Singapore,\nunder its SMU-SUTD Joint Grant (22-SIS-SMU-048).\nThis research is also supported in part by the MSIT (Ministry of Science\nand ICT), Korea, under the ICT Creative Consilience program (IITP-2020-0-\n01821) supervised by the IITP (Institute for Information & Communications\nTechnology Planning & Evaluation).\nG. Liu, and H. Du are with the School of Computer Science and\nEngineering, the Energy Research Institute @ NTU, Interdisciplinary\nGraduate Program, Nanyang Technological University, Singapore (e-mail:\nliug0022@e.ntu.edu.sg, hongyang001@e.ntu.edu.sg).\nD. Niyato is with the School of Computer Science and Engineering,\nNanyang Technological University, Singapore (e-mail: dniyato@ntu.edu.sg).\nJ. Kang is with the School of Automation, Guangdong University of\nTechnology, China. (e-mail: kavinkang@gdut.edu.cn).\nZ. Xiong is with the Pillar of Information Systems Technology and\nDesign, Singapore University of Technology and Design, Singapore (e-mail:\nzehui xiong@sutd.edu.sg).\nD. I. Kim is with the Department of Electrical and Computer Engineering,\nSungkyunkwan University, South Korea (e-mail: dikim@skku.ac.kr).\nX. Shen is with the Department of Electrical and Computer Engineering,\nUniversity of Waterloo, Canada (e-mail: sshen@uwaterloo.ca).\nAIGC, resource allocation, wireless network\nI. INTRODUCTION\nArtificial Intelligence Generated Content services (AIGC\nservices) have gained significant attention due to their ability\nto enhance creativity, accelerate design processes, provide\npersonalized content and promote accessibility in various\ndomains, such as digital marketing, video game design and\nfilmmaking [1]. AIGC employs advanced Generative AI (GAI)\ntechniques to produce content corresponding to human in-\nstructions by deciphering the intent and generating appropriate\ncontent in response.\nThe considerable advancements in AIGC can be attributed\nto the development of increasingly sophisticated generative\nmodels, expanded foundation model architectures and the\naccessibility of vast computational resources. AIGC services\nhold substantial importance for a variety of reasons, including:\n\u2022 Enhancing creativity: GAI models support users in gen-\nerating unique and original images from textual prompts,\nthereby unveiling new avenues for artistic and creative\nexpression1.\n\u2022 Streamlining design processes: AIGC services facilitate\nrapid generation of visual content, optimizing workflows\nfor designers and artists which subsequently reducing\ntime and effort required for manual design tasks.\n\u2022 Tailoring content: These services enable the creation of\ncustomized content that is specifically designed to cater\nto individual user preferences or distinct target audiences,\nultimately resulting in heightened user engagement.\n\u2022 Promoting accessibility: AIGC services enable the users\nwith limited design abilities to generate professional-\nquality visuals, thereby fostering inclusivity and democ-\nratizing the design process.\nThe efficient functioning and widespread adoption of AIGC\nservices are contingent on robust communication infrastructure\nand technologies, such as wireless networks and semantic\ncommunication (SemCom). The technologies offer many ben-\nefits to AIGC services including [2]:\n\u2022 Ubiquitous\naccess:\nWireless\nnetworks\nfacilitate\nwidespread access to AIGC services, allowing users to\nbenefit from these services regardless of their location\nor device.\n1https://hbr.org/2022/11/how-generative-ai-is-changing-creative-work,\naccessed July 06, 2023\narXiv:2308.04942v2  [cs.NI]  20 Jan 2024\n2\n\u2022 Real-time processing: Wireless networks enable rapid\ndata transfer, promoting real-time interactions between\nusers and AI models for content generation, thus improv-\ning the overall user experience.\n\u2022 Scalability: Wireless networks can efficiently support\na large number of users simultaneously, enhancing the\navailability and accessibility of AIGC services.\nOn the other hand, SemCom can focus on the intended\nmeaning or context of the transmitted data, rather than on\nits raw form, which leads to a more efficient and intelli-\ngent exchange of information. When SemCom is applied to\nAIGC services, this results in optimized transmission and\ninterpretation of generated content. Specifically, the benefits\nof integrating SemCom into AIGC services include [3]:\n\u2022 Bandwidth efficiency: SemCom makes possible more\nefficient use of bandwidth, allowing generated contents\nto be transmitted with lower latency and less resource\nconsumption.\n\u2022 Enhanced privacy: SemCom also contributes to in-\ncreased privacy, ensuring secure exchanges of informa-\ntion between users and AIGC services due to shorter\ntransmission time and less amount of transferred data.\n\u2022 Energy Efficiency: By focusing on the meaningful com-\nponents of data, SemCom can reduce the energy con-\nsumption of data transmission and processing in AIGC\nservices.\nEvidently, the development of efficient and secure wireless and\nSemCom technologies is essential for the widespread adoption\nand effective implementation of AIGC services. As such,\nfurther clear understanding of their integration is necessary\nto guide the design and implementation of AIGC services to\nmeet the diverse needs of different applications and domains.\nIn this paper, we introduce a conceptual model for inte-\ngrating and designing AIGC services with SemCom. Specif-\nically, we extend three-level of SemCom, i.e., physical level,\nsemantic level and effectiveness level, by having a generation\nlevel that allows AIGC services at the receiver to generate\nmeaningful contents from input provided by the transmitter\nover a communication link. To realize the proposed model,\nwe then explore the effect of extracting semantic information\nfrom AIGC inputs on the AIGC output quality. We propose an\ninnovative framework that quantitatively evaluates the impact\nof various factors, such as image resolution and compression\nlevels. The contributions of this paper are summarized as\nfollows:\n\u2022 We present the model that serves as a foundation to\ndevelop AIGC services by leveraging the capability of\nSemCom. The model can represent building blocks of the\nSemCom-enabled AIGC services and their interactions\nto achieve effective and efficient content generation by\ngenerative AI over wireless networks.\n\u2022 We realize the model by conducting a thorough analysis\nof how alterations in the extraction and reduction of input\ninformation, such as changes in image resolution and\ncompression, influence AIGC output quality.\n\u2022 We introduce a novel framework that describes the vital\nrole of AIGC in semantic information transmission. This\nSemantic/Prompt\nrepresentation\nSemantic\nencoding\nChannel\nencoding\nSemantic\ndecoding\nChannel\ndecoding\nBackground\nknowledge\nBackground\nknowledge\nSemantic level\nEffective \ninformation \ncreation level\nPhysical level\nGeneration level\nSource \ndata\nPrompt \nengineering\nSemantic noise\nPhysical\nChannel\nPhysical noise\nSemantic\nchannel\nShared\nknowledge\nPFMs\nGeneration \nchannel\nGeneration noise\nGeneration\nInference\nDestination\nGoal of \ncreation\nPretraining\nGeneration \nparameters\nGeneration \nparameters\nSemantic/Prompt\ninterpretaion\nFig. 1: SemCom-enabled AIGC model, which is divided into\nphysical level and semantic level for SemCom to support\ngeneration level and effective information creation level.\nstrategy aims to optimize resource allocation to maximize\nuser satisfaction with AIGC services.\n\u2022 We present an in-depth experimental study of joint\nresource allocation to understand the complexities of\naccommodating various services within a single trans-\nmission framework. This study offers crucial insights into\noptimization results and their convergence characteristics.\nThen, we provide validation of our proposed framework\nthrough a Deep Q-Network (DQN), demonstrating its fea-\nsibility and promising implications for enhancing AIGC\nservices efficiency.\nII. SEMANTIC COMMUNICATIONS-ENABLED\nAI-GENERATED CONTENT MODEL\nTraditional SemCom model prioritizes accurate transmis-\nsion and reception of semantic content over relying solely\non average information related to source data probabilities\n[4]. However, the advent of AIGC offers an opportunity to\naugment and benefit from SemCom model. In this section, we\npropose two integral components, the Effective Information\nCreation Level and the Generation Level. By implementing\nthese components, AIGC can fulfill its dual objectives of\ninformation generation and communication more effectively.\nA. Integration of SemCom with AIGC\nIn traditional SemCom model, as shown in Fig. 1, physical\nand semantic levels form the two-pronged structure. The\nphysical level encapsulates transmission operations within\nthe physical layer, including modules responsible for chan-\nnel encoding and decoding. This level necessitates symbol\ntransmission over a physical channel susceptible to noise. The\nsemantic level is composed of semantic representation and\nencoding modules at the transmitter end. These components\nwork together to extract and represent semantic information.\nFurthermore, semantic interpretation and decoding modules\nsituated at the receiver end are for reconstructing and inter-\npreting the received semantic information.\n3\nTo extend the capabilities of the SemCom model, the\nintroduction of effective information creation level and the\ngeneration level is essential [4]. Specifically, the effective\ninformation creation level in the AIGC framework transforms\nraw user data into semantic representations, which are then\nused to guide the generation process. It involves feature\nextraction and the creation of model fine-tuning parameters\nbased on context-specific requirements. Meanwhile, the gen-\neration level provides an engine of content creation. It utilizes\nthe semantically-encoded information and the generation pa-\nrameters to run controlled diffusion models, generating the\nfinal content. Together, these levels augment the traditional\nSemCom model by adding control and personalization, thereby\nmaking AIGC a more adaptable and effective tool for content\ngeneration and transmission.\nThe generation level has the following components:\n\u2022 Background knowledge: This component represents the\nfoundation of knowledge and expertise necessary for con-\ntent generation. On the transmitter side, it encompasses\ngeneration parameters that are finely tuned for specific\ngeneration tasks. On the receiver side, it includes the\nknowledge of how to fine-tune models with provided\nparameters and how to infer the generation process using\nthe given generation parameters.\n\u2022 Shared knowledge: As a shared knowledge base, this\ncomponent allows both the transmitter and receiver to\naccess relevant information during content generation and\ninterpretation. It consists of extensive data containing Pre-\ntrained Foundation Models (PFMs) that can be utilized\nfor additional fine-tuning, thereby enhancing the effec-\ntiveness and relevance of content generation [5].\n\u2022 Goal of creation: This component represents the specific\nobjective or intention behind content creation. It guides\nthe generative process to ensure that the output aligns\nwith the desired outcome.\nThe generation level has several integral components, in-\ncluding:\n\u2022 PFMs: As the primary source of content generation,\nPFMs are pre-trained on extensive datasets [5]. This pre-\ntraining process endows them with considerable knowl-\nedge and capabilities, allowing them to be fine-tuned\nfor specific tasks. Thus, they are capable of generating\ndiverse, high-quality content such as images, stories and\ncode.\nElaborating further on PFMs, it is important to understand\nthat these models assimilate the underlying patterns from\nthe vast amounts of training data. This wide-ranging and\nextensive training allows them to generate a rich variety\nof content, providing the basis for generating content in\na variety of contexts.\n\u2022 Prompt Engineering: The process of creating prompts to\nguide AI model generation forms the crux of prompt en-\ngineering. By optimizing and customizing these prompts,\nthe desired content output can be achieved. Prompt en-\ngineering plays a pivotal role in steering the generative\nprocess, resulting in more accurate and effective content\ngeneration.\nThe effectiveness of Prompt Engineering is determined by\nhow well it aligns with the information generation task\nand the desired outcome. It necessitates a comprehensive\nunderstanding of the generative model and the task at\nhand to produce precise prompts that yield the most\ndesirable output.\n\u2022 Generation Inference: This process involves content\nrecreation at the receiver end, integrating and applying\nthe generated content in the pertinent context.\n\u2022 Generation Channel: A virtual medium that facilitates\ncontent generation. This channel enables the transfer of\ncreativity from the transmitter to the receiver.\n\u2022 Generation Noise: Representing potential inconsisten-\ncies or errors arising during the generative process [5],\nthis noise can lead to mismatches in the quality, values\nand utility of the generated content between the transmit-\nter and receiver.\nB. Practical Applications and Insights\nThe AIGC framework offers a significant advantage in\nterms of personalization, a feature that sets it apart from\ntraditional SemCom. While traditional SemCom often remains\nconstrained to transmitting generic semantic information, the\nSemCom-enabled AIGC framework exhibits the ability to\ntailor the generation of content to specific scenarios or user\npreferences such as personal driving assistant and smart health-\ncare [2].\nTo illustrate, consider a news organization employing the\nAIGC framework to generate digital content. Traditional Sem-\nCom model may merely transmit a generic scene of a car\naccident. However, the AIGC framework empowers the news\norganization (the receiver) to modify this scene according to\nthe context of their report. The organization can integrate\nspecific elements such as a particular street scene or addi-\ntional prompts such as \u201ccrowded street,\u201d thereby rendering the\ncontent more relevant and impactful for their audience, e.g.,\nthrough personal driving assistant services. The framework\nthereby facilitates greater receiver control over the content,\nenhancing the value and applicability of the generative process.\nTransitioning to data security considerations, the AIGC\nframework\u2019s feature of customization at the receiver\u2019s end\nbecomes particularly advantageous. As transmitters only send\nsemantic information and prompts, the receiver\u2019s specific\nadjustments remain undisclosed, significantly reducing the\npotential for inadvertent exposure of sensitive information.\nThus, the AIGC framework proves especially suitable for ap-\nplications requiring a high degree of privacy and data security,\ne.g., smart healthcare. Furthermore, the AIGC framework\u2019s\npotential to introduce generation noise actually contributes to\nits overall robustness. Although generation noise originates\nfrom inconsistencies within the AIGC model, service providers\nemploying precise prompts and meticulous model fine-tuning\ntechniques can mitigate these inconsistencies, yielding more\nreliable and high-quality generation results. Therefore, despite\nthe inherent complexities of generation-based communication,\nthe AIGC framework represents a robust mechanism, pro-\nficient in ensuring secure and personalized digital content\ngeneration and transmission.\n4\nIII. CONTROLLABLE AI GENERATED CONTENT SERVICES\nIn this section, we explore the latest AIGC advancements,\nfocusing on image generation from text prompts. We address\nhow models such as ControlNet increases user control in the\ncontent generation process. Furthermore, we propose the ap-\nplication of controlled diffusion as generation encoder/decoder\nin the aforementioned generation framework, outlining the role\nof prompt engineering, service validation, receiver generation\ninference, and highlight how this shift improves data security\nand user experience.\nA. AIGC in Image Content Generation\nOur research primarily focuses on image content generation\nfrom text prompts in AIGC services, a recent development\nwith transformative potential.\n\u2022 DALL\u00b7E: Developed by OpenAI, DALL\u00b7E is a state-\nof-the-art AI model that demonstrates the capability to\ngenerate a wide array of images from text prompts [6].\nThis model represents a major step forward in translating\nabstract textual concepts into concrete visual imagery.\n\u2022 VQGAN+CLIP: In subsequent research, CLIP, a joint\ntext-image encoder from OpenAI, was combined with a\nvariant of Generative Adversarial Network (GAN) known\nas Vector Quantized GAN (VQGAN)2. This integration\nresults in the capability of generating complex and cre-\native images from text prompts.\n\u2022 ControlNet+Stable diffusion: Similar to DALL\u00b7E, Sta-\nble diffusion generates images from textual prompts.\nHowever, ControlNet enhances the user experience by\nproviding more control over the generated output [7]. By\nenabling modifications to the descriptive text during the\ngenerative process, ControlNet allows for more precise\nand interactive image creation.\nThese models, with their emphasis on high-resolution image\nsynthesis, are revolutionizing the industry, lessening the re-\nliance on individual skills and years of experience traditionally\nconsidered essential in this field. Therefore, they continue to\nprogress and already significantly impact various domains,\nincluding advertising, game development and film effects. This\ntransformative potential is paving the way for new standards\nand workflows.\nB. Enhanced Control in Generative AI\nOne of the most significant challenges faced by generative\nmodels has been their limited controllability. Traditional meth-\nods have primarily relied on brute force techniques, involving\nlinear combinations of prompts and the mass production of\nimages. While this approach provides users with a broad scope\nof outputs, it also faces many issues, primarily rooted in\ninefficiency and a lack of precision.\nHowever, the advent of ControlNet [7] signals a trans-\nformative shift in AI-driven creation. ControlNet is adeptly\nintegrated into the Stable Diffusion model, which is a large\ntext-to-image diffusion model based on a U-Net architecture.\n2https://github.com/nerdyrodent/VQGAN-CLIP, accessed July 06, 2023\nBy using a unique dual-parameter mechanism involving a\nlocked and trainable copy of parameters, ControlNet ensures\nefficient learning while preventing overfitting. Moreover, it\nutilizes zero convolution layers as a key technique, providing\nan efficient connection between different network blocks. Even\nthough these layers start with zero weights, they adapt during\nthe training phase, contributing to the network\u2019s output and\nenhancing control. This structure allows for layer-wise manip-\nulation of the Stable Diffusion model, adding controllability\nto the image generation process.\nControlNet allow users to interactively guide the image gen-\neration process. By adding control over the neural network\u2019s\nbehavior by manipulating the input conditions of network\nblocks, ControlNet provides another modality of control in\nAI-based content creation. In essence, ControlNet improved\ncontrol and precision capabilities. For example, a generated\ndancing scene can be controlled with the dedicated pose\nextracted from a guiding image.\nC. Controlled Diffusion as the generation Encoder/Decoder\nInterestingly, the shift towards controlled generation aligns\nclosely with the core principles of the proposed framework.\nSemCom inherently involves the extraction and construction\nof information, paralleling the controlled generative process as\nexemplified by controlled diffusion technologies. This charac-\nteristic alignment underscores the potential synergy between\ngenerative AI models and SemCom, indicating the vast op-\nportunities present for their integration. Given the idea, The\ndata flow across the proposed information generation and\ncommunication can be described through the following steps:\nStep 1. Prompt engineering : As illustrated in Fig. 2 Part\nA, the transmission process commences with data collection by\nthe edge devices, which can encompass various user interfaces\nsuch as sensors and smartphones. These devices gather raw\nuser inputs, ranging from images and text prompts to user-\nspecific data like the service type that ultimately defines the\ngeneration prompt, and transmit this data to a server. This\nserver is a specialized unit designed for feature extraction\nwhich transforms the raw data into an abstract semantic\nrepresentation. The server then employs controlled diffusion\nmodels guided by a collection of generation parameters in-\ncluding the random seed and generation steps, among other\nsettings related to the generative process. Subsequently, these\nmodels will generate content derived from the given prompts\nand extracted semantic information. Within this framework,\nPretrained Foundation Models (PFMs) play a critical role as a\nshared knowledge base, accessible to both the transmitter and\nreceiver, thus instead of transmitting entire large pretrained\nmodels, only the transmission of the fine-tuning parameters is\nrequired. This strategic approach significantly reduces commu-\nnication overhead and enhances the overall creation efficiency.\nFurthermore, the procedure is designed to be shareable across\nmultiple edge devices, an attribute that optimizes resource\nallocation and maximizes system performance. The outcome\nof this stage is a semantic/prompt representation\u2014an encoded\nversion of the user\u2019s input that encapsulates both the extracted\nfeatures and the generation parameters.\n5\nEdge Device 2\nEdge Device 3\nEdge Device 1\nService Provider Server\nEdge device 1/2\nUser/Auto\nValidation\nReceiver 1 \u2013 Virtual meeting server \nReceiver 2 \u2013 Metaverse server\nFeature \nExtraction\nModel 2\nControlled \nDiffusion model 1\nPrompt 1\n\u201cCar accident\u201d\nFeature \nExtraction\nModel 1\nControlled \nDiffusion model 2\nFinetuned \nGeneration Model 1\nFinetuned \nGeneration Model 2\nRegenerate \nwith other \nrandom seed\nRegenerate \nwith other \nrandom seed\nwireless \nTransmission\nGeneration Parameters\nRandom Seed\nPrompt 1\nPrompt 3\nRandom Seed\nGeneration Parameters\nwireless \nTransmission\nUser/Auto\nValidation\nEdge device 3\nPrompt engineering\nGeneration Inference\nPretrained \nFoundation \nModels (PFMs)\nPrompt 1\nRandom Seed\nGeneration \nParameters\nPrompt 2\n\u201cOffice \nmeeting\nSession 1\u201d\nPrompt 1\n\u201cOffice \nmeeting \nSession 1\u201d\nPrompt 3\n\u201cForest\u201d\nData Source\nPrompt 3\nRandom Seed\nGeneration \nParameters\nImmersive environment \nbased on real features\nSame meeting room \nbased on united real \nfeatures\nFig. 2: AIGC model as generation encoder and decoder. In this AIGC framework, edge devices 1 and 2 represent users in a\nprofessional meeting. This step fuses their Semantic/prompt representation through Prompt engineering, guiding AI models\nto generate a unified modern meeting room theme in Generation inference. On the other hand, edge device 3 applied this\nframework in VR to generate immersive environments and to synchronize with metaverse server, addressing VR bounding\nissues by automatically adapting to the user\u2019s surroundings environments.\nStep 2. Servcie validation: As shown in Figure 2 Part\nB, upon generating the content, the server conveys it back\nto the transmitter for validation. This step can either be\nsupervised by the user or automated mechanism through\npredefined criteria or algorithms such as convolutional neural\nnetworks for image recognition. Though it may create more\ncommunication overheads, this validation process is integral\nto the framework, as it not only enhances communication\nbut also enables creative possibilities. The validation process\nfortifies the reliability and quality of the service, ensuring\nthat the produced images meet the established standards and\nuser requirements. If validation criteria is met, the corre-\nsponding semantic/prompt representation is then dispatched\nfor transmission. Conversely, if the content does not meet\nvalidation standards, regeneration is initiated with adjustments\nmade to the generation variables. Traditional SemCom model\nviews Parts A and B together as a semantic encoder, trans-\nforming user inputs into semantically encoded information.\nHowever, within the context of the AIGC framework, this\nprocess is interpreted as prompt engineering. This process\nnot only includes the encoding of semantic content but also\nencompasses the formulation and refinement of generation\nprompts, thus ensuring a more precise, efficient and user-\nspecific content generation. In addition, the validation process\ncould be adopted in determining the minimal prompt/semantic\nrepresentation necessary for recreating content. Aligned with\nSemantic Entropy(SE) [8], such a concept can be termed as\n\u201cgeneration entropy\u201d. This concept concurs with the process of\nprompt engineering and ensures maximum overhead reduction\nduring transmission.\nStep 3. Receiver generation inference: Following success-\nful validation, the semantic/prompt representation is sent to\nthe receiving entity, which can be another edge device or a\nserver, as depicted in Fig. 2 Part C. In contrast to the traditional\nSemCom model, where this step serves as a semantic decoder,\nthe AIGC framework interprets it as an embodiment of gener-\nation inference, thus underlining the creative aspect of content\ninterpretation from the received information. The versatility\nof this process is demonstrated across various domains. For\nexample, in gaming, it facilitates the creation of user-specific\navatars using the received semantic information. In the realm\nof virtual reality, this technology addresses the common issue\nof obstructed vision within VR bounding areas3. Rather than\ndisrupting the user experience with the necessity of manu-\nally drawing a bounding box, the system can regenerate an\nenvironment reflecting the user\u2019s actual surroundings, thereby\nenhancing the immersive experience.\nIn conventional content generation methods, transmission of\nsensitive user data, such as images or videos, over the Internet\npotentially risks user privacy. However, the AIGC model\noperates as an encoder-decoder system for SemCom, trans-\nmitting only semantic information and generation variables.\nThis method maintains the transmitted data encrypted and\ninaccessible to unauthorized entities equipped with different\nAIGC models and generation parameters, thereby amplifying\ndata privacy and security. For example, eavesdroppers may not\nhave the correct AIGC inference engine, unable to generate the\nsame or similar content as the legitimate receiver. Moreover,\nthis approach transitions power to users, offering a versatile\ntool in place of a predetermined outcome.\n3https://github.com/Zetaphor/webxr-environment-mapper, accessed July 28,\n2023\n6\nText Prompt \nInput\nStable Diffusion\nControlNet\nSemantic\nText \nEncoder\nImage\nTime\nTime \nEncoder\nSD \nEncoder\nSD \nMiddle\nSD \nDecoder\nExtraction\nZero Convolution\nOutput\nControlled\nDiffusion\nEncoded\nfeature\n\u201cA man sitting \nin a modern \nmeeting room\u201d\nPose estimation*\n* The extraction of semantic information may varies regrading to the service\nDownscale\nFactor\n1\n2\n4\n8\n16\n32\nSemantic \nSize(Bytes)\n1376421\n344229\n86179\n21658\n5530\n1498\nExtractions\nSemantic\nOutput\nSemantic\nOutput\nSemantic\nOutput\nSemantic\nOutput\nSemantic\nOutput\nSemantic\nOutput\nDepth \nMap\nMiDaS\nSegmentat\nion\nPose\nHED\nCanny\nDownscale\nFig. 3: Semantic variation and downscaling impact in generative task. The figure illustrates ControlNet\u2019s structure and where\ndownscaling in semantic information could be deployed. Different extraction models show varied scaling levels, reducing\ntransmitted data. Each method exhibits different sensitivity to downscaling, highlighting the need for flexible resource allocation.\nTailoring the downscale factor to the specific model ensures efficient communication by prioritizing less sensitive to more\nsensitive methods.\nIV. CASE STUDY: JOINT OPTIMIZATION OF SEMCOM AND\nAIGC\nThis section presents a case study on the joint optimization\nof SemCom and AIGC services based on ControlNet[7]. We\ninvestigate most suitable semantic extraction methods, the role\nof evaluation metrics in content quality maintenance and the\nchallenges of joint resource allocation across multiple compo-\nnents, from physical, semantic and generation levels. Through\nempirical studies and the use of DQN, this section offers\ninsights and solutions for more efficient resource allocation\nin the multifarious realm of AIGC services.\nA. Semantic extraction methods\nSemantic extraction is a crucial component of the transmis-\nsion framework of AIGC services. The method of semantic ex-\ntraction depends primarily on the type of service and can vary\nconsiderably. As depicted in Fig. 3, several common semantic\ninformation such as depth maps, Multi-Instance Depth via\nAttention Sampling (MiDaS), segmentation, pose estimation,\nHolistically-Nested Edge Detection (HED) and Canny edge\ndetection have been employed in our proposed transmission\nframework. Depth maps typically measure the distance be-\ntween the imaging sensor and each pixel\u2019s corresponding real-\nworld point, resulting in a grayscale image representation.\nMeanwhile, MIDAS uses a novel attention mechanism to\nproduce high-quality depth maps from 2D images [9]. On\nthe other hand, segmentation separates an image into regions\nor objects for further analysis. For pose estimation, which\ninterprets the human form in an image or video, recognizing\nhuman posture and outputting skeleton position information.\nMoreover, HED leverages the power of deep learning to\npredict the presence and location of edges in an image,\nproviding a structural layout. In contrast, Canny edge detection\nis a multi-stage algorithm used to detect a wide range of\nimage edges, offering a binary output that emphasizes the\nboundaries of objects within an image [10]. These examples\nrepresent a fraction of the broad, flexible range of methods\nto obtain semantic representation (As discussed in Section II)\nthat services can deploy.\nA case in point is when a service pertains to human figures,\nwhere pose estimation semantic information have the potential\nto retain substantial information. This allows for satisfactory\nreconstruction results at the receiver\u2019s end. In our experi-\nmental studies, we found that the final output only diverged\nsignificantly from the original text prompt, \u201ca man sitting\nin a modern meeting room\u201d when the semantic information\nis subjected to a downscaling factor of 10. This observation\nsuggests that even under significant compression, the chosen\nsemantic (pose) preserved essential information effectively.\nHowever, the selection of semantic information may only\nsometimes align with the service type or user requirements.\nFor instance, another scenario outlined in Fig. 3 used a depth\nmap as the semantic information for a different service. In this\ncase, the maximum permissible downscaling factor without\nnoticeable loss of information is only 4, corresponding to\nimage compression of 16 times. Therefore, the degree of\ncompression semantic information can be adapted without\nimpacting quality depends heavily on the chosen semantic\ninformation. This highlights the importance of carefully se-\nlecting the most suitable semantic extraction method based on\nservice type and user requirements.\nB. Evaluation metrics\nThe proposed methodology for identifying the most suitable\nsemantic extraction method and corresponding evaluation met-\nrics for a particular service is illustrated in Fig. 4, using four\nservice examples.\nFor Services 1 and 3, the process begins by selecting\nan evaluation metric aligning with the provider\u2019s quality\nassessment needs. This step is followed by identifying a\nsemantic extraction method that pairs effectively with the\nchosen metric, particularly the semantic extraction method\nand evaluation metric pair that is providing a predictable and\nstable linear response to various levels of image degradation.\nThis approach ensures predictable and maintainable content\n7\nRequires least Pixel-wise changes\nService 1 :\nService 2 :\nRequires similar image structure\nService 3 :\nRequires least variation in \nimage area segmentation\nRequires least error ratio in Edge changes \nService 4 :\nMean Squared Error(MSE)\nMiDas \nDepthMap\nHED\nPeak \nSignal-to-Noise \nRatio (PSNR)\nEstimated \nPose\nSegmentation\nVariation of \nInformation\n(VI)\n*Extraction Method \n*Evaluation Metrics\nText Prompt: \u201ca man sitting in a modern meeting room\u201d Input Image:\nStructural Similarity Index Measure(SSIM)\nFig. 4: Workflow for defining predictable pairs of semantic extraction methods and evaluation metrics. Service 2 presents a\ntraditional case where a service provider defines both the extraction method and evaluation metric. Services 1 and 3 illustrate\nthe process of selecting the most suitable semantic extraction method when the service provider defines the evaluation metrics.\nConversely, Service 4 demonstrates the process of choosing the most appropriate evaluation metrics when the semantic extraction\nmethod is defined. This iterative workflow ensures the identification of most predictable combinations for effective semantic\nextraction and evaluation in the given context.\nquality, even under diverse degrees of downscaling. On the\ncontrary, Service 4 employs a reversed process where the\nservice provider selects the most suitable semantic extraction\nmethod that aligns with the service type or user requirements\nand subsequently identifies an evaluation metric offering a\npredictable linear response to the chosen extraction method.\nService 2 presents a different scenario, where the service\nprovider simultaneously defines both the extraction method\nand evaluation metric. This approach is advantageous when\nservice requirements are well-understood and quality standards\nare clearly established.\nThis study utilizes a variety of established evaluation met-\nrics, including Mean Squared Error (MSE), Peak Signal to\nNoise Ratio (PSNR), Structural Similarity Index (SSIM) and\nVariation of Information (VI) [11]. MSE measures the average\npixel-wise squared difference between the generated images\nwith and without semantic downscaling. PSNR compares the\nmaximum possible power of the original signal to the power\nof the noise that affects its quality. SSIM assesses structural\nsimilarity which provides insight into perceived changes in\nstructural information and VI quantifies the change in shared\ninformation, reflecting the effectiveness of semantic content\ntransmission. Although other metrics, such as Inception Score\n(IS), Fr\u00b4echet Inception Distance (FID) [12] and Content Loss\n[13] could be considered, this study concentrates on a selected\ngroup of common metrics for simplicity and clarity.\nIn summary, selecting the most predictable pair of semantic\nextraction methods and evaluation metrics can be complex\nand service-specific. However, a systematic approach that\nconsiders the provider\u2019s needs and the pair\u2019s linear response\nunder compression can yield predictable image quality.\nC. Multi service joint resource allocation\nFollowing the selection of distinct semantic extraction meth-\nods and evaluation metrics tailored to individual service ,\na complex dynamic emerges when accommodating multiple\nservices\u2019 transmission requirements concurrently. To provide\na comprehensive understanding of our framework\u2019s deployable\nenvironment, we detail the specifications of the equipment\nspecification used in our experiments:\n\u2022 CPU: AMD Ryzen Threadripper PRO 3975WX 32-Cores\n\u2022 GPU: NVIDIA RTX A5000\n(a) Reward analysis\n(b) Loss analysis\nFig. 5: Rewards and down-sampling losses over episodes.\nThe scenario, as represented in Fig. 4, involves four ser-\nvices, each possessing unique evaluation metrics and semantic\nextraction methods. For the purpose of maintaining consis-\ntency across varying metrics, all evaluation metrics were\nnormalized to fall within a range of zero to one. Here, a\nvalue of one denotes an exact match between the original\nand regenerated image, indicating no loss of information or\nquality. In this study, we employed Deep Q-Learning Network\n(DQN) as a solution technique to assess the feasibility of joint\nresource allocation. In the DQN model, the action space is\ndefined by the downscaling factor for each service, while the\nreward signal is measured based on the evaluation results.\nThe outcomes of the DQN optimization are depicted in Fig.\n5. As the results indicate, the optimization process converges\nafter approximately 50 epochs. This convergence is significant\nas it indicates the attainment of the most efficient resource\nallocation scheme, which is essential for maximizing the\nefficiency and effectiveness of our AIGC framework. The loss\nis calculated by comparing the quality of images generated\n8\nwith original and down-scaled semantics, reflecting how re-\nsource allocation schemes affects image quality. To enhance\nsystem performance, the reward is inversely modeled related\nto loss, guiding the DQN to efficiently allocate resources while\npreserving image quality by reducing loss. The substantial\nfluctuation observed within this process is a likely conse-\nquence of the escalated complexity of image restoration when\nthe downscaling factor increments. Specifically, an increased\ndownscaling factor signifies a greater division of the image\u2019s\nwidth and height. This substantial partitioning invariably com-\nplicates restoring the original semantic information, thereby\ninfluencing the quality of the final generated image.\nNonetheless, despite these challenges, the results validate\nthe feasibility of the proposed framework for joint resource al-\nlocation. The approach demonstrates adaptability to the diverse\nrange of requirements inherent in contemporary and future\nAIGC services. Therefore, this framework holds significant\npotential for widespread deployment, facilitating more efficient\nand optimized resource allocation within the diverse landscape\nof AIGC services.\nIn Section I, we highlighted AIGC + SemCom\u2019s capability\nto manage complex content generation, which is later sub-\nstantiated by our experiments in Section IV-B. Our model\nadeptly managed resource allocation for four distinct services,\nshowcasing its effectiveness in complex scenarios that align\nwith our theoretical assertions about the AIGC + SemCom\nframework\u2019s practicality in real-world applications. Addition-\nally, using the DQN is pivotal in determining the most suit-\nable allocation schemes. This strategy efficiently downscales\nsemantics for transmission with the least effect on generated\nimage quality, demonstrating efficient and high-quality content\ncreation. Such results affirm the framework\u2019s efficiency and\nquality standards.\nV. FUTURE RESEARCH DIRECTIONS\nIn this section, we present future research directions related\nto the integration of SemCom and AIGC services:\n\u2022 Development of Universal Evaluation Metrics: Current\nAIGC services present a challenge in creating universal\nevaluation metrics, as different services have varying\nrequirements [2]. A comprehensive metric that quanti-\nfies performance across various AIGC services can be\ndeveloped to provide a consistent performance measure\nindependent of the services. This would enable easier\ncomparison across different services and provide a better\nunderstanding of performance trade-offs in various AIGC\napplications.\n\u2022 Exploration of Low-rank Adaptation (LoRa): Investi-\ngate the application of LoRa, a method that condenses\nlarge language models into smaller, efficient versions\nwithout significant performance loss [14]. By leveraging\nLoRa\u2019s capabilities to optimize image creation and fine-\ntuning, it is possible to enhance the transmission and\ndecoding of semantic information in AIGC services.\nThis approach can improve the accessibility and usability\nof AIGC services in resource-limited environments by\nproviding streamlined and efficient fine-tuning of PFMs,\nmaking the process more standardized and effective.\n\u2022 Development of Lightweight AIGC Services: Adapting\nAIGC services to be more lightweight and efficient for\nmobile edge computing can be a potential direction.\nThis direction focuses on optimizing AIGC algorithms\nto ensure they are resource-efficient and can operate\neffectively in the constrained environments typical of\nedge devices for a better quality of the service [15].\nSuch a method aims to enhance real-time data processing\nand content generation capabilities in edge computing\nscenarios, which could contribute to advancements in\nsmart transportation and connected vehicle technologies.\nVI. CONCLUSION\nThis article has presented a conceptual model for integrating\nSemCom into AIGC services, featuring an additional gen-\neration level for content creation. Our analysis has revealed\nhow modifications in input information extraction, like image\nresolution and compression, can impact AIGC output. The\nintroduced evaluation framework highlighted AIGC\u2019s role in\nsemantic information transmission and facilitated optimized\nresource allocation. Validation through a Deep Q-Network\nconfirmed the feasibility of our framework, promising signif-\nicant efficiency improvements for AIGC services.\nREFERENCES\n[1] Y. Cao, S. Li, Y. Liu, Z. Yan, Y. Dai, P. S. Yu, and L. Sun, \u201cA\ncomprehensive survey of ai-generated content (aigc): A history of\ngenerative ai from gan to chatgpt,\u201d arXiv preprint arXiv:2303.04226,\n2023.\n[2] H. Du, Z. Li, D. Niyato, J. Kang, Z. Xiong, D. I. Kim et al., \u201cEnabling\nai-generated content (aigc) services in wireless edge networks,\u201d arXiv\npreprint arXiv:2301.03220, 2023.\n[3] Y. Lin, Z. Gao, H. Du, D. Niyato, J. Kang, A. Jamalipour, and X. Shen,\n\u201cA unified framework for integrating semantic communication and ai-\ngenerated content in metaverse,\u201d arXiv preprint arXiv:2305.11911, 2023.\n[4] W. Yang, Z. Q. Liew, W. Y. B. Lim, Z. Xiong, D. Niyato, X. Chi, X. Cao,\nand K. B. Letaief, \u201cSemantic communication meets edge intelligence,\u201d\nIEEE Wireless Communications, vol. 29, no. 5, pp. 28\u201335, 2022.\n[5] C. Zhou, Q. Li, C. Li, J. Yu, Y. Liu, G. Wang, K. Zhang, C. Ji, Q. Yan,\nL. He et al., \u201cA comprehensive survey on pretrained foundation models:\nA history from bert to chatgpt,\u201d arXiv preprint arXiv:2302.09419, 2023.\n[6] A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. Voss, A. Radford, M. Chen,\nand I. Sutskever, \u201cZero-shot text-to-image generation,\u201d in Proceedings\nof the 38th International Conference on Machine Learning, ser.\nProceedings of Machine Learning Research, M. Meila and T. Zhang,\nEds., vol. 139.\nPMLR, 18\u201324 Jul 2021, pp. 8821\u20138831. [Online].\nAvailable: https://proceedings.mlr.press/v139/ramesh21a.html\n[7] L. Zhang, A. Rao, and M. Agrawala, \u201cAdding conditional control\nto text-to-image diffusion models,\u201d in Proceedings of the IEEE/CVF\nInternational Conference on Computer Vision, 2023, pp. 3836\u20133847.\n[8] L. Yan, Z. Qin, R. Zhang, Y. Li, and G. Ye Li, \u201cQoe-aware resource\nallocation for semantic communication networks,\u201d in GLOBECOM 2022\n- 2022 IEEE Global Communications Conference, 2022, pp. 3272\u20133277.\n[9] S. Fuster, T. Eftest\u00f8l, and K. Engan, \u201cNested multiple instance\nlearning with attention mechanisms,\u201d CoRR, vol. abs/2111.00947, 2021.\n[Online]. Available: https://arxiv.org/abs/2111.00947\n[10] S. Xie and Z. Tu, \u201cHolistically-nested edge detection,\u201d CoRR, vol.\nabs/1504.06375, 2015. [Online]. Available: http://arxiv.org/abs/1504.\n06375\n[11] A. Hor\u00b4e and D. Ziou, \u201cImage quality metrics: Psnr vs. ssim,\u201d in 2010\n20th International Conference on Pattern Recognition, 2010, pp. 2366\u2013\n2369.\n[12] Y. Benny, T. Galanti, S. Benaim, and L. Wolf, \u201cEvaluation metrics\nfor conditional image generation,\u201d International Journal of Computer\nVision, vol. 129, pp. 1712\u20131731, 2021.\n[13] J. Chen, J. An, H. Lyu, and J. Luo, \u201cLearning to evaluate the artness of\nai-generated images,\u201d arXiv preprint arXiv:2305.04923, 2023.\n9\n[14] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang,\nand W. Chen, \u201cLora: Low-rank adaptation of large language models,\u201d\narXiv preprint arXiv:2106.09685, 2021.\n[15] S. Verma, Y. Kawamoto, and N. Kato, \u201cEnergy-efficient group paging\nmechanism for qos constrained mobile iot devices over lte-a pro net-\nworks under 5g,\u201d IEEE Internet of Things Journal, vol. 6, no. 5, pp.\n9187\u20139199, 2019.\n",
    "2308.15483": "1\nGenerative AI for Semantic Communication:\nArchitecture, Challenges, and Outlook\nLe Xia, Yao Sun, Chengsi Liang, Lei Zhang, Muhammad Ali Imran, and Dusit Niyato\nAbstract\u2014Semantic communication (SemCom) is expected to\nbe a core paradigm in future communication networks, yielding\nsignificant benefits in terms of spectrum resource saving and\ninformation interaction efficiency. However, the existing SemCom\nstructure is limited by the lack of context-reasoning ability and\nbackground knowledge provisioning, which, therefore, motivates\nus to seek the potential of incorporating generative artificial\nintelligence (GAI) technologies with SemCom. Recognizing GAI\u2019s\npowerful capability in automating and creating valuable, diverse,\nand personalized multimodal content, this article first highlights\nthe principal characteristics of the combination of GAI and Sem-\nCom along with their pertinent benefits and challenges. To tackle\nthese challenges, we further propose a novel GAI-integrated\nSemCom network (GAI-SCN) framework in a cloud-edge-mobile\ndesign. Specifically, by employing global and local GAI models,\nour GAI-SCN enables multimodal semantic content provisioning,\nsemantic-level joint-source-channel coding, and AIGC acquisition\nto maximize the efficiency and reliability of semantic reasoning\nand resource utilization. Afterward, we present a detailed im-\nplementation workflow of GAI-SCN, followed by corresponding\ninitial simulations for performance evaluation in comparison with\ntwo benchmarks. Finally, we discuss several open issues and offer\nfeasible solutions to unlock the full potential of GAI-SCN.\nI. INTRODUCTION\nRecently, semantic communication (SemCom) is popular-\nized as an emerging paradigm that promises to significantly\nalleviate the scarcity of communication resources in future\nwireless networks [1]. This is mainly benefited from prosper\nadvancement in deep learning (DL) technologies that can drive\nsemantic encoding and decoding models to achieve efficient\nand high-quality semantic refinement on desired meaning with\nlow spectrum consumption. Moreover, through equipping both\nends of the transceiver with equivalent background knowledge,\nthe implicit meaning in conveyed content can be recovered\nwith ultra-low semantic errors even under harsh channel\nconditions. However, realizing such superiorities obviously\nposes a huge demand on data acquisition for constructing\nbackground knowledge and pre-training DL-driven semantic\nmodels. Meanwhile, considering that the achievable semantic\nperformance is essentially confined by the quality of pre-\ntraining data used, existing SemCom systems still lack suf-\nficient context reasoning capabilities, i.e., accurate semantic\ncalibration and recovery in transmitting multiple complex and\ncoherent contextual fragments.\nLe Xia, Yao Sun (corresponding author), Chengsi Liang, Lei Zhang, and\nMuhammad Ali Imran are with University of Glasgow, United Kingdom;\nDusit Niyato is with Nanyang Technology University, Singapore.\nFortunately, state-of-the-art (SOTA) generative AI (GAI)\nmodels, have lately emerged as killer applications in many\nverticals, promising to bring considerable productivity, innova-\ntion, and economic value to the real-world services as diverse\nas image synthesis, text generation, and drug discovery [2].\nTo be concrete, GAI leverages powerful DL algorithms, such\nas Transformer and diffusion to automate photorealistic and\nmultimodal AI-generated content (AIGC) in response to user-\nprovided prompts, while its fidelity and accuracy are contin-\ngent on adequate pre-training on billions of parameters in large\nlanguage (e.g., ChatGPT) or image (e.g., Dall-E) models. Most\nimportantly, GAI has immense abilities of context-reasoning\nand cross-modal content synthesis to generate high-quality\nand basically correct responses by successfully mimicking\nhuman\u2019s thinking and speaking patterns, enabling users feel\nthat they are interacting with a real human-being rather than a\ndull machine [3]\u2013[6]. Such a milestone innovation stimulates\nus to investigate the potential of applying AIGC into wireless\nSemCom, which hypothesizes to yield the below benefits.\nBetter SemCom Training Efficiency: Undoubtedly, the\ngrowing prosperity of SemCom is inseparable from colossal\ndata resources for semantic model pre-training and background\nknowledge preparation targeting effective semantic interpreta-\ntion [7]. To enable better SemCom training efficiency, GAI\nmodels are capable of producing vast multimodal content with\na certain degree of authenticity and thus should be valuable\nmaterials to semantic training and background knowledge.\nEnhanced Semantic Context-Reasoning: The historical\nAIGC can be stored online and retrieved easily to provision\nsemantic coding models a better understanding for the context\ninformation, thereby offering significant context reasoning and\nsemantic generalization. Furthermore, the creativity of GAI\nmodels can offer high-quality and precise content automati-\ncally for semantic interpretation in SemCom, thanks to the\nPrompt Engineer mechanism [8]. This ensures high semantic\nfidelity even if coding errors occur during joint-source-channel\ncoding (JSCC) or physical signal transmission.\nHigher Spectrum Utilization: Notice that most of AIGC\ncan be produced via inputting only a few prompts, and the\nresponses can be highly precise and specific if the prompts\nare well-crafted to align with a task-oriented communication.\nHence, by utilizing well-trained GAI models, only several\nprompts need to be sent, instead of transmitting the whole\nsource information, in each SemCom process to significantly\ndeduct the required bandwidth resources while retaining the\noriginal meaning.\nDespite many ascendancies offered by the combination of\nGAI and SemCom, it still encounters several inevitable and\narXiv:2308.15483v4  [cs.NI]  13 Aug 2024\n2\nthorny challenges in practical implementation. Among them,\nthe paramount issue is how to deal with such considerable\ncomputing and storage resources required by these large GAI\nmodels. For instance, OpenAI\u2019s product ChatGPT-3 comprises\napproximately 175 billion parameters in total [2], and hence it\nundoubtedly needs to consume colossal computing resources\nto operate the system. Another problem worth pointing out\nhere lies in the reliability and latency aspects. AIGC is\nautonomously created that may lead to uncertainty to some\nextent, while introducing extra delay for data processing as\nwell as data dissemination. To the best of our knowledge, only\na few studies have explored the potential of incorporating GAI\nwith SemCom. For example, the authors in [3] and [9] em-\nployed different deep GAI networks to enhance the perceptual\nquality and semantic reliability for SemCom. Similarly, [10]\nand [11] respectively sought the possibility of using GAI to\nquantify the semantic importance and adapt the end-to-end\ntransmission rate. However, all of these works consider it from\na transceiver design perspective in device-to-device scenarios,\nwhile relevant research for the system framework design in\ngeneral cellular networks is still lacking. To this end, this arti-\ncle focuses on unleashing the full potential of GAI-integrated\nSemCom network (GAI-SCN) across the cloud-edge-mobile\nlayers, and the main contributions are summarized in a nutshell\nas follows:\n\u2022 We first present the basic concept of SemCom and four\nmajor types of GAI technologies, and then provide a com-\nprehensive comparison among traditional communication,\nSemCom, and GAI-integrated SemCom. Next, we present\nthe potential junctions between SemCom and GAI.\n\u2022 We propose a novel GAI-SCN framework that integrates\nglobal and local GAI with semantic coding models in\na collaborative cloud-edge-mobile design. Afterward, we\nshowcase its viable implementation workflow consist-\ning of three successive stages: Initial Network Prepara-\ntion Stage, GAI-integrated SemCom Service Provisioning\nStage, and Model Synchronization and Update Stage.\nMoreover, numerical results validate that the proposed\nframework can save a significant number of transmitted\nbits while maintaining high-precision semantic delivery\ncompared with two benchmarks.\n\u2022 Finally, several open issues with prospects of GAI-SCN\nare outlined, including device hardware limitations, in-\nactive information sharing of users, and potential data\ntampering and privacy leakage.\nII. WHEN SEMCOM MEETS GAI\nIn this section, we first introduce typical technologies of\nSemCom and GAI, as shown in Fig. 1, followed by several\njunctions between them identified and discussed in detail.\nA. SemCom Systems\nCompared with traditional communication of guaranteeing\nthe precise reception of transmitted bits, the accurate deliv-\nery of semantics implied in desired messages becomes the\ncornerstone of SemCom [11]. Taking an end-to-end SemCom\nsystem as the example, a transmitter first leverages background\nknowledge relevant to source messages to filter out irrelevant\ncontent and extract core features that only require fewer bits\nfor transmission, the process of which is called semantic\nencoding. Once the receiver has the required knowledge, its\nlocal semantic interpreters are capable of accurately restoring\nthe original meanings from the received bits, even with intol-\nerable bit errors in data dissemination. This process is called\nsemantic decoding. Consequently, efficient exchanges for the\ndesired information with ultra-low semantic ambiguity can be\nachieved in SemCom under equivalent background knowledge,\nwhile significantly alleviating the resource scarcity problem.\nB. Typical GAI Technologies\nWith proper pre-training and fine-tuning alongside extensive\ndatasets, GAI excels in learning background knowledge and\ncontent structures from input training data, thereby generating\noutputs that closely resemble real-world samples [2]. In what\nfollows, we briefly introduce four basic GAI technologies:\ngenerative adversarial networks (GANs), variational auto-\nencoders (VAEs), diffusion probabilistic models (DPMs), and\nflow-based generative models (FGMs). Note that other tech-\nnologies like Transformer (related to ChatGPT) or the variants\nof these four (related to Dall-E) are equally essential as the\nindispensable components in the most of existing mainstream\nGAI models.\nGANs: The GAN consists of two distinct neural networks:\na generator and a discriminator. In the form of constant con-\ntestation, the goal of generator is to confuse the discriminator,\nwhile the discriminator should distinguish the samples gener-\nated by the generator from the real samples, until reaching a\nstable equilibrium [3]. Although the GAN enables GAI-SCNs\nto output a certain degree of accurate content, it is still not\nsatisfactory enough in terms of semantic quality, generation\ndiversity, and multimodal distribution problem learning.\nVAEs: The VAE is a likelihood-based generative auto-\nencoder model, normally comprising of a multi-layer encoder\nand a symmetric decoder. By taking random training samples\nwith a specific distribution as input, the encoder can regularize\nits coding distribution to ensure good properties of latent\nspace, while the decoder maps from the latent space to the\ninput space so as to produce new data points [4]. When\nit comes to the GAI-SCNs, efficient multi-task SemCom is\nenvisioned to be realized with the support of VAEs.\nDPMs: The DPM is a class of latent variable models,\nand its generation principle mainly includes two processes\nof forward diffusion and reverse diffusion. In the forward\nprocess, the input content is polluted in steps by introduced\nGaussian noise. In comparison of GANs and VAEs, DPMs\nrender remarkable superiority in semantic recovery tasks (e.g.,\nimage denoising, inpainting, and super-resolution), producing\nhigh-quality content and have better resistance to the risk of\nnoise and interference [5].\nFGMs: Differing from the previous models, FGMs are\nexact log-likelihood models with tractable sampling and latent\nvariable inference, which applies a bunch of reversible trans-\nformations to samples from the prior so that log-likelihoods\nof observations can be computed [6]. Besides, it leverages the\n3\nSemantic Encoder\nTransmitter\nPhysical\nChannel\nSemCom Systems\nChannel Encoder\nChannel Decoder\nSemantic Decoder\nSource\nMessage\nRecovered\nMessage\nBackground\nKnowledge\nBackground\nKnowledge\nKnowledge\nSharing\nReceiver\nJSCC\nInterplay between SemCom and GAI\nTypical GAI Technologies\nLatent Space Data\nGenerator\nGenerated\u00a0Data\nReal Space Data\nDiscriminator\nReal\nFake\nReal\nInput\nData\nEncoder neural\nnetwork\nLatent\nData\nDecoder neural\nnetwork\nOutput\nData\nData 1\nData 2\nData n\nData\n\u00a0n+1\nForward Diffusion\nReverse Diffusion\nInput\nData\nFlow neural\nnetwork\nLatent\nData\nInverse neural\nnetwork\nOutput\nData\n(1) Generative Adversarial Networks\n(2) Variational Auto-encoders\n(3) Diffusion Probabilistic Models\n(4) Flow-based Generative Models\nStable\nequilibrium\nBackground \nKnowledge\nProvisioning and\nAlignment\nContent Re-\nconstruction and\nSemantic\nCalibration\nKeyword Extraction\nand Goal \nIdentification\nPublic information\nresources\nPersonalized\nknowledge\nrecords\nKnowledge consistency\nPowerful\nreasoning and\ninformation\nprocessing ability\nPrecise content\nrecovery and\ncompletion ability\nCoding efficiency\nimprovement\nHigh semantic\nfidelity guaranty\nOr\nFig. 1.\nOverview of SemCom systems and four types of typical GAI\ntechnologies along with three aspects of interplay between SemCom and GAI.\nchange-of-variable law of probabilities to transform a simple\ndistribution into a complex one, which greatly facilitates the\nsemantic generation accuracy and communication efficiency.\nC. Interplay between SemCom and GAI\nBased on the above introduction of SemCom systems and\nGAI technologies, herein we list three principal conjunctions\nbetween them with the corresponding elaboration.\nBackground Knowledge Provisioning and Alignment:\nTechnically, GAI can be exploited as valuable data assets for\nusers\u2019 background knowledge provisioning, which is roughly\ndivided into two categories of global knowledge and person-\nalized knowledge. For starters, global knowledge represents\nthe common information publicly available to society (e.g.,\nthe content recorded in books, articles, videos, and other\nonline sources), while personalized knowledge indicates users\u2019\npersonal information (e.g., language habits and communi-\ncation style preferences). Thanks to sufficient pre-training,\nexisting large GAI models like ChatGPT can easily and\nquickly retrieve global knowledge online to be stored as the\ncommon background knowledge of users. More importantly,\nsuch AI-generated global knowledge guarantees information\nconsistency between any pair of communication parties, which\nensures knowledge equivalence in SemCom. As for the per-\nsonalized knowledge, it can be stipulated that GAI models\nstore private conversations with users in the preparation stage\nof SemCom, by which their preferences can be analyzed in the\nbackground so as to offer personalized and customized AIGC\naccording to local environments.\nKeyword Extraction and Goal Identification: Recap that\nthe core of SemCom is meaning delivery, for this purpose,\nGAI models are capable of extracting some keywords from\nthe input long content, and the corresponding communication\ngoal can be identified in a small amount of text (or the\nbounding box of objects in image) through excellent context-\nunderstanding ability. Note that the extracted semantic gran-\nularity with respect to keywords and goals can be flexibly\nadjusted according to the importance of semantic information\ncombined with each user\u2019s personal preference, especially in\nthe task-oriented semantic transmission scenario. Accordingly,\nthe global GAI model (e.g., a stable diffusion model) is trained\nspecifically to restore the original content from received\nkeywords and goals given background knowledge. Moreover,\nfewer communication resources (including wireless bandwidth\nand energy) are demanded, while the pressure from stringent\nlatency requirements is relieved.\nContent Reconstruction and Semantic Calibration: Co-\noperating with the keyword extraction function at the transmit-\nter side, the GAI models deployed either in the core network\nor on the receiver side can realize content reconstruction ac-\ncording to different SemCom goals. Besides, a certain degree\nof semantic ambiguity may inevitably arise in the process\nof signal transmission and semantic interpretation, such as\nwording or sentence structure errors in the delivered text\nand blurred or partially missing tiles in the delivered images.\nTo this end, the initially recovered content after semantic\ndecoding can be input into some GAI models (like GPT-Neo)\nfor fundamental and comprehensive semantic calibration to\nfurther improve the accuracy and reliability of SemCom.\nLesson Learned: The GAI is promising to be integrated\nwith SemCom especially for task-oriented (i.e., meaning\ndelivery-driven) and high-capacity modern entertainment com-\nmunication services, such as mobile virtual reality delivery and\nMetaverse. Notably, although producing AIGC can consume\nsome extra local processing time, the transmission delay is\ngreatly reduced by SemCom in parallel, promising to sig-\nnificantly relieve the latency-cost pressure. Furthermore, we\nspecially compare the system characteristics of GAI-integrated\nSemCom with traditional communication and SemCom along-\nside their respective benefits and limitations, as sketched\nin Fig. 2. Among them, traditional communication is built\non bit-based source-and-channel coding following pre-defined\nand stringent codebooks, while SemCom integrates AI-based\nsemantic encoder and decoder with equivalent background\nknowledge for accurate semantics-aware JSCC. On this basis,\nGAI-integrated SemCom takes full advantage of GAI tech-\nnologies to significantly enhance semantic delivery efficiency\nand ease resource pressure.\nIII. GAI-INTEGRATED SEMCOM NETWORK FRAMEWORK\nA. Hierarchical Structure of GAI-SCN\nConsider a SemCom-enabled cellular network scenario as\ndemonstrated in Fig. 3, where there are multiple terminal\ndevices (TDs) of senders and receivers within the coverage\n4\nTraditional Commu.\nSemCom\nGAI-assisted SemCom\nThree Different Wireless Communication Approaches\nSemantic encoder\nSemantic decoder\nPhysical channel\nChannel encoder\nChannel decoder\nSource info.\nDestination info.\nKnowledge\u00a0sharing\nGAI\nPrompts\nSemantic\ncalibration\nAutomated\nknowledge\ngeneration\nHigh automation and\nflexibility of AIGC;\nEfficient contextual\nsemantic reasoning;\nSupport cross-modal\ncontent conversion;\nOffer personalized and\ncustomized services.\nPros:\nKeyword\nextraction\nUnstable AIGC\ncontrollability and\nlack of authenticity;\nRequire significant\ncomputing and\nstorage resources;\nUnignorable\nprocessing delay.\nCons:\nHighly accurate\ninformation interaction;\nSufficient resilience to\nchannel conditions;\nLow bandwidth\nconsumptions and low\ncommunication delay.\nPros:\nHigh demands for\ncomputing and storage\nresources;\nComplicated module\ndesign;\nStringent requirements\nfor knowledge data.\nCons:\nBroad applicability;\nProven technical\nsupport;\nAdequate information\nprivacy and data\nsecurity.\nPros:\nDemands for high\nbandwidth;\nSusceptible to\nunfavorable wireless\nchannel conditions;\nUnable to support\ncontent transitions\nbetween modalities.\nCons:\npre-defined\ncodebooks\nFig. 2.\nComparisons among three different approaches of GAI-SemCom,\nSemCom, and traditional communication in terms of their pros and cons.\nof base stations (BSs). Among them, multimodal SemCom\nservices (e.g., text, image, and video) with specific communi-\ncation goals consecutively arrive at each TD, and each BS acts\nas the service controller to efficiently schedule and coordinate\nthe goal-oriented SemCom service provisioning. Additionally,\na large GAI model (e.g., GPT-4 or Dall-E) is deployed in\nthe cloud to complete computationally intensive tasks, while\na small one (e.g., GPT-Neo [12]) is embedded in the TD\nfor coping with local lightweight service demands, such as\ncustomized content extraction and text generation services.\nService Provisioning in the Mobile Layer: Each TD is first\nequipped with a light-weight GAI model to realize context-\naware keyword extraction and goal identification, and com-\npared to data compression methods, this takes full advantage\nof the context reasoning ability of GAI to guarantee more\nefficient and intelligent semantic transmission. Through pre-\ntraining on large datasets (like Wikipedia and Common Crawl)\nand fine-tuning on user data (to be more personalized and\ncustomized), GPT-Neo is capable to be directly installed into\nTDs to precisely extract keywords of source information for\nusers and identify the communication goal in only several\nwords, by which fewer bits and smaller latency are consumed\non the transmitter side for data transmission. As for the TDs\non the receiver side, semantic decoders are deployed to recover\nthe delivered meaning from obtained bits, after which the GPT-\nNeo can be further used for semantic calibration or language\ntranslation, etc. Note that the GPT-Neo can be flexibly replaced\nby other SOTA DL-based semantic extraction models, as\nlong as they can efficiently accomplish the task of extracting\nkeywords and goals accurately.\nJSCC Process in the Edge Layer: By enabling sufficient\ncomputing and storage ability in distributed edge servers,\nsemantic encoders are considered to be deployed in the edge\nlayer of GAI-SCN. On one hand, we exploit the JSCC method\nas it is able to greatly improve resilience and robustness of\nSemCom especially against the extreme channel conditions,\nwhere the essential processes like pre-training, fine-tuning,\nand reasoning can be completely handled by edge computing\nservers. On the other hand, considering the large-capacity\nAIGC transmission scenario that requires excessive wireless\nnetwork resources, SemCom can ensure not only the resource\nsavings but also the accurate semantic conveying and recovery\nfor the application-layer counterpart, where related semantic\ncoding tasks can be also offloaded to edge servers.\nAIGC Acquisition in the Cloud Layer: Based on the\nabove mobile and edge layer designs, the generation of AIGC\nbecomes an indispensable process for smooth SemCom. In\nthe proposed GAI-SCN, a centralized infrastructure, i.e., the\nremote cloud server, can support and run large GAI models\nlike Google Bard or Microsoft Bing Chat. All preparation\nprocesses related to the AI model itself, such as pre-training\nand fine-tuning, are accomplished in the cloud. Likewise, the\ncollection, analysis, and reasoning for multi-users\u2019 personal\ninformation and preferences can be realized in real time by\nleveraging the massive computing and storage resources of the\ncloud servers. Moreover, according to the specific keywords\nand goals uploaded from sender TDs, these large GAI models\ncan quickly and correctly create the response content of\ndesired modes. The rationale behind this is due to the historical\nconversation record, i.e., referred to as context, between users\nand GAI servers, which provides reference information for\nmodels\u2019 understanding and inference. Therefore, the original\nmeaning implied in the delivered keywords can be recovered\nto intact text or image content.\nLesson Learned: By adopting the above collaborative cross-\nlayer GAI-SCN framework, both link-level wireless resource\nutilization and application-layer performance (e.g., satisfaction\nof user semantic provisioning) can be maximized. Particu-\nlarly, JSCC-based SemCom is a very appropriate solution\nto ensure not only resource savings but also accurate key\nsemantics conveying and recovery for the application-layer\ncounterpart. Note that our proposed GAI-SCN does not assume\nthe common phenomenon of signal transmission inconsistency\nin SemCom, but instead, its whole design is based on the\nconsideration of how to accurately transmit and recover the\ncore semantics between the source and destination. Besides,\nalthough the usage cost of GAI-SCN is higher than traditional\ncommunication or general SemCom, the savings in commu-\nnication resources (e.g., spectrums and communication delay)\nand the promotion in communication quality (e.g., semantic\ntransmission efficiency and resilience to signal distortion)\nshould be considerable as well. Most importantly, the global\nGAI is placed in the cloud that is generally computing-\nresource-unlimited, while semantic coding models are preset\nas maturely trained in advance that means the related training\ncosts are not counted into the budget.\nB. Implementation Workflow\nBy revisiting the key rationales of GAI-SCN, we now\nshowcase its workflow below step-by-step to guide network\ndesigners to make proper changes on relevant protocols, as\nshown in Fig. 4.\n5\nGlobal generative\nAI models\u00a0\n(e.g. GPT-4, Dall-E)\n...\nMutimodal AI\ngenerative content\u00a0\nText\nImage\nAudio\nSemantic features\nRendered\ncontent\n\nSemantic\nEncoder\nLocal generative \nAI models\u00a0\nSemantic\nDecoder\nInitially\nrecovered info.\nSemantic\ncalibration\nBS (at the transmitter side)\nBS (at the receiver side)\nMEC Server\nReceivers\nTraditional Commu.\u00a0\nSemCom (with JSCC)\nPeriodic update &\nsynchronization\nCloud\nLayer\nEdge\nLayer\nMobile\nLayer\nKeywords\n& Goals\nSource\ncontent\nLocal generative \nAI models\u00a0(e.g. GPT-Neo)\nIdentification\nKeywords\nwith communication\ngoals\n...\nSenders\n...\nBackground\nKnowledge of\neach user\nSharing for model\nfine-tuning\nSharing for\nsemantic encoder\nSharing for local\ngenerative AI &\nsemantic decoder\nAn\u00a0exemplification of\nimage service provisioning\nin the GAI-SCN\u00a0\nSource Image\n(the sender side)\nImage of AIGC\n(the cloud/edge side)\nRecovered Image\n(the receiver side)\n\"A large brown\nbear is walking\nthrough a\nforest.\"\nK: \"a large brown\nbear\", \"walking\",\n\"forest\"\nImplicit\nSemantics\nExtracted\nKeywords&Goal\nG: \"Image-based\nAIGC service\"\nPublic data\nresources (e.g.,\nbooks, news)\nCollecting for\npre-training\n\u2460\n\u2461\n\u2462\n\u2463\n\u2464\n\u2465\n\u2466\n\u2467\nFig. 3. Illustration of the proposed GAI-SCN framework in a collaborative cloud-edge-mobile design, where an exemplification of image service provisioning\nis presented.\nInitial Network Preparation Stage: In this stage, the con-\nstruction, pre-training and fine-tuning of GAI models are im-\nplemented collaboratively across the cloud and mobile layers.\nNote that all AI models are well pre-trained under society data\npublic to users in the first place. Subsequently, considering the\npreference discrepancy between different users, personal data\nare collected by local GAI and then shared with global GAI in\nthe cloud. Next, multiple parallel branch models corresponding\nto multiple users are created and fine-tuned based on personal\ndata, where the branch model refers to a design pattern about\nmultiple paths or subnetworks to make different predictions.\nAfterward, all parameters trained in each branch model are\ndownloaded into the local light-weight GAI model related to\neach user, so as to avoid the drawback of limited computing\nability in mobile TDs. Apart from the above, the construction\nand joint pre-training of semantic encoders and decoders\nare also completed in advance given specific channel state\ninformation. Keeping in mind the requirement of knowledge\nequivalence in SemCom, knowledge sharing between encoders\nand decoders is required if the condition is triggered [7].\nGAI-Integrated SemCom Service Provisioning Stage:\nOnce all communication parties in the GAI-SCN are equipped\nwith mature-trained AI models, the SemCom transmission\nservices begin. The local GAI model first extracts keywords\nand identifies the explicit goal (referring to the exemplification\nin Fig. 3) for each user. Hereafter, such keywords and goals are\nuploaded via traditional communications to global GAI models\nin the cloud layer as input prompts, so that the corresponding\nbranch AI model can create AIGC in line with the user\npreference to recover the original meaning with the original\nmodality.\nWhen it comes to the downlink side, each edge server\ndetects the current wireless channel state and analyzes the\nreceived AIGC service-related signaling to select an appro-\npriate pre-trained semantic encoder. As such, the entire AIGC\nis smoothly encoded into semantic features to be transmitted\nto the corresponding TD. Since semantic errors may still\noccur in the above JSCC process due to potential signal\nimpairment and the limited computing power of TD, under\nthe assistance of personalized knowledge and user preference,\nits local generative-AI model is utilized for further semantic\ncalibration, such as error correction for text content, color\nrendering for image content, and frame completion for video\ncontent, to enhance the resilience and robustness against\nsemantic ambiguity for SemCom.\nModel Synchronization and Update Stage: At the end\nof each GAI-integrated SemCom process, the service expe-\nrience feedback (i.e., the user satisfaction regarding service\nperformance, availability, and accessibility, etc.) is collected\nfrom each user and cached in the associated edge server. The\nfeedback data as well as real-time user transmission data are\nsynced periodically from the edge layer to the GAI models\ndeployed in the other two layers. In this way, GAI analyzes and\npredicts users\u2019 up-to-date preferences by fine-tuning model\n6\nInitial\u00a0Network\nPreparation Stage\n\nHistorical user data sharing\nUser data packets uploading\nModel parameter\ndownloading\nTransfer learning\nBackground knowledge\nequivalence checking\nKnowledge sharing request\n\u00a0 \u00a0 \u00a0 \u00a0\t\t\n\u00a0 \u00a0 \u00a0 (if necessary)\nKnowledge sharing\nKnowledge equivalence\nacknowledgement\nKeywords and service\ngoals uploading\nService data uploading and\nAIGC service request\nCreate multiple\u00a0generative\nAI branch models to realize\npersonalization for users;\nFine-tune each branch model\nbased on collected data from\neach individual user.\nInput keywords and goals as\nprompts into generative AI\nbranch models for each user;\nPre-train local AI generative\nmodels;\nHistorical user data collection\nfor preference analysis.\nFine-tune local generative AI\nmodels;\nPre-train semantic decoders\nbased on prepared KBs.\nEncapsulation of required\nknowledge.\nSemCom service arrival.\nExtract keywords and iden-\ntify explicit goals via local\ngenerative AI models.\nDetect current channel state\nand analyze received AIGC\nservice-related signaling;\nEncode AIGC via suitable\nsemantic encoders.\nAIGC downloading\u00a0\nSemantic features\ndownloading\nRecover content via suitable\nsemantic decoders;\nSemantic calibration via local\ngenerative AI models.\nCollect\u00a0service experience\nfeedback and up-to-date user\npreference.\nUsers' new data uploading\n\nUpdate related parameters\nin semantic encoder as\nwell as the linked\nbackground knowledge.\nUsers' new data uploading\nPredict up-to-date user data\nby fine-tuning model para-\nmeters and structures based\non the received feedback.\nTransfer learning\nModel download\nCloud/Core Networks\n(Global Generative AI\nModels)\nTDs of Mobile Users\n(Local Generative AI &\nSemantic Decoder Models)\nBS & MEC Server\n(Semantic Encoder Models)\nGenerative AI-\nAssisted SemCom\nService\nProvisioning Stage\nModel\nSynchronization\nand Update Stage\nPre-train global AI generative\nmodels.\nUser data encapsulation and\npackaging.\nIf successful, feedback ack-\nnowledgement information.\nIf failed, request knowledge\nsharing until successful, and\nthen pre-train semantic\nencoders via JSCC.\nKnowledge downloading\nrequest (if necessary)\nKnowledge downloading\nSemCom service\nacknowledgement\nRetrieve and encapsulate the\nrequired knowledge.\nEncapsulate and package all\nreceived keywords and goals.\nProduce AIGC in line\nwith\u00a0the user preference to\nrecover the original meaning\nwith the original modality.\nBackground knowledge\nupdating\nUpdate background know-\nledge and local semantic\ndecoders in the TDs.\nFig. 4. A schematic diagram of implementing a complete round of semantic service provisioning in the GAI-SCN, including three successive stages of Initial\nNetwork Preparation, Generative AI-integrated SemCom Service Provisioning, and Model Synchronization and Update.\nparameters and structures. Meanwhile, the data are also fed\nback to semantic models to update the relative parameters as\nwell as the linked background knowledge.\nIV. CASE STUDY: IMAGE TRANSMISSION SERVICE\nPROVISIONING IN GAI-SCN\nIn this section, numerical results for a case study of image\ntransmission are presented to evaluate the initial performance\nof the proposed GAI-SCN framework. For the simulation\nsettings, an image-captioning model by combining ViT model\nwith GPT-2 model [13] is exploited as the local GAI to\nrealize the image-to-text transformation as well as the keyword\nextraction and goal identification. Besides, we employ the\nlatest text-to-image model called Stable Diffusion 2.1 [5]\nas the global GAI to create the AI-generated images from\nreceived prompts. As for the SemCom part, the main setups\nare proceeding as in the work [7], where an advanced deep\nconvolutional network named Observation-Centric Sort and\na Transformer-powered semantic decoder are leveraged for\nsemantic segmentation and recovery, respectively. Meanwhile,\nall semantic models are trained based on the additive white\nGaussian noise channel with a signal-to-noise ratio (SNR)\nof 0 dB to transmit 327 images with different contents for\ntesting. Finally, the Adam optimizer is adopted to train the\nneural networks in GAI-SCN with an initial learning rate of\n5 \u00d7 10\u22124 based on the given image dataset. In parallel, for\ncomparison purposes, we utilize two benchmarks: 1) A GAI-\nintegrated traditional communication scheme, where the AIGC\nis encoded into bits based on the variable length source coding\nand LDPC channel coding [14] for precise image delivery;\n2) A typical SemCom scheme [1], [3], which transmits the\noriginal images via only DL-based semantic coding and JSCC\nwithout any involvement of GAI.\nFigure 5 first demonstrates the performance of GAI-SCN\nby comparing the recovered images with the original ones\nunder different numbers of observable objects that can be\ndetected and segmented (such as \u201cbear\u201d, \u201ctree\u201d, and \u201cground\u201d\nas shown in the exemplification image in Fig. 3). Note\nthat the appearances of the transmitted images may be not\ncompletely consistent with the received ones, however, the\nsemantics implicit in the content should be our sole focus\nin measuring the system performance. Herein, we first test\nthe semantic similarity performance measured by spaCy [15],\nwhere generally, the higher the spaCy score, the more accurate\nthe recovered semantics. Due to the cross-layer design of our\nproposed GAI-SCN framework, semantic similarity is actually\nan application-layer indicator to measure the degree of user\nsemantic provisioning, which should be distinguished from\n7\n1~3\n4~6\n7~9\n10~12\n13~15\nNumber of observable objects in original images\n91\n92\n93\n94\n95\n96\nA: Semantic similarity by spaCy (%)\nA\n1\n2\n3\n4\n5\n6\nB: Object quantity discrepancy\nB\n40\n50\n60\n70\n80\nC: Recovery ratio of original objects (%)\nC\nFig. 5. Comparisons between original and recovered images by the proposed\nGAI-SCN framework in terms of three metrics: A) Semantic similarity by\nspaCy; B) Object quantity discrepancy; C) Recovery ratio of original objects.\nTABLE I\nAMOUNT OF BITS REQUIRED AND THE PSNR PERFORMANCE IN\nTRANSMITTING 300 IMAGES ON THE DOWNLINK (1024 \u22171024 PIXELS)\nDifferent image\ntransmission schemes\nNumber of required\nbits for downlink\nPSNR\nGAI-integrated traditional\ncommunication [14]\n1.28 \u00d7 105\n28.05\nSemCom [1]\n5.99 \u00d7 104\n28.25\nGAI-SCN\n3.03 \u00d7 104\n28.64\nlower-level technical indicators such as bit/symbol error ratios.\nParticularly, the error occurs at the bit/symbol level does not\nnecessarily imply an error at the semantic level, while there\ncould be errors at the semantic level even if there is no error\nat the bit level. The former is owing to the powerful semantic\nreasoning ability of semantic models and the assistance of\nperfectly matching background knowledge, and the latter is\nbecause of the potential background knowledge discrepancy\nbetween the sender and the receiver. Back to Fig. 5, it is\nobserved that the increasing number of objects in original\nimages results in a decreasing semantic similarity, which is\nbecause that the higher complexity of images makes GAI\nmore difficult to extract the keywords correctly as well as the\nimage recovery. This phenomenon is also consistent with the\nrecovery ratio performance of original objects, which metric\nshows the proportion of objects accurately recovered in the\nAIGC, and as the complexity of images rises, the average\nrecovery ratio drops from 82.2% to 41.8% steadily. Moreover,\nwe can see a lower object quantity discrepancy with fewer\nnumber of objects contained in the transmitted images. All\nof these trends above represent that semantic ambiguity is\nmore likely to occur in regenerating more complex images\ndue to confusing key object identification and a certain degree\nof semantic interference.\nBesides the above AI-generated quality measurement, the\nproposed GAI-SCN is further tested from the wireless trans-\nmission perspective. Table I shows the number of bits re-\nquired and the image transmission performance achieved to\ndownlink 300 images with the equal size of 1024 \u22171024\npixels in the same 0 dB SNR Gaussian noise channel. For\ntractability, the peak signal-to-noise ratio (PSNR) is employed\nhere to compare the images before and after performing\ndifferent transmission schemes, noting that other image quality\nevaluation metrics like structural similarity index can also\nbe adopted. Moreover, since we concentrate only upon the\ndiscrepancy in transmitted content (AIGC vs. original) and\ncommunication technology used (SemCom vs. traditional), the\nsame source and channel coding rules are assumed for all\nschemes to encode the images from the pixel/semantic level\nto the bit level. It can be found that the proposed GAI-SCN\nonly requires 3.03 \u00d7 104 bits, which reduces 2.96 \u00d7 104 bits\ncompared with the SemCom scheme and 9.77 \u00d7 104 bits with\nthe GAI-integrated conventional scheme. Furthermore, the\nPSNR score obtained by our GAI-SCN maintains a very high\nlevel of 28.64, which is even slightly better than the other two\napproaches. This can be explained by the fact that the typical\nSemCom scheme starts the image delivery process from the\nuplink direction, which increases the risk of image sharp-\nness loss, while the GAI-integrated traditional communication\nscheme is less resilient to harsh channel conditions compared\nwith GAI-SCN. In summary, the above results demonstrate\nthat our GAI-SCN can further save bandwidth resources while\nguaranteeing very high-quality SemCom service provisioning\nwith accurate semantic delivery.\nV. OPEN RESEARCH ISSUES AND OUTLOOKS\nIn this section, we list several thorny issues and outlooks\nthat can be highlighted as future research directions in the\nGAI-SCN.\nLimited Device Resources for Supporting AI Modules:\nIn the GAI-SCN, sophisticated AI-enabled computing modules\n(including local GAI models and SemCom coding models)\nneed distributed implementation at each TD, imposing a heavy\nburden on its inherently limited device resources (like storage,\nmemory, computational units, and battery power). To make it\npractically implementable, advanced model compression and\nacceleration technologies, such as knowledge distillation, pa-\nrameter pruning and quantization, are promising to efficiently\ndrop the complexity and size of AI networks with an affordable\ncost of performance degradation.\nRandomness of Content Rendered in GAI-SCN: Notice\nthat the appearance of AIGC output from the cloud GAI may\nvary even given the same keywords and goals. Besides, the\nrepresentation of semantics recovered via the semantic decoder\nalso have uncertainty to some extent, due to the knowledge\nmismatching or semantic errors. Therefore, granularity tuning\non keyword extraction and subsequent semantic calibration\ndeserve further investigation to tackle such randomness.\nInactive Sharing of Background Knowledge and Per-\nsonal Preferences: Since the prerequisite of customized AIGC\nand SemCom services mainly lies in the proactive sharing\nof users\u2019 personal preferences and background knowledge,\ndevising a scores- or rewards-based incentive mechanism, such\nas delegated proof of stake-based blockchain, is necessary to\nattract users to spontaneously contribute personal data to the\nupgrading of GAI-SCN, where potential reward alternatives\ninclude social welfare and tech benefits, etc.\n8\nVI. CONCLUSIONS\nThis article explored the potential of applying AIGC into\nSemCom for service provisioning, where we first showcased\nthe development of SemCom and GAI technologies with their\nintegration cases, and then proposed the GAI-SCN framework.\nSpecially, the collaborative cloud-edge-mobile structure was\nwell-devised to incorporate both global and local GAI models\nwith the JSCC process, which not only enables efficient and\nhigh-quality meaning delivery, but also significantly reduces\ntransmission traffic as well as latency. Moreover, implemen-\ntation alongside initial simulations was provided, followed\nby associated open issues and corresponding solutions. We\nhope that our GAI-SCN serves as a pioneer in facilitating\ncommunication resource usage as well as user experience\nfor futuristic context-aware and GAI-based wireless SemCom\nnetworks.\nREFERENCES\n[1] D. Huang, X. Tao, F. Gao, and J. Lu, \u201cDeep Learning-Based Image\nSemantic Coding for Semantic Communications,\u201d in 2021 IEEE Global\nCommunications Conference (GLOBECOM). IEEE, 2021, pp. 1\u20136.\n[2] M. Xu, H. Du, D. Niyato, J. Kang, Z. Xiong, S. Mao, Z. Han, A.\nJamalipour, D. I. Kim, V. Leung et al., \u201cUnleashing the Power of Edge-\nCloud Generative AI in Mobile Networks: A Survey of AIGC Services,\u201d\nIEEE Communications Surveys & Tutorials, 2024.\n[3] E. Erdemir, T.-Y. Tung, P. L. Dragotti, and D. G\u00a8und\u00a8uz, \u201cGenerative\nJoint Source-Channel Coding for Semantic Image Transmission,\u201d IEEE\nJournal on Selected Areas in Communications, 2023.\n[4] D. P. Kingma, M. Welling et al., \u201cAn Introduction to Variational\nAutoencoders,\u201d Foundations and Trends\u00ae in Machine Learning, vol. 12,\nno. 4, pp. 307\u2013392, 2019.\n[5] Z. J. Wang, E. Montoya, D. Munechika, H. Yang, B. Hoover, and D. H.\nChau, \u201cDiffusionDB: A Large-scale Prompt Gallery Dataset for Text-\nto-Image Generative Models,\u201d arXiv preprint arXiv:2210.14896, 2022.\n[6] D. Rezende and S. Mohamed, \u201cVariational Inference with Normalizing\nFlows,\u201d in International Conference on Machine Learning. PMLR, 2015,\npp. 1530\u20131538.\n[7] L. Xia, Y. Sun, C. Liang, D. Feng, R. Cheng, Y. Yang, and M. A. Imran,\n\u201cWiserVR: Semantic Communication Enabled Wireless Virtual Reality\nDelivery,\u201d IEEE Wireless Communications, vol. 30, no. 2, pp. 32\u201339,\n2023.\n[8] V. Liu and L. B. Chilton, \u201cDesign Guidelines for Prompt Engineering\nText-to-Image Generative Models,\u201d\nin Proceedings of the 2022 CHI\nConference on Human Factors in Computing Systems, 2022, pp. 1\u201323.\n[9] C. K. Thomas and W. Saad, \u201cNeuro-Symbolic Causal Reasoning Meets\nSignaling Game for Emergent Semantic Communications,\u201d IEEE Trans-\nactions on Wireless Communications, 2023.\n[10] S. Guo, Y. Wang, S. Li, and N. Saeed, \u201cSemantic Importance-Aware\nCommunications Using Pre-Trained Language Models,\u201d IEEE Commu-\nnications Letters, 2023.\n[11] S. Barbarossa, D. Comminiello, E. Grassucci, F. Pezone, S. Sardellitti,\nand P. Di Lorenzo, \u201cSemantic Communications Based on Adaptive\nGenerative Models and Information Bottleneck,\u201d IEEE Communications\nMagazine, vol. 61, no. 11, pp. 36\u201341, 2023.\n[12] R. Kashyap, V. Kashyap et al., \u201cGPT-Neo for Commonsense Reasoning-\nA Theoretical and Practical Lens,\u201d arXiv preprint arXiv:2211.15593,\n2022.\n[13] Y. Shen, K. Song, X. Tan, D. Li, W. Lu, and Y. Zhuang, \u201cHuggingGPT:\nSolving AI Tasks with ChatGPT and its Friends in HuggingFace,\u201d arXiv\npreprint arXiv:2303.17580, 2023.\n[14] Z. Cai, J. Hao, P. Tan, S. Sun, and P. Chin, \u201cEfficient Encoding of IEEE\n802.11 n LDPC Codes,\u201d Electronics Letters, vol. 42, no. 25, p. 1, 2006.\n[15] Y. Vasiliev, Natural Language Processing with Python and spaCy: A\nPractical Introduction.. No Starch Press, 2020.\nLe Xia (l.xia.2@research.gla.ac.uk) received his Ph.D degree from the James\nWatt School of Engineering, University of Glasgow, UK. His research inter-\nests include semantic communications, NextG wireless networking, resource\nmanagement, AI for wireless, and smart vehicular networks.\nYao Sun (Yao.Sun@glasgow.ac.uk) is currently a Lecturer with the James\nWatt School of Engineering, the University of Glasgow, UK. His research\ninterests include semantic communications, intelligent wireless networking,\nand wireless blockchain system.\nChengsi Liang (2357875l@student.gla.ac.uk) is currently pursuing her Ph.D.\ndegree with the James Watt School of Engineering, University of Glasgow,\nUK. Her research interest includes semantic communication and networking.\nLei Zhang (Lei.Zhang@glasgow.ac.uk) is a Professor at the University of\nGlasgow. He has academia and industry combined research experience on\nwireless communications and networks, and distributed systems for IoT,\nblockchain, autonomous systems. He is the founding Chair of IEEE Special\nInterest Group on Wireless Blockchain Networks in Cognitive Networks\nTechnical Committee.\nMuhammad Ali Imran (Muhammad.Imran@glasgow.ac.uk) is a Professor of\ncommunication systems with the University of Glasgow, UK, and a Dean with\nGlasgow College UESTC. He is also an Affiliate Professor with the University\nof Oklahoma, USA, and a Visiting Professor at University of Surrey, UK. He\nhas over 20 years of combined academic and industry experience with several\nleading roles in multi-million pounds funded projects.\nDusit Niyato (dniyato@ntu.edu.sg) is a professor in the School of Computer\nScience and Engineering, at Nanyang Technological University, Singapore. He\nreceived Ph.D. in Electrical and Computer Engineering from the University\nof Manitoba, Canada in 2008. He has published more than 400 technical\npapers in the areas of wireless and mobile computing, sustainability, edge\nintelligence, decentralized machine learning, and incentive mechanism design.\nHe was a Distinguished Lecturer of the IEEE Communications Society from\n2016 to 2017. He is a Fellow of IEEE.\n",
    "2310.17705": "1\nA Wireless AI-Generated Content (AIGC)\nProvisioning Framework Empowered by Semantic\nCommunication\nRunze Cheng, Graduate Student Member, IEEE, Yao Sun, Senior Member, IEEE, Dusit Niyato, Fellow, IEEE,\nLan Zhang, Member, IEEE, Lei Zhang, Senior Member, IEEE, and Muhammad Imran, Fellow, IEEE\nAbstract\u2014Generative AI applications have been recently cater-\ning to a vast user base by creating diverse and high-quality\nAI-generated content (AIGC). With the proliferation of mobile\ndevices and rapid growth of mobile traffic, providing ubiquitous\naccess to high-quality AIGC services via wireless communication\nnetworks is becoming the future direction. However, it is challeng-\ning to provide qualified AIGC services in wireless networks with\nunstable channels, limited bandwidth resources, and unevenly\ndistributed computational resources. To tackle these challenges,\nwe propose a semantic communication (SemCom)-empowered\nAIGC (SemAIGC) generation and transmission framework,\nwhere only semantic information of the content rather than all\nthe binary bits should be generated and transmitted by using\nSemCom. Specifically, SemAIGC integrates diffusion models\nwithin the semantic encoder and decoder to design a workload-\nadjustable transceiver thereby allowing adjustment of compu-\ntational resource utilization in edge and local. In addition, a\nresource-aware workload trade-off (ROOT) scheme is devised\nto intelligently make workload adaptation decisions for the\ntransceiver, thus efficiently generating, transmitting, and fine-\ntuning content as per dynamic wireless channel conditions and\nservice requirements. Simulations verify the superiority of our\nproposed SemAIGC framework in terms of latency and content\nquality compared to conventional approaches.\nIndex Terms\u2014AI-generated content, Semantic communication,\nDiffusion model, Intelligent workload adaptation\nI. INTRODUCTION\nD\nRIVEN by recent advancements in deep learning and\ncomputing hardware, generative AI has demonstrated\nremarkable strides in analyzing various forms of media and\ncreating AI-generated content (AIGC) [1]. For the delivery of\nhigh-quality content, well-crafted AIGC models have evolved\nto maintain millions of parameters within their neural net-\nworks. This feat can necessitate a large-scale server devouring\nthousands of hours of graphics processing unit (GPU) time in\na single model training session [2]. Limited by the computing-\nintensive nature of AIGC, existing AIGC applications, includ-\ning notable products like ChatGPT, DELL-R-2, and ERNIE\nRunze Cheng, Yao Sun, Lei Zhang, and Muhammad Ali Imran are with\nthe James Watt School of Engineering, University of Glasgow, Glasgow G12\n8QQ, U.K.\nDusit Niyato is with the School of Computer Science and Engineering,\nNanyang Technological University, 639798, Singapore.\nLan Zhang is with the Department of Electrical and Computer Engineering,\nClemson University, 29634, South Carolina, United States.\nThe\ncorresponding\ncode\ncan\nbe\nfound\nat\nhttps://github.com/\nRoyChengsCode/SemAIGCtransceiver.git.\nYao Sun is the corresponding author. (Email: Yao.Sun@glasgow.ac.uk)\nBot, predominantly find their home on cloud servers equipped\nwith ample computational resources [3].\nA. Background: AIGC in Wireless\nDue to the rapid development of mobile technology and\nthe increasing adoption of smartphones, tablets, and other\nmobile devices, the percentage of global Internet traffic on\nwireless devices has surged over the past decade. In 2022,\nit was estimated that there were over 15 billion wireless\ndevices worldwide, which contributed 55% of global Internet\ntraffic [4]. In this background, many AI companies are actively\nstrategizing and positioning themselves in the realm of wire-\nless device-oriented AIGC applications. However, wireless\nAIGC services demand strict requirements on content quality\nand latency, which pose significant challenges under dynamic\nwireless channels. Moreover, these services often grapple\nwith limited communication resources (like bandwidth, and\nhigh-quality channels) and unevenly distributed computational\nresources in wireless networks. Therefore, more efficient and\naccessible AIGC generation and transmission frameworks are\nrequired for wireless AIGC service provisioning.\nRecently, a few studies about wireless AIGC generation\nand transmission have been conducted to improve the uti-\nlization of unevenly distributed computational resources. The\nauthors in [5] propose a wireless AIGC network architecture\nwhere cloud servers primarily handle computationally inten-\nsive AIGC model pre-training. Additionally, it offloads content\ngeneration tasks from cloud servers to edge transmitters. In\n[6], a dynamic AIGC service provider selection scheme is\nproposed in an intelligent wireless AIGC network to enable\nusers to connect to the provider with suitable edge servers\nand enough computational resources. Considering the limited\nbandwidth resources and dynamic channel quality, the authors\nin [7] develop a pricing-based incentive mechanism for AIGC\ngeneration and transmission framework to maximize users\u2019\nutility in mobile edge networks. These existing works didn\u2019t\naddress the insufficient communication resources in wireless\nnetworks when coping with the potentially overwhelming\nnumber of service requests.\nIn parallel, some research works aim to deploy AIGC\nmodels in local devices to address the communication resource\nshortage in the wireless network. Lightweight AIGC models\nhave been tested and certified in works [8], [9], thus it is\nbecoming possible to deploy AIGC models on local mo-\nbile devices with limited computational resources. Under this\narXiv:2310.17705v2  [cs.NI]  29 May 2024\n2\npremise, a novel collaborative distributed AIGC framework is\nconceptualized in [10], which allows smartphones to process\nthe diffusion model locally in an edge server-empowered\nwireless AIGC network. In this way, less content is transmitted\nfrom edge to local, thus the pressure of communication\nresources is relieved. However, considering the computational\nresource limitation of mobile devices, the generated content\nquality and content-generating latency are difficult to ensure.\nB. Motivation\nTo explore an AIGC service provisioning framework in\nwireless networks, it is required to meet diverse service re-\nquirements under limited communication resources, unevenly\ndistributed computational resources, and dynamic channel\nquality. In this case, semantic communication (SemCom) is a\npotential technique to empower wireless AIGC provisioning.\nSemCom, aims to effectively transmit necessary semantic\ninformation of source message, as opposed to the accurate\nreception of every single binary bit without considering its\nmeaning [11]\u2013[14]. Empowered by SemCom, the generated\nsemantic information from the AIGC model can be transmit-\nted instead of the entire bits of content, and the pressure\nof communication resources, especially bandwidth, can be\nrelieved with a slim data size [15]. Meanwhile, the receiver\naccurately interprets semantic information from transmitted\nbits and reduces semantic distortion caused by channel noise,\nthus improving transmission reliability at a semantic level\nand allowing for suitable AIGC services over harsh wireless\nchannels [16]. With these superiorities, combining SemCom\nwith generative AI models is promising to provide AIGC\nservice over wireless networks with limited communication\nresources and unevenly distributed computational resources.\nHowever, resources in wireless networks, such as band-\nwidth, GPU/CPU cores, and computational power, are often\nwith dynamic availability. Therefore, it is inefficient to directly\nintegrate SemCom and AIGC with a fixed encoder and decoder\nstructure, where the AIGC model is merely deployed within\nthe encoder side or decoder side. This fixed structure makes\nthe encoder/decoder unable to adjust the computing workloads\naccording to the resource availability. Furthermore, in the fixed\nstructure of the encoder and decoder, the semantic density\nis unadjustable, causing a high semantic noise ratio under\nbad channel conditions, thereby posing additional denoising\ndifficulty in decoding. Meanwhile, users may have varying\nservice requirements, such as latency and content quality,\nwhen accessing various AIGC services. Since the semantic\ncomputing workloads and semantic density are unadjustable in\nthe transceiver, meeting these requirements becomes another\ndifficulty.\nIn response to the unsolved difficulties, deploying diffusion\nmodels in both edge and local, and employing machine learn-\ning (ML) in the joint AIGC generation and transmission is a\npotential solution. The diffusion models, as popular generative\nAI models, are utilized to denoise irrelevant information from\npure Gaussian noise and finally retain valid information of\ncontent like text [17], audio [18], or image [19]. By deploying\ndiffusion models into the encoder and decoder, it is promising\nto develop a workload-adjustable transceiver, in which the\nsemantic information can be generated within both edge and\nlocal. Simultaneously, ML is capable of intelligently deciding\nthe denoising steps of the encoder and decoder as per resource\navailability and channel quality, i.e., optimizing the workload\nadaptation, thus meeting the content generation latency re-\nquirement [20]. Furthermore, semantic density can also be\noptimized to reduce the semantic noise ratio, thus efficiently\nensuring that the content quality is consistent and satisfies the\nrequirements under varying channel qualities.\nC. Contributions and Organization\nIn this paper, to narrow down our focus, we delve specif-\nically into image-based AIGC service provisioning over\nwireless networks. We first propose a SemCom-empowered\nAIGC (SemAIGC) framework, in which a workload-adjustable\ntransceiver is deployed to jointly generate and transmit images,\nand a resource-aware workload trade-off (ROOT) scheme is\ndeveloped to intelligently make workload adaptation decisions\nfor transceiver. Simulation results demonstrate the effective-\nness and robustness of our proposed SemAIGC under dynamic\nresource availability, varying channel quality, and diverse\nservice requirements. The main contributions of the paper are\nsummarized as follows:\n\u2022 To address communication and computational resource\nconstraints, we exploit SemCom and AIGC to propose a\nwireless SemAIGC framework, which pre-trains models\nat the cloud, extracts and generates semantic information\nat the edge, and uses SemCom to transmit semantic\ninformation to local for fine-tuning and restructuring.\n\u2022 We modify the diffusion models to design a workload-\nadjustable AIGC transceiver in the SemAIGC framework.\nIn this way, the workload at both the transmitter and\nreceiver sides can be adjusted by changing the denoising\nsteps as per the available resources, channel condition,\nand service requirements.\n\u2022 We theoretically prove that the modified diffusion model\ndeployed at the receiver to can denoise the semantic noise\ncaused by the wireless channel.\n\u2022 In order to optimize the workload adaption in SemAIGC,\nwe formulate the problem as a Markov decision process\n(MDP) by considering dynamic resource availability, dy-\nnamic channel quality, and diverse AIGC service require-\nments. We then propose a dueling double deep Q network\n(D3QN)-based ROOT scheme to solve the problem and\nintelligently make the workload adaptation decisions.\nThis paper is organized as follows. In Section II, we present\nthe SemAIGC framework, followed by the design of edge\ntransmitter and local receiver in Section III. The ROOT scheme\ndesign for the workload-adjustable transceiver is elaborated\nin Section IV. Then, we evaluate the performance gain of\nthe SemAIGC framework and ROOT scheme in Section V.\nSection VI concludes the paper.\nII. SEMCOM-EMPOWERED AIGC GENERATION AND\nTRANSMISSION FRAMEWORK\nGiven unevenly distributed computational resources and\nlimited communication resources, we introduce the SemAIGC\n3\nStage II. Edge\nEncoding\nStage I. Cloud\u00a0Pre-training\nPre-training\nremotely\nPre-training\nremotely\nDeploy to edge transmitter\nDeploy to local receiver\nWireless Channel\nText\nEdge Transmitter\nLocal\nReceiver\nStage III. Local\nDecoding\nCloud Server\nText\nGenerated\n\u00a0image\nSemantic\ninformation\nDistorted\nsemantic\ninformation\nWireless Channel\nSemantic\nextraction\nmodule\nText\nImage\nSemantic\ngeneration\nmodule\nChannel encoder\nChannel eecoder\nFine-tuning\nmodule\nAuto-\nencoder\ndecoder\nBinary bits\nof semantic information\nBinary bits\nwith physical channel noise\nChannel\nnoise\nBinary\nbits\nBits\nwith\nchannel\nnoise\nROOT\nMake workload\ntrade-off decisions\n...\nDenoising\n...\nDenoising\nAdjustable\nAdjustable\nServer\nGaussian noise\nFig. 1. The proposed SemAIGC framework. Stage I is the cloud pre-training process that carried out in the cloud server to\ntrain transceiver semantic processing networks and ROOT scheme networks; Stage II edge encoding is executed by the edge\ntransmitter, for example, a base station with an edge server, which is the major stage of semantic information generation and\ntransmission; Stage III is the local decoding stage in the local receiver, deployed to fine-tune the semantic noise caused by\nchannel noise and restructure semantic information into images.\nframework, as shown in Fig. 1. In this framework, our specific\nfocus is on the generation and transmission of images from\ntextual descriptions. SemAIGC framework has three main\nstages, i.e., cloud pre-training, edge encoding, and local de-\ncoding.\nA. Cloud Pre-Training\nIn SemAIGC, we utilize a cloud server to conduct the text-\nto-image (T2I) model training processes. Generally, a high-\nquality T2I model requires millions of parameters in a total\nsize of 1-10 GB, stringent requirements are exposed for spe-\ncialized hardware like GPU, CPU, and capable devices during\nits training. The cloud server as a centralized infrastructure\nwith ample computing power, storage, database, etc. can be\nwell-matched to the demands. As shown in Fig. 1, the cloud\nserver retains the copy of all the modules within both the\nencoder and decoder. After feeding these modules with a\nsubstantial corpus of text-image pairs, the edge transmitter\nand local receiver can download the pre-trained encoder and\ndecoder from the cloud server, respectively. Additionally, the\nencoder and decoder can be periodically updated within the\ncloud server, while the edge transmitter and local receiver do\nnot require further training before using them to offer AIGC\naccess services. Moreover, the neural network of the ROOT\nscheme is also trained remotely and later deployed in the edge\ntransmitter, then fine-tuned according to the local wireless\ncommunication environment.\nB. Edge Encoding\nAs shown in Fig. 1, the edge transmitter is composed of a se-\nmantic extraction module, a semantic generation module, and\na channel encoder. The semantic extraction module comprises\ntwo independent networks, responsible for extracting semantic\ninformation from text and image, respectively. As the core of\nthe edge transmitter, the semantic generation module uses a\ndiffusion model to predict and gradually denoise data starting\nfrom pure noise according to the provided textual description.\nCompared with the pre-training stage, fewer computational re-\nsources are required in the AIGC generation and transmission\nstage. Therefore, the transmitter with edge computing servers\nis sufficient to run these modules with acceptable computing\nlatency. Apart from the semantic encoder, the channel encoder\nin Fig. 1 is deployed at the edge transmitter to convert semantic\ninformation into binary bits for transmission.\nC. Local Decoding\nWith the improvement of computing power in mobile de-\nvices, plenty of user devices are capable of executing informa-\ntion fine-tuning and recovery processes. In SemAIGC, the T2I\ndecoder of a local receiver in Fig. 1 is composed of a semantic\nfine-tuning module, an autoencoder decoder module, and a\nchannel decoder. Specifically, the channel decoder converts the\nbinary bits into semantic information. Given the limited com-\nputing power of local devices, a lightweight diffusion model is\ndeployed into the semantic fine-tuning module. After a rapid\n4\nfine-tuning process, semantic noise can be eliminated, and\nthen the autoencoder decoder module restructures semantic\ninformation into high-resolution images with text guidance.\nIII. WORKLOAD-ADJUSTABLE TRANSCEIVER DESIGN\nIn this section, we consider a downlink transmission sce-\nnario, where the image semantic information is generated\nat the edge transmitter and then transmitted to the local\nreceiver for further fine-tuning via a wireless channel. The\nedge transmitter and local receiver design in SemAIGC are\ndetailed in the following.\nA. Encoder Design at Edge Transmitter\nAs mentioned, the semantic extraction module, semantic\ngeneration module, and channel encoder are deployed in the\nedge transmitter, as shown in the upper part of Fig 2.\n1) Semantic extraction module: Let stext and s denote the\ninput text and image to the semantic extraction module,\nrespectively. The semantic information extracted from text and\nthat from image are denoted as ztext and z, respectively. As\nthe guidance of image generation, the semantic information\nof text ztext is extracted by a contrastive language-image pre-\ntraining (CLIP) encoder [21] as a sequence. Meanwhile, by\nusing an attention-based variational autoencoder (VAE) model\n[22], the input image is encoded into Gaussian-like distribution\nand outputs multiple sets of means and standard deviations.\nThen, we use these values to generate latent space image z,\ni.e., image semantic information. Note that the semantic infor-\nmation of real image is only used during the model training\nstage and is not directly involved in the T2I generation. The\ntwo modalities\u2019 semantic information is extracted as follows:\nztext = E (stext; \u03c6text) , z = E (s; \u03c6) .\n(1)\nHere, E (\u00b7; \u03c6text) and E (\u00b7; \u03c6) are the text encoder and image\nencoder with learnable parameters \u03c6text and \u03c6, respectively.\n2) Semantic-generation module:\nThe semantic generation modules in Fig. 2 is based on the\ndenoising diffusion implicit models (DDIMs), consisting of\nthe diffusion process and the reverse diffusion process [23].\nAs shown in Fig. 3, the diffusion process is a fixed (or\npredefined) forward diffusion process, which is denoted as\nq(zt|zt\u22121). In the diffusion process, a scheduler gradually adds\nGaussian noise at each time step t \u2208[0, T], until the initial\nsemantic information of an image z0 becomes pure noise zT.\nBasically, each new image at time step t is drawn from a\nconditional Gaussian distribution as\nzt =\np\n1 \u2212\u03b2tzt\u22121 +\np\n\u03b2t\u03f5,\n(2)\nwhere 0 < \u03b21 < \u03b22 < \u00b7 \u00b7 \u00b7 < \u03b2T < 1 is a known variance\nschedule with time-related constants, and \u03f5 \u223cN(0, I) is the\nadded Gaussian noise with an identity matrix I.\nMeanwhile, the reverse diffusion process in Fig. 3 is a\ndenoising process which is represented as p(zt\u22121|zt). In this\nprocess, a neural network, i.e., UNet [24], is trained to learn\nthe conditional probability distribution p\u03b8(zt\u22121|zt, ztext) and\ngradually denoise the semantic information according to text\nsemantic starting from pure noise until it ends up with the\nsemantic information of an actual image. Here, \u03b8 is the learn-\nable parameters of the UNet, text guidance is implemented\nby concatenating the text embedding to the key-value pairs of\neach self-attention layer in the UNet [19]. Accordingly, the\nreverse diffusion process is\nzt\u22121 =\n1\n\u221a\u03b1t\n\u0012\nzt \u22121 \u2212\u03b1t\n\u221a1 \u2212\u02d9\u03b1t\n\u03f5\u03b8 (zt, t, ztext)\n\u0013\n+ \u00af\u03c3t\u02dc\u03f5,\n(3)\nwhere \u03f5\u03b8 is the UNet predicted noise, \u03b1t = 1 \u2212\u03b2t is a known\nconstant of step t, \u02d9\u03b1t = Qt\ni=1 \u03b1i is a cumulative product of\n\u03b1t, \u00af\u03c3t is a time dependent constant of step t, and \u02dc\u03f5 \u223cN(0, I)\nis the random normal Gaussian noise.\nNote that the semantic generation module conducts different\nprocesses during the pre-training stage and content-generating\nstage, as shown in Fig. 3. In the pre-training stage, the se-\nmantic generation module executes both processes to learn the\nnoise distribution, while only the reverse diffusion process is\nneeded in content-generating stage. In the content-generating\nstage, with pre-trained UNet, the target image is denoised from\nrandomly generated pure noisy data zT. After the scheduled\ndenoising steps T, the image semantic information is output\naccording to text guidance, which is expressed as\nz\u03b8 = F1(zT, T, ztext; \u03b8),\n(4)\nwhere F1(\u00b7; \u03b8) is the UNet with learnable parameter \u03b8. The\nmodel training of diffusion models will be elaborated in\nSection III-C.\n3) Channel encoder module: As very few bits are required\nfor text semantic information transmission, let us only focus\non the transmission of image semantic information [25]. The\ntransmitted signal is encoded as y = C(z\u03b8) via the channel\nencoder.\nAfter passing through the physical channel, the received\nsignal is expressed as\ny\u2032 = hy + n,\n(5)\nwhere h represents the channel gain and n is the noise. We\nconsider the additive white Gaussian noise (AWGN) channel\nin this paper.1\nB. Decoder Design at Local Receiver\nThen, we present the T2I decoder of the local receiver,\nwhich is composed of the channel decoder module, fine-tuning\nmodule, and autoencoder decoder module, as shown in the\nlower part of Fig. 2.\n1) Channel decoder module: The received binary bits are\nrecovered as semantic information by a traditional channel\ndecoder. The decoded information can be represented as\nz\u2032 = C\u22121(y\u2032),\n(6)\nwhere C\u22121 is the channel decoder. Therefore, \u03f5C = z\u2032\u2212z, \u03f5C \u223c\nN(0, \u03c32I) is the semantic noise with a variance matrix \u03c32I\ncaused by the physical channel noise n.\n1The used diffusion model is Gaussian noise-based hot diffusion, which is\ndesigned to denoise Gaussian distributed noise. For filtering other types of\nnoise, like Rayleigh noise, a cold diffusion-based module could be necessary\n[26].\n5\nInput\nImage\nInput\nText\n\u00a0Edge Transmitter\n\u00a0 \u00a0Local Receiver\u00a0 \u00a0\nOutput\nImage\nWireless Channel\nPhysical \nchannel \nnoise\u00a0\nQ K\nV\nQ K\nV\nQ K\nV\nQ K\nV\nUNet\n...\nRepeat denosing\nFine-tuning module\nROOT\nScheme\nChannel quality\nTask requirement\nChannel\ndecoder\nmodule\nChannel\nencoder\nmodule\nAutoencoder\ndecoder\nmodule\nSemantic\nextraction\nmodule\nVAE encoder\nCLIP encoder\nQ K\nV\nQ K\nV\nQ K\nV\nQ K\nV\nUNet\n...\nRepeat denosing\nBinary bits of \nsemantic\ninformation\nBinary bits \nwith channel \nnoise\nSemantic generation module\nResource\u00a0availability\nDecide denoising step numbers\nFig. 2. The workload-adjustable transceiver in SemAIGC.\n2) Fine-tuning module: This is a lightweight version of\nthe semantic generation module, which is used for fine-\ntuning decoded image semantic information [27]. The reverse\ndiffusion process of fine-tuning module is as follows\nz\u00af\u03b8 = F2(z\u2032, \u00afT, ztext; \u00af\u03b8),\n(7)\nwhere F2(\u00b7; \u00af\u03b8) is the UNet with learnable parameter \u00af\u03b8, \u00afT is the\nnumber of reverse diffusion steps for the fine-tuning module.\nNevertheless, unlike the semantic generation module, the fine-\ntuning module considers semantic noise \u03f5C when training the\nUNet. We theoretically prove that semantic noise \u03f5C can be\ndenoised according to the modified reverse diffusion process,\nas shown in the Proposition. 1.\nProposition 1. Given the semantic noise \u03f5C \u223cN(0, \u03c32I), the\nreverse diffusion process from denoising step t to t \u22121 in the\nfine-tuning module is:\nzt\u22121 =\n1\n\u221a\u03b1t\n(zt \u2212C(\u03b1, \u03c3, t)\u03f5\u03b8(zt, t, ztext)) + \u00af\u03c3t\u03f5,\nC(\u03b1, \u03c3, t) =\n\u00001 \u2212\u03b1t + \u03c32\nt,t\u22121\n\u0001 \u0000\u221a1 \u2212\u02d9\u03b1t \u2212\u03c32\nt\n\u0001\n1 \u2212\u02d9\u03b1t + \u03c32\nt\u22121\u03b1t + \u03c32\nt,t\u22121\n,\n(8)\nwhere \u03f5\u03b8(zt, t, ztext) is the noise predicted from semantic in-\nformation zt, and C(\u03b1, \u03c3, t) is a set of time related constants.\nAdditionally, \u03c3t, \u03c3t\u22121, \u03c3t,t\u22121, and \u00af\u03c3t are time-dependent\nstandard deviations for the random sample of Gaussian noise.\nProof: When the delivered semantic information is im-\npacted by channel noise, according to (2), the semantic infor-\nmation is\nzt = \u221a\u03b1tzt\u22121 +\n\u221a\n1 \u2212\u03b1t\u03f5 + \u03f5C\n=\np\n\u02d9\u03b1tz0 +\np\n1 \u2212\u02d9\u03b1t\u03f5 + \u03f5C,\n\u03f5C \u223cN(0, \u03c32I), \u03f5 \u223cN(0, I).\n(9)\nHowever, for model training, we consider that the se-\nmantic noise \u03f5C is gradually added in the diffusion steps\n{1, \u00b7 \u00b7 \u00b7 , t, \u00b7 \u00b7 \u00b7 , \u00afT}, then the diffusion process can be formu-\nlated as\nzt = \u221a\u03b1tzt\u22121 +\n\u221a\n1 \u2212\u03b1t\u03f5 + \u221a\u03b3t\u03f5C\n=\np\n\u02d9\u03b1tz0 +\np\n1 \u2212\u02d9\u03b1t\u03f5 + \u03c3\n\u00afT\nX\nt=1\n\u00afT \u22121\nY\nj=t+1\n\u221a\u03b3t\u221a\u03b1j\u03f5,\n(10)\nwhere 0 < \u03b31\n< \u03b32\n< \u00b7 \u00b7 \u00b7 < \u03b3t\n< \u00b7 \u00b7 \u00b7 < \u03b3 \u00afT\n<\n1 is a variance schedule with time related constants, and\nP \u00afT\nt=1\nQ \u00afT \u22121\nj=t+1\n\u221a\u03b3t\u221a\u03b1j = 1.\nThe aim of fine-tuning module is to generate image semantic\ninformation z0 from received semantic information zt via the\nreverse diffusion process. Therefore, it is important to predict\nthe distribution probability of the semantic information in\nthe previous step zt\u22121 with the present information zt, i.e.,\nq(zt\u22121|zt, z0). According to the Bayes\u2019 theorem, we have\nq(zt\u22121|zt, z0) = q(zt|zt\u22121, z0)q(zt\u22121|z0)\nq(zt|z0) ,\nq(zt|z0) \u223cN(\np\n\u02d9\u03b1tz0, 1 \u2212\u02d9\u03b1t + \u03c32\nt ),\nq(zt\u22121|z0) \u223cN(\np\n\u02d9\u03b1t\u22121z0, 1 \u2212\u02d9\u03b1t\u22121 + \u03c32\nt\u22121),\nq(zt|zt\u22121, z0) \u223cN(\np\n\u02d9\u03b1tzt\u22121, 1 \u2212\u03b1t + \u03c32\nt,t\u22121).\n(11)\n6\nDiffusion process\nDiffusion process\nModel Training Stage\nContent-Generating Stage\nReverse diffusion process\nDenoising UNet\nUNet\nSemantic information of text\n\u00a0\n\u00a0\n\u00a0\n\u00a0\n\u00a0 text\nSemantic\ninformation of\ninput image\nGaussian\nnoise\nGaussian\nnoise\nSemantic\ninformation of\ngenerated image\nFig. 3. The diffusion and reverse diffusion processes in the semantic generation module.\nHere, noise variances \u03c32\nt , \u03c32\nt\u22121, and \u03c32\nt,t\u22121 can be determined\naccording to \u03c3 Q \u00afT \u22121\nj=t+1\n\u221a\u03b3t\u221a\u03b1j. Then, with the Gaussian\ndistribution formula f(x) =\n1\n\u03c3\n\u221a\n2\u03c0exp\n\u0010\n\u22121\n2\n\u0000 x\u2212\u00b5\n\u03c3\n\u00012\u0011\n, we have\nq(zt\u22121|zt,z0) \u221d\n1\n\u03c3\n\u221a\n2\u03c0 exp\n \n\u22121\n2\n \u0000zt \u2212\u221a\u02d9\u03b1tzt\u22121\n\u00012\n1 \u2212\u03b1t + \u03c32\nt,t\u22121\n+(zt\u22121 \u2212\u221a\u02d9\u03b1t\u22121z0)2\n1 \u2212\u02d9\u03b1t\u22121 + \u03c32\nt\u22121\n\u2212\n\u0000zt \u2212\u221a\u02d9\u03b1tz0\n\u00012\n1 \u2212\u02d9\u03b1t + \u03c32\nt\n!!\n.\n(12)\nSince the purpose of the reverse diffusion process is to predict\nthe semantic information in the previous step, while zt and z0\nare known semantic information, we have\nq(zt\u22121|zt,z0) \u221d\n1\n\u03c3\n\u221a\n2\u03c0 \u00d7\nexp\n \n\u22121\n2\n  \n\u03b1t\n1 \u2212\u03b1t + \u03c32\nt,t\u22121\n+\n1\n1 \u2212\u02d9\u03b1t\u22121 + \u03c32\nt\u22121\n!\nz2\nt\u22121\n\u22122\n \n\u221a\u03b1tzt\n1\u2212\u03b1t+\u03c32\nt,t\u22121\n+\n\u221a\u02d9\u03b1t\u22121z0\n1\u2212\u02d9\u03b1t\u22121+\u03c32\nt\u22121\n!\nzt\u22121+C (zt, z0)\n!!\n.\n(13)\nAs Gaussian distribution formula can be transformed as\nf(x) =\n1\n\u03c3\n\u221a\n2\u03c0exp\n\u0010\n\u22121\n2\n\u0010\n1\n\u03c32 x2 \u22122\u00b5\n\u03c32 x + \u00b52\n\u03c32\n\u0011\u0011\n, we can calcu-\nlate the mean of the distribution as\n\u00b5\u03b8(zt, z0) =\n\u221a\u03b1t\n\u00001 \u2212\u02d9\u03b1t\u22121 + \u03c32\nt\u22121\n\u0001\n1 \u2212\u02d9\u03b1t + \u03c32\nt\u22121\u03b1t + \u03c32\nt,t\u22121\nzt+\n\u221a\u02d9\u03b1t\u22121\n\u00001 \u2212\u03b1t + \u03c32\nt,t\u22121\n\u0001\n1 \u2212\u02d9\u03b1t + \u03c32\nt\u22121\u03b1t + \u03c32\nt,t\u22121\nz0.\n(14)\nThen,\n(10)\ncan\nbe\nreversed\nas\nz0\n=\n1\n\u221a\u02d9\u03b1t\n\u0000zt \u2212(\u221a1 \u2212\u02d9\u03b1t \u2212\u03c32\nt )\u03f5t\n\u0001\n, \u03f5t\n\u223c\nN(0, I),\nthus\nwe\nhave\n\u00b5\u03b8(zt, t)=\n1\n\u221a\u03b1t\n \nzt\u2212\n\u00001\u2212\u03b1t+\u03c32\nt,t\u22121\n\u0001 \u0000\u221a1\u2212\u02d9\u03b1t\u2212\u03c32\nt\n\u0001\n1 \u2212\u02d9\u03b1t + \u03c32\nt\u22121\u03b1t + \u03c32\nt,t\u22121\n\u03f5t\n!\n.\n(15)\nTherefore, to sample zt\u22121 \u223cp\u00af\u03b8(zt\u22121|zt) is to compute zt\u22121 =\n1\n\u221a\u03b1t (zt \u2212C(\u03b1, \u03c3, t)\u03f5\u03b8(xt, t)) + \u00af\u03c3t\u03f5, we prove Proposition 1.\n3) Autoencoder decoder module: This is the decoder of the\nVAE model with KL loss [28], which paints the final image\noutput using the fused semantic information of text and image.\nThe image semantic information is gradually recovered to the\ntarget image. The final image from the autoencoder decoder\nmodule is output as\n\u00afs = D(z\u00af\u03b8|ztext; \u00af\u03c6),\n(16)\nwhere D(\u00b7; \u00af\u03c6) is the autoencoder decoder with learnable\nparameter \u00af\u03c6.\nC. Training Algorithm\nThe training of image process modules is the major part of\ngenerating a high-quality image from text. Specifically, we first\nintroduce the joint training of the image semantic extraction\nmodule and autoencoder decoder module. Then, we present the\ntraining of diffusion models in the semantic generation module\nand the fine-tuning module. The text-extracting module can\nuse a pre-trained CLIP model since it is not a main focus.\nThe image semantic extraction module and the autoencoder\ndecoder module are jointly trained according to the loss\nfunction of the VAE encoder-decoder [28]. In the consideration\n7\nof semantic similarity and reconstruction likelihood, the loss\nfunction is\nloss1(\u03c6, \u00af\u03c6) =\n\u22121\n2m\nM\nX\ni=1\nK\nX\nj=1\n\u00001 + log \u03c32\nj \u2212\u03c32\nj \u2212\u00b52\nj\n\u0001\n+ 1\nm\nM\nX\ni=1\n(si \u2212\u00afsi)2\n= \u2212DKL (\u02dcq\u03c6 (z|s) ||\u02dcp (z)) + Ez\u223c\u02dcq\u03c6(s|z) [log\u02dcp \u00af\u03c6 (s|z)] ,\n(17)\nwhere i \u2208{1, \u00b7 \u00b7 \u00b7 , M} is the ith sample in a dataset with\na total size M, K is the set size of means \u00b5j and standard\ndeviations \u03c3j generated by the VAE encoder, \u02dcq\u03c6(z|s) is the\ndistribution of the VAE encoder output semantic information,\n\u02dcp(z) the distribution of a real image\u2019s semantic information,\n\u02dcp \u00af\u03c6(s|z) is the distribution of the VAE decoder output, and\nDKL is the cross-entropy.\nTo achieve the efficient generation and transmission of high-\nquality content, the pre-training of the diffusion model in the\nsemantic generation module is the crucial part. The corre-\nsponding objective of the information generator is to predict\nthe noise distribution in the extracted semantic information as\nfollows\nloss2 = EE(s),\u03f5\u223cN (0,I),t\n\u0002\n\u2225\u03f5 \u2212\u03f5\u03b8 (z, t|ztext) \u22252\n2\n\u0003\n.\n(18)\nFor the fine-tuning module, the training objective is similar\nto (18), except its UNet is trained to learn the distribution\nof the semantic noise plus additional channel noise-caused\nsemantic noise.\nIV. INTELLIGENT WORKLOAD TRADE-OFF SCHEME\nDESIGN\nConsidering the dynamic nature of resource availability\nand channel quality in wireless networks, as well as varying\nuser preferences, it becomes essential to flexibly adapt the\ntransmitter and receiver workload, thus catering to the service\nneeds effectively.\nA. T2I Service Evaluation Metrics\nIn our SemAIGC framework, image quality and latency are\nthe two crucial performance metrics that affect service quality.\nThe image quality is primarily influenced by semantic simi-\nlarity and reconstruction likelihood. We can fetch the image\nquality score by evaluating the loss between the SemAIGC\nimage and the target image2, as defined in (17). Meanwhile,\nthe latency of accessing T2I service by the local receiver j\nfrom edge transmitter i consists of transmission delay Li,j\n1 ,\nedge computing delay Li,j\n2 , and local computing delay Li,j\n3 ,\ni.e., Li,j = Li,j\n1 + Li,j\n2 + Li,j\n3 . Let Oi,j denote the data size\nof semantic information transmitted by edge transmitter i to\nlocal receiver j, then the transmission delay is\nLi,j\n1\n= Oi,j\nvi,j\n,\n(19)\nwhere vi,j = Bi,j \u00b7 log2(1 + SNRi,j) is the bit transmission\nrate of the link from transmitter i to receiver j, SNRi,j is the\n2In practice, if there is no target image available, the aesthetics scores\npredictor can be used to evaluate the image quality in model training and\nimage generation [29].\nsignal-to-noise-ratio (SNR) of this link, and Bi,j represents\nthe bandwidth allocated to this link.\nFor the computing delay, according to Amdahl\u2019s law, the\ncomputing delay consists of the computing time of the seri-\nalized part and the computing time of the parallelizable part\n[30]. In this work, the computing speed of edge transmitter i is\nmajorly dependent on the GPU3. Meanwhile, the majority of\nthe computing workload is caused by the reverse diffusion\nprocess of the semantic generation module and fine-tuning\nmodule, we denote the delay resulting from other modules as\na small constant l [31]. Therefore, the edge computing delay\nis calculated as\nLi,j\n2\n= (1 \u2212\u03c4)Wi(T)Os\n\u03bdi\n+ \u03c4Wi(T)Os\n\u03bdimi\n+ l\n= Wi(T)Os\n\u03bdi\n\u0012\n1 \u2212\u03c4 + \u03c4\nmi\n\u0013\n+ l,\n(20)\nwhere Wi(T) is the processing density (in GPU/CPU cy-\ncles/bits) of the transmitter UNet that corresponds to the\ntotal denoising step number T of the semantic generation\nmodule, Os is the input data size, and \u03c4 \u2208[0, 1] stands\nfor the parallelizable fraction of AIGC task. Moreover, \u03bdi\nis the processing capability (i.e., the GPU/CPU frequency in\ncycles/s) of each core of the GPU, and mi denotes the GPU\ncore number of edge transmitter i. The local computing delay\nLi,j\n3\nis calculated in the same way.\nThe Proposition 2 proves that to allow SemAIGC to out-\nperform the edge AIGC framework in terms of total latency,\nthe information compression rate should fit certain conditions.\nHere, the edge AIGC framework generates images by the T2I\nmodel deployed in the edge server and delivers images with\ntraditional communication.\nProposition 2. Assuming identical channel quality and re-\nsource allocation under the SemAIGC framework and the edge\nAIGC framework, to make the SemAIGC framework provide\nlower service latency than the edge AIGC framework, i.e.,\nLi,j < Ledge, the compression rate of the AIGC encoder\nshould satisfy\nQi,j\nQs\n<\n\f\f\f\f1\u2212\nWj( \u00afT)vi,j [C1\u03bdi\u2212C2\u03bdj]\n\u03bdi\u03bdj+Wj( \u00afT)vi,j [C1\u03bdi\u2212C2\u03bdj]\n\f\f\f\f ,\n(21)\nHere, C1 and C2 are constants, and 0 < C1 < 1, 0 < C2 <\n1.\nProof: When the SemAIGC framework provides lower\nlatency than the edge AIGC framework L < Ledge, we have\nOi,j\nvi,j\n+ Wi(T)Os\n\u03bdi\n(1 \u2212\u03c4 + \u03c4\nmi\n)+ Wj( \u00afT)Oi,j\n\u03bdj\n(1 \u2212\u03c4 + \u03c4\nmj\n) <\nOs\nvi,j\n+ Wi(T)Os + Wj( \u00afT)Oi,j\n\u03bdi\n(1 \u2212\u03c4 + \u03c4\nmi\n).\n(22)\n3The GPUs work within an ideal environment with suitable device temper-\nature, enough graphics memory, and ample processing memory.\n8\nThen, equation (22) is transformed as follows\nOi,j\u00b7\n\u0012 1\nvi,j\n+ Wj( \u00afT)\n\u03bdj\n(1\u2212\u03c4 + \u03c4\nmj\n)\u2212Wj( \u00afT)\n\u03bdi\n(1\u2212\u03c4 + \u03c4\nmi\n)\n\u0013\n<\nOs \u00b7\n1\nvi,j\n.\n(23)\nGiven that\nQi,j\nQs\n> 0, and \u03c4, mi and mj are constants, we\nprove Proposition 2.\nB. Computing Workload Adaptation Problem Formulation\nConsidering the dynamic resource availability, channel qual-\nity, and service requirements, we should adjust the reverse\ndiffusion step numbers of the semantic generation module\nand fine-tuning module. We formulate the workload adaptation\nproblem as an MDP problem, and the action, state, reward, and\nobjective function of this problem are defined as follows.\nAction: In this work, the edge transmitter acts as the agent\nto decide its encoding workload. We denote a \u2208[0, \u02c6T] as the\naction, which is the reverse diffusion steps taken charge by\nthe edge transmitter\u2019s encoder. Here, \u02c6T is the largest reverse\ndiffusion step for image generation. Meanwhile, the number\nof denoising steps in the fine-tuning module is set to \u02c6T \u2212a.\nState:\nThe\nstate\nof\nsystem\nis\ndenoted\nas\nx\n=\n{ \u00afWi, \u00afWj, SNRi,j, \u00af\u03bdi, \u00af\u03bdj, \u00afBi,j, \u00afLj}, where \u00afWi and \u00afWj repre-\nsent the average processing density of edge transmitter i and\nlocal receiver j, respectively. Moreover, \u00af\u03bdi and \u00af\u03bdj are the\naverage processing capability of transmitter i and receiver j,\nSNRi,j denotes the average SNR of the link from transmitter\ni to receiver j, \u00afBi,j is the average bandwidth allocated to\nthis link, and \u00afLj represents the average delay requirement of\nreceiver j. A D3QN model is sufficient to analysis this state\nspace.\nReward and objective function: In order to provide a re-\nquired image quality with target latency according to the\nspecific requirements of the receiver, the reward function is\nset as\nR =\n\uf8f1\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f3\n1,\nLj < \u02c7Lj,\n\u02c6Lj\u2212Lj\n\u02c6Lj\u2212\u02c7Lj ,\n\u02c7Lj < Lj < \u02c6Lj,\n0,\notherwise.\n(24)\nHere, [\u02c7Lj, \u02c6Lj] is the delay requirement of receiver j.\nC. ROOT Scheme\nTo solve the formulated MDP problem, we propose the\nROOT scheme to dynamically adjust image quality and service\nlatency by intelligently making computing workload adapta-\ntion decisions. Given the discrete action space in this scenario,\na suitable approach is to employ a value-based DRL method.\nThe D3QN has demonstrated remarkable performance in solv-\ning problems with discrete action spaces [32]. It effectively\nmitigates the issue of overestimation of action values in the\nQ-learning model and can be further enhanced by incorpo-\nrating the decaying \u03b5-greedy strategy in the policy learning.\nTherefore, we apply the D3QN in ROOT to estimate the\noptimal action value and efficiently make the optimal workload\nadaptation decisions.\nAlgorithm 1 The training the process of ROOT.\n1: Initialize the parameter of two networks \u03c9 and \u00af\u03c9, the\ndiscount rate \u03bb, the minibatch size mD, and time t = 0;\n2: for Episode 1 to the maximum training episode do\n3:\nDecide an action a according to estimated Q-value\nunder state x;\n4:\nStart the SemAIGC image generation\n5:\nExecute transmitter-side semantic processing according\nto action a;\n6:\nTransmit image semantic information;\n7:\nExecute receiver-side semantic processing according to\nthe action;\n8:\nObserve reward r, and update state x\u2032;\n9:\nStore transaction (x, a, r, x\u2032) into replay buffer;\n10:\nExperience replay: Sample random minibatch of trans-\nactions (xi, ai, ri, xi+1) from the replay buffer;\n11:\nfor i = 1 to mD do\n12:\nComputer\nthe\ntarget\nvalue\nyi\n=\nri\n+\n\u03bbQ\u03c9\n\u0000xi+1, argmax\n\u0000Q\n\u0000xi+1, ai+1; \u03c9i\u0001\u0001\u0001\n;\n13:\nUpdate\nthe\nQ-network\n\u03c9\n\u2190\n\u03c9\n\u2212\u03b7\n\u00b7\n1\nmD\nP\ni\u2208mD\n\u0002\nyi \u2212Q\n\u0000xi, ai\u0001\u0003\n\u00b7 \u2207\u03c9Q\u03c9\n\u0000xi, ai\u0001\n.\n14:\nend for\n15: end for\nThe D3QN is composed of two networks. One network with\nparameter \u03c9 is used to estimate the state value function V (x)\nand the other with parameter \u00af\u03c9 is used to represent the state-\ndependent action advantage function \u039b(x, a) [32], the outputs\nof the two separate networks are integrated as\nQ(x, a) =V (x; \u03c9) + \u039b(x, a; \u00af\u03c9)\n\u22121\n|A|\nX\na\u2032\n\u039b(x, a\u2032; \u00af\u03c9),\n(25)\nwhere a\u2032 is the next action.\nFor action selection, the \u03b5-greedy strategy is utilized to\nbalance the exploration and exploitation where the transmitter\nselects an action a randomly with probability \u03b5 or selects an\naction a = argmaxaQ(x, a; \u03c9) = argmaxa\u039b(x, a; \u00af\u03c9) with\nprobability 1 \u2212\u03b5. After intelligent workload adaptation and\nAIGC service delivery, the state, action, reward, and the next\nstate (x, a, r, x\u2032) are stored as transactions in the replay buffer\nfor model training. In each training iteration, there are mD\ntransactions used in training, and the target is computed as\nyi = ri+\u03bbQ\u03c9\n\u0000xi+1, argmax\n\u0000Q\n\u0000xi+1, ai+1; \u03c9i\u0001\u0001\u0001\n, i \u2208mD,\n(26)\nwhere \u03bb is a discount rate and mD is the batch size. The\nQ-network is updated according to a gradient descent step\n\u03c9 \u2190\u03c9 \u2212\u03b7 \u00b7 1\nmD\nmD\nX\ni=1\n\u0002\nyi \u2212Q\n\u0000xi, ai\u0001\u0003\n\u00b7\u2207\u03c9Q\u03c9\n\u0000xi, ai\u0001\n, (27)\nwhere \u03b7 is the learning rate. The training process of the ROOT\nscheme is presented in Algorithm 1.\nWith the D3QN, the transmitter can intelligently decide the\ndenoising step numbers of the semantic generation module, so\nas that of the fine-tuning module.\n9\nEdge AIGC\nNon-ROOT SemAIGC\n-3\nSNR/dB\nNon-fine-tuning AIGC\u00a0\n0\n3\n6\n9\n12\n\u00a0SemAIGC\nFig. 4. The delivered images of three AIGC generation and transmission frameworks under different SNRs (text input: \u201cA cute\nfurry cat\u201d, the seed value for initial noise: 30).\nV. SIMULATION RESULTS AND DISCUSSIONS\nIn this section, we conduct simulations to evaluate the per-\nformance of the proposed SemAIGC framework and its ROOT\nscheme under different scenarios. In order to demonstrate the\nrationality of integrating SemCom into AIGC, we compare\nwith the following four benchmarks.\n1) Non-ROOT SemAIGC: This framework is identical to\nSemAIGC, except that the ROOT scheme is disabled.\n2) Non-fine-tuning AIGC: This framework offers a straight-\nforward application of SemCom to the AIGC transmitter-\nreceiver without a fine-tuning module in the receiver.\n3) Edge AIGC: The image is generated by the T2I model\ndeployed in edge server and uses traditional communica-\ntion to deliver to users.\n4) Local AIGC: This framework uses local receiver to\ncompute all the processes of T2I generation, in which\nno wireless communication is involved.\nA. Simulation Settings\nIn the simulation, a workstation with the GPU RTX A6000\nacts as the edge transmitter and a laptop with the GPU of\nRTX1080 Ti acts as the local receiver. The bandwidth of\ntransmitter provided for receiver does not exceed 20 MHz,\nand the SNR is set to a range of [\u22126, 15]dB. Additionally,\nthe latency requirement of the receiver is within the range of\n[5, 25]s. The satisfaction score within [0, 1] is issued according\nto the latency for the receiver to fetch appropriate image\nquality from transmitter. If the generation time cost of one\nimage exceeds the default maximum number of 60s, the task\nis failed.\nEdge AIGC\nNon-ROOT SemAIGC\nNon-fine-tuning AIGC\u00a0\n0dB\nSemAIGC\nFig. 5. The image details of three AIGC generation and\ntransmission frameworks under 0dB wireless channel.\n10\n0\n100\n200\n300\n400\n500\nEpisode\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nAverage reward\nSemAIGC\nNon-ROOT SemAIGC\nNon-fine-tuning AIGC\nEdge AIGC\nLocal AIGC\nFig. 6. Convergence performance for four AIGC generation\nand transmission framework.\n-3\n0\n3\n6\n9\n12\nSNR(dB)\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nAverage denoising step number of transmitter\nSemAIGC\nEdge AIGC\n(a) Average denoising steps executed by transmitter\nunder varying SNRs.\n20%\n40%\n60%\n80%\n100%\nPercentage of available computing resource\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n20\nAverage denoising step number of transmitter\nSemAIGC\nEdge AIGC\n(b) Average denoising steps executed by transmitter\nunder different percentages of computing power.\nFig. 7. Average denoising steps executed by transmitter.\nThe model training is composed of two major parts, i.e.,\nSemAIGC model training and ROOT scheme training. For the\nSemAIGC model, the Stable Diffusion v1-5 model checkpoint\nis used in the pre-trained model [19]. The corresponding\nsemantic extraction module of text is deployed with pre-trained\nOpenAI CLIP [21]. Meanwhile, the pre-trained VAE encoder\nand decoder are used as the image semantic extraction module\nand autoencoder decoder module, respectively [28]. In this\nwork, to adjust the UNet weights of the fine-tuning module,\na subset within the laion-aesthetics v2 5+ is used, which\ncontains high-resolution figures, and corresponding caption\ntexts. In training, all the images in this subset are filtered to\na size of 512 \u00d7 512 \u00d7 3. All the pre-processed images are\nextracted as 1 \u00d7 4 \u00d7 64 \u00d7 64 image semantic information by\nVAE encoder for UNet training. Moreover, the UNet is trained\nwith 1 middle block in 8 \u00d7 8 resolution, 12 encoding blocks,\nand 12 decoding blocks in 4 resolutions, i.e., 64\u00d764, 32\u00d732,\n16 \u00d7 16, and 8 \u00d7 8 [19].\nFor the D3QN setting in the ROOT scheme, both the DQN\nnetwork and target network have an input layer with 7 neurons\nand a 10-neural output layer, as well as 2 hidden layers with\neach of 256 neurons [32]. We employ ReLU as the activation\nfunction between the input layer and the two hidden layers.\nThe training minibatch size is set to 64, and the reward\ndiscount rate is set to 0.99.\n0.4\n100%\n0.5\n90%\n0.6\n80%\n0.7\n70%\nSatisfaction score\n15\n0.8\n60%\n12\nPACR\n50%\n0.9\n9\nSNR (dB)\n40%\n6\n1\n3\n30%\n0\n20%\n-3\n10%\n-6\nFig. 8. Satisfaction score for the SemAIGC framework under\ndynamic computing power and channel quality.\nB. Numerical Results\nWe first examine the generated image quality under different\nchannel qualities, shown in Fig. 4 and Fig. 5. Notably, since\nLocal AIGC does not involve wireless transmission, it is not\nconsidered as a benchmark here. Moreover, as the number of\ndenoising steps affects image quality, for fairness, we ought\nto set the total denoising step of different frameworks into the\nsame number of 20. The SemAIGC tends to intelligently adjust\nthe denoising step of the transmitter and receiver. Meanwhile,\nfor the Non-ROOT SemAIGC service, both the denoising step\nof the semantic generation module and that of the fine-tuning\nmodule are set to 10, whereas the other two frameworks have\n20 denoising steps solely in edge transmitter or local receiver.\n11\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n100%\nPercentage of available computing resource\n10\n15\n20\n25\n30\n35\n40\n45\n50\n55\n60\n65\nLatency (s)\nSemAIGC\nNon-ROOT SemAIGC\nNon-fine-tuning AIGC\nEdge AIGC\nLocal AIGC\n(a) Average latency under different percentages of computing\npower.\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n100%\nPercentage of available computing resource\n0\n0.2\n0.4\n0.6\n0.8\n1\nSatisfaction score\nSemAIGC\nNon-ROOT SemAIGC\nNon-fine-tuning AIGC\nEdge AIGC\nLocal AIGC\n(b) Satisfaction score under different percentages of computing\npower.\n-6\n-3\n0\n3\n6\n9\n12\n15\nSNR (dB)\n10\n15\n20\n25\n30\n35\n40\n45\n50\n55\n60\n65\nLatency (s)\nSemAIGC\nNon-ROOT SemAIGC\nNon-fine-tuning AIGC\nEdge AIGC\nLocal AIGC\n(c) Average latency under different SNRs.\n-6\n-3\n0\n3\n6\n9\n12\n15\nSNR (dB)\n0\n0.2\n0.4\n0.6\n0.8\n1\nSatisfaction score\nSemAIGC\nNon-ROOT SemAIGC\nNon-fine-tuning AIGC\nEdge AIGC\nLocal AIGC\n(d) Satisfaction score under different SNRs.\nFig. 9. Service quality experienced by users for four different frameworks.\nAs shown in Fig. 4, it is obvious that the images generated by\nSemAIGC exhibit excellent clarity and align seamlessly with\nthe textual description. The SemAIGC outperforms the Non-\nfine-tuning AIGC and Non-ROOT SemAIGC systems under\nall channel qualities while generating images with structures\nthat nearly resemble those of the edge AIGC, thanks to\nthe fine-tuning model\u2019s effective channel noise reduction and\npreservation of valuable semantic information. Since this study\ndoes not prioritize UNet training and its corresponding sched-\nuler design, some impact from harsh channels may persist,\nresulting in a slight green tint in the images generated by Se-\nmAIGC. Nevertheless, this impact is significantly eliminated\ncompared to images generated by Non-ROOT SemAIGC,\nbecause the majority of channel-caused semantic noise is elim-\ninated by intelligently decided denoising step in SemAIGC.\nMoreover, we compared the image details of SemAIGC and\nthe other three frameworks under a 0dB channel in Fig. 5. It is\nobserved that SemAIGC can output the highest quality image\nwith a smooth texture, while images from other frameworks\nhave noisy points, blurred edges, and texture distortion. The\nresults further indicate that the proposed SemAIGC is effective\nand robust in generating high-quality images over a noisy\nchannel.\nThen, we evaluate its convergence performance by compar-\ning its average reward with that of four alternative benchmarks,\nas shown in Fig. 6. It is worth noting that these four bench-\nmarks employ the same reward function as the SemAIGC\nframework. We observe that SemAIGC excels in conver-\ngence speed, reaching convergence within approximately 350\nepisodes. This superior performance can be attributed to the\nROOT scheme of SemAIGC, which intelligently adjusts the\nworkload for the transmitter and receiver based on resource\navailability and channel quality.\nFig.7 demonstrates the effectiveness of the ROOT scheme\nfor SemAIGC in terms of intelligently adjusting denoising\nsteps, so as computing workload. From Fig.7(a) and Fig.7(b),\nwe observe that the ROOT scheme of SemAIGC intelligently\nallocates more workload to the transmitter under batter channel\nconditions and higher computing resource availability, respec-\ntively.\nAdditionally, Fig. 8 illustrates the average satisfaction score\nof the user when utilizing the SemAIGC framework, in\nresponse to dynamic changes in channel quality and the\npercentages of available computing resources (PACR) for the\n12\ntransmitter. Notably, the satisfaction score exhibits an increase,\nranging from approximately 45% to 98%, in tandem with\nthe PACR and SNR. Although under the most challenging\nconditions, characterized by the poorest channel quality with\nan SNR of \u22126dB, SemAIGC can still attain an acceptable\nsatisfaction score of approximately 70%, provided that the\ntransmitter possesses sufficient computational resources. This\nimpressive performance can be attributed to that the transmitter\nwith ample computing power can speedily generate semantic\ninformation, and the fine-tuning module can effectively and\npromptly mitigate channel noise while preserving valuable\nsemantic information.\nTo further demonstrate the performance of SemAIGC, we\nconduct a comparative analysis of its average latency and\nsatisfaction score with other four frameworks, as depicted in\nFig. 9. As seen in Fig. 9(a), when computational resources\nare fixed and the SNR varies dynamically, SemAIGC consis-\ntently maintains an average latency below 25s, surpassing the\nperformance of the other three frameworks. This superiority\nis even more pronounced in Fig. 9(b). Although SemAIGC\nexhibits a slightly lower average latency than Edge AIGC by\na mere 2s, its satisfaction rate outperforms Edge AIGC by\napproximately 40%. This is due to the fact that SemAIGC pri-\noritizes delivering images within a required time range rather\nthan blindly pursuing extremely low latency. Furthermore,\nFig. 9(c) and Fig. 9(d) offer insights into the performance\nof these frameworks under varying SNRs. In Fig. 9(c), it\nbecomes evident that under the harsh channel, the user with\nboth the non-fine-tuning AIGC and Edge AIGC framework\ncan experience significantly higher latency, approximately 25s\nand 45s greater than that of SemAIGC, respectively. This\ndisparity arises from the absence of UNet, which is responsible\nfor denoising received information from the receiver side and\nensuring suitable image quality within the given time con-\nstraints. Additionally, from Fig. 9(d), it is more obvious that\nthe other four frameworks cannot provide a satisfying service\nas the SemAIGC, which further validates the effectiveness and\nrobustness of SemAIGC.\nVI. CONCLUSION\nIn this paper, we introduce the SemAIGC framework as a\nnovel approach for jointly generating and transmitting con-\ntent in wireless networks. Our framework employs SemCom\nto reduce the consumption of communication resources. In\naddition, diffusion models are deployed into the encoder and\ndecoder to develop a workload-adjustable transceiver and im-\nprove the utilization of computational resources. Furthermore,\na ROOT scheme is presented in SemAIGC to intelligently\nmake workload adaptation decisions for providing adaptive\nAIGC access service. Simulation results demonstrate the su-\nperiority of SemAIGC framework in terms of service quality\nand robustness.\nThis paper is a pioneer work in the realm of wireless AIGC\nprovisioning. The utilization of SemCom shows instrumental\nin efficiently managing communication and computational\nresources in resource-intensive AIGC networks. Moreover,\nthe generative AI model employed in this work can inspire\nthe development of novel methods for semantic extraction,\ntransmission, and recovery in the domain of image SemCom.\nREFERENCES\n[1] A. Jo, \u201cThe Promise and Peril of Generative AI,\u201d Nature, vol. 614, no. 1,\npp. 214\u2013216, 2023.\n[2] Y. Wang, Y. Pan, M. Yan, Z. Su, and T. H. Luan, \u201cA Survey on\nChatGPT: AI-Generated Contents, Challenges, and Solutions,\u201d arXiv\npreprint arXiv:2305.18339, 2023.\n[3] L. Xia, Y. Sun, C. Liang, L. Zhang, M. A. Imran, and D. Niyato,\n\u201cGenerative AI for Semantic Communication: Architecture, Challenges,\nand Outlook,\u201d arXiv preprint arXiv:2308.15483, 2023.\n[4] F. J. G. Pe\u02dcnalvo, A. Sharma, A. Chhabra, S. K. Singh, S. Kumar, V. Arya,\nand A. Gaurav, \u201cMobile Cloud Computing and Sustainable Develop-\nment: Opportunities, Challenges, and Future Directions,\u201d International\nJournal of Cloud Applications and Computing (IJCAC), vol. 12, no. 1,\npp. 1\u201320, 2022.\n[5] M. Xu, H. Du, D. Niyato, J. Kang, Z. Xiong, S. Mao, Z. Han,\nA. Jamalipour, D. I. Kim, V. Leung et al., \u201cUnleashing the Power of\nEdge-Cloud Generative AI in Mobile Networks: A Survey of AIGC\nServices,\u201d arXiv preprint arXiv:2303.16129, 2023.\n[6] H. Du, Z. Li, D. Niyato, J. Kang, Z. Xiong, D. I. Kim et al., \u201cEnabling\nAI-Generated Content (AIGC) Services in Wireless Edge Networks,\u201d\narXiv preprint arXiv:2301.03220, 2023.\n[7] J. Wang, H. Du, D. Niyato, J. Kang, Z. Xiong, D. Rajan, S. Mao\net al., \u201cA Unified Framework for Guiding Generative AI with Wireless\nPerception in Resource Constrained Mobile Edge Networks,\u201d arXiv\npreprint arXiv:2309.01426, 2023.\n[8] H. Park, A. Yessenbayev, T. Singhal, N. K. Adhikari, Y. Zhang, S. M.\nBorse, H. Cai, N. P. Pandey, F. Yin, F. Mayer et al., \u201cReal-Time,\nAccurate, and Consistent Video Semantic Segmentation via Unsuper-\nvised Adaptation and Cross-Unit Deployment on Mobile Device,\u201d in\nProceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition, 2022, pp. 21 431\u201321 438.\n[9] Z. Sun, H. Yu, X. Song, R. Liu, Y. Yang, and D. Zhou, \u201cMobilebert:\nA Compact Task-Agnostic Bert for Resource-Limited Devices,\u201d arXiv\npreprint arXiv:2004.02984, 2020.\n[10] H. Du, R. Zhang, D. Niyato, J. Kang, Z. Xiong, D. I. Kim, H. V.\nPoor et al., \u201cExploring Collaborative Distributed Diffusion-Based AI-\nGenerated Content (AIGC) in Wireless Networks,\u201d arXiv preprint\narXiv:2304.03446, 2023.\n[11] Z. Qin, X. Tao, J. Lu, and G. Y. Li, \u201cSemantic Communications:\nPrinciples and Challenges,\u201d arXiv preprint arXiv:2201.01389, 2021.\n[12] L. Xia, Y. Sun, C. Liang, D. Feng, R. Cheng, Y. Yang, and M. A. Imran,\n\u201cWiserVR: Semantic Communication Enabled Wireless Virtual Reality\nDelivery,\u201d IEEE Wireless Communications, vol. 30, no. 2, pp. 32\u201339,\n2023.\n[13] C. Liang, X. Deng, Y. Sun, R. Cheng, L. Xia, D. Niyato, and M. A.\nImran, \u201cVISTA: Video Transmission Over a Semantic Communication\nApproach,\u201d ICC 2023 - IEEE International Conference on Communica-\ntion (ICC), 2023.\n[14] F. Zhao, Y. Sun, R. Cheng, and M. A. Imran, \u201cBackground Knowledge\nAware Semantic Coding Model Selection,\u201d in 2022 IEEE 22nd Interna-\ntional Conference on Communication Technology (ICCT).\nIEEE, 2022,\npp. 84\u201389.\n[15] D. Huang, X. Tao, F. Gao, and J. Lu, \u201cDeep Learning-Based Image\nSemantic Coding for Semantic Communications,\u201d in 2021 IEEE Global\nCommunications Conference (GLOBECOM).\nIEEE, 2021, pp. 1\u20136.\n[16] B. G\u00a8uler, A. Yener, and A. Swami, \u201cThe Semantic Communication\nGame,\u201d IEEE Transactions on Cognitive Communications and Network-\ning, vol. 4, no. 4, pp. 787\u2013802, 2018.\n[17] Z. Lin, Y. Gong, Y. Shen, T. Wu, Z. Fan, C. Lin, N. Duan, and W. Chen,\n\u201cText Generation with Diffusion Language Models: A Pre-Training\nApproach with Continuous Paragraph Denoise,\u201d in International Con-\nference on Machine Learning.\nPMLR, 2023, pp. 21 051\u201321 064.\n[18] R. Huang, Z. Zhao, H. Liu, J. Liu, C. Cui, and Y. Ren, \u201cProdiff:\nProgressive Fast Diffusion Model for High-Quality Text-to-Speech,\u201d in\nProceedings of the 30th ACM International Conference on Multimedia,\n2022, pp. 2595\u20132605.\n[19] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer,\n\u201cHigh-Resolution Image Synthesis with Latent Diffusion Models,\u201d in\nProceedings of the IEEE/CVF conference on computer vision and\npattern recognition, 2022, pp. 10 684\u201310 695.\n13\n[20] H. Hu, D. Wu, F. Zhou, X. Zhu, R. Q. Hu, and H. Zhu, \u201cIntelligent\nResource Allocation for Edge-Cloud Collaborative Networks: A Hybrid\nDDPG-D3QN Approach,\u201d IEEE Transactions on Vehicular Technology,\n2023.\n[21] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal,\nG. Sastry, A. Askell, P. Mishkin, J. Clark et al., \u201cLearning Transferable\nVisual Models from Natural Language Supervision,\u201d in International\nconference on machine learning.\nPMLR, 2021, pp. 8748\u20138763.\n[22] D. P. Kingma and M. Welling, \u201cAuto-Encoding Variational Bayes,\u201d\narXiv preprint arXiv:1312.6114, 2013.\n[23] J. Song, C. Meng, and S. Ermon, \u201cDenoising diffusion implicit models,\u201d\narXiv preprint arXiv:2010.02502, 2020.\n[24] O. Ronneberger, P. Fischer, and T. Brox, \u201cU-net: Convolutional Net-\nworks for Biomedical Image Segmentation,\u201d in Medical Image Comput-\ning and Computer-Assisted Intervention\u2013MICCAI 2015: 18th Interna-\ntional Conference, Munich, Germany, October 5-9, 2015, Proceedings,\nPart III 18.\nSpringer, 2015, pp. 234\u2013241.\n[25] P. Jiang, C.-K. Wen, S. Jin, and G. Y. Li, \u201cDeep Source-Channel Coding\nfor Sentence Semantic Transmission with HARQ,\u201d IEEE transactions on\ncommunications, vol. 70, no. 8, pp. 5225\u20135240, 2022.\n[26] A. Bansal, E. Borgnia, H.-M. Chu, J. Li, H. Kazemi, F. Huang, M. Gold-\nblum, J. Geiping, and T. Goldstein, \u201cCold Diffusion: Inverting Arbitrary\nImage Transforms without Noise,\u201d Advances in Neural Information\nProcessing Systems, vol. 36, 2024.\n[27] Y. Li, H. Wang, Q. Jin, J. Hu, P. Chemerys, Y. Fu, Y. Wang, S. Tulyakov,\nand J. Ren, \u201cSnapFusion: Text-to-Image Diffusion Model on Mobile\nDevices within Two Seconds,\u201d arXiv preprint arXiv:2306.00980, 2023.\n[28] D. P. Kingma, T. Salimans, R. Jozefowicz, X. Chen, I. Sutskever, and\nM. Welling, \u201cImproved Variational Inference with Inverse Autoregres-\nsive Flow,\u201d Advances in neural information processing systems, vol. 29,\n2016.\n[29] V. Hosu, B. Goldlucke, and D. Saupe, \u201cEffective Aesthetics Prediction\nwith Multi-Level Spatially Pooled Features,\u201d in proceedings of the\nIEEE/CVF conference on computer vision and pattern recognition, 2019,\npp. 9375\u20139383.\n[30] Q. Luo, S. Hu, C. Li, G. Li, and W. Shi, \u201cResource Scheduling in Edge\nComputing: A Survey,\u201d IEEE Communications Surveys & Tutorials,\nvol. 23, no. 4, pp. 2131\u20132165, 2021.\n[31] A. Sauer, T. Karras, S. Laine, A. Geiger, and T. Aila, \u201cStylegan-\nt: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image\nSynthesis,\u201d arXiv preprint arXiv:2301.09515, 2023.\n[32] Z. Wang, T. Schaul, M. Hessel, H. Hasselt, M. Lanctot, and N. Freitas,\n\u201cDueling Network Architectures for Deep Reinforcement Learning,\u201d in\nInternational conference on machine learning. PMLR, 2016, pp. 1995\u2013\n2003.\nRunze Cheng received the Ph.D. degree in Electri-\ncal and Electronic Engineering from the James Watt\nSchool of Engineering, University of Glasgow, U.K.\nin 2023. He is currently a Postdoctoral Research\nAssociate with the Communications, Sensing, and\nImaging Research Group, University of Glasgow,\nGlasgow, U.K. His research interests include in-\ntelligent resource management, semantic communi-\ncation, distributed machine learning, and space-air-\nground integrated networks.\nYao Sun is currently a Lecturer with James Watt\nSchool of Engineering, the University of Glasgow,\nGlasgow, UK. Dr. Sun has extensive research ex-\nperience in wireless communication area. He has\nwon the IEEE IoT Journal Best Paper Award 2022,\nand IEEE Communication Society of TAOS Best\nPaper Award in 2019 ICC. His research interests\ninclude intelligent wireless networking, SemCom\nand wireless blockchain system. Dr. Sun is a senior\nmember of IEEE.\nDusit Niyato (Fellow, IEEE) received the B.Eng.\ndegree from the King Mongkuts Institute of Tech-\nnology Ladkrabang, Thailand, in 1999, and the Ph.D.\ndegree in electrical and computer engineering from\nthe University of Manitoba, Canada, in 2008. He\nis a Professor with the School of Computer Science\nand Engineering, Nanyang Technological University,\nSingapore. His research interests are in the areas of\nsustainability, edge intelligence, decentralized ma-\nchine learning, and incentive mechanism design\nLan Zhang received B.E. and M.S. degrees from the\nUniversity of Electronic Science and Technology of\nChina in 2013 and 2016, respectively, and a Ph.D.\ndegree from the University of Florida in 2020. She\nhas been a tenure-track assistant professor with the\nDepartment of Electrical and Computer Engineering\nat Clemson University since 2024. Before that, she\nwas an assistant professor with the Department of\nElectrical and Computer Engineering at Michigan\nTechnological University from 2020 to 2023. Her\nresearch interests include wireless communications,\ndistributed machine learning, and cybersecurity for various Internet-of-Things\napplications.\nLei Zhang (Senior Member, IEEE) is a Professor\nof Trustworthy Systems with the University of Glas-\ngow, Glasgow, U.K. He has academia and industry\ncombined research experience on wireless commu-\nnications and networks, and distributed systems for\nthe Internet of Things, blockchain, and autonomous\nsystems. His 20 patents are granted/filed in more\nthan 30 countries/regions. He published three books,\nand more than 200 papers in peer-reviewed journals,\nconferences, and edited books.\nDr. Zhang received the IEEE ComSoc TAOS\nTechnical Committee Best Paper Award in 2019, the IEEE Internet of Things\nJournal Best Paper Award in 2022, Digital Communications and Networks\nJournal Best Paper Award 2023 in addition to several best paper awards in\nIEEE conferences. He is the Founding Chair of the IEEE Special Interest\nGroup on Wireless Blockchain Networks in the IEEE Cognitive Networks\nTechnical Committee (TCCN). He delivered tutorials in IEEE ICC\u201920, IEEE\nPIMRC\u201920, IEEE Globecom\u201921, IEEE VTC\u201921 Fall, IEEE ICBC\u201921, EU-\nSIPCO\u201921, and IEEE Globecom22. He is an Associate Editor of IEEE Internet\nof Things Journal, IEEE Wireless Communications Letters, IEEE Transactions\non Network Science and Engineering, and Digital Communications and\nNetworks.\n14\nMuhammad Ali Imran (Fellow, IEEE) is a Pro-\nfessor of Wireless Communication Systems and\nDean of Graduate Studies in College of Science\nand Engineering. His research interests include self-\norganized networks, wireless networked control sys-\ntems, and the wireless sensor systems. He heads the\nCommunications, Sensing and Imaging CSI Hub,\nUniversity of Glasgow, Glasgow, U.K. He is also\nan Affiliate Professor with The University of Okla-\nhoma, Norman, OK, USA, and a Visiting Professor\nwith the 5G Innovation Centre, University of Surrey,\nGuildford, U.K. He has more than 20 years of combined academic and\nindustry experience with several leading roles in multimillion pounds funded\nprojects. He has filed 15 patents and has authored/co-authored more than\n600 journal and conference publications. He is author/editor of 13 books and\nauthor of more than 20 book chapters. He has successfully supervised more\nthan 50 postgraduate students at doctoral level. He has been a consultant\nto international projects and local companies in the area of self-organized\nnetworks. His research interests include self-organized networks, wireless\nnetworked control systems, and the wireless sensor systems.\nProf. Imran is a Fellow of the esteemed societies and institutions like IEEE,\nRSE, IET, EAI and a Senior Fellow of the HEA.\n",
    "2301.03220": "1\nEnabling AI-Generated Content (AIGC) Services in\nWireless Edge Networks\nHongyang Du, Zonghang Li, Dusit Niyato, Fellow, IEEE, Jiawen Kang, Zehui Xiong,\nXuemin (Sherman) Shen, Fellow, IEEE, and Dong In Kim, Fellow, IEEE\nAbstract\u2014Arti\ufb01cial Intelligence-Generated Content (AIGC)\nrefers to the use of AI to automate the information creation\nprocess while ful\ufb01lling the personalized requirements of users.\nHowever, due to the instability of AIGC models, e.g., the\nstochastic nature of diffusion models, the quality and accuracy\nof the generated content can vary signi\ufb01cantly. In wireless\nedge networks, the transmission of incorrectly generated content\nmay unnecessarily consume network resources. Thus, a dynamic\nAIGC service provider (ASP) selection scheme is required to\nenable users to connect to the most suited ASP, improving\nthe users\u2019 satisfaction and quality of generated content. In\nthis article, we \ufb01rst review the AIGC techniques and their\napplications in wireless networks. We then present the AIGC-as-\na-service (AaaS) concept and discuss the challenges in deploying\nAaaS at the edge networks. Yet, it is essential to have perfor-\nmance metrics to evaluate the accuracy of AIGC services. Thus,\nwe introduce several image-based perceived quality evaluation\nmetrics. Then, we propose a general and effective model to\nillustrate the relationship between computational resources and\nuser-perceived quality evaluation metrics. To achieve ef\ufb01cient\nAaaS and maximize the quality of generated content in wireless\nedge networks, we propose a deep reinforcement learning-enabled\nalgorithm for the optimal ASP selection. Simulation results show\nthat the proposed algorithm can provide a higher quality of\ngenerated content to users and achieve fewer crashed tasks by\ncomparing with four benchmarks, i.e., overloading-avoidance,\nrandom, round-robin policies, and the upper-bound schemes.\nIndex Terms\u2014AI-generated content, wireless networks, perfor-\nmance metric, deep reinforcement learning.\nI. INTRODUCTION\nArti\ufb01cial Intelligence-Generated Content (AIGC) tech-\nniques have gained signi\ufb01cant attention due to the unprece-\ndented ability to automate the creation of various content [1],\ne.g., text, images, and videos. Undoubtedly, AIGC will signif-\nicantly impact daily applications, especially Metaverse. With\nthe ability to produce ef\ufb01ciently large amounts of high-\nH. Du, and D. Niyato are with the School of Computer Science\nand Engineering, the Energy Research Institute @ NTU, Interdisciplinary\nGraduate Program, Nanyang Technological University, Singapore (e-mail:\nhongyang001@e.ntu.edu.sg, dniyato@ntu.edu.sg).\nZ. Li is with the School of Information and Communication Engineering,\nUniversity of Electronic Sciences and Technology of China, Chengdu, China.\n(Email: lizhuestc@gmail.com).\nJ. Kang is with the School of Automation, Guangdong University of\nTechnology, China. (e-mail: kavinkang@gdut.edu.cn)\nZ. Xiong is with the Pillar of Information Systems Technology and\nDesign, Singapore University of Technology and Design, Singapore (e-mail:\nzehui xiong@sutd.edu.sg)\nX. Shen is with the Department of Electrical and Computer Engineering,\nUniversity of Waterloo, Canada (e-mail: sshen@uwaterloo.ca)\nD. I. Kim is with the Department of Electrical and Computer Engineering,\nSungkyunkwan University, South Korea (e-mail: dikim@skku.ac.kr)\nquality content, AIGC can save time and resources that would\notherwise be spent on manual content creation.\nRecent\nresearch\nstudies\ndemonstrate\nthat\nsigni\ufb01cant\nprogress has been made in AIGC. Speci\ufb01cally, in text gen-\neration, the authors in [2] and [3] have explored methods\nfor generating coherent and diverse texts using deep learning\ntechniques. For image generation, studies such as [4] and [5]\nhave focused on generating photo-realistic images using gen-\nerative adversarial networks (GANs). In the audio generation,\nthe authors in [6] have explored deep learning techniques for\nsynthesizing high-quality speech. Furthermore, the diffusion\nmodel brings the latest breakthrough in the AIGC area. In\n2020, GPT-3 model was published by OpenAI as a multimodal\ndo-it-all language model that is capable of machine translation,\ntext generation, semantic analysis, etc [7]. Then, the diffusion\nmodel-based DALL-E2 released in 2022 is regarded as the\nstate-of-the-art image generation model which can outperform\nGANs [8].\nHowever, AIGC models require a large amount of data for\ntraining, and the big AIGC models are dif\ufb01cult to be deployed.\nTaking Stable Diffusion for example, Stability AI company\nmaintains over 4,000 NVIDIA A100 GPU clusters and has\nspent over $50 million in operating costs (https://stability.ai/).\nThe Stable Diffusion V1 requires 150,000 A100 GPU hours\nfor a single training session. Moreover, AIGC models that are\ntrained by different datasets are suitable for different tasks. For\nexample, the AIGC model trained by the human face dataset\ncan be used to repair corrupted face images, but may not be\neffective in correcting blurred landscape images. Due to the\ndiversity of users\u2019 tasks and the limited edge device capacities,\nit is dif\ufb01cult to deploy multiple AIGC models on every\nnetwork edge device. To further increase the availability of the\nAIGC services, one promising deployment scheme is based on\n\u201cEverything-as-a-service\u201d (EaaS), which can effectively pro-\nvide users with subscription-based services. By embracing the\nEaaS deployment scheme, we present the concept of \u201cAIGC-\nas-a-service\u201d (AaaS). Speci\ufb01cally, AIGC service providers\n(ASPs) can deploy AI models on edge servers to deliver\ninstant services to users over wireless networks, offering\na more convenient and customizable experience. Users can\neasily access and enjoy AIGC with low latency and resource\nconsumption. There are several advantages of deploying AaaS\nin edge networks:\nA1) Personalization: AIGC models can be used to generate\ncontent tailored to each user\u2019s requirements, providing\na personalized and engaging experience. For example,\npersonalized product recommendations can be offered\narXiv:2301.03220v1  [cs.AI]  9 Jan 2023\n2\nto users based on their locations, preferences, and usage\npatterns.\nA2) Ef\ufb01ciency: By deploying AIGC services closer to users,\nquality of services (QoS) will be improved signi\ufb01cantly,\ne.g., lower delay, while network and computing re-\nsources can be utilized more ef\ufb01ciently due to local\ncontent transfer.\nA3) Flexibility: AIGC can be customized and optimized to\nmeet dynamic demands and resource availability. By\nscheduling wireless network users\u2019 access for AIGC\nservice providers, the overall QoS for users in the\nnetwork can be maximized.\nTherefore, edge-based AaaS has the potential to revolutionize\nthe way that content is created and delivered over wireless\nnetworks. However, the current research on AIGC focuses\nmainly on AIGC model training while ignoring the resource\nallocation issues when deploying AIGC in wireless edge net-\nworks. Speci\ufb01cally, AIGC may require signi\ufb01cant bandwidth\nand computation power to generate and deliver content to\nusers, which could lead to degraded network performance.\nFurthermore, scaling AaaS to meet the needs of a large number\nof users can be challenging. Thus, assigning suitable ASPs to\nusers is critical. On the one hand, users pursue their goals of\nbeing served by the ASPs with the best performance. On the\nother hand, it is important to avoid overloading certain AIGC\nservices and requiring re-transmissions, so as to consume\nscarce network resources. To the best of our knowledge,\nthis is the \ufb01rst research work to discuss the deployments,\naforementioned challenges, and future directions of AIGC in\nwireless edge networks. Our contributions can be summarized\nas follows:\n\u2022 We provide a comprehensive overview of the AIGC and\ntechniques behind it. Then, we discuss various appli-\ncations of AIGC and their use cases in wireless edge\nnetworks and their deployment challenges.\n\u2022 We review the existing image-based perceived quality\nmetrics. By conducting real experiments, we propose a\ngeneral model to reveal the relationship between compu-\ntational resource consumption and the quality of gener-\nated content in AaaS.\n\u2022 We propose a deep reinforcement learning (DRL)-enabled\nmethod to achieve a dynamic selection of optimal ASPs.\nWe demonstrate the superiority of our proposed DRL-\nenabled algorithm compared with four solutions, includ-\ning upper-bound, overloading-avoidance, random, and\nround-robin policies.\nII. AI-GENERATED CONTENT AND TECHNIQUES\nIn this section, we review the recent progress of AIGC.\nSpeci\ufb01cally, we introduce the technologies behind the AIGC.\nThen, we discuss several categories of AIGC and associated\napplications in edge networks.\nA. Generative Techniques\nWe introduce generative techniques in training AIGC mod-\nels [9]. The basic model structures are shown on the left of\nFig. 1.\n\u2022 Autoregressive Models (ARMs): ARMs belong to statis-\ntical modeling that involves predicting the future values\nof a time series based on past values [9]. ARMs can\ngenerate text or other media types for content generation\nby predicting the next element based on the previous\nones. A potential use case for ARMs is to generate music\nby predicting the next note in a musical sequence based\non the previous notes from edge users.\n\u2022 Variational Autoencoders (VAEs): VAEs can generate\nnew data by learning a compact, latent representation\nof the input data, consisting of an encoder network and\na decoder network [9]. The encoder network processes\nthe input data and outputs a latent representation. The\ndecoder network takes this latent representation as input\nand generates synthetic data similar to the input data.\n\u2022 Generative Adversarial Networks (GANs): GANs con-\nsist of two neural networks, i.e., generator and discrimi-\nnator networks [4]. The two networks are trained together\nto improve the generator\u2019s ability to generate realistic\nimages and the discriminator\u2019s ability to distinguish syn-\nthetic images from real images.\n\u2022 Flow-based Models (FBMs): FBMs transform a simple\ndistribution into a target distribution through a series\nof invertible transformations [9]. These transformations\nare implemented as neural networks, and the process of\napplying the transformations is referred to as \u201c\ufb02ow\u201d.\n\u2022 Diffusion Models (DMs): DMs are trained to denoise\nimages blurred by Gaussian noise to learn how to reverse\nthe diffusion process [8]. Several diffusion-based gen-\nerative models have been proposed, including diffusion\nprobabilistic models, noise-conditioned score networks,\nand denoising diffusion probabilistic models.\nMoreover, classic techniques such as Transformer can also\nbe used to train AIGC models, which are discussed in the\nfollowing.\nB. Categories of AIGC and Applications in Mobile Networks\nWe then present several categories of AIGC technologies\nand their applications in edge networks, which can serve as\npotential future research directions.\n1) Text-to-Text AIGC: Text-to-text AIGC can generate the\nhuman-like message as an output based on a given text input.\nTherefore, it can be used for automatic answers, language\ntranslation, or article summarization. One representative text-\nto-text AIGC model is the Generative Pre-training Transformer\n(GPT) (https://openai.com/blog/chatgpt/), a language model\ndeveloped by OpenAI [7]. The GPT is trained on a large\ndataset of human-generated text, such as books or articles.\nThe model can then create text by predicting the next word in\na sequence based on the words that come before it. GPT has\nbeen highly successful and has achieved state-of-the-art results\non several natural language processing (NLP) benchmarks.\nGPT can be used to build many popular language-based\nservices. In wireless edge networks, as shown in Fig. 1, GPT\ncan serve as a chatbot that provides drivers with navigation\nand information alert services.\n3\nArtificial Intelligence-Generated Content (AIGC)-as-a-Service\nCategories of AIGC and \nApplications in Edge Network\nGenerative Techniques\nAutoregressive Models\nX1\nX2\nXn\n...\nVariational Autoencoders\nX\nEncoder\nZ\nDecoder\nX`\nGenerative Adversarial Networks\nFlow-based Models\n`\nX\nDiscriminator\nGenerator\n0/1\nX`\nZ\nX`\nX\nFlow\nZ\n`\nInverse\nX`\nDiffusion Model\nXT\nXt\nXt-1\nX0\n... \n... \nProbability\n(Xt-1|Xt)\nProbability\n(Xt|Xt-1)\n1) Text-to-Text AIGC\n4) Image-to-Image AIGC\n5) Audio-related AIGC\nUser: How can I go to the supermarket?\nAIGC: Go Straight and turn left.\nUser: Please draw me a map that shows \nthe road.\nAIGC: \n1) Text-to-Text AIGC\nUser: How can I go to the supermarket?\nAIGC: Go Straight and turn left.\n2) Text-to-Image AIGC\nUser: Please create a \n3D robot model for me.\nAIGC:\nAIGC:\nUser: \nAIGC: \nUser: \nAIGC: \nUser: Please draw me a picture \nin which a cat is sleeping.\nAIGC: \nUser: Please draw me a map that shows \nthe road.\nthe road\nthe road\nAIGC: \n2) Text-to-Image AIGC\nUser: Please draw me a picture \nPlease draw me a picture \nin which a cat is sleeping.\nAIGC:\n4) Image-to-Image AIGC\nUser:\nAIGC:\nUser:\nAIGC:\n3) Text-to-3D AIGC\nUser: Create some music.\nAIGC:\n5) Audio-related AIGC User: Create some music.\nAIGC:\nUser: Let this robot \nimitate my tone.\nAIGC:\n\u0102\nAIGC Service Providers\nMobile Users\nSupport\nImage Creation From Draft\nCorrupted Image repair\n\u0102\nExample: ChatGPT is a large language model chatbot \ndeveloped by OpenAI based on GPT-3.5\nhttps://openai.com/blog/chatgpt/\nExample: Imagen launched by \nGoogle, is a text-to-image \ndiffusion model with an \nunprecedented degree of \nphotorealism and a deep level \nof language understanding.\nhttps://imagen.research.google/\nExample: DreamFusion launched \nby Google can create 3D model \nbased on the given text.\nhttps://dreamfusion3d.github.io/\nExample: Crypko launched \nby Preferred Networks Inc can \ncreate waist up illustrations of \nanime characters.\nhttps://crypko.ai/\nExample: Human Voice \nGenerator launched by Murf \nAI can make studio-quality  \nvoice overs in minutes.\nhttps://murf.ai/\nFig. 1.\nGenerative techniques in AIGC [9], categories of AIGC, and applications in wireless edge networks. We list several online available AIGC\nservices as examples, e.g., ChatGPT for text-to-text AIGC (https://openai.com/blog/chatgpt/), Imagen for text-to-image AIGC (https://imagen.research.google/),\nDreamFusion for text-to-3D AIGC (https://dreamfusion3d.github.io/), Crypko for image-to-image AIGC (https://crypko.ai/), and Human Voice Generator for\naudio-related AIGC (https://murf.ai/).\n2) Text-to-Image AIGC: Text-to-image AIGC allows users\nto generate images based on text input, enabling the creation\nof visual content from written descriptions. It can be regarded\nas a combination of natural language processing and computer\nvision techniques. As shown in Fig. 1, the text-to-image AIGC\ncan assist mobile users with various activities. For example,\nusers in Internet-of-Vehicles can request visual-based path\nplanning. Furthermore, text-to-image AIGC can also assist\nusers in creating art and producing pictures in various styles\nbased on users\u2019 descriptions or keywords.\n3) Text-to-3D AIGC: Text-to-3D AIGC can generate 3D\nmodels from text descriptions while using wireless AR appli-\ncations. Typically, generating 3D models requires higher com-\nputational resources than generating 2D images. Considering\nthe development of next-generation Internet services, such as\nMetaverse [10], generating 3D models based on text without\ncomplicated manual design is fascinating.\n4) Image-to-Image AIGC: Image-to-Image AIGC uses AI\nmodels to generate realistic images from source images or\ncreate a stylized version of an input image. For example, when\nit comes to assisting artwork creation, image-to-image AIGC\ncan generate visually satisfying pictures based solely on user-\ninputted sketches. Furthermore, image-to-image AIGC can be\nused for image editing services. Users can remove occlusions\nin one image or repair corrupted images.\n5) Audio-related AIGC: Audio-related AIGC models ana-\nlyze, classify, and manipulate audio signals, including speech\nand music. Speci\ufb01cally, text-to-speech models are designed\nto synthesize natural-sounding speech from text input. Music\ngeneration models can synthesize music in a variety of styles\nand genres. Audio-visual music generation involves using\nboth audio and visual information, such as music videos or\nalbum artwork, to generate music compositions that are more\nclosely tied to a particular visual style or theme. Moreover,\naudio-related AIGC can serve as voice assistants that an-\nswer users\u2019 queries. Alexa (https://developer.amazon.com/en-\nUS/alexa) and Siri (https://www.apple.com/sg/siri/) are exam-\nples of real-life applications.\nGiven the power of AIGC models, there are several chal-\nlenges in deploying AaaS in wireless edge networks, which\nare introduced in the following.\nIII. AI-GENERATED CONTENT-AS-A-SERVICE IN\nWIRELESS EDGE NETWORKS\nIn this section, we discuss the AaaS in detail, including the\nchallenges and performance metrics.\nA. AI-Generated Content-as-a-Service and Challenges\nTo deploy AaaS in wireless edge networks, the ASPs should\n\ufb01rst train AIGC models on large datasets. The AIGC models\n4\nwould need to be hosted on edge servers and can be accessed\nby users. Continuous maintenance and updates would be\nrequired to ensure that the AIGC models remain accurate and\neffective for generating high-quality content. Users can submit\nrequests for content generation and receive the generated\ncontent from edge servers rented by ASPs. Despite several\nadvantages of deploying AaaS in wireless edge networks, there\nare pertaining challenges to be addressed.\n\u2022 Bandwidth Consumption: The AIGC consumes a sig-\nni\ufb01cant amount of bandwidth. Especially for AaaS\nrelated to high-resolution images, both upload and\ndownload processes require considerable network re-\nsources to ensure low-latency services. For example,\nthe data size of an AI-generated wallpaper in wall-\nhaven (https://wallhaven.cc/tag/133451) can be around\n10 Megabytes. Furthermore, due to the diversity of the\ngenerated images, users may make multiple repeated\nrequests to speci\ufb01c edge servers to obtain a satisfactory\nimage.\n\u2022 Time-varying Channel Quality: The QoS in AaaS can\nbe affected by the wireless transmission of the generated\ncontent. Low Signal-to-Noise Ratio (SNR), low Outage\nProbability (OP), and high bit-error probability (BEP) can\ndegrade QoS of AIGC services and users\u2019 satisfaction,\nwhich results from time-varying fading channels when\nthe channel encounters deep fading occasionally.\n\u2022 Dataset used for training AIGC Models: The dataset\nused for training AIGC models can impact the quality of\nthe generated content. Since different ASPs have various\nAIGC models, users can be allocated to the suitable ASP\nto meet their requirements. For example, AIGC models\ntrained with more face images will be more suitable for\ngenerating avatars than those trained with other datasets.\n\u2022 Computation Resource Consumption: The well-trained\nAIGC model still consumes time and computational re-\nsources when generating content, e.g., \ufb01ne-tuning and\ninference. For example, the quality of the output of\nthe diffusion model-AaaS increases with the number of\ninference steps.\n\u2022 Utility Maximization and Incentive Mechanism: In-\ncentive mechanism design is signi\ufb01cant in AaaS as it can\nmotivate ASPs to generate high quality content, meeting\nthe desired goals and objectives. Here, the utility function\nshould include the perceived QoS from users.\nA common issue in addressing the above challenges is eval-\nuating AIGC performance. Although many evaluation metrics\nin various modalities have been proposed, most of them are\nbased on AI models or are dif\ufb01cult to be calculated, without\na mathematical expression. For the optimal design of AaaS\nin wireless networks, AI-based resource allocation solutions\ncan utilize AI-based performance metrics to consider the sub-\njective feelings of the user. However, traditional mathematical\nresource allocation schemes require modeling the relationship\nbetween the computational resources consumption, e.g., the\nnumber of inference steps in the diffusion model, and the\nquality of the generated content, as shown in Fig. 2. To\nsolve this problem, taking image-related AaaS as an example,\nwe introduce various performance evaluation metrics and\nexplore the mathematical relationship between metric values\nand computational resource consumption in the following.\nB. Performance Metric Modelling\nWe \ufb01rst discuss AIGC evaluation metrics. We focus on\nevaluating the perceived quality of images, but the same\nmethodology can be applied to other types of content. Then,\nwe formulate the relationship between computational resource\nconsumption and the quality of generated content in AaaS.\n1) Image-based\nmetrics:\nThe\nimage\nquality\nassess-\nment metrics can be distribution-based and image-based.\nThe distribution-based metrics, e.g., Frechet inception dis-\ntance [11], take a list of image features to compute the dis-\ntance between distributions for evaluating generated images.\nHowever, for practical AaaS in the wireless network, the\nquality evaluation is subjective, and it is hard for users to\ncalculate distribution-based metrics. Thus, we focus on image-\nbased metrics that attempt to achieve consistency in quality\nprediction by modeling salient physiological and psycho-\nvisual features of the human visual system or by signal \ufb01delity\nmeasures.\nSpeci\ufb01cally, without access to the original image as a\nreference, no-reference image quality evaluation methods can\nbe considered [11]:\n\u2022 Total Variation (TV): TV is a measure of the smooth-\nness of an image. One common way to compute total\nvariation is to take the sum of the absolute differences\nbetween adjacent samples in an image. This measures\nthe \u201droughness\u201d or \u201ddiscontinuity\u201d of the image.\n\u2022 Blind/Referenceless Image Spatial Quality Evalua-\ntor (BRISQUE)1: BRISQUE utilizes scene statistics of\nlocally normalized luminance coef\ufb01cients to quantify\npossible losses of \u201cnaturalness\u201d in the image due to dis-\ntortions [12]. It has been shown that BRISQUE performs\nwell in correlation with human perception of quality.\nThe higher the image quality, the smaller the values of TV\nand BRISQUE.\nFor AaaS where a reference image is available, we can use\nfull-reference image quality evaluation methods [11]:\n\u2022 Discrete\nCosine\nTransform\nSubbands\nSimilarity\n(DSS): DSS exploits essential characteristics of human\nvisual perception by measuring changes in structural\ninformation in subbands in the discrete cosine transform\n(DCT) domain and weighting the quality estimates for\nthese subbands [13].\n\u2022 Haar\nWavelet-based\nPerceptual\nSimilarity\nIndex\n(HaarPSI): HaarPSI utilizes the coef\ufb01cients obtained\nfrom a Haar wavelet decomposition to assess local sim-\nilarities between two images, as well as the relative\nimportance of image areas.\n\u2022 Mean Deviation Similarity Index (MDSI): MDSI is a\nreliable and complete reference perceptual image quality\nassessment model that utilizes gradient similarity, chro-\nmaticity similarity, and deviation pooling.\n1http://live.ece.utexas.edu/research/quality/\n5\nInference steps\nBRISQUE\n0      10      20     30      40\n0       50    100    150    200    250\nInference steps\nBRISQUE\n0      10      20     30      40\n0       50    100    150    200    250\n\u0102\n\u0102\n\u0102\n\u0102\n10                40              70              100            130             160            190             220             250\nTimesteps\n\u0102\nMobile Users\n\u0102\nAIGC Service Providers\nUplink: \nCorrupted \nImages\nDownlink: \nRepaired \nImages\nASP \nSelection \nScheme\nA\n\u0102\nOriginal Images:\nMask:\nCorrupted Images: (To be uploaded)\nRepaired Images: (To be downloaded)\nNo-Reference: \nBRISQUE, TV\nFull-Reference: \nVIFp, DSS, \nHaarPSI, MDSI\nPerformance \nMetrics\nServer\nOur Experiment Demo of AaaS in Wireless Edge Network\nReceived Images\nUploaded Images\nUser1\nUser2\nUser3\nServer\nUser1\nUser2\nUser3\nB\nC\nD\nE\nSystem \nModel\nPerformance Metric\nFig. 2. Example of an AaaS for repairing corrupted images. The corrupted images are shown in Part A, and the repaired images under different inference\nsteps are shown in Part D. Part B shows how the performance metric, BRISQUE, varies over different inference steps. Part C shows the system model of\nASP selection problem. A experiment demo is shown in Part E.\n\u2022 Visual Information Fidelity (VIF): VIF is a competitive\nway of measuring \ufb01delity that relates well with visual\nquality, which quanti\ufb01es the information in the reference\nimage and how much of the reference information can be\nextracted from the distorted image.\nThe higher the image quality, the higher the values of the\naforementioned full-reference image quality metrics.\n2) A General Modelling of Perceived Image Quality Metric:\nAIGC models based on diffusion models are becoming main-\nstream. As shown in the left of Fig. 1, the diffusion process can\nbe regarded as a step-wise denoising process. Thus, increasing\nthe number of inference steps will improve the perceived\nimage quality. However, the generated image quality does not\nalways increase with the number of steps. Excessive inference\nsteps incur unnecessary resource consumption. We conduct\nreal experiments to investigate the relationship between the\nnumber of inference steps and various perceived image quality\nmetrics, i.e., TV, BRISQUE, DSS, HaarPSI, MDSI, and VIF.\nThe experimental platform is built on a generic Ubuntu\n20.04 system with an AMD Ryzen Threadripper PRO\n3975WX 32-Cores CPU and an NVIDIA RTX A5000 GPU.\nWe take diffusion model-based corrupted image restoration\nservice as an example of AaaS. Speci\ufb01cally, we deploy the\nwell-trained model, RePaint, proposed in [14] on our server.\nAs shown in Fig. 2 (Part A), we \ufb01rst generate a series of\ncorrupted images, e.g., 20 images, with the help of masks.\nThen, these corrupted images are fed into RePaint. We can\nobserve that the corrupted image gradually recovers as the\ninference progresses, as shown in Fig. 2 (Part D). Moreover,\nthe values of image quality metric, e.g., BRISQUE, decrease,\nas shown in Fig. 2 (Part B). We show the values of each\nperformance metric under the different number of timesteps\nin Fig. 3.\nThus, we present a general model of the perceived image\nquality metric that contains four parameters, as shown at the\ntop of Fig. 3. Speci\ufb01cally, Ax is the minimum number of\ninference steps where the image quality starts to improve,\nAy is the lower bound of the image quality, which can be\nregarded as the evaluation value for images with high noise,\nBx is the number of inference steps when the image quality\nstarts to stabilise because of the capability of AIGC models,\nand By is the highest image quality value that the model can\nachieve. Regardless of whether the performance metric value is\npositively or inversely proportional to the image quality, and\nregardless of the AaaS types, we can easily \ufb01nd the points\n(Ax, Ay) and (Bx, By) experimentally, as shown in Fig. 3.\nLesson Learned: Despite the inherent uncertainty of the\ndiffusion process, from Fig. 3, we can observe that the per-\nceived image quality increases or decreases approximately\nproportionally with the increase of inference steps. In the\npractical AIGC model analysis, we can perform experiments\nwith the simple \ufb01tting method as shown in Fig. 3 to a\nperformance metric to obtain four parameters in our proposed\ngeneral mathematical model. Then, the model can be used in\nwireless edge network-enabled AIGC services analysis.\nIV. DEEP REINFORCEMENT LEARNING-AIDED DYNAMIC\nASP SELECTION\nIn this section, we study the optimal ASP edge server\nselection problem. We propose a DRL-enabled solution to\nmaximize utility function while satisfying users\u2019 requirements.\n6\nx\nA\ny\nA\nx\nB\ny\nB\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\n0\n5\n10\n15\n20\n25\n0\n5\n10\n15\n20\n25\nTimestep\n0.4\n0.5\n0.6\n0.7\nMDSI\n0.3\n0.25\n0.3\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\n0\n5\n10\n15\n20\n25\nTimestep\n0.4\n0.5\n0.6\n0.7\nMDSI\n0.3\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n5\n10\n15\n20\n25\n0\n5\n10\n15\n20\n25\n0\nTimestep\n0.3\n0.5\n0.7\n0.9\nHaarPSI\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n5\n10\n15\n20\n25\n0\nTimestep\n0.3\n0.5\n0.7\n0.9\nHaarPSI\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0\n5\n10\n15\n20\n25\n0\n5\n10\n15\n20\n25\nTimestep\n0.2\n0.4\n0.6\n0.8\nDSS\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n0\n5\n10\n15\n20\n25\nTimestep\n0.2\n0.4\n0.6\n0.8\nDSS\n0\n10\n20\n30\n40\n50\n60\n70\n0\n10\n20\n30\n40\n50\n60\n70\n0\n10\n20\n30\n40\n50\n60\n70\n0\n5\n10\n15\n20\n25\n0\n5\n10\n15\n20\n25\nTimestep\n20\n40\n60\nBRISQUE\n0\n10\n20\n30\n40\n50\n60\n70\n0\n5\n10\n15\n20\n25\nTimestep\n20\n40\n60\nBRISQUE\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0\n5\n10\n15\n20\n25\n0\n5\n10\n15\n20\n25\n0.2\n0.4\n0.6\n0.8\nTimestep\nVIF\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0\n5\n10\n15\n20\n25\n0.2\n0.4\n0.6\n0.8\nTimestep\nVIF\n0\n20\n40\n60\n80\n100\n120\n140\n160\n180\n0\n20\n40\n60\n80\n100\n120\n140\n160\n180\n0\n20\n40\n60\n80\n100\n120\n140\n160\n180\n0\n5\n10\n15\n20\n25\n0\n5\n10\n15\n20\n25\nTimestep\n40\n80\n120\n160\nTV\n0\n20\n40\n60\n80\n100\n120\n140\n160\n180\n0\n5\n10\n15\n20\n25\nTimestep\n40\n80\n120\n160\nTV\n(\n)\n,\nx\ny\nA A\n(\n)\n,\nx\ny\nB B\n(\n)\n,\nx\ny\nA A\n(\n)\n,\nx\ny\nA A\n(\n)\n,\nx\ny\nA A\n(\n)\n,\nx\ny\nA A\n(\n)\n,\nx\ny\nA A\n(\n)\n,\nx\ny\nB B\n(\n)\n,\nx\ny\nB B\n(\n)\n,\nx\ny\nB B\n(\n)\n,\nx\ny\nB B\n(\n)\n,\nx\ny\nB B\nParameters\nMetrics\nTV\nBRISQUE\nDSS\nHaarPSI\nMDSI\nVIF\n10\n0.1\n14\n0.7\n7\n0.4\n14\n0.77\n5\n0.4\n14\n0.67\n5\n79.3\n10\n21\n5\n0.3\n13\n0.65\n1\n40\n6\n17\nNo-reference image \nquality evaluation\nFull-reference image \nquality evaluation\n(\n)\ny\ny\nx\ny\nx\nx\nB\nA\nA\nA\nB\nA\n-\n=\n- - - - - -\n+\n-\nPerceived Image Quality =  \nTimesteps\n(\n)\ny\ny\nx\ny\nx\nx\nB\nA\nA\nA\nB\nA\n-\n=\n- - - - - -\n+\n-\nPerceived Image Quality =  \nTimesteps\nWhen        < Timesteps <\nx\nA\nx\nB\nWhen        < Timesteps <\nx\nA\nx\nB\nWhen Timesteps >=\nx\nB\nWhen Timesteps >=\nx\nB\nWhen Timesteps <=\nx\nA\nWhen Timesteps <=\nx\nA\ny\nA\ny\nB\n(\n)\ny\ny\nx\ny\nx\nx\nB\nA\nA\nA\nB\nA\n-\n=\n- - - - - -\n+\n-\nPerceived Image Quality =  \nTimesteps\nWhen        < Timesteps <\nx\nA\nx\nB\nWhen Timesteps >=\nx\nB\nWhen Timesteps <=\nx\nA\ny\nA\ny\nB\nFitting\nParameter \nValues\n(x10)\n(x10)\n(x10)\n(x10)\n(x10)\n(x10)\nFig. 3. The relationship between the number of inference steps and various perceived image quality metrics, i.e., TV, BRISQUE, DSS, HaarPSI, MDSI, and\nVIF.\nA. AaaS System Model\nOur demo is shown in Fig. 2 (Part E). Speci\ufb01cally, three\nusers are selecting between two image reparation AIGC mod-\nels that are trained on datasets CelebA-HQ and Places2 [14],\nrespectively. User 1 and User 2 upload the same corrupted\nimages. We can observe that different AIGC models will create\ndifferent results for the same user task.\nThen, we study the case for large-scale deployment of AaaS\nin wireless edge networks. We consider 20 AIGC service\nproviders (ASPs) and 1000 edge users in the simulation.\nEach ASP provides AaaS with maximal resource capacity, i.e.,\ntotal diffusion timesteps within a time window, ranging from\n600 to 1500 at random. Each user submits multiple AIGC\ntask requests to ASPs at different times. These tasks specify\nthe amount of AIGC resources that they need, i.e., diffusion\ntimesteps, which we set as a random value between 100 and\n250. The user task arrivals follow the Poisson distribution.\nSpeci\ufb01cally, during a period of 288 hours, user tasks arrive\nat the rate of \u03bb = 0.288 hour/request and there are a total of\n1000 tasks. Note that the quality of AIGC models provided\nby different ASPs is different, e.g., the repaired images could\nbe more realistic and natural.\nA simple, yet less effective ASP selection, is that the user\nsends the task request directly to the ASP with the best quality\nof generated content. However, this approach will inevitably\noverload some ASPs due to insuf\ufb01cient computational re-\nsources and interrupting tasks in practice. In addition, the qual-\nity of generated content of ASPs is unknown to users. Mobile\nusers need to ask ASPs several times to estimate the quality\nof generated content to execute myopic selection, which\nintroduces unnecessary load and wireless network resource\nconsumption. To this end, under the premise of the unknown\nquality of generated content, how to choose a suitable ASP for\nuser tasks to maximize the overall system\u2019s utility and reduce\nAIGC resource overload and interruption caused by popular\nASPs, is a challenging yet important problem.\nB. Deep Reinforcement Learning-based Solution\nReward\n(QYLURQPHQW\n)ORZ\u0003RI\u0003DUULYLQJ\u0003\nXVHU\u0003WDVNV\n$63V\n'11\n'11\n'11\n/RVV\u0003\n)XQFWLRQ\n/RVV\u0003\n)XQFWLRQ\nNext State\nState, Reward,\nAction, Next State\nReplay Memory\nAction\nState\n$FWRU\n/RVV\u0003\n)XQFWLRQ\n&ULWLF\nFig. 4. The structure of soft actor\u2013critic DRL algorithm.\nWe use the soft actor\u2013critic (SAC) DRL [15] to solve\nthe above dynamic ASP selection problem. As shown in\nFig. 4, the learning process alternates between policy eval-\nuation (Critic) and policy improvement (Actor). Unlike the\nconventional actor-critic architecture, the policy in SAC is\ntrained to maximize a trade-off between the expected return\nand entropy. The state space, action space, and reward in the\nAaaS environment are de\ufb01ned as follows:\n\u2022 State: The state space is composed of two parts: (a) a\nfeature vector (the demand of AIGC resources for current\nuser task and the estimated completion time of the task)\n7\nof the arriving user task, and (b) feature vectors (the\ntotal AIGC resources of the i-th ASP and the currently\navailable resources of the i-th ASP) of all ASPs in the\ncurrent state.\n\u2022 Action. The action space of the ASP selection problem\nis an integer indicating the selected ASP. In detail, the\nactor policy network outputs a 20-dimensional logits\nvector, and then the probability of selecting each ASP\nis obtained after being post-processed by the softmax\noperator. Finally, DRL selects an ASP to handle the\ncurrent user task according to the assigned probability\nof each ASP.\n\u2022 Reward. The reward consists of two parts: a quality of\ngenerated content reward and an congestion penalty. The\nformer is de\ufb01ned as the perceived quality of the repaired\nimage, as discussed in Section III-B. Furthermore, any\naction that overloads AIGC models must be penalized as\nan congestion penalty. First, the action itself should be\npunished with \ufb01xed penalty value. Second, considering\nthat ill-considered actions can cause bottleneck ASP\u2019s\nmodel to crash and the running tasks will be interrupted,\nthe current action will also be subject to additional\npenalties according to the progress of ongoing tasks. The\ntotal reward returned is the quality reward minus the\ncongestion penalty. Note that a larger penalty value will\nencourage DRL to pay more attention to avoid crashes.\nWe compare the performance of the DRL-enabled ASP\nselection algorithm with four benchmarks. The lower bound\nis the random allocation policy, assigning every new user task\nto an ASP randomly. In contrast, the optimal policy gives\nan approximate upper-bound on the performance, assuming\nthat the quality scores available for each task on all ASPs\nare known (which is a posterior knowledge and is rarely\nsatis\ufb01ed in practice). The upper-bound policy can use the\ngreedy algorithm to allocate a new user task to the ASP with\nenough AIGC resources and the highest quality. Furthermore,\nwe implement the round-robin and overloading-avoidance\npolicies, which are widely adopted in web applications to\nrealize load balancing. It is simple, easy to implement, and\nstarvation-free. The overloading-avoidance policy assigns the\nnew user task to the ASP with most AIGC resources currently\navailable to prevent or reduce the severity of overloads and\ncrashes.\nFigure 5 shows the utility curves (i.e., reward curves) of the\nDRL-enabled ASP selection policy and the four benchmark\npolicies. Since DRL can learn and evolve, as the learning\nstep progresses, DRL has a more comprehensive and accurate\nselection of the ASP. Thus the utility rises rapidly, showing\nunique learning ability. One interesting \ufb01nding is that when\nDRL overtakes the round-robin, DRL already has a speci\ufb01c\nload-balancing capability. Immediately afterward, DRL sur-\npasses overloading-avoidance. At this time, DRL has learned\nto avoid actions that may cause crashes, thereby avoiding the\ncongestion penalty. Then, DRL starts to learn the priority of\ndifferent ASPs, and it seeks to place the current user task on\nthe ASP with high quality to maximize the reward. Therefore,\nas shown in Fig. 5, DRL still has much room for improvement\n0\n2\n4\n6\n8\n10\nIteration Number\n105\n-400\n-200\n0\n200\n400\n600\n800\nReward\nUpper Bound\nOverloading-avoidance Policy \nRandom Policy\nRound-Robin Policy\nDeep Reinforcement Learning Algorithm\nFig. 5.\nReward values versus the number of iteration number in DRL.\nFor performance comparison, we show the results of overloading-avoidance,\nrandom, round-robin policies, and their upper bound.\nUpper\n Bound\nDeep Reinforcement\n Learning Algorithm\nCrash Avoid\n Algorithm\nRound Robin\n Algorithm\nRandom\n Allocation\nASP Selection Algorithms\n0\n0.2\n0.4\n0.6\n0.8\n1\nNormalized Values\nNumber of Crashed AIGC Tasks\nFinal Reward\nAverage Reward of Finished Tasks\n0\n5830.59\n0\n0\n578\n0.54\n3780.38\n24\n284\n0.34\n116\n97.3\n0.35\nUpper Bound\nDeep Reinforcement \nLearning Algorithm\nOverloading-\navoidance Policy\nRound-Robin \nPolicy\nRandom Policy\nFig. 6. Comparison of episodic rewards, average rewards of \ufb01nished tasks,\nand number of crashed tasks.\nafter surpassing the overloading-avoidance policy and \ufb01nally\nreaching an episodic reward comparable to the upper-bound\npolicy.\nFigure 6 counts the episodic rewards, the average rewards\nof \ufb01nished tasks, and the number of crashed tasks of the \ufb01ve\npolicies. On the one hand, the DRL-enabled ASP selection\npolicy achieves zero task crashes and minimizes the congestion\npenalty, which is critical to providing a satisfying quality of\ngenerated content to users. On the other hand, DRL policy can\nlearn the quality of content that ASPs may provide, which is\nunknown in other policies. Then, DRL can assign user tasks\nto ASPs that can provide higher QoS so that the average\nreward for each task is effectively increased. The combination\nof the above two advantages makes a much higher cumulative\nepisodic reward for the DRL-enable ASP selection policy.\nV. FUTURE DIRECTION\nA. Secure AIGC-as-a-Service\nWhen deploying AaaS in a wireless network, the requests\nfrom users and the generated contents from ASPs are trans-\nmitted in a wireless environment. Therefore, advanced security\n8\ntechniques for AIGC need to be studied, e.g., protecting the\ntransmission of AIGC data through improved physical layer\nsecurity techniques. Moreover, blockchain can be used to\nenable decentralized content distribution, allowing content to\nbe shared and accessed directly between users without the\nneed for a central authority. The authenticity and provenance\nof AIGC can be veri\ufb01ed with the aid of blockchain, helping to\nensure that the AIGC is accurate and trustworthy. Furthermore,\nduring the training process of AIGC models, the privacy of\nthe training data needs to be guaranteed, especially biometric\ndata, such as face images. One possible solution is to train the\nmodel by secure federated learning.\nB. IoT-based and Wireless Sensing-aided Passive AaaS\nConsidering the fast development of sensing technologies,\nwe aim to enable ubiquitous passive AaaS with wireless\nsensing signals. For example, wireless sensors can gather data\nabout the environment or user behavior, which can then be fed\ninto an AIGC model to generate relevant content. Wireless\nsensing-aided passive AaaS can also be used in healthcare.\nSpeci\ufb01cally, by using IoT devices to detect users\u2019 activity\nlevels, sleep patterns, or heart rates with the aid of wireless\nsensing, the AIGC could generate content such as personalized\nworkout plans. Moreover, the mobility of network devices\npredominantly affects the throughput of the connected links\nfor AaaS, which is worth further study.\nC. Personalized Resource Allocation in AaaS\nAlthough the current AIGC models can meet users\u2019 needs\nwith customized tasks, more studies are needed to achieve\npersonalized AIGC services. For example, for text-to-image\nAaaS, when both users enter the text \u201cA monkey is standing\nnext to a zebra\u201d, current ASPs will produce similar images for\nusers. However, if we deduce that the two users are a horse\ntrainer and a monkey researcher, respectively, we can per-\nsonalize the computing resource allocation [10]. Speci\ufb01cally,\nmore computing resources should be allocated to generate\nand transmit the zebra in the image for the horse trainer.\nFor the monkey researcher, the AIGC model that is more\nadapted to generating monkey images should be assigned to\nhandle the task. One potential solution is incorporating user\nfeedback and preferences into the content generation process\nand developing techniques for evaluating the effectiveness of\npersonalized content.\nVI. CONCLUSION\nIn this article, we reviewed the AIGC technologies and\ndiscussed the applications in wireless networks. To provide\nAIGC services to users, we proposed the concept of AaaS.\nThen, the challenges of deploying AaaS in wireless networks\nare discussed. In addressing these challenges, a fundamental\nproblem is about the mathematical relationship between the\nresource consumption and the perceived quality of the gener-\nated content. After exploring various image-based performance\nevaluation metrics, we proposed a general modeling equation.\nMoreover, we studied the important ASP selection problem.\nA DRL-enabled algorithm was used to achieve nearly optimal\nASP selection. As the \ufb01rst article to discuss AIGC in wireless\nnetworks, we hope that this article can inspire researchers\nto contribute to the advancement of wireless edge networks-\nenabled AaaS.\nREFERENCES\n[1] L. Yunjiu, W. Wei, and Y. Zheng, \u201cArti\ufb01cial intelligence-generated and\nhuman expert-designed vocabulary tests: A comparative study,\u201d SAGE\nOpen, vol. 12, no. 1, Jan. 2022.\n[2] M. Chen, A. Radford, R. Child, J. Wu, H. Jun, D. Luan, and I. Sutskever,\n\u201cGenerative pretraining from pixels,\u201d in Proc. Int. Conf. Mach. Learn.\nPMLR, 2020, pp. 1691\u20131703.\n[3] J. Guo, S. Lu, H. Cai, W. Zhang, Y. Yu, and J. Wang, \u201cLong text\ngeneration via adversarial training with leaked information,\u201d in Proc.\nAAAI Conf. Artif. Intell., vol. 32, no. 1, 2018.\n[4] T. Karras, T. Aila, S. Laine, and J. Lehtinen, \u201cProgressive growing of\ngans for improved quality, stability, and variation,\u201d in Proc. Int. Conf.\nMach. Learn., 2018.\n[5] X. Huang, M.-Y. Liu, S. Belongie, and J. Kautz, \u201cMultimodal unsu-\npervised image-to-image translation,\u201d in Proc. Eur. Conf. Comput. Vis.,\n2018, pp. 172\u2013189.\n[6] W. Ping, K. Peng, K. Zhao, and Z. Song, \u201cWaveFlow: A compact \ufb02ow-\nbased model for raw audio,\u201d in Proc. Int. Conf. Mach. Learn.\nPMLR,\n2020, pp. 7706\u20137716.\n[7] L. Floridi and M. Chiriatti, \u201cGPT-3: Its nature, scope, limits, and\nconsequences,\u201d Minds Mach., vol. 30, no. 4, pp. 681\u2013694, Apr. 2020.\n[8] P. Dhariwal and A. Nichol, \u201cDiffusion models beat GANs on image\nsynthesis,\u201d Adv. Neural Inf. Process. Syst., vol. 34, pp. 8780\u20138794, 2021.\n[9] G. Harshvardhan, M. K. Gourisaria, M. Pandey, and S. S. Rautaray,\n\u201cA comprehensive survey and analysis of generative models in machine\nlearning,\u201d Comput. Sci. Rev., vol. 38, p. 100285, 2020.\n[10] H. Du, J. Liu, D. Niyato, J. Kang, Z. Xiong, J. Zhang, and D. I. Kim,\n\u201cAttention-aware resource allocation and QoE analysis for metaverse\nxURLLC services,\u201d arXiv preprint arXiv:2208.05438, 2022.\n[11] S. Kastryulin, D. Zakirov, and D. Prokopenko, \u201cPyTorch Image Quality:\nMetrics and measure for image quality assessment,\u201d 2019, open-\nsource software available at https://github.com/photosynthesis-team/piq.\n[Online]. Available: https://github.com/photosynthesis-team/piq\n[12] A. Mittal, A. K. Moorthy, and A. C. Bovik, \u201cNo-reference image quality\nassessment in the spatial domain,\u201d IEEE Trans. Image Process., vol. 21,\nno. 12, pp. 4695\u20134708, Dec. 2012.\n[13] L. Gatys, A. Ecker, and M. Bethge, \u201cA neural algorithm of artistic style,\u201d\nJ. Vis., vol. 16, no. 12, pp. 326\u2013326, Dec. 2016.\n[14] A. Lugmayr, M. Danelljan, A. Romero, F. Yu, R. Timofte, and\nL. Van Gool, \u201cRepaint: Inpainting using denoising diffusion probabilistic\nmodels,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2022, pp.\n11 461\u201311 471.\n[15] P. Christodoulou, \u201cSoft actor-critic for discrete action settings,\u201d arXiv\npreprint arXiv:1910.07207, 2019.\n",
    "2303.02836": "1\nBlockchain-Empowered Lifecycle Management for\nAI-Generated Content (AIGC) Products in Edge\nNetworks\nYinqiu Liu, Hongyang Du, Dusit Niyato, Fellow, IEEE, Jiawen Kang, Zehui Xiong,\nChunyan Miao, Fellow, IEEE, Xuemin (Sherman) Shen, Fellow, IEEE, and Abbas Jamalipour, Fellow, IEEE\nAbstract\u2014The rapid development of Arti\ufb01cial Intelligence-\nGenerated Content (AIGC) has brought daunting challenges\nregarding service latency, security, and trustworthiness. Recently,\nresearchers presented the edge AIGC paradigm, effectively\noptimize the service latency by distributing AIGC services to\nedge devices. However, AIGC products are still unprotected and\nvulnerable to tampering and plagiarization. Moreover, as a kind\nof online non-fungible digital property, the free circulation of\nAIGC products is hindered by the lack of trustworthiness in\nopen networks. In this article, for the \ufb01rst time, we present\na blockchain-empowered framework to manage the lifecycle of\nedge AIGC products. Speci\ufb01cally, leveraging fraud proof, we\n\ufb01rst propose a protocol to protect the ownership and copyright\nof AIGC, called Proof-of-AIGC. Then, we design an incentive\nmechanism to guarantee the legitimate and timely executions of\nthe funds-AIGC ownership exchanges among anonymous users.\nFurthermore, we build a multi-weight subjective logic-based\nreputation scheme, with which AIGC producers can determine\nwhich edge service provider is trustworthy and reliable to handle\ntheir services. Through numerical results, the superiority of the\nproposed approach is demonstrated. Last but not least, we discuss\nimportant open directions for further research.\nIndex Terms\u2014AI-Generated Content (AIGC), Blockchain,\nEdge Networks, Circulation, Reputation.\nI. INTRODUCTION\nAs an emerging technique, Arti\ufb01cial Intelligence-Generated\nContent (AIGC) has attracted signi\ufb01cant attention from both\nacademia and industry [1]. Instead of manually generating the\ncontent, AIGC enables the automatic creation (e.g., writing\nan essay, composing a song, and drawing a picture) using\nmachine learning techniques such as Generative Adversarial\nNetworks (GAN) and diffusion models. Consequently, we can\nacquire massive high-quality multimodal content while signif-\nicantly saving on the required labor. Since 2014, AIGC has\nexperienced rapid development and has been widely adopted\nin 3D gaming, voice assistants, video processing, etc. [2].\nY. Liu, H. Du, D. Niyato, and C. Miao are with the School of Com-\nputer Science and Engineering, Nanyang Technological University, Sin-\ngapore (e-mail: yinqiu001@e.ntu.edu.sg, hongyang001@e.ntu.edu.sg, dniy-\nato@ntu.edu.sg, and ascymiao@ntu.edu.sg).\nJ. Kang is with the School of Automation, Guangdong University of\nTechnology, China (e-mail: kavinkang@gdut.edu.cn)\nZ. Xiong is with the Pillar of Information Systems Technology and Design,\nSingapore University of Technology and Design, Singapore (e-mail: zehui\nxiong@sutd.edu.sg)\nX. Shen is with the Department of Electrical and Computer Engineering,\nUniversity of Waterloo, Canada (e-mail: sshen@uwaterloo.ca)\nA. Jamalipour is with the School of Electrical and Information Engineering,\nUniversity of Sydney, Australia (e-mail: a.jamalipour@ieee.org)\nHowever, the current centralized AIGC framework suffers\nfrom high service latency. For instance, to generate an im-\nage on Hugging Face platform (https://huggingface.co/spaces)\nusing Stable Diffusion model, users have to wait for 40\u201360\nseconds. The reasons are twofold. Firstly, AIGC inference\nis complicated and time-consuming. In the above example,\nthe Stable Diffusion model creates images from scratch by\nconducting denoising operations gradually, which takes around\n20\u201330 seconds. Moreover, the queueing latency is also consid-\nerable (20\u201330 seconds in our example) since massive service\nrequests congest one central server.\nRecently, researchers have presented the idea of edge AIGC,\nwhich deploys AIGC generation services on edge devices [1].\nBy distributing services to numerous edge devices which are\nclose to users, service latency can be effectively reduced.\nMeanwhile, the robustness gets increased due to the elimi-\nnation of single-point-failure. Moreover, users can customize\nAIGC services, e.g., sharing their background, locations, or\ncharacters with edge devices to generate personalized content\naccordingly. Finally, since the users directly communicate with\nedge devices, personal information can be protected from\nleakage. Although enjoying these advantages, the following\nchallenges exist in deploying edge AIGC.\n\u2022 As digital property on the Internet, AIGC products are\nvulnerable to tampering and plagiarization (the tampering\nand plagiarization are shown in Section III).\n\u2022 The economic system of AIGC is complicated. Without\na mechanism guaranteeing that all the participants can\nbene\ufb01t from AIGC circulation and obtain their deserved\nrevenue legitimately, the generation, distribution, and\ntrading of AIGC products will be discouraged.\n\u2022 Recall that the generation services become distributed\nin edge AIGC. Therefore, as Edge Service Providers\n(ESPs) show signi\ufb01cant heterogeneity in terms of model\ncon\ufb01guration and service quality, the users can hardly\nselect reliable ESPs for their tasks.\nFortunately, blockchain provides available solutions for\nthese issues. As a distributed ledger, blockchain can construct\ntrustworthiness among anonymous participants by maintaining\nan immutable and traceable history [3]. Moreover, smart\ncontracts make blockchain programmable, enabling the on-\nchain deployment of arbitrarily complex mechanisms (e.g.,\ntwo-phase locks and incentive mechanisms). Consequently,\nthe status and trading of AIGC products can be monitored\narXiv:2303.02836v1  [cs.CR]  6 Mar 2023\n2\non-chain, eliminating the security and trustworthiness prob-\nlems. In 2022, Oben AI published the proposal of AIGC\nchain (https://www.aigcchain.io/about), which allows users to\ncontribute resources for training distributed AIGC models and\nacquiring rewards. As the \ufb01rst blockchain for AIGC, however,\nthis project is still under development and far from completing\nthe whole ecosystem. Moreover, it only uses blockchain as\na crowdsourcing platform for generating AIGC, while the\ndistribution and trading of AIGC are unprotected.\nIn this article, we propose the blockchain-empowered AIGC\nproduct lifecycle management in edge networks. Speci\ufb01cally,\nwe \ufb01rst de\ufb01ne \u201cAIGC product lifecycle\u201d and discuss four\nmajor concerns regarding lifecycle management. To help\nAIGC products defend malicious attacks, a Proof-of-AIGC\nmechanism is proposed, using fraud proofs to deal with\nplagiarization. Given the complex economic system of AIGC,\nwe further equip our framework with an on-chain incentive\nmechanism based on Hash Time Look (HTL) [4]. With\nguaranteed and timely revenue issuance, the circulation of\nAIGC can be motivated and incentivized. Finally, noticing the\nheterogeneity of ESPs, we enable AIGC producers to select the\nESPs based on their accumulated reputation, which is modeled\nby Multi-weight Subjective Logic (MWSL) method [5]. To the\nbest of our knowledge, this is the \ufb01rst work discussing the\nissues and solutions of AIGC product lifecycle management.\nOur contributions are summarized as follows:\n\u2022 We present Proof-of-AIGC mechanism. Different from\nProof-of-X (e.g., Proof-of-Semantics [6]), a challenge\nscheme is implemented, thus deregistering plagiarized\nAIGC products and protecting users\u2019 copyright.\n\u2022 We propose an incentive mechanism with one-way in-\ncentives and two-way guarantees. The former encourages\nusers to participate in managing the AIGC product lifecy-\ncle, and the latter ensures the atomic executions of AIGC\ntrading, i.e., fund-ownership exchanges.\n\u2022 We design a reputation-based ESP selection strategy.\nBy calculating and sharing reputation, users can easily\nquantify the trustworthiness of numerous heterogeneous\nESPs and assign their tasks to the most reliable one.\nII. AIGC: CURRENT PROGRESS, LIFECYCLE\nMANAGEMENT, AND CONCERNS\nIn this section, we \ufb01rst review the development of AIGC.\nThen, we show the AIGC product lifecycle in edge networks.\nFinally, important security and circulation concerns existing in\nthe AIGC product lifecycle are discussed.\nA. Development of AIGC\nAIGC is an emerging generation diagram after Professional-\nGenerated Content and User-Generated Content. As the name\nsuggests, the development of AIGC is driven by progresses\nin AI research. Before 2010, machines can hardly generate\nhigh-quality content due to the limited capability of deep\nlearning models. Since 2014, various generative neural net-\nworks have been presented, such as GAN and variational\nautoencoders. Consequently, AIGC enters a period of rapid\ndevelopment. In 2020, OpenAI published the Generative Pre-\ntrained Transformer-3 (GPT-3) model, supporting multiple\ntext generation tasks, e.g., mechanism translation and report\ncreation [7]. Two years later, the diffusion-based DALL-E-2\nmodel is presented. Based on the text description given by\nusers, DALL-E-2 can generate high-quality realistic images\nautomatically. Apart from text-to-text and text-to-image gen-\neration, AIGC is widely adopted in video processing, gaming,\nvoice assistants, etc. Moreover, it is regarded as a building\nblock for many revolutionary techniques, including Web3,\nmetaverse, digital twin, even the future 7G [8].\nB. AIGC Product Lifecycle Management in Edge Networks\nTraditionally, AIGC models are operated by centralized\nservers, such as Hugging Face platform. In this case, massive\nusers send requests to the central server, wait in line, and\nreceive the services. Researchers attempt to deploy AIGC\nservices in edge networks to avoid request congestion and op-\ntimize service latency. Compared with central servers, edge de-\nvices also have enough computing resources to conduct AIGC\ninference and are closer to users. Therefore, the users can\ncommunicate with devices with lower transmission latency.\nMoreover, since AIGC services are distributed to multiple edge\ndevices, the waiting latency can be signi\ufb01cantly decreased.\nNonetheless, the current research only covers the generation of\nAIGC products. As a kind of non-fungible online property like\nNFT [9], each AIGC product has its ownership, copyright, and\nvalue. Accordingly, the protection and management of AIGC\nproducts should cover their whole lifecycle. Next, we de\ufb01ne\nthe concept of \u201cAIGC product lifecycle\u201d.\nThe entire AIGC product lifecycle has three phases, namely\ngeneration, distribution, and trading (see Steps\n1\u20dd- 3\u20ddin Fig.\n1). Taking text-to-image generation as an example, the primary\nprocess of each phase is described below.\n\u2022 Generation: Producers, with insuf\ufb01cient physical re-\nsources, pack prompts, i.e., interesting and accurate text\ndescriptions, and requirements in a request and sends\nthem to ESPs (Step\n1\u20dd). Edge devices serve as ESPs,\nproviding AIGC generation services for clients using\nlocal well-trained AIGC models (Step\n2\u20dd). Since AIGC\ngeneration is time-consuming and takes computing re-\nsources, ESPs can claim fees from producers.\n\u2022 Distribution: After generation, the producers acquire the\nownership of the AIGC products. Consequently, they have\nthe right to distribute these products to social media or\nAIGC platforms through edge networks (Step\n3\u20dd).\n\u2022 Trading: Since AIGC products are regarded as a novel\nkind of non-fungible digital properties, they can be\ntraded. The trading process can be modelled as a fund-\nownership exchange between two parties.\nDuring such a lifecycle, several issues are yet to be addressed.\nAs shown in Fig. 1, \ufb01rstly, the ownership and copyright of\nAIGC products are vulnerable on the Internet. Meanwhile,\nthe producers also encounter problems in choosing reliable\nESPs. Finally, the legitimate trading of AIGC products among\nanonymous participants is unsolved. In the following part, we\ndiscuss these concerns in detail.\n3\nPhase 1: Generation\nPhase 2: Distribution\nPhase 3: Trading\nProducer\nEdge Service \nProvider (ESP)\n2\n1\nHow to select a \nreliable and \ntrustworthy one \namong these \nheterogeneous\nESPs?\nEdge \nNetwork\n3\nDistribute AIGC \nproducts to the Internet\nHow to defend \nthe ownership \ntampering and \nplagiarization \nof AIGC \nproducts?\nAIGC Distribution \nPlatforms\n4\nMonitor the Internet\n5\n6\n8\n7\nAttackers \n(plagiarization)\nAttackers \n(tampering)\nHow to find the \nproducer and ensure \nthe legitimate \nexecution of the  \nfunds-AIGC \nownership exchange? \nconsumer\nESP\n4\n5\nClaim ownership by \nmassive fake messages\n6\nDownload victim product\nConduct slight revision (e.g., color change)\n7\n8 Re-publish the AIGC product\nFig. 1. The AIGC product lifecycle and its important concerns.\nC. Security Concerns\nSince AIGC products are published on open networks,\nvarious kinds of attacks threaten them [10]. Here, we illustrate\ntwo crucial attacks targeting the AIGC products, namely the\ntampering of ownership and the plagiarization of AIGC. Note\nthat other attacks, such as denial-of-service and injection, can\nalso destroy AIGC [11]. Nevertheless, since they are general-\npurpose attacks and have been well-elaborated, we do not\ncover them in this article.\n1) Tampering of Ownership: Taking text-to-image AIGC as\nan example, \ufb01rst, Steps\n1\u20dd- 3\u20ddin Fig. 1 illustrate its lifecycle.\nFor conducting ownership tampering, the attackers generally\ndeploy many robots to monitor closely the Internet and \ufb01nd\nhigh-quality AIGC products timely (Step\n4\u20dd). After selecting\nthe victim image, the attacker, assisted by its robots, distributes\nmassive messages to re-publish the image, pretending that\nthe image is its original (Step\n5\u20dd). Since the attacker can\nbroadcast information more rapidly, the consumers have a\nhigh probability of \ufb01rst reading the information offered by\nthe attacker. If so, the ownership of the victim image can be\nregarded as successfully tampered.\n2) Plagiarization of AIGC: Compared with ownership tam-\npering, the plagiarization of AIGC is harder to be detected. In\nthis case, the attacker will not directly claim ownership of the\nvictim image. Instead, it downloads the high-quality victim\nimage, conducts some slight revision (e.g., adding noise or\nchanging the colors of some objects), and publishes it as a\nbrand new AIGC product (Step\n6\u20dd- 8\u20dd). Since such revision\nis much easier and cheaper than generating AIGC images from\nscratch, the attacker can make signi\ufb01cant pro\ufb01ts. Moreover, it\ncan even repeat this strategy, i.e., using one original image\nto generate a series of duplicates with little difference, thus\nfurther increasing its gains.\nD. Circulation Concerns\nApart from security concerns, to realize the free circulation\nof AIGC, we also encounter two challenges.\n1) Heterogeneity of ESPs: The lifecycle of every AIGC\nproduct starts from generation, i.e., using well-trained AIGC\nmodels to create content based on producers\u2019 requirements.\nNonetheless, ESPs in edge networks show great heterogeneity\nin model and service quality. Taking Fig. 1 as an example,\none ESP is equipped with Stable Diffusion [12], the state-\nof-the-art AIGC model. The training of Stable Diffusion is\ncalled forward diffusion, i.e., smoothly perturbing the original\nimage data by adding noise. The corresponding training time\nexceeds 150,000 hours on 256 Nvidia A100 GPUs, at a cost\nof US$600,000. In contrast, another ESP in Fig. 1 only has a\nsimple GAN model. The quality of the resulting content gen-\nerated by these two ESPs is signi\ufb01cantly different. However,\nsince ESPs may lie to producers, they cannot determine which\nESPs are trustworthy.\n2) Issuance of the Deserved Revenue: Nowadays, we are\nexperiencing the evolution from Web2 to Web3. In the Web3\nera, everyone owns the content he/she generates. Correspond-\ningly, all the contributions to maintain, distribute, and enrich\nthe community should be rewarded. Nevertheless, ensuring\nthat all the deserved revenue can be issued timely is chal-\nlenging, especially in the AIGC scenario, whose economic\nsystem is complex. Given the high costs of AIGC generation,\nthe computing power and time invested by ESPs should be\nrewarded with fees. Meanwhile, the producers are only willing\nto pay if they are guaranteed to receive the AIGC products\non time. Likewise, AIGC trading also involves a two-way\nguarantee of whether the producer and consumer can obtain\nthe funds and AIGC ownership, respectively. However, on the\npublic Internet, two parties of transactions can hardly build\ntrustworthiness. Such a concern might discourage the produc-\ners from distributing and trading products, thus blocking the\nfree circulation of AIGC products.\nFrom the above discussion, we can observe that the dif-\n\ufb01culty of AIGC lifecycle management originates from two\nissues, i.e., i) the intrinsic venerability of AIGC as a kind of\ndigital non-fungible property and ii) the lack of trustworthiness\non the Internet. Fortunately, as an immutable ledger and trust\nmaker, blockchain can effectively solve these two issues.\nIII. BLOCKCHAIN-EMPOWERED AIGC LIFECYCLE\nMANAGEMENT\nA. Framework Overview\nThe proposed blockchain-based framework for AIGC prod-\nuct lifecycle management is shown in Fig. 2. In the following\n4\nAIGC Services (text, image, voice generation)\nAIGC Models\nA\nB\nD\nC\nProof-of-AIGC\nESP Selection\nIncentive Mechanism\nAIGC Operation Records\nAIGC Generation Services\nCPU & GPU\nNetwork\nStorage\nXT\nXt\nX0\nXt-1\n...\n...\nq(xt|xt-1)\nDenoising \nprocess\nRandom \nseed\nHigh-quality and \nrealistic image \naccording to text \ndescription\nComputing power\nModel parameters\nXt-1\nProof Generation\nChallenge\nP2P \nNetwork\nFull Node \n(ESP)\nProducer\nBlockchain Ledger\nEdge Network \n(Blockchain Platform)\nStakeholders (Producers, \nConsumers, & Attackers)\nProducer\nBlock \n0\nBlock \n1\nBlock \nn\n...\nSmart \nContract \nEngine\nP2P \nNetwork\nFull Nodes \n(ESPs)\nAttackers\nConsumer\n- Transaction 0\n\u2026\u2026\n- Transaction n\n- Sender, Receiver\n- Payload\n- Signature\n- Timestamp\nCentralized \nServer\n- State Synchronization\n- Consensus Mechanism\n- Ledger Storage\nResponsibility:\nTwo-way \nexchange between \nAIGC ownership \nand fund\nAIGC Trading\nAIGC Generation\nTwo-way \nexchange \nbetween \nAIGC \nproduct \nand service \nfee\n1\n2\n3\nAIGC Distribution\nSocial Media \nor AIGC \nPlatform\n1. Confirm \nthe task \ndetails and \nservice fee\n3. Register \nproduct on \nblockchain\n3. Acquire \nownership\nAIGC Generative Services (text, image, voices)\n1. Initialize \nchallenge\n2. Check \nidentity\n3. Measure \nsimilarity level\n4. Deregister \nthe duplicate \n(if challenge \nsucceeds)\n2. Check \navailability\nFull Nodes \n(ESPs)\nProducer\n1. Create a \nrandomness-\nhash pair (R, \nH(R))\nTwo-way exchange between \nAIGC product and service fee\n2. Receive \nH(R)\n3. Create contract \nC1, lock AIGC \nusing H(R)\n4. Send \npayment \nreminder\n5. Create contract \nC2, lock service fee \nusing H(R)\n6. unlock \nAIGC in C1 \nusing H(R)\nH(R)\n7. unlock \nservice fee in \nC2 by H(R)\nAll Available \nESPs\nP2P \nNetwork\nH(R)\nProducer\n1\n1\nESP1\nESP3\n...\nESP2\n2\n1. Calculate the reputation of every available ESP\n2. Sort all ESPs based on their reputation\n3. Assign AIGC generation task to the first available ESP\n1\n3\nThe reputation \nof ESP\nFig. 2. The blockchain-empowered framework for AIGC product lifecycle management. Part A represents the AIGC models operated by ESPs. Parts B, C,\nand D illustrate the Proof-of-AIGC (demonstrated in Section III-B), incentive mechanism (demonstrated in Section III-C), and reputation-based ESP selection\n(demonstrated in Section IV), respectively.\npart, we introduce this framework in terms of stakeholders,\nblockchain platform, and on-chain mechanisms.\n1) Stakeholders: The entire AIGC product lifecycle in edge\nnetworks involves four types of stakeholders in total, namely\nproducers, ESPs, consumers, and attackers.\n\u2022 Producer: Producers initialize the lifecycle of an AIGC\nproduct. Due to resource limitations, they only propose\nprompts (e.g., interesting and accurate text descriptions\nin text-to-image AIGC) and then request for ESPs to\ncomplete the generation tasks. After the generation, they\nbecome the \ufb01rst owners of the resulting products and have\nthe right to publish and sell them.\n\u2022 ESP: ESPs (e.g., edge servers) have enough resources\nto save well-trained AIGC models and generate content\n(see Fig. 2, Part A). Therefore, they can provide con-\ntent generation services for producers. However, given\nthe complexity of AIGC generation, ESPs can charge\nproducers based on the time and computing power that\nthey invest to the tasks.\n\u2022 Consumer: After distribution, the AIGC product will be\nviewed by numerous people, some of whom may buy it.\nSuch viewers are called consumers. During the lifecycle\nof an AIGC product, it might experience multiple times\nof trading with different consumers.\n\u2022 Attacker: Attackers can launch ownership tampering and\nAIGC plagiarization to disturb the normal operations of\nAIGC products and make pro\ufb01ts.\n2) Blockchain Platform: In our framework, blockchain has\ntwo major functions: i) providing a traceable and immutable\nledger and ii) supporting on-chain mechanisms. To this end,\nevery phase of the AIGC product lifecycle will be recorded\nby transactions, whose basic format is Trans (Sender, Receiver,\nPayload, Timestamp, Signature). Note that the payload is\ndifferent depending on the speci\ufb01c types of events. Transac-\ntions are packed into blocks and submitted to the blockchain\nnetwork, a distributed Peer-to-Peer (P2P) network. The par-\nticipants of the P2P network, named full nodes, conduct a\nconsensus mechanism for block veri\ufb01cation. Finally, valid\nblocks can be appended to the ledger and saved by all full\nnodes in parallel. Since everyone preserves a ledger copy, the\nattackers have to revise at least 50% copies for tampering\nhistory, which is almost impossible. In addition, we can easily\ntrace any historical events by traversing the ledger. Moreover,\nto support complex on-chain mechanisms, a turing-complete\nsmart contract engine is deployed.\nAmong all participants, ESPs serve as full nodes and are\nresponsible for message synchronization, block veri\ufb01cation,\nand ledger storage. Given the resource limitation, producers\nand consumers act as clients, relying on ESPs to access the\nblockchain services. Note that the consensus mechanism in our\nblockchain is delegated Proof-of-Stake [13], in which ESPs\ndeposit stakes and take turns to create blocks. In this case, the\nattackers need to manipulate 50% ESPs for launching 51%\nattacks. Moreover, the deposited stakes will be locked if their\nmalicious attacks are detected.\n3) On-chain Mechanism: The framework is equipped with\nthree on-chain mechanisms for different purposes. Firstly, we\ndesign the Proof-of-AIGC mechanism to defend plagiarization\n(see Fig. 2, Part B). To protect the funds-AIGC ownership\nexchange, we further implement an incentive mechanism based\non HTL (see Fig. 2, Part C). Finally, we present the reputation-\nbased ESP selection, which effectively schedules AIGC gen-\n5\neration tasks among ESPs (see Fig. 2, Part D).\nB. Proof of AIGC\nAs shown in Fig. 2, Part B, the Proof-of-AIGC consists of\ntwo phases, namely proof generation and challenge.\n1) Proof Generation: Proof generation intends to register\nAIGC products on blockchain. We still take text-to-image\nAIGC as an example. For generating an image, the producer\n\ufb01rst sends a corresponding request to an ESP (ESP selection\nstrategy is discussed in Section IV). The request format is\n(Text description, service fee, expected time). After receiving\nthe service request, the ESP checks its availability and decides\nwhether to accept the task. If the expected time and service fee\nare acceptable, it conducts a handshake with the producer (see\nFig. 2, Part B). Then, the image creation can be conducted by\nthe ESP, using well-trained AIGC models.\nAfter generating the image, ESP initializes a transaction\nTransGen\nAIGC(Sender, Receiver, Payload, Timestamp, Signa-\nture). The Payload format is (Product index, Metadata, Chal-\nlenge expiration), in which Product index is calculated by hash\nfunction and is regarded as the unique identity for the AIGC\nproduct. Metadata contains the basic information of the AIGC\nproduct. Such a transaction will go through the veri\ufb01cation\nand be recorded by the blockchain. Finally, the ESP will\nsend the image to the producer, with a copy of TransGen\nAIGC.\nTransGen\nAIGC can be regarded as a proof, which not only\nregisters the AIGC product, but also claims its ownership by\nsetting Receiver as producer\u2019s address. Given the immutability\nof blockchain ledger, the concerns about ownership tamper-\ning can be effectively addressed. Next, we demonstrate the\nchallenge mechanism to help producers defend the AIGC\nplagiarization.\n2) Challenge: Proof-of-AIGC follows the principle of fraud\nproof. In other words, our blockchain assumes that all AIGC\nproducts are original work in the proof generation phase.\nHowever, the information recorded in TransGen\nAIGC enables\nproducers to challenge any on-chain AIGC product that they\nbelieve copies their own work. If the challenge succeeds, the\nduplicate will be deregistered, thus protecting the copyright of\nthe real producer. Next, we illustrate the challenge work\ufb02ow.\nSuppose that the producer has created and published an\nAIGC product (called original product). Then, it surfs the\nInternet and \ufb01nds an AIGC product which is signi\ufb01cantly\nsimilar to its own work (called duplicate). In this case, it\ncan initialize the challenge process by sending a transaction\nTransChall\nAIGC with the payload (Product1, Product index1,\nProduct2, Product index2, Pledge deposit). Here, Product1\n(Product2) and Product index1 (Product index2) represent\nthe content and indexes of the original product (duplicate),\nrespectively. We consider that the duplicates will also be\nregistered on blockchain because consumers will only buy the\nAIGC products with clear proof. After receiving TransChall\nAIGC,\nthe ESPs will conduct the following four steps:\n\u2022 Step 1: Fetch the proofs. The TransGen\nAIGC of both the\noriginal product and the duplicate will be fetched from\nlocal ledger. Recall that the format of TransGen\nAIGC is\n(Sender, Receiver, Payload, Timestamp, Signature).\n\u2022 Step 2: Check the identity of the challenger. The ESPs\nverify challenger\u2019s signature in TransChall\nAIGC using Re-\nceiver public key in TransGen\nAIGC. If signature veri\ufb01cation\nis successful, it can prove that the challenger is indeed\nthe owner of the original product.\n\u2022 Step 3: Measure the similarity between the original\nproduct and the duplicate. Firstly, ESPs conduct hash\noperations on Product1 and Product2 and check whether\nthe hashes match Product index1 and Product index2,\nrespectively. If so, they conduct the similarity measure-\nment using three well-established metrics, namely image\nhistogram, perceptual hash, and difference hash. Note that\nthe metrics can be changed for other AIGC scenarios.\n\u2022 Step 4: Check the results. If the similarity level exceeds\nthe threshold in any two metrics, the challenge can be\nregarded as successful. Otherwise, the challenge fails.\nIf the challenge succeeds, the ESPs create and send a trans-\naction TransDere\nAIGC with the payload (Product index2, Pledge\ndeposit, Similarity), where Similarity is de\ufb01ned as a three-\nelement tuple (histogram, phash, dhash). TransDere\nAIGC aims\nto deregister the duplicate by pointing out its product index.\nMoreover, it unlocks the pledge deposit provided by the chal-\nlenger. Recall that the challenge is initialized by TransChall\nAIGC,\nwhose Sender is obviously the challenger\u2019s address. However,\nthe Receiver address of TransChall\nAIGC does not belong to any\nparticipant. Instead, it is a special system account for locking\nthe pledge deposit provided by challenger. The motivation\nfor requiring pledge deposit is to restrict challengers from\nlaunching challenges arbitrarily, since the challenge process\ncauses extra burden to the blockchain. Nonetheless, such\ndeposit can be waived if the challenge happens before the pre-\nde\ufb01ned Challenge expiration in TransGen\nAIGC. For example,\nif the original product is registered in the 5th block and\nChallenge expiration is 20, the challenge will be free from\nthe 6th to the 20th block. From the 21st block, the challenger\ncan only withdraw its deposit if it successfully proves that a\nduplicate is mistakenly registered on blockchain. Otherwise,\nthe locked pledge deposit will be regarded as a service fee\nand be used to reward the next block creator.\nC. Incentive Mechanism\nThe economic system of AIGC is complicated because it\naccommodates different stakeholders, which conduct transac-\ntions with each other frequently. Thus, we should guarantee\nthat: i) all the stakeholders can be incentivized to manage the\nAIGC lifecycle; ii) the funds-AIGC ownership exchanges can\nbe conducted legitimately without repudiation. To this end, an\non-chain incentive mechanism is presented.\n1) One-way Incentives: One-way incentives are automati-\ncally issued to the ESPs which maintain the ledger and provide\nblockchain services. Recall that our blockchain adopts dele-\ngated Proof-of-Stake as the consensus mechanism, where ESPs\ntake turns to generate new blocks. During each round of block\ngeneration, the generator can include a coinbase transaction\nto reward itself. The Sender and Receiver addresses of such\ncoinbase transactions are the system account and generator\u2019s\npublic key address, respectively. For the speci\ufb01c reward value,\n6\nit can be set according to the target system in\ufb02ation rate. Note\nthat there is no transaction fee in our incentive mechanism.\nHence, block generator just packs pending transactions by the\n\ufb01rst-come-\ufb01rst-serve strategy.\n2) Two-way Guarantee: As mentioned before, during both\nAIGC generation and trading, there exist two-way exchanges\nbetween fund and ownership. However, people might hesitate\nto conduct such exchanges, since they cannot guarantee that\nthe other party will strictly follow its promise. To build mutual\ntrust and facilitate AIGC circulation, we design a two-way\nguarantee protocol using HTL (Hash Time Lock) as a part of\nour incentive mechanism.\nTake the two-way exchange happening in AIGC generation\nphase as an example. In this case, the ESP grants the producer\nthe ownership of its AIGC product, and the producer pays\nthe pre-con\ufb01gured service fee. To do so, we implement a\nsmart contract with two atomic operations named lock and\nrelease. As shown in Fig. 2, Part C, during the handshake\nprocess described in Section IV-B, the producer creates a\nrandomness R and sends its hash H(R) to ESP. When\nTransGen\nAIGC is recorded on the blockchain, a corresponding\ncontract instance C1 will be created by ESP immediately.\nC1 calls lock function to lock the ownership storing in\nTransGen\nAIGC using H(R). Only the one with R can release\nthe lock. Meanwhile, the ESP sends a payment reminder to\nthe producer. Receiving the bill, the producer sends a payment\ntransaction with the payload (Balance), where Balance should\nbe equal to the pre-con\ufb01gured service fee. Then, it also\ninitializes its own contract instance C2, which locks the fund\nin the payment transaction by H(R). Up till now, both fund\nand AIGC ownership are on-chain.\nThen, the secure exchange between fund and AIGC own-\nership can be conducted. Firstly, the producer unlocks the\nAIGC ownership by calling release operation of C1, with\nan input R. C1 will check whether the hash of R matches\nH(R) and unlock the TransGen\nAIGC if H(R) is correct. Since\nsuch a process exposes R to C1, the owner of C1, i.e.,\nESP, can also release the fund locked by C2 using R. To\nprevent participants from intentional delay, we further add an\nexpiration to the smart contract. Consequently, if they fail to\nunlock the properties on time, the lock will become permanent\nand the corresponding transactions will be discarded. Clearly,\nsuch a protocol guarantees the atomic and timely executions\nof the exchange process.\nD. Security Analysis\nRecall that in Section II, we point out four concerns of\nthe AIGC product lifecycle, namely ownership tampering,\nAIGC plagiarization, non-guaranteed exchanges, and ESP het-\nerogeneity. Firstly, our Proof-of-AIGC registers every AIGC\nproducts on chain. In this case, even though attackers can dis-\ntribute massive fake messages to \u201cclaim\u201d their ownership, they\ncan hardly launch 51% attacks (as mentioned in Section III-A)\nor tamper the registration history preserved in all full nodes.\nAdditionally, the challenge scheme provides the standard\nprocedure for producers to defend AIGC plagiarization and\nretrieve their copyright. Furthermore, the incentive mechanism\nP3\nP2\nP1\nESP1\nESP2\nESP3\nLoc 1\nLoc 2\nLoc 3\nCentral \nServers\nLoc N: the local opinion to ESPN\n1\n1\n1\n2\nRec 1\nRec 2\nRec 3\nRec N: the recommended opinion to ESPN\n2\nFin N: the final opinion to ESPN\nFin 1\nFin 2\nFin 3\n2\n3\n4\nFin N := [pfin, nfin, ufin]\n: \nLoc N := [ploc, nloc, uloc]\nRec N := [prec, nrec, urec]\npfin = (plocurec + preculoc)/(uloc + urec \u2013 ulocurec)\nnfin = (nlocurec + nreculoc)/(uloc + urec \u2013 ulocurec)\nufin = (ureculoc)/(uloc + urec \u2013 ulocurec)\nFor P1:\nStable Diffusion v1.4 \nmodel, 30 steps\nUser Interface (Draw Things)\nModel Setting\nImage generation\nPrompt\nFig. 3. The reputation calculation process (from the perspective of producer\nP1) and the illustration of AIGC services.\nguarantees that all the funds-AIGC ownership exchanges can\nbe conducted strictly following the pre-con\ufb01rmed contracts.\nNext, we address the \ufb01nal concern, i.e., ESP heterogeneity, by\npresenting a reputation-based ESP selection.\nIV. REPUTATION-BASED ESP SELECTION\nA. Problem Statement\nRecall that AIGC services are distributed to numerous\nedge devices in our framework. Hence, each producer can\naccess multiple heterogeneous ESPs simultaneously. In this\ncase, selecting a reliable ESP for the speci\ufb01c task becomes a\nproblem. Traditionally, producers can select the most familiar\nESP, i.e., the one with which they have traded the most times,\nto minimize the potential risk. However, such strategies may\nlead to an imbalanced workload among ESPs, thus increasing\nthe service latency on busy ESPs. Meanwhile, the computing\nresources of idle ESPs will be wasted.\nTo solve this problem, we implement a reputation-based\nESP selection scheme in our framework. Speci\ufb01cally, it sorts\nall available ESPs according to their reputation, which is\ncalculated by Multi-weight Subjective Logic (MWSL) [5]. We\nintend to achieve three goals: i) helping producers select the\nmost reliable ESP for each AIGC generation task; ii) balancing\nthe workload among multiple ESPs, thereby reducing the\noverall service latency; iii) encouraging ESPs to complete the\nassigned tasks timely and honestly, since a negative reputation\nwill directly affect their pro\ufb01ts.\nB. Reputation Based on Multi-weight Subjective Logic\nAs shown in Fig. 2, Part D, producers select ESPs by the fol-\nlowing steps: i) calculate the reputation of all available ESPs,\nii) sort candidate ESPs according to their latest reputation,\nand iii) assign the AIGC generation task to the ESP with\nthe highest reputation. Note that the item ESP1 is marked\nred because it denies the service request. In this case, the\n7\nproducer traverses the reputation table and re-sends the request\nto the next candidate, i.e., ESP3. Next, we demonstrate the\nreputation calculation based on MWSL.\nAs shown in Fig. 3, MWSL utilizes the term \u201copinion\u201d\nto denote the basic items for reputation calculation. Suppose\nthat our edge AIGC has three producers (P1-P3) and three\nESPs (ESP1-ESP3). Firstly, for a given producer, say P1,\nif it has direct interactions with these ESPs, P1\u2019s evaluation\nof them is called local opinions. Meanwhile, considering that\nP2 and P3 may also have the experience for interacting with\nthese ESPs, their evaluation should also be taken into account.\nFrom the perspective of P1, the evaluation of ESP1-ESP3\nfrom P2 and P3 are called recommended opinions. Here, an\ninteraction refers to the entire process from sending service\nrequest, to con\ufb01rming AIGC generation order, and to acquire\nAIGC products. The opinion is de\ufb01ned as a three-element\nvector [p, n, u], where p and n represent the proportion of\npositive and negative interactions in all interaction attempts,\nrespectively. u (from 0 to 1) indicates the uncertainty level\nbetween producer and ESP. According to MWSL, u is set\nmanually according to the communication quality.\nAlthough recommended opinions make reputation calcula-\ntion more comprehensive, the hidden subjectivity might affect\nthe fairness. For instance, if P2 once suffered an unexpected\nhigh latency from ESP1, it may regard all subsequent interac-\ntions as negative. To mitigate the effect caused by subjectivity,\nfor each producer, say P1, an overall opinion averaging all the\nreceived recommended opinions will be generated. Moreover,\nsince P2 and P3 have different familiarity degrees with ESPs,\nthe weight of their recommended opinions is also different.\nThe detailed reputation calculation process is:\n\u2022 Step 1: Generate local opinions. Every producer updates\nits local opinion for every ESP (see Step\n1\u20ddin Fig. 3).\n\u2022 Step 2: Synchronize information. Producers share the\nlatest local opinions. Assisted by blockchain, they can\npack their opinions into transactions for secure sharing.\n\u2022 Step 3: Calculate overall opinion Each producer col-\nlects all received recommended opinions and averages\nthem as the overall opinion. Note that the opinions\nare weighted before calculating the average. For any\nrecommended opinion from Pn to ESPn, the weight is\n\u03b11\u00d7Familiarity+\u03b12\u00d7V alue. Familiarity is de\ufb01ned\nas the number of historical interactions between Pn and\nESPn. V alue equals the total service fee for these\ninteractions. Finally, \u03b11 and \u03b12 are two weighting factors\nsatisfying \u03b11 + \u03b12 = 1. Notably, the more interactions\nhave been conducted, the larger the weight.\n\u2022 Step 4: Calculate reputation. Every producer combines\nits local opinion with overall opinion and achieves the\n\ufb01nal opinion [pfin, nfin, ufin]. The corresponding equa-\ntion is shown in Fig. 3. Finally, reputation is measured\nby pfin + ufin \u00d7 nfin.\nAfter reputation calculation, producers take Steps\n2\u20dd- 3\u20dd\nin Fig. 2, Part D, and select an ESP. Clearly, our reputation\nscheme successfully achieves all the design goals. Firstly, it\nquanti\ufb01es the trustworthiness of ESPs. Hence, producers can\neasily determine which ESP is more reliable. In addition,\n0\n5\n1 0\n1 5\n2 0\n2 5\n3 0\n3 5\n0\n1\n2\n3\n4\n5\n6\nd e la yin g  se rvice s \nRe p u ta tio n  V a lu e\nRo u n d s\n E S P\n1\n E S P\n2\n E S P\n3\nS ta rt in te n tio n a lly \nFig. 4. The reputation trends of three ESPs (from the perspective of a random\nproducer).\n0\n5\n10\n15\n20\n0\n5\n10\n15\n20\n25\n30\nThe total number of assigned tasks\nRounds\n ESP_1 (traditional)\n ESP_2 (traditional)\n ESP_3 (traditional)\n ESP_1 (ours)\n ESP_2 (ours)\n ESP_3 (ours)\nFig. 5. The total number of assigned tasks of three ESPs.\nproducers do not need to only rely on the most familiar ESP,\nthereby alleviating the potential service congestion. Finally,\nsince the reputation records are store on-chain and clear to\nall participants, ESPs are encouraged to provide high quality\nAIGC services for maximizing their pro\ufb01ts.\nC. Numerical Results\nTo prove the validity of the proposed methods, we imple-\nment a demo of our AIGC lifecycle management framework\nand deploy the reputation-based ESP selection on it1. As\nshown in Fig. 3, the testbed consists of three ESPs (served by\nthree virtual machines on Apple MacBook Pro with 8-Core\nIntel Core i9 CPU and AMD Radeon Pro 5500M GPU) and\nthree producers (served by iPhones). The AIGC services are\nsupported by Draw Things application (https://drawthings.ai/).\nFactors \u03b11 and \u03b12 are set as 0.35 and 0.65, respectively. Addi-\ntionally, uloc is \ufb01xed to 0.5 [5]. For each producer, it marks one\ninteraction as \u201cnegative\u201d if ESP fails to return the AIGC proof\nwithin the pre-con\ufb01rmed time. The service quality (i.e., the\nprobability of receiving positive opinions) of ESP1, ESP2,\nand ESP3 are 95%, 70%, and 55%, respectively. Finally, after\nacquiring the ESPs\u2019 reputation, producers can utilize Softmax\nfunction to determine the probability for selecting each ESP.\nFirstly, Fig. 4 illustrates the reputation trends of three ESPs.\nDuring the 1st-14th rounds, all ESPs accumulate reputation.\nGiven the high service quality, the reputation of ESP1 directly\nreaches to the top and stays stable, while ESP2 and ESP3\ngradually increase their reputation by providing more positive\ninteractions. From the 15th round, we let ESP1 intentionally\ndelay the AIGC services. Corresponding, its reputation drops\ndramatically, since more negative interactions are reported. In\n1https://github.com/Lancelot1998/AIGCLifecycleManagement\n8\ncontrast, since ESP2 and ESP3 acquire the chance to handle\nmore tasks, their reputation keeps increasing. We conclude that\nthe proposed reputation scheme can effectively quantify the\ntrustworthiness of ESPs. In this way, the producers can easily\njudge which ESP is the most reliable. On the other hand, ESPs\nare also supervised to keep performing honestly.\nThen, Fig. 5 shows ESPs\u2019 workload under different ESP\nselection methods. Here, we suppose that all three producers\nrequest for AIGC services with the same frequency, and we\nlet them randomly select ESPs during the \ufb01rst 5 rounds. From\nthe 6th round, two ESP selection methods are tested, namely\ntraditional method and the proposed reputation-based method.\nRecall that traditionally, the producers tend to assign tasks to\ntheir most familiar ESPs. As a result, the workload among\nESPs is imbalanced, causing long service latency. As shown\nin Fig. 5, most AIGC generation tasks congest in ESP3, while\nthe computing power of ESP2 becomes wasted. Assisted\nby reputation, the producers can qualitatively evaluate the\ntrustworthiness of ESPs and no longer need to rely on their\nempirical judgement. Consequently, the workload among ESPs\nis effectively balanced. Note that since there is no similar work\nregarding blockchain-empowered AIGC in the literature, we\ndo not set a baseline to compare with.\nV. FUTURE DIRECTION\nA. Blockchain-Based AIGC Governance\nThe rapid development of AIGC greatly enriches the Inter-\nnet content, but it also brings deepfake [14]. Deepfake refers\nto synthetic media in which a person in an existing image\nor video is replaced with someone else\u2019s likeness. According\nto thesentinel (https://thesentinel.ai/), the number of deepfake\nvideos online has jumped from 14,678 in 2019 to 145,277\nin 2021. Moreover, leveraging advanced AIGC models, such\nas GAN and autoencoders, deepfake is becoming more and\nmore realistic and harder to be identi\ufb01ed. Given the security\nproperty of blockchain, it can help AIGC against deepfake.\nFor example, some distributed governance organization can\nbe deployed on-chain, thus conducting the AIGC supervision\nand deepfake identi\ufb01cation. However, since identifying deep-\nfake requires off-chain knowledge, how to effectively bridge\nblockchain and physical AIGC is worth exploring.\nB. Distributed AIGC Model Training\nThis article mainly focuses on the AIGC product lifecycle.\nThe AIGC model construction lifecycle, including model train-\ning, \ufb01ne-tuning, and inference, is also a meaningful research\ntopic. For instance, since the training of diffusion models is\ntime-consuming and resource-intensive, new algorithms and\nframeworks for building the distributed AIGC model training\nare worth studying. In this way, the computing power in the\nentire edge network can be exploited and thus signi\ufb01cantly\nimprove the training speed. Meanwhile, blockchain can be\napplied to protect the security of the training process and\nreward the users who contribute their resources fairly.\nC. Metaverse\nAIGC is a building block for metaverse, since it can create\nnumerous multimodal content for rendering immersive and\nrealistic virtual worlds [15]. For example, the text-to-3D AIGC\nallows machines to collect the background, locations, and char-\nacters of users, thereby generating personalized avatars in the\nmetaverse environment. Although such a process brings high\nQoE and immersiveness, some sensitive personal information\nmight be leaked. Since blockchain has shown great strength\nin protecting data storage and sharing, the metaverse-oriented\nAIGC storage, access control, and sharing based on blockchain\ntechnique are also worth investigating.\nVI. CONCLUSION\nIn this article, we \ufb01rst review the progress of AIGC and its\ndeployment in edge networks. Then, we point out four major\nconcerns of the AIGC product lifecycle. Hence, we present\na blockchain-empowered framework, realizing the lifecycle\nmanagement for AIGC products. Speci\ufb01cally, Proof-of-AIGC\nsolves the ownership tampering and plagiarization of AIGC\nproducts. Additionally, an incentive mechanism is proposed\nto encourage the AIGC circulation. Moreover, we design a\nreputation scheme to help producers select reliable ESPs, with\nnumerical results to prove its validity. Last but not least,\nwe discuss future directions regarding the combination of\nblockchain and AIGC.\nREFERENCES\n[1] H. Du, Z. Li, D. Niyato, J. Kang, Z. Xiong, X. Shen, and\nD. Kim, \u201cEnabling ai-generated content (aigc) services in wireless edge\nnetworks,\u201d 2023. [Online]. Available: https://arxiv.org/abs/2301.03220\n[2] Y. Sun, Y. Xu, C. Cheng, Y. Li, C. H. Lee, and A. Asadipour,\n\u201cTravel with wander in the metaverse: An ai chatbot to visit the future\nearth,\u201d in 2022 IEEE 24th International Workshop on Multimedia Signal\nProcessing (MMSP), 2022, pp. 1\u20136.\n[3] Y. Liu, K. Wang, Y. Lin, and W. Xu, \u201cLightChain: A lightweight\nblockchain system for industrial internet of things,\u201d IEEE Transactions\non Industrial Informatics, vol. 15, no. 6, pp. 3571\u20133581, 2019.\n[4] W.-J. Lai, C.-W. Hsueh, and J.-L. Wu, \u201cA fully decentralized time-\nlock encryption system on blockchain,\u201d in 2019 IEEE International\nConference on Blockchain (Blockchain), 2019, pp. 302\u2013307.\n[5] J. Kang, Z. Xiong, D. Niyato, D. Ye, D. I. Kim, and J. Zhao, \u201cToward\nsecure blockchain-enabled internet of vehicles: Optimizing consensus\nmanagement using reputation and contract theory,\u201d IEEE Transactions\non Vehicular Technology, vol. 68, no. 3, pp. 2906\u20132920, 2019.\n[6] Y.\nLin,\nZ.\nGao,\nH.\nDu,\nD.\nNiyato,\nJ.\nKang,\nR.\nDeng,\nand\nX. S. Shen, \u201cA uni\ufb01ed blockchain-semantic framework for wireless\nedge\nintelligence\nenabled\nweb\n3.0,\u201d\n2022.\n[Online].\nAvailable:\nhttps://arxiv.org/abs/2210.15130\n[7] L. Floridi and M. Chiriatti, \u201cGpt-3: Its nature, scope, limits, and\nconsequences,\u201d Minds and Machines, vol. 30, no. 4, pp. 681\u2013694, Apr.\n2020.\n[8] J. Sun, W. Gan, H.-C. Chao, and P. S. Yu, \u201cMetaverse: Survey,\napplications, security, and opportunities,\u201d 2022. [Online]. Available:\nhttps://arxiv.org/abs/2210.07990\n[9] N. Karandikar, A. Chakravorty, and C. Rong, \u201cBlockchain based\ntransaction system with fungible and non-fungible tokens for a\ncommunity-based energy infrastructure,\u201d Sensors, vol. 21, no. 11, 2021.\n[Online]. Available: https://www.mdpi.com/1424-8220/21/11/3822\n[10] R. A. A. Mochram, C. T. Makawowor, K. M. Tanujaya, J. V. Moniaga,\nand B. A. Jabar, \u201cSystematic literature review: Blockchain security in\nnft ownership,\u201d in 2022 International Conference on Electrical and\nInformation Technology (IEIT), 2022, pp. 302\u2013306.\n[11] E. Choi, Y. Jo, J. Jang, and M. Seo, \u201cPrompt injection: Parameterization\nof \ufb01xed inputs,\u201d 2022. [Online]. Available: https://arxiv.org/abs/2206.\n11349\n9\n[12] Stable diffusion model. 2022. [Online]. Available: https://huggingface.\nco/spaces/stabilityai/stable-diffusion\n[13] G. Xu, Y. Liu, and P. W. Khan, \u201cImprovement of the dpos consensus\nmechanism in blockchain based on vague sets,\u201d IEEE Transactions on\nIndustrial Informatics, vol. 16, no. 6, pp. 4252\u20134259, 2020.\n[14] Y. Nirkin, L. Wolf, Y. Keller, and T. Hassner, \u201cDeepfake detection based\non discrepancies between faces and their context,\u201d IEEE Transactions\non Pattern Analysis and Machine Intelligence, vol. 44, no. 10, pp. 6111\u2013\n6121, 2022.\n[15] M. Xu, W. C. Ng, W. Y. B. Lim, J. Kang, Z. Xiong, D. Niyato,\nQ. Yang, X. S. Shen, and C. Miao, \u201cA full dive into realizing the edge-\nenabled metaverse: Visions, enabling technologies, and challenges,\u201d\nIEEE Communications Surveys And Tutorials, pp. 1\u20131, 2022.\n",
    "2305.12130": "Joint Foundation Model Caching and Inference of\nGenerative AI Services for Edge Intelligence\nMinrui Xu1, Dusit Niyato1, Hongliang Zhang2, Jiawen Kang3, Zehui Xiong4, Shiwen Mao5, and Zhu Han6,7\n1School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798, Singapore\n2School of Electronics, Peking University, Beijing 100871, China\n3School of Automation, Guangdong University of Technology, Guangzhou 510006, China\n4Singapore University of Technology and Design, Singapore 487372, Singapore\n5Department of Electrical and Computer Engineering, Auburn University, Auburn, AL 36849-5201, USA\n6Department of Electrical and Computer Engineering, University of Houston, Houston, TX 77004, USA\n7Department of Computer Science and Engineering, Kyung Hee University, Seoul 446-701, South Korea\nEmail: minrui001@e.ntu.edu.sg, dniyato@ntu.edu.sg, hongliang.zhang@pku.edu.cn, kavinkang@gdut.edu.cn,\nzehui xiong@sutd.edu.sg, smao@ieee.org, hanzhu22@gmail.com.\nAbstract\u2014With the rapid development of arti\ufb01cial general in-\ntelligence (AGI), various multimedia services based on pretrained\nfoundation models (PFMs) need to be effectively deployed.\nWith edge servers that have cloud-level computing power, edge\nintelligence can extend the capabilities of AGI to mobile edge\nnetworks. However, compared with cloud data centers, resource-\nlimited edge servers can only cache and execute a small number\nof PFMs, which typically consist of billions of parameters and\nrequire intensive computing power and GPU memory during\ninference. To address this challenge, in this paper, we propose\na joint foundation model caching and inference framework that\naims to balance the tradeoff among inference latency, accuracy,\nand resource consumption by managing cached PFMs and user\nrequests ef\ufb01ciently during the provisioning of generative AI\nservices. Speci\ufb01cally, considering the in-context learning ability\nof PFMs, a new metric named the Age of Context (AoC), is\nproposed to model the freshness and relevance between examples\nin past demonstrations and current service requests. Based\non the AoC, we propose a least context caching algorithm to\nmanage cached PFMs at edge servers with historical prompts\nand inference results. The numerical results demonstrate that\nthe proposed algorithm can reduce system costs compared with\nexisting baselines by effectively utilizing contextual information.\nIndex Terms\u2014Mobile edge computing, generative arti\ufb01cial in-\ntelligence, pretrained foundation models, joint foundation model\ncaching and inference\nI. INTRODUCTION\nMoving towards Arti\ufb01cial General Intelligence (AGI) in\nmobile edge networks [1], [2], pre-trained foundation mod-\nels (PFMs), such as generative pre-trained transformers\n(GPTs) [3], have achieved great successes in a variety of\n\ufb01elds over the past few years. As building blocks of AGI,\nPFMs with billions of parameters are essential due to their\neffectiveness in demonstrating emergent capabilities in down-\nstream tasks with various data modalities [4]. The pre-training\napproach provides an ef\ufb01cient parameter initialization for a\nwide range of downstream tasks, including semantic segmenta-\ntion, content generation, and information retrieval. As a result,\nlanguage/visual/multimodal foundation models belong to the\nparadigm of transfer learning, which can adapt to new tasks\nand domains without any task-speci\ufb01c data during pre-training.\nMultimedia services based on edge intelligence, such as\nintelligent digital twins (DTs), autonomous driving, and AI-\ngenerated content (AIGC), can be greatly enhanced by deploy-\ning PFMs on edge servers, bene\ufb01ting from edge computing\u2019s\nlow latency and \ufb02exible features. For instance, in autonomous\ndriving, PFMs can generate traf\ufb01c simulations and provide\ndriving assistance in making complex driving decisions [5].\nAdditionally, during immersive human-avatar interactions in\nthe Metaverse, PFMs can assist in comprehending and reacting\nto human emotions and behaviors. For example, ChatGPT\nfacilitates consistent and \ufb02uent interactions with humans, \ufb01ne-\ntuned based on GPT-3 to release its contextual awareness [3],\nwhich is an LFM with 175 billion parameters. Beyond exe-\ncuting PFMs in cloud data centers, edge servers can support\n\ufb01ne-tuning and inference processes of PFMs requested by\nAI services, thus igniting the sparks of AGI in mobile edge\nnetworks.\nHowever, unlike cloud data centers, resource-constrained\nedge servers are unable to concurrently load all PFMs to\nserve users\u2019 AI service requests. In literature, existing research\ngenerally focuses on of\ufb02oading AI services to cloud data cen-\nters for remote execution or caching inference results at edge\nservers for low-latency response [6]. On one hand, of\ufb02oading\ninference requests of PFMs to cloud data centers introduce\nadditional latency, traf\ufb01c overhead, and privacy threats to\nserving AI services over core networks and public cloud\ninfrastructure. On the other hand, merely caching inference\nresults at edge servers is no longer effective for satisfying\nusers\u2019 interactive requirements. To enable mobile AI services\nwith the computing and GPU resources currently loaded into\nthe GPUs of edge servers, effective deployment of PFMs at\nedge servers requires \ufb02exible and context-aware management\non computing resources and user requests.\nDiffering from the existing works on joint service caching\nand task of\ufb02oading, several unique challenges arise for joint\nfoundation model caching and inference to balance the tradeoff\namong inference latency, accuracy, and resource consumption\nin mobile edge networks [7]. First, different quantities of re-\narXiv:2305.12130v1  [cs.NI]  20 May 2023\nquests and performance requirements of the downstream tasks,\nsuch as accuracy and latency, are present during the \ufb01ne-tuning\nand inference of PFMs [6]. Additionally, a variety of PFMs can\nbe applied to comparable downstream tasks in a range of AI\nservices. This presents a challenge for edge servers in that the\ncached PFMs may be called interchangeably to handle model\nmisses. Furthermore, PFMs can continuously learn and adapt\nto new domains and tasks through prompts of instruction and\ninteractive demonstrations [8]. Due to the in-context learning\nability of PFMs, cached models can enhance their inference\naccuracy during inference without parameter updates. These\nchallenges make decisions about cached model management\nand request of\ufb02oading increasingly dif\ufb01cult for optimizing the\nperformance of the framework, which is a tradeoff among\ninference latency, accuracy, and resource consumption.\nTo address these issues, in this paper, we investigate the\nimportant but rarely studied problem of joint foundation model\ncaching and inference of generative AI services for edge\nintelligence in mobile edge networks. We propose a joint\nfoundation model caching and inference framework to serve\nPFMs for provisioning generative AI services. Furthermore,\nto balance the tradeoff among inference latency, accuracy, and\nresource consumption, we propose a new metric named Age of\nContext (AoC) to indicate the freshness and relevance between\nexamples in historical demonstrations and current inference\nrequests. With a context vanishing factor, the AoC follows\nthe non-increasing utility function that affects the effective\nexamples in context from instruction, demonstrations, and\noutputs of past interactions. Based on the AoC, we propose a\nLeast Context (LC) algorithm to manage cached PFMs at edge\nservers. Simulation experiments demonstrate that the proposed\nLC algorithm can reduce the total system cost by utilizing\ncontextual information for improving the service accuracy and\nutilizing the computing power and GPU memory of edge\nservers ef\ufb01ciently.\nThe main contributions of this paper are summarized as\nfollows.\n\u2022 For the \ufb01rst time, we formulate the joint foundation\nmodel caching and inference problem in mobile edge\nnetworks, for minimizing service cost and accuracy loss\nunder limited computing and GPU memory capacity of\nedge servers.\n\u2022 Considering the in-context learning ability of PFMs, we\npropose a new metric named age of context to measure\nthe freshness and relevance of historical examples in\ncontext and current inference requests.\n\u2022 Based on the AoC, we develop the least context algorithm\nto ef\ufb01ciently manage the cached models by utilizing the\ncontextual information and thus reducing model switch-\ning, inference, and accuracy costs.\nCompared with our prior work in [9], this paper provides\nformal mathematical formulations for the joint foundation\nmodel caching and inference problem, the new age of context\nmetric, and the least context algorithm.\nCloud Data\nCenter\n: Edge server\n: Cached model\n: Mobile device\n: AIGC\nGPU Memory\nExamples\nin context\nFig. 1: Joint foundation model caching and inference of\ngenerative AI services for edge intelligence.\nII. SYSTEM MODEL\nAs shown in Fig. 1, we consider an edge intelligence system\nmodel consisting of service providers, including one cloud data\ncenter and a set of edge servers, and a massive amount of users.\nThe cloud data center and edge servers can serve generative\nAI services. The cloud data center is represented by 0 and the\nset of edge servers is represented by N = {1, 2, . . . , N}. In\nthis system, edge servers and the cloud center provide generic\nAI services such as AIGC, depending on different PFMs. We\nuse a set I = {1, 2, . . . , I} to denote the available generative\nAI services based on a set of PFMs M = {1, 2, . . . , M}. As\nPFMs are capable of performing multiple downstream tasks in\ngenerative AI services simultaneously, and thus we consider\nI \u226bM that the number of AI servers is far greater than the\nnumber of PFMs.\nMobile users must request generative AI services from\nedge servers or cloud data centers when their devices are\ninsuf\ufb01cient for executing PFMs. The inference requests of the\ndiverse services might request different PFMs when they are\nserving different functions. Typically, a generative AI service\nrequires the collaboration of several PFMs to process users\u2019\nrequests. For instance, in Stable Diffusion [10], text-related\nconditioning is based on a pre-trained CLIP ViT-L/14 model.\nThen, a variational autoencoder compresses images into a\nsmaller dimensional latent space. Finally, a U-Net block is\nused to denoise the output from forward diffusion backwardly\nto obtain a latent representation. This is a typical process\nof serving text-to-image generation service requests. We use\nRt\nn,i,m to denote the number of inference requests generated\nby AI service i to execute foundation model m at edge server\nn. The con\ufb01guration of PFM m consists of the amount of\nruntime GPU memory, which is proportion to model size sm,\nthe inference cost per token em, the model accuracy am, and\nthe size of context window wm. The inference process of AI\nservices can put certain context information into the context\nwindow of models. Then, the number of examples in context\nis denoted by Kt\ni,m of model m for application i which is zero\ninitially, i.e., K0\ni,m = 0.\nA. Decision Variables\nTo offer AI services based on PFMs, we propose a joint\nfoundation model caching and inference framework. Edge\nservers need to make model caching and request of\ufb02oading\ndecisions to utilize the existing edge computing resources\nfor accommodating generative AI service requests of mobile\nusers. Speci\ufb01cally, edge server n needs to determine the\nfollowing variables: (i) Let at\nn,i,m \u2208{0, 1} denote the binary\nvariable indicating whether model m of application i is cached\nat edge server n at time slot t; (ii) Let bt\nn,i,m \u2208[0, 1]\ndenote the continuous variable on whether model m of ap-\nplication i is cached at edge server n at time slot t. Let\nat\nn = {at\nn,1,1, . . . , at\nn,I,M} denote the model caching decisions\nof edge server n and at = {at\n1, . . . , at\nn}. In addition, the\nrequest of\ufb02oading decision of edge server n can be denoted as\nbt\nn = {bt\nn,1,1, . . . , bt\nn,I,M} and the request of\ufb02oading decisions\nof all edge servers can be denoted as bt = {bt\n1, . . . , bt\nn}.\nThe generative AI service requests of users can be executed\nat edge servers if the required components of models are\nloaded at the GPU memories. Let Gn denote the capacity\nof GPU memory of edge server n. Then, the model caching\ndecision variables are subjected to the following constraint\nX\ni\u2208I\nX\nm\u2208M\nat\nn,i,msm \u2264Gn, \u2200n \u2208N.\n(1)\nThe models of AI services can be executed at the edge server\nafter they are loaded into the GPU memory. Therefore, the\nconstraint of model execution at edge servers is\nbt\nn,i,m1(Rt\nn,i,m > 0) \u2264at\nn,i,m, \u2200n \u2208N, i \u2208I, m \u2208M (2)\nat time slot t and 1(\u00b7) is the indicator function. Let En denote\nthe resource capacity of edge server n. The total resource\nconsumption of servers is constrained by the total energy\ncapacity, which can be represented as\nX\ni\u2208I\nX\nm\u2208M\nemat\nn,i,mbt\nn,i,mRt\nn,i,m \u2264En, n \u2208N.\n(3)\nIn cloud data centers, there are no GPU memory constraints\nor energy constraints for cached PFMs.\nB. Age of Context and In-context Learning Accuracy\nPFMs, such as GPT-3, have the ability to perform in-context\nlearning, which means that they can learn from past prompts\nand inference results when an unseen task is presented to them.\nSome primary experiments show that larger models are more\neffective at using in-context instructions and demonstrations,\nas demonstrated by their improved ability to learn a task\nfrom contextual information [3]. This is particularly useful in\nNLP tasks, where understanding the context of a sentence or\nparagraph is crucial for accurate interpretation. Based on the\nevidence that GPT-3 is capable of in-context learning, which\ncontributes to its strong performance on a variety of language\ntasks, such as translation, basic arithmetic, and Q&A. Let\nKt\ni,m denote the number of effective examples of model m\nfor application i. The examples in the demonstration might\nhave different impacts on the model performance in terms\nTABLE I: The Parameters of Accuracy in Downstream Tasks\nof GPT3-13B/175B [3].\nTask\nModel\nK\nA0\nA1\n\u03b1\nTranslation\n13B\n64\n15.45\n11.8\n0.0923\n175B\n64\n22.03\n7.59\n0.1565\nBasic Arithmetic\n13B\n50\n3.79\n12.19\n-0.0501\n175B\n50\n25.99\n14.72\n0.1813\nSuperGLUE\n13B\n32\n54.40\n9.89\n0.0969\n175B\n32\n58.20\n10.70\n0.1431\nof relevance, quality, and freshness. We propose the AoC to\nmeasure the freshness of examples in demonstrations that have\nan impact on the quality of services provided by PFMs in\ntasks that are now being carried out downstream. For instance,\nthe historical Q&A records that are recorded during PFM\ninference can be used to improve future inference accuracy.\nThese examples can be used to increase the accuracy of PFMs,\nas PFMs can use meta-gradient learn during interaction to \ufb01t\nthem [11]. However, depending on the caliber, applicability,\nand timeliness of examples, the meta-gradient may have fa-\nvorable or unfavorable impacts on the model performance.\nSimilar to the de\ufb01nition of age of information (AoI), the AoC\nmeasures the freshness of historical contextual examples in\ndemonstrations between the cached PFMs and the inference\nrequests. As shown in TABLE I, with a vanishing factor \u03bdi,m\nof context, the AoC is adjusted by the non-increasing age\nutility function. Therefore, the effective number of examples\nin context Kt\ni,m at edge server n can be represented as\nKt\ni,m = min\n\u0000wm, {Kt\u22121\ni,m + Rt\nn,i,mat\nn,i,mbt\nn,i,m \u2212\u03bdi,m}+\u0001\n,\n(4)\nfor t = 1, . . . , T. According to the AoC, the weighted total\nof the number of examples in demonstrations may be used to\ndetermine the number of examples in context.\nAs shown in Table I, the in-context (few-show) accuracy\nAi,m of model m for the downstream task in application i\ncan be \ufb01t by a logarithmic function as [3]\nAi,m(Kt\ni,m) = A0\nm + A1\nm log2(1 + Kt\ni,m\n\u03b1m),\n(5)\nwhere A0\nm is the zero-shot accuracy, A1\nm is the one-shot\naccuracy, Kt\ni,m is the number of examples in context, and\n\u03b1m is the coef\ufb01cient of model m.\nC. Cost Structure\nAs discussed above, the generative AI service requests can\nbe executed by edge servers and of\ufb02oaded to cloud data centers\nover the core network. Given the model caching and request\nof\ufb02oading decisions, the total system cost of serving generative\nAI services consisting of the edge inference cost and cloud\ninference cost can be formulated as follows.\n1) Edge Inference Cost: Speci\ufb01cally, the edge inference\ncost consists of the edge switching cost, the edge transmission\ncost, the edge computing cost, and the model accuracy cost.\nAccording to model caching decisions, each edge server needs\nto load models into the GPU memory before execution. During\nthe loading process, the model switching cost consisting of\nthe model loading latency and hardware wear-and-tear cost is\nincurred. Therefore, the switching cost ls\nn of edge server n to\nload and evict models can be calculated as\nlswitch\nn\n(at) =\nX\ni\u2208I\nX\nm\u2208M\n\u03bb1(at\nn,i,m > at\u22121\nn,i,m),\n(6)\nwhere \u03bb denotes the coef\ufb01cient for loading and evicting the\nmodel and 1(\u00b7) is the indicator function. When at\nn,i,m >\nat\u22121\nn,i,m, i.e., at\nn,i,m = 1 and at\u22121\nn,i,m = 0, 1(at\nn,i,m > at\u22121\nn,i,m)\nindicates that the loading of an uncached model. Otherwise,\nthere is no switching cost incurred at edge servers.\nWhen the requested models are cached into the GPU\nmemory of edge servers, users communicate with the edge\nservers for requesting generative AI services. Let ltrans\nn\ndenote\nthe transmission cost of input prompts and inference results.\nThe transmission cost of edge server n can be calculated as\nltrans\nn\n(at, bt) =\nX\ni\u2208I\nX\nm\u2208M\nln,mRt\nn,i,mat\nn,i,mbt\nn,i,m,\n(7)\nwhere ri,m is the unit transmission cost per input and result\nfor model m of application i.\nLet fn denote the computing capacity of edge server n. The\nforward propagation process of AI services at edge servers\nincurs inference latency, which can be denoted as lcomp\nn\nfor\nedge server n. The edge computing cost can be calculated as\nlcomp\nn\n(at, bt) =\nX\ni\u2208I\nX\nm\u2208M\nRt\nn,i,mat\nn,i,mbt\nn,i,m\ncn\nfn\n.\n(8)\nFinally, as edge servers might not have suf\ufb01cient resources for\nexecuting the best match model requested by AI services, the\nrequests processed by other PFMs with the equivalent function\nincur accuracy cost lacc\nn , which can be represented as\nlacc\nn (at, bt) =\nX\ni\u2208I\nX\nm\u2208M\n(1 \u2212Ai,m)Rt\nn,i,mat\nn,i,mbt\nn,i,m.\n(9)\nBy sacri\ufb01cing some accuracy of generative AI services, the\nsystem can reduce the model missing rate. Therefore, the total\nedge inference cost of edge server n is\nLt\nn(at, bt) =lswitch\nn\n(at\nn) + ltrans\nn\n(at\nn, bt\nn)\n+ lcomp\nn\n(at\nn, bt\nn) + lacc\nn (at\nn, bt\nn).\n(10)\nThe edge inference cost is jointly determined by the caching\ndecisions and of\ufb02oading decisions of edge servers. Neverthe-\nless, the missed or of\ufb02oaded requests are processed by the\ncloud data center.\n2) Cloud Inference Cost: The edge servers are resource-\nconstrained, such that they are unable to serve all PFMs. On\none hand, due to the limited storage resources of the edge\nserver, the model requested by a user may be too large to\nbe loaded into the GPU of the edge server. On the other\nhand, the limited computing power of the edge server makes it\nnecessary to actively migrate some requests to the cloud data\ncenter for execution. Therefore, when the requested models are\nmissed at edge servers or of\ufb02oaded to cloud data centers, this\npart of user requests are transmitted to the cloud data center,\nwhich needs to allocate resources for accomplishing such user\nrequests. In line with [12], the cloud data centers can consider\nserving generative AI services in a serverless manner, which\nis charged in a \u201cpay-as-you-go\u201d manner. Therefore, users need\nto pay for executing AI services according to the number\nof requests instead of speci\ufb01c occupied resources. When the\nrequests are missed at edge servers or edge servers do not have\nenough resources for serving the requests, the unaccomplished\nrequests will be of\ufb02oaded to the cloud data centers for remote\nexecution. The cloud data centers can execute the models\nwith their abundant computing and energy resources, and\nthen return the inference results to edge servers. However,\ncloud inference incurs additional latency for data transmission\nin the core network, which is much higher than the data\ntransmission latency at edge servers. Moreover, the accuracy\ncost of of\ufb02oaded inference requests executed by the cloud data\ncenter is expected to be almost zero as they can be processed\nby the most accurate model with common in-context examples\nowned by the data center. Based on the above analysis, we use\nl0,n to denote the aggregated cost of of\ufb02oading one request to\nthe cloud data center for remote execution of model m. Then,\nthe total cloud computing cost at time slot t is\nLt\n0(at, bt) =\nX\nn\u2208N \\{0}\nX\ni\u2208I\nX\nm\u2208M\nl0,m(1\u2212at\nn,i,mbt\nn,i,m)Rt\nn,i,m.\n(11)\nD. Problem Formulation\nTo optimize the performance of mobile edge intelligence,\nwe jointly consider the cost of edge inference and cloud\ninference, including the switching cost, the accuracy cost, the\ntransmission cost, and the inference cost over a time horizon\nT. The problem is formulated as follows:\nmin\nat, bt\n1\nT\nX\nt\u2208T\n \nLt\n0 +\nX\nn\u2208N\nLt\nn\n!\n(12a)\ns.t.\n(1), (2), (3),\n(12b)\nat\nn,i,m \u2208{0, 1},\n(12c)\nbt\nn,i,m \u2208[0, 1].\n(12d)\nTo solve the optimization problem described above, we must\novercome the following challenges: (i) The problem involves\ntime-coupling elements, such as GPU memories and in-context\nexamples, as it considers both future request dynamics and\nhistorical inference contexts; (ii) Through historical statistical\ndata, we can forecast future information before making a\ndecision The problem becomes a mixed-integer programming\nproblem, which is NP-hard. To address these challenges, a\nlow-complexity heuristic algorithm is needed to make deci-\nsions regarding model caching and request of\ufb02oading, despite\nthe lack of future information.\nIII. THE LEAST CONTEXT ALGORITHM\nTo effectively serve PFMs for provisioning generative AI\nservices, we propose the least context algorithm based on\nthe AoC metric. When additional GPU memory is required\nfor loading an uncached requested PFM, the LC algorithm\n20\n30\n40\nB\nB\nB\nB\nB\nA - Cloud Inference\nB - FIFO\nC - LFU\nD - Least Context (LC)\nCloud Inference Cost\nAccuracy Cost\nEdge Inference Cost\nSwitching Cost\n20\n40\n60\n80\n100\nNumber of Time Slots\n0\n2\n4\n6\n8\n                                    Average Total Cost\nA\nA\nA\nA\nA\nC\nC\nC\nC\nC\nD\nD\nD\nD\nD\nFig. 2: Average total cost versus number\nof time slots.\n20\n30\n40\nB\nB\nB\nB\nB\nA - Cloud Inference\nB - FIFO\nC - LFU\nD - Least Context (LC)\nCloud Inference Cost\nAccuracy Cost\nEdge Inference Cost\nSwitching Cost\n22\n24\n26\n28\n30\nNumber of Services\n0\n2\n4\n6\n8\n                                    Average Total Cost\nA\nA\nA\nA\nA\nC\nC\nC\nC\nC\nD\nD\nD\nD\nD\nFig. 3: Average total cost versus number\nof services.\n20\n40\n60\n80\nB\nB\nB\nB\nA - Cloud Inference\nB - FIFO\nC - LFU\nD - Least Context (LC)\nCloud Inference Cost\nAccuracy Cost\nEdge Inference Cost\nSwitching Cost\n2\n4\n8\n16\nNumber of GPUs\n0\n2\n4\n6\n8\n                                    Average Total Cost\nA\nA\nA\nA\nC\nC\nC\nC\nD\nD\nD\nD\nFig. 4: Average total cost versus number\nof GPUs.\ncounts the number of examples in context, calculates them,\nand removes the cached PFM with the fewest effective ex-\namples in context. Therefore, at each time slot t, the model\ncaching decisions can be obtained by solving the maximization\nproblem of the number of effective examples for the cached\nmodels, which can be represented as\nmax\nat\nX\ni\u2208I\nX\nm\u2208M\nKt\ni,m\n(13a)\ns.t.\nX\ni\u2208I\nX\nm\u2208M\nat\nn,i,msm \u2264Gt\nn, \u2200n \u2208N,\n(13b)\nat\nn,i,m \u2208{0, 1}.\n(13c)\nThe available capacity of GPU memory Gt\nn of server n at time\nslot t can be calculated as Gt\nn = Gn \u2212Rt\nn,i,mat\nn,i,mbt\nn,i,msm.\nThis optimization problem can be tackled with a complexity\nof O(IM) with prior knowledge and statistical data. This\nalgorithm gives the least important PFM for the current\ninference task priority for eviction. It works well with huge\nnumbers of PFMs on edge servers with limited GPU memory.\nBy using more contextual information during inference, the\nPFMs of mobile generative AI services are more accurate.\nBased on caching decisions at by solving the optimization\nproblem (13a), of\ufb02oading decisions bt are obtained by solving\nthe optimization problem (12a).\nIV. NUMERICAL RESULTS\nIn the experiment, we consider an edge intelligence system\nwith T = 100 slots. The requests for generative AI services per\ntime slot follow the Poisson process with an average of one.\nWe consider three types of PFMs and select six representative\nmodels to serve in the experiments, i.e., GPTs, Uniformers,\nand CLIPs. The detailed model con\ufb01guration can be found\nin [9]. The main parameters are listed in TABLE II.\nWe evaluate the proposed LC approach in comparison to\nseveral baselines including cloud inference, the \ufb01rst-in-\ufb01rst-out\n(FIFO) caching algorithm, and the least frequently used (LFU)\ncaching algorithm. Initially, we examined the effectiveness\nof the LC algorithm by comparing the average total cost in\nvarious system settings. As we observe in Fig. 2, the switching\ncost of the LC algorithm gradually converges to a smaller value\nTABLE II: The List of Main System Parameters.\nParameters\nValue\nNumber of time slots\n100\nNumber of services\n30\nNumber of GPUs\n8\nSize of context window\n2048\nSize of examples\n[10, 100]\nGPU Memory\n80 GB\nGPU Computing Capacity\n312000 GFLOPS\nEdge transmission cost\n0.0001\nCloud inference cost\n0.0015\nSwitching cost coef\ufb01cient\n0.0001\nAccuracy cost coef\ufb01cient\n0.01\nGPU energy ef\ufb01ciency\n810 GFLOPS/W\nEnergy capacity\n300 W\nat around 1.3%, while the switching cost of the FIFO algorithm\nremains constant with system time. This indicates that the\nLC algorithm is able to cache most of the required models\nfor inference services on the edge server in GPU memory. In\naddition, the LC algorithm achieves the lowest average total\ncost among all the algorithms. The LC algorithm can reduce\nthe cloud inference cost by increasing the utilization of edge\ncomputing resources so that the requests can be executed at\nedge servers with low latency.\nWe then show that the proposed LC algorithm is robust\nunder different system settings, such as a different number of\nservices and a different number of GPUs. From Fig. 3, we\ncan see that the total system cost increases with the number\nof services. This is because the resources in the edge servers\nbecome insuf\ufb01cient when more services need to be served on\nthe edge servers. On one hand, the GPU memory on the edge\nservers is limited, and as the number of services increases,\nmore model switching will be required when running the\nmodel, so the switching cost becomes higher. On the other\nhand, when the resources on the edge servers are not suf\ufb01cient,\nthe requests for cloud inference have to be forwarded to\ncloud data centers, whose costs are higher than those of edge\ninference. In the meanwhile, the experimental results in Fig. 4\nindicate that the number of GPUs has a complex impact on the\ntotal system cost. When the number of GPUs increases, the\n0.0\n0.2\n0.4\n0.6\n0.8\n1\nContext Vanishing Factor\n0.35\n0.38\n0.40\n0.43\n0.45\n0.48\n0.50\n0.53\nAverage Accuracy Cost\nFIFO\nLFU\nLeast Context (LC)\nFig. 5: Edge accuracy cost vs. context vanishing factor.\nswitching cost increases. The reason is that the edge servers\ncan cache more models in the GPU memory. Without effective\nmanagement of cached models, the switching cost is high for\nthe FIFO algorithms. Though the cost of the proposed LC\nalgorithm is always lower than those of the other algorithms,\nits cost increases when the number of GPUs increases. The\nreason behind this trend is that edge servers can cache larger\nmodels when the number of GPUs is large. However, such\nlarge models require intensive computing resources while\nincurring similar edge inference costs. Therefore, these user\nrequests for large models are better of\ufb02oaded to cloud data\ncenters for remote execution.\nAfter demonstrating the effectiveness of the proposed LC\nalgorithm, we next investigate the impacts of the context\nvanishing factor. To make comparisons between models more\nnoticeable, the size of the context window is set to 214. As\nshown in Fig. 5, as the context vanishing factor increases,\nthe average accuracy cost of edge inference is \ufb01rst static and\nthen decreases. When the context vanishing factor is small, the\nperformance gap among these three algorithms becomes large.\nHowever, when the context vanishing factor is large, such as\none in Fig. 5, the average accuracy cost decreases, and their\nperformance gap starts to shrink. Another interesting \ufb01nding\nshown in Fig. 6 is that the averse edge inference cost \ufb01rst\nincreases as the context vanishing factor increases and then\ndramatically declines after a certain threshold.\nV. CONCLUSIONS\nIn this paper, we investigated the joint foundation model\ncaching and inference problem for deploying PFMs to serve\nAI-based multimedia services in mobile edge networks. We\nintroduced a joint foundation model caching and inference\nframework designed to effectively provision generative AI\nservices at edge servers, and thus advancing toward AGI.\nTo this end, we proposed a new metric for measuring the\nrelevance and freshness of contextual examples in relation to\nongoing inference requests. Moreover, we have developed the\nLC algorithm for PFM management, which optimizes the uti-\nlization of historical contextual prompts and inference results,\nsubsequently enhancing the performance of generative AI\nservices. Experimental results indicated that the LC algorithm\n0.0\n0.2\n0.4\n0.6\n0.8\n1\nContext Vanishing Factors\n1.56\n1.58\n1.60\n1.62\n1.64\nAverage Edge Inference Cost\nFIFO\nLFU\nLeast Context (LC)\nFig. 6: Edge inference cost vs. context vanishing factor.\neffectively reduces system costs by effectively leveraging\nhistorical demonstrates and managing cached models.\nREFERENCES\n[1] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Ka-\nmar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg et al., \u201cSparks of arti\ufb01cial\ngeneral intelligence: Early experiments with GPT-4,\u201d arXiv preprint\narXiv:2303.12712, Mar. 2023, [Online]. Available: https://arxiv.org/abs/\n2303.12712.\n[2] P. Zhou, J. Zhu, Y. Wang, Y. Lu, Z. Wei, H. Shi, Y. Ding, Y. Gao,\nQ. Huang, Y. Shi et al., \u201cVetaverse: Technologies, applications, and\nvisions toward the intersection of metaverse, vehicles, and transporta-\ntion systems,\u201d arXiv preprint arXiv:2210.15109, Oct. 2022, [Online].\nAvailable: https://arxiv.org/abs/2210.15109.\n[3] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,\nA. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., \u201cLanguage models\nare few-shot learners,\u201d Proc. of the Advances in Neural Information\nProcessing Systems, vol. 33, pp. 1877\u20131901, Dec. 2020.\n[4] C. Zhou, Q. Li, C. Li, J. Yu, Y. Liu, G. Wang, K. Zhang, C. Ji, Q. Yan,\nL. He et al., \u201cA comprehensive survey on pretrained foundation models:\nA history from BERT to ChatGPT,\u201d arXiv preprint arXiv:2302.09419,\nFeb. 2023, [Online]. Available: https://arxiv.org/abs/2302.09419.\n[5] M. Xu, D. Niyato, J. Chen, H. Zhang, J. Kang, Z. Xiong, S. Mao, and\nZ. Han, \u201cGenerative AI-empowered simulation for autonomous driving\nin vehicular mixed reality metaverses,\u201d arXiv preprint arXiv:2302.08418,\nFeb. 2023, [Online]. Available: https://arxiv.org/abs/2302.08418.\n[6] G. R. Gilman, S. S. Ogden, R. J. Walls, and T. Guo, \u201cChallenges and\nopportunities of dnn model execution caching,\u201d in Proc. of the Workshop\non Distributed Infrastructures for Deep Learning, Davis, CA, Dec. 2019,\npp. 7\u201312.\n[7] Z. Zhou, X. Chen, E. Li, L. Zeng, K. Luo, and J. Zhang, \u201cEdge\nintelligence: Paving the last mile of arti\ufb01cial intelligence with edge\ncomputing,\u201d Proc. of the IEEE, vol. 107, no. 8, pp. 1738\u20131762, Jun.\n2019.\n[8] Q. Dong, L. Li, D. Dai, C. Zheng, Z. Wu, B. Chang, X. Sun,\nJ. Xu, and Z. Sui, \u201cA survey for in-context learning,\u201d arXiv preprint\narXiv:2301.00234, Jan. 2023, [Online]. Available: https://arxiv.org/abs/\n2301.00234.\n[9] M. Xu, D. Niyato, H. Zhang, J. Kang, Z. Xiong, S. Mao, and Z. Han,\n\u201cSparks of gpts in edge intelligence for metaverse: Caching and infer-\nence for mobile aigc services,\u201d arXiv preprint arXiv:2304.08782, Apr.\n2023, [Online]. Available: https://arxiv.org/abs/2304.08782.\n[10] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer, \u201cHigh-\nresolution image synthesis with latent diffusion models,\u201d in Proc. of the\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\nNew Orleans, LA, Jun. 2022, pp. 10 684\u201310 695.\n[11] D. Dai, Y. Sun, L. Dong, Y. Hao, Z. Sui, and F. Wei, \u201cWhy can gpt\nlearn in-context? language models secretly perform gradient descent as\nmeta optimizers,\u201d arXiv preprint arXiv:2212.10559, Dec. 2022, [Online].\nAvailable: https://arxiv.org/abs/2212.10559.\n[12] K. Zhao, Z. Zhou, X. Chen, R. Zhou, X. Zhang, S. Yu, and D. Wu,\n\u201cEdgeadaptor: Online con\ufb01guration adaption, model selection and re-\nsource provisioning for edge dnn inference serving at scale,\u201d IEEE\nTransactions on Mobile Computing, pp. 1 \u2013 16, Jul. 2022.\n",
    "2303.13052": "1\nDiffusion-based Reinforcement Learning for\nEdge-enabled AI-Generated Content Services\nHongyang Du*, Zonghang Li*, Dusit Niyato, Fellow, IEEE, Jiawen Kang, Zehui Xiong, Huawei Huang, and\nShiwen Mao, Fellow, IEEE\n\u2726\nAbstract\u2014As Metaverse emerges as the next-generation Internet\nparadigm, the ability to efficiently generate content is paramount. AI-\nGenerated Content (AIGC) emerges as a key solution, yet the resource-\nintensive nature of large Generative AI (GAI) models presents chal-\nlenges. To address this issue, we introduce an AIGC-as-a-Service\n(AaaS) architecture, which deploys AIGC models in wireless edge\nnetworks to ensure broad AIGC services accessibility for Metaverse\nusers. Nonetheless, an important aspect of providing personalized user\nexperiences requires carefully selecting AIGC Service Providers (ASPs)\ncapable of effectively executing user tasks, which is complicated by\nenvironmental uncertainty and variability. Addressing this gap in current\nresearch, we introduce the AI-Generated Optimal Decision (AGOD)\nalgorithm, a diffusion model-based approach for generating the opti-\nmal ASP selection decisions. Integrating AGOD with Deep Reinforce-\nment Learning (DRL), we develop the Deep Diffusion Soft Actor-Critic\n(D2SAC) algorithm, enhancing the efficiency and effectiveness of ASP\nselection. Our comprehensive experiments demonstrate that D2SAC\noutperforms seven leading DRL algorithms. Furthermore, the proposed\nAGOD algorithm has the potential for extension to various optimization\nproblems in wireless networks, positioning it as a promising approach\nfor future research on AIGC-driven services. The implementation of our\nproposed method is available at: https://github.com/Lizonghang/AGOD.\nIndex Terms\u2014AI-generated content, wireless networks, generative AI,\ndiffusion models, and deep reinforcement learning.\n1\nINTRODUCTION\nT\nHE Turing Test, a renowned evaluation benchmark, was\nproposed by Alan Turing in his seminal paper [1] to\nassess the intelligence of machines, i.e., their ability to mimic\nhuman thinking and generate content that can interact with\nhumans. Since then, the ability of Artificial Intelligence (AI)\nto create content has become a fundamental research goal,\nas it is believed to be a key enabler for an epoch-making\nH. Du, and D. Niyato are with the School of Computer Science and\nEngineering, the Energy Research Institute @ NTU, Interdisciplinary\nGraduate Program, Nanyang Technological University, Singapore (e-mail:\nhongyang001@e.ntu.edu.sg, dniyato@ntu.edu.sg). Z. Li is with the School of\nInformation and Communication Engineering, University of Electronic Sci-\nences and Technology of China, Chengdu, China (email: lizhuestc@gmail.com).\nJ. Kang is with the School of Automation, Guangdong University of Technol-\nogy, China (e-mail: kavinkang@gdut.edu.cn). Z. Xiong is with the Pillar of\nInformation Systems Technology and Design, Singapore University of Tech-\nnology and Design, Singapore (e-mail: zehui xiong@sutd.edu.sg). H. Huang\nis with the School of Software Engineering, Sun Yat-Sen University, Zhuhai,\nChina (e-mail: huanghw28@mail.sysu.edu.cn). S. Mao is with the Department\nof Electrical and Computer Engineering, Auburn University, Auburn, USA\n(e-mail: smao@ieee.org). H. Du and Z. Li have equal contributions.\nintelligence society. This ambitious vision aligns with the\nrequirements of Metaverse [2]. As we move towards a more\nimmersive and interactive future Internet, the ability to\ngenerate vast amounts of high-quality digital content, e.g.,\nuser-defined avatars, becomes increasingly significant.\nFortunately, AI-Generated Content (AIGC) has emerged\nas a powerful force driving innovation. According to a\nstudy by PriceWaterhouseCoopers, AI can increase global\nGDP by 14% or approximately $15.7 trillion by 2030 [3].\nThis highlights the transformative impact of AIGC in driv-\ning economic growth and spurring technology adoption.\nFor example, ChatGPT, a chatbot developed by OpenAI,\nhas achieved remarkable success in generating human-\nlike text [4]. Furthermore, Stable Diffusion, a text-to-image\nGenerative AI (GAI) model launched in 2022 by Stability\nAI, can generate images in seconds conditioned on text\ndescriptions [5]. With these capabilities, AIGC techniques\nare rapidly becoming essential for content creation and\ndelivery, which is considered the \u201cengine\u201d in powering\nMetaverse [6, 7].\nDespite the remarkable advances in AIGC techniques,\nseveral challenges are associated with deployment [8]. One\nof the most significant issues is the increasing cost of\ndeveloping and deploying AIGC models in user devices,\ne.g., head-mounted displays. AIGC models require large\ndatasets and complex architectures to achieve state-of-the-\nart performance, leading to massive resource consumption\nand longer training times [9]. Furthermore, these models\nrequire high-end hardware and specialized software for\ntraining and inference, making it difficult for individuals\nto access and utilize AIGC in Metaverse. As such, the high\ncost limits the widespread adoption of AIGC.\nAnother major obstacle stems from the diversity of\nusers [10]. The Metaverse is expected to accommodate many\nuser types, including those with varying cultural back-\ngrounds, languages, and preferences. AIGC models must\ntherefore be capable of generating content that is tailored\nto the individual user and meets their unique needs and\nexpectations. Achieving this level of customization is chal-\nlenging, as it requires a deep understanding of user behavior\nand online task scheduling mechanisms. In general, on the\nway to building a human-centric Metaverse with the AIGC\ntechnique, the following two goals exist:\nG1)\nMake AIGC a Metaverse support technology accessible\narXiv:2303.13052v3  [cs.NI]  21 Nov 2023\n2\nfrom any device, anywhere, at any time\nG2)\nProvide human-centric AIGC services, maximizing Meta-\nverse user utilities while meeting users needs\nTo achieve the first goal (G1), one promising approach is\nto adopt the \u201ceverything-as-a-service\u201d paradigm. Specif-\nically, instead of distributing the trained AIGC models\nto user devices, they can be deployed on network edge\nservers, enabling the realization of \u201cAIGC-as-a-Service\u201d\n(AaaS) through the wireless edge networks. When a user\nrequires AIGC services, the user can upload the demand to\nthe network edge server, which executes the task through\nthe AIGC model and sends the results back to the user.\nThis approach has several advantages, including reducing\nthe computational burden on user devices and providing\nflexible and scalable AIGC services. Furthermore, with the\nrapid advancement of wireless communication and com-\nputing technologies, the Sixth Generation (6G) of wireless\nnetworks is emerging as the next frontier in mobile commu-\nnication systems, which are expected to provide ultra-high\ndata speeds, ultra-low latency, and ultra-high dependability,\nenabling real-time responses to user requests. As a result,\nthe deployment of AaaS can provide an efficient and reliable\nsolution for delivering AIGC services to users while also\nenabling the development of new applications and services.\nHowever, the adoption of the AaaS approach poses a\nsignificant challenge to the second goal (G2), which is to\nprovide human-centric AIGC services that maximize the\nutilities for the users. The challenge stems from the fact that\nvarious AIGC models possess different capabilities and are\nsuited to specific tasks. For example, some AIGC models\ngenerate human-like images, while others perform better\nin producing natural scenery. Users also exhibit varying\ninterests and preferences, and servers display varying com-\nputation capacities. Consequently, it becomes imperative\nto select the best AIGC Service Provider (ASP) for many\nusers, considering their specific requirements, personality,\nthe computing resources available on the edge servers, and\nthe attributes of the deployed AIGC models. By utilizing\nan efficient scheduling algorithm, it is possible to optimize\nthe benefits of AaaS services for the users, enhancing their\nimmersive experience and augmenting their engagement\nwith Metaverse [6, 11].\nThus, a well-designed ASP selection algorithm is es-\nsential to achieve the two goals of providing ubiquitous\nand human-centric AIGC services. However, the difficulty\nin mathematically modeling both user utilities and AIGC\nmodel capabilities poses a significant challenge. Deep Rein-\nforcement Learning (DRL)-based methods are a promising\nsolution, but may not be efficient due to their dependence\non exploration-exploitation trade-offs and potential con-\nvergence to suboptimal policies [12]. To overcome these\nlimitations, we propose a novel diffusion model-based AI-\nGenerated Optimal Decision (AGOD) algorithm [13]. Similar\nto the AIGC technique in which diffusion models generate content,\nwe adapt diffusion models to generate optimal decisions. The\ncontributions of this paper are summarized as follows:\n\u2022\nWe propose an architecture for AaaS that deploys\nAIGC models in the edge network, providing ubiq-\nuitous AIGC functionality to users in Metaverse (For\nG1).\n\u2022\nWe propose the AGOD algorithm, empowered by\ndiffusion models, to generate optimal decisions in\nthe face of environmental uncertainty and variability\n(For G2).\n\u2022\nWe apply our proposed AGOD to DRL, specifically\nin the form of the Deep Diffusion Soft Actor-Critic\n(D2SAC) algorithm, which achieves efficient and op-\ntimal ASP selection, thereby maximizing the user\u2019s\nsubjective experience (For G1 and G2).\n\u2022\nWe demonstrate the effectiveness of the proposed\nalgorithm through extensive experiments, showing\nthat D2SAC outperforms seven representative DRL\nalgorithms, i.e., Deep Q-Network (DQN) [14], Deep\nRecurrent\nQ-Network\n(DRQN)\n[15],\nPrioritized-\nDQN [16], Rainbow [17], REINFORCE [18], Proximal\nPolicy Optimization (PPO) [19], and Soft Actor-Critic\n(SAC) [20] algorithms, not only in the studied ASP\nselection problem but also in various standard con-\ntrol tasks.\nThe rest of the paper is structured as follows: Section 2\nreviews the related work. In Section 3, we introduce the\nAaaS concept and formulate the ASP selection problem. In\nSection 4, we propose the diffusion model-based AGOD\nalgorithm. Section 5 presents the novel deep diffusion re-\ninforcement learning algorithm, e.g., D2SAC, by applying\nAGOD in DRL. We conduct a comprehensive evaluation\nof the proposed D2SAC in Section 6. Finally, Section 7\nconcludes this paper.\n2\nRELATED WORK\nIn this section, we provide a brief review of the related work,\ni.e., AIGC in Metaverse, diffusion model in optimization,\nand DRL.\n2.1\nArtificial Intelligence-Generated Content in Meta-\nverse\nMetaverse has gained significant attention as a future In-\nternet. However, creating digital content is a prerequisite\nfor establishing a symbiotic Internet between the virtual\nand real worlds. Fortunately, AIGC technologies provide\ntechnical support for the rapid creation of digital content\nby leveraging the power of AI to automate the information\ncreation process [21]. This innovative content generation\nmethod represents a paradigm shift from traditional User-\nGenerated Content (UGC) and Professionally Generated\nContent (PGC). Recent research has explored the potential of\nAIGC in empowering Metaverse. For example, to promote\nthe construction of a virtual transportation system, the au-\nthors in [7] propose a blockchain-aided semantic communi-\ncation framework for AIGC services to facilitate interactions\nof the physical and virtual domains among virtual service\nproviders and edge devices. Moreover, the authors in [22]\npresent a blockchain-empowered framework to manage the\nlife-cycle of edge AIGC products. Despite the significant\npotential of AIGC, the issue of enabling widespread access\nto huge AIGC models still needs to be solved [23].\n3\n2.2\nDiffusion Model in Optimization\nDiffusion models, recognized as potent deep generative\nmodels, have become increasingly popular in machine\nlearning, particularly in the image and video generation\nand molecule design [5, 13]. These models aim to learn\na given dataset\u2019s latent structure by modeling how data\npoints diffuse through the latent space. In computer vi-\nsion, neural networks have been trained to denoise images\nblurred with Gaussian noise by learning to reverse the\ndiffusion process [5]. A groundbreaking approach called\nDiffusion Q-Learning (DQL) was introduced recently, using\na conditional diffusion model to perform behavior cloning\nand policy regularization [24]. The authors demonstrate\nthe superior performance of their method compared to\nprior works in a 2D bandit example with a multi-modal\nbehavior policy. However, it should be noted that DQL can\nonly be used in offline DRL tasks with imitation learning.\nThis limitation makes obtaining open datasets for online\ncommunication scheduling tasks impractical. More recently,\na novel AI-generated incentive mechanism algorithm was\nproposed by authors in [25] to solve the utility maximiza-\ntion problem by generating optimal contract designs. The\nproposed diffusion model-based algorithm has been shown\nto outperform two deep reinforcement learning algorithms,\ni.e., PPO and SAC. However, both methods in [24, 25] are\ndesigned for continuous action space problems and cannot\nbe applied in environments with discrete action spaces.\n2.3\nDeep Reinforcement Learning\nDRL, an extension of Reinforcement Learning utilizing deep\nneural networks, excels at capturing state space representa-\ntions. This capability empowers DRL agents to address com-\nplex and high-dimensional challenges, making it particu-\nlarly effective for sequential decision-making problems [26].\nThe ASP selection problem, characterized by its online na-\nture, presents a scenario where DRL\u2019s adaptability is par-\nticularly advantageous. DRL\u2019s dynamic learning framework\nallows it to efficiently adjust to unforeseen tasks that may\nemerge during operational processes, making it a highly\nsuitable approach for the ASP selection challenge. However,\nthere are limitations to this method that can impede its\neffectiveness. In particular, the high computational require-\nments of DRL algorithms can be a challenge, especially\nfor problems with large state or action spaces [27]. In this\ncase, the policy function in the DRL algorithm may not\noutput optimal action decisions based on the current state.\nTherefore, an innovative approach is to incorporate the\nAIGC technique in generating optimal action decisions.\nBuilding upon the limitations of existing research, we in-\ntroduce an innovative solution to the ASP selection problem\nin the form of an AaaS approach. To this end, we leverage\nthe power of the diffusion model and present the AGOD\nalgorithm, which we then apply to DRL to propose the\nD2SAC algorithm.\n3\nAIGC SERVICES IN WIRELESS NETWORKS\nIn this section, we introduce the AaaS in wireless edge net-\nworks, followed by the ASP selection problem formulation.\nThen, we introduce the human-aware utility function.\n3.1\nAIGC-as-a-Service\nAIGC techniques provide a fast and efficient content gen-\neration ability while reducing network resource consump-\ntion. AIGC models can help repair corrupted images,\ngenerate natural and realistic Augmented Reality/Virtual\nReality/High-Definition (AR/VR/HD) video content for\nMetaverse users, and simplify the design of wireless trans-\nmission protocols. However, deploying AIGC models is\ntypically challenging due to their large size and difficulty\nin training and deployment. To make AIGC services acces-\nsible from any device, anywhere, at any time, we propose\ndeploying the AIGC model on network edge devices, as\nillustrated in Fig. 1 (Part B), to support AaaS. For instance,\na Metaverse user can upload a generation request via the\nmobile device to an edge server. Then, the server sends\nthe AIGC computation results after completing the task.\nMoreover, users can customize the computational resources\nrequired for their tasks when uploading them to the ASP.\nOne example is given in Fig. 1 (Part A), the user interface\nof the stable diffusion model of the Hugging Face platform1\nallows users to specify the number of denoising steps for\nthe diffusion model. Thus, the AaaS approach provides a\nscalable and efficient solution for wireless users to access\nAIGC services on demand, even on resource-constrained\ndevices. However, to deploy AaaS, the following challenges\nstill need to be addressed:\nC1)\nUsers may access the AIGC service at their discretion\nand request customized computational resources,\nsuch as denoising steps of the diffusion model-based\nAIGC.\nC2)\nPerformance evaluation of AIGC tasks is human-\nsubjective and difficult to model mathematically.\nC3)\nThe capacities of AIGC models deployed on net-\nwork edge servers vary, as do the qualities of AIGC\nservices offered by different ASPs and the compu-\ntational resources available for each server, i.e., the\nmaximum number of AIGC tasks that can be pro-\ncessed in a given time window.\nTherefore, to improve the QoS of the entire AaaS system, an\nefficient and feasible algorithm for selecting an appropriate\nASP is necessary. A high-quality AaaS system produces sat-\nisfactory results and reduces the likelihood of encountering\nproblems or errors that could negatively impact the wireless\nnetwork\u2019s performance. By selecting the optimal ASP, users\ncan benefit from high-quality content generation services\nand fully leverage the potential of the wireless network with\nminimal errors and resource consumption.\n3.2\nAIGC Service Provider Selection\nThe ASP selection problem is analogous to a resource-\nconstrained task assignment problem, where the aim is to\nallocate incoming tasks to available resources, satisfying\nresource constraints and maximizing overall utility. This\nproblem is frequently encountered in wireless networks,\nwhere resources are scarce and their efficient utilization is\ncrucial to achieving the desired performance, including task\n1. The URL for Stable Diffusion v1-5 Demo in Hugging Face is https:\n//huggingface.co/spaces/runwayml/stable-diffusion-v1-5.\n4\n\u2026\n\u2026\nEdge Server 1\nEdge Server 2\nEdge Server I\nUser 1\nUser 2\nUser J\n\u2026\n\u2026\nI want to see ``A vase filled \nwith colorful flowers.``\nASP 1\nASP 2\nASP I\nA\nAIGC Service Provider \nSelection Problem\nUplink: Tasks, \nRequired Resource\nDownlink: \nFinished Tasks\nB Edge-enabled AIGC-as-a-service\nDeploy the trained AIGC model \nto the network edge server\nC\nAn illustration of human-aware utilities over different ASPs\nPrompt: ``The sun shines on the snowy mountains``\nPrompt: ``The supercar drives in the city``\nPrompt: ``The dog sleeps by the river``\nASP 1\nASP 2\nASP 3\nASP 4\nASP 5\nUtility\nUtility\nUtility\nUtility: Normalized(-BRISQUE)\n0.46\n0.61\n0.32\n1.0\n0.79\n0.68\n1.0\n0.81\n0.32\n1.0\n0.23\n0.25\n0.74\n0.53\n1.0\nA demo of diffusion-based AIGC service\nAn example of \ndeployed AIGC model \nin the edge server\nText prompt and \nrequired denoising steps \nrequested by the user\nDifferent AIGC \nmodels owned by \ndifferent ASPs\nDifferent human-aware \nutility achieved by \ndifferent AIGC models\nFig. 1. The architecture of AIGC-as-a-Service in wireless edge networks. Part A is demo of AIGC service based on Stable Diffusion v1.5 as an\nexample of deployable AIGC model for edge servers; Part B is network architecture of ASPs employing edge servers to deploy AIGC models for\nproviding AaaS to users; Part C shows variation in user experience demonstrated by different outputs from the same text prompt on various AIGC\nmodels, highlighting the importance of ASP selection.\nscheduling and resource allocation in wireless networks [28\u2013\n30].\nFor the ASP selection, which can be framed as a resource-\nconstrained task assignment problem, a set of sequential\ntasks J = {j1, j2, . . . , jJ}, a set of available ASPs I =\n{i1, i2, . . . , iI}, and the unique utility function ui(\u00b7) of the\nith ASP are given. The objective is to find an assignment\nof tasks to ASPs, i.e., A = {a1, . . . , aj, . . . , aJ}, such that\nthe overall users\u2019 utility U = PJ\nj=1 ui (Tj) is maximized.\nNote that the utility ui (Tj) of the jth task assigned to the\nith ASP is a function of the required resource Tj. Without\nloss of generality, we consider that Tj is the number of\ndenoising steps of the diffusion model, which is positively\ncorrelated to the energy cost. The reason is that each step of\nthe diffusion model has energy consumption as it involves\nrunning a neural network to remove Gaussian noise [31]. To\nempirically validate this relationship, we conducted experi-\nments using a Dell Precision 5820 Tower equipped with an\nIntel Xeon W-2235 CPU. Power metrics were meticulously\nrecorded via HWiNFO642 during the inference process of\nstable-diffusion-v1-4 model [32]. The results, illustrated in\nFig. 2, confirm a consistent increase in energy cost corre-\nsponding to the number of denoising steps, alongside an\ninitial energy expenditure likely due to model initialization.\nFurthermore, the utility function is human-aware, which\nis discussed in Section 3.3. The total availability of resources\nTi (i = 1, . . . , I) for each ASP is considered. Note that,\nfor illustrative purposes, we consider image-based AIGC\nthat utilizes the diffusion model. However, our research\napproach is generalizable to other types of AIGC services,\nincluding those based on natural language processing (e.g.,\nChatGPT). One can substitute the relevant resources to be\nscheduled (e.g., GPU resources) and corresponding user\nutility functions as appropriate. Mathematically, the ASP\nselection problem can be formulated as an integer pro-\n2. HWiNFO64 (https://www.hwinfo.com/) is a hardware analysis\nand monitoring tool for Windows, presenting real-time information\nincluding fan speeds, voltages, power consumption, etc.\n5\n10\n15\n20\n25\nDenoising Steps\n0\n0.5\n1\n1.5\n2\n2.5\n3\n3.5\nEnergy (Joules)\n104\nExperimental Data\nTrend Line\nEstimated Initial Energy Cost\nFig. 2. Energy cost versus diffusion steps for stable-diffusion-v1-4 model\ninference.\ngramming problem with decision variables aj (\u2200j \u2208J ) in\nA, which represents the time series of task assignments to\navailable ASPs. Additionally, \u02c6\nJi denotes the set of running\ntasks on the ith ASP at the time of assigning the current task.\nThus, the problem can be formulated as\nmax\nA\nU =\nX\nj\u2208J\nui (Tj),\n(1)\ns.t.\ni = aj,\n(2)\nTj +\nX\nj\u2032\u2208\u02c6\nJi\nTj\u2032 \u2a7dTi\n(\u2200i \u2208I) ,\n(3)\ni = 1, . . . I, and j = 1, . . . J.\n(4)\nIn this formulation, the resource constraints are incorpo-\nrated through the constraint (3), which specifies the limita-\ntions on the available resources. Note that failing to satisfy\nthe constraint (3) can result in the crash of ith ASP, causing\nthe termination and restart of its running tasks.\nRemark 1. The resource-constrained task assignment problem,\ni.e., (1), is a well-known NP-complete problem [33], which implies\n5\nthat finding an optimal solution in polynomial time is com-\nputationally infeasible. Moreover, the user can access the AaaS\nat their discretion, and the user utility is human-aware with-\nout mathematical expressions. Traditional mathematical methods\nare difficult to be applied. To address this challenge, different\ntechniques, including greedy algorithms, genetic algorithms, and\n(meta-)heuristics algorithms, have been proposed to find an ap-\nproximate solution. However, these techniques often assume that\nall tasks and their corresponding utility values are known in\nadvance [34], which is impractical in ASP selection, where tasks\narrive dynamically and in real time.\nIn this case, the AaaS system scheduler must make real-\ntime decisions while considering the current system state\nand the arrival of new tasks. Balancing the task assignments\nto available servers and reserving resources for future tasks\nis essential. Moreover, characteristics such as the utility\nvalue depend not only on the human-aware tasks but also\non the assigned ASP\u2019s ability, which is unknown at the time\nof scheduling, making the problem more challenging than\nthe online resource-constrained task assignment [35].\n3.3\nHuman-aware Utility Function\nThe utility value of a Metaverse user task is not known in\nadvance. Instead, it is determined by considering human-\naware content quality assessment techniques to the AIGC.\nLet us denote Fi(Tj) as the forward function of the AIGC\nmodel of the ith ASP and G(\u00b7) as the human-aware content\nquality assessment function. Then, the utility value ui(Tj)\nof the jth task on the ith ASP can be expressed as\nui(Tj) = G(Fi(Tj)), (i = 1, . . . I, and j = 1, . . . J) .\n(5)\nTaking the image-based AIGC service as an example, the\nAI model can generate images according to the text prompt\nuploaded by users or impair the distorted images. Without\nthe loss of generality, the human-aware content quality as-\nsessment function G(\u00b7) could be the Blind/Referenceless Im-\nage Spatial Quality Evaluator (BRISQUE), which is designed\nto be human-aware with aims to predict the image quality\nbased on how humans perceive image quality. BRISQUE\nis trained on a dataset of natural images perceived as high\nquality by human observers, which can extract features rele-\nvant to human perception of image quality, such as contrast,\nsharpness, and texture. Therefore, BRISQUE is considered a\nno-reference (or blind) image quality assessment model that\ndoes not require a reference image to compare against. This\nmakes BRISQUE more practical for real-world applications\nwhere a reference image may not be available or practical\nto use as the reference. By being human-aware, BRISQUE\nprovides a reliable and objective measure of image quality.\nAn illustration of the utility distribution among different\nASPs in our case is presented in Fig. 1 (Part C). We can\nobserve that there is a significant variance in human-aware\nutility values between ASPs, highlighting the importance of\nusers selecting a well-suited ASP.\n4\nAI-GENERATED OPTIMAL DECISION\nIn this section, we propose the AGOD algorithm that gener-\nates optimal discrete decisions starting from Gaussian noise\nwith the help of the diffusion model.\n4.1\nMotivation of AGOD\nThe discrete variables in the ASP selection problem present\na unique challenge: the solution set is finite and discrete,\nmaking traditional optimization techniques for continuous\nvariables ineffective [27]. In this scenario, unlike the grad-\nual progression toward optimality offered by continuous\nvariables, discrete variables necessitate jumping from one\ndistinct solution to another. This characteristic turns the\nproblem into a combinatorial one, where the solution space\ngrows exponentially with each added variable, rendering\nexhaustive searches impractical for large-scale problems [26,\n27]. Resorting to continuous optimization by ignoring the\ndiscrete nature of decision variables only yields inaccurate\nand suboptimal results. This necessitates the development\nof novel optimization techniques adept at handling discrete\nvariables and the complexity of combinatorial optimization,\noutperforming existing DRL algorithms in navigating this\nintricate and expansive solution space.\nThe Denoising Diffusion Probabilistic Model (DDPM),\na framework originally for image generation, inspires our\napproach to optimize discrete decision solutions [13]. It\ninvolves gradually adding noise to the data until the data\nis entirely Gaussian noise (the forward process). Then,\nthe model learns to reverse the diffusion process to re-\ncover the original image (the reverse process). Motivated\nby DDPM\u2019s exceptional generative capabilities, we aim to\ndevelop a diffusion-based optimizer for generating discrete\ndecision solutions. The diffusion model\u2019s inherent ability\nto incorporate conditioning information into the denoising\nprocess enhances its applicability and precision [13]. More\nimportantly, the potential interaction between the diffusion\nmodel and DRL represents a complementary and mutually\nenhancing relationship, allowing both methods to benefit,\nthereby broadening the effectiveness of discrete decision\noptimization in complex and dynamic environments.\nIn the decision-making problem, the decision scheme can\nbe expressed as a set of discrete probabilities for choosing\neach decision. The constraints and task-related factors af-\nfecting the optimal decision scheme can be considered the\nenvironment. According to the diffusion model, an optimal\ndecision solution under the current environment can keep\nincreasing the noise until it becomes Gaussian, known as\nthe forward process of probability noising [13]. Then, in the\nreverse process of probability inference, the optimal decision\ngeneration network, i.e., \u03c0\u03b8(\u00b7), can be viewed as a denoiser\nthat starts with Gaussian noise and recovers the optimal de-\ncision solution, i.e., x0, based on the environment condition,\ni.e., s. An illustration of the diffusion process is provided in\nFig. 3. In the following, we present the forward process and\npropose the AGOD algorithm as the reverse process.\n4.2\nThe Forward Process of Probability Noising\nAs the decision scheme output x0 = \u03c0\u03b8 (s) \u223cR|A| is\nthe probability distribution of each decision being selected\nunder the observed environment state s, we represent the\ndiscrete vector of the distribution at step t in the forward\nprocess as xt, which have the same dimensionality as x0.\nGiven a target probability distribution x0, the forward\nprocess adds a sequence of Gaussian noises at each step\nto obtain x1, x2, . . . , xT . The transition from xt\u22121 to xt is\n6\nE\nE\nEnvironment\nE\nE\nAI-Generated Optimal Decision\nE\nE\nE\nD\nD\nD\nD\nD\n\u2026\nOptimal Decision\nEnvironment\nE\nE\nE\nE\nE\nD\nD\nD\nD\nD\nDiffusion Process\nMaximize Utility\nOptimal Decision\nEnvironment: Arriving \nuser task, current \nresource status, etc.\nOptimal Decision: \nOptimal selection \ndecision corresponding\nto the environment\nE\nEnvironment\nOptimal Decision\nD\n\u2026\n\u2026\nConditions:\nMLP\nMLP\nMLP\nMLP\nForward Process\nReverse Process\nSoftmax\nAction\nProbability\nForward Process\nReverse Process\nConditions\n:\nSoftmax\nAction\nProbability\nDecision \nSpace\nMLP\nConditioned Inference\nNoise\nReparameterization\nA\nB\nGaussian \nNoise\nFig. 3. Illustration of the AGOD algorithm with the conditioned diffusion process.\ndefined as a normal distribution with mean \u221a1 \u2212\u03b2txt\u22121\nand variance \u03b2tI as [31]\nq (xt|xt\u22121) = N\n\u0010\nxt;\np\n1 \u2212\u03b2txt\u22121, \u03b2tI\n\u0011\n,\n(6)\nwhere t = 1, . . . , T, \u03b2t = 1 \u2212e\u2212\u03b2min\nT\n\u22122t\u22121\n2T 2 (\u03b2max\u2212\u03b2min)\nrepresents the forward process variance controlled by the\nVariational Posterior (VP) scheduler [31].\nAs xt depends only on xt\u22121 at the previous step, the\nforward process can be considered a Markov process, and\nthe distribution xT given x0 can be formed as the product\nof transitions q (xt|xt\u22121) over denoising step as [31]\nq (xT |x0) =\nT\nY\nt=1\nq (xt|xt\u22121).\n(7)\nThe forward process is not actually executed, but it\nestablishes the mathematical relationship between x0 and\nany xt as\nxt = \u221a\u00af\u03b1tx0 +\n\u221a\n1 \u2212\u00af\u03b1t\u03f5,\n(8)\nwhere \u03b1t = 1 \u2212\u03b2t, \u00af\u03b1t = Qt\nk=1 \u03b1k is the cumulative\nproduct of \u03b1k over previous denoising step k (\u2200k \u2264t), and\n\u03f5 \u223cN (0, I) is a standard normal noise. As t increases, xT\nbecomes purely noise with a normal distribution of N(0, I).\nHowever, note that optimization problems in wireless net-\nwork often lack a dataset of optimal decision solutions, i.e.,\nx0, to be used for the forward process. Consequently, the\nforward process is not performed in AGOD.\n4.3\nThe Reverse Process of Probability Inference\nThe reverse process, also called the sampling process, aims\nto infer the target x0 from a noise sample xT \u223cN(0, I)\nby removing noise from it. In our AGOD algorithm, the\npurpose is to infer the optimal decision scheme from the\nnoise sample. The transition from xt to xt\u22121 is defined as\np (xt\u22121|xt), which cannot be calculated directly. However,\nit follows a Gaussian distribution as given by\np\u03b8 (xt\u22121|xt) = N\n\u0010\nxt\u22121; \u00b5\u03b8 (xt, t, s) , \u02dc\u03b2tI\n\u0011\n,\n(9)\nwhere the mean \u00b5\u03b8 can be learned by a deep model, and\n\u02dc\u03b2t =\n1\u2212\u00af\u03b1t\u22121\n1\u2212\u00af\u03b1t \u03b2t is a deterministic variance amplitude that\ncan be easily calculated [31].\nBy applying the Bayesian formula, we transform the\ncalculation of the reverse process into the calculation of the\nforward process and reformat it into the form of a Gaussian\nprobability density function. Then, we obtain the mean as\nfollows,\n\u00b5\u03b8 (xt, t, s) =\n\u221a\u03b1t (1 \u2212\u00af\u03b1t\u22121)\n1 \u2212\u00af\u03b1t\nxt +\n\u221a\u00af\u03b1t\u22121\u03b2t\n1 \u2212\u00af\u03b1t\nx0,\n(10)\nwhere t = 1, . . . , T. According to (8), the reconstructed\nsample x0 can be directly obtained via\nx0 =\n1\n\u221a\u00af\u03b1t\nxt \u2212\ns\n1\n\u00af\u03b1t\n\u22121 \u00b7 tanh (\u03f5\u03b8(xt, t, s)) ,\n(11)\nwhere \u03f5\u03b8(xt, t, s) is a deep model parameterized by \u03b8 that\ngenerates denoising noises conditioned on the observation\ns. The generated noise is scaled to be small through the\napplication of the hyperbolic tangent activation, as it may\nresult in a high level of noise in x0, making it difficult to\nidentify the true underlying action probability.\nThe reverse process introduces a new source of noise \u03f5\u03b8\nat each denoising step t, and they are independent of the\nnoise \u03f5 added in the forward process. This makes us unable\nto calculate x0 by directly using (11). Instead, we apply (11)\ninto (10) to estimate the mean\n\u00b5\u03b8 (xt, t, s) =\n1\n\u221a\u03b1t\n\u0012\nxt \u2212\u03b2t tanh (\u03f5\u03b8(xt, t, s))\n\u221a1 \u2212\u00af\u03b1t\n\u0013\n.\n(12)\nThen, we can sample xt\u22121 from the reverse transition dis-\ntribution p(xt)p\u03b8 (xt\u22121|xt), and further use the cumulative\nproduct over t = T, T \u22121, . . . , 1 to obtain the generation\ndistribution p\u03b8 (x0) as follows,\np\u03b8 (x0) = p (xT )\nT\nY\nt=1\np\u03b8 (xt\u22121|xt),\n(13)\nwhere p (xT ) is a standard Gaussian distribution. Once we\n7\nhave the generation distribution p\u03b8 (x0), we can sample the\noutput x0 from it.\nIt is a common challenge in training generative models\nwith stochasticity that gradients cannot be back-propagated\nthrough the random variable in the operation of sampling\nfrom a distribution. To address this issue, we employ repa-\nrameterization, which decouples the randomness from the\ndistribution parameters. Specifically, the following update\nrule is used instead,\nxt\u22121 = \u00b5\u03b8 (xt, t, s) +\n\u0010\n\u02dc\u03b2t/2\n\u00112\n\u2299\u03f5,\n(14)\nwhere \u03f5 \u223cN (0, I). By iteratively applying the reverse\nupdate rule, i.e., (14), we can obtain all xt (\u2200t, 0 \u2264t < T),\nand in particular, the output sample x0, from a randomly\ngenerated normal noise.\nFinally, we apply the softmax function to x0 to convert\nit into a probability distribution as\n\u03c0\u03b8 (s) =\n(\nexi\n0\nPA\nk=1 exk\n0 , \u2200i \u2208A\n)\n.\n(15)\nThe elements in \u03c0\u03b8 (s) correspond to the probability of\nselecting each action.\nWhen implementing AGOD in practical systems, we first\ncompute the mean \u00b5\u03b8 of the reverse transition distribution\np\u03b8 (xt\u22121|xt), as defined in (9) and (12), and then obtain\nthe distribution xt\u22121 using the update rule in (14). Next,\nwe can derive the probability distribution of the optimal\ndecision x0 using (15). However, in DDPM, the optimization\nobjective is the Mean Squared Error (MSE) loss, which re-\nquires labeled images as targets [31]. This requirement poses\nsignificant challenges in real decision-making problems in\nwireless networks. Therefore, AGOD needs to learn in an\nexploratory manner, and the training goal of the denoising\nnetwork shifts from minimizing the error with labeled data\nto maximizing the value of the decision scheme, i.e., being\nable to maximize the optimization objective. One possible\napproach proposed by authors in [25] is to construct a deci-\nsion value network whose output assesses the utility resulting\nfrom the decision scheme, i.e., the output of the optimal\ndecision generation network. Then, the two networks can be\ntrained jointly. However, the approach in [25] is for the case\nwhen the decision valuables are continuous valuables.\nLeveraging AGOD\u2019s adaptability, we aim to enhance the\noptimization potential by integrating AGOD into advanced\nDRL algorithms, specifically within the SAC framework.\nThe SAC\u2019s efficiency and stable policy learning complement\nAGOD\u2019s generative strengths. This integration enriches the\nSAC model with AGOD\u2019s exploration and learning capabil-\nities, leading to the development of D2SAC as a diffusion-\nbased DRL algorithm.\n5\nDIFFUSION-BASED REINFORCEMENT LEARNING\nIn this section, we model the ASP selection problem and\npresent our innovative deep diffusion reinforcement learn-\ning algorithm, D2SAC, by applying the AGOD in the action\npolicy.\n5.1\nProblem Modeling\nRecall that we have a series of tasks, J , and a set of available\nASPs, I. The objective is to assign tasks to ASPs in a way\nthat maximizes the overall utility, denoted as U, where the\nutility of each task assigned to an ASP is a function of\nthe required resource Tj. We consider resource limitations\nof each ASP, acknowledging that an ASP can only handle\na finite number of tasks due to its resource constraints.\nExceeding these resources risks ASP failure and the poten-\ntial restart of tasks. This reality makes the Markov Decision\nProcess (MDP) framework particularly suitable for the ASP\nselection problem [36]. MDP captures the sequential nature\nof decision-making and how each task assignment influ-\nences future rewards and actions. The unpredictable nature\nof task arrivals further justifies an MDP-based approach.\nThis method enables real-time decision-making, considering\nthe current system state and the need to allocate resources\nfor future tasks, ensuring a balanced and sustainable task\ndistribution among ASPs.\nGiven an initial state s0, the agent transitions from one\nstate sl \u2208S to the next sl+1 \u2208S at each step l = 0, 1, . . . , L,\nby taking an action al \u2208A and receiving a reward rl \u2208R\nin the environment. Here, the action decision is chosen\naccording to the policy. We use the diffusion model in\nAGOD, i.e., \u03c0\u03b8, as the action policy. The aim is to maximize\nthe accumulated reward, R(s0, \u03c0\u03b8), defined as the expected\nsum of discounted rewards as\nR (s0, \u03c0\u03b8) = E\n\" L\nX\nl=0\n\u03b3lrl|s0, \u03c0\u03b8\n#\n,\n(16)\nwhere \u03b8 are the parameters of the diffusion policy network,\n\u03b3 \u2208[0, 1] is the discount factor that determines the impor-\ntance of future rewards relative to immediate rewards, L\nis the number of transitions in an episode, and P is the\ntransition probability of states. In this manner, the MDP\nmodel for our problem can be formally described as a tuple\n(S, A, P, R).\na) State Space. The state space S in our problem contains\nthe environment information to make the decision. The state\nof the agent s \u2208S is composed of two feature vectors, one\nrepresenting the arriving user task, sT, and one representing\nthe current resource status of all ASPs, sA. The feature vector\nsT encodes the resources T, i.e., denoising step, required\nby the task and its estimated completion time o, which is\nrepresented as sT = [T, o]. The feature vector sA includes\nthe total available resources Ti and the currently available\nresources \u02dcTi of each of the I ASPs, which is defined as\nsA = [Ti, \u02dcTi|\u2200i \u2208I]. Finally, these two feature vectors are\nconcatenated to form the state vector s as s = [sT, sA].\nThe values of T, o, Ti, and \u02dcTi are normalized to the range\n(0, 1) before being fed into the AGOD network, i.e., policy\nnetwork \u03c0\u03b8(s), to ensure stable training.\nb) Action Space. The action space A is defined as the\nset of all possible decisions that can be made by the agent.\nIn the ASP selection problem, the action taken by the agent,\na \u2208A, represents the assignment of the current Metaverse\nuser task to one of the I available ASPs. Specifically, the\naction space is an integer space with values ranging from 1\nto I. The action a is determined by the AGOD network,\ni.e., \u03c0\u03b8(s), which generates a vector of I elements with\n8\nthe current state s as the input. Each element of the vector\nrepresents the probability of selecting a particular ASP, i.e.,\na \u223c\u03c0\u03b8(s). Note that, during evaluation, the ASP with the\nhighest probability is selected, i.e.,\na = arg max\ni\n\b\u03c0i\n\u03b8(s), \u2200i \u2208I\n\t ,\n(17)\nwhere \u03c0i\n\u03b8(s) represents the probability of selecting ASP i.\nc) Reward Function. The reward r \u2208R is a scalar\nrepresenting the immediate benefit received upon executing\naction a in state s. The reward function r (s, a) comprises\ntwo parts: the AIGC quality reward rR and the crash penalty\nrP. Specifically, rR reflects the generated content\u2019s quality,\ndetermined using the content quality assessment methods\ndetailed in (5). To discourage low-quality content, the utility\nvalue ui (Tj) is adjusted by a baseline score \u02c6rR from a noise\nsample, resulting in rR = ui (Tj)\u2212\u02c6rR. The crash penalty rP,\nimposed on actions that overload the ASP causing task in-\nterruptions, consists of a fixed penalty \u02c6rP\nF and an additional\npenalty \u02c6rP\nI proportional to the progress of ongoing tasks \u02c6\nJ\nas\nrP = \u02c6rP\nF \u2212\nX\nj\u2032\u2208\u02c6\nJ\n\u02c6rP\nI (j\u2032).\n(18)\nWe set \u02c6rP\nF = 2 by default and \u02c6rP\nI (j\u2032) as the multiply of\n\u02c6rP\nF and the remaining progress of task j\u2032 when it was\ninterrupted. Incorporating the fixed penalty value \u02c6rP\nF dis-\ncourages the agent from taking actions that may cause a\ncrash. The additional penalty \u02c6rP\nI (j\u2032) is associated with the\ninterrupted task j\u2032, serving as incentive for the agent to\nrefrain from disrupting ongoing tasks. Together, these penal-\nties help to promote system stability. Finally, the reward r\nreturned by the environment can be represented as the sum\nof the reward and penalty as r = rR \u2212rP. In Section 6,\nwe differentiate between \u2018training reward,\u2019 which affects the\nlearning process and policy optimization during training,\nand \u2018test reward,\u2019 which evaluates the learned policy\u2019s gen-\neralization and robustness in new environments.\nd) Transition Function. The transition function, repre-\nsented by p(s\u2032|s, a) \u2208P, defines the probability of tran-\nsitioning from the current state s to the next state s\u2032 af-\nter taking action a. The state transition model is intricate\nand cannot be mathematically formulated in our scenario.\nInstead, it relies on the unpredictable variables inherent\nin practical wireless network environments. The arrival of\nnovel and unfamiliar tasks, the allocation of tasks to ASPs,\nand the successful or failed execution of tasks all influence\nstate transitions.\ne) Initialization and Termination. Every observation\noriginates from the initial state s0, and the agent begins\nacting based on it. s0 is set as (T0, o0, T1, 1, T2, 1, . . . , TI, 1),\nwith T0 representing the required resources and o0 denoting\nthe estimated completion time of the first task. The repeated\n(Ti, 1) of I ASPs indicates that no ongoing tasks exist. The\nenvironment progresses from one state to another based on\nthe actions taken by the agent until a termination criterion is\nmet. To facilitate the policy network training, we introduce\na termination condition by specifying a maximum number\nof transitions L for each episode.\nBased on the above definitions, we present the overall\ngoal of our problem, which is to train the parameters \u03b8\u2217of\nGDM-based Network\nPT\nPt\nP0\n\u2026\n\u2026\nReverse Diffusion Chain \nExecute Action\nGaussian Noise\nOptimal Action\nActor\n0        10        20\n   0.5    1.0\nv\nProbability\nAction\nv\nSampling\nAaaS \nEnvironment\nObservation sl\nExperience Replay Memory\nObservation sl+1\nReward rl\nTrajectory Collection\n( sl, al, sl+1, rl )\nData Batch\nCritic 1\nCritic 2\nDouble Critic\nTarget Critic\nCritic 1\nCritic 2\nGDM-based \nNetwork\nQeval\nQtarget\nTarget Actor\nGDM-based \nNetwork\nActor\nSoft Update\nOptimizer\nCritic Loss\nUpdate\nFig. 4. The overall architecture of the D2SAC algorithm.\nthe AGOD network that maximizes the expected cumulative\nreward defined in (16) as\n\u03b8\u2217= arg max\n\u03b8\nE\n\" L\nX\nl=0\n\u03b3l (rl + \u03b1H(\u03c0\u03b8(sl)))\n#\n,\n(19)\nwhere the expectation is taken over all initial states s0, and\nH(\u03c0\u03b8(sl)) is called the action entropy regularization [20],\nwith \u03b1 known as the temperature. The H(\u03c0\u03b8(sl)) encour-\nages the agent to explore more diverse actions. To take\nadvantage of the efficient parallel computing capabilities\nof GPUs, we reverse the goal (19) by transforming the\nmaximization problem into a minimization problem as\n\u03b8\u2217= arg min\n\u03b8\n\u2212E\n\" L\nX\nl=0\n\u03b3l (rl + \u03b1H(\u03c0\u03b8(sl)))\n#\n.\n(20)\nIn solving the goal (20), the agent strives to balance the\ntrade-off between achieving high utility of task assignment\nand avoiding crashes to ASPs. Thus, the agent continuously\nupdates the AGOD network parameters \u03b8 based on the\nexperience it gains during training.\n5.2\nAlgorithm Architecture\nThe algorithm architecture of D2SAC, as shown in Fig. 4,\nconsists of several components that work together to op-\ntimize the policy, i.e., an actor-network, a double critic\nnetwork, a target actor, a target critic, an experience replay\nmemory, and the environment.\nTrajectory Collection. In this process, the agent starts\nby observing the environment and obtaining the initial\nobservation s0. The agent then collects C transitions by\niteratively generating and executing action decisions in the\nenvironment. These transitions are regarded as experiences\nand added to the experience replay memory D, which has a\ncapacity of D = |D|. More specifically, at each environment\nstep l, the actor takes in the observation sl and outputs\na discrete probability distribution \u03c0\u03b8(sl) over all possible\nactions A. The agent then samples an action al \u223c\u03c0\u03b8(sl)\nfrom this distribution and feeds it into the environment.\nThe environment takes action, transits to state sl+1, and\nreturns an immediate reward rl as feedback to the agent.\nThe agent records this experience with the transition tuple\n9\n(sl, al, sl+1, rl) into the experience replay memory. These\nsteps are repeated C times before the policy improvement\nstep.\nDiffusion Model-based AGOD as the Policy. In D2SAC, the\ncore of the actor-network \u03c0\u03b8(sl) is the diffusion model-\nbased AGOD, rather than a conventional Multi-Layer Per-\nception (MLP). AGOD enables effective representation en-\ncoding of the observation sl, by utilizing sl as the input\ncondition. This way, the diffusion process can effectively\ncapture the dependencies between the observation and the\naction space.\nExperience Replay Memory. Experience replay memory is\na key component of D2SAC, as it allows the algorithm to\nhandle the delay in receiving reward feedback. This is in\ncontrast to traditional scheduling algorithms that require\nimmediate utility feedback. Experience replay memory al-\nlows D2SAC to store experiences (sl, al, sl+1) and fill in\nmissing reward rl at a later time before updating the AGOD\nnetwork. Off-policy training is used to further improve the\nalgorithm\u2019s ability to handle delayed feedback. Noted that,\nwhile the introduction of experience replay does bring a de-\nlay into the learning process, it does not impact the real-time\nperformance in the decision process because the system\u2019s\npolicy can be updated and used in real time, while learning\ntakes place concurrently in an asynchronous manner.\nDouble Critic Network. During the policy improvement\nprocess, AGOD \u03c0\u03b8 is optimized by sampling mini-batches\nof transitions from experience replay memory D. A double\ncritic network is used as the Q function to reduce overesti-\nmation bias. Each critic network has its own set of parame-\nters, denoted as \u03d51 and \u03d52, respectively. Both networks are\nupdated independently using the same optimization target.\nDuring training, the Q-value estimate used to update the\nactor-network is the minimum of the two Q-value estimates\nfrom the two critic networks. This approach ensures that\nthe actor-network is updated based on a conservative esti-\nmate of the Q-value function, promoting stable and efficient\ntraining. In contrast to the Q function Q\u03d5(sl, al) defined in\nthe policy gradient theorem [37], D2SAC employs a more\nefficient Q function, denoted Q\u03d5(sl), where \u03d5 = {\u03d51, \u03d52}.\nInstead of only outputting the Q-value for a specific ac-\ntion, this Q function outputs a Q-value vector q \u2208R|A|\ncontaining the Q-values of all possible actions al \u2208A, i.e.,\nq = Q\u03d5 (sl) = min\n\bQ\u03d51 (sl) , Q\u03d52 (sl)\n\t\n.\nPolicy Improvement. The Q-values q estimate the expected\ncumulative reward for each action at the current state sl.\nThen, the actor can learn to maximize the expectation of q\nover all actions to improve the policy, which is expressed as:\nmax\n\u03b8\n\u03c0\u03b8 (sl)T Q\u03d5 (sl) .\n(21)\nMaximizing (21) encourages the current policy \u03c0\u03b8 to update\nin the direction where the actions with higher Q-values\ncan increase their probabilities of being selected, while\nthe others are suppressed. This maximization problem is\nsolved using the gradient ascent algorithm, which can be\ntransformed into a minimization problem expressed as\nmin\n\u03b8\n\u2212\u03c0\u03b8 (sl)T Q\u03d5 (sl) .\n(22)\nThe standard gradient descent algorithm, such as Adam,\ncan be used to solve this problem. Specifically, the gradient\nof (22) with respect to the policy parameters \u03b8 can be\ncomputed as the expectation over a mini-batch of transitions\nof size b sampled from the experience replay memory D at\nthe e-th training step, denoted by Be. Therefore, the gradient\nis given by\nEsl\u223cBe\nh\n\u2212\u2207\u03b8e\u03c0\u03b8e (sl)T Q\u03d5e (sl)\ni\n,\n(23)\nwhere \u03b8e and \u03d5e are the policy and Q-function parameters\nat the e-th training step, respectively. The actor is then\nupdated by performing gradient descent with respect to the\nabove gradient, as follows,\n\u03b8e+1 \u2190\u03b8e \u2212\u03b7a \u00b7\n\u0010\nEsl\u223cBe\nh\n\u2212\u2207\u03b8e\u03c0\u03b8e (sl)T Q\u03d5e (sl)\ni\u0011\n, (24)\nwhere \u03b7a is the learning rate of the actor. By iteratively per-\nforming (24), D2SAC learns an optimal policy parameters\nthat maximizes the sub-goal (21).\nAction Entropy Regularization. To prevent the policy from\nbecoming overly confident in certain actions and converging\nprematurely to a suboptimal solution, D2SAC introduces an\naction entropy regularization term on the vanilla target (21)\nto encourage exploration,\nmax\n\u03b8\n\u03c0\u03b8 (sl)T Q\u03d5 (sl) + \u03b1H (\u03c0\u03b8 (sl))\n(25)\ns.t. H (\u03c0\u03b8 (sl)) = \u2212\u03c0\u03b8 (sl)T log \u03c0\u03b8 (sl)\n(26)\nwhere H (\u03c0\u03b8 (sl)) is the entropy of the action probabil-\nity distribution \u03c0\u03b8 (sl), and the temperature coefficient \u03b1\ncontrols the strength of the entropy term. Following the\nderivation process similar to (21)-(24), the update rule in\n(24) should add the gradient term of the entropy term\n\u2207\u03b8eH (\u03c0\u03b8e (sl)), as follow,\n\u03b8e+1 \u2190\u03b8e \u2212\u03b7a \u00b7 Esl\u223cBe\n\u0014\n\u2212\u03b1\u2207\u03b8eH (\u03c0\u03b8e (sl))\n\u2212\u2207\u03b8e\u03c0\u03b8e (sl)T Q\u03d5e (sl)\n\u0015\n. (27)\nQ-function Improvement. Ensuring accurate estimates of\nthe Q-function Q\u03d5e (sl) is crucial to the success of finding\nthe optimal policy \u03c0\u2217\n\u03b8. Thus, Q\u03d5e (sl) must be trained effec-\ntively. To update the Q-function, we minimize the Temporal\nDifference (TD) error between the Q-target \u02c6ye and the Q-eval\nyi\ne,\nmin\n\u03d51,\u03d52\nE(sl,al,sl+1,rl)\u223cBe[\nX\ni=1,2\n\u0000\u02c6ye \u2212yi\ne\n\u00012],\n(28)\ns.t.\nyi\ne = Q\u03d5i\ne (sl, al) ,\n(29)\n\u02c6ye = rl + \u03b3 (1 \u2212dl+1) \u02c6\u03c0\u02c6\u03b8e (sl+1)T \u02c6Q \u02c6\n\u03d5e (sl+1) . (30)\nHere, Q\u03d5ie (sl, al) denotes the Q-value corresponding to\naction al output by Q\u03d5ie (sl), \u03b3 represents the discount factor\nfor future rewards, and dl+1 is a 0-1 variable that represents\nthe terminated flag. By updating the Q-function with the\nloss in (28), we can improve the estimation accuracy of the\nQ-value.\nTarget Networks. In (30), \u02c6\u03b8e and \u02c6\u03d5e represent the parame-\nters of the target actor \u02c6\u03c0 and the target critic \u02c6Q, respectively.\nThe target networks (\u02c6\u03c0, \u02c6Q) have the same network structure\nas the online networks (\u03c0, Q), but their parameters (\u02c6\u03b8e, \u02c6\u03d5e)\nare frozen during gradient descent and are updated slowly\n10\nthrough a soft update mechanism, which is defined as\n\u02c6\u03b8e+1 \u2190\u03c4\u03b8e + (1 \u2212\u03c4)\u02c6\u03b8e,\n\u02c6\u03d5e+1 \u2190\u03c4\u03d5e + (1 \u2212\u03c4) \u02c6\u03d5e,\n(31)\nThe hyperparameter \u03c4 \u2208(0, 1] determines the update rate\nof the target network. A smaller value of \u03c4 leads to slower\nupdates, while a larger value results in more rapid updates.\nBy controlling \u03c4, the stability of the target network can\nbe maintained. Finally, the D2SAC algorithm iteratively\nperforms E steps of policy and Q-function improvement\nuntil convergence is achieved. This results in near-optimal\npolicy parameters \u03b8\u2217that maximize the cumulative reward\nin (16), which, in turn, maximizes the ultimate utility target\nin (1).\n5.3\nOptimization Goal\nLike most DRL tasks in communication and networking,\nthe scheduling task is both online and discrete, making\nlabeled actions unavailable for calculating the MSE loss.\nMoreover, the goal of D2SAC is to maximize the Q-value,\nnot to reconstruct an action probability distribution that\ndoes not exist. While the authors in [24] introduced a\nsimilar loss, called behavior cloning loss, for offline DRL\ntasks using imitation learning, it is impractical to obtain\nopen datasets for online communication scheduling tasks.\nAdditionally, approaches designed for general continuous\ncontrol tasks [24, 38] cannot be applied in environments\nwith discrete action spaces. In summary, the optimization\ngoal of D2SAC only needs to consider the policy loss and\nthe action entropy loss, as defined in (25). Thus, we present\nthe overview of our D2SAC algorithm is then presented in\nAlgorithm 1. In the experiment part, we show that doing\nthis way achieves excellent performance in various online\nand discrete-action tasks.\n5.4\nComplexity Analysis\nThe\ncomputational\ncomplexity\nof\nD2SAC\nis\nO (E [CV + TC|\u03b8| + (b + 1) (|\u03b8| + |\u03d5|)]). This complexity\ncan be divided into two parts:\n\u2022\nTrajectory Collection: O(EC (V + T|\u03b8|)). Through-\nout the E training steps, C trajectories are collected\nat each training step, resulting in a cumulative over-\nhead of O(ECV ) for the environment interaction.\nFurthermore, for each trajectory sampling, an addi-\ntional overhead of O(T|\u03b8|) is incurred due to the re-\nverse diffusion process, which involves T denoising\nstep of neural network inference.\n\u2022\nParameter Updates: O(E (b + 1) (|\u03b8| + |\u03d5|)). This\nterm is composed of three parts, i.e., O(bE|\u03b8|) for\npolicy improvement, O(bE|\u03d5|) for Q-function im-\nprovement, and O (E (|\u03b8| + |\u03d5|)) for target network\nupdates. Here, b represents the batch size, and |\u03b8|\nand |\u03d5| are the number of parameters in the policy\nand Q-function networks, respectively.\nThe\nspace\ncomplexity\nof\nD2SAC\nis\nO (2 (|\u03b8| + |\u03d5|) + D (2|S| + |A| + 1)). This includes storage\nfor the policy and Q-function networks, as well as their\ntarget networks, which is O (2 (|\u03b8| + |\u03d5|)). Additionally, we\nAlgorithm 1 D2SAC: Deep Diffusion Soft Actor Critic\n1: Initialize policy parameters \u03b8, Q-function parameters \u03d5,\ntarget network parameters \u02c6\u03b8 \u2190\u03b8, \u02c6\u03d5 \u2190\u03d5, and replay buffer\nD;\n2: for the training step e = 1 to E do\n3:\nfor the number of collected transitions c = 1 to C do\n4:\nObserve state s and initialize a random normal dis-\ntribution xT \u223cN(0, I);\n5:\nfor the denoising step t = T to 1 do\n6:\nInfer\nand\nscale\na\ndenoising\ndistribution\ntanh (\u03f5\u03b8(xt, t, sl)) using a deep neural network;\n7:\nCalculate the mean \u00b5\u03b8 of the reverse transition\ndistribution p\u03b8 (xt\u22121|xt), as defined in (9) and (12);\n8:\nCalculate the distribution xt\u22121 using the repa-\nrameterization trick by (14);\n9:\nCalculate the probability distribution of x0 using (15)\nand select action a at random based on it.\n10:\nExecute action a in the environment, and observe the\nnext state s\u2032 and reward r;\n11:\nStore the transition (s, a, s\u2032, r) in the replay buffer D;\n12:\nSample a batch of transitions B = {(s, a, s\u2032, r)} from the\nreplay buffer D;\n13:\nUpdate the policy parameters \u03b8 using B by (27);\n14:\nUpdate the Q-function parameters \u03d5 using B by one\nstep of gradient descent to minimize (28);\n15:\nUpdate the target networks \u02c6\u03b8, \u02c6\u03d5 using (31);\n16: return a AGOD-based policy \u03c0\u2217with well-trained parame-\nters \u03b8\u2217;\nneed to store the trajectory experiences, which consist of D\ntransitions, each containing two state tuples of dimension\n|S|, an action tuple of dimension |A|, and a reward scalar.\nIn summary, D2SAC has the same space complexity\nas SAC, but its computational complexity increases by\nO (EC|\u03b8| (T \u22121)) due to the additional T denoising step\nin the reverse diffusion process. However, the increase\nin\ncomputational\ncomplexity\nhelps\nto\nachieve\nhigher\nperformance and faster convergence, as demonstrated in\nTable 3.\n6\nEXPERIMENTS AND INSIGHTS\nIn this section, we comprehensively evaluate the AGOD-\nbased D2SAC algorithm and demonstrate its superior per-\nformance compared with existing methods. Our analyses\nalso provide valuable insights into the use of diffusion-\nbased DRL in discrete action spaces.\n6.1\nExperimental Setup\nExperimental Platform. Our experiments were conducted\nwith an NVIDIA GeForce RTX 3090 GPU with 24 GB of\nmemory and an AMD Ryzen 9 5950X 16-Core processor\nwith 128 GB of RAM. The workstation was running Ubuntu\n16.04 LTS operating system and utilized PyTorch 1.13 along\nwith the CUDA toolkit 11.6 and cuDNN 8.0. We packaged\nour software environment and dependencies into a Docker\nimage to ensure reproducibility.\nEnvironment Details. We train an agent to assign Meta-\nverse users\u2019 AIGC tasks to wireless ASPs in a simulation en-\nvironment with 20 ASPs. Each ASP had a random resource\ncapacity T , which represented the total available denoising\nstep for the diffusion process and ranged from 400 to 1000.\n11\nWe use RePaint3 [39] as the AIGC model and PyTorch Image\nQuality (PIQ)4 [40] as the human-aware content quality\nassessment function. Note that the quality of AIGC services\nthat different ASPs provide can vary, as depicted in Fig. 1\n(Part C). A linear function parameterized by Ax, Ay, Bx,\nand By was determined based on tests using the real image\ndataset CelebA-HQ [41] to model the quality of images\ngenerated by an AIGC model [6]. To simulate the varying\ncapabilities of different ASPs, we set Ax \u2208[0, 100], Ay \u2208\n[0, 0.5], Bx \u2208[150, 250], and By \u2208[0.5, 1]. Our simulations\ninvolved 1000 Metaverse users submitting multiple AIGC\ntask requests to the ASPs at different times. Given the\nunpredictable nature of user behavior, each request was\nassumed to require a random amount of resources T (i.e.,\nthe number of denoising steps) ranging from 100 to 250.\nThe arrival of user tasks was modeled as a Poisson process5,\ni.e., P(k; \u03bb) = \u03bbke\u2212\u03bb\nk!\n, where \u03bb = 0.001 is the average arrival\nrate, and J = 1000 is the number of tasks that arrive in the\ntime interval of 1 \u00d7 106 seconds. To manage the ASPs and\nuser task requests, we implemented a swarm manager that\nallocated task requests to ASPs based on the action decided\nby D2SAC. We monitored the operation status to measure\nthe performance.\nModel Design. D2SAC employs the diffusion model-\nbased AGOD as the core of the actor network and uses two\ncritic networks with the same structure to mitigate the prob-\nlem of overestimation. Table 1 shows the detailed configu-\nrations of the actor and critic networks. The actor-network\nin D2SAC not only predicts the denoised distribution from\na random normal distribution and the current state but also\nincludes denoising step encodings, i.e., Sinusoidal position\nembeddings [44], to capture temporal information about the\ndiffusion process. This helps the actor-network better under-\nstand the relationships between each step in the diffusion\nchain. The backbone of the actor-network consists of three\nfully-connected layers that use the Mish activation function,\nexcept for the final layer, which employs the Tanh activation\nto normalize its outputs. The critic networks share a similar\nstructure with the actor-network, consisting of three fully-\nconnected layers with Mish activations. However, the final\nlayer of the critic networks produces Q values for actions\nwithout any activation function. The actor and critic net-\nworks are trained by using the Adam optimizer [45], with\na learning rate of \u03b7a = 0.0001 for the actor-network and\n\u03b7c = 0.001 for the critic networks. A weight decay rate\nof \u03bb = 0.0001 was employed to regularize model weights\nand promote learning more policies. The target networks\nmirrored the structures of the online networks to reduce\nvariance during the learning process. By default, we set the\nupdate rate \u03c4 = 0.005 for soft updating the target networks,\nas defined in (31). The detailed settings for other training\nhyperparameters in our experiments are summarized in\nTable 2.\nBenchmarks. In our experiments, we compare the\n3. Github: https://github.com/andreas128/RePaint\n4. Github: https://github.com/photosynthesis-team/piq\n5. The use of a Poisson process in modeling the arrival of user\ntasks in our experiments is motivated by its wide acceptance and\nprevalence [42, 43]. Fortunately, leveraging the inherent adaptability of\nreinforcement learning, our proposed method offers flexibility, capably\nmanaging task arrivals that follow various distributions.\nTABLE 1\nThe structure of actor and critic networks\nNetworks\nLayer\nActivation\nUnits\nActor\nSinusoidalPosEmb\n-\n16\nFullyConnect\nMish\n32\nFullyConnect\n-\n16\nConcatenation\n-\n-\nFullyConnect\nMish\n256\nFullyConnect\nMish\n256\nFullyConnect\nTanh\n20\nCritic\nFullyConnect\nMish\n256\nFullyConnect\nMish\n256\nFullyConnect\n-\n20\nTABLE 2\nSummary of Training Hyperparameters\nSymbol\nDescription\nValue\n\u03b7a\nLearning rate of the actor network\n1 \u00d7 10\u22124\n\u03b7c\nLearning rate of the critic networks\n1 \u00d7 10\u22123\n\u03b1\nTemperature of action entropy regularization\n0.05\n\u03c4\nWeight of soft update\n0.005\nb\nBatch size\n512\n\u03bb\nWeight decay\n1 \u00d7 10\u22124\n\u03b3\nDiscount factor to accumulate rewards\n0.95\nT\nDenoising steps for the diffusion model\n5\nD\nMaximum capacity of the replay buffer\n1 \u00d7 106\nE\nTotal number of training steps\n1000\nC\nNumber of transitions per training step\n1000\nD2SAC with seven well-known DRL benchmarks, including\nDQN [14], DRQN [15], Prioritized-DQN [16], Rainbow [17],\nREINFORCE [18], PPO [19], and SAC [20]. Specifically,\nDQN, DRQN, Prioritized-DQN, and Rainbow are value-\nbased methods suited for optimization problems with dis-\ncrete action spaces. The other algorithms are policy-based\nand were evaluated in the discrete action space to ensure fair\ncomparisons. Despite similarities to SAC, D2SAC replaces\nthe actor-network with diffusion model-based AGOD. In\nthe following experiments, we demonstrate the superiority\nof D2SAC over these benchmarks and present interesting\ninsights. In addition to these advanced DRL benchmarks,\nwe implement four heuristic policies:\n\u2022\nRandom Policy. The random policy assigns incom-\ning tasks to ASPs randomly without considering\navailable resources, task processing time, or other\nconstraints. This policy serves as the lower-bound\nbaseline for scheduling performance.\n\u2022\nRound Robin Policy. The Round Robin policy as-\nsigns tasks to ASPs in cyclical order. This policy can\nproduce favorable schedules when tasks are well-\nbalanced. However, it may not perform optimally\nwithout significant differences among tasks [46].\n\u2022\nCrash Avoid Policy. The Crash Avoid policy assigns\ntasks to ASPs based on their available resources.\nASPs with more resources are given priority in task\nassignments to prevent overloading.\n\u2022\nProphet Policy. We assume that the scheduler knows\nin advance every utility that the ASP will bring\nto every user before assigning tasks. In this case,\nthe prophet policy provides an upper bound on the\n12\nTABLE 3\nPerformance Comparisons of D2SAC and Benchmarks (Totally 1000 Steps).\nPolicy\nTrain Reward\nTest Reward\nToal Time / h\nTime to Baseline / h\nStep to Baseline\nHeuristic\nRandom\n-21\n-35\n0.74\n\u221e\n\u221e\nRound Robin\n273\n280\n0.76\n\u221e\n\u221e\nCrash Avoid\n389\n400\n0.77\n0.0\n0\nProphet\n604\n596\n\u221e\n\u221e\n\u221e\nDRL\nDQN\n418\n503\n1.9\n0.9\n470\nPrioritized-DQN\n386\n460\n1.8\n1.0\n470\nDRQN\n384\n430\n2.9\n2.0\n700\nREINFORCE\n395\n463\n1.1\n0.9\n850\nPPO\n353\n481\n1.1\n1.1\n950\nRainbow\n414\n450\n2.6\n2.2\n{130,850}\nSAC\n418\n436\n2.9\n1.2\n430\nOurs\nD2SAC\n528\n537\n7.0\n1.3\n190\nperformance of human-centric services, by assigning\ntasks to ASPs with the highest utility while avoid-\ning crashes. However, this policy uses the unknown\nutility function as prior information before tasks are\nassigned, which is not feasible in the real world.\n6.2\nNumerical Results\nLeading Performance. For the ASP selection problem, we\nsummarize the best performance achieved by the proposed\nD2SAC and 11 benchmark policies in Table 3, in terms of\ncumulative reward, training time, and convergence speed.\nEach experiment was run for E = 1000 training steps and\nin a total of 1 \u00d7 106 environment steps. To assess the time\nefficiency and convergence speed, we used the Crash Avoid\npolicy as the baseline. We recorded the time and steps taken\nby each policy to reach the baseline reward. The time to\nbaseline and step to baseline refer to the time and the number\nof training steps when the test reward reaches that of the\nCrash Avoid policy, respectively.\nThe DRL-based policies outperformed the Crash Avoid\npolicy, as shown in Table 3. However, there is still a sig-\nnificant variation in performance among different policies.\nREINFORCE and PPO, have relatively short training times\nbut produce subpar results, while DQN and our proposed\nD2SAC require longer training times but achieve better\nperformance. Notably, D2SAC stands out in the comparison,\ndelivering the highest training and test rewards, achiev-\ning the baseline reward after only 190 training steps, and\na relatively fast training time of 1.3 hours. The superior\nperformance of D2SAC can be attributed to its use of the\ndiffusion model-based AGOD, which enhances its capability\nto capture complex patterns and relationships in the obser-\nvations. The performance of D2SAC in comparison with the\nother policies is further evaluated in Fig. 5. Furthermore,\nFig. 6 shows the test rewards of different policies under\nvarious task arrival rates, which verifies the robustness of\nthe proposed D2SAC. More importantly, we compare the\nD2SAC with other DRL algorithms through various stan-\ndard control tasks in the Gym environment, as presented in\nTable 4. These results demonstrate the superior characteris-\ntics of D2SAC in terms of high-performance, time-efficient, and\nfast-converging, positioning it as the top choice for discrete\naction scenarios such as the ASP selection in wireless edge\nnetworks.\nUnderstand the Learning Process. To gain insights into\nthe learning process of D2SAC, we compared it against\nconventional heuristic policies in subfigure (c) of Fig. 5.\nThese heuristic policies rely on simple or random rules\nto make action decisions. While these policies are easy\nto interpret, they are suboptimal. D2SAC and other DRL-\nbased policies can adapt to changing environments and\nmaximize performance over time. D2SAC interacts with the\nenvironment during the learning process by taking action\nand learning from feedback rewards. This information is\nthen used to improve its decision-making process, i.e., the\nAGOD network, leading to continuous performance en-\nhancement. D2SAC begins with a random policy, progres-\nsively learning the optimal one through trial and error in\nthe environment. It outperformed the Round Robin policy\nafter about 45 training steps and exceeded the Crash Avoid\nbaseline by 80 steps, showing superior load-balancing and\ncrash-prevention abilities. Initially, D2SAC prioritized task\ncompletion over utility optimization. Over time, its policy\nrefined and approached the theoretical upper limit, akin\nto the prophet policy. This progression demonstrates that\nD2SAC can maintain its Crash Avoiding capability while\nmaximizing user utility.\nNew and Advanced Abilities. The results presented\nin Table 5 offer a comprehensive comparison of several\nmetrics, including finish rate, obtained utility, crash rate,\nand lost utility. The finished and crash rates indicate the\npercentage of completed and crashed tasks, respectively.\nThe obtained utility is the total rewards, while the lost\nutility reflects the rewards lost due to task crashes. The data\nin Table 5 indicate that all DRL-based policies outperform\nthe heuristic policies regarding obtained utility and provide\ncompetitive benchmarks to our D2SAC. This observation is\nconsistent with the findings from Table 3. However, policies\nsuch as REINFORCE, PPO, and the proposed D2SAC, which\nachieved high utility, still experienced a near-zero crash rate.\nThis highlights the trade-offs required to maximize utility,\nas some crashes are inevitable. Conversely, policies such as\nRainbow, which focused on zero crashes, suffered from the\nlower utility. Among the DRL-based policies, DQN achieved\n13\n0\n2\n4\n6\n8\n10\nEnvironment Steps\n105\n0\n100\n200\n300\n400\n500\nRewards\nD2SAC\nDQN\nDRQN\nPrioritized-DQN\nRainbow\n(a) D2SAC vs DQN, DRQN, Prioritized-\nDQN, and Rainbow\n0\n2\n4\n6\n8\n10\nEnvironment Steps\n105\n0\n100\n200\n300\n400\n500\nRewards\nD2SAC\nPPO\nREINFORCE\nSAC\n(b) D2SAC vs REINFORCE, PPO, and SAC\n0\n2\n4\n6\n8\n10\nEnvironment Steps\n105\n-300\n-200\n-100\n0\n100\n200\n300\n400\n500\n600\nRewards\nD2SAC\nCrash Avoid\nProphet\nRandom\nRound Robin\n(c) D2SAC vs Prophet, Round Robin,\nCrash Avoid, and Random policies\nFig. 5. Comparison of test reward curves of D2SAC and benchmarks.\n0\n0.5\n1\n1.5\n2\nTask Arrival Rate \n10-3\n102\n103\nTest Rewards\nRoundrobin\nRandom\nCrashavoid\nProphet\nD2SAC\n0\n0.5\n1\n1.5\n2\nTask Arrival Rate \n10-3\n102\n103\nTest Rewards\nDQN\nPrioritized-DQN\nDRQN\nRainbow\nD2SAC\n0\n0.5\n1\n1.5\n2\nTask Arrival Rate \n10-3\n102\n103\nTest Rewards\nREINFORCE\nPPO\nSAC\nD2SAC\nFig. 6. The cumulative test rewards over different task arrival rates. Negative reward values are not displayed.\n0\n5\n10\n15\nDenoising Steps\n0.88\n0.9\n0.92\n0.94\n0.96\n0.98\n1\nNormalized Reward\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nNormalized Time\nNormalized Reward Value\nNormalized Time Value\nFig. 7. Denoising step impact on reward and training time, normalized to\ntheir maximum value.\nthe highest utility with no crashes. However, D2SAC out-\nperformed DQN regarding utility, indicating that D2SAC\nlearned to prioritize tasks by estimating their values and\nselectively discarding low-value tasks to reserve resources\nfor high-value tasks. This insight is further evident in\nthe comparison between PPO and D2SAC, where D2SAC\ncrashed 1.1% of tasks with a lost utility of 5, while PPO\ncrashed 0.7% of tasks with a lost utility of 4. This feature is\nprecious in real-world scheduling systems where resource\nallocation is critical. However, when avoiding crashes is of\nutmost importance, DQN might be a better option.\nNo Longer Large Denoising Step. The diffusion chain in\ndiffusion-based generation models refers to the sequential\nspread of information from one state to another, with the\nlength of the chain represented by the denoising step T.\nSelecting an appropriate value for T involves a trade-off\nbetween computational efficiency and accuracy. To ensure\naccuracy, a large value of T is recommended, but this comes\nat the cost of longer computation times. However, a small\nvalue of T reduces computation time but can increase the\nrisk of instability and numerical errors. In a recent study\n[31], a value of T = 500 was found to strike a balance\nbetween accuracy and computational efficiency.\nHowever, in D2SAC, the relationship between the de-\nnoising step, reward, and computational time did not follow\nthe above rule. Specifically, in Fig. 7, we vary the denoising\nstep T \u22081, 2, 3, 4, 5, 10, 15. We observe that the reward\nfirst increased, but then decreased as the number of de-\nnoising step increased, while the training time consistently\nincreased. This finding suggests that there is an optimal\ndenoising step at the inflection point of the reward curve,\nwhich appears to be T = 5. Moreover, we discovered that\nthe optimal denoising step was significantly fewer than\nthe one used in [31], indicating that the trade-off between\nlearning performance and computational efficiency was no\nlonger present. Thus, taking a small T can achieve a satisfy-\ning reward while maintaining high computational efficiency.\nUnderstand the Reverse Diffusion Process. Diffusion-\nbased generative models employ the reverse diffusion pro-\n14\nTABLE 4\nAccumulated Reward Comparisons on General Benchmark Tasks.\nPolicy\nAcrobot-v1\nCartPole-v1\nCoinRun-v0\nMaze-v0\nDRL\nDQN\n-81.81 \u00b1 17.19\n499.80 \u00b1 0.14\n6.00 \u00b1 4.90\n3.00 \u00b1 4.58\nPrioritized-DQN\n-105.20 \u00b1 14.74\n498.70 \u00b1 1.43\n5.00 \u00b1 5.00\n2.00 \u00b1 4.00\nDRQN\n-82.26 \u00b1 14.34\n132.50 \u00b1 69.79\n\u2212\n\u2212\nREINFORCE\n-104.80 \u00b1 14.51\n500.00 \u00b1 0.00\n0.00 \u00b1 0.00\n0.00 \u00b1 0.00\nPPO\n-77.22 \u00b1 8.45\n499.90 \u00b1 0.33\n0.00 \u00b1 0.00\n2.00 \u00b1 4.00\nRainbow\n-158.10 \u00b1 55.48\n478.30 \u00b1 29.28\n5.00 \u00b1 5.00\n2.00 \u00b1 4.00\nSAC\n-121.00 \u00b1 35.31\n500.00 \u00b1 0.00\n10.00 \u00b1 0.00\n3.00 \u00b1 4.58\nOnline [47, 48]\nA2C\n-86.62 \u00b1 25.10\n499.90 \u00b1 1.67\n\u2212\n\u2212\nACER\n-90.85 \u00b1 32.80\n498.62 \u00b1 23.86\n\u2212\n\u2212\nACKTR\n-91.28 \u00b1 32.52\n487.57 \u00b1 63.87\n\u2212\n\u2212\nPPO2\n-85.14 \u00b1 26.27\n500.00 \u00b1 0.00\n\u2212\n\u2212\nDQN\n-88.10 \u00b1 33.04\n500.00 \u00b1 0.00\n\u2212\n\u2212\nTRPO\n\u2212\n485.39 \u00b1 70.51\n\u2212\n\u2212\nPPO + IMPALA\n\u2212\n\u2212\n8.95\n9.88\nRainbow + IMPALA\n\u2212\n\u2212\n5.50\n4.24\nOurs\nD2SAC\n-70.77 \u00b1 4.12\n500.00 \u00b1 0.00\n10.00 \u00b1 0.00\n7.00 \u00b1 4.58\nTABLE 5\nTask Performance Comparisons of D2SAC and Benchmarks\nPolicy\nFinished Rate6\nObtained Utility\nCrashed Rate\nLost Utility\nHeuristic\nRandom\n70.2%\n215\n27.7%\n93\nRound Robin\n90.3%\n309\n7.6%\n32\nCrash Avoid\n97.7%\n357\n0%\n0\nProphet\n97.7%\n548\n0%\n0\nDRL\nDQN\n97.7%\n479\n0.0%\n0\nPrioritized-DQN\n97.7%\n433\n0.0%\n0\nDRQN\n94.3%\n433\n3.8%\n17\nREINFORCE\n95.8%\n458\n1.9%\n10\nPPO\n97.0%\n457\n0.7%\n4\nRainbow\n97.7%\n419\n0.0%\n0\nSAC\n94.3%\n412\n3.5%\n11\nOurs\nD2SAC\n96.6%\n494\n1.1%\n5\ncess to generate new samples from a noise distribution. A\ndenoising network is used to predict and remove noise at\neach step, gradually resulting in a high-quality and coherent\nsample. Fig. 8 illustrates how the distribution of action\nprobability changes during each step of the reverse diffusion\nprocess at various training iterations. The starting point,\nrepresented by the step 0 column, is the softmax of a random\nnormal distribution, which reflects the initial uncertainty of\nthe diffusion model. As the process progresses, the decision\nprobability, i.e., the output of the AGOD, becomes more\npeaked and approaches the optimal action predicted by the\nprophet policy, as shown by the vertical dotted lines.\nFigure 8 highlights two important aspects of D2SAC.\nFirstly, as the learning process progresses, D2SAC can pre-\ndict the optimal action decision probability distribution.\nThis is evident in the third row of Fig. 8, where D2SAC\ncan successfully predict multiple optimal actions. Second,\nD2SAC maintains uncertainty after several denoising step of\ndenoising, allowing for exploration, which is crucial in DRL.\nHowever, as the number of denoising step increases, the ex-\nploration ability decreases, leading to suboptimal solutions.\nThis explains the reason for the decrease in reward in Fig. 7\nwhen T is larger than 5. The exploration-exploitation trade-\noff feature of D2SAC in discrete action spaces is distinct\nand novel, different from approaches in continuous action\nspaces. In the problem with continuous action spaces, other\ntechniques, such as noise exploration, should be used to\nenhance exploration. Our approach is thus innovative and\ndifferent from other approaches [24, 38].\nBalance Exploration and Exploitation with Action En-\ntropy. To balance exploration and exploitation in D2SAC, it\nis crucial to determine the strength of inherent exploration\nability. A smaller value of the denoising step T can increase\nuncertainty, causing the agent to explore actions that may\nnot yield high rewards. Conversely, a larger T can decrease\nuncertainty but may cause the agent to stay with suboptimal\nsolutions. The action entropy regularization proposed in\n[20] addresses this challenge by adding a penalty to the ex-\npected reward, which is controlled by the temperature coef-\nficient \u03b1. This regularization balances the trade-off between\nexploration and exploitation by modulating the extent to\nwhich the agent can explore less likely actions.\n15\n0         10         20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0          10        20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0          10        20\n   0.5     1.0\n0          10        20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0          10        20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0          10        20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0         10         20\n   0.5     1.0\n0         10         20\n   0.5     1.0\nIteration 0\nIteration 500\nIteration 1000\nDiffusion Step 0\nDiffusion Step 1\nDiffusion Step 3\nDiffusion Step 4\nDiffusion Step 5\nDiffusion Step 2\nFig. 8. Illustration of the \u201cmoving\u201d action probability distribution during the\nreverse diffusion process, i.e., AGOD algorithm. The vertical dotted lines\nrepresent the optimal action(s) predicted by the prophet policy.\n0\n0.1\n0.2\n0.3\n0.4\n0.5\nEntropy Temperature\n0.8\n0.85\n0.9\n0.95\n1\nNormalized Reward\nNormalized Reward Value\nFig. 9. Effects of entropy regularization at different temperatures.\nValues are normalized by their maximum.\nFigure 9 illustrates the impact of the action entropy\nregularization on the expected reward of D2SAC for varying\nentropy temperature values (\u03b1). The results suggest an\noptimal value of \u03b1 = 0.05, which balances exploration and\nexploitation performance. A lower \u03b1 hinders the agent from\nselecting actions with high uncertainty, leading to greedy\nbehavior and missing out on discovering better actions.\nConversely, a higher \u03b1 encourages the agent to become\nrandom, resulting in slow or no progress in learning the\noptimal policy. By maintaining an appropriate level of en-\ntropy, D2SAC achieves a balance between exploration and\nexploitation, resulting in a fast convergence to the optimal\npolicy.\n7\nCONCLUSION\nWe have proposed an innovative edge-enabled AaaS archi-\ntecture to enable ubiquitous AIGC functionality. To tackle\nthe challenges of environmental uncertainty and variabil-\nity, we have developed the AGOD based on the diffusion\nmodel, which is used in DRL to create the D2SAC algorithm\nfor efficient and optimal ASP selection. Our extensive ex-\nperimental results have demonstrated the effectiveness of\nthe proposed algorithm, which outperformed seven repre-\nsentative DRL algorithms in both the ASP selection problem\nand various standard control tasks. Our proposed approach\nprovides a practical and effective solution for the ubiquitous\nAIGC service in Metaverse. More importantly, the AGOD\nalgorithm can potentially be applied to various optimization\nproblems in wireless networks. In our future research, we\nintend to collect and employ real-world datasets related to\nedge-enabled ASP selections, allowing us to validate and\nrefine our algorithm in practical scenarios effectively.\nREFERENCES\n[1]\nA.\nM.\nTuring,\nComputing\nMachinery\nand\nIntelligence.\nSpringer, 2009.\n[2]\nY. Wang, Z. Su, N. Zhang, R. Xing, D. Liu, T. H. Luan, and\nX. Shen, \u201cA survey on metaverse: Fundamentals, security,\nand privacy,\u201d IEEE Commun. Surveys Tuts., to appear, 2022.\n[3]\nS. Anand and G. Verweij, \u201cWhat\u2019s the real value of AI for\nyour business and how can you capitalise,\u201d 2019.\n[4]\nM. Aljanabi, M. Ghazi, A. H. Ali, S. A. Abed et al., \u201cChat-\nGpt: Open possibilities,\u201d Iraqi J. Comput. Sci. Mathematics,\nvol. 4, no. 1, pp. 62\u201364, Jan. 2023.\n[5]\nA. Ulhaq, N. Akhtar, and G. Pogrebna, \u201cEfficient dif-\nfusion models for vision: A survey,\u201d arXiv preprint\narXiv:2210.09292, 2022.\n[6]\nH. Du, Z. Li, D. Niyato, J. Kang, Z. Xiong, D. I. Kim\net al., \u201cEnabling AI-generated content (AIGC) services in\nwireless edge networks,\u201d IEEE Netw., to appear, 2023.\n[7]\nY. Lin, H. Du, D. Niyato, J. Nie, J. Zhang, Y. Cheng, and\nZ. Yang, \u201cBlockchain-aided secure semantic communica-\ntion for AI-generated content in metaverse,\u201d IEEE Open J.\nComp. Soc., vol. 4, pp. 72\u201383, 2023.\n[8]\nH. Du, D. Niyato, J. Kang, Z. Xiong, P. Zhang, S. Cui,\nX. Shen, S. Mao, Z. Han, A. Jamalipour et al., \u201cThe age\nof generative AI and AI-generated everything,\u201d arXiv\npreprint arXiv:2311.00947, 2023.\n[9]\nG. Harshvardhan, M. K. Gourisaria, M. Pandey, and S. S.\nRautaray, \u201cA comprehensive survey and analysis of gen-\nerative models in machine learning,\u201d Comput. Sci. Rev.,\nvol. 38, p. 100285, 2020.\n[10] H. Du, J. Liu, D. Niyato, J. Kang, Z. Xiong, J. Zhang, and\nD. I. Kim, \u201cAttention-aware resource allocation and QoE\nanalysis for metaverse xURLLC services,\u201d IEEE J. Sel. Areas\nCommun., to appear, 2023.\n[11] J. Ren, J. Liu, Y. Zhang, Z. Li, F. Lyu, Z. Wang, and\nY. Zhang, \u201cAn efficient two-layer task offloading scheme\nfor MEC system with multiple services providers,\u201d in IEEE\nINFOCOM 2022-IEEE Conference on Computer Communica-\ntions.\nIEEE, 2022, pp. 1519\u20131528.\n[12] I. Osband, C. Blundell, A. Pritzel, and B. Van Roy, \u201cDeep\nexploration via bootstrapped DQN,\u201d Proc. Adv. Neural Inf.\nProcess. Syst., vol. 29, 2016.\n[13] H. Du, R. Zhang, Y. Liu, J. Wang, Y. Lin, Z. Li, D. Niyato,\nJ. Kang, Z. Xiong, S. Cui et al., \u201cBeyond deep reinforcement\nlearning: A tutorial on generative diffusion models in\nnetwork optimization,\u201d arXiv preprint arXiv:2308.05384,\n2023.\n[14] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness,\nM. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland,\nG. Ostrovski et al., \u201cHuman-level control through deep\nreinforcement learning,\u201d Nature, vol. 518, no. 7540, pp.\n529\u2013533, 2015.\n[15] M. Hausknecht and P. Stone, \u201cDeep recurrent q-learning\nfor partially observable mdps,\u201d in 2015 AAAI Fall Sympo-\nsium Series, 2015.\n[16] T. Schaul, J. Quan, I. Antonoglou, and D. Silver, \u201cPriori-\ntized experience replay,\u201d arXiv preprint arXiv:1511.05952,\n2015.\n[17] M. Hessel, J. Modayil, H. Van Hasselt, T. Schaul, G. Os-\ntrovski, W. Dabney, D. Horgan, B. Piot, M. Azar, and\nD. Silver, \u201cRainbow: Combining improvements in deep\nreinforcement learning,\u201d in AAAI Conf. Artif. Intell., vol. 32,\nno. 1, 2018.\n[18] R. J. Williams, \u201cSimple statistical gradient-following algo-\nrithms for connectionist reinforcement learning,\u201d Reinforce-\nment Learning, pp. 5\u201332, 1992.\n16\n[19] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and\nO. Klimov, \u201cProximal policy optimization algorithms,\u201d\narXiv preprint arXiv:1707.06347, 2017.\n[20] T. Haarnoja, A. Zhou, P. Abbeel, and S. Levine, \u201cSoft actor-\ncritic: Off-policy maximum entropy deep reinforcement\nlearning with a stochastic actor,\u201d in Proc. Int. Conf. Mach.\nLearn.\nPMLR, 2018, pp. 1861\u20131870.\n[21] H. Du, R. Zhang, D. Niyato, J. Kang, Z. Xiong, D. I.\nKim, X. S. Shen, and H. V. Poor, \u201cExploring collaborative\ndistributed diffusion-based AI-generated content (AIGC)\nin wireless networks,\u201d IEEE Netw., no. 99, pp. 1\u20138, 2023.\n[22] Y. Liu, H. Du, D. Niyato, J. Kang, Z. Xiong, C. Miao,\nS. Xuemin, and A. Jamalipour, \u201cBlockchain-empowered\nlifecycle management for AI-generated content (AIGC)\nproducts in edge networks,\u201d IEEE Wireless Commun., to\nappear, 2023.\n[23] S. Yue, J. Ren, J. Xin, D. Zhang, Y. Zhang, and W. Zhuang,\n\u201cEfficient federated meta-learning over multi-access wire-\nless networks,\u201d IEEE J. Sel. Areas Commun., vol. 40, no. 5,\npp. 1556\u20131570, May 2022.\n[24] Z. Wang, J. J. Hunt, and M. Zhou, \u201cDiffusion policies as an\nexpressive policy class for offline reinforcement learning,\u201d\narXiv preprint arXiv:2208.06193, 2022.\n[25] H. Du, J. Wang, D. Niyato, J. Kang, Z. Xiong, and D. i.\nKim, \u201cAI-generated incentive mechanism and full-duplex\nsemantic communications for information sharing,\u201d IEEE\nJ. Sel. Areas Commun., to appear, 2023.\n[26] X. Chen, Z. Li, Y. Zhang, R. Long, H. Yu, X. Du,\nand M. Guizani, \u201cReinforcement learning\u2013based qos/qoe-\naware service function chaining in software-driven 5g\nslices,\u201d Trans. Emerg. Telecommun. Technol., vol. 29, no. 11,\np. e3477, Nov. 2018.\n[27] K. Arulkumaran, M. P. Deisenroth, M. Brundage, and A. A.\nBharath, \u201cDeep reinforcement learning: A brief survey,\u201d\nIEEE Signal Process. Mag., vol. 34, no. 6, pp. 26\u201338, Jun.\n2017.\n[28] G. Sun, Z. Xu, H. Yu, and V. Chang, \u201cDynamic network\nfunction provisioning to enable network in box for in-\ndustrial applications,\u201d IEEE Trans. Industr. Inform., vol. 17,\nno. 10, pp. 7155\u20137164, 2020.\n[29] G. Sun, L. Sheng, L. Luo, and H. Yu, \u201cGame theoretic ap-\nproach for multipriority data transmission in 5g vehicular\nnetworks,\u201d IEEE Trans. Intell. Transp. Syst., vol. 23, no. 12,\npp. 24 672\u201324 685, 2022.\n[30] M. Dai, L. Luo, J. Ren, H. Yu, and G. Sun, \u201cPsaccf: Prior-\nitized online slice admission control considering fairness\nin 5g/b5g networks,\u201d IEEE Trans. Network Sci. Eng., vol. 9,\nno. 6, pp. 4101\u20134114, 2022.\n[31] J. Ho, A. Jain, and P. Abbeel, \u201cDenoising diffusion proba-\nbilistic models,\u201d Proc. Adv. Neural Inf. Process. Syst., vol. 33,\npp. 6840\u20136851, 2020.\n[32] S. AI, \u201cStable diffusion,\u201d https://stability.ai/.\n[33] J. B. Mazzola and A. W. Neebe, \u201cResource-constrained\nassignment scheduling,\u201d Oper. Res., vol. 34, no. 4, pp. 560\u2013\n572, 1986.\n[34] S. Desale, A. Rasool, S. Andhale, and P. Rane, \u201cHeuristic\nand meta-heuristic algorithms and their relevance to the\nreal world: A survey,\u201d Int. J. Comput. Eng. Res. Trends, vol.\n351, no. 5, pp. 2349\u20137084, May 2015.\n[35] A. Mehta et al., \u201cOnline matching and ad allocation,\u201d\nFound. Trends Theor. Comput. Sci., vol. 8, no. 4, pp. 265\u2013368,\nApr. 2013.\n[36] W. Chen, X. Qiu, T. Cai, H.-N. Dai, Z. Zheng, and Y. Zhang,\n\u201cDeep reinforcement learning for internet of things: A\ncomprehensive survey,\u201d IEEE Commun. Surv. Tut., vol. 23,\nno. 3, pp. 1659\u20131692, Mar. 2021.\n[37] R. S. Sutton, D. McAllester, S. Singh, and Y. Mansour,\n\u201cPolicy gradient methods for reinforcement learning with\nfunction approximation,\u201d Proc. Adv. Neural Inf. Process.\nSyst., vol. 12, 1999.\n[38] M. Janner, Y. Du, J. B. Tenenbaum, and S. Levine, \u201cPlan-\nning with diffusion for flexible behavior synthesis,\u201d arXiv\npreprint arXiv:2205.09991, 2022.\n[39] A. Lugmayr, M. Danelljan, A. Romero, F. Yu, R. Timofte,\nand L. Van Gool, \u201cRepaint: Inpainting using denoising\ndiffusion probabilistic models,\u201d in IEEE Conf. Comput. Vis.\nPattern Recog., 2022, pp. 11 461\u201311 471.\n[40] S. Kastryulin, J. Zakirov, D. Prokopenko, and D. V. Dylov,\n\u201cPytorch image quality: Metrics for image quality assess-\nment,\u201d 2022.\n[41] Z. Liu, P. Luo, X. Wang, and X. Tang, \u201cDeep learning face\nattributes in the wild,\u201d in Proc. IEEE Int. Conf. Comput. Vis.,\n2015, pp. 3730\u20133738.\n[42] S.-W. Ko, K. Han, and K. Huang, \u201cWireless networks\nfor mobile edge computing: Spatial modeling and latency\nanalysis,\u201d IEEE Trans. Wireless Commun., vol. 17, no. 8, pp.\n5225\u20135240, Aug. 2018.\n[43] S.-P. Chung and J.-C. Lee, \u201cPerformance analysis and over-\nflowed traffic characterization in multiservice hierarchical\nwireless networks,\u201d IEEE Trans. Wireless Commun., vol. 4,\nno. 3, pp. 904\u2013918, Mar. 2005.\n[44] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones,\nA. N. Gomez, \u0141. Kaiser, and I. Polosukhin, \u201cAttention is\nall you need,\u201d Proc. Adv. Neural Inf. Process. Syst., vol. 30,\n2017.\n[45] D. P. Kingma and J. Ba, \u201cAdam: A method for stochastic\noptimization,\u201d Proc. Int. Conf. Learn. Represent., 2015.\n[46] F. Garcia-Carballeira, A. Calderon, and J. Carretero, \u201cEn-\nhancing the power of two choices load balancing algo-\nrithm using round robin policy,\u201d Cluster Comput., vol. 24,\nno. 2, pp. 611\u2013624, Feb. 2021.\n[47] K. Cobbe, C. Hesse, J. Hilton, and J. Schulman, \u201cLever-\naging procedural generation to benchmark reinforcement\nlearning,\u201d in Proc. Int. Conf. Mach. Learn., vol. 119.\nPMLR,\n13\u201318 Jul 2020, pp. 2048\u20132056.\n[48] A. Raffin, \u201cRl baselines zoo,\u201d https://github.com/araffin/\nrl-baselines-zoo, 2018.\n",
    "2309.01426": "1\nA Unified Framework for Guiding Generative AI\nwith Wireless Perception in Resource Constrained\nMobile Edge Networks\nJiacheng Wang, Hongyang Du, Dusit Niyato, Fellow, IEEE, Jiawen Kang, Zehui Xiong, Deepu Rajan,\nShiwen Mao, Fellow, IEEE, and Xuemin (Sherman) Shen, Fellow, IEEE\nAbstract\u2014With the significant advancements in artificial in-\ntelligence (AI) technologies and powerful computational capa-\nbilities, generative AI (GAI) has become a pivotal digital con-\ntent generation technique for offering superior digital services.\nHowever, directing GAI towards desired outputs still suffer the\ninherent instability of the AI model. In this paper, we design a\nnovel framework that utilizes wireless perception to guide GAI\n(WiPe-GAI) for providing digital content generation service, i.e.,\nAI-generated content (AIGC), in resource-constrained mobile\nedge networks. Specifically, we first propose a new sequential\nmulti-scale perception (SMSP) algorithm to predict user skeleton\nbased on the channel state information (CSI) extracted from\nwireless signals. This prediction then guides GAI to provide\nusers with AIGC, such as virtual character generation. To ensure\nthe efficient operation of the proposed framework in resource\nconstrained networks, we further design a pricing-based incentive\nmechanism and introduce a diffusion model based approach to\ngenerate an optimal pricing strategy for the service provisioning.\nThe strategy maximizes the user\u2019s utility while enhancing the\nparticipation of the virtual service provider (VSP) in AIGC\nprovision. The experimental results demonstrate the effectiveness\nof the designed framework in terms of skeleton prediction and\noptimal pricing strategy generation comparing with other existing\nsolutions.\nIndex Terms\u2014Wireless perception, AI-generated content, re-\nsource allocation, quality of service\nI. INTRODUCTION\nIn recent years, the accelerated proliferation of diverse user\ndata, advancements in hardware devices, and the evolution\nof AI models catalyze the rapid progression of generative\nartificial intelligence (GAI) technology [1]. As a result, the\nartificial intelligence-generated content (AIGC) and its asso-\nciated applications attract considerable attention [2]. Major\ntechnological giants, such as Microsoft and Google, invest\nheavily in creating their own exclusive GAI model, with\nthe objective of offering users a more comprehensive digital\nJ. Wang, H. Du, D. Niyato, and D. Rajan are with the School of\nComputer Science and Engineering, Nanyang Technological University, Sin-\ngapore (e-mail: jiacheng.wang@ntu.edu.sg, hongyang001@e.ntu.edu.sg, dniy-\nato@ntu.edu.sg, asdrajan@ntu.edu.sg).\nJ. Kang is with the School of Automation, Guangdong University of\nTechnology, China (e-mail: kavinkang@gdut.edu.cn).\nZ. Xiong is with the Pillar of Information Systems Technology and\nDesign, Singapore University of Technology and Design, Singapore (e-mail:\nzehui xiong@sutd.edu.sg).\nS. Mao is with the Department of Electrical and Computer Engineering,\nAuburn University, Auburn, USA (e-mail: smao@ieee.org)\nX. Shen is with the Department of Electrical and Computer Engineering,\nUniversity of Waterloo, Canada (e-mail: sshen@uwaterloo.ca).\nservice [3]. A representative work is OpenAI\u2019s ChatGPT,\nwhich achieves notable breakthroughs in emulating human in\ntext processing tasks. For instance, ChatGPT is capable of not\nonly executing grammar error detection and refinement, but\nalso generating text, code, and performing content retrieval\noperations [4]. Beyond text processing, the powerful capabil-\nities of GAI are also unleashed in the realm of image and\nvideo generation. For instance, Stable Diffusion can generate\nimages based on users\u2019 descriptions (i.e., prompts), as well as\nprocess images according to users\u2019 instructions, including style\nmodifications and rectification of missing pixels and other\nvisual imperfections [5].\nIn comparison to the conventional generation methods, GAI\nexhibits two salient advantages. First, GAI has a superior\nproductivity, capable of generating digital content quickly in\naccordance with user directives. For example, stable diffusion\nmodel [6] can generate a high-definition image within seconds,\nwhich is challenging to accomplish by a traditional user based\ngeneration method. Second, AIGC exhibits greater diversity,\nmanifested in two aspects [7]. The first aspect pertains to the\nrichness of the generated content. Owing to the randomness\nof the seed in AI models, GAI\u2019s outputs can vary significantly\neven with identical instructions. For example, the diffusion\nmodel can generate entirely different images with the same\ninput prompt, thus offering users a broader range of choices.\nThe second aspect is the multimodal presentation format,\nwhich allows AIGC to be delivered in various forms such\nas text, images, videos, and even audio [8]. This makes AIGC\nhighly adaptable, catering to a range of applications. Due to\nthese aforementioned benefits, GAI has emerged as the critical\nengine for creating digital content, playing an indispensable\nrole in our progression towards a more immersive and inter-\nactive next-generation Internet [9].\nDespite the significant advancements, several challenges\nstill need to be tackled for practical applications. First, the\ninherent instability of AI models makes it difficult to meet\nusers\u2019 needs, especially when generating digital content\ndirectly related to users themselves [6]. For example, in\naugmented reality (AR) applications, such as virtual game and\nshopping, the virtual service providers (VSPs) use the GAI\ntechnology to create virtual characters for users. However, due\nto the randomness of seeds in AI model and the difficulty of\nconveying information through prompts about users\u2019 posture\nto the AI model, the generated characters may not align\naccurately with the actual user. As a result, users may generate\narXiv:2309.01426v1  [cs.NI]  4 Sep 2023\n2\nmultiple requests until a satisfactory character is generated,\nwhich not only degrades the quality of service (QoS) of the\nVSP, but also leads to resource wastage. To mitigate this,\nan effective solution is to guide GAI with the help of other\nmethods. However, the computation resources of the VSP\ndeployed in mobile edge networks are typically limited. This\nleads to the second challenge when employing other methods\nto guide GAI, that is, how to incentivize the VSPs to engage\nactively in service provision, thereby ensuring the efficient\noperation of the overall framework. A potential solution to\nthis issue entails establishing a payment plan between the\nuser and the VSP, whereby the user provides fee to the VSP\naccording to the plan to encourage participation.\nGiven the aforementioned challenges and potential so-\nlutions, this paper introduces wireless perception guided\nGAI (WiPe-GAI), a novel framework deployed in resource-\nconstrained mobile edge networks, which uses wireless per-\nception to guide GAI in providing AIGC to users and in-\ntroduces an incentive mechanism to ensure its economical\noperation. Specifically, in WiPe-GAI, we first propose a novel\nsequential multi-scale perception (SMSP) algorithm, which\nenables WiPe-GAI to construct a feature channel state infor-\nmation (CSI) matrix. This is then fed into a trained neural\nnetwork to predict the user\u2019s skeleton, to accurately capture the\nuser\u2019s posture in the physical space. By integrating the user\u2019s\nprompts with the predicted skeleton, WiPe-GAI then guides\nthe GAI model to generate the corresponding virtual characters\nfor the user. Compared to image-guided AIGC, WiPe-GAI\nnot only enhances privacy by reducing the exposure of users\nunder the camera, but also expands service coverage through\nthe ubiquitous availability of wireless signals. Furthermore,\nconsidering the limited resources of the VSP deployed in\nthe mobile edge network, we design an incentive mechanism\nbased on pricing for this framework and propose a diffusion\nmodel based approach to generate the optimal pricing strategy.\nThis strategy maximizes the user\u2019s utility, while encouraging\nthe VSP to actively participate in service provision, thereby\nensuring the efficient operation of WiPe-GAI. In summary, the\nmain contributions of this paper are as follows.\n\u2022 We design a unified framework deployed in resource-\nconstrained mobile edge networks, which combines wire-\nless perception and GAI to provide AIGC to users. It\nalso incorporates an incentive mechanism to ensure its\neconomical operation.\n\u2022 In the developed framework, we propose a novel SMSP\nalgorithm, which sequentially performs large-scale and\nsmall-scale perception on the user to construct a CSI\nfeature matrix for user skeleton prediction. During this\nprocess, the perception at different scales cooperates by\nsharing perception results, thus enhancing the overall\nperception performance.\n\u2022 To ensure the economical operation of the framework,\nwe design an incentive mechanism based on pricing and\npropose a diffusion model-based approach to generate\nan optimal pricing strategy. Through this strategy, users\ncan maximize their utility while the VSP with limited\nresources is encouraged to participate actively in AIGC\nprovisioning.\n\u2022 The experimental results validate the effectiveness of the\nproposed framework. That is, WiPe-GAI can accurately\npredict the user\u2019s skeleton and generate the corresponding\nvirtual character for the user. Moreover, the proposed\ndiffusion-based method can effectively generate the opti-\nmal strategy that not only yields greater user utility than\nexisting methods, but also ensures VSP\u2019s participation,\nthereby enhancing the efficiency of the framework.\nThis paper is structured as follows. Section II reviews\nrelated works. Section III presents the overall framework and\ndetails the design of the framework. The evaluation is given\nin Section IV. Section V summarizes the paper.\nII. RELATED WORK\nIn this section, we provide a brief review of the related\nworks about wireless perception, diffusion model, and pricing-\nbased incentive mechanisms.\nA. Wireless Perception\nWireless perception involves using various signal processing\ntechniques to extract features from wireless signals. These fea-\ntures are then analyzed to achieve human perception, including\nlocalization [10], behavior and gesture recognition [11], and\neven imaging [12]. In [13], the authors proposed a novel con-\nvolution neural network (CNN) architecture to condense the\nspatial-temporal information in wireless signals, enabling the\nconversion of frequency modulated continuous wave (FMCW)\nsignals to human skeleton. This approach has also been\nextended to through-wall scenarios [14]. The radio-frequency\nidentification (RFID) can also be used for human skeleton\nestimation. For instance, in [15], the authors first calibrated the\nphase of RFID data and imputed the missing data via tensor\ncompletion. On this basis, they estimated the spatial rotation\nangle of each human limb and utilize the angles to reconstruct\nhuman pose. In addition to RFID, some other researchers have\nalso proposed methods for converting WiFi signals to user\nskeleton [16]. For example, in\n[17], the authors designed\na shared convolutional module and a transformer, which ex-\nplores the spatial information of human pose via self-attention\nand maps the WiFi CSI to human skeleton. The authors\nin [18] developed a deep learning approach, which takes the\nobtained WiFi signals as input and utilizes annotations on two-\ndimensional images to achieve human body segmentation and\npose estimation in an end-to-end manner. Unlike these WiFi\nbased methods, which lacks targeted processing of wireless\nsignals, we introduce the SMSP algorithm in this paper to fully\nexploit the information contained in CSI, thereby predicting\nmore accurate human skeleton.\nB. Diffusion Model\nThe diffusion model is a type of deep generative model [19],\nwhich can generate the sample by gradually learning the re-\nverse diffusion process [5]. This model is widely used in image\ngeneration [20]. For instance, the authors in [21] proposed a\nunified multi-modal latent diffusion model, which takes texts\nand images containing specified subjects as the input and\n3\nEncoder\nDecoder\nTrainable copy\nTrainable copy\nTx\nRx1\nRx2\nRx3\nRx4\nRx5\nFresnel zones\nRaw CSI\nLink 1\nLink 2\nLink 3\nLink 4\nLink 5\nZero \nconvolution\nZero \nconvolution\nZero \nconvolution\nZero \nconvolution\nNeural network \nblock (locked)\nNeural network \nblock (locked)\nPrompts:\u03c6 \nPrompts:\u03c6 \nRotation factor \nmatrix construction\nUser orientation \nanalysis to get Ss-q\nCSI amplitude and \nphase feature matrix\n,\nph\nam\n\uf0a2\n\uf0a2\n\uf0e9\n\uf0f9\n\uf0eb\n\uf0fb\n\u0397\n\u0397\nUser location \nanalysis to get Sl-q\n2 18 18\np\n\uf0b4\n\uf0b4\n\uf0ce\nV\n2 18 18\np\n\uf0b4\n\uf0b4\n\uf0ce\nV\nSkeleton:\u03b6\n\uff0b\n3). ControlNet\n2). S(\u00b7)\n1). SMSP\n4). Virtual characters\n\uf0a2\uf0a2\uf0a2\n\u0397\uf0a2\uf0a2\uf0a2\n\u0397\nFeature extractor\nFeature extractor\n\uf0a2\uf0a2\n\u0397\uf0a2\uf0a2\n\u0397\nUser\nVirtual service provider (VSP)\n fOptimal pricing strategy ffffff\nService provision\nA. Request for service\nC. Accept the strategy\nand provide the service\nB. Generate the optimal pricing strategy\nThe optimal pricing strategy generation process\n: The utility of VSP\n: The utility of user\n: The utility of VSP\n: The utility of user\nFig. 1: The structure of the WiPe-GAI framework. When the user initiates the service request, WiPe-GAI employs the proposed\ndiffusion model-based method to generate the pricing strategy, as four figures at the bottom show. It can be observed that,\nthrough the iterations, the pricing gradually converges to the optimal position, thereby forming the final pricing strategy. If the\nutility brought by this pricing strategy meets the requirements of the VSP, the VSP subsequently provides AIGC to the user.\ngenerates customized images with the subjects. By introducing\ncross-attention layers, the authors in [22] transformed the\ndiffusion model into a generator for general conditional inputs,\nmaking it possible for high-resolution synthesis in a convo-\nlutional manner. Additionally, the authors in [23] achieved\nhigh perceptual quality image generation with less data, by\nadopting a novel neural adapter based on layout attention\nand task-aware prompts. Besides image generation, recent\nworks apply the diffusion model to behavior cloning, policy\nregularization [24], and optimization problem solving [25].\nUnlike existing works that focus on generating images, we\npropose to use the diffusion model to generate optimal pricing\nstrategy for users and VSPs, thereby ensuring the efficient\noperation of WiPe-GAI.\nC. Pricing-based Incentives\nIn wireless network ecosystems, pricing strategies are often\nused in building incentive mechanisms, with the aim of en-\nhancing the utility of the strategy provider [26]. For instance,\nthe authors in [27] developed a stochastic game to simulate\nthe dynamics between users and the access point (AP). Here,\nthe AP establishes a price to maximize its utility, while users\nstrategize their offloading to minimize both latency and costs.\nMoreover, authors in [28] employed the Stackelberg pricing\ngame to facilitate spectrum trading between mobile network\noperators (MNOs) and wireless spectrum providers (WSPs),\naiming to simultaneously maximize the payoffs for both\nMNOs and WSPs. Their results confirmed the achievement of\nthis goal and that the Stackelberg equilibrium can be reached.\nIn another study [29], the authors introduced a pricing strategy\nto stimulate content caching among device-to-device (D2D)\nusers and proposed four algorithms based on varied pricing\nand cache reward methods. The results indicate that a uniform\npricing scheme with linear rewards is ideal for high cache\nquality scenarios, while the discriminatory pricing scheme\nwith nonlinear rewards better serves scenarios demanding\nmore evenly distributed cache content. Additionally, focusing\non vehicular ad hoc networks (VANETs), the authors in [30]\npresented a pricing strategy by considering both cellular base\nstation\u2019s revenue and network throughput. Through extensive\ntests, they showed that the proposed algorithm can improve the\ntotal transmission rate of VANET by at least 20% compared\nwith the random selection approach. Inspired by these works,\nthis paper aims to incentivize the VSP to actively participate\nin service provision, by designing an effective pricing strategy\nfor users and VSPs.\n4\nTABLE I: Some key notations\nSection\nNotation\nDefinition\nNotation\nDefinition\nPerception\nM\nTotal number of antennas\nN\nTotal number of subcarriers\nk\nAntenna spacing\nc\nSignal propagation speed\nU\nTotal number of measurements\nL\nTotal number of propagation paths\n\u03b8\nSignal AoA\n\u03c4\nSignal ToF\nQ\nTotal number of receivers\nI\nIdentity matrix\nFq\nRotation matrix\n[H\u2032\nph, H\u2032\nam]\nCSI feature matrix\nSkeleton\nB (\u00b7)\nNeural network for converting V into V\u2032\nS (\u00b7)\nNeural network for predicting Vp\nV\nVideo data\nV\u2032\nPose adjacent matrix\nextraction\nH\u2032\u2032\nOutput of encoder\nH\u2032\u2032\u2032\nOutput of feature extractor\nVp\nPredicted skeleton\nLMSE\nLoss function\nIncentive\nvr\nPrice for per unit of QoS paid by user\nQt\nQoS\nIb\nBase fee provided by user to VSP\nvc\nUnit cost of computing resources\nmechanism\nvm\nUser\u2019s gain per unit of QoS\nEt\nTotal computing resources\nUth\nUtility threshold of VSP\nT\nNumber of rounds to add noise\nIII. SYSTEM DESIGN\nIn this section, we first provide an overview of the proposed\nWiPe-GAI. Subsequently, we introduce the key components,\nincluding SMSP algorithm, the user skeleton extraction, and\nthe GAI based virtual character generation. Finally, we present\nthe design of the pricing-based incentive mechanisms and\nthe generation of the optimal pricing strategy based on the\ndiffusion model.\nA. System Overview\nBy taking virtual interactive gaming as an example, Fig. 1\nillustrates the proposed framework, which involves two parties,\ni.e., the users (service requester) and the VSP deployed in\nmobile edge networks, as well as three core steps, represented\nby A, B, and C, respectively. Specifically, when the user\ninitiates a service request, the WiPe-GAI first employs the\nproposed diffusion model based approach to generate the\noptimal pricing strategy and presents it to the VSP. Once\nthe utility brought by the strategy meets the requirements\nof the VSP, the VSP provides AIGC services to the user.\nAs the service provision part in Fig. 1 shows, the VSP\nfirst runs the proposed SMSP algorithm to construct the CSI\nfeature matrix, which, unlike the raw CSI data, emphasizes\nthe information relevant to the user. Subsequently, leveraging\nthe trained neural network (denoted as B (\u00b7)), the extracted\nCSI feature matrix is converted into a skeleton, accurately\nrepresenting the user\u2019s posture in the physical world. Lastly,\nthe VSP uses the acquired skeleton to guide GAI to generate\na corresponding virtual character for the user. In contrast to\nother guiding strategies based on images or videos, WiPe-GAI\nnot only offers better protection of user\u2019s privacy but also has\na wider coverage due to the ubiquity of wireless signals [31].\nMeanwhile, the pricing-based incentive mechanism and the\ncorresponding generated optimal pricing strategy ensure the\nentire framework operates efficiently. Next, we will detail\nthe designs of the proposed WiPe-GAI. To facilitate the\ndescription, we summarize the main notation in Table I.\nB. Sequential Multi-scale Perception\n1) Large-scale Perception: Upon receiving the service re-\nquest from the user, the VSP employs the wireless nodes\naround the user to perform SMSP by transmitting and re-\nceiving wireless signals. Using the captured wireless signals,\nthe first step is to perform large-scale perception. Concretely,\nassuming that the device located at [xt, yt] transmits the signals\nmodulated by the orthogonal frequency division multiplexing\n(OFDM) technique, while the wireless node located at [xq, yq]\nutilizes a uniform linear antenna array to receive signals. Then,\nthe CSI obtained by the q-th receiver can be expressed as\nH =\n\uf8ee\n\uf8ef\uf8f0\nH1,1 \u00b7 \u00b7 \u00b7 H1,N\n...\n...\n...\nHM,1 \u00b7 \u00b7 \u00b7 HM,N\n\uf8f9\n\uf8fa\uf8fb,\n(1)\nwhere Hm,n is the CSI extracted from the m-th antenna and\nthe n-th subcarrier, M represents the number of antennas at\nthe receiver, and N represents the number of subcarriers. Each\nelement in matrix H is the sum of the CSI of all the signal\npropagation paths [31]. For any given specified propagation\npath l, the corresponding CSI can be written as\nH[l]\nm,n = \u03b1[l]\nm,ne\u2212j2\u03c0fn[\u03c4 [l1]\nq\n+(m\u22121)k sin(\u03b8[l]\nq )/c]e\u2212j\u03b5+\u03b7[l]\nm,n,\n(2)\nwhere \u03b1[l]\nm,n represents the attenuation introduced by the\npropagation path, fn is the frequency of the n-th subcarrier,\n\u03c4 [l1]\nq\nis the time of flight (ToF) of the signal arriving at the\nreference antenna, k represents the antenna spacing at the\nreceiver (assumed to be half-wavelength [32]), \u03b8[l]\nq represents\nthe signal angle of arrival (AoA), c is the signal propagation\nspeed, e\u2212j\u03b5 represents the phase error, and \u03b7[l]\nm,n is the noise.\nAs it can be observed from (2), for each propagation path,\nthe signal AoA is encoded in the phase difference between the\nantennas, while the ToF is embedded in the phase difference\nbetween the subcarriers. Consequently, based on H, the two-\ndimensional multiple signal classification algorithm is used\nhere to jointly estimate the AoA and ToF of the propagation\npath. The basic idea of this algorithm is the eigenstructure\nanalysis of a correlation matrix RX, which is giving\nRX= E\n\u0002\nXX\u2020\u0003\n= ARSA\u2020 + \u03c32I,\n(3)\nwhere X \u2208RM \u2032\u00d7N \u2032 is obtained by conducting spatial smooth-\ning on the H, the superscript \u2020 is the conjugate transpose\noperator, A is the array manifold corresponding to X, RS is\n5\nthe correlation matrix of the signal matrix, I is the identity\nmatrix, and \u03c32 is the variance of noise. The matrix RX has\nM \u2032 eigenvalues, among which the larger ones correspond to\neigenvectors that form the signal subspace ES. According to\nthe information theoretic criteria [33], the number of large\neigenvalues, denoted as L, can be estimated by minimizing\nMDL (L) = \u2212log\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8f0\nM \u2032\nQ\ni=L+1\n\u03bb\n1/(M \u2032\u2212L)\ni\n1\nM \u2032\u2212L\nM \u2032\nP\ni=L+1\n\u03bbi\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fb\n(M \u2032\u2212L)U\n(4)\n+ 1\n2L (2M \u2032 \u2212L) log (U) ,\nwhere \u03bbi is the i-th largest eigenvalue, and U is the number of\nobservations1. Apart from the signal subspace, the remaining\neigenvectors form the noise subspace EN, which is orthogonal\nto the steering matrix a\u2020 (\u03b8, \u03c4) extracted from X. Using this\northogonality, we have\nPs (\u03b8, \u03c4) =\n1\na\u2020 (\u03b8, \u03c4) ENE\u2020\nNa (\u03b8, \u03c4)\n,\n(5)\nthrough which the joint AoA and ToF estimation for each\nsignal propagation path is achieved by traversing AoA and\nToF, i.e., \u03b8 and \u03c4, respectively. In this way, the VSP uses the\nCSI obtained from each receiver to estimate the AoA and ToF\ncorresponding to the user induced reflection. By combining\nthese estimated parameters, along with the locations of the\ntransceivers, the VSP calculates the user\u2019s physical location,\nand here we denote it as [xus, yus].\nAccording to the Fresnel Zone Theory [35], the user\u2019s\nposture has a greater influence on nearby wireless links. This\nimplies that the CSI obtained from wireless links closer to\nthe user carries more detailed information regarding the user\u2019s\nposture. Hence, the VSP calculates the distance between the\nuser and each wireless link. By using the link formed by the\nq-th receiver and transmitter as an example, this distance is\nDq = |\u03a5xus + \u03a5\u2032yus + (xq \u2212xt) yt \u2212(yus \u2212yt) xt|\np\n\u03a52 + \u03a5\u20322\n,\n(6)\nwhere \u03a5 = yq \u2212yt, and \u03a5\u2032 = xt \u2212yq. On this basis, the\nscore of large-scale perception is calculated according to the\ncomputed distance as follows:\nS1q = min {Dq}/Dq,\n(7)\nwhere min {Dq} represents the minimum value among Q\ndistances, q\n= 1, . . . , Q, and Q is the total number of\nreceivers which are involved in the perception. As shown in\n(7), links closer to the user yield higher scores due to the\nricher information that they contain. These scores will later be\nutilized as weights during the construction of the CSI feature\nmatrix, and hence ensuring that links with more information\nplay a more pivotal role in skeleton prediction. In this manner,\nthe VSP accomplishes large-scale perception of the user, and\n1This value is determined based on the data transmission rate of the wireless\nnodes. For instance, assuming the node is a commonly used WiFi device with\na data packet transmission frequency of 400 Hz. Then, based on the channel\ncoherence time [34], U can be set as 400 \u00d7 0.84 \u224834.\nthe obtained user\u2019s location will then be used to assist in the\nsubsequent small-scale perception.\n2) Small-scale Perception: To improve the accuracy of the\nextracted user skeleton, the VSP further conducts small-scale\nperception of users to obtain the CSI that contains more\ndetailed information about user\u2019s posture. Inspired by the\nFresnel Zone Theory and the impact of user\u2019s orientation\nand behavior on the wireless link, the VSP analyzes the\nsignal fluctuation characteristic with the help of large-scale\nperception result, to achieve small-scale perception.\nSpecifically, the VSP first utilizes [xus, yus] and [xq, yq] to\ncalculate the direction of the user relative to the q-th receiver,\ndenoted as \u03b8\u2032\nq. Then, the VSP uses \u03b8\u2032\nq to construct a phase\nweight for the CSI of the m-th antenna and the n-th subcarrier,\nwhich is\nwm,n\n\u0000\u03b8\u2032\nq\n\u0001\n= ej2\u03c0fn\n(m\u22121)k sin(\u03b8\u2032\nq)\nc\n.\n(8)\nBy using this weight, the power received along a beam in the\n\u03b8\u2032\nq direction of q-th receiver at time u can be calculated as\nP [u]\nw\n\u0000\u03b8\u2032\nq\n\u0001\n=\n\f\f\f\f\f\nM\nX\nm=1\nN\nX\nn=1\nwm,n \u00b7 Hm,n\n\f\f\f\f\f\n2\n.\n(9)\nAssuming the power in (9) is obtained at time u, and then for\na power stream containing U observations, the VSP employs\nunbiased variance to characterize the fluctuation features of\nthe wireless link during this period of time as follows:\nS2\n\u03b8\u2032q =\n1\nU \u22121\nU\nX\nu=1\nh\nP [u]\nw\n\u0000\u03b8\u2032\nq\n\u0001\n\u2212\u00afPw\n\u0000\u03b8\u2032\nq\n\u0001i2\n,\n(10)\nwhere \u00afPw\n\u0000\u03b8\u2032\nq\n\u0001\nis the average power value during this period.\nBy doing so, the score of small-scale perception is obtained\nby calculating the variance of each wireless transmission link\nas follows:\nS2q = S2\n\u03b8\u2032q\n.\nmax\nn\nS2\n\u03b8\u2032q\no\n,\n(11)\nwhere max\nn\nS2\n\u03b8\u2032q\no\nis the maximum among Q variances. From\n(8) to (11), it can be seen that a link influenced more signifi-\ncantly by the user\u2019s posture (i.e., with higher link fluctuations)\ntends to contain more information [35], subsequently yielding\na higher score. With the help of large-scale perception results,\nthe VSP finishes the small-scale perception of the user and\nobtains the corresponding score, which will be combined with\nthe large-scale score later to create the CSI feature matrix used\nfor skeleton generation.\nTo further improve the user skeleton extraction performance\nby combining CSI from all receivers, the VSP performs more\nprocessing on the original CSI data to enhance the user\ninduced reflection before constructing the CSI feature matrix.\nWe use the case with two receivers as an example. For the\nm-th antenna and the n-th subcarrier, the CSI obtained by\nthe 1-st and the q-th receivers are shown in Fig. 2, where\nthe blue arrowed line represents the CSI of the user induced\nreflection signal, the red arrowed line is the CSI corresponding\nto the sum of the signals from all other paths, and the green\narrowed line is the noise. As shown by the first row in Fig. 2,\n6\n+\n=\n+\n=\n1-st receiver\nq-th receiver\nDirectly summed \nSummed after rotation\nSummation\nComparison of the two \nsummation results\nThe sum of other paths: \nThe noise vector: \nThe user induced reflection:\nRotation via  q\nF\nRotation via  q\nF\nRe\nIm\nRe\nRe\nRe\nRe\nRe\nRe\nRe\nIm\nIm\nIm\nIm\nIm\nIm\n+\n=\n+\n=\n1-st receiver\nq-th receiver\nDirectly summed \nSummed after rotation\nSummation\nComparison of the two \nsummation results\nThe sum of other paths: \nThe noise vector: \nThe user induced reflection:\nRotation via  q\nF\nRe\nIm\nRe\nRe\nRe\nRe\nRe\nRe\nRe\nIm\nIm\nIm\nIm\nIm\nIm\nFig. 2: The enhancement process of the CSI induced by the user before the feature matrix construction. As illustrated in the\nfirst row of the figure, if the raw CSIs are directly summed, the inconsistent phases of CSIs obtained from different receivers\nmay reduce the proportion of user-induced reflections in the summed CSI, consequently degrading the perception performance.\nIn WiPe-GAI, we propose to rotate the CSIs corresponding to the user to the same direction before summation, as depicted in\nthe second row of the figure, thereby circumventing such an issue.\nif directly summed, the phase inconsistency of the CSI among\ndifferent receivers may weaken the user induced reflection,\nthereby reducing the perception performance. To circumvent\nsuch an issue, the VSP needs to rotate the CSI of the user\nobtained by each receiver to the same direction. Recall that\nthe phase (i.e., the angle between the blue vector and the Re-\naxis) of the CSI corresponding to the user induced reflection is\ndetermined by the ToF and initial phase, while the amplitude\n(i.e., the magnitude of the blue vector) is determined by the\nreflection coefficient [36]. Therefore, using the estimated AoA\nand ToF of the user induced reflection, the VSP builds a\nrotation factor matrix. For the q-th receiver, the matrix is\nFq =\n\uf8ee\n\uf8ef\uf8ef\uf8f0\nF [1,1]\nq\n\u00b7 \u00b7 \u00b7\nF [1,N]\nq\n...\n...\n...\nF [M,1]\nq\n\u00b7 \u00b7 \u00b7\nF [M,N]\nq\n\uf8f9\n\uf8fa\uf8fa\uf8fb,\n(12)\nwhere\nF [m,n]\nq\n= e\nj2\u03c0fn\n\"\n\u03c4 [l1]\nq\n+\n(m\u22121)k sin(\u03b8[l]\nq )\nc\n#\n.\n(13)\nNext, H is multiplied with Fq to rotate the CSI induced by\nthe user to the positive direction of the Re-axis, as\nH\u2032\nq = H \u25e6Fq,\n(14)\nwhere \u25e6is the Hadamard product operator. By performing this\noperation to all receivers, the CSI corresponding to the user\ninduced reflection received by each receiver will be rotated\ntowards the same direction. As demonstrated in the second\nrow of Fig. 2, this ensures that no attenuation occurs during\nthe summation process. Subsequently, the rotated CSI from\neach receiver is weighted by the scores acquired by the SMSP\nalgorithm, which are then aggregated to construct the CSI\namplitude and phase feature matrix, respectively denoted as:\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\nH\u2032ph =\nQ\nP\nq=1\n(S1q + S2q) angle (H\u2032q)\nH\u2032am =\nQ\nP\nq=1\n(S1q + S2q) abs (H\u2032q),\n(15)\nwhere angle {\u00b7} and abs {\u00b7} are phase and amplitude ex-\ntractor, respectively. From (15), it is clear that the derived\nCSI feature matrix is abundant with information about user\u2019s\nposture. Hence, the VSP uses these matrices to generate human\nskeleton data with neural networks, which will be explained\nin detail in the following section.\nC. Skeleton Extraction\nBased on the acquired CSI feature matrix, the VSP further\nneeds to convert it into skeleton before feeding it into the\nGAI model for the generation of a virtual user character. To\nthis end, the VSP utilizes a camera synchronized with the\nsignal receiver to capture a video stream, from which the\nuser\u2019s skeleton is extracted (via neural network B (\u00b7)) and\nused as supervision to train a neural network (denoted as\nS (\u00b7)), as shown in Fig. 3. Finally, based on the trained neural\nnetwork, the VSP can convert the CSI feature matrix into\nuser\u2019s skeleton.\nSpecifically, let {V, H\u2032\u2032} be a pair of synchronized training\ndata, where H\u2032\u2032 is composed of multiple samples of H\u2032ph and\nH\u2032am, since the sampling rate of CSI is higher than that of the\nvideo frame. To convert the CSI data into skeleton data, the\nneural networks B (\u00b7) and S (\u00b7) are constructed. For any given\ndata pair, B (\u00b7) takes V as the input and outputs skeleton data\ncontaining 18 points, by using OpenPose [37]. After that, these\n18 points are transformed into a pose adjacent matrix V\u2032, and\nwe denote this process as B (V) \u21d2V\u2032 \u2208R2\u00d718\u00d718. At the\nsame time, S (\u00b7) takes H\u2032\u2032 as input and predicts Vp, which is\n7\nOpen\nPose\nUser\nKey points\nSupervision\n( )\uf0d7\nB\n( )\uf0d7\nS\n2 18 18\np\n\uf0b4\n\uf0b4\n\uf0ce\nV\n2 18 18\n\uf0b4\n\uf0b4\n\uf0a2\uf0ce\nV\n\uf0a2\uf0a2\n\u0397\uf0a2\uf0a2\n\u0397\nWireless \ndevice\nWireless device\nCSI\nVideo stream\n\uf0a2\uf0a2\uf0a2\n\u0397\uf0a2\uf0a2\uf0a2\n\u0397\nFeature \nextractor\nFeature \nextractor\nEncoder\nEncoder\nDecoder\nDecoder\nCamera\n,\nph\nam\n\uf0a2\n\uf0a2\n\uf0e9\n\uf0f9\n\uf0eb\n\uf0fb\n\u0397\n\u0397\n,\nph\nam\n\uf0a2\n\uf0a2\n\uf0e9\n\uf0f9\n\uf0eb\n\uf0fb\n\u0397\n\u0397\nFig. 3: The training process of the network which converts CSI feature matrix to user skeleton. Note that during the training\nprocess, the VSP needs to use a camera to acquire V\u2032, which serves as supervision to optimize the neural network S (\u00b7).\nHowever, during the operation of framework WiPe-GAI, the VSP only needs the wireless signals to generate the user\u2019s\nskeleton, without the assistance of a camera. This makes the proposed framework applicable to more scenarios where cameras\nare not suitable.\ndenoted as S (H\u2032\u2032) \u21d2Vp \u2208R2\u00d718\u00d718. On this basis, S (\u00b7)\nis optimized with the supervision of V\u2032, to assist training.\nThe architecture of this network is shown in Fig. 3, where\nS (\u00b7) includes three components: encoder, feature extractor,\nand decoder, which are introduced below.\nEncoder. This module is designed to adjust the data di-\nmension of H\u2032\u2032 through operations such as data deletion and\ninterpolation. In this paper, the CSI is collected using an IEEE\n802.11ac wireless node, with one antenna at the transmitter\nand four antennas at the receiver. One of the receiver\u2019s\nantennas is used for phase calibration and the remaining ones\nfor H\u2032\u2032 construction. Because of the different sampling rates\nbetween the camera and receiver, one image is used to match\nthree CSI measurements. Therefore, we have H\u2032ph \u2208R256\u00d73\nand H\u2032am \u2208R256\u00d73, where 256 represents the number of\nsubcarriers and 3 represents the number of antennas. Subse-\nquently, the encoder removes the CSI corresponding to subcar-\nriers at the bandwidth edges and performs down-sampling to\nconvert [H\u2032ph, H\u2032am] \u2208R512\u00d73 to [H\u2032\u2032ph, H\u2032\u2032am] \u2208R150\u00d73.\nOn this basis, three [H\u2032\u2032ph, H\u2032\u2032am] are directly stacked to\nobtain H\u2032\u2032pm \u2208R150\u00d73\u00d73. After that, H\u2032\u2032pm \u2208R150\u00d73\u00d73\nis interpolated to obtain H\u2032\u2032 \u2208R150\u00d7144\u00d7144. Specifically,\nassuming that the values of four adjacent elements in H\u2032\u2032pm\nare h\u2032\u2032\n11, h\u2032\u2032\n12, h\u2032\u2032\n21, and h\u2032\u2032\n2, respectively, and their corresponding\ncoordinates are [\u00b7, r1, c1], [\u00b7, r1, c2], [\u00b7, r2, c1], and [\u00b7, r2, c2],\nrespectively. Using these four elements, the element obtained\nthrough interpolation located at [\u00b7, r, c] is\nh\u2032\u2032\u2032\nrc = [h\u2032\u2032\n11 (r2 \u2212r) (c2 \u2212c) + h\u2032\u2032\n21 (r \u2212r1) (c2 \u2212c)]\n+ [h\u2032\u2032\n12 (r2 \u2212r) (c \u2212c1) + h\u2032\u2032\n22 (r \u2212r1) (c \u2212c1)] ,\n(16)\nwhere r1 < r < r2 and c1 < c < c2. At last, H\u2032\u2032 is fed into\nthe next module for feature extraction. The structure of the\nencoder is shown in Fig. 4.\nFeature extractor. Based on H\u2032\u2032, a feature extractor is used\nto learn the effective features for user posture estimation. As\ndeeper networks are known to have greater feature learning ca-\npabilities, the VSP could use them to fully unleash the feature\ninformation contained within H\u2032\u2032. However, the potential risk\n\uf0a2\uf0a2\n\u0397\nEdges removing \n& down sampling\n,\nph\nam\n\uf0a2\n\uf0a2\n\uf0e9\n\uf0f9\n\uf0eb\n\uf0fb\n\u0397\n\u0397\n,\nph\nam\n\uf0a2\uf0a2\n\uf0a2\uf0a2\n\uf0e9\n\uf0f9\n\uf0eb\n\uf0fb\n\u0397\n\u0397\nInterpolation\nStacking\npm\uf0a2\uf0a2\n\u0397\n,\nph\nam\n\uf0a2\uf0a2\n\uf0a2\uf0a2\n\uf0e9\n\uf0f9\n\uf0eb\n\uf0fb\n\u0397\n\u0397\nFig. 4: The structure of the encoder.\nassociated with deeper networks, i.e., the gradient vanishing\nor exploding in deep convolutional layers caused by the chain\nrule in the back-propagation optimization, must also be taken\ninto consideration. The ResNet [38], a widely-used network\nin deep learning, can alleviate this problem through the use\nof shortcut connections and residual blocks. Hence, the VSP\nstacks four ResNets basic blocks to form the feature extractor,\nas shown in Fig. 5, for learning features H\u2032\u2032\u2032 \u2208R300\u00d718\u00d718.\nNote that each convolutional layer is followed in succession\nby a batch normalization layer [39] and a rectified linear unit\nactivation layer [40].\nDecoder. The purpose of the decoder is to perform shape\nadaptation between H\u2032\u2032\u2032 and V\u2032. As explained for the encoder,\nV\u2032 is a tensor of size 2 \u00d7 18 \u00d7 18, and the decoder takes\nH\u2032\u2032\u2032 as the input and predicts matrix Vp which has the\nsame size as V\u2032. To accomplish this, the decoder utilizes\ntwo convolutional layers, as depicted in Fig. 6, where the\nfirst layer primarily extracts the channel-wise information, and\nthe second layer reorganizes the spatial information of H\u2032\u2032\u2032\nusing 1 \u00d7 1 convolutional kernels. During the training phase,\nB (V) \u21d2V\u2032 is used as the supervision and S (H\u2032\u2032) \u21d2Vp\nis the prediction. Hence, the loss function is set as the mean\nsquared error (MSE) between V\u2032 and Vp, which is:\nLMSE = \u2225Vp \u2212V\u2032\u22252\n2 .\n(17)\nUnder the above configurations, the network is trained for\n20 epochs using the Adam optimizer with an initial learning\nrate of 0.001 and a batch size of 32. The learning rate is\ndecayed by 0.5 at the 5-th, 10-th, and 15-th epochs. Once the\ntraining is finished, the model shall be able to predict Vp using\n8\n\uf0a2\uf0a2\uf0a2\n\u0397\uf0a2\uf0a2\uf0a2\n\u0397\nOutput size:\n150\u00d7144\u00d7144\nBlock 1\nBlock 2\nBlock 3\nBlock 4\nParameters\nOutput size:\n150\u00d772\u00d772\nOutput size:\n300\u00d736\u00d736\nOutput size:\n300\u00d718\u00d718\nFeature extractor\n\uf0a2\uf0a2\n\u0397\uf0a2\uf0a2\n\u0397\nkernel  \n, \n 150, stride  1\nkernel  \n, \n 150, stride  \n3 3 out-channel\n3 3 out-channel\n3 3 out-chann\ne\n1\nkernel  \n, \n 150, stride  1\nk\n0\nel\n3\n \n3\nernel  \n,\n 15 , str d\nout-cha\n1\nnnel\ni\n \n\uf0b4\n\uf0e9\n\uf0f9\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0ea\n\uf0fa\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0eb\n\uf0fb\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\nkernel  \n, \n 150, stride  2\nkernel  \n, \n 150, stride  \n3 3 out-channel\n3 3 out-channel\n3 3 out-chann\ne\n1\nkernel  \n, \n 150, stride  1\nk\n0\nel\n3\n \n3\nernel  \n,\n 15 , str d\nout-cha\n1\nnnel\ni\n \n\uf0b4\n\uf0e9\n\uf0f9\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0ea\n\uf0fa\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0eb\n\uf0fb\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uf0a2\uf0a2\uf0a2\n\u0397\nOutput size:\n150\u00d7144\u00d7144\nBlock 1\nBlock 2\nBlock 3\nBlock 4\nParameters\nOutput size:\n150\u00d772\u00d772\nOutput size:\n300\u00d736\u00d736\nOutput size:\n300\u00d718\u00d718\nFeature extractor\n\uf0a2\uf0a2\n\u0397\nkernel  \n, \n 150, stride  1\nkernel  \n, \n 150, stride  \n3 3 out-channel\n3 3 out-channel\n3 3 out-chann\ne\n1\nkernel  \n, \n 150, stride  1\nk\n0\nel\n3\n \n3\nernel  \n,\n 15 , str d\nout-cha\n1\nnnel\ni\n \n\uf0b4\n\uf0e9\n\uf0f9\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0ea\n\uf0fa\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0eb\n\uf0fb\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\nkernel  \n, \n 150, stride  2\nkernel  \n, \n 150, stride  \n3 3 out-channel\n3 3 out-channel\n3 3 out-chann\ne\n1\nkernel  \n, \n 150, stride  1\nk\n0\nel\n3\n \n3\nernel  \n,\n 15 , str d\nout-cha\n1\nnnel\ni\n \n\uf0b4\n\uf0e9\n\uf0f9\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0ea\n\uf0fa\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0ea\n\uf0fa\n\uf0b4\n\uf0eb\n\uf0fb\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\n\uff1a\nFig. 5: The structure and parameters of the feature extractor.\n\uf0a2\uf0a2\uf0a2\n\u0397\nkernel: 3\u00d73\nout-channel: 36\nstride: 1\n2 18 18\np\n\uf0b4\n\uf0b4\n\uf0ce\nV\n\uf052\nkernel: 1\u00d71\nout-channel: 2\nstride: 1\nLayer 1\nLayer 2\nFig. 6: The structure of the decoder.\nonly the CSI feature matrix. Finally, the diagonal elements\nfrom Vp are extracted and paired to get the predicted user\nskeleton. The pairing process can be denoted as\n(\nXp = Vp(1,p,p), p \u2208[1, 18]\nYp = Vp(2,p,p), p \u2208[1, 18] ,\n(18)\nwhere Xp and Yp are the coordinates of the predicted skeleton.\nD. Generative AI Based Content Generation\nAfter obtaining user skeleton, the VSP needs to further\ngenerate virtual characters or even specific background based\non the user\u2019s requests. So far, many GAI models have been\nproposed for such tasks. In this paper, the VSP is deployed\nat the network edge to provide such services to users. Con-\nsidering the size of the training dataset, training time, and\ndeployability, ControlNet [6] is used to generate virtual char-\nacters for users. However, unlike existing work that employs\nimage as guidance [41], WiPe-GAI utilizes the predicted user\nskeleton to guide ControlNet to generate the virtual character\nand the corresponding background for the user.\nSpecifically, assuming a feature matrix is \u03c6, a neural\nnetwork \u0393 (\u00b7; \u0398), where \u0398 is a set of network parameters,\ncan transform the feature matrix \u03c6 into another feature matrix\n\u03c6\u2032, i.e., \u0393 (\u03c6; \u0398) =\u03c6\u2032. This process is illustrated in part A\nof Fig. 7. To control neural networks in generating digital\ncontent according to the user\u2019s skeleton, VSP first locks \u0398,\nand then copies and creates a trainable \u0398\u2032, which is trained\nwith an external condition vector \u03b6. This operation not only\nmitigates the over-fitting problem due to a limited number of\nsamples, but also maintains the quality of the content produced\nby the original network. After that, the neural network block\nis connected to a unique \u201czero convolution\u201d layer, i.e., a 1\u00d71\n\u03c6\nInput: \u03c6\nInput: \nOutput: \uf0a2\n\u03c6\nOutput: \uf0a2\n\u03c6\nTrainable copy\nTrainable copy\nNeural network \nblock (locked)\nZero \nconvolution\nZero \nconvolution\nB. ControlNet\nZero \nconvolution\nZero \nconvolution\n\uff0b\nInput: \nInput: \u03b6\nInput: \u03b6\n\uff0b\n\u03c6\nInput: \u03c6\nInput: \nOutput: \uf0a2\n\u03c6\nOutput: \uf0a2\n\u03c6\nNeural network \nblock\n(\n)\n.;\n\uf047\n\uf051\nNeural network \nblock\n(\n)\n.;\n\uf047\n\uf051\nA. original\n\u00b7\n\u03c6\nInput: \nOutput: \uf0a2\n\u03c6\nTrainable copy\nNeural network \nblock (locked)\nZero \nconvolution\nB. ControlNet\nZero \nconvolution\n\uff0b\nInput: \u03b6\n\uff0b\n\u03c6\nInput: \nOutput: \uf0a2\n\u03c6\nNeural network \nblock\n(\n)\n.;\n\uf047\n\uf051\nA. original\n\u00b7\n\u03c6\nInput: \nOutput: \uf0a2\n\u03c6\nTrainable copy\nNeural network \nblock (locked)\nZero \nconvolution\nB. ControlNet\nZero \nconvolution\n\uff0b\nInput: \u03b6\n\uff0b\n\u03c6\nInput: \nOutput: \uf0a2\n\u03c6\nNeural network \nblock\n(\n)\n.;\n\uf047\n\uf051\nA. original\n\u00b7\nFig. 7: A comparison between the original network and Con-\ntrolNet. Building upon the original network, ControlNet creats\na trainable block for external condition training. Meanwhile,\nthe neural network is connected to the zero convolution layers,\nwhere both weight and bias are initialized with zeros, and\nsubsequently transform from zero to the optimal parameters\nthrough the training.\nconvolution layer where both weight and bias are initialized\nwith zeros, as shown in Fig. 7. By doing so, such a layer can\ngradually grow from zero to the optimal parameters through\ntraining. Therefore, the user virtual character generated based\non the trained network can meet the user\u2019s needs in terms of\ncharacter posture and image quality. Based on this structure,\nthe VSP uses stable diffusion as the core neural network,\nwith the user prompts serving as \u03c6 and the extracted user\nskeleton as the external condition vector \u03b6, to generate the\nvirtual character for AIGC service provisioning.\nE. Pricing-based Incentive Mechanism Design\nGiven the limited resources of VSP deployed at the mo-\nbile edge networks, we propose a pricing-based incentive\nmechanism to ensure efficient operation of WiPe-GAI. In\nthis mechanism, the user compensates the VSP based on the\nquality of both perception and virtual character generation\nservices, to encourage the VSP\u2019s active participation. On this\nbasis, we further propose a diffusion model based method to\ngenerate the optimal pricing strategy for the implementation\nof this incentive mechanism.\n9\n1) Incentive Mechanism Design: We design a pricing strat-\negy to stimulate a VSP to engage actively in service provision\nwhile maximizing the benefits of users. In particular, assuming\nthat the VSP provides perception and AIGC services to users,\nthen the user pays a basic fee, as well as an additional fee\nbased on the quality of service (QoS) to the VSP. Therefore,\nthe profit of the VSP can be denoted as\nIV SP =vrQt + Ib,\n(19)\nwhere vr denotes the price that the user pays to the VSP for\nper unit of QoS, Qt represents the QoS, and Ib denotes the\nbasic fee offered by the user to the VSP. Since the service\nprovided by the VSP consists of wireless perception and AI-\nbased virtual digital content generation, the QoS measure\nshould consider the performance of both tasks. Specifically,\nwireless perception provides the skeleton for GAI, and then\nthe GAI generates the virtual character with the same posture\nas the user in the physical world. Therefore, the following\nmetrics are used.\n\u2022 The reciprocal of the normalized Euclidean distance\nbetween Vp and V\u2032 is used as Qs to quantify the\nprecision of perception. As more computing resources\nare allocated to perception, the VSP can engage more\nwireless nodes to participate in perception, leading to a\nmore accurate skeleton. Therefore, we have Qs = \u03c2s (\u03c7s),\nwhere \u03c7s represents the computing resources allocated\nto the wireless perception and \u03c2s (\u00b7) is the mapping\nrelationship between computing resources and QoS.\n\u2022 The Blind/Referenceless Image Spatial Quality Evaluator\n(BRISQUE) and Total Variation (TV) are utilized to\nassess the QoS of AIGC. Similar to wireless perception,\nwhen more computing resources are assigned to GAI,\nthe GAI model can execute more inferences, resulting\nin better QoS. Hence, the QoS of AIGC is Qag =\nBRISQUE + TV = \u03c2brq (\u03c7ag) + \u03c2tv (\u03c7ag), where \u03c7ag\nrepresents the resource allocation for GAI by the VSP,\n\u03c2brq (\u00b7) is the mapping relationship between computing\nresources and BRISQUE, and \u03c2tv (\u00b7) is the mapping\nrelationship between computing resources and TV2.\nBased on the above analysis, we can model the total QoS\nof the service as\nQt = Qs + Qag = \u03c2s (\u03c7s) + \u03c2brq (\u03c7ag) + \u03c2tv (\u03c7ag) .\n(20)\nGiven IV SP and Qt, the utility function of the VSP can be\nobtained as\nUvsp = IV SP \u2212(\u03c7s + \u03c7ag) vc = vrQt + Ib \u2212(\u03c7s + \u03c7ag) vc,\n(21)\nwhere vc is the unit cost of computing resources, and vr is the\nfee paid by user for a unit QoS value. Meanwhile, for users,\nthe utility function can be defined as\nUus = vmQt \u2212(vrQt + Ib) = (vm \u2212vr) Qt \u2212Ib,\n(22)\n2These mapping relationships, including \u03c2s (\u00b7), \u03c2brq (\u00b7), and \u03c2tv (\u00b7) are\nobtained by fitting real-world test results, which will be explained in detail in\nSection IV.\nwhere vm is the gain per unit QoS obtained by user, which\nis determined by the market. Based on the aforementioned\nmodel, the pricing strategy offered by users includes Ib and\nvr, which aims to maximize user\u2019s utility and provide rational\nincentives for the VSP to agree to the pricing strategy. To ob-\ntain an optimal pricing strategy, we formulate an optimization\nproblem as follows:\nmax\nvr,Ib,\u03c7s,\u03c7ag Uus (vr, Ib, \u03c7s, \u03c7ag)\ns.t.\n\uf8f1\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f3\n\u03c7\u2032\ns, \u03c7\u2032\nag \u2208arg max\n\u03c7s,\u03c7ag\nUvsp (vr, Ib, \u03c7s, \u03c7ag) ,\n\u03c7\u2032\ns+\u03c7\u2032\nag \u2264Et,\nUvsp\n\u0000\u03c7\u2032\ns, \u03c7\u2032\nag, vr, Ib,\n\u0001\n\u2265Uth,\n(23)\nwhere the first constraint is to ensure that the VSP can max-\nimize its own utility, the second one comes from the limited\ncomputing resources of the VSP, and the third one is the utility\nthreshold Uth, signifying that the VSP only participates in\nservice provision when the expected utility exceeds this value.\nAs demonstrated by the above model, the user maximizes their\nown utility through pricing, while the VSP seeks to optimize\nits utility by conducting resource allocation while meeting\nthe constraints imposed by the provided pricing and limited\ncomputing resources. Therefore, the optimization problem is\nessentially a joint pricing and resource allocation problem.\nConsidering the uncertainty in mapping relationship between\ncomputing resources and QoS and varying prices of computing\nresources across different situations, we propose a diffusion\nmodel-based approach to tackle this optimization problem.\n2) Diffusion Model Generated Optimal Pricing Strategy:\nThe diffusion model is a type of latent variable model, which\nfirst introduces Gaussian noise to perturb training samples,\nand then learns to perform the inverse denoising process to\ngenerate samples similar to the original. This denoising pro-\ncess allows the model to understand the underlying structure\nof the data, leading to more accurate and realistic genera-\ntions [25]. Hence, we leverage the inverse diffusion process\nto generate optimal pricing strategy to solve this optimization\nproblem [19].\nSpecifically, the forward process of the diffusion model is\ndefined as a Markov chain, wherein T rounds of noises are\nsequentially added to the training samples. As T approaches\ninfinity, the original samples converge to standard Gaussian\nnoise distribution. For a given distribution s0, this forward\nprocess can be expressed as follows\nz (s1:T |s0) =\nT\nY\nt=1\nz (st|st\u22121)\n(24)\n=\nT\nY\nt=1\nN\n\u0010\nst;\np\n1 \u2212\u03b2tst\u22121, \u03b2tI\n\u0011\n,\nwhere {\u03b2}t=1:T is the hyperparameter corresponding to the\nvariance of Gaussian distribution, I is the identity matrix.\nTherefore, for given s0, st can be denoted as\nz (st|s0) = N\n\u0010\nst;\np\u00af\u03d1ts0,\n\u00001 \u2212\u00af\u03d1t\n\u0001\nI\n\u0011\n,\n(25)\nwhere \u00af\u03d1t = Qt\ni=1 (1 \u2212\u03b2i). In contrast to the forward process,\nthe inference stage involves an inverse denoising process to\n10\ngenerate samples. Theoretically, if z (st\u22121|st) can be obtained,\nwe can use it to recover the original sample from the standard\nGaussian distribution. However, the acquisition of z (st\u22121|st)\nrequires knowledge of all pricing strategies in all conditions,\nwhich is difficult to acheive in WiPe-GAI. Therefore, a neural\nnetwork is used to learn the following transition relation as\nfollows:\np\u03c9 (st\u22121|st) = N\n\u0000st\u22121; \u00b5 (st, t) , \u03c32\n\u03c9 (st, t) I\n\u0001\n,\n(26)\nwhere \u03c9 is the hyperparameter of the neural network. On this\nbasis, the inverse denoising process can be described as\np\u03c9 (s0:T ) = p (sT )\n1\nY\nt=T\np\u03c9 (st\u22121|st)\n(27)\n= p (sT )\n1\nY\nt=T\nN\n\u0000st\u22121; \u00b5\u03c9 (st, t) , \u03c32\n\u03c9 (st, t) I\n\u0001\n,\nwhere p (sT ) = N (sT ; 0, I). As it can be seen, the purpose of\ntraining the neural network is to enable it to learn \u00b5\u03c9 (st, t)\nand \u03c32\n\u03c9 (st, t), respectively. From another perspective, given\ns0, the Bayes equation can be utilized to obtain\nz (st\u22121|st, s0) = N\n\u0010\nst\u22121; \u02dc\u00b5t (st) , \u02dc\u03b2tI\n\u0011\n,\n(28)\nwhere \u02dc\u00b5t (st)\n=\n\u0010\nst \u2212\u03b2t\u00af\u03b5\n.p\n1 \u2212\u00af\u03d1t\n\u0011.\u221a\u03d1t and \u02dc\u03b2t\n=\n\u00001 \u2212\u00af\u03d1t\u22121\n\u0001\n\u03b2t\n\u000e\u00001 \u2212\u00af\u03d1t\n\u0001\n. Considering \u02dc\u00b5t (st) as the ground\ntruth, therefore, the learned \u00b5\u03c9 (st, t) is essentially \u03b5\u03c9 (st, t),\ndue to the relation\n\u02dc\u00b5\u03c9 (st, t) =\n1\n\u221a\u03d1t\n\"\nst \u2212\n\u03b2t\np\n1 \u2212\u00af\u03d1t\n\u00af\u03b5\u03c9 (st, t)\n#\n,\n(29)\nand the prediction result of the model at step t \u22121 is\nst\u22121 (st, t; \u03c9) =\n1\n\u221a\u03d1t\n\"\nst \u2212\n\u03b2t\np\n1 \u2212\u00af\u03d1t\n\u03b5\u03c9 (st, t)\n#\n+ \u03c3\u03c9 (st, t) ,\n(30)\nwhere z \u223cN (0, I).\nBuilding upon the aforementioned model, and taking into\naccount the influence of parameters such as the cost of\ncomputing resources on pricing, we construct a conditional\ndiffusion model and utilize its inverse process to generate the\noptimal pricing strategy. Specifically, assuming the pricing to\nbe generated is represented by s = {vr, Ib}, and the state\nparameters influencing the resource allocation and QoS of the\nVSP are denoted by c =\n\b\nc\u03c2s, c\u03c2brq, c\u03c2tv, vc, vr, vm\n\t\n, then the\ninverse process of the conditional diffusion model is\np\u2032\n\u03c9 (s|c) = N\n\u0000sT ; 0, I\n\u0001\n1\nY\nt=T\np\u2032\n\u03c9 (st\u22121|st,c),\n(31)\nwhere p\u2032\n\u03c9 (st\u22121|st,c) can be model as a Gaussian distribution\nexpressed as N\n\u0000st\u22121; \u00b5\u03c9 (st, t, c) , \u03c32\n\u03c9 (st, t, c) I\n\u0001\n, and its cor-\nresponding mean and variance are denoted as\n\uf8f1\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f3\n\u00b5\u03c9 (st, t, c) =\n1\n\u221a\u03d1t\n\"\nst \u2212\n\u03b2t\nq\n1\u2212\u221a\u00af\u03d1t\n\u03b5\u03c9 (st, t, c)\n#\n,\n\u03c32\n\u03c9 (st, t, c) = \u03b2tI,\n(32)\nAlgorithm 1 Diffusion Model Generated Optimal Pricing\nStrategy\nTraining Phase:\n1: Input hyper-parameters: denoising step T, initialize neural\nnetwork parameters \u03c9 and v\n2: ##\nLearning Process\n3: Initialize a random process for pricing strategy exploration\n4: while not converge do\n5:\nObserve the current environment\n6:\nc =\n\b\nc\u03c2s, c\u03c2brq, c\u03c2tv, vc, vr, vm\n\t\n7:\nSet sN as Gaussian noise. Generate pricing strategy\ns0 by denoising sN according to (33)\n8:\nApply the generated pricing strategy s0 to the envi-\nronment and observe the utility value as (22).\n9:\nRecord the real utility value\n10:\nUpdate Qv by minimizing the mean squared error\nbetween the real and predicted utility values\n11:\nUpdate \u03b5\u03c9 according to (34)\n12: return The trained solution generation network \u03b5\u03b8\nInference Phase:\n1: Observe the environment vector c\n2: Generate the optimal pricing strategy s0 by denoising\nGaussian noise using \u03b5\u03b8\n3: return The optimal pricing strategy s0\nrespectively. Meanwhile, according to (31), under the condi-\ntion of c, the prediction outcome of the conditional diffusion\nmodel inverse process at step t \u22121 can be expressed as\nst\u22121 (st, t, c; \u03c9) =\n1\n\u221a\u03d1t\n\"\nst \u2212\n\u03b2t\np\n1 \u2212\u00af\u03d1t\n\u03b5\u03c9 (st, t, c)\n#\n(33)\n+ \u03c3\u03c9 (st, t, c) \u03b5.\nIn WiPe-GAI, our training objective is to determine an \u03b5\u03c9\ncapable of generating an optimal s0 given the condition c.\nHere, an optimal s0 is defined as one that maximizes Uus\nsubject to the constraints defined in (23). Drawing inspiration\nfrom the deep reinforcement learning paradigm, we redefine\ncertain elements in our context. Here, c is treated as the\nenvironment, while s0 is considered the action. The expected\ncumulative reward is represented as the Q-value, denoted\nas Qv(s0, c). To manage the training process, Q-learning is\nadopted. Hence, the optimal \u03b5\u03c9 becomes synonymous with\na denoising network that maximizes the expected cumulative\nQ-values, which can be expressed as\narg min\n\u03b5\u03c9\nL(\u03c9) = \u2212Es0\u223c\u03b5\u03c9 [Qv (s0, c)] .\n(34)\nUpon completion of the training, the resulting model is utilized\nto generate the optimal strategy, by solving the optimization\nproblem in (23). The overall training and inference process is\nsummarized in Algorithm 1.\nIV. EXPERIMENT AND EVALUATION\nIn this section, we conduct a comprehensive evaluation\nand analysis of the proposed WiPe-GAI framework through\n11\nexperiments from two perspectives. First, we evaluate the\nperformance of the user skeleton extraction and virtual char-\nacter generation, based on collected CSI data, to validate\nthe feasibility of WiPe-GAI. Utilizing the evaluation results,\nthen, we obtain the mapping functions \u03c2s (\u00b7), \u03c2brq (\u00b7), and\n\u03c2tv (\u00b7) through fitting and perform experiments to evaluate the\nefficiency of the proposed incentive mechanisms.\nA. Experimental Configuration\nIn the experiments, multiple APs equipped with the Broad-\ncom 4366C0 chips and the Nexmon toolkit [42] are used to\ncollect CSI data based on the IEEE 802.11ac protocol. The\nAP operates at 5.805 GHz with the signal bandwidth of 80\nMHz (including 256 subcarriers) and the transmission rate of\n100 packets per second. During the perception process, the\ntransmitter utilizes a single antenna for signal transmission and\nthe receiver employs four antennas to collect CSI, while one of\nthem is used for phase error cancellation and the others for user\nskeleton generation. The proposed algorithms are executed on\nan experimental platform constructed on a standard Ubuntu\n20.04 system, equipped with an AMD Ryzen Threadripper\nPRO 3975WX 32-core processor and an NVIDIA RTX A5000\ngraphics processing unit (GPU).\nB. Wireless Perception to Virtual Character Generation\n1) Effectiveness of WiPe-GAI: To verify the effectiveness\nof WiPe-GAI, we first conduct experiments on user skeleton\nprediction and the virtual character generation, the results\nare presented in Fig. 8. Taking the skeleton predicted by\nOpenPose [37] as the ground truth, from the figures, we can\nobserve that WiPe-GAI can effectively predict the skeleton of\nthe user via CSI by using the proposed SMSP algorithm and\nthe S (\u00b7). There are some differences between our predicted\nskeleton and the user\u2019s actual posture. For instance, some\ndifferences exist between the positions of the predicted knee\nand the real knee of the user, as can be seen in the second\nrow of results. However, these differences are small and the\noverall skeleton extracted from CSI is fairly close to the\nuser\u2019s real posture. This validates the effectiveness of the\nproposed SMSP based skeleton extraction. Building on this,\nthe predicted skeleton and the user\u2019s prompts are used as\nexternal conditions and prompts, respectively, to generate the\nvirtual character for the user. As can be seen from the fourth\ncolumn in Fig. 8, WiPe-GAI is able to effectively generate the\nvirtual character based on the predicted skeleton and user\u2019s\nprompt. Compared to the results in the fifth column without\nperception guidance, WiPe-GAI produces a virtual character\nwhose posture aligns more accurately with the user\u2019s actual\nposture, demonstrating the effectiveness of the proposed WiPe-\nGAI framework. Furthermore, WiPe-GAI can craft a fitting\nbackground for the virtual character based on user\u2019s prompts,\nthereby enhancing the naturalness of the overall generated\nimage.\n2) Impact of AP Quantity on Skeleton Prediction: After\nverifying the effectiveness of WiPe-GAI, we next analyze\nthe effect of the number of APs on perception accuracy, and\ncompare our approach with the existing method in [43]. The\nresults are presented in Fig. 9. As the results show, the skeleton\nprediction performance deteriorates as the number of APs\ndecreases. This can be explained by the fact that a decrease\nin the AP quantity causes a reduction in the information\nabout user posture contained in the CSI feature matrix, which\nsubsequently leads to a drop in prediction accuracy. However,\ngiven the fixed total computational resource, using fewer APs\nwould free up more resources for the GAI, which can enhance\nthe AIGC quality.\nFurthermore, a comparison between the results in the first\nand second rows reveals that the skeleton prediction accuracy\nof the proposed SMSP algorithm outperforms the methods that\ndirectly use the original CSI data for skeleton prediction [43],\nespecially when fewer APs are involved. For instance, with\nperception involves only one AP, the skeleton predicted by our\nalgorithm can roughly indicate that the user is in a standing\nposition, while the prediction of [43] implies that the user is in\na squatting position, which does not match the ground truth.\nUsing the reciprocal of the normalized Euclidean distance\nbetween the predicted skeleton and the skeleton obtained by\nOpenPose as metric, we conduct multiple predictions under\ndifferent numbers of APs and analyze the prediction accuracy.\nThe results are shown in Fig. 10. For the proposed WiPe-\nGAI framework and the method in [43], as shown by the blue\nand red bars in the figure, respectively, the more APs, the\nmore user information the feature CSI matrix contains, thereby\nresulting in a higher prediction accuracy for the skeleton.\nSpecifically, with one AP involved, the prediction accuracy\nof WiPe-GAI and the method in [43] approximates 5.7 and\n4.2, respectively. However, as the number of APs increases to\n5, the prediction accuracy of these two methods improves to\naround 23.5 and 22.9, respectively. At the same time, as the\nnumber of APs increases, it can be found that the performance\nof the method in [43] gradually approaches to that of WiPe-\nGAI. This is because an increase in the number of APs results\nin an additional amount of information related to the user\u2019s\nposture, enabling a more accurate prediction even without\nspecific signal processing.\nBy fitting the prediction results of both systems, the map-\nping relationships between the number of APs and the per-\nception accuracy can be obtained, as shown by the red and\nblue lines in Fig. 10. From the fitting results, it can be seen\nthat the overall prediction performance of WiPe-GAI is better,\nespecially with fewer APs, demonstrating the efficacy of the\nproposed SMSP algorithm. Essentially, the obtained mapping\nrelationship signifies the relationship between computational\nresources and perception accuracy, since the more APs in-\nvolved in perception, the higher the resource consumption for\nprediction. Therefore, we use the fitted relationship as \u03c2s (\u00b7)\nfor the following analysis.\n3) Impact of Inference Steps on Virtual Character Gen-\neration: In addition to the perception, we also analyze the\nimpact of the number of inference steps on the generation\nof virtual characters, the results are illustrated in Fig. 11.\nFrom the figures, it is clear that the quality of the generated\nvirtual character improves as the number of inference steps\nincreases. Specifically, the virtual character generated with\nonly 2 to 3 inference steps are predominantly in black and\n12\nPrompt: A dinosaur in the forest \nPrompt: The kung fu panda\nPrompt: A spiderman in the city\nPrompt: The superman in the field\nVideo\nOpenPose\nAIGC with guidance\nPredicted\nPrompt: The batman in the sky  \nAIGC without guidance\nPrompt: captain America with shield\nPrompt: A dinosaur in the forest \nPrompt: The kung fu panda\nPrompt: A spiderman in the city\nPrompt: The superman in the field\nVideo\nOpenPose\nAIGC with guidance\nPredicted\nPrompt: The batman in the sky  \nAIGC without guidance\nPrompt: captain America with shield\nFig. 8: The predicted user skeleton and the generated virtual character. In the figures, the first column presents the user\u2019s posture\ncaptured by camera in the real-world scenario. The second column depicts the posture predicted by OpenPose based on the\ncaptured video sequence. The third and fourth columns, respectively, illustrate the user\u2019s skeleton predicted by WiPe-GAI and\nthe generated corresponding virtual character. The fifth column displays the virtual characters generated without perceptual\nguidance.\nwhite, with incomplete character limbs, as the first two figures\nin the results show. However, with more inference steps, these\nissues are effectively alleviated, exhibiting a character with\nmore thematic color, complete limbs, and less noise in the\nbackground. This is understandable, as more steps implies that\nthe GAI model can perform more in-depth denoising, thereby\nproducing higher quality results.\nOn this basis, we further calculate the BRISQUE and TV\nvalues based on the images generated from multiple experi-\nments. The results, represented as data points, are shown in\nFig. 12 and Fig. 13. According to the results, we observe\na decrease in the TV value (from around 78 to 32) and a\ndrop in the BRISQUE value (from approximately 55 to 3), as\nthe number of inference steps increases from 1 to 10. These\ndecreasing trends suggest an improvement in the naturalness\nand smoothness of the generated image, which contains the\nvirtual character and the corresponding background, while\nalso showing that GAI consumes more resources. By fitting\nthese data points, we obtain the relationship between the\ncomputation resources allocated to GAI and the quality of the\ngenerated digital content, as the blue curves show. Hence, we\nuse them as \u03c2tv (\u00b7) and \u03c2brq (\u00b7) for subsequent analysis.\nC. Incentive Mechanism Analysis\n1) Pricing Strategy Generation: Using the obtained \u03c2s (\u00b7),\n\u03c2tv (\u00b7), and \u03c2brq (\u00b7), we analyze the optimal pricing strategy\ngenerated by diffusion model and compare it with two deep re-\ninforcement learning (DRL) algorithms, i.e., Soft Actor-Critic\n(SAC) [44] and Proximal Policy Optimization (PPO) [45].\nThe PPO realizes optimization by using a clipped surrogate\nobjective to update the policy iteratively, which can provide\nsmooth policy changes. The SAC is an off-policy algorithm,\nwhich maximizes the expected cumulative reward and the\nentropy of the policy by learning a stochastic policy. During\n13\nGround truth  \nvia OpenPose\n5 APs\nPredicted with the \nproposed SMSP\nPredicted without the \nproposed SMSP\nThe number of AP\n4 APs\n3 APs\n2 APs\n1 AP\nFig. 9: The impact of AP quantity on skeleton prediction.\n0\n5\n10\n15\n20\n25\n30\n35\n40\n1 AP\n2 APs\n3 APs\n4 APs\n5 APs\nPerception accuracy\nThe number of AP involved in perception\nThe fitting result of the proposed method\nThe fitting result of work [42]\nFig. 10: The relation between the number of APs involved in perception and the perception performance.\n2 steps\n3 steps\n4 steps\n5 steps\n6 steps\n7 steps\n8 steps\n9 steps\nFig. 11: Impact of inference steps on virtual character generation.\nthe experiments, we assume that the VSP has a maximum of\n100 units of computational resources, with the processing of\nCSI data of a single AP consuming 2 units, the prediction of\nthe skeleton requiring 1 unit, and each inference step using 2\nunits.\nThe results in Fig. 14 show the achievable reward against\nthe training epoch of the proposed algorithm in comparison\nwith SAC and PPO. From the experimental results, it can\nbe observed that, under the preset number of epochs, the\nproposed algorithm has already converged, while SAC and\nPPO do not show a clear trend of convergence, indicating that\nthe proposed algorithm converges faster. Moreover, the reward\nof the proposed algorithm is about 1000, whereas DRL-SAC\nand DRL-PPO can achieve around 970 and 960, respectively,\nwhich is lower than that of the proposed algorithm. We believe\nthis is due to two main reasons. First, the proposed algorithm\nhas a better sampling quality, as the diffusion model can reduce\nthe influence of uncertainty and noise through multiple rounds\nof fine-tuning. Second, unlike traditional neural networks that\nonly consider the input at the current time step, the diffusion\nmodel can generate samples for more time steps by fine-\ntuning, providing a stronger processing capability for tasks\nwith long-term dependencies.\nUsing the trained models, we further compare the optimal\npricing strategy design capabilities of different models under\na given environment state. The results of this comparison are\npresented in Fig. 15. As can be seen from the figure, the\nstrategy generated by the proposed method (with Ib = 13\nand vr = 35) yields a user utility of 910, exceeding the\nutility of 787 and 737, which are achieved by DRL-SAC (with\nIb = 17 and vr = 43) and DRL-PPO (with Ib = 15 and\nvr = 46), respectively. A noteworthy detail is that the VSP\u2019s\n14\n20\n30\n40\n50\n60\n70\n80\n90\n100\n110\n0\n2\n4\n6\n8\n10\nTV\nInference steps\nFig. 12: The TV value versus the number of inference steps.\n0\n10\n20\n30\n40\n50\n60\n70\n0\n2\n4\n6\n8\n10\nBRISQUE)\nInference steps\nFig. 13: The BRISQUE value versus the number of inference\nsteps.\nutility provided by the optimal pricing strategy generated by\nthe diffusion model stands at 496, which is lower than 557\nand 626 achieved by SAC and PPO, respectively. We believe\nthat this trade-off is reasonable, as the pricing strategy aims\nto maximize the utility of the user while still incentivizing the\nVSP\u2019s participation.\n2) Impact of Perception on Incentive Mechanism: In some\npractical scenarios, the number of APs available for perception\nin the physical environment may be relatively limited. Hence,\nwe analyze the influence of the number of APs on the incentive\nmechanism. The results are presented in Fig. 16. As can be\nseen, when the total number of APs is relatively small, an\nincrease in the number of APs yields an enhancement in the\nutility of both the user and VSP, while vr and the total amount\nthat the user needs to pay are both decreasing. Specifically,\nwhen a single AP is involved in perception, the generated\noptimal pricing strategy is (Ib = 13, vr = 41), and the utility\nof the user and the VSP are 575 and 341, respectively.\nHowever, when the perception incorporates 6 APs, Ib increases\nto 17, vr falls to 34, and the utility of user and the VSP\nincrease to 1016 and 450, respectively.\nThis is because, when there are few APs involved in\nperception, the QoS of perception (i.e., Qs) is low, driving\nthe VSP to allocate more resources to the GAI. The aim\nof WiPe-GAI adopting this strategy is to enhance Qt by\nincreasing the number of inference steps, so as to maximize\nthe VSP\u2019s utility and guarantee its participation in service\n0\n500\n1000\n1500\n2000\n2500\nTraining Epoch\n900\n920\n940\n960\n980\n1000\n1020\nReward\nDRL-PPO\nDRL-SAC\nThe proposed\nFig. 14: The training curves, with the diffusion step of 10,\nbatch size of 512, soft target update parameter of 0.005,\ndiscount factor of 0.95, exploration noise of 0.01, and learning\nrate of 10\u22125.\n13\n17\n15\n35\n43\n46\n0\n170\n340\n510\n680\n850\n1020\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\n50\nThe proposed\nSAC\nPPO\nUtility\nContract Values\nI_b\nv_r\nUser\nVSP\nFig. 15: The generated optimal pricing strategy and the corre-\nsponding utility of user and the VSP.\nprovisioning. However, once the number of inference steps\nreaches a certain level, the rate of increase in Qt slows down,\nwhich forces the user to further increase vr to ensure the VSP\u2019s\nparticipation in service provision. Fortunately, as the number\nof APs gradually rises, the QoS improvement brought about\nby perception exceeds that of AIGC when consuming unit\nenergy. Consequently, the VSP reassigns some of the resources\ninitially allocated to GAI to perception, therefore maximizing\nits utility and ensuring its participation in service provision.\nFrom another perspective, this reallocation strategy not only\nreduces vr but also enhances the user utility, verifying the\nrationality of the generated optimal pricing strategy and further\nillustrates the effectiveness of the proposed framework.\nD. Discussion\nIn the experiments presented above, we conduct a com-\nprehensive evaluation of the proposed WiPe-GAI framework\nfrom perspectives of skeleton prediction, virtual character\n15\n13\n14\n15\n16\n17\n17\n41\n39\n37\n34\n35\n34\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\n0\n 170\n 340\n 510\n 680\n 850\n1020\n1190\n1\n2\n3\n4\n5\n6\nContract Values\nUtility\nThe number of AP involved in perception \nI_b\nv_r\nVSP\nUser\nFig. 16: The impact of the number of APs involved in\nperception on the utility of the user and VSP.\ngeneration, and incentive mechanism. From these results, we\ncan observe the following critical points:\n\u2022 The proposed SMSP algorithm utilizes the information\nabout user posture contained within CSI more effectively,\nthus enhancing the performance of user skeleton pre-\ndiction and, overall, outperforming the method without\nSMSP.\n\u2022 Using the predicted skeleton and user\u2019s requests, i.e.,\nprompts, WiPe-GAI can effectively generate the virtual\ncharacter and the corresponding background for the user,\nverifying the effectiveness of the proposed framework.\n\u2022 The proposed diffusion model based method can effi-\nciently generate the optimal pricing strategy, better than\nthe conventional DRL based methods in terms of maxi-\nmizing the user\u2019s utility and speed of convergence, while\nalso encouraging the VSP to actively participate in service\nprovision.\nBesides these achievements, the proposed WiPe-GAI has cer-\ntain limitations, which are summarized as follows:\n\u2022 The proposed SMSP improves the performance of CSI-\nbased skeleton prediction, but it may show unsatisfactory\nresults when fewer APs are available. One possible solu-\ntion to address this issue is to optimize the deployment of\nAPs, so that each AP can collect more non-overlapping\ninformation at different spatial locations for prediction .\n\u2022 This paper only uses image as examples of the generated\ndigital content. Yet, practical applications may require\nvideo streams to be produced for users. Given that video\ngeneration demands more resources, retraining the model\nmight be necessary. However, the framework and opti-\nmization strategies proposed in this paper should remain\neffective.\n\u2022 While the proposed diffusion based model demonstrates\nfaster convergence in optimal pricing strategy generation,\neach execution involves a multi-step denoising process,\nwhich may not be outstanding in terms of efficiency.\nConsidering the complexity of real-world applications,\nfurthe refining the efficiency of the proposed model is\nneeded.\nV. CONCLUSION\nThis paper introduces WiPe-GAI, a framework that com-\nbines wireless perception with GAI to provide the AIGC\nservice to users. For WiPe-GAI, we introduced a novel SMSP\nalgorithm, which uses CSI to predict the user\u2019s skeleton,\nthereby guiding the GAI to generate virtual characters for\nthe user. Furthermore, to encourage the VSP to participate in\nservice provision, WiPe-GAI builds an incentive mechanism\nbased on pricing and incorporates an new diffusion-based\nmethod to generate optimal pricing strategy, which maximizes\nuser\u2019s utility while ensuring the VSP\u2019s participation. Through\ncomprehensive experiments, it was demonstrated that WiPe-\nGAI can accurately predict the user\u2019s skeleton and generate\nthe corresponding virtual character for the user. Furthermore,\nthe proposed diffusion-based approach can effectively generate\nthe optimal pricing strategy, which not only yields greater\nuser utility, but also ensures that the VSP\u2019s participation,\noutperforming the existing DRL based methods. For future\nwork, we plan to refine the proposed framework by incorporat-\ning additional factors such as communication loss and multi-\nuser concurrency. Meanwhile, we will continue to explore the\napplication of optimization methods based on the diffusion\nmodel in various domains.\nREFERENCES\n[1] M. Xu, H. Du, D. Niyato, J. Kang, Z. Xiong, S. Mao, Z. Han,\nA. Jamalipour, D. I. Kim, X. Shen, V. Leung, and P. H. Vincent,\n\u201cUnleashing the power of edge-cloud generative ai in mobile networks:\nA survey of aigc services,\u201d arXiv preprint arXiv:2303.16129, 2023.\n[2] A. K\u00a8oksal, K. E. Ak, Y. Sun, D. Rajan, and J. H. Lim, \u201cControllable\nvideo generation with text-based instructions,\u201d IEEE Transactions on\nMultimedia, 2023.\n[3] J. Wu, W. Gan, Z. Chen, S. Wan, and H. Lin, \u201cAi-generated content\n(aigc): A survey,\u201d arXiv preprint arXiv:2304.06632, 2023.\n[4] Y. Cao, S. Li, Y. Liu, Z. Yan, Y. Dai, P. S. Yu, and L. Sun, \u201cA\ncomprehensive survey of ai-generated content (aigc): A history of\ngenerative ai from gan to chatgpt,\u201d arXiv preprint arXiv:2303.04226,\n2023.\n[5] F.-A. Croitoru, V. Hondru, R. T. Ionescu, and M. Shah, \u201cDiffusion\nmodels in vision: A survey,\u201d IEEE Transactions on Pattern Analysis\nand Machine Intelligence, 2023.\n[6] L. Zhang and M. Agrawala, \u201cAdding conditional control to text-to-image\ndiffusion models,\u201d arXiv preprint arXiv:2302.05543, 2023.\n[7] J. Wang, H. Du, D. Niyato, Z. Xiong, J. Kang, S. Mao, and X. Shen,\n\u201cGuiding AI-generated digital content with wireless perception,\u201d arXiv\npreprint arXiv:2303.14624, 2023.\n[8] S. Bond-Taylor, A. Leach, Y. Long, and C. G. Willcocks, \u201cDeep\ngenerative modelling: A comparative review of vaes, gans, normalizing\nflows, energy-based and autoregressive models,\u201d IEEE transactions on\npattern analysis and machine intelligence, 2021.\n[9] H. Du, Z. Li, D. Niyato, J. Kang, Z. Xiong, H. Huang, and S. Mao,\n\u201cGenerative AI-aided optimization for AI-generated content (aigc) ser-\nvices in edge networks,\u201d arXiv preprint arXiv:2303.13052, 2023.\n[10] X. Wang, L. Gao, S. Mao, and S. Pandey, \u201cCSI-based fingerprinting for\nindoor localization: A deep learning approach,\u201d IEEE transactions on\nvehicular technology, vol. 66, no. 1, pp. 763\u2013776, 2016.\n[11] S. Tan, J. Yang, and Y. Chen, \u201cEnabling fine-grained finger gesture\nrecognition on commodity WiFi devices,\u201d IEEE Transactions on Mobile\nComputing, vol. 21, no. 8, pp. 2789\u20132802, 2020.\n[12] C. R. Karanam and Y. Mostofi, \u201c3D through-wall imaging with\nunmanned aerial vehicles using wifi,\u201d in Proceedings of the 16th\nACM/IEEE International Conference on Information Processing in Sen-\nsor Networks, 2017, pp. 131\u2013142.\n[13] M. Zhao, Y. Tian, H. Zhao, M. A. Alsheikh, T. Li, R. Hristov, Z. Kabelac,\nD. Katabi, and A. Torralba, \u201cRF-based 3D skeletons,\u201d in Proceedings\nof the 2018 Conference of the ACM Special Interest Group on Data\nCommunication, 2018, pp. 267\u2013281.\n16\n[14] M. Zhao, T. Li, M. Abu Alsheikh, Y. Tian, H. Zhao, A. Torralba, and\nD. Katabi, \u201cThrough-wall human pose estimation using radio signals,\u201d\nin Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition, 2018, pp. 7356\u20137365.\n[15] C. Yang, X. Wang, and S. Mao, \u201cRFID-pose: Vision-aided three-\ndimensional human pose estimation with radio-frequency identification,\u201d\nIEEE transactions on reliability, vol. 70, no. 3, pp. 1218\u20131231, 2020.\n[16] L. Guo, Z. Lu, X. Wen, S. Zhou, and Z. Han, \u201cFrom signal to image:\nCapturing fine-grained human poses with commodity Wi-Fi,\u201d IEEE\nCommunications Letters, vol. 24, no. 4, pp. 802\u2013806, 2019.\n[17] Y. Zhou, H. Huang, S. Yuan, H. Zou, L. Xie, and J. Yang, \u201cMetaFi++:\nWiFi-enabled transformer-based human pose estimation for metaverse\navatar simulation,\u201d IEEE Internet of Things Journal, 2023.\n[18] F. Wang, S. Zhou, S. Panev, J. Han, and D. Huang, \u201cPerson-in-\nWiFi: Fine-grained person perception using wifi,\u201d in Proceedings of\nthe IEEE/CVF International Conference on Computer Vision, 2019, pp.\n5452\u20135461.\n[19] H. Du, R. Zhang, Y. Liu, J. Wang, Y. Lin, Z. Li, D. Niyato, J. Kang,\nZ. Xiong, S. Cui et al., \u201cBeyond deep reinforcement learning: A tutorial\non generative diffusion models in network optimization,\u201d arXiv preprint\narXiv:2308.05384, 2023.\n[20] J. Ho, C. Saharia, W. Chan, D. J. Fleet, M. Norouzi, and T. Salimans,\n\u201cCascaded diffusion models for high fidelity image generation.\u201d J. Mach.\nLearn. Res., vol. 23, no. 47, pp. 1\u201333, 2022.\n[21] Y. Ma, H. Yang, W. Wang, J. Fu, and J. Liu, \u201cUnified multi-modal latent\ndiffusion for joint subject and text conditional image generation,\u201d arXiv\npreprint arXiv:2303.09319, 2023.\n[22] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer, \u201cHigh-\nresolution image synthesis with latent diffusion models,\u201d in Proceedings\nof the IEEE/CVF Conference on Computer Vision and Pattern Recogni-\ntion, 2022, pp. 10 684\u201310 695.\n[23] J. Cheng, X. Liang, X. Shi, T. He, T. Xiao, and M. Li, \u201cLayoutdiffuse:\nAdapting foundational diffusion models for layout-to-image generation,\u201d\narXiv preprint arXiv:2302.08908, 2023.\n[24] Z. Wang, J. J. Hunt, and M. Zhou, \u201cDiffusion policies as an expres-\nsive policy class for offline reinforcement learning,\u201d arXiv preprint\narXiv:2208.06193, 2022.\n[25] H. Du, J. Wang, D. Niyato, J. Kang, Z. Xiong, and D. I. Kim, \u201cAI-\ngenerated incentive mechanism and full-duplex semantic communica-\ntions for information sharing,\u201d arXiv preprint arXiv:2303.01896, 2023.\n[26] N. C. Luong, P. Wang, D. Niyato, Y.-C. Liang, Z. Han, and F. Hou,\n\u201cApplications of economic and pricing models for resource management\nin 5G wireless networks: A survey,\u201d IEEE Communications Surveys &\nTutorials, vol. 21, no. 4, pp. 3298\u20133339, 2018.\n[27] Z. Zhao, W. Zhou, D. Deng, J. Xia, and L. Fan, \u201cIntelligent mobile edge\ncomputing with pricing in internet of things,\u201d IEEE Access, vol. 8, pp.\n37 727\u201337 735, 2020.\n[28] B. Qian, H. Zhou, T. Ma, K. Yu, Q. Yu, and X. Shen, \u201cMulti-\noperator spectrum sharing for massive iot coexisting in 5G/B5G wireless\nnetworks,\u201d IEEE Journal on Selected Areas in Communications, vol. 39,\nno. 3, pp. 881\u2013895, 2020.\n[29] Y. Yang, Z. Liu, Z. Liu, K. Y. Chan, Y. Xie, and X. Guan, \u201cJoint\noptimization of edge computing resource pricing and wireless caching\nfor blockchain-driven networks,\u201d IEEE Transactions on Vehicular Tech-\nnology, vol. 71, no. 6, pp. 6661\u20136670, 2022.\n[30] B. Qian, H. Zhou, T. Ma, Y. Xu, K. Yu, X. Shen, and F. Hou,\n\u201cLeveraging dynamic stackelberg pricing game for multi-mode spectrum\nsharing in 5G-VANET,\u201d IEEE Transactions on Vehicular Technology,\nvol. 69, no. 6, pp. 6374\u20136387, 2020.\n[31] Z. Yang, Z. Zhou, and Y. Liu, \u201cFrom rssi to csi: Indoor localization via\nchannel response,\u201d ACM Computing Surveys (CSUR), vol. 46, no. 2, pp.\n1\u201332, 2013.\n[32] M. Kotaru, K. Joshi, D. Bharadia, and S. Katti, \u201cSpotfi: Decimeter level\nlocalization using wifi,\u201d in Proceedings of the 2015 ACM Conference\non Special Interest Group on Data Communication, 2015, pp. 269\u2013282.\n[33] M. Wax and T. Kailath, \u201cDetection of signals by information theoretic\ncriteria,\u201d IEEE Transactions on acoustics, speech, and signal processing,\nvol. 33, no. 2, pp. 387\u2013392, 1985.\n[34] D. Vasisht, S. Kumar, and D. Katabi, \u201cDecimeter-Level localization with\na single WiFi access point,\u201d in 13th USENIX Symposium on Networked\nSystems Design and Implementation (NSDI 16), 2016, pp. 165\u2013178.\n[35] D. Zhang, F. Zhang, D. Wu, J. Xiong, and K. Niu, \u201cFresnel zone based\ntheories for contactless sensing,\u201d Contactless Human Activity Analysis,\npp. 145\u2013164, 2021.\n[36] Y. Zeng, J. Liu, J. Xiong, Z. Liu, D. Wu, and D. Zhang, \u201cExploring\nmultiple antennas for long-range WiFi sensing,\u201d Proceedings of the ACM\non Interactive, Mobile, Wearable and Ubiquitous Technologies, vol. 5,\nno. 4, pp. 1\u201330, 2021.\n[37] Z. Cao, G. Hidalgo, T. Simon, S.-E. Wei, and Y. Sheikh, \u201cOpenPose:\nrealtime multi-person 2d pose estimation using part affinity fields,\u201d IEEE\ntransactions on pattern analysis and machine intelligence, vol. 43, no. 1,\npp. 172\u2013186, 2021.\n[38] K. He, X. Zhang, S. Ren, and J. Sun, \u201cDeep residual learning for image\nrecognition,\u201d in Proceedings of the IEEE conference on computer vision\nand pattern recognition, 2016, pp. 770\u2013778.\n[39] S. Ioffe and C. Szegedy, \u201cBatch normalization: Accelerating deep\nnetwork training by reducing internal covariate shift,\u201d in International\nconference on machine learning.\npmlr, 2015, pp. 448\u2013456.\n[40] A. Krizhevsky, I. Sutskever, and G. E. Hinton, \u201cImagenet classification\nwith deep convolutional neural networks,\u201d Communications of the ACM,\nvol. 60, no. 6, pp. 84\u201390, 2017.\n[41] D. Li, J. Li, and S. C. Hoi, \u201cBlip-diffusion: Pre-trained subject repre-\nsentation for controllable text-to-image generation and editing,\u201d arXiv\npreprint arXiv:2305.14720, 2023.\n[42] F. Gringoli, M. Schulz, J. Link, and M. Hollick, \u201cFree your CSI: A\nchannel state information extraction platform for modern wi-fi chipsets,\u201d\nin Proceedings of the 13th International Workshop on Wireless Network\nTestbeds, Experimental Evaluation & Characterization, 2019, pp. 21\u201328.\n[43] F. Wang, S. Panev, Z. Dai, J. Han, and D. Huang, \u201cCan WiFi estimate\nperson pose?\u201d arXiv preprint arXiv:1904.00277, 2019.\n[44] T. Haarnoja, A. Zhou, P. Abbeel, and S. Levine, \u201cSoft actor-critic: Off-\npolicy maximum entropy deep reinforcement learning with a stochastic\nactor,\u201d in International conference on machine learning.\nPMLR, 2018,\npp. 1861\u20131870.\n[45] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, \u201cProx-\nimal policy optimization algorithms,\u201d arXiv preprint arXiv:1707.06347,\n2017.\n",
    "2303.04226": "111\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\nYIHAN CAO\u2217, Lehigh University & Carnegie Mellon University, USA\nSIYU LI, Lehigh University, USA\nYIXIN LIU, Lehigh University, USA\nZHILING YAN, Lehigh University, USA\nYUTONG DAI, Lehigh University, USA\nPHILIP S. YU, University of Illinois at Chicago, USA\nLICHAO SUN, Lehigh University, USA\nRecently, ChatGPT, along with DALL-E-2 [1] and Codex [2],has been gaining significant attention from society.\nAs a result, many individuals have become interested in related resources and are seeking to uncover the\nbackground and secrets behind its impressive performance. In fact, ChatGPT and other Generative AI (GAI)\ntechniques belong to the category of Artificial Intelligence Generated Content (AIGC), which involves the\ncreation of digital content, such as images, music, and natural language, through AI models. The goal of\nAIGC is to make the content creation process more efficient and accessible, allowing for the production of\nhigh-quality content at a faster pace. AIGC is achieved by extracting and understanding intent information\nfrom instructions provided by human, and generating the content according to its knowledge and the intent\ninformation. In recent years, large-scale models have become increasingly important in AIGC as they provide\nbetter intent extraction and thus, improved generation results. With the growth of data and the size of the\nmodels, the distribution that the model can learn becomes more comprehensive and closer to reality, leading\nto more realistic and high-quality content generation. This survey provides a comprehensive review on the\nhistory of generative models, and basic components, recent advances in AIGC from unimodal interaction and\nmultimodal interaction. From the perspective of unimodality, we introduce the generation tasks and relative\nmodels of text and image. From the perspective of multimodality, we introduce the cross-application between\nthe modalities mentioned above. Finally, we discuss the existing open problems and future challenges in AIGC.\nCCS Concepts: \u2022 Computer systems organization \u2192Embedded systems; Redundancy; Robotics; \u2022 Net-\nworks \u2192Network reliability.\nAdditional Key Words and Phrases: datasets, neural networks, gaze detection, text tagging\nACM Reference Format:\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun. 2018. A Comprehensive\nSurvey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT. J. ACM 37, 4,\nArticle 111 (August 2018), 44 pages. https://doi.org/XXXXXXX.XXXXXXX\n\u2217Incoming Ph.D. student at Lehigh University.\nAuthors\u2019 addresses: Yihan Cao, yihanc@andrew.cmu.edu, Lehigh University & Carnegie Mellon University, Pittsburgh, PA,\nUSA; Siyu Li, applicantlisiyu@hotmail.com, Lehigh University, Bethlehem, PA, USA; Yixin Liu, lis221@lehigh.edu, Lehigh\nUniversity, Bethlehem, PA, USA; Zhiling Yan, zhilingyan724@outlook.com, Lehigh University, Bethlehem, PA, USA; Yutong\nDai, lis221@lehigh.edu, Lehigh University, Bethlehem, PA, USA; Philip S. Yu, University of Illinois at Chicago, Chicago,\nIllinois, USA, psyu@uic.edu; Lichao Sun, lis221@lehigh.edu, Lehigh University, Bethlehem, PA, USA.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\nthe full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\nprior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\u00a9 2018 Association for Computing Machinery.\n0004-5411/2018/8-ART111 $15.00\nhttps://doi.org/XXXXXXX.XXXXXXX\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\narXiv:2303.04226v1  [cs.AI]  7 Mar 2023\n111:2\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\n1\nINTRODUCTION\nIn recent years, Artificial Intelligence Generated Content (AIGC) has gained much attention beyond\nthe computer science community, where the whole society begins to be interested in the various\ncontent generation products built by large tech companies [3], such as ChatGPT [4] and DALL-E-\n2 [5]. AIGC refers to content that is generated using advanced Generative AI (GAI) techniques, as\nopposed to being created by human authors, which can automate the creation of large amounts\nof content in a short amount of time. For example, ChatGPT is a language model developed by\nOpenAI for building conversational AI systems, which can efficiently understand and respond to\nhuman language inputs in a meaningful way. In addition, DALL-E-2 is another state-of-the-art GAI\nmodel also developed by OpenAI, which is capable of creating unique and high-quality images\nfrom textual descriptions in a few minutes, such as \"an astronaut riding a horse ina photorealistic\nstyle\" as shown in Figure 1. As the remarkable achievements in AIGC, many people believe it will\nbe the new era of AI and make significant impacts on the whole world.\nInstruction 2:\nTeddy bears working on \nnew AI research on the \nmoon in the 1980s.\nDALL\u00b7E 2\nInstruction 1:\nAn astronaut riding a \nhorse in a photorealistic \nstyle.\nFigure 1\nFigure 2\nFig. 1. Examples of AIGC in image generation. Text instructions are given to OpenAI DALL-E-2 model, and it\ngenerates two images according to the instructions.\nTechnically, AIGC refers to, given human instructions which could help teach and guide the model\nto complete the task, utilizing GAI algorithms to generate content that satisfies the instruction.\nThis generation process usually consists of two steps: extracting intent information from human\ninstructions and generating content according to the extracted intentions. However, the paradigm\nof GAI models containing the above two steps is not entirely novel, as demonstrated by previous\nstudies [6, 7]. The core advancements in recent AIGC compared to prior works are the result of\ntraining more sophisticated generative models on larger datasets, using larger foundation model\narchitectures, and having access to extensive computational resources. For example, the main\nframework of GPT-3 maintains the same as GPT-2, but the pre-training data size grows from\nWebText [8](38GB) to CommonCrawl [9](570GB after filtering), and the foundation model size\ngrows from 1.5B to 175B. Therefore, GPT-3 has better generalization ability than GPT-2 on various\ntasks, such as human intent extraction.\nIn addition to the benefits brought by the increase in data volume and computational power,\nresearchers are also exploring ways to integrate new technologies with GAI algorithms. For example,\nChatGPT utilizes reinforcement learning from human feedback (RLHF) [10\u201312] to determine the\nmost appropriate response for a given instruction, thus improving model\u2019s reliability and accuracy\nover time. This approach allows ChatGPT to better understand human preferences in long dialogues.\nMeanwhile, in computer vision, stable diffusion [13], proposed by Stability.AI in 2022, has also\nshown great success in image generation. Unlike prior methods, generative diffusion models\ncan help generate high-resolution images by controlling the trade-off between exploration and\nexploitation, resulting in a harmonious combination of diversity in the generated images and\nsimilarity to the training data.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:3\nUnimodal\nMultimodal\nData\nGenerative AI Models\nGenerative AI Models\nPre-train\nData\nPre-train\nPlease write a \nstory about a cat.\nOnce upon a time, \nthere was a cat \nnamed \nJessy\u2026.\nPrompt\nDecode\nDescribe this \npicture.\nDraw a picture\nof a cat.\nInstruction \ud835\udc3c!\nResult \ud835\udc45!\nInstruction \ud835\udc3c\"\nInstruction \ud835\udc3c#\nInstruction \ud835\udc3c$\nWrite a song \nabout a cat.\nPrompt\nPrompt\nPrompt\nResult \ud835\udc45\"\nResult \ud835\udc45#\nResult \ud835\udc45$\nThis is a cat.\nFig. 2. Overview of AIGC. Generally, GAI models can be categorized into two types: unimodal models and\nmultimodal models. Unimodal models receive instructions from the same modality as the generated content\nmodality, whereas multimodal models accept cross-modal instructions and produce results of different\nmodalities.\nBy combining these advancements, models have made significant progress in AIGC tasks and\nhave been adopted in various industries, including art [14], advertising [15], and education [16]. In\nthe near future, AIGC will continue to be a significant area of research in machine learning. It is\ntherefore crucial to conduct an extensive review of past research and identify the open problems in\nthis field. This survey is the first one that focuses on the core technologies and applications in the\nfield of AIGC.\n1.1\nMajor Contributions\nThis is the first comprehensive survey of AIGC that summarizes GAI in the aspects of techniques\nand applications. Previous surveys have focused on GAI from various angles, including natural\nlanguage generation [17], image generation[18], generation in multimodal machine learning [7, 19].\nHowever, these prior works only focus on a specific part of AIGC. In this survey, we first provide\na review of foundation techniques commonly used in AIGC. Then, we further offer a thorough\nsummary of advanced GAI algorithms, both in terms of unimodal generation and multimodal\ngeneration, as shown in Figure 2. In addition, we examine the applications and potential challenges\nof AIGC. Finally, we highlight the open problems and future directions in this field. In summary,\nthe main contributions of this paper are as follows:\n\u2022 To our best knowledge, we are the first to provide a formal definition and a thorough survey\nfor AIGC and AI-enhanced generation process.\n\u2022 We review the history, foundation techniques of AIGC and conduct a comprehensive analysis\nof recent advances in GAI tasks and models from the perspective of unimodal generation\nand multimodal generation.\n\u2022 We discuss the main challenges facing AIGC and future research trends confronting AIGC.\n1.2\nOrganization\nThe rest of the survey is organized as follows. Section 2 reviews the history of AIGC mainly from\nthe view of vision and language modalities. Section 3 introduces the basic components that are\nwidely used in nowadays GAI model training. Section 4 summarizes recent advances of GAI models,\namong which, Section 4.1 reviews the advances from unimodal perspective and Section 4.2 reviews\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:4\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nthe advances from the perspective of multimodal generation. Among multimodal generation, we\nintroduce vision language models, text audio models, text graph models and text code models.\nSection 5 and Section 6 introduce the applications of GAI models in AIGC and some other important\nresearch that are related to this area. Furthermore, Sections 7, 8 reveal the risk, open problems and\nfuture directions of AIGC technologies. Finally, we conclude our research in 9.\n2\nHISTORY OF GENERATIVE AI\nGenerative models have a long history in artificial intelligence, dating back to the 1950s with the\ndevelopment of Hidden Markov Models (HMMs) [20] and Gaussian Mixture Models (GMMs) [21].\nThese models generated sequential data such as speech and time series. However, it wasn\u2019t until\nthe advent of deep learning that generative models saw significant improvements in performance.\nIn early years of deep generative models, different areas do not have much overlap in general.\nIn natural language processing (NLP), a traditional method to generate sentences is to learn\nword distribution using N-gram language modeling [22] and then search for the best sequence.\nHowever, this method cannot effectively adapt to long sentences. To solve this problem, recurrent\nneural networks (RNNs) [23] were later introduced for language modeling tasks , allowing for\nmodeling relatively long dependency. This was followed by the development of Long Short-Term\nMemory (LSTM) [24] and Gated Recurrent Unit (GRU) [25], which leveraged gating mechanism to\ncontrol memory during training. These methods are capable of attending to around 200 tokens in a\nsample [26], which marks a significant improvement compared to N-gram language models.\nMeanwhile, in computer vision (CV), before the advent of deep learning-based methods, tra-\nditional image generation algorithms used techniques such as texture synthesis [27] and texture\nmapping [28]. These algorithms were based on hand-designed features, and were limited in their abil-\nity to generate complex and diverse images. In 2014, Generative Adversarial Networks (GANs) [29]\nwas first proposed, which was a significant milestone in this area, due to its impressive results\nin various applications. Variational Autoencoders (VAEs) [30] and other methods like diffusion\ngenerative models [31] have also been developed for more fine-grained control over the image\ngeneration process and the ability to generate high-quality images.\nThe advancement of generative models in various domains has followed different paths, but\neventually, the intersection emerged: the transformer architecture [32]. Introduced by Vaswani et\nal. for NLP tasks in 2017, Transformer has later been applied in CV and then become the dominant\nbackbone for many generative models in various domains [9, 33, 34]. In the field of NLP, many\nprominent large language models, e.g., BERT and GPT, adopt the transformer architecture as\ntheir primary building block, offering advantages over previous building blocks, i.e., LSTM and\nGRU. In CV, Vision Transformer (ViT) [35] and Swin Transformer [36] later takes this concept\neven further by combining the transformer architecture with visual components, allowing it to\nbe applied to image based downstreams. Except for the improvement that transformer brought\nto individual modalities, this intersection also enabled models from different domains to be fused\ntogether for multimodal tasks. One such example of multimodal models is CLIP [37]. CLIP is a\njoint vision-language model that combines the transformer architecture with visual components,\nallowing it to be trained on a massive amount of text and image data. Since it combines visual\nand language knowledge during pre-training, it can also be used as image encoders in multimodal\nprompting for generation. In all, the emergence of transformer based models revolutionized AI\ngeneration and led to the possibility of large-scale training.\nIn recent years, researchers have also begun to introduce new techniques based on these models.\nFor instance, in NLP, instead of fine-tuning, people sometimes prefer few-shot prompting [38],\nwhich refers to including a few examples selected from the dataset in the prompt, to help the\nmodel better understand task requirements. And in visual language, researchers often combine\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:5\n2014\n2020\n2018\n2016\nNLP\nN-Gram\nNLP\nLSTM/GRU\nNLP\nTransformer\nNLP\nNLP\nNLP\nCV\nStyleGAN \nBigBiGAN\nDDPM \nViT\nMoCo\nBiGAN\nRevNet\nShow-Tell\nDALL-E\nBLIP2\nDALL-E 2\nCV\nCV\nCV\nVL\nVL\nVL\nVisualBERT\nViLBERT\nUNITER\nVL\nVL\nUnimodal- CV & NLP\nMultimodal \u2013 Vision Language\nCLIP\nALBEF\nBLIP\nVQ-GAN\nVL\nGAN \nVAE\nFlow\nELMO \nBERT \nGPT-2\nStyleNet\nStackGAN\nCAVP\nDMGAN\nVQ-VAE\nSparrow \nchatGPT\nGPT-3 \nOPT \nBART \nT5\nFig. 3. The history of Generative AI in CV, NLP and VL.\nmodality-specific models with self-supervised contrastive learning objectives to provide more\nrobust representations.\nIn the future, as AIGC becomes increasingly important, more and more technologies shall be\nintroduced, empowering this area with vitality.\n3\nFOUNDATIONS FOR AIGC\nIn this section, we introduce foundation models that are commonly used in AIGC.\n3.1\nFoundation Model\n3.1.1\nTransformer. Transformer is the backbone architecture for many state-of-the-art models,\nsuch as GPT-3 [9], DALL-E-2 [5], Codex [2], and Gopher [39]. It was first proposed to solve the\nlimitations of traditional models such as RNNs in handling variable-length sequences and context-\nawareness. Transformer architecture is mainly based on a self-attention mechanism that allows\nthe model to attend to different parts in a input sequence. Transformer consists of an encoder and\na decoder. The encoder takes in the input sequence and generates hidden representations, while\nthe decoder takes in the hidden representation and generates output sequence. Each layer of the\nencoder and decoder consists of a multi-head attention and a feed-forward neural network. The\nmulti-head attention is the core component of Transformer, which learns to assign different weights\nto tokens according their relevance. This information routing method allows the model to be better\nat handling long term dependency, hence, improving the performance in a wide range of NLP tasks.\nAnother advantage of transformer is that its architecture makes it highly parallelizable, and allows\ndata to trump inductive biases [40]. This property makes transformer well-suited for large-scale\npre-training, enabling transformer based models to become adaptable to different downstream\ntasks.\n3.1.2\nPre-trained Language Models. Since the introduction of the Transformer architecture, it has\nbecome the dominant choice in natural language processing due to its parallelism and learning\ncapabilities. Generally, these transformer based pre-trained language models can be commonly\nclassified into two types based on their training tasks: autoregressive language modeling and\nmasked language modeling [41]. Given a sentence, which is composed of several tokens, the\nobjective of masked language modeling, e.g., BERT [42] and RoBERTa [43], refers to predicting the\nprobability of a masked token given context information. The most notable example of masked\nlanguage modeling is BERT [42], which includes masked language modeling and next sentence\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:6\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nDecoder (GPT)\n\ud835\udc38!\n\ud835\udc38\"\n\ud835\udc38#\nTrm\nTrm\nTrm\nTrm\nTrm\nTrm\n\ud835\udc47!\n\ud835\udc47\"\n\ud835\udc47#\n\u2026\n\u2026\n\u2026\n\u2026\n\ud835\udc38!\n\ud835\udc38\"\n\ud835\udc38#\nTrm\nTrm\nTrm\nTrm\nTrm\nTrm\n\ud835\udc47!\n\ud835\udc47\"\n\ud835\udc47#\n\u2026\n\u2026\n\u2026\n\u2026\nEncoder (BERT)\n\ud835\udc38!\n\ud835\udc38\"\n\ud835\udc38#\n\u2026\nTrm\nTrm\nTrm\n\u2026\nTrm\nTrm\nTrm\n\u2026\nTrm\nTrm\nTrm\n\u2026\n\ud835\udc47!\n\ud835\udc47\"\n\ud835\udc47#\n\u2026\nEncoder-Decoder (T5/BART)\nFig. 4. Categories of pre-trained LLMs. Black line represents information flow in bidirectional models, while\ngray line representas left-to-right information flow. Encoder models, e.g. BERT, are trained with context-aware\nobjectives. Decoder models, e.g. GPT, are trained with autoregressive objectives. Encoder-decoder models, e.g.\nT5 and BART, combines the two, which use context-aware structures as encoders and left-to-right structures\nas decoders.\nprediction tasks. RoBERTa [43], which uses the same architecture as BERT, improves its performance\nby increasing the amount of pre-training data and incorporating more challenging pre-training\nobjectives. XL-Net [44], which is also based on BERT, incorporates permutation operations to change\nthe prediction order for each training iteration, allowing the model to learn more information\nacross tokens. While autoregressive language modeling, e.g., GPT-3 [9] and OPT [45], is to model\nthe probability of the next token given previous tokens, hence, left-to-right language modeling.\nDifferent from masked language models, autoregressive models are more suitable for generative\ntasks. We will introduce more about autoregressive models in Section 4.1.1.\n3.2\nReinforcement Learning from Human Feedback\nDespite being trained on large-scale data, the AIGC may not always produce output that aligns\nwith the user\u2019s intent, which includes considerations of usefulness and truthfulness. In order to\nbetter align AIGC output with human preferences, reinforcement learning from human feedback\n(RLHF) has been applied to fine-tune models in various applications such as Sparrow, InstructGPT,\nand ChatGPT [10, 46].\nTypically, the whole pipeline of RLHF includes the following three steps: pre-training, reward\nlearning, and fine-tuning with reinforcement learning. First, a language model \ud835\udf030 is pre-trained\non large-scale datasets as an initial language model. Since the (prompt-answer) pair given by \ud835\udf030\nmight not align with human purposes, in the second step we train a reward model to encode\nthe diversified and complex human preference. Specifically, given the same prompt \ud835\udc65, different\ngenerated answers {\ud835\udc661,\ud835\udc662, \u00b7 \u00b7 \u00b7 ,\ud835\udc663} are evaluated by humans in a pairwise manner. The pairwise\ncomparison relationships are later transferred to pointwise reward scalars, {\ud835\udc5f1,\ud835\udc5f2, \u00b7 \u00b7 \u00b7 ,\ud835\udc5f3}, using\nan algorithm such as ELO [47]. In the final step, the language model \ud835\udf03is fine-tuned to maximize\nthe learned reward function using reinforcement learning. To stabilize the RL training, Proximal\nPolicy Optimization (PPO) is often used as the RL algorithm. In each episode of RL training,\nan empirically-estimated KL penalty term is considered to prevent the model from outputting\nsomething peculiar to trick the reward model. Specifically, the total reward \ud835\udc5f\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59at each step is\ngiven by \ud835\udc5f\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59(\ud835\udc65,\ud835\udc66) = \ud835\udc5f\ud835\udc45\ud835\udc40(\ud835\udc65,\ud835\udc66) \u2212\ud835\udf06KL\ud835\udc37KL\n\u0000\ud835\udf0b\ud835\udf03|\ud835\udf0b\ud835\udf030\n\u0001, where \ud835\udc5f\ud835\udc45\ud835\udc40is the learned reward model, \ud835\udc37KL\nis the KL penalty term, and \ud835\udf0b\u00b7 is the trained policy. For more details on RLHF, please refer to [48].\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:7\n#Parameters\nTraining Speed (based on V100 16G)\n100M\n1B\n10B\n1T\n100B\n2018\n2019\n2020\n2021\n2022\nGPT\nBERT\nGPT-2\nT5\nGPT-3\nMegatron\nRoBERTa\nERNIE\nBART\nSwitch\nPaLM\nBLOOM\n2023\nChatGPT\nDALL-E-2\nVisualBERT\nCLIP\nGLIDE\nImagen\n1x\n3x\n5x\n7x\n9x\nRTX \n8000\nRTX\n4090\nA100\n40G\nV100\n16G\nRTX\n3090\nA100\n80G\nH100\n80G Gen5\nDALL-E\nH100\n80G SXM5\nFig. 5. Statistics of model size [52] and training speed 1across different models and computing devices.\nAlthough RLHF has shown promising results by incorporating fluency, progress in this field is\nimpeded by a lack of publicly available benchmarks and implementation resources, leading to a\nperception that RL is a challenging approach for NLP. To address this issue, an open-source library\nnamed RL4LMs [49] has recently been introduced, consisting of building blocks for fine-tuning\nand evaluating RL algorithms on LM-based generation.\nBeyond human feedback, the latest dialogue agent, Claude, favors Constitutional AI [50], where\nthe reward model is learned via RL from AI Feedback (RLAIF). Both the critiques and the AI\nfeedback are guided by a small set of principles drawn from a \u201cconstitution\u201d, which is the only\nthing provided by humans in Claude. The AI feedback focuses on controlling the outputs to be\nless harmful by explaining its objections to dangerous queries. Moreover, recently a preliminary\ntheoretical analysis of the RLAIF [51] justifies the empirical success of RLHF and provides new\ninsights for specialized RLHF algorithm design for language models.\n3.3\nComputing\n3.3.1\nHardware. In recent years, there have been significant hardware advancements that have\nfacilitated the training of large-scale models. In the past, training a large neural network using\nCPUs could take several days or even weeks. However, with the emergence of more powerful\ncomputing resources, this process has been accelerated by several orders of magnitude. For instance,\nthe NVIDIA A100 GPU achieves seven times faster during BERT-large inference compared to the\nV100 and 11 times faster than the T42. Additionally, Google\u2019s Tensor Processing Units (TPUs), which\nare designed specifically for deep learning, offer even higher computing performance compared to\nthe current generation of A100 GPUs3. This rapid progress in computing power has significantly\nincreased the efficiency of AI model training and opened up new possibilities for developing large\nand complex models.\n3.3.2\nDistributed training. Another significant improvement is distributed training. In traditional\nmachine learning, training is typically performed on a single machine using a single processor.\nThis approach can work well for small datasets and models, but it becomes impractical when\n1https://lambdalabs.com/gpu-benchmarks\n2https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-nvidia-us-2188504-\nweb.pdf\n3https://cloud.google.com/blog/products/ai-machine-learning/google-wins-mlperf-benchmarks-with-tpu-v4\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:8\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\ndealing with large datasets and complex models. In distributed training, the training workload is\nsplit among multiple processors or machines, allowing the model to be trained much faster. Some\ncompanies have also released frameworks that simplify the process of distributed training on deep\nlearning stacks [53\u201355]. These frameworks provide tools and APIs that allow developers to easily\ndistribute their training workloads across multiple processors or machines, without having to\nmanage the underlying infrastructure.\n3.3.3\nCloud computing. Cloud computing has also played a vital role in training large-scale models.\nPreviously, models are often trained locally. Now with the cloud computing services like AWS\nand Azure providing access to powerful computing resources, deep learning researchers and\npractitioners could spin up large clusters of GPUs or TPUs as needed for training large-scale models.\nOverall, these advancements have enabled the development of more complex and accurate models,\nunlocking new possibilities in various areas of AI research and applications.\n4\nGENERATIVE AI\n4.1\nUnimodal Models\nIn this section, we will introduce state-of-the-art unimodal generative models. These models\nare designed to accept a specific raw data modality as input, such as text or images, and then\ngenerate predictions in the same modality as the input. We will discuss some of the most promising\napproaches and techniques used in these models, including generative language models, e.g., GPT-\n3 [9], BART [34], T5 [56], and generative vision models, e.g., GAN [29], VAE [30], and normalizng\nflow [57].\n4.1.1\nGenerative Language Models. Generative language models (GLMs) are a type of NLP models\nthat are trained to generate readable human language based on patterns and structures in input\ndata that they have been exposed to. These models can be used for a wide range of NLP tasks such\nas dialogue systems [58], , translation [59] and question answering [60].\nRecently, The use of pre-trained language models has emerged as the prevailing technique\nin the domain of NLP. Generally, current state-of-the-art pre-trained language models could be\ncategorized as masked language models (encoders), autoregressive language models (decoders)\nand encoder-decoder language models, as shown in Figure 4. Decoder models are widely used for\ntext generation, while encoder models are mainly applied to classification tasks. By combining\nthe strengths of both structures, encoder-decoder models can leverage both context information\nand autoregressive properties to improve performance across a variety of tasks. The primary\nfocus of this survey is on generative models. In the following sections, we will delve into recent\nadvancements in decoder and encoder-decoder architectures.\nDecoder Models. One of the most prominent examples of autoregressive decoder-based language\nmodels is GPT [61], which is a transformer-based model that utilizes self-attention mechanisms to\nprocess all words in a sequence simultaneously. GPT is trained on next word prediction task based\non previous words, allowing it to generate coherent text. Subsequently, GPT-2 [62] and GPT-3 [9]\nmaintains the autoregressive left-to-right training method, while scaling up model parameters and\nleveraging diverse datasets beyond basic web text, achieving state-of-the-art results on numerous\ndatasets. Gopher [39] uses a GPT-like structure but replace LayerNorm [63] with RSNorm, where\na residual connection is added to the original layernorm structure to maintain the information.\nIn addition to enhancing the normalization function, several other studies have concentrated on\noptimizing the attention mechanism. BLOOM [64] shares the same structure as GPT-3 but instead\nof using sparse attention, BLOOM uses a full attention network, which is better suited for modeling\nlong dependencies. [65] proposes Megatron, which extends commonly used architectures like\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:9\nFig. 6. The architecture of InstructGPT [10]. First, demonstration data are collected with human labelers\nand is used to fine-tune GPT-3. Then prompts and corresponding answers are sampled from the language\nmodel and human labelers will rank the answers from best to worst. This data is used to train a reward model.\nFinally, with the trained reward model, the language model could be optimized according to the preference\nof human labelers.\nGPT-3, BERT and T5 with distributed training objectives to process large amount of data. This\nmethod is also later adopted by MT-NLG [66] and OPT [45]. Except for the advancements in model\narchitecture and pre-training tasks, there has also been significant efforts put into improving\nthe fine-tuning process for language models. For example, InstructGPT [10] takes advantage of\npre-trained GPT-3 and uses RLHF for fine-tuning, allowing the model to learn preference according\nto ranking feedback labeled by human.\nEncoder-Decoder Models. One of the main encoder-decoder methods is Text-to-Text Transfer\nTransformer (T5) [56], which combines transformer-based encoders and decoders together for\npre-training. T5 employs a \"text-to-text\" approach, which means that it transforms both the input\nand output data into a standardized text format. This allows T5 to be trained on a wide range\nof NLP tasks, such as machine translation, question-answering, summarization, and more, using\nthe same model architecture. Switch Transformer [67], as stated in its name, utilizes \"switching\",\nwhich refers to a simplified MoE routing algorithm, for parallelized training on T5. This model\nsuccessfully obtained larger scale and better performance with the same computational resources\ncompared to the base model. Another widely-used method that improves upon T5 is ExT5 [68],\nwhich is proposed by Google in 2021, extending the scale of previous T5 model. Compared to T5,\nExT5 is continue pre-trained on C4 and ExMix, which is a combinition of 107 supervised NLP\ntasks across diverse domains. Another widely used encoder-decoder method is BART [34], which\nblends the bidirectional encoder from BERT and the autoregressive decoder from GPT, allowing it\nto leverage the bidirectional modeling abilities of the encoder while retaining the autoregressive\nproperties for generation tasks. HTLM [69] leverages BART denoising objectives for modeling\nhyper-text language, which contains valuable information regarding document-level structure. This\nmodel also achieves state-of-the-art performance on zero-shot learning on various generation tasks.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:10\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nFig. 7. Categories of vision generative models.\nWhile DQ-BART [70], instead, aims at compressing BART into a smaller model using distillation\nand quantization, which achieves the BART original performance on various downstream tasks.\n4.1.2\nVision Generative Models.\nGAN. Generative Adversarial Networks (GANs) have gained popularity in the field of image\ngeneration research. GANs consist of two parts, a generator and a discriminator. The generator\nattempts to learn the distribution of real examples in order to generate new data, while the\ndiscriminator determines whether the input is from the real data space or not.\nStructure. The structure of the generator and the discriminator highly influence GAN\u2019s training\nstability and performance. LAPGAN [71] generates high-quality images in a coarse-to-fine fashion\nusing a cascade of convolutional networks within a Laplacian pyramid framework [72]. A. Radford\net al. [73] propose DCGANs structure, a class of CNNs with architectural constraints, as a powerful\nsolution for unsupervised learning. Progressive GAN [74] progressively grows the generator and\ndiscriminator, starting from low resolution and adding layers to model finer details, resulting in faster\nand more stable training and producing high-quality images. As traditional convolutional GANs\ngenerate high-resolution details based only on spatially local points in lower-resolution feature\nmaps, SAGAN [75] introduces attention-driven, long-range dependency modeling and spectral\nnormalization for improved training dynamics. In addition, generating high-resolution and diverse\nsamples from complex datasets remains a challenge. To address this, BigGAN [76] is proposed as a\nlarge scale TPU implementation of GANs. StyleGAN [77] improves GANs by separating high-level\nattributes and variations, allowing for intuitive control and better performance in terms of quality\nmetrics, interpolation, and disentanglement. [78, 79] focus on inverse mapping - projecting data\nback into the latent space, resulting in a useful feature representation for auxiliary discrimination\ntasks. To address mode collapse and improve the generative model, both the D2GAN [80] and\nGMAN [81] methods extend the traditional GANs by combining extra discriminators. MGAN [82]\nand MAD-GAN [83] address the mode collapse problem by incorporating multiple generators and\none discriminator. CoGAN [84] is composed of a pair of GANs with a weight-sharing constraint,\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:11\nallowing for learning the joint distribution from separate marginal distributions without requiring\ncorresponding images in the training set.\nRepresentative variants. As the latent vector \ud835\udc67of the generator is highly unstructured, Info-\nGAN [85] proposes another latent code \ud835\udc50to extract the significant structured features of the actual\ndata space. In CGANs [86\u201388], the generator and discriminator are conditioned on additional infor-\nmation, such as class labels or data from other modalities, to generate samples that are conditioned\non specific attributes. f-GAN [89] allows for the use of any f-divergence as the objective function\nfor training the generative model. The choice of f-divergence provides a flexible framework for\ncontrolling the trade-off between the quality of the generated samples and the difficulty of training\nthe model.\nObjective function. The goal of generative models is to match the real data distribution. WGAN [90]\nand LS-GAN [91, 92] aim to regularize the loss function with a Lipschitz regularity condition\non the density of real data in order to better generalize and produce realistic new data. [93]\nis a weight normalization technique proposed to stabilize the training of the discriminator in\nGANs. Che et al. [94] regularize the objective, which can stabilize the training of GAN models.\nUGAN [95] stabilizes training of GANs by defining the generator objective with respect to an\nunrolled optimization of the discriminator. [96] makes discriminator relativistic by sampling from\nreal/generated data pairs to improve stability and coverage of the data distribution generated by\nthe generator.\nVAE. Following variational bayes inference [97], Variational Autoencoders (VAE) are generative\nmodels that attempt to reflect data to a probabilistic distribution and learn reconstruction that is\nclose to its original input.\nComplex priors. Rewriting the variational evidence lower bound objective (ELBO) of variational\nautoencoders contributes to improve the variational bounds [98]. Since the true aggregate posterior\nis intractable, VampPrior [99] introduces a variational mixture of posteriors priors conditioned\non learnable pseudo-inputs. [100\u2013102] propose skip connections around the stochastic sampling\nprocess to capture different aspects of the data distribution.\nRegularized Autoencoders. [1, 103, 104] introduce regularisation to the latent space of the encoder\nand lead to a smooth and representative latent space without conforming to an arbitrarily chosen\nprior. [105] propose a multi-scale hierarchical organization to model larger images.\nFlow. A Normalizing Flow is a distribution transformation from simple to complex by a sequence\nof invertible and differentiable mappings.\nCoupling and autoregressive flows. A non-linear deterministic transformation of the data is learned\nthrough a coupling method in [57] to make the transformed data conform to a factorized distribution.\nDinh et al. [106] proposes multi-scale flow to gradually introduce dimensions to the distribution in\nthe generative direction. A more flexible generalisation of coupling layers is the autoregressive\nflow [107\u2013109], which permits parallel density estimation as a universal approximator.\nConvolutional and Residual Flows. Zheng et al. [110] used 1D convolutions (ConvFlow) and\nHoogeboom et al. [111] have provided a more general solution for modelling d\u00d7d convolutions. They\nexploited the triangular structure to improve the interaction among inputs and efficiently compute\nthe determinant. RevNets [112] and iRevNets [113] are the first to build a reversible network\narchitecture based on residual connections, which alleviate the vanishing gradients problem.\nIn addition, the residual connections can be viewed as discretizations of a first order ordinary\ndifferential equation (ODE) [114] to improve parameter efficiency.\nDiffusion. The Generative Diffusion Model (GDM) is a cutting-edge class of generative models\nbased on probability, which demonstrates state-of-the-art results in the field of computer vision. It\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:12\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nworks by progressively corrupting data with multiple-level noise perturbations and then learning\nto reverse this process for sample generation.\nModel Formulations. Diffusion Models are mainly formulated into three categories. DDPM [115]\napplies two Markov chains respectively to progressively corrupt data with Gaussian noise and\nreverse the forward diffusion process by learning Markov transition kernels. Score-based generative\nmodels (SGMs) directly work on the gradient of log density of data a.k.a score function. NCSN\n[31] perturbs data with multi-scale intensifying noise and jointly estimates score function of all\nsuch noisy data distribution by a neural network conditioned on all noise levels. It enjoys flexible\nsampling due to the completely decoupled training and inference steps. Score SDE [116] generalizes\nprevious two formulations into continuous settings, where noise perturbations and denoising\nprocesses are solutions to stochastic differential equations. It is proved that probability flow ODE\ncould also be used to model the reverse process.\nTraining Enhancement. Training enhancement aims to improve sampling by introducing prior\nknowledge from another pre-trained model or extra trainable hyper-parameters. Inspired from the\nidea of knowledge distillation, Salimans et al. [117] propose to progressively distill knowledge from\na pre-trained complicated teacher model to a faster student model, which could cut sampling steps in\nhalf. TDPM [118] and ES-DDPM [119] improve sampling speed by truncating the diffusion process\nwith early stop. To generate sample from reverse process initialized by a non-Gaussian distribution,\nanother pre-trained generative model such as VAE or GAN is introduced to approximate such\ndistribution. Franzese et al. [120] formulate the number of training steps as a variable to realize\nan optimal trade-off. Improved DDPM [121] first introduces noise scale tuning by adding noise\nscale term into loss function.Meanwhile, San Romans et al [122] introduce a noise prediction\nnetwork to enable noise schedule adjustment step-by-step. Such noise schedule learning improves\nreconstruction by efficiently guiding the random walk of noise during training and inference.\nEfficient Training-free Sampling. Instead of additional training, training-free sampling directly\nreduce the number of discretized time steps while minimizing discretization errors. Under same\ntraining objective, DDIM [123] generalizes DDPM to a class of non-Markovian diffusion process and\nintroduces jump-step acceleration. This could provide shorter generative Markov chains. Analytic-\nDPM [124] provides more efficient inference by estimating the analytic form of optimal model\nreverse variance and KL-divergence w.r.t its score function. There are also works [125, 126] which\ndirectly figure out optimal sampling trajectories via dynamic programming.\nNoise Distribution. The distribution of noise perturbations is an essential part of diffusion models\nand most of them are Gaussian. Meanwhile, fitting such distribution with more degrees of freedom\ncould benefit performance. Nachmani et al. [127] prove that Gamma distribution could improve\nimage and speech generation and a mixture of Gaussian distribution also outperforms a single\ndistribution.Furthermore, cold diffusion [128] proposes a more generalized conclusion that noise can\nbe set to any distribution as the generative behavior of diffusion model is not strongly dependent on\nthe choice of noise distribution. Apart from noise perturbation, CCDF [129] shows it is unnecessary\nto initialize from Gaussian distribution and it could reduce sampling steps with a simple forward\ndiffusion but better noise initialization.\nMixed Modeling. Mixed-modeling is aimed at combining diffusion model with another category of\ngenerative model to take all their advantages, which could provide stronger expressiveness or higher\nsampling speed. DiffuseVAE [130] merges a standard VAE into the DDPM pipeline by conditioning\ndiffusion sampling process with blurry image reconstructions generated by VAE. LSGM [131] trains\nSGMs in the latent space of VAE, which generalizes SGMs into non-continuous data and enables\nsmoother SGMs learning in a small space. Denoising diffusion GANs [132] introduces conditional\nGANs into DDPM pipeline to parameterize denoising process with a more expressive multimodal\ndistribution, which provides large denoising steps. DiffFlow [133] integrates flow function into\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:13\nInputs\nEncoder\nDecoder\nRepresentation\nOutput\nTo-image\n\u201cGenerate a \ncartoon cat.\u201d\nTo-text\nVL Pre-trained \nEncoders\nRepresentation\nTransformer \nDecoders\n\u201cThis is a cat.\u201d\nVL Pre-trained \nEncoders\nRepresentation\nVision Decoders \n(GANs, Diffusions)\nEncoder-\nDecoder\nFig. 8. The general structure of generative vision language. We separate the generation process into encoder\npart and decoder part. Encoder models will encode the inputs into a latent representation and then the\ndecoder will decode this representation into a generated output.\ntrajectories of SDE-based diffusion model, which makes forward steps also trainable. The introduced\nrandomness from noise perturbation endows normalizing flow with stronger expression power\nwhile the trainable forward process substantially reduce the diffusion trajectory length. Therefore,\nDiffFlow is able to learn distribution with sharper boundaries with better sampling efficiency.\n4.2\nMultimodal Models\nMultimodal generation serves as an essential part in nowadays AIGC. The goal of multimodal\ngeneration is to learn a model that generates raw modalities by learning the multimodal connection\nand interaction from data [7]. This connection and interaction between modalities can sometimes\nbe very intricate, which makes the multimodal representation space hard to learn compared to\nthe unimodal one. However, with the emergence of the powerful modality-specific foundation\narchitectures mentioned in previous sections, a growing number of methods are proposed in\nresponse to this challenge. In this section, we introduce the state-of-the-art multimodal models in\nvision language generation, text audio generation, text graph generation and text code generation.\nSince most multimodal generative models are always highly related to real-world applications, this\nsection will mainly introduce from the perspective of downstream tasks.\n4.2.1\nVision Language Generation. The encoder-decoder architecture is a widely used framework\nfor solving unimodal generation problems in computer vision and natural language processing. In\nmultimodal generation, particularly in vision-language generation, this method is often used as a\nfoundation architecture. The encoder is responsible for learning a contextualized representation\nof the input data, while the decoder is used to generate raw modalities that reflect cross-modal\ninteractions, structure, and coherence in the representation. In the following, we present a com-\nprehensive survey of state-of-the-art vision-language encoders, followed by an exposition of the\ndecoder component.\nVision Language Encoders. Recently, the development of encoders for single modalities has\nadvanced significantly, leading to the question of how to learn contextualized representations\nfrom multiple modalities. A common way to do this is to combine modality-specific encoders\nusing a fusion function and then leverage multiple pre-training tasks to align the representation\nspace [37, 134, 135]. Generally. these encoder models could be separated into two categories,\nconcatenated encoders and cross-aligned encoders [7].\nConcatenated Encoders. A straight-forward solution to this problem is by concatenating the\nembeddings from single encoders. An early example is VisualBERT [134], which leverages BERT\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:14\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nTransformer Self-Attention Encoder\n[CLS]\nThis\nis\na\n[MASK]\n.\n[IMG]\n[SEP]\nFeature \nExtractor\n\u201cThis is a cat.\u201d\nObjective 1\nObjective 2\n\u2026\u2026\n\u2026\u2026\n\u201cThis is a cat.\u201d\nText Encoder\nImage Encoder\nCross-Modal \nTransformer\nCross-Modal \nTransformer\nText Output\nCross\nOutput\nImage Output\n(a) Concatenated Encoder\n(b) Cross-aligned Encoder\nFig. 9. Two types of vision language encoders: concatenated encoders and cross-aligned encoders. Concate-\nnated encoders accepts concatenated embeddings from different raw modalities, and cross-aligned encoders\nare aligned in abstract modalities.\nas text encoder, CNN as image encoder. The embeddings from the image encoder will be directly\nincorporated into BERT input embeddings, allowing the model to implicitly learn the aligned joint\nrepresentation space. VisualBERT also leverages the multi-task pre-training paradigm as BERT,\nusing two visually-grounded language model objectives: masked language modeling with image\nand sentence image prediction. Additionally, VisualBERT also incorporated some modality-specific\npre-trianing objectives. Another example is VL-BERT [136], which shares the similar architecture\nas VisualBERT. Different from VisualBERT, VL-BERT uses Faster R-CNN [137] as regions of interest\n(ROI) extractor, and leverages this extracted ROI information as the image region embedding.\nVL-BERT also includes an additional pre-training task, masked ROI classification with linguistic\nclues, for better incoporating the visual information. Later, UNITER [138] was proposed based\non the same architecture as VisualBERT, but with different training objectives. UNITER uses\nmasked language modeling, masked region modeling, image text matching prediction and word\nregion alignment prediction as its pre-training tasks. In this way, UNITER could learn informative\ncontextualized embeddings. To this end, we see that concatenated encoders are generally based on\nthe same BERT architecture, and pre-trained with BERT-like tasks. However, these models always\ninvolves a very complicated pre-training process, data collection and loss design. To solve this\nproblem, [135] proposed SimVLM, which simplified the pre-training procedure of vision language\nmodels by setting PrefixLM as the training objective and directly using ViT as both text encoder\nand image encoder. SimVLM achieved state-of-the-art performance on multiple vision language\ntasks compared with previous methods with a much simplified architecture.\nCross-aligned Encoders. In addition to concatenating embeddings as input to encoders, another\nway to learn contextualized representations is to look at pairwise interactions between modalities [7].\nDifferent from concatenated encoders, cross-aligned encoders always use a two-tower structure,\nwhere one tower for each modality and then learn a joint representation space using a cross-\nmodality encoder. LXMERT [139] uses Transformers to extract image features and text features,\nand then adds a multimodal cross-attention module for coordination learning. The resulting output\nembeddings would be visual embeddings, language embeddings and multimodal embeddings. The\nmodel is also pre-trained with several multimodal tasks. Similarly, ViLBERT [140] leverages a\ncross-transformer module to align the two modalities. Given vision and language embeddings, the\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:15\nEmbedding\n(a) Jointly-trained Models \nPre-trained \nEncoder\nPre-train\nDecoder\n\u201cThis is a cat with \nblack background.\u201d\n\u201cThis is a cat.\u201d\nImage Encoder\nEmbedding\n\u201cWhat is this?\u201d\nLLMs\n\u201cThis is a cat with \nblack background.\u201d\n(b) Frozen Models\nPrompt\nFig. 10. Two types of to-language decoder models: jointly-trained models and frozen models. Jointly-trained\nmodels are normally trained end-to-end, while frozen models normally keep the language decoder frozen and\nonly train the image encoder.\nkeys and values of one certain modality will be input into another modality\u2019s attention module to\ngenerate a pooled attention embedding that incorporates both information. In general, these models\nall leverage a cross layer to fuse the information into a joint representation space. Nevertheless,\nemploying a transformer architecture in this context would be inefficient due to its large number\nof parameters. To simplify the training process and calculation, CLIP [37] uses dot product as the\ncross layer, which is more efficient than the transformer encoder, enabling efficient large-scale\ndownstream training. Furthermore, CLIP is trained on copious amounts of pairwise data, which\nhas been shown to outperform numerous other models.\nVision Language Decoders. Given a representation from a certain modality, vision language\ndecoder mainly aims to transform it into a certain raw modality as specified by the task. In this\nsection, we will mainly focus on to-text and to-image decoders.\nTo-text decoders. To-text decoders generally take in contextualized representations from the\nencoder and decode the representation into a sentence. With the emergence and proven effectiveness\nof large language models, many architectures are now selectively freezing the language decoder\ncomponent. As a result, to-text decoders can be broadly categorized into two types: jointly-trained\nmodels and frozen models.\nJointly-trained decoders. Jointly-trained decoders refer to decoders that require complete cross-\nmodal training when decoding representation. The challenge of text-to-text generation typically\nlies in aligning the two modalities during pre-training. As a result, the model requires a stronger\nencoder rather than a decoder. To address this challenge, many models prioritize constructing\na strong encoder and then combine it with a relatively lightweight decoder model. For example,\nVLP [138] and ALBEF [141] leverage a simple transformer decoder to decode the information.\nBLIP [142] combines an encoder and decoder together during pre-training, allowing for multimodal\nspace alignment for both understanding and generation objectives. BLIP is composed of three parts,\na unimodal encoder for extracting image and text features, an image-grounded text encoder which\naccepts image and text features as input, and an image-grounded text decoder, which accepts image\nfeatures and outputs text. Except for the aligned encoder and decoder structure, the authors also\ndesigned several corresponding pre-training tasks to help the model better learn the multimodal\ndependency.\nFrozen deocders. Another way to efficiently perform to-text generation tasks is to freeze the large\nlanguage model and train an image encoder only, which can also be seen as a way to perform\nmultimodal prompting. Due to the success of prompting and in-context learning in NLP, there has\nbeen increased attention towards methods of this nature. This has led people to question whether\nsuch methods could be effective in multimodal settings as well. Frozen [143] first introduced in-\ncontext learning into vision language tasks. It freezes the language model and only trains the\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:16\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nimage encoder. The produced image representations will be embeded in the input embeddings\nof the language model. This method achieves state-of-the-art performance in various zero-shot\nand few-shot vision language tasks. Later, Alayrac et al. proposed Flamingo [144], which further\nexplored multimodal in-context learning. Flamingo involves a frozen vision encoder and a frozen\nlanguage encoder to get vision language representations, and utilizes gated cross-attention-dense\nlayer to fuse the image representation into text representation. Recently, [145] proposed a method\nto realize VL dialogue with frozen language models, enabling the model to generate interleaved\nmultimodal data. This method also freezes input encoders and train text-to-image and image-to-text\nlinear maps to further encode and decode produced embeddings. However, it still remains a question\nwhy this kind of prompting based method work in multimodal generation. Some works have also\nbeen proposed to answer this question. Merullo et al. proposed a method [146] that injects a linear\nprojection between the frozen image encoder and the text encoder. During training, only the linear\nprojection is tuned. The experiment results show that frozen language models with similar sizes\ngenerally perform equally well at transferring visual information into language, but image encoders\npre-trained with linguistic supervision like CLIP text encoder, could encode extra information and\nthus perform significantly better on vision language tasks.\nTo-image decoders. To-image generation refers to given an instruction, generating an image\nthat corresponds to the instruction. Similarly, commonly used models in image generation also\nfollow an encoder-decoder architecture, where the encoders are more focused on learning language\ninformation and the decoders are more focused on leveraging the learned information to restrict\nimage synthesis. Generally, recent works could be separated into two categories, GAN-based\nmethods and diffusion-based methods.\nGAN-based decoders. Given a text encoder \ud835\udf19(\ud835\udc61), GAN-based methods combine a discriminator\n\ud835\udc37and a generator \ud835\udc3a, where the generator \ud835\udc3aaccepts the text embedding generated by \ud835\udf19(\ud835\udc61) and\nnoise vector \ud835\udc67to generate output \ud835\udc4b\ud835\udc54, which are input to the discriminator \ud835\udc37with the real sample\ndistribution \ud835\udc4b\ud835\udc5f[147]. A notable model in this area is StackGAN [148]. StackGAN architecture\nconsists of two stages: a conditioning stage and a refinement stage. In the conditioning stage,\nthe model takes in the textual description as input and generates a low-resolution image. This\nimage is then fed into the refinement stage, where it is further refined to produce a high-resolution\nimage that matches the textual description. AttnGAN [149] is another text-to-image synthesis\nmodel that builds upon the StackGAN architecture. Attngan adds an attention mechanism to\nthe StackGAN architecture to further improve the quality of generated images. However, these\nmodels mainly uses a comparatively simple text encoder during instruction learning, which could\nlead to certain information loss. StyleCLIP [150] is a recent model for text-to-image synthesis\nthat uses contrastive learning to align text and image features. It is based on the StyleGAN [77]\narchitecture and represents a significant advancement over previous text-to-image synthesis models\nsuch as StackGAN. StyleCLIP also follows the encoder-decoder structure that use a text encoder to\nencode instructions and an image decoder to synthesize a new image. One of the key innovations\nof StyleCLIP is its use of contrastive learning to align the text and image features. By training\nthe model to maximize the similarity between the text and image features while minimizing the\nsimilarity between different text and image pairs, StyleCLIP is able to learn a more effective mapping\nbetween text and image features, resulting in higher-quality image synthesis.\nDiffusion-based decoders. Generative image modelling has recently seen great success with the\nuse of diffusion models. These models have also been applied in text-to-image generation. For\nexample, GLIDE [151] introduces ablated diffusion model (ADM) into text-to-image generation.\nCompared to previous diffusion based methods, GLIDE uses larger model with 3.5B parameters\nand larger pairwise datasets, which achieved better results on many benchmarks. Different from\nGLIDE, Imagen [152] combines a frozen T5 language model with a super-resolution diffusion model.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:17\nFig. 11. The model structure of DALL-E-2. Above the dotted line is the CLIP pre-training process, which aims\nto align the vision and language modalities. And below the dotted line is the image generation process. The\ntext encoder accepts an instruction and encodes it into a representation, then the prior network and diffusion\nmodel decodes this representation to generate the final output.\nThe frozen encoder will encode the text instruction and generates an embedding, then the first\ndiffusion model will accordingly generate an low-resolution image. The second diffusion model\naccepts this image with the text embedding and outputs a high-resolution image. DALL-E-2 [5]\ncombines CLIP encoder with diffusion decoder for image genration and editing tasks. Compared\nwith Imagen, DALL-E-2 leverages a prior network to translation between text embedding and\nimage embedding. Except for advancement in model design, another major difference between\nthese diffusion based models and previous generative methods is that these diffusion based models\nare commonly trained on larger dataset with much more parameters, which make them possible to\nlearn better representations over others.\nIn addition to previously mentioned methods, there are also works that use VAE as the decoder.\nFor example, Ramesh et al. proposed DALL-E [33], a zero-shot image generator that utilizes dVAE\nas image encoder and decoder, BPE as text encoder and pre-trained CLIP during inference.\n4.2.2\nText Audio Generation. The field of text-audio multimodal processing has seen significant\ngrowth in recent years. Most models in this field focus on either synthesis tasks, such as speech\nsynthesis, or recognition tasks, such as automatic speech recognition. They refer to the process of\nconverting written text into spoken speech or accurately transcribing human speech into machine-\nreadable text. However, text audio generation is a distinct task that involves creating novel audio\nor text using multimodal models. While related, text-audio generation, synthesis, and recognition\ntasks differ in their goals and the techniques used to achieve them. In this work, we focus on\ntext-audio generation rather than synthesis or recognition tasks.\nText-Audio Generation. AdaSpeech [153] is proposed to efficiently customize new voices with\nhigh quality using limited speech data by utilizing two acoustic encoders and conditional layer\nnormalization in the mel-spectrogram decoder. Since previous studies have limitations in style\nconversion, Lombard [154] exploits the Spectral Shaping and Dynamic Range Compression [155]\nto generate highly intelligible speech in the presence of noise. Cross-lingual generation is an-\nother Influential work to transfer voices across languages. [156] can produce high-quality speech\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:18\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nin multiple languages and transfer voices across languages through the use of phonemic input\nrepresentation and adversarial loss term to disentangle speaker identity from speech content.\nText-Music Generation. [157] proposes a deep cross-modal correlation learning architecture for\naudio and lyrics, where intermodal canonical correlation analysis is used to calculate the similarity of\ntemporal structures between audio and lyrics. To better learn social media content, JTAV [158] fuses\ntextual, acoustic, and visual information using cross-modal fusion and attentive pooling techniques.\nDifferent from JTAV, [159] combines multiple types of information more related to music, such as\nplaylists-track interactions and genre metadata, and align their latent representations to model\nunique music piece. In addition, there are some works focusing on generating text information, such\nas descriptions and captions, given the audio as input. [160] is proposed to generate descriptions\nfor music playlists by combining audio content analysis and natural language processing to utilize\nthe information of each track. MusCaps [161] is a music audio captioning model that generates\ndescriptions of music audio content by processing audio-text inputs through a multimodal encoder\nand leveraging audio data pre-training to obtain effective musical feature representations. For\nmusic and language pre-training, Manco et al. [162] propose a multimodal architecture, which\nuses weakly aligned text as the only supervisory signal to learn general-purpose music audio\nrepresentations. CLAP [163] is another method for learning audio concepts from natural language\nsupervision that utilizes two encoders and contrastive learning to bring audio and text descriptions\ninto a joint multimodal space.\n4.2.3\nText Graph Generation. Text-graph generation is an essential multi-modal topic which could\nlargely free the potential of NLP systems. Natural language text is intrinsically vague as it carries\nvarious redundant information and is also weakly organized in logic. Meanwhile, it is favorable for\nmachines to work with structured, well-organized and compressed form of contents. Knowledge\ngraph (KG) is structural meaning representation which reflects relationships among semantic\ninternal states as graph structure in a language processing system. And there are increasing number\nof works extracting KG from text to assist text generation which incorporates complicated ideas\nacross multiple sentences. Semantic parsing can also be formulated into a problem of text-to-graph\ngeneration. It aims to convert natural language text to a logical form, mostly abstract meaning\nrepresentation (AMR) [164], which is a broad-coverage sentence-level semantic representation.\nCompared to text-to-KG generation, it emphasizes on providing machine interpretable represen-\ntations rather than constructing a semantic network. Conversely, KG-to-text generation aims to\ngenerate fluent and logically-coherent text based on already constructed KG. Apart from the domain\nof NLP, text-graph generation could also push forward the boundary of computer aided drug design.\nThere are emerging works bridging highly structured molecule graph with language descriptions,\nwhich facilitates human understanding of profound molecular knowledge and novel molecule\nexploration. In the following, we briefly overview some representative works in these four topics.\nText To Knowledge Graph Generation. Li et al. [165] treat text-to-KG construction as a process of\nknowledge graph completion (KGC), where missing terms are progressively covered by inference.\nA bilinear model and another DNN-based model are adopted to embed terms and compute score of\narbitrary tuples for additive operation. KG-BERT [166] utilizes the power of pre-trained language\nmodels to capture more contextualized information during KGC. The idea is to represent triplets\nas textual sequences and models graph completion as a sequence classification problem by fine-\ntuned BERT model. Malaviya et al. [167] propose an approach incorporating graph convolutional\nnetwork (GCN) for to extract more structural and semantic context. It also tackles graph sparsity\nand scalability issues by introducing graph augmentation and progressive masking strategies.\nAlternatively, another line of works [168\u2013170] directly query pre-trained language models to obtain\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:19\na semantic knowledge network. Specifically, language models are repeatedly prompted to predict the\nmasked terms in cloze sentence to acquire relational knowledge. CycleGT [171] is an unsupervised\nmethod allowing text-KG translation in both directions. An unsupervised cycle training strategy\nis adopted to provide self-supervision, which enables the entire training process possible with\nnon-parallel text and graph data. Utilizing similar strategy, DualTKB [172] further proves that\nmodel performance could be largely improved even under a weakly supervised setting. Lu et al.\n[173] propose a unified text-to-graph framework which incorporates most information extraction\ntasks. Meanwhile, the use of a pre-defined schema may limit its generalization to diverse text\nforms of nodes and edges. Grapher [174] performs end-to-end text-to-KG construction efficiently\nby generating node and edge in two separate stages. Specifically, a pre-trained language model\nis first fine-tuned with entity extraction tasks for node generation. Subsequently, focal loss and\nsparse adjacency matrix are introduced to address the skewed edge distribution issue during edge\nconstruction.\nFig. 12. DUALENC [175]: a KG-to-text generation model that bridges the structural gap between KG and\ngraph via dual-encoding.\nKnowledge Graph To Text Generation. GTR-LSTM [176] is a sequence-to-sequence encoder-\ndecoder framework which generates text from linearized KG triples. It could handle cycles in\nKGs for capturing global information. Meanwhile, its linearized graph nature could still result\nin considerable structural information loss, especially for large graphs. To address this issue,\nSong et al. [177] encode graph semantics with a graph-state LSTM which enables information\npropagation between nodes during a series of state transitions. It proves to be capable of modeling\nnon-local interactions between nodes while also efficient due to high parallelization. Zhao et al.\n[175] propose DUALENC, a dual encoding model, to bridge the structural discrepancy between\ninput graph and output text. Specifically, it utilizes a GCN-based graph encoder to extract structural\ninformation, while a neural planner is also adopted to create a sequential content plan of a graph for\ngenerating linear output text. Alternatively, Koncel-Kedziorski et al. [178] encode graph structure\nfor text generation with a transformer-based architecture extended from the graph attention\nnetwork (GAT) [179]. The idea is to compute the node representations of KG by traversing its local\nneighborhood with self-attention mechanism. In contrast, Ribeiro et al. [180] focus on utilizing\nlocal and global node encoding strategies jointly to capture complementary information from\ngraph contexts. Adapted from transformer, HetGT [181] aims at modeling different relationships\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:20\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nin the graph independently to avoid information loss by simply mixing them. The input graph\nis first transformed into a heterogeneous Levi graph and then split into sub-graphs based on the\nheterogeneity of each part for future information aggregation.\nSemantic Parsing. Early works [182, 183] formulate semantic parsing as sequence-to-sequence\ngeneration problems. However, AMR is a structured object by its nature. Sequence-to-sequence\nproblem setup could only capture shallow word sequence information meanwhile potentially ignore\nabundant syntax and semantic information. Lyu et al. [184] model semantic parsing as a graph\nprediction problem by expressing AMR as a root labeled directed acyclic graph (DAG) This would\nrequire an alignment between node in the graph and word in the sentences. A neural parser which\ntreat alignments as a latent variable in a joint probabilistic model is proposed for node alignment\nand edge prediction during AMR parsing. Chen et al. [185] construct semantic graph with an action\nset via a neural sequence-to-action RNN model. Parsing process are reinforced by integrating both\nstructural and semantic constraints during decoding. Zhang et al. [186] tackle issues emerged\nfrom the reentrancy property in AMR parsing via an aligner-free attention based model which\nformulate the problem into sequence-to-graph transduction. Utilizing a pointer-generator network,\nit is proved that the model can be trained effectively with limited labeled AMR data. Fancellu et\nal. [187] propose a graph-aware sequential model to construct linearized graph for AMR graph\nprediction. Without a latent variable, it ensures each well-formed string will be only paired with\nexactly only one derivation by a novel graph-aware string rewriting strategy.\nPaired graph-\ntext data\nGraph Encoder\nRelation \nbridge\nText Encoder\nContrastive \nLearning\nInput text\nMoMu\nFig. 13. MoMu [188]: A cross-modal text-molecule generation model.\nText Molecule Generation. Text2Mol [189] is a cross-modal information retrieval system to retrieve\nmolecule graph based on language description. A BERT-based text encoder and a MLP-GCN\ncombined molecule encoder are utilized to create multi-modal embedding in a semantic space,\nwhich is aligned by contrast learning with paired data. Instead of retrieving from existing molecules,\nMolT5 [190] proposes a self-supervised learning framework for text-conditioned de-novo molecule\ngeneration and molecule captioning. It tackles the scarcity of cross-modal data pair with a pre-\ntrain and fine-tune strategy. Specifically, it pre-trains the model on unpaired text and molecule\nstrings with a denoising objective, followed by fine-tuning with limited paired data. However,\nrestricted by its linearized graph nature, string-based representation of a molecule is not unique\nand could result in structural information loss. To tackle this issue, MoMu [188] introduces a graph\nbased multi-modal framework which trains two separate encoders jointly by contrast learning for\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:21\nsemantic space alignment with weakly-paired cross-modal data. It can also be adapted to various\ndownstream tasks apart from de-novo molecule graph generation.\n4.2.4\nText Code Generation. Text-code generation aims to automatically generate valid program-\nming code from natural language description or provide coding assist. LLMs have recently exhibited\ngreat potential in programming language (PL) code generation from natural language (NL) de-\nscriptions. Early works directly formulate text-code generation as a pure language generation task.\nHowever, NL and PL are data types with inherently different modalities, additional strategies are\nessential in capturing mutual dependencies between NL and PL during semantic space alignment.\nCompared to NL data, PL data also encapsulates rich structural information and different syn-\ntax, which makes it more challenging to understand semantic information from the PL context.\nFurthermore, text-code models are also expected to be multi-lingual as they could provide better\ngeneralization. In the following, we mainly introduce code generation models conditioned on NL\ndescription. We also review other coding assist models based on language.\nText-conditioned Programming Code Generation. CodeBERT [191] is a bimodal Transformer-based\npre-trained text-code model which could capture the semantic connection between NL and PL.\nIt adopts a hybrid objective function by utilizing binomial NL-PL paired data for model training\nand unimodal PL code data for learning better generators respectively to align NL and PL in\nsemantic space. This model is further pre-trained on six multi-lingual PL for better generalization.\nCuBERT [192] shares similar model architecture with CodeBERT meanwhile it is not required\nto perform sentence separation between the natural-language description of a function and its\nbody for sentence-pair representation. CodeT5 [193] proposes a pre-trained encoder-decoder Trans-\nformer model which better captures contextualized semantic information from code. Specifically, it\nintroduces novel identifier-aware pre-training tasks to preserve crucial token type information\nby discriminating identifiers from code tokens and recover them when masked. PLBART [194]\nextends bimodal text-code model from generative tasks to a broader categories of discriminative\ntasks such as clone and vulnerable code detection under a unified framework. Another line of\nworks [195, 196] introduce the notion of program graphs [197] to explicitly model the structures\nunderlying PL code to assist generation. The program graphs are constructed as Abstract Syntax\nTrees (AST) to encapsulate knowledge from program-specific semantic and syntax.\nInteractive Programming System. Text-code generation are jointly challenged by the intractable\nsearching space of programming code generation and improper specification of user intent due to\nthe intrinsic ambiguity of NL. CODEGEN [198] propose a multi-turn program synthesis approach\nwhich factorizes program synthesis conditioned on a single complicated NL specification into\nprogressive generation controlled by a series of user intents. It is constructed in the form of\nautoregressive transformers learning a conditional distribution of the next token given previous\ntokens and it is trained on both PL and NL data. TDUIF [199] extends interactive programming\nframework by formalizing the user intent and providing more understandable user feedback. It\nfurther realizes scalable automatic algorithm evaluation which does not require user in loop with\nhigh-fidelity user interaction modeling.\n5\nAPPLICATIONS\n5.1\nChatBot\nA chatbot is a computer program designed to simulate conversation with human users through\ntext-based interfaces. Chatbots normally use language models to understand and respond to user\nqueries and inpus in a conversational manner. They can be programmed to perform a wide range\nof tasks, for example, providing customer support and answering frequently asked questions. One\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:22\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\ndevelops\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelongs\nbelo\u2026\nMicrosoft\nGoogle\nMeta\nOpenAI\nAmazon\nAiva Tech\nCodeParot\nDeepMind\nStability\nChatBot\nMusic\nCode\nEducation\nAlgorithm\nArt\nXiaoice\nMeena\nBlenderBot\nChatGPT\nAlexa\nLex\nAIVA\nJukebox\nCodeGen\nCodeParot\nCodex\nCoPilot\nMinerva\nAlphaTensor\nDALLE-2\nDreamStudio\ncraiyon\nImagen\nFig. 14. A relation graph of a current research areas, applications and related companies, where dark blue\ncircles represent research areas, light blue circles represent applications and green circles represents companies.\nApplication\nPlatform/Software\nCompany\nYear\nPapaer\nLink\nChatBot\nXiaoice\nMicrosoft\n2018\n[200]\nXiaoice\nChatBot\nMeena\nGoogle\n2020\n[201]\nMeena Blog\nChatBot\nBlenderBot\nMeta\n2022\n[202]\nBlenderbot\nChatBot\nChatGPT\nOpenAI\n2022\n[10]\nChatGPT\nChatBot\nAlexa\nAmazon\n2014\n-\nAmazon Alexa\nChatBot\nLex\nAmazon\n2017\n-\nAmazon Lex\nMusic\nAIVA\nAiva Tech\n2016\n-\nAIVA\nMusic\nJukebox\nOpenAI\n2020\n[203]\nJukebox\nCode\nCodeGPT\nMicrosoft\n2021\n[204]\nCodeGPT\nCode\nCodeParrot\nCodeParrot\n2022\n[205]\nCodeParrot\nCode\nCodex\nOpenAI\n2021\n[206]\nCodex blog\nCode\nCoPilot\nMicrosoft\n2021\n[206]\nCoPilot\nArt\nDALL-E-2\nOpenAI\n2022\n[5]\nDALL-E-2 Blog\nArt\nDreamStudio\nStability\n2022\n[13]\nDreamstudio\nArt\ncraiyon\nOpenAI\n2021\n[1]\nCraiyon\nArt\nImagen\nGoogle\n2022\n[152]\nImagen\nEducation\nMinerva\nGoogle\n2022\n[207]\nMinerva Blog\nAlgorithm\nAlphaTensor\nDeepMind\n2022\n[208]\nAlphaTensor\nTable 1. Applications of Generative AI models.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:23\nof the most prominent example is Xiaoice [200]. XiaoIce was developed by a team of researchers\nand engineers from Microsoft, using state-of-the-art techniques in natural language processing,\nmachine learning, and knowledge representation. An important feature of Xiaoice is that it is able to\nexpress empathy, which is achieved by using sentiment analysis methods, to make Xiaoice perform\nlike a human. In 2020, Google proposed Meena [201], a multi-turn open-domain chatbot trained on\nsocial media conversations, which achieves state-of-the-art interactive SSA score and perplexity.\nRecently, Microsoft released their newest version Bing, which incorporates ChatGPT, enabling\nits users to ask open domain or conditioned questions and get results through conversation. This\npresents new possibilities for the development of chatbots in the future.\n5.2\nArt\nAI art generation refers to using computer algorithms to create original works of art. These\nalgorithms are trained on large datasets of existing artwork and use machine learning techniques to\ngenerate new pieces that mimic the styles and techniques of famous artists or explore new artistic\nstyles. With the rapid development in diffusion based models, more and more companies have\nlaunched their art generation products. One of the most notable advancements in the field is the\nDALL-E series, which was introduced by OpenAI. DALL-E [1], which is now Craiyon, was first\nbuilt on VQ-VAE and CLIP, then diffusion was also applied to this product, becoming DALL-E-\n2 [5]. DreamStudio [13], created by Stability.ai, is a text-to-image generation service that utilizes\nstable diffusion to generate images based on given phrases or sentences. This technology offers\ncomparable performance to that of DALL-E-2, but with even faster processing speeds, making it\na popular choice for many users. Imagen [152], developed by Google, uses diffusion in its image\nediting and generation service. In a blog post, Google reported that they conducted a study with\nhuman raters to evaluate the quality of AI-generated images. The results showed that Imagen\noutperformed other models in side-by-side comparisons, with higher ratings for sample quality\nand image-text alignment preferred by the human raters.\n5.3\nMusic\nDeep music generation refers to the use of deep learning techniques and artificial intelligence\nalgorithms to generate novel and original pieces of music. A prominent approach is to produce a\nsymbolic representation of the music in the form of a piano roll. This approach entails specifying the\ntiming, pitch, velocity, and instrument for each note to be played. AIVA 4 is one of the most notable\nexamples, which is developed by Aiva Technologies in 2016. It can generate music clips in multiple\nstyles including electronic, pop, jazz, etc. and can be used in various contexts. As the world\u2019s\nfirst artificial intelligence composer recognized by symphonic organizations, AIVA obtained the\nglobal status of Composer in the SACEM music society. OpenAI develops Jukebox [203] in 2020. It\ngenerates music with singing in the raw audio domain in diverse genres and artistic styles. Jukebox\nis considered as a leap forward in terms of musical quality, coherence, audio sample duration, and\nthe capacity to be conditioned by artist, genre, and lyrics.\n5.4\nCode\nAI-based programming systems generally aim for tasks including code completion, source code to\npseudo-code mapping, program repair, API sequence prediction, user feedback, and natural language\nto code generation. Recently, the emergence of powerful LLMs has pushed the boundary of AI-\nbased programming a large step forward. CodeGPT [204] is an open-source code generation model\ndeveloped by OpenAI which follows the transformer architecture as many other models in the GPT\n4http://www.aiva.ai\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:24\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nfamily. It can be fine-tuned for various code generation tasks such as code completion, summary,\nor translation based on a vast amount of source code data. CodeParrot [205] is a programming\nlearning platform that provides user with personalized feedback and assistance during coding.\nA variety of interactive exercises and programming challenges are designed in the fashion of\nprogressive human-machine interaction. One unique feature is the scaffolding strategy which splits\ncomplicated tasks into smaller and manageable steps to help students gradually build their coding\nskills. Trained on a much larger and more diverse corpus of data, Codex [206] is a significant step\nforward compared to most previous models. Specifically, it is designed to generate complete coding\nprograms from scratch while CodeGPT is only able to generate code fragments that complete a\ngiven prompt. It also enjoys the benefits of being adapted to multiple programming languages,\nwhich could provide better flexibility and generalization.\n5.5\nEducation\nAIGC has the potential to achieve significant advancements in education by leveraging multi-\nmodality data, for example, tutorial videos, academic papers, and other high-quality information,\nthereby improving the personalized education experience. On the academic side, Google Research\nintroduced Minerva [207], which is built upon PaLM general language models [209] and an ad-\nditional science-and-math-focused dataset, to solve college-level multi-step quantitative tasks,\ncovering algebra, probability, physics, number theory, precalculus, geometry, biology, electric\nengineering, chemistry, astronomy, and machine learning. For example, it can give step-by-step\ndetails of proving the inequality \ud835\udc4e2 + \ud835\udc4f2 \u22652\ud835\udc4e\ud835\udc4ffor any (\ud835\udc4e,\ud835\udc4f) \u2208R2 and it can also correctly identify\nAmericium as the radioactive element among other three choices, including Sodium, Chromium,\nand Aluminum. As is described in the blog5, Minerva achieves state-of-the-art performance on\nreasoning tasks by combing techniques, including few-shot prompting, a chain of thought or\nscratchpad prompting, and majority voting. Although Minerva\u2019s performance is still below human\nperformance, with continuous improvement and future advancement, AIGC could provide afford-\nable personalized math tutors. On the commercial side, Skillful Craftsman Education Technology\nannounced to develop a class bot product powered by AIGC and featuring auto curriculum, AI\ntutor, and self-adaptive learning for online education, which is expected to be shipped by the fourth\nquarter of 2023.\n6\nEFFICIENCY IN AIGC\nDeep generative AI models with neural networks has dominated the field of machine learning\nfor the past decade, with its rise attributed to the ImageNet competition in 2012 [210], which led\nto a race to create deeper and more complex models. This trend is also seen in natural language\nunderstanding, where models like BERT and GPT-3 have been developed with a large number\nof parameters. However, the increasing model footprint and complexity, as well as the cost and\nresources required for training and deployment, pose challenges for practical deployment in the\nreal world. The core challenge is efficiency, which can be broken it down as follows:\n\u2022 Inference efficiency: This is concerned with the practical considerations of deploying a\nmodel for inference, i.e., computing the model\u2019s outputs for a given input. Inference efficiency\nis mostly related to the model\u2019s size, speed, and resource consumption (e.g., disk and RAM\nusage) during inference.\n\u2022 Training efficiency: This covers factors that affect the speed and resource requirements of\ntraining a model, such as training time, memory footprint, and scalability across multiple\n5https://ai.googleblog.com/2022/06/minerva-solving-quantitative-reasoning.html\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:25\nStep I  Prompt Engineer\nStep II  Inference\nStep III  Label Mapping\nI love this movie. \nOverall, it was a _____ movie.\nPrompt \ud835\udc65\u2032:\nInput \ud835\udc65\nTemplate\nLLM\nprompt\nGood 0.6\nGreat 0.3\nBad\n0.05\nBoring 0.05\n\u2026\u2026\nPositive\nNegative\nVerbalizer\nExample: I hate this movie. Overall,\u2026\nContext\nExample: I hate this movie. Because \u2026, \noverall\u2026\nCoT\n\ud835\udc43(\ud835\udc66|\ud835\udc65')\nFig. 15. General procedure of prompt learning for emotion detection examples. First, the user need to construct\na prompt that fits the problem well, the user can also use in-context learning and chain-of-thought (CoT) to\nhelp improve the performance. Then, an LLM will generate suitable words for the blank space in the prompt.\nFinally, a verbalizer will project the generated word to a specific classification category.\ndevices. It may also encompass considerations around the amount of data required to achieve\noptimal performance on a given task.\n6.1\nPrompt Learning\nPrompt learning is a relatively new concept that has been proposed in recent years within the\ncontext of pre-trained large language models. Previously, to make a prediction \ud835\udc66given input \ud835\udc65, the\ngoal of traditional supervised learning is to find a language model that predicts the probability\n\ud835\udc43(\ud835\udc66|\ud835\udc65). With prompt learning, the goal becomes finding a template \ud835\udc65\u2032 that directly predicts the\nprobability \ud835\udc43(\ud835\udc66|\ud835\udc65\u2032) [211]. Hence, the objective of using a language model becomes encouraging\na pre-trained model to make predictions by providing a prompt specifying the task to be done.\nNormally, prompt learning will freeze the language model and directly perform few-shot or zero-\nshot learning on it. This enables the language models to be pre-trained on large amount of raw text\ndata and be adapted to new domains without tuning it again. Hence, prompt learning could help\nsave much time and efforts.\n6.1.1\nTraditional Prompt Learning. The process of utilizing prompt learning with a language model\ncan be divided into two main stages: prompt engineering and answer engineering.\n\u2022 Prompt engineering. In general, there are two commonly used forms of prompt engineering:\ndiscrete prompt and continuous prompt. Discrete prompts are typically manually designed\nby humans for specific tasks, while continuous prompts are added to the input embeddings\nto convey task-specific information.\n\u2022 Answer engineering. After the task has been reformulated, the answer generated by the\nlanguage model based on the provided prompt needs to be mapped to the ground truth space.\nThere are different paradigms for answering engineering, including discrete search space\nand continuous search space. As this topic is more closely related to classification tasks, we\nrefer interested readers to for further information.\nIn addition to single-prompt learning methods, there are also multi-prompt methods. These\napproaches primarily focus on ensembling multiple prompts together as input during inference to\nimprove prediction robustness, which is more effective than relying on a single prompt. Another\napproach to multi-prompt learning is prompt augmentation, which aims to assist the model in\nanswering questions by providing additional prompts that have already been answered.\n6.1.2\nIn-context Learning. Recently, in-context learning has received significant attention as an\neffective method for improving language models\u2019 performance. This approach is a subset of prompt\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:26\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nlearning and involves using a pre-trained language model as the backbone, along with adding a\nfew input-label demonstration pairs and instructions to the prompt. In-context learning has been\nshown to be highly effective in guiding language models to produce better answers that are more\nclosely aligned with the given prompt. Some recent studies have also suggested that in-context\nlearning can be viewed as a form of implicit fine-tuning, as it enables the model to learn how to\ngenerate answers more accurately based on the input prompt.\n6.2\nEfficiency in Pretrained Foundation Models\nWithin the context of the AIGC framework, a fundamental component of each proposed method\ninvolves utilizing large pretrained foundation models (PFMs) [212]. PFMs, such as BERT [42], GPT-\n2 [62], and RoBERTa [43], have revolutionized the field of natural language processing by achieving\nstate-of-the-art results on a wide range of NLP tasks. However, these models are incredibly large\nand computationally expensive, which can lead to efficiency problems. This is especially true\nwhen working with limited computational resources, such as on personal computers or in cloud\nenvironments with limited processing power. In order to address these efficiency problems, recent\nnumerous works have been dedicated to exploring more cost-effective pretraining methods to\npretrain large-scale PFMs. The effectiveness of learning algorithms is contingent upon both training\nmethods and model architecture efficiency. For example, ELECTRA [213] introduces an RTD task\nthat predicts whether each input marker is replaced by other tokens, thereby enabling ELECTRA\nto train against all input tokens. In addition to effective training methods, model architecture\nefficiency can also contribute to improved PFMs efficiency. Most PFMs based on the Transformer\nalgorithm may benefit from a more efficient model architecture by reducing the complexity of the\nTransformer algorithm.\n6.3\nModel Compression\nModel compression is an effective approach to reduce model size and improve computation ef-\nficiency. It requires fewer computing resources and memory and can better meet the needs of\nvarious applications than the original model, where its strategies can be divided into two categories:\nparameter compression and structure compression. Parameter compression methods include param-\neter pruning, parameter quantization, low-rank decomposition, and parameter sharing. Parameter\npruning deletes redundant parameters based on a sizeable PFM, while parameter quantization re-\nduces model parameters to lower-order numbers without significant impact on model performance.\nLow-rank decomposition reduces the dimension of a high-dimensional parameter vector, and\nparameter sharing maps model parameters to reduce their number. Structure compression refers\nto designing new compact network structures and employing knowledge distillation, where the\nknowledge learned from a larger teacher model is transferred to a smaller student model through\nsoft labels, among other techniques. DistilBERT [214], for instance, uses knowledge distillation to\ncompress BERT, reducing its size by 40% while maintaining 97% of its language comprehension.\nALBERT uses decomposition-embedded parameterization and cross-layer parameter sharing to\nreduce the number of model parameters.\n7\nTRUSTWORTHY & RESPONSIBLE AIGC\nWhile AIGC has the potential to be incredibly useful in many different applications, it also raises\nsignificant concerns about security and privacy. In this section, we will discuss studies that disclose\nthe \"dark\" side of AIGC and countermeasures proposed to ensure that AIGC can be used in a safe\nand responsible way.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:27\n7.1\nSecurity\nFactuality. Although tools like ChatGPT [4] is capable of generating content that usually appears\nor sounds reasonable, they are often unreliable in terms of factuality [215]. Sometimes, the model\noutputs counterfactual or even absurd answers, which pose a serious threat to the truthfulness of\ninformation on the internet. Recently, NewsGuard\u2019s Misinformation Monitor [216] has indicated\nthe possibility that AI-generated content tools are being weaponized to spread misinformation at an\nunprecedented scale. Presented with 100 samples from NewsGuard\u2019s proprietary misinformation\ndatabase, the tested model, ChatGPT, generated false narratives for 80 of the 100 previously identified\nfalse arguments, which could easily come across as legitimate and authoritative for those unfamiliar\nwith the topics [216]. Moreover, Alex [217] offers a more specific example by demonstrating how\nto leverage ChatGPT [4] to generate a newspaper. Besides natural language processing, factuality\nconcerns also exist in the computer vision domain. For example, stable diffusion [13], which has\nbeen demonstrated to be a powerful vision-generated model, has trouble drawing realistic human\nhands with the correct number of fingers [218]. To prevent the spread of misinformation on the\ninternet, websites like Stackoverflow [219] propose policies that ban users from using AI-generated\ncontent as an answer to reduce the risk of being overwhelmed by inaccurate and biased content.\nEarlier studies have shown that AI models suffer from factual incorrectness and hallucination\nof knowledge [220]. To evaluate and improve the factual accuracy of AI-generated content, [221]\nproposed model-based metrics that measure the factualness of generated text, complementing\ntraditional metrics such as ROUGE (Recall-Oriented Understudy for Gisting Evaluation) [222] and\nBLEU (Bilingual Evaluation Understudy) [223]. Specifically, [221] proposed a Transformer-based\nend-to-end fact extraction model, which enables the structured prediction of relation tuples for\nfactualness assessment. More systematic definitions of truthfulness standards and approaches for\ngoverning AI-generated content were later proposed in Truthful AI [224]. The standard proposed\nby Truthful AI aims to avoid \"negligent falsehoods\" and explicitly train AI systems to be truthful\nvia curated datasets and human interaction. Based on GPT-3, WebGPT [225] proposed a humanoid\nprototype that models the AI answering process into web searching and evidence-composing\nphrases. Since the model is trained to cite its sources, the factual accuracy of AI-generated content is\nsignificantly improved in multiple benchmark datasets [226, 227]. Specifically, the model is obtained\nby fine-tuning GPT-3 using imitation learning, which leverages human feedback to optimize answer\nquality. Furthermore, [228] measures and improves the factual accuracy of large-scale language\nmodels for open-ended text generation. [228] proposed the factual-nucleus sampling algorithm\nthat dynamically adapts the randomness to balance the factuality and quality of AI-generated\ncontent. A factuality-enhanced training method that uses TOPICPREFIX for better awareness of\nfacts and sentence completion is designed as the training objective, which vastly reduces factual\nerrors. Despite these preliminary advances in developing more truthful AI, challenges still remain.\nFor example, AI-generated content might be problematic on unfamiliar types of questions and\ncontexts that involve contradictions [215].\nToxicity. Besides utility, it is important for AI-generated content (AIGC) to be helpful, harmless,\nunbiased, and non-toxic. Extensive research has been conducted on the potential harm caused by\ndeployed models [229\u2013231], which can include biased outputs [232, 233], stereotypes [234], and\nmisinformation [235]. To address this issue of toxicity in the language domain, OpenAI proposes\nInstructGPT [10], which aligns language models with human preferences by using human feedback\nas a reward signal to fine-tune the models, ensuring more relevant and safe responses. Concurrently,\nGoogle proposes LaMDA [236], a family of neural language models specialized for safe and factual\ndialog by leveraging fine-tuning and external knowledge sources. To improve model safety, LaMDA\n[236] designs a set of metrics (Appendix A.1 in the original paper) that quantify model safety based\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:28\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\non an illustrative set of human values derived from Google\u2019s AI Principles 6. Furthermore, Ganguli\net al. [237] study and improve the safety of language models in an adversarial way. Specifically, they\ninvestigate the scaling behaviors for red teaming across models with different sizes (2.7B, 13B, and\n52B parameters) and training schemes (plain LM, fine-tuned LM, LM with rejection sampling, and\nLM trained with RLHF). They found that models trained with RLHF scale better and are increasingly\ndifficult to red team.\n7.2\nPrivacy\nMembership inference. The goal of the membership inference attack (MIA) is to determine whether\nan image \ud835\udc65belongs to the set of training data. Wu et al. [238] investigated the membership leakage in\ntext-to-image (diffusion-based and sequence-to-sequence-based) generation models under realistic\nblack-box settings. Specifically, three kinds of intuitions including quality, reconstruction error,\nand faithfulness are considered to design the attack algorithms. However, Wu et al. [238] assumed\nthat the member set and the hold-out set come from different distributions, which makes the MIA\nmuch easier. Under a more practical setting [239], where the member set and the hold-out set\nare in the same distribution, Duan et al. [240] propose Step-wise Error Comparing Membership\nInference (SecMI), a black-box MIA that infers memberships by assessing the matching of forward\nprocess posterior estimation at each timestep. Concurrently, Hu and Pang [241] propose two attack\napproaches, including loss-based and likelihood-based MIA. Furthermore, Matsumoto et al. [242]\nintroduce more comparisons with GANs.\nData Extraction. The objective of a data extraction attack is to retrieve an image from the set of\ntraining data, denoted as \ud835\udc65\u2208\ud835\udc37. The attack can be considered a success if the attacker is able to\nobtain an image \u02c6\ud835\udc65that closely resembles image \ud835\udc65\u2208\ud835\udc37. Compared to the membership inference\nattack, the data extraction attack poses stronger privacy risks to the model. The feasibility of such an\nattack might be due to the memorization property of large-scale models [243], in which they turn to\nmemorize parts of their training data. When prompted appropriately, the memorized training data\nthat might contain sensitive information will be emitted verbatim. Earlier, in the language domain,\nCarlini et al. [244] demonstrated that large language models (specifically, GPT-2 [245]) memorize\nand leak individual training examples. Specifically, they proposed a simple and efficient method for\nextracting verbatim sequences from a language model\u2019s training set using only black-box query\naccess. Recently, in the vision domain, Somepalli et al. [246] showed that the data replication\nproblem existed in diffusion models, where the generated images are close to the training data in\nterms of semantic similarity. To disclose worse-case privacy risk, Carlini et al. [247] further explored\nthe privacy vulnerabilities of state-of-the-art diffusion models by leveraging a generate-and-filter\npipeline to extract over a thousand training examples from the models. Specifically, the extraction\napproach first samples 500 candidate images by querying the generation function in a black-box\nmanner using selected prompts. Based on the intuition that generations of memorized data are\nnearly identical, a similarity graph is then constructed to determine whether an image belongs to\nthe training set. The results in [247] show that diffusion models, including Stable Diffusion [13]\nand Imagen [152], are more susceptible to privacy breaches compared to earlier generative models\nlike GANs [29]. These results highlight the necessity of developing new techniques for preserving\nprivacy during training to address these vulnerabilities.\n8\nOPEN PROBLEMS AND FUTURE DIRECTIONS\nIn this section, we discuss some challenges in AIGC and potential ways to address them.\n6https://ai.google/principles/\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:29\nHigh-stakes Applications. Although the community has witnessed the huge success of AIGC\nin images, texts, and audio generations, these areas are arguably more fault-tolerant. On the\ncontrary, AIGC for high-stakes applications, including healthcare [248], financial services [249],\nautonomous vehicles [250], and science discovery [251], are still challenging. In these domains,\ntasks are mission-critical and require a high degree of accuracy, reliability, transparency, and less\nor near zero fault-tolerant. For example, the large language model Galactica [252], which is made\nfor automatically organizing science, can perform knowledge-intensive scientific tasks and have\npromising performances on several benchmark tasks. Its public demo were taken down from the\nservice only three days after its initial release, due to the intensive criticism on its generated biased\nand incorrect results in an authoritative tone. It would be crucial for generative models in these\nhigh-stakes applications to give confidence scores, reasoning, and source information along with\ngenerated results. Only when professionals understand how and where these results are coming\nfrom, they can confidently utilize these tools in their tasks.\nSpecialization and Generalization. AIGC relies on the choice of foundation models, which\nare trained on different datasets, including crawl-based [37] one and carefully curated [252]. And it\nis argued in [230] that \u201ctraining on a more diverse dataset is not always better for downstream\nperformance than a more specialized foundation model.\" However, the curation of highly specialized\ndataset can be both time-consuming and cost-ineffective. A better understanding of cross-domain\nrepresentations and how they are resilient to testing-time distribution-shift may guide the design\nof training datasets that balance specialization and generalization.\nContinual Learning and Retraining. The human knowledge base keeps expanding and new\ntasks continue emerging. To generate the contents with up-to-date information, it not only requires\nmodel to \u201cremember\" the learned knowledge, but also be able to learn and infer from newly acquired\ninformation. For some scenarios [253], it suffices to perform the continual learning on downstream\ntasks while keeping the pre-trained foundation model unchanged. When necessary [254], one can\nperform continual learning on foundation models. However, it is also observed that the continual\nlearning may not always outperform the retrained models [255]. This calls for the need to understand\nwhen should one choose continual learning strategy and when to choose to the retraining strategy.\nAlso, training foundation models from scratch may be prohibitive, so modularized design of next\ngeneration of foundation models for AIGC may elucidate which parts of the model should be\nretrained.\nReasoning. Reasoning is a crucial component of human intelligence that enables us to draw\ninferences, make decisions, and solve complex problems. However, even trained with large scale\ndataset, sometimes GAI models could still fail at common sense reasoning tasks [256, 257]. Recently,\nmore and more researchers began to focus on this problem. Chain-of-thought (CoT) prompting [256]\nis a promising solution to the challenge of reasoning in generative AI models. It is designed to\nenhance the ability of large language models to learn about logical reasoning in the context of\nquestion answering. By explaining the logical reasoning process that humans use to arrive at\nanswers to models, they can follow the same road that humans take in processing their reasoning.\nBy incorporating this approach, large language models can achieve higher accuracy and better\nperformance in tasks that require logical reasoning. CoT has also been applied to other areas like\nvision language question answering [257] and code generation [258]. However, it still remains a\nproblem that how to construct these CoT prompts according to specific tasks.\nScaling up. Scaling up has been a common problem in large-scale pretraining. Model training\nis always limited by compute budget, available dataset and model size. As the size of pretraining\nmodels increases, the time and resources required for training also increases significantly. This\nposes a challenge for researchers and organizations that seek to utilize large-scale pretraining for\nvarious tasks, such as natural language understanding, computer vision, and speech recognition.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:30\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nAnother issue pertains to the efficacy of pretraining with large-scale datasets, which may not\nyield optimal results if experimental hyperparameters, such as model size and data volume, are\nnot thoughtfully designed. As such, suboptimal hyperparameters can result in wasteful resource\nconsumption and the failure to achieve desired outcomes through further training. Several works\nhave been proposed to solve these problems. Hoffmann et al. [259] introduce a formal scaling law\nto predict model performance based on the number of parameters and dataset size. This work\nprovides a useful framework for understanding the relationship between these key factors when\nscaling up. Aghajanyan et al. [260] conduct empirical analyses to validate the Hoffmann scaling law\nand propose an additional formula that explores the relationship between different training tasks in\nmultimodal model training settings. These findings provide valuable insights into the complexities\nof large-scale model training and the nuances of optimizing performance across diverse training\ndomains.\nSocial issues. As AIGC continues to proliferate across various domains, social concerns re-\ngarding its use have become increasingly prominent. These concerns relate to issues such as bias,\nethics, and the impact of AI-generated content on various stakeholders. One major concern is the\npotential for bias in AI-generated content, particularly in areas such as natural language processing\nand computer vision. AI models can inadvertently perpetuate or amplify existing societal biases,\nparticularly if the training data used to develop the models are themselves biased. This can have\nsignificant negative consequences, such as perpetuating discrimination and inequities in areas\nsuch as hiring, loan approvals, and criminal justice. Ethical concerns also arise with the use of\nAI-generated content, particularly in cases where the technology is used to generate deepfakes or\nother forms of manipulated media. Such content can be used to spread false information, incite\nviolence, or harm individuals or organizations. Additionally, there are concerns around the potential\nfor AI-generated content to infringe on copyright and intellectual property rights, as well as issues\naround privacy and data security. Overall, while AI-generated content holds significant promise in\nvarious domains, it is crucial to address these social concerns to ensure that its use is responsible\nand beneficial for society as a whole.\n9\nCONCLUSION\nThis survey provides a comprehensive overview of the history and recent advancements in AIGC,\nwith a particular focus on both unimodality and multimodality generative models. In addition, we\ndiscuss the recent applications of generative AI models, commonly used techniques in AIGC, and\naddress concerns surrounding trustworthiness and responsibility in the field. Finally, we explore\nopen problems and future directions for AIGC, highlighting potential avenues for innovation and\nprogress. The primary objective of this survey is to provide readers with a comprehensive under-\nstanding of recent developments and future challenges in generative AI. Our analysis of the general\nframework of AI generation aims to distinguish contemporary generative AI models from their\npredecessors. Ultimately, we hope this survey will aid readers in gaining deeper insights into this\nfield. Moving forward, we would further investigate this topic and provide a more comprehensive\nanalysis of AIGC.\nREFERENCES\n[1] A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. Voss, A. Radford, M. Chen, and I. Sutskever, \u201cZero-shot text-to-image\ngeneration,\u201d in International Conference on Machine Learning, pp. 8821\u20138831, PMLR, 2021.\n[2] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, et al.,\n\u201cEvaluating large language models trained on code,\u201d arXiv preprint arXiv:2107.03374, 2021.\n[3] L. Yunjiu, W. Wei, and Y. Zheng, \u201cArtificial intelligence-generated and human expert-designed vocabulary tests: A\ncomparative study,\u201d SAGE Open, vol. 12, no. 1, p. 21582440221082130, 2022.\n[4] \u201cChatgpt: Optimizing language models for dialogue,\u201d Nov. 2022.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:31\n[5] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. Chen, \u201cHierarchical Text-Conditional Image Generation with\nCLIP Latents,\u201d Apr. 2022. arXiv:2204.06125 [cs].\n[6] M. Stefanini, M. Cornia, L. Baraldi, S. Cascianelli, G. Fiameni, and R. Cucchiara, \u201cFrom Show to Tell: A Survey on\nDeep Learning-based Image Captioning,\u201d Nov. 2021. arXiv:2107.06912 [cs].\n[7] P. P. Liang, A. Zadeh, and L.-P. Morency, \u201cFoundations and Recent Trends in Multimodal Machine Learning: Principles,\nChallenges, and Open Questions,\u201d Sept. 2022. arXiv:2209.03430 [cs].\n[8] A. Gokaslan and V. Cohen, \u201cOpenwebtext corpus,\u201d 2019.\n[9] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell,\nS. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse,\nM. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and\nD. Amodei, \u201cLanguage Models are Few-Shot Learners,\u201d in Advances in Neural Information Processing Systems, vol. 33,\npp. 1877\u20131901, Curran Associates, Inc., 2020.\n[10] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. L. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray,\nJ. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welinder, P. Christiano, J. Leike, and R. Lowe,\n\u201cTraining language models to follow instructions with human feedback,\u201d Mar. 2022. arXiv:2203.02155 [cs].\n[11] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and D. Amodei, \u201cDeep Reinforcement Learning from Human\nPreferences,\u201d in Advances in Neural Information Processing Systems, vol. 30, Curran Associates, Inc., 2017.\n[12] N. Stiennon, L. Ouyang, J. Wu, D. M. Ziegler, R. Lowe, C. Voss, A. Radford, D. Amodei, and P. Christiano, \u201cLearning to\nsummarize from human feedback,\u201d in Proceedings of the 34th International Conference on Neural Information Processing\nSystems, NIPS\u201920, (Red Hook, NY, USA), pp. 3008\u20133021, Curran Associates Inc., Dec. 2020.\n[13] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer, \u201cHigh-Resolution Image Synthesis with Latent Diffusion\nModels,\u201d Apr. 2022. arXiv:2112.10752 [cs].\n[14] N. Anantrasirichai and D. Bull, \u201cArtificial intelligence in the creative industries: a review,\u201d Artificial Intelligence Review,\nvol. 55, pp. 589\u2013656, jul 2021.\n[15] J. Kietzmann, J. Paschen, and E. Treen, \u201cArtificial Intelligence in Advertising,\u201d Journal of Advertis-\ning Research, vol. 58, no. 3, pp. 263\u2013267, 2018.\nPublisher: Journal of Advertising Research _eprint:\nhttps://www.journalofadvertisingresearch.com/content/58/3/263.full.pdf.\n[16] M. Kandlhofer, G. Steinbauer, S. Hirschmugl-Gaisch, and P. Huber, \u201cArtificial intelligence and computer science in\neducation: From kindergarten to university,\u201d in 2016 IEEE Frontiers in Education Conference (FIE), pp. 1\u20139, 2016.\n[17] J. Li, T. Tang, W. X. Zhao, J.-Y. Nie, and J.-R. Wen, \u201cPretrained language models for text generation: A survey,\u201d 2022.\n[18] J. Agnese, J. Herrera, H. Tao, and X. Zhu, \u201cA survey and taxonomy of adversarial neural networks for text-to-image\nsynthesis,\u201d 2019.\n[19] M. Suzuki and Y. Matsuo, \u201cA survey of multimodal deep generative models,\u201d Advanced Robotics, vol. 36, pp. 261\u2013278,\nfeb 2022.\n[20] K. Knill and S. Young, \u201cHidden Markov Models in Speech and Language Processing,\u201d in Corpus-Based Methods in\nLanguage and Speech Processing (S. Young and G. Bloothooft, eds.), pp. 27\u201368, Dordrecht: Springer Netherlands, 1997.\n[21] D. A. Reynolds et al., \u201cGaussian mixture models.,\u201d Encyclopedia of biometrics, vol. 741, no. 659-663, 2009.\n[22] Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin, \u201cA neural probabilistic language model,\u201d J. Mach. Learn. Res., vol. 3,\np. 1137\u20131155, mar 2003.\n[23] T. Mikolov, M. Karafi\u00e1t, L. Burget, J. Cernock`y, and S. Khudanpur, \u201cRecurrent neural network based language model.,\u201d\nin Interspeech, vol. 2, pp. 1045\u20131048, Makuhari, 2010.\n[24] A. Graves and A. Graves, \u201cLong short-term memory,\u201d Supervised sequence labelling with recurrent neural networks,\npp. 37\u201345, 2012.\n[25] R. Dey and F. M. Salem, \u201cGate-variants of gated recurrent unit (gru) neural networks,\u201d in 2017 IEEE 60th international\nmidwest symposium on circuits and systems (MWSCAS), pp. 1597\u20131600, IEEE, 2017.\n[26] U. Khandelwal, H. He, P. Qi, and D. Jurafsky, \u201cSharp nearby, fuzzy far away: How neural language models use context,\u201d\n2018.\n[27] A. A. Efros and T. K. Leung, \u201cTexture synthesis by non-parametric sampling,\u201d in Proceedings of the seventh IEEE\ninternational conference on computer vision, vol. 2, pp. 1033\u20131038, IEEE, 1999.\n[28] P. S. Heckbert, \u201cSurvey of texture mapping,\u201d IEEE computer graphics and applications, vol. 6, no. 11, pp. 56\u201367, 1986.\n[29] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, \u201cGenerative\nadversarial networks,\u201d 2014.\n[30] D. P. Kingma and M. Welling, \u201cAuto-encoding variational bayes,\u201d arXiv preprint arXiv:1312.6114, 2013.\n[31] Y. Song and S. Ermon, \u201cGenerative modeling by estimating gradients of the data distribution,\u201d Advances in Neural\nInformation Processing Systems, vol. 32, 2019.\n[32] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u. Kaiser, and I. Polosukhin, \u201cAttention is\nall you need,\u201d in Advances in Neural Information Processing Systems (I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:32\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nR. Fergus, S. Vishwanathan, and R. Garnett, eds.), vol. 30, Curran Associates, Inc., 2017.\n[33] A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. Voss, A. Radford, M. Chen, and I. Sutskever, \u201cZero-shot text-to-image\ngeneration,\u201d 2021.\n[34] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, and L. Zettlemoyer, \u201cBart: Denoising\nsequence-to-sequence pre-training for natural language generation, translation, and comprehension,\u201d arXiv preprint\narXiv:1910.13461, 2019.\n[35] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold,\nS. Gelly, et al., \u201cAn image is worth 16x16 words: Transformers for image recognition at scale,\u201d arXiv preprint\narXiv:2010.11929, 2020.\n[36] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo, \u201cSwin transformer: Hierarchical vision transformer\nusing shifted windows,\u201d in Proceedings of the IEEE/CVF international conference on computer vision, pp. 10012\u201310022,\n2021.\n[37] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, G. Krueger,\nand I. Sutskever, \u201cLearning transferable visual models from natural language supervision,\u201d 2021.\n[38] Q. Dong, L. Li, D. Dai, C. Zheng, Z. Wu, B. Chang, X. Sun, J. Xu, L. Li, and Z. Sui, \u201cA survey on in-context learning,\u201d\n2023.\n[39] J. W. Rae, S. Borgeaud, T. Cai, K. Millican, J. Hoffmann, F. Song, J. Aslanides, S. Henderson, R. Ring, S. Young, et al.,\n\u201cScaling language models: Methods, analysis & insights from training gopher,\u201d arXiv preprint arXiv:2112.11446, 2021.\n[40] N. Elhage, N. Nanda, C. Olsson, T. Henighan, N. Joseph, B. Mann, A. Askell, Y. Bai, A. Chen, T. Conerly, N. DasSarma,\nD. Drain, D. Ganguli, Z. Hatfield-Dodds, D. Hernandez, A. Jones, J. Kernion, L. Lovitt, K. Ndousse, D. Amodei, T. Brown,\nJ. Clark, J. Kaplan, S. McCandlish, and C. Olah, \u201cA mathematical framework for transformer circuits,\u201d Transformer\nCircuits Thread, 2021. https://transformer-circuits.pub/2021/framework/index.html.\n[41] X. Qiu, T. Sun, Y. Xu, Y. Shao, N. Dai, and X. Huang, \u201cPre-trained models for natural language processing: A survey,\u201d\nScience China Technological Sciences, vol. 63, no. 10, pp. 1872\u20131897, 2020.\n[42] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, \u201cBert: Pre-training of deep bidirectional transformers for language\nunderstanding,\u201d arXiv preprint arXiv:1810.04805, 2018.\n[43] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, \u201cRoberta: A\nrobustly optimized bert pretraining approach,\u201d arXiv preprint arXiv:1907.11692, 2019.\n[44] Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R. R. Salakhutdinov, and Q. V. Le, \u201cXlnet: Generalized autoregressive pretraining\nfor language understanding,\u201d Advances in neural information processing systems, vol. 32, 2019.\n[45] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin, T. Mihaylov, M. Ott,\nS. Shleifer, K. Shuster, D. Simig, P. S. Koura, A. Sridhar, T. Wang, and L. Zettlemoyer, \u201cOpt: Open pre-trained transformer\nlanguage models,\u201d 2022.\n[46] A. Glaese, N. McAleese, M. Tr\u0119bacz, J. Aslanides, V. Firoiu, T. Ewalds, M. Rauh, L. Weidinger, M. Chadwick, P. Thacker,\net al., \u201cImproving alignment of dialogue agents via targeted human judgements,\u201d arXiv preprint arXiv:2209.14375, 2022.\n[47] R. Coulom, \u201cWhole-history rating: A bayesian rating system for players of time-varying strength,\u201d in Computers and\nGames: 6th International Conference, CG 2008, Beijing, China, September 29-October 1, 2008. Proceedings 6, pp. 113\u2013124,\nSpringer, 2008.\n[48] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and D. Amodei, \u201cDeep reinforcement learning from human\npreferences,\u201d Advances in neural information processing systems, vol. 30, 2017.\n[49] R. Ramamurthy, P. Ammanabrolu, K. Brantley, J. Hessel, R. Sifa, C. Bauckhage, H. Hajishirzi, and Y. Choi, \u201cIs\nreinforcement learning (not) for natural language processing?: Benchmarks, baselines, and building blocks for natural\nlanguage policy optimization,\u201d arXiv preprint arXiv:2210.01241, 2022.\n[50] Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen, A. Goldie, A. Mirhoseini, C. McKinnon, et al.,\n\u201cConstitutional ai: Harmlessness from ai feedback,\u201d arXiv preprint arXiv:2212.08073, 2022.\n[51] B. Zhu, J. Jiao, and M. I. Jordan, \u201cPrincipled reinforcement learning with human feedback from pairwise or \ud835\udc58-wise\ncomparisons,\u201d arXiv preprint arXiv:2301.11270, 2023.\n[52] X. Amatriain, \u201cTransformer models: an introduction and catalog,\u201d arXiv preprint arXiv:2302.07730, 2023.\n[53] A. Sergeev and M. Del Balso, \u201cHorovod: fast and easy distributed deep learning in tensorflow,\u201d 2018.\n[54] J. Rasley, S. Rajbhandari, O. Ruwase, and Y. He, \u201cDeepspeed: System optimizations enable training deep learning models\nwith over 100 billion parameters,\u201d in Proceedings of the 26th ACM SIGKDD International Conference on Knowledge\nDiscovery & Data Mining, pp. 3505\u20133506, 2020.\n[55] J. J. Dai, D. Ding, D. Shi, S. Huang, J. Wang, X. Qiu, K. Huang, G. Song, Y. Wang, Q. Gong, et al., \u201cBigdl 2.0: Seamless\nscaling of ai pipelines from laptops to distributed cluster,\u201d in Proceedings of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition, pp. 21439\u201321446, 2022.\n[56] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu, \u201cExploring the limits of\ntransfer learning with a unified text-to-text transformer,\u201d The Journal of Machine Learning Research, vol. 21, no. 1,\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:33\npp. 5485\u20135551, 2020.\n[57] L. Dinh, D. Krueger, and Y. Bengio, \u201cNice: Non-linear independent components estimation,\u201d arXiv preprint\narXiv:1410.8516, 2014.\n[58] J. Ni, T. Young, V. Pandelea, F. Xue, and E. Cambria, \u201cRecent advances in deep learning based dialogue systems: A\nsystematic survey,\u201d Artificial intelligence review, pp. 1\u2013101, 2022.\n[59] S. Yang, Y. Wang, and X. Chu, \u201cA survey of deep learning techniques for neural machine translation,\u201d arXiv preprint\narXiv:2002.07526, 2020.\n[60] F. Zhu, W. Lei, C. Wang, J. Zheng, S. Poria, and T.-S. Chua, \u201cRetrieving and reading: A comprehensive survey on\nopen-domain question answering,\u201d arXiv preprint arXiv:2101.00774, 2021.\n[61] A. Radford and K. Narasimhan, \u201cImproving language understanding by generative pre-training,\u201d 2018.\n[62] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, \u201cLanguage models are unsupervised multitask\nlearners,\u201d 2019.\n[63] J. L. Ba, J. R. Kiros, and G. E. Hinton, \u201cLayer normalization,\u201d arXiv preprint arXiv:1607.06450, 2016.\n[64] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ili\u0107, D. Hesslow, R. Castagn\u00e9, A. S. Luccioni, F. Yvon, M. Gall\u00e9, et al., \u201cBloom:\nA 176b-parameter open-access multilingual language model,\u201d arXiv preprint arXiv:2211.05100, 2022.\n[65] M. Shoeybi, M. Patwary, R. Puri, P. LeGresley, J. Casper, and B. Catanzaro, \u201cMegatron-lm: Training multi-billion\nparameter language models using model parallelism,\u201d 2019.\n[66] S. Smith, M. Patwary, B. Norick, P. LeGresley, S. Rajbhandari, J. Casper, Z. Liu, S. Prabhumoye, G. Zerveas, V. Korthikanti,\nE. Zhang, R. Child, R. Y. Aminabadi, J. Bernauer, X. Song, M. Shoeybi, Y. He, M. Houston, S. Tiwary, and B. Catanzaro,\n\u201cUsing deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model,\u201d 2022.\n[67] W. Fedus, B. Zoph, and N. Shazeer, \u201cSwitch transformers: Scaling to trillion parameter models with simple and\nefficient sparsity,\u201d J. Mach. Learn. Res, vol. 23, pp. 1\u201340, 2021.\n[68] V. Aribandi, Y. Tay, T. Schuster, J. Rao, H. S. Zheng, S. V. Mehta, H. Zhuang, V. Q. Tran, D. Bahri, J. Ni, et al., \u201cExt5:\nTowards extreme multi-task scaling for transfer learning,\u201d arXiv preprint arXiv:2111.10952, 2021.\n[69] A. Aghajanyan, D. Okhonko, M. Lewis, M. Joshi, H. Xu, G. Ghosh, and L. Zettlemoyer, \u201cHtlm: Hyper-text pre-training\nand prompting of language models,\u201d 2021.\n[70] Z. Li, Z. Wang, M. Tan, R. Nallapati, P. Bhatia, A. Arnold, B. Xiang, and D. Roth, \u201cDq-bart: Efficient sequence-to-\nsequence model via joint distillation and quantization,\u201d arXiv preprint arXiv:2203.11239, 2022.\n[71] E. L. Denton, S. Chintala, R. Fergus, et al., \u201cDeep generative image models using a laplacian pyramid of adversarial\nnetworks,\u201d Advances in neural information processing systems, vol. 28, 2015.\n[72] P. J. Burt and E. H. Adelson, \u201cThe laplacian pyramid as a compact image code,\u201d in Readings in computer vision,\npp. 671\u2013679, Elsevier, 1987.\n[73] A. Radford, L. Metz, and S. Chintala, \u201cUnsupervised representation learning with deep convolutional generative\nadversarial networks,\u201d arXiv preprint arXiv:1511.06434, 2015.\n[74] T. Karras, T. Aila, S. Laine, and J. Lehtinen, \u201cProgressive growing of gans for improved quality, stability, and variation,\u201d\narXiv preprint arXiv:1710.10196, 2017.\n[75] H. Zhang, I. Goodfellow, D. Metaxas, and A. Odena, \u201cSelf-attention generative adversarial networks,\u201d in International\nconference on machine learning, pp. 7354\u20137363, PMLR, 2019.\n[76] A. Brock, J. Donahue, and K. Simonyan, \u201cLarge scale gan training for high fidelity natural image synthesis,\u201d arXiv\npreprint arXiv:1809.11096, 2018.\n[77] T. Karras, S. Laine, and T. Aila, \u201cA style-based generator architecture for generative adversarial networks,\u201d in\nProceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 4401\u20134410, 2019.\n[78] J. Donahue, P. Kr\u00e4henb\u00fchl, and T. Darrell, \u201cAdversarial feature learning,\u201d arXiv preprint arXiv:1605.09782, 2016.\n[79] D. Ulyanov, A. Vedaldi, and V. Lempitsky, \u201cIt takes (only) two: Adversarial generator-encoder networks,\u201d in Proceedings\nof the AAAI Conference on Artificial Intelligence, vol. 32, 2018.\n[80] T. Nguyen, T. Le, H. Vu, and D. Phung, \u201cDual discriminator generative adversarial nets,\u201d Advances in neural information\nprocessing systems, vol. 30, 2017.\n[81] I. Durugkar, I. Gemp, and S. Mahadevan, \u201cGenerative multi-adversarial networks,\u201d arXiv preprint arXiv:1611.01673,\n2016.\n[82] Q. Hoang, T. D. Nguyen, T. Le, and D. Phung, \u201cMulti-generator generative adversarial nets,\u201d arXiv preprint\narXiv:1708.02556, 2017.\n[83] A. Ghosh, V. Kulharia, V. P. Namboodiri, P. H. Torr, and P. K. Dokania, \u201cMulti-agent diverse generative adversarial\nnetworks,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 8513\u20138521, 2018.\n[84] M.-Y. Liu and O. Tuzel, \u201cCoupled generative adversarial networks,\u201d Advances in neural information processing systems,\nvol. 29, 2016.\n[85] X. Chen, Y. Duan, R. Houthooft, J. Schulman, I. Sutskever, and P. Abbeel, \u201cInfogan: Interpretable representation\nlearning by information maximizing generative adversarial nets,\u201d Advances in neural information processing systems,\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:34\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nvol. 29, 2016.\n[86] M. Mirza and S. Osindero, \u201cConditional generative adversarial nets,\u201d arXiv preprint arXiv:1411.1784, 2014.\n[87] Y. Lu, Y.-W. Tai, and C.-K. Tang, \u201cAttribute-guided face generation using conditional cyclegan,\u201d in Proceedings of the\nEuropean conference on computer vision (ECCV), pp. 282\u2013297, 2018.\n[88] Q. Mao, H.-Y. Lee, H.-Y. Tseng, S. Ma, and M.-H. Yang, \u201cMode seeking generative adversarial networks for diverse\nimage synthesis,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 1429\u20131437,\n2019.\n[89] S. Nowozin, B. Cseke, and R. Tomioka, \u201cf-gan: Training generative neural samplers using variational divergence\nminimization,\u201d Advances in neural information processing systems, vol. 29, 2016.\n[90] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville, \u201cImproved training of wasserstein gans,\u201d\nAdvances in neural information processing systems, vol. 30, 2017.\n[91] G.-J. Qi, \u201cLoss-sensitive generative adversarial networks on lipschitz densities,\u201d International Journal of Computer\nVision, vol. 128, no. 5, pp. 1118\u20131140, 2020.\n[92] X. Mao, Q. Li, H. Xie, R. Y. Lau, Z. Wang, and S. Paul Smolley, \u201cLeast squares generative adversarial networks,\u201d in\nProceedings of the IEEE international conference on computer vision, pp. 2794\u20132802, 2017.\n[93] T. Miyato, T. Kataoka, M. Koyama, and Y. Yoshida, \u201cSpectral normalization for generative adversarial networks,\u201d arXiv\npreprint arXiv:1802.05957, 2018.\n[94] T. Che, Y. Li, A. P. Jacob, Y. Bengio, and W. Li, \u201cMode regularized generative adversarial networks,\u201d arXiv preprint\narXiv:1612.02136, 2016.\n[95] L. Metz, B. Poole, D. Pfau, and J. Sohl-Dickstein, \u201cUnrolled generative adversarial networks,\u201d arXiv preprint\narXiv:1611.02163, 2016.\n[96] A. Jolicoeur-Martineau, \u201cThe relativistic discriminator: a key element missing from standard gan,\u201d arXiv preprint\narXiv:1807.00734, 2018.\n[97] C. W. Fox and S. J. Roberts, \u201cA tutorial on variational bayesian inference,\u201d Artificial intelligence review, vol. 38, pp. 85\u201395,\n2012.\n[98] M. D. Hoffman and M. J. Johnson, \u201cElbo surgery: yet another way to carve up the variational evidence lower bound,\u201d\nin Workshop in Advances in Approximate Bayesian Inference, NIPS, vol. 1, 2016.\n[99] J. Tomczak and M. Welling, \u201cVae with a vampprior,\u201d in International Conference on Artificial Intelligence and Statistics,\npp. 1214\u20131223, PMLR, 2018.\n[100] L. Maal\u00f8e, M. Fraccaro, V. Li\u00e9vin, and O. Winther, \u201cBiva: A very deep hierarchy of latent variables for generative\nmodeling,\u201d Advances in neural information processing systems, vol. 32, 2019.\n[101] A. Vahdat and J. Kautz, \u201cNvae: A deep hierarchical variational autoencoder,\u201d Advances in neural information processing\nsystems, vol. 33, pp. 19667\u201319679, 2020.\n[102] B. Wu, S. Nair, R. Martin-Martin, L. Fei-Fei, and C. Finn, \u201cGreedy hierarchical variational autoencoders for large-scale\nvideo prediction,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2318\u20132328,\n2021.\n[103] P. Ghosh, M. S. Sajjadi, A. Vergari, M. Black, and B. Sch\u00f6lkopf, \u201cFrom variational to deterministic autoencoders,\u201d arXiv\npreprint arXiv:1903.12436, 2019.\n[104] A. Van Den Oord, O. Vinyals, et al., \u201cNeural discrete representation learning,\u201d Advances in neural information processing\nsystems, vol. 30, 2017.\n[105] A. Razavi, A. Van den Oord, and O. Vinyals, \u201cGenerating diverse high-fidelity images with vq-vae-2,\u201d Advances in\nneural information processing systems, vol. 32, 2019.\n[106] L. Dinh, J. Sohl-Dickstein, and S. Bengio, \u201cDensity estimation using real nvp,\u201d arXiv preprint arXiv:1605.08803, 2016.\n[107] G. Papamakarios, T. Pavlakou, and I. Murray, \u201cMasked autoregressive flow for density estimation,\u201d Advances in neural\ninformation processing systems, vol. 30, 2017.\n[108] C.-W. Huang, D. Krueger, A. Lacoste, and A. Courville, \u201cNeural autoregressive flows,\u201d in International Conference on\nMachine Learning, pp. 2078\u20132087, PMLR, 2018.\n[109] N. De Cao, W. Aziz, and I. Titov, \u201cBlock neural autoregressive flow,\u201d in Uncertainty in artificial intelligence, pp. 1263\u2013\n1273, PMLR, 2020.\n[110] G. Zheng, Y. Yang, and J. Carbonell, \u201cConvolutional normalizing flows,\u201d arXiv preprint arXiv:1711.02255, 2017.\n[111] E. Hoogeboom, R. Van Den Berg, and M. Welling, \u201cEmerging convolutions for generative normalizing flows,\u201d in\nInternational Conference on Machine Learning, pp. 2771\u20132780, PMLR, 2019.\n[112] A. N. Gomez, M. Ren, R. Urtasun, and R. B. Grosse, \u201cThe reversible residual network: Backpropagation without storing\nactivations,\u201d Advances in neural information processing systems, vol. 30, 2017.\n[113] J.-H. Jacobsen, A. Smeulders, and E. Oyallon, \u201ci-revnet: Deep invertible networks,\u201d arXiv preprint arXiv:1802.07088,\n2018.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:35\n[114] E. Haber, L. Ruthotto, E. Holtham, and S.-H. Jun, \u201cLearning across scales\u2014multiscale methods for convolution neural\nnetworks,\u201d in Thirty-second AAAI conference on artificial intelligence, 2018.\n[115] J. Ho, A. Jain, and P. Abbeel, \u201cDenoising diffusion probabilistic models,\u201d Advances in Neural Information Processing\nSystems, vol. 33, pp. 6840\u20136851, 2020.\n[116] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole, \u201cScore-based generative modeling through\nstochastic differential equations,\u201d arXiv preprint arXiv:2011.13456, 2020.\n[117] T. Salimans and J. Ho, \u201cProgressive distillation for fast sampling of diffusion models,\u201d arXiv preprint arXiv:2202.00512,\n2022.\n[118] H. Zheng, P. He, W. Chen, and M. Zhou, \u201cTruncated diffusion probabilistic models,\u201d stat, vol. 1050, p. 7, 2022.\n[119] Z. Lyu, X. Xu, C. Yang, D. Lin, and B. Dai, \u201cAccelerating diffusion models via early stop of the diffusion process,\u201d arXiv\npreprint arXiv:2205.12524, 2022.\n[120] G. Franzese, S. Rossi, L. Yang, A. Finamore, D. Rossi, M. Filippone, and P. Michiardi, \u201cHow much is enough? a study\non diffusion times in score-based generative models,\u201d 2022.\n[121] A. Q. Nichol and P. Dhariwal, \u201cImproved denoising diffusion probabilistic models,\u201d in International Conference on\nMachine Learning, pp. 8162\u20138171, PMLR, 2021.\n[122] R. San-Roman, E. Nachmani, and L. Wolf, \u201cNoise estimation for generative diffusion models,\u201d arXiv preprint\narXiv:2104.02600, 2021.\n[123] J. Song, C. Meng, and S. Ermon, \u201cDenoising diffusion implicit models,\u201d arXiv preprint arXiv:2010.02502, 2020.\n[124] F. Bao, C. Li, J. Zhu, and B. Zhang, \u201cAnalytic-dpm: an analytic estimate of the optimal reverse variance in diffusion\nprobabilistic models,\u201d arXiv preprint arXiv:2201.06503, 2022.\n[125] D. Watson, J. Ho, M. Norouzi, and W. Chan, \u201cLearning to efficiently sample from diffusion probabilistic models,\u201d arXiv\npreprint arXiv:2106.03802, 2021.\n[126] D. Watson, W. Chan, J. Ho, and M. Norouzi, \u201cLearning fast samplers for diffusion models by differentiating through\nsample quality,\u201d in International Conference on Learning Representations, 2022.\n[127] E. Nachmani, R. S. Roman, and L. Wolf, \u201cNon gaussian denoising diffusion models,\u201d 2021.\n[128] A. Bansal, E. Borgnia, H.-M. Chu, J. S. Li, H. Kazemi, F. Huang, M. Goldblum, J. Geiping, and T. Goldstein, \u201cCold\ndiffusion: Inverting arbitrary image transforms without noise,\u201d arXiv preprint arXiv:2208.09392, 2022.\n[129] H. Chung, B. Sim, and J. C. Ye, \u201cCome-closer-diffuse-faster: Accelerating conditional diffusion models for inverse\nproblems through stochastic contraction,\u201d 2021.\n[130] K. Pandey, A. Mukherjee, P. Rai, and A. Kumar, \u201cDiffusevae: Efficient, controllable and high-fidelity generation from\nlow-dimensional latents,\u201d 2022.\n[131] A. Vahdat, K. Kreis, and J. Kautz, \u201cScore-based generative modeling in latent space,\u201d Advances in Neural Information\nProcessing Systems, vol. 34, pp. 11287\u201311302, 2021.\n[132] Z. Xiao, K. Kreis, and A. Vahdat, \u201cTackling the generative learning trilemma with denoising diffusion gans,\u201d arXiv\npreprint arXiv:2112.07804, 2021.\n[133] Q. Zhang and Y. Chen, \u201cDiffusion normalizing flow,\u201d Advances in Neural Information Processing Systems, vol. 34,\npp. 16280\u201316291, 2021.\n[134] L. H. Li, M. Yatskar, D. Yin, C.-J. Hsieh, and K.-W. Chang, \u201cVisualbert: A simple and performant baseline for vision\nand language,\u201d arXiv preprint arXiv:1908.03557, 2019.\n[135] Z. Wang, J. Yu, A. W. Yu, Z. Dai, Y. Tsvetkov, and Y. Cao, \u201cSimvlm: Simple visual language model pretraining with\nweak supervision,\u201d arXiv preprint arXiv:2108.10904, 2021.\n[136] W. Su, X. Zhu, Y. Cao, B. Li, L. Lu, F. Wei, and J. Dai, \u201cVl-bert: Pre-training of generic visual-linguistic representations,\u201d\narXiv preprint arXiv:1908.08530, 2019.\n[137] S. Ren, K. He, R. Girshick, and J. Sun, \u201cFaster r-cnn: Towards real-time object detection with region proposal networks,\u201d\nAdvances in neural information processing systems, vol. 28, 2015.\n[138] L. Zhou, H. Palangi, L. Zhang, H. Hu, J. Corso, and J. Gao, \u201cUnified vision-language pre-training for image captioning\nand vqa,\u201d in Proceedings of the AAAI conference on artificial intelligence, vol. 34, pp. 13041\u201313049, 2020.\n[139] H. Tan and M. Bansal, \u201cLxmert: Learning cross-modality encoder representations from transformers,\u201d arXiv preprint\narXiv:1908.07490, 2019.\n[140] J. Lu, D. Batra, D. Parikh, and S. Lee, ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-\nLanguage Tasks. Red Hook, NY, USA: Curran Associates Inc., 2019.\n[141] J. Li, R. Selvaraju, A. Gotmare, S. Joty, C. Xiong, and S. C. H. Hoi, \u201cAlign before fuse: Vision and language representation\nlearning with momentum distillation,\u201d Advances in neural information processing systems, vol. 34, pp. 9694\u20139705, 2021.\n[142] J. Li, D. Li, C. Xiong, and S. Hoi, \u201cBlip: Bootstrapping language-image pre-training for unified vision-language\nunderstanding and generation,\u201d in International Conference on Machine Learning, pp. 12888\u201312900, PMLR, 2022.\n[143] M. Tsimpoukelli, J. Menick, S. Cabi, S. Eslami, O. Vinyals, and F. Hill, \u201cMultimodal few-shot learning with frozen\nlanguage models,\u201d Proc. Neural Information Processing Systems, 2021.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:36\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\n[144] J.-B. Alayrac, J. Donahue, P. Luc, A. Miech, I. Barr, Y. Hasson, K. Lenc, A. Mensch, K. Millican, M. Reynolds, et al.,\n\u201cFlamingo: a visual language model for few-shot learning,\u201d arXiv preprint arXiv:2204.14198, 2022.\n[145] J. Y. Koh, R. Salakhutdinov, and D. Fried, \u201cGrounding language models to images for multimodal generation,\u201d arXiv\npreprint arXiv:2301.13823, 2023.\n[146] J. Merullo, L. Castricato, C. Eickhoff, and E. Pavlick, \u201cLinearly mapping from image to text space,\u201d arXiv preprint\narXiv:2209.15162, 2022.\n[147] R. Zhou, C. Jiang, and Q. Xu, \u201cA survey on generative adversarial network-based text-to-image synthesis,\u201d Neurocom-\nputing, vol. 451, pp. 316\u2013336, 2021.\n[148] H. Zhang, T. Xu, H. Li, S. Zhang, X. Wang, X. Huang, and D. N. Metaxas, \u201cStackgan: Text to photo-realistic image\nsynthesis with stacked generative adversarial networks,\u201d in Proceedings of the IEEE international conference on computer\nvision, pp. 5907\u20135915, 2017.\n[149] T. Xu, P. Zhang, Q. Huang, H. Zhang, Z. Gan, X. Huang, and X. He, \u201cAttngan: Fine-grained text to image generation\nwith attentional generative adversarial networks,\u201d in Proceedings of the IEEE conference on computer vision and pattern\nrecognition, pp. 1316\u20131324, 2018.\n[150] O. Patashnik, Z. Wu, E. Shechtman, D. Cohen-Or, and D. Lischinski, \u201cStyleclip: Text-driven manipulation of stylegan\nimagery,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 2085\u20132094, 2021.\n[151] A. Nichol, P. Dhariwal, A. Ramesh, P. Shyam, P. Mishkin, B. McGrew, I. Sutskever, and M. Chen, \u201cGlide: Towards\nphotorealistic image generation and editing with text-guided diffusion models,\u201d 2021.\n[152] C. Saharia, W. Chan, S. Saxena, L. Li, J. Whang, E. Denton, S. K. S. Ghasemipour, B. K. Ayan, S. S. Mahdavi, R. G.\nLopes, et al., \u201cPhotorealistic text-to-image diffusion models with deep language understanding,\u201d arXiv preprint\narXiv:2205.11487, 2022.\n[153] M. Chen, X. Tan, B. Li, Y. Liu, T. Qin, S. Zhao, and T.-Y. Liu, \u201cAdaspeech: Adaptive text to speech for custom voice,\u201d\narXiv preprint arXiv:2103.00993, 2021.\n[154] D. Paul, M. P. Shifas, Y. Pantazis, and Y. Stylianou, \u201cEnhancing speech intelligibility in text-to-speech synthesis using\nspeaking style conversion,\u201d arXiv preprint arXiv:2008.05809, 2020.\n[155] T.-C. Zorila, V. Kandia, and Y. Stylianou, \u201cSpeech-in-noise intelligibility improvement based on spectral shaping and\ndynamic range compression,\u201d in Thirteenth Annual Conference of the International Speech Communication Association,\n2012.\n[156] Y. Zhang, R. J. Weiss, H. Zen, Y. Wu, Z. Chen, R. Skerry-Ryan, Y. Jia, A. Rosenberg, and B. Ramabhadran, \u201cLearning to\nspeak fluently in a foreign language: Multilingual speech synthesis and cross-language voice cloning,\u201d arXiv preprint\narXiv:1907.04448, 2019.\n[157] Y. Yu, S. Tang, F. Raposo, and L. Chen, \u201cDeep cross-modal correlation learning for audio and lyrics in music retrieval,\u201d\nACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), vol. 15, no. 1, pp. 1\u201316, 2019.\n[158] H. Liang, H. Wang, J. Wang, S. You, Z. Sun, J.-M. Wei, and Z. Yang, \u201cJtav: Jointly learning social media content\nrepresentation by fusing textual, acoustic, and visual features,\u201d arXiv preprint arXiv:1806.01483, 2018.\n[159] A. Ferraro, X. Favory, K. Drossos, Y. Kim, and D. Bogdanov, \u201cEnriched music representations with multiple cross-modal\ncontrastive learning,\u201d IEEE Signal Processing Letters, vol. 28, pp. 733\u2013737, 2021.\n[160] K. Choi, G. Fazekas, B. McFee, K. Cho, and M. Sandler, \u201cTowards music captioning: Generating music playlist\ndescriptions,\u201d arXiv preprint arXiv:1608.04868, 2016.\n[161] I. Manco, E. Benetos, E. Quinton, and G. Fazekas, \u201cMuscaps: Generating captions for music audio,\u201d in 2021 International\nJoint Conference on Neural Networks (IJCNN), pp. 1\u20138, IEEE, 2021.\n[162] I. Manco, E. Benetos, E. Quinton, and G. Fazekas, \u201cLearning music audio representations via weak language supervision,\u201d\nin ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 456\u2013460,\nIEEE, 2022.\n[163] B. Elizalde, S. Deshmukh, M. A. Ismail, and H. Wang, \u201cClap: Learning audio concepts from natural language supervision,\u201d\narXiv preprint arXiv:2206.04769, 2022.\n[164] L. Banarescu, C. Bonial, S. Cai, M. Georgescu, K. Griffitt, U. Hermjakob, K. Knight, P. Koehn, M. Palmer, and\nN. Schneider, \u201cAbstract meaning representation for sembanking,\u201d in Proceedings of the 7th linguistic annotation\nworkshop and interoperability with discourse, pp. 178\u2013186, 2013.\n[165] X. Li, A. Taheri, L. Tu, and K. Gimpel, \u201cCommonsense knowledge base completion,\u201d in Proceedings of the 54th Annual\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1445\u20131455, 2016.\n[166] L. Yao, C. Mao, and Y. Luo, \u201cKg-bert: Bert for knowledge graph completion,\u201d arXiv preprint arXiv:1909.03193, 2019.\n[167] C. Malaviya, C. Bhagavatula, A. Bosselut, and Y. Choi, \u201cCommonsense knowledge base completion with structural\nand semantic context,\u201d in Proceedings of the AAAI conference on artificial intelligence, vol. 34, pp. 2925\u20132933, 2020.\n[168] F. Petroni, T. Rockt\u00e4schel, P. Lewis, A. Bakhtin, Y. Wu, A. H. Miller, and S. Riedel, \u201cLanguage models as knowledge\nbases?,\u201d arXiv preprint arXiv:1909.01066, 2019.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:37\n[169] T. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh, \u201cAutoprompt: Eliciting knowledge from language models\nwith automatically generated prompts,\u201d arXiv preprint arXiv:2010.15980, 2020.\n[170] X. L. Li and P. Liang, \u201cPrefix-tuning: Optimizing continuous prompts for generation,\u201d arXiv preprint arXiv:2101.00190,\n2021.\n[171] Q. Guo, Z. Jin, X. Qiu, W. Zhang, D. Wipf, and Z. Zhang, \u201cCyclegt: Unsupervised graph-to-text and text-to-graph\ngeneration via cycle training,\u201d 2020.\n[172] P. L. Dognin, I. Melnyk, I. Padhi, C. N. dos Santos, and P. Das, \u201cDualtkb: A dual learning bridge between text and\nknowledge base,\u201d 2020.\n[173] Y. Lu, Q. Liu, D. Dai, X. Xiao, H. Lin, X. Han, L. Sun, and H. Wu, \u201cUnified structure generation for universal information\nextraction,\u201d arXiv preprint arXiv:2203.12277, 2022.\n[174] I. Melnyk, P. Dognin, and P. Das, \u201cKnowledge graph generation from text,\u201d arXiv preprint arXiv:2211.10511, 2022.\n[175] C. Zhao, M. Walker, and S. Chaturvedi, \u201cBridging the structural gap between encoding and decoding for data-to-text\ngeneration,\u201d in Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, (Online),\npp. 2481\u20132491, Association for Computational Linguistics, July 2020.\n[176] B. Distiawan, J. Qi, R. Zhang, and W. Wang, \u201cGtr-lstm: A triple encoder for sentence generation from rdf data,\u201d\nin Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),\npp. 1627\u20131637, 2018.\n[177] L. Song, Y. Zhang, Z. Wang, and D. Gildea, \u201cA graph-to-sequence model for amr-to-text generation,\u201d 2018.\n[178] R. Koncel-Kedziorski, D. Bekal, Y. Luan, M. Lapata, and H. Hajishirzi, \u201cText generation from knowledge graphs with\ngraph transformers,\u201d arXiv preprint arXiv:1904.02342, 2019.\n[179] P. Veli\u010dkovi\u0107, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio, \u201cGraph attention networks,\u201d arXiv preprint\narXiv:1710.10903, 2017.\n[180] L. F. Ribeiro, Y. Zhang, C. Gardent, and I. Gurevych, \u201cModeling global and local node contexts for text generation\nfrom knowledge graphs,\u201d Transactions of the Association for Computational Linguistics, vol. 8, pp. 589\u2013604, 2020.\n[181] S. Yao, T. Wang, and X. Wan, \u201cHeterogeneous graph transformer for graph-to-sequence learning,\u201d in Proceedings of\nthe 58th Annual Meeting of the Association for Computational Linguistics, pp. 7145\u20137154, 2020.\n[182] L. Dong and M. Lapata, \u201cLanguage to logical form with neural attention,\u201d arXiv preprint arXiv:1601.01280, 2016.\n[183] R. Jia and P. Liang, \u201cData recombination for neural semantic parsing,\u201d arXiv preprint arXiv:1606.03622, 2016.\n[184] C. Lyu and I. Titov, \u201cAmr parsing as graph prediction with latent alignment,\u201d arXiv preprint arXiv:1805.05286, 2018.\n[185] B. Chen, L. Sun, and X. Han, \u201cSequence-to-action: End-to-end semantic graph generation for semantic parsing,\u201d arXiv\npreprint arXiv:1809.00773, 2018.\n[186] S. Zhang, X. Ma, K. Duh, and B. V. Durme, \u201cAmr parsing as sequence-to-graph transduction,\u201d 2019.\n[187] F. Fancellu, S. Gilroy, A. Lopez, and M. Lapata, \u201cSemantic graph parsing with recurrent neural network dag grammars,\u201d\narXiv preprint arXiv:1910.00051, 2019.\n[188] B. Su, D. Du, Z. Yang, Y. Zhou, J. Li, A. Rao, H. Sun, Z. Lu, and J.-R. Wen, \u201cA molecular multimodal foundation model\nassociating molecule graphs with natural language,\u201d 2022.\n[189] C. Edwards, C. Zhai, and H. Ji, \u201cText2mol: Cross-modal molecule retrieval with natural language queries,\u201d pp. 595\u2013607,\n01 2021.\n[190] C. Edwards, T. Lai, K. Ros, G. Honke, K. Cho, and H. Ji, \u201cTranslation between molecules and natural language,\u201d 2022.\n[191] Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang, et al., \u201cCodebert: A pre-trained\nmodel for programming and natural languages,\u201d arXiv preprint arXiv:2002.08155, 2020.\n[192] A. Kanade, P. Maniatis, G. Balakrishnan, and K. Shi, \u201cLearning and evaluating contextual embedding of source code,\u201d\nin International conference on machine learning, pp. 5110\u20135121, PMLR, 2020.\n[193] Y. Wang, W. Wang, S. Joty, and S. C. Hoi, \u201cCodet5: Identifier-aware unified pre-trained encoder-decoder models for\ncode understanding and generation,\u201d arXiv preprint arXiv:2109.00859, 2021.\n[194] W. U. Ahmad, S. Chakraborty, B. Ray, and K.-W. Chang, \u201cUnified pre-training for program understanding and\ngeneration,\u201d arXiv preprint arXiv:2103.06333, 2021.\n[195] P. Yin and G. Neubig, \u201cA syntactic neural model for general-purpose code generation,\u201d arXiv preprint arXiv:1704.01696,\n2017.\n[196] H. Dai, Y. Tian, B. Dai, S. Skiena, and L. Song, \u201cSyntax-directed variational autoencoder for structured data,\u201d arXiv\npreprint arXiv:1802.08786, 2018.\n[197] M. Allamanis, M. Brockschmidt, and M. Khademi, \u201cLearning to represent programs with graphs,\u201d arXiv preprint\narXiv:1711.00740, 2017.\n[198] E. Nijkamp, B. Pang, H. Hayashi, L. Tu, H. Wang, Y. Zhou, S. Savarese, and C. Xiong, \u201cCodegen: An open large\nlanguage model for code with multi-turn program synthesis,\u201d 2022.\n[199] S. K. Lahiri, A. Naik, G. Sakkas, P. Choudhury, C. von Veh, M. Musuvathi, J. P. Inala, C. Wang, and J. Gao, \u201cInteractive\ncode generation via test-driven user-intent formalization,\u201d 2022.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:38\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\n[200] L. Zhou, J. Gao, D. Li, and H.-Y. Shum, \u201cThe design and implementation of xiaoice, an empathetic social chatbot,\u201d\nComputational Linguistics, vol. 46, no. 1, pp. 53\u201393, 2020.\n[201] D. Adiwardana, M.-T. Luong, D. R. So, J. Hall, N. Fiedel, R. Thoppilan, Z. Yang, A. Kulshreshtha, G. Nemade, Y. Lu,\net al., \u201cTowards a human-like open-domain chatbot,\u201d arXiv preprint arXiv:2001.09977, 2020.\n[202] K. Shuster, J. Xu, M. Komeili, D. Ju, E. M. Smith, S. Roller, M. Ung, M. Chen, K. Arora, J. Lane, et al., \u201cBlenderbot 3: a\ndeployed conversational agent that continually learns to responsibly engage,\u201d arXiv preprint arXiv:2208.03188, 2022.\n[203] P. Dhariwal, H. Jun, C. Payne, J. W. Kim, A. Radford, and I. Sutskever, \u201cJukebox: A generative model for music,\u201d arXiv\npreprint arXiv:2005.00341, 2020.\n[204] S. Lu, D. Guo, S. Ren, J. Huang, A. Svyatkovskiy, A. Blanco, C. Clement, D. Drain, D. Jiang, D. Tang, et al., \u201cCodexglue:\nA machine learning benchmark dataset for code understanding and generation,\u201d arXiv preprint arXiv:2102.04664, 2021.\n[205] L. Tunstall, L. Von Werra, and T. Wolf, Natural language processing with transformers. \" O\u2019Reilly Media, Inc.\", 2022.\n[206] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, A. Ray,\nR. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser,\nM. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, W. H.\nGuss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike,\nJ. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer, P. Welinder, B. McGrew,\nD. Amodei, S. McCandlish, I. Sutskever, and W. Zaremba, \u201cEvaluating Large Language Models Trained on Code,\u201d July\n2021. arXiv:2107.03374 [cs].\n[207] A. Lewkowycz, A. Andreassen, D. Dohan, E. Dyer, H. Michalewski, V. Ramasesh, A. Slone, C. Anil, I. Schlag, T. Gutman-\nSolo, et al., \u201cSolving quantitative reasoning problems with language models,\u201d arXiv preprint arXiv:2206.14858, 2022.\n[208] A. Fawzi, M. Balog, A. Huang, T. Hubert, B. Romera-Paredes, M. Barekatain, A. Novikov, F. J. R Ruiz, J. Schrittwieser,\nG. Swirszcz, et al., \u201cDiscovering faster matrix multiplication algorithms with reinforcement learning,\u201d Nature, vol. 610,\nno. 7930, pp. 47\u201353, 2022.\n[209] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann,\net al., \u201cPalm: Scaling language modeling with pathways,\u201d arXiv preprint arXiv:2204.02311, 2022.\n[210] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, \u201cImagenet: A large-scale hierarchical image database,\u201d in\n2009 IEEE conference on computer vision and pattern recognition, pp. 248\u2013255, Ieee, 2009.\n[211] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, \u201cPre-train, prompt, and predict: A systematic survey of\nprompting methods in natural language processing,\u201d ACM Computing Surveys, vol. 55, no. 9, pp. 1\u201335, 2023.\n[212] C. Zhou, Q. Li, C. Li, J. Yu, Y. Liu, G. Wang, K. Zhang, C. Ji, Q. Yan, L. He, et al., \u201cA comprehensive survey on pretrained\nfoundation models: A history from bert to chatgpt,\u201d arXiv preprint arXiv:2302.09419, 2023.\n[213] K. Clark, M.-T. Luong, Q. V. Le, and C. D. Manning, \u201cElectra: Pre-training text encoders as discriminators rather than\ngenerators,\u201d arXiv preprint arXiv:2003.10555, 2020.\n[214] V. Sanh, L. Debut, J. Chaumond, and T. Wolf, \u201cDistilbert, a distilled version of bert: smaller, faster, cheaper and lighter,\u201d\narXiv preprint arXiv:1910.01108, 2019.\n[215] A. Borji, \u201cA categorical archive of chatgpt failures,\u201d 2023.\n[216] \u201cCould chatgpt become a monster misinformation superspreader?,\u201d Jan 2023.\n[217] A. Mahadevan, \u201cThis newspaper doesn\u2019t exist: How chatgpt can launch fake news sites in minutes,\u201d Feb 2023.\n[218] \u201cWhy can\u2019t ai draw realistic human hands?,\u201d Jan 2023.\n[219] S. Wang, D. Lo, and L. Jiang, \u201cAn empirical study on developer interactions in stackoverflow,\u201d in Proceedings of the\n28th annual ACM symposium on applied computing, pp. 1019\u20131024, 2013.\n[220] H. Zhang, Y. Li, F. Ma, J. Gao, and L. Su, \u201cTexttruth: an unsupervised approach to discover trustworthy information\nfrom multi-sourced text data,\u201d in Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery\n& Data Mining, pp. 2729\u20132737, 2018.\n[221] B. Goodrich, V. Rao, P. J. Liu, and M. Saleh, \u201cAssessing the factual accuracy of generated text,\u201d in Proceedings of the\n25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 166\u2013175, 2019.\n[222] C.-Y. Lin, \u201cRouge: A package for automatic evaluation of summaries,\u201d in Text summarization branches out, pp. 74\u201381,\n2004.\n[223] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, \u201cBleu: a method for automatic evaluation of machine translation,\u201d in\nProceedings of the 40th annual meeting of the Association for Computational Linguistics, pp. 311\u2013318, 2002.\n[224] O. Evans, O. Cotton-Barratt, L. Finnveden, A. Bales, A. Balwit, P. Wills, L. Righetti, and W. Saunders, \u201cTruthful ai:\nDeveloping and governing ai that does not lie,\u201d arXiv preprint arXiv:2110.06674, 2021.\n[225] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim, C. Hesse, S. Jain, V. Kosaraju, W. Saunders, et al., \u201cWebgpt:\nBrowser-assisted question-answering with human feedback,\u201d arXiv preprint arXiv:2112.09332, 2021.\n[226] A. Fan, Y. Jernite, E. Perez, D. Grangier, J. Weston, and M. Auli, \u201cEli5: Long form question answering,\u201d arXiv preprint\narXiv:1907.09190, 2019.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:39\n[227] S. Lin, J. Hilton, and O. Evans, \u201cTruthfulqa: Measuring how models mimic human falsehoods,\u201d arXiv preprint\narXiv:2109.07958, 2021.\n[228] N. Lee, W. Ping, P. Xu, M. Patwary, M. Shoeybi, and B. Catanzaro, \u201cFactuality enhanced language models for open-\nended text generation,\u201d arXiv preprint arXiv:2206.04624, 2022.\n[229] E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell, \u201cOn the dangers of stochastic parrots: Can language\nmodels be too big?,\u201d in Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, pp. 610\u2013623,\n2021.\n[230] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill,\net al., \u201cOn the opportunities and risks of foundation models,\u201d arXiv preprint arXiv:2108.07258, 2021.\n[231] Z. Kenton, T. Everitt, L. Weidinger, I. Gabriel, V. Mikulik, and G. Irving, \u201cAlignment of language agents,\u201d arXiv preprint\narXiv:2103.14659, 2021.\n[232] J. Dhamala, T. Sun, V. Kumar, S. Krishna, Y. Pruksachatkun, K.-W. Chang, and R. Gupta, \u201cBold: Dataset and metrics\nfor measuring biases in open-ended language generation,\u201d in Proceedings of the 2021 ACM conference on fairness,\naccountability, and transparency, pp. 862\u2013872, 2021.\n[233] P. P. Liang, C. Wu, L.-P. Morency, and R. Salakhutdinov, \u201cTowards understanding and mitigating social biases in\nlanguage models,\u201d in International Conference on Machine Learning, pp. 6565\u20136576, PMLR, 2021.\n[234] M. Nadeem, A. Bethke, and S. Reddy, \u201cStereoset: Measuring stereotypical bias in pretrained language models,\u201d arXiv\npreprint arXiv:2004.09456, 2020.\n[235] I. Solaiman, M. Brundage, J. Clark, A. Askell, A. Herbert-Voss, J. Wu, A. Radford, G. Krueger, J. W. Kim, S. Kreps, et al.,\n\u201cRelease strategies and the social impacts of language models,\u201d arXiv preprint arXiv:1908.09203, 2019.\n[236] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, A. Kulshreshtha, H.-T. Cheng, A. Jin, T. Bos, L. Baker, Y. Du, et al.,\n\u201cLamda: Language models for dialog applications,\u201d arXiv preprint arXiv:2201.08239, 2022.\n[237] D. Ganguli, L. Lovitt, J. Kernion, A. Askell, Y. Bai, S. Kadavath, B. Mann, E. Perez, N. Schiefer, K. Ndousse, et al.,\n\u201cRed teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned,\u201d arXiv preprint\narXiv:2209.07858, 2022.\n[238] Y. Wu, N. Yu, Z. Li, M. Backes, and Y. Zhang, \u201cMembership inference attacks against text-to-image generation models,\u201d\narXiv preprint arXiv:2210.00968, 2022.\n[239] H. Hu, Z. Salcic, L. Sun, G. Dobbie, P. S. Yu, and X. Zhang, \u201cMembership inference attacks on machine learning: A\nsurvey,\u201d ACM Computing Surveys (CSUR), vol. 54, no. 11s, pp. 1\u201337, 2022.\n[240] J. Duan, F. Kong, S. Wang, X. Shi, and K. Xu, \u201cAre diffusion models vulnerable to membership inference attacks?,\u201d\narXiv preprint arXiv:2302.01316, 2023.\n[241] H. Hu and J. Pang, \u201cMembership inference of diffusion models,\u201d arXiv preprint arXiv:2301.09956, 2023.\n[242] T. Matsumoto, T. Miura, and N. Yanai, \u201cMembership inference attacks against diffusion models,\u201d arXiv preprint\narXiv:2302.03262, 2023.\n[243] N. Carlini, D. Ippolito, M. Jagielski, K. Lee, F. Tram\u00e8r, and C. Zhang, \u201cQuantifying memorization across neural language\nmodels,\u201d arXiv preprint arXiv:2202.07646, 2022.\n[244] N. Carlini, Y. Liu, H. Daume III, U. Erlingsson, T. Kohno, and D. Song, \u201cExtracting training data from large language\nmodels,\u201d in 30th USENIX Security Symposium (USENIX Security 21), 2021.\n[245] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, \u201cLanguage models are unsupervised multitask\nlearners,\u201d OpenAI Blog, vol. 1, no. 8, 2019.\n[246] G. Somepalli, V. Singla, M. Goldblum, J. Geiping, and T. Goldstein, \u201cDiffusion art or digital forgery? investigating data\nreplication in diffusion models,\u201d arXiv preprint arXiv:2212.03860, 2021.\n[247] N. Carlini, J. Hayes, M. Nasr, M. Jagielski, V. Sehwag, F. Tram\u00e8r, B. Balle, D. Ippolito, and E. Wallace, \u201cExtracting\ntraining data from diffusion models,\u201d arXiv preprint arXiv:2301.13188, 2023.\n[248] S. Reddy, S. Allan, S. Coghlan, and P. Cooper, \u201cA governance model for the application of ai in health care,\u201d Journal of\nthe American Medical Informatics Association, vol. 27, no. 3, pp. 491\u2013497, 2020.\n[249] Y. Qi and J. Xiao, \u201cFintech: Ai powers financial services to improve people\u2019s lives,\u201d Communications of the ACM, vol. 61,\nno. 11, pp. 65\u201369, 2018.\n[250] S. Grigorescu, B. Trasnea, T. Cocias, and G. Macesanu, \u201cA survey of deep learning techniques for autonomous driving,\u201d\nJournal of Field Robotics, vol. 37, no. 3, pp. 362\u2013386, 2020.\n[251] Y. Gil, M. Greaves, J. Hendler, and H. Hirsh, \u201cAmplify scientific discovery with artificial intelligence,\u201d Science, vol. 346,\nno. 6206, pp. 171\u2013172, 2014.\n[252] R. Taylor, M. Kardas, G. Cucurull, T. Scialom, A. Hartshorn, E. Saravia, A. Poulton, V. Kerkez, and R. Stojnic, \u201cGalactica:\nA large language model for science,\u201d arXiv preprint arXiv:2211.09085, 2022.\n[253] O. Ostapenko, T. Lesort, P. Rodr\u00edguez, M. R. Arefin, A. Douillard, I. Rish, and L. Charlin, \u201cContinual learning with\nfoundation models: An empirical study of latent replay,\u201d in Conference on Lifelong Learning Agents, pp. 60\u201391, PMLR,\n2022.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:40\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\n[254] S. Gururangan, A. Marasovi\u0107, S. Swayamdipta, K. Lo, I. Beltagy, D. Downey, and N. A. Smith, \u201cDon\u2019t stop pretraining:\nAdapt language models to domains and tasks,\u201d arXiv preprint arXiv:2004.10964, 2020.\n[255] I. Chalkidis, M. Fergadiotis, P. Malakasiotis, N. Aletras, and I. Androutsopoulos, \u201cLegal-bert: The muppets straight\nout of law school,\u201d arXiv preprint arXiv:2010.02559, 2020.\n[256] J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. Chi, Q. Le, and D. Zhou, \u201cChain of thought prompting elicits reasoning\nin large language models,\u201d arXiv preprint arXiv:2201.11903, 2022.\n[257] Z. Zhang, A. Zhang, M. Li, H. Zhao, G. Karypis, and A. Smola, \u201cMultimodal chain-of-thought reasoning in language\nmodels,\u201d arXiv preprint arXiv:2302.00923, 2023.\n[258] A. Madaan, S. Zhou, U. Alon, Y. Yang, and G. Neubig, \u201cLanguage models of code are few-shot commonsense learners,\u201d\narXiv preprint arXiv:2210.07128, 2022.\n[259] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. d. L. Casas, L. A. Hendricks, J. Welbl,\nA. Clark, et al., \u201cTraining compute-optimal large language models,\u201d arXiv preprint arXiv:2203.15556, 2022.\n[260] A. Aghajanyan, L. Yu, A. Conneau, W.-N. Hsu, K. Hambardzumyan, S. Zhang, S. Roller, N. Goyal, O. Levy, and\nL. Zettlemoyer, \u201cScaling laws for generative mixed-modal language models,\u201d arXiv preprint arXiv:2301.03728, 2023.\n[261] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, \u201cDistributed representations of words and phrases and\ntheir compositionality,\u201d Advances in neural information processing systems, vol. 26, 2013.\n[262] J. Pennington, R. Socher, and C. D. Manning, \u201cGlove: Global vectors for word representation,\u201d in Proceedings of the\n2014 conference on empirical methods in natural language processing (EMNLP), pp. 1532\u20131543, 2014.\n[263] A. M. Dai and Q. V. Le, \u201cSemi-supervised sequence learning,\u201d Advances in neural information processing systems,\nvol. 28, 2015.\n[264] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, \u201cEnriching word vectors with subword information,\u201d Transactions\nof the association for computational linguistics, vol. 5, pp. 135\u2013146, 2017.\n[265] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer, \u201cDeep contextualized word\nrepresentations,\u201d arXiv, 2018.\n[266] Y. Sun, S. Wang, Y. Li, S. Feng, X. Chen, H. Zhang, X. Tian, D. Zhu, H. Tian, and H. Wu, \u201cErnie: Enhanced representation\nthrough knowledge integration,\u201d arXiv preprint arXiv:1904.09223, 2019.\n[267] Z. Dai, Z. Yang, Y. Yang, J. Carbonell, Q. V. Le, and R. Salakhutdinov, \u201cTransformer-xl: Attentive language models\nbeyond a fixed-length context,\u201d arXiv preprint arXiv:1901.02860, 2019.\n[268] L. Dong, N. Yang, W. Wang, F. Wei, X. Liu, Y. Wang, J. Gao, M. Zhou, and H.-W. Hon, \u201cUnified language model\npre-training for natural language understanding and generation,\u201d Advances in neural information processing systems,\nvol. 32, 2019.\n[269] K. Song, X. Tan, T. Qin, J. Lu, and T.-Y. Liu, \u201cMass: Masked sequence to sequence pre-training for language generation,\u201d\narXiv preprint arXiv:1905.02450, 2019.\n[270] W. Wang, B. Bi, M. Yan, C. Wu, Z. Bao, J. Xia, L. Peng, and L. Si, \u201cStructbert: Incorporating language structures into\npre-training for deep language understanding,\u201d arXiv, 2019.\n[271] M. E. Peters, M. Neumann, R. L. Logan IV, R. Schwartz, V. Joshi, S. Singh, and N. A. Smith, \u201cKnowledge enhanced\ncontextual word representations,\u201d arXiv preprint arXiv:1909.04164, 2019.\n[272] W. Liu, P. Zhou, Z. Zhao, Z. Wang, H. Deng, and Q. Ju, \u201cFastbert: a self-distilling bert with adaptive inference time,\u201d\narXiv preprint arXiv:2004.02178, 2020.\n[273] M. Joshi, D. Chen, Y. Liu, D. S. Weld, L. Zettlemoyer, and O. Levy, \u201cSpanbert: Improving pre-training by representing\nand predicting spans,\u201d Transactions of the Association for Computational Linguistics, vol. 8, pp. 64\u201377, 2020.\n[274] N. Kitaev, \u0141. Kaiser, and A. Levskaya, \u201cReformer: The efficient transformer,\u201d arXiv preprint arXiv:2001.04451, 2020.\n[275] X. Jiao, Y. Yin, L. Shang, X. Jiang, X. Chen, L. Li, F. Wang, and Q. Liu, \u201cTinybert: Distilling bert for natural language\nunderstanding,\u201d arXiv preprint arXiv:1909.10351, 2019.\n[276] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut, \u201cAlbert: A lite bert for self-supervised learning of\nlanguage representations,\u201d arXiv preprint arXiv:1909.11942, 2019.\n[277] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozi\u00e8re, N. Goyal, E. Hambro, F. Azhar,\net al., \u201cLlama: Open and efficient foundation language models,\u201d arXiv preprint arXiv:2302.13971, 2023.\n[278] J. T. Rolfe, \u201cDiscrete variational autoencoders,\u201d arXiv preprint arXiv:1609.02200, 2016.\n[279] W. Kim, B. Son, and I. Kim, \u201cVilt: Vision-and-language transformer without convolution or region supervision,\u201d in\nInternational Conference on Machine Learning, pp. 5583\u20135594, PMLR, 2021.\n[280] J. Cho, J. Lu, D. Schwenk, H. Hajishirzi, and A. Kembhavi, \u201cX-lxmert: Paint, caption and answer questions with\nmulti-modal transformers,\u201d arXiv preprint arXiv:2009.11278, 2020.\n[281] Z. Huang, Z. Zeng, B. Liu, D. Fu, and J. Fu, \u201cPixel-bert: Aligning image pixels with text by deep multi-modal\ntransformers,\u201d arXiv preprint arXiv:2004.00849, 2020.\n[282] Y. Huo, M. Zhang, G. Liu, H. Lu, Y. Gao, G. Yang, J. Wen, H. Zhang, B. Xu, W. Zheng, et al., \u201cWenlan: Bridging vision\nand language by large-scale multi-modal pre-training,\u201d arXiv preprint arXiv:2103.06561, 2021.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:41\n[283] J. Li, D. Li, S. Savarese, and S. Hoi, \u201cBlip-2: Bootstrapping language-image pre-training with frozen image encoders\nand large language models,\u201d arXiv preprint arXiv:2301.12597, 2023.\nA\nCURATED ADVANCES IN GENERATIVE AI\nIn this section, we present a comprehensive review of the recent significant advancements in the\nfield of generative AI. Consistent with the aforementioned discussion, we classify the general\nframework into unimodal and multimodal generative models. In each subsection, we further\ncategorize the models based on specific modalities, and we provide a table summary of relative\npaper details.\nA.1\nLanguage\nIn this section, we give a summary of the main milestone models in NLP. Generally, the architec-\nture includes probabilistic objectives, encoder, decoder, and encoder-decoder structure. We also\nsummarize the backbones of these methods.\nYear\nConference\nMethod\nArchitecture\nBackbone\nCode\n2013\nNeurIPS\nSkip-Gram [261]\nProbabilistic\nWord2Vec\nhttps://github.com/.../models\n2014\nEMNLP\nGloVe [262]\nProbabilistic\nWord2Vec\nhttps://github.com/.../GloVe\n2015\nNeurIPS\nLM-LSTM [263]\nProbabilistic\nLSTM\n-\n2017\nTACL\nFastText [264]\nProbabilistic\nWord2Vec\nhttps://github.com/.../fastText\n2018\nNAACL\nELMO [265]\nEncoder\nLSTM\nhttps://allennlp.org/elmo\n2018\n-\nGPT [61]\nDecoder\nTransformer\nhttps://github.com/huggingface/transformers\n2019\nACL\nERNIE [266]\nEncoder\nTransformer\nhttps://github.com/.../ERNIE\n2019\nACL\nTransformer-XL [267]\nEncoder\nTransformer\nhttps://github.com/.../transformer-xl\n2019\nNeurIPS\nUNILM [268]\nEncoder\nTransformer\nhttps://github.com/.../unilm\n2019\nNAACL\nBERT [42]\nEncoder\nTransformer\nhttps://github.com/google-research/bert\n2019\nCoRR\nRoBERTa [43]\nEncoder\nTransformer\nhttps://github.com/pytorch/fairseq\n2019\nNeurIPS\nXLNet [44]\nEncoder\nTransformer\nhttps://github.com/zihangdai/xlnet\n2019\nNeurIPS\nDistilBERT [214]\nEncoder\nTransformer\nhttps://github.com/huggingface/transformers\n2019\nICML\nMASS [269]\nEncoder\nTransformer\nhttps://github.com/microsoft/MASS\n2019\nICLR\nStructBERT [270]\nEncoder\nTransformer\n-\n2019\nEMNLP\nKnowBERT [271]\nEncoder\nTransformer\nhttps://github.com/.../kb\n2019\n-\nGPT-2 [245]\nDecoder\nTransformer\nhttps://github.com/openai/gpt-2\n2019\nJMLR\nT5 [56]\nEncoder-Decoder\nTransformer\nhttps://github.com/google-research/text-to-text-transfer-transformer\n2019\n-\nMegatron [65]\nGeneral\nTransformer\nhttps://github.com/NVIDIA/Megatron-LM\n2020\nACL\nfastBERT [272]\nEncoder\nTransformer\nhttps://github.com/.../FastBERT\n2020\nACL\nspanBERT [273]\nEncoder\nTransformer\nhttps://github.com/.../SpanBERT\n2020\nICLR\nReformer [274]\nEncoder\nReformer\nhttps://github.com/.../reformer\n2020\nEMNLP\nTinyBERT [275]\nEncoder\nTransformer\nhttps://github.com/.../TinyBERT\n2020\nICLR\nALBERT [276]\nEncoder\nTransformer\nhttps://github.com/google-research/ALBERT\n2020\nICLR\nELECTRA [213]\nEncoder\nTransformer\nhttps://github.com/google-research/electra\n2020\nNeurIPS\nGPT-3 [245]\nDecoder\nTransformer\nhttps://github.com/openai/gpt-3\n2020\nACL\nBART [34]\nEncoder-Decoder\nTransformer\nhttps://github.com/huggingface/transformers\n2020\n-\nPaLM [209]\nDecoder\nTransformer\nhttps://github.com/lucidrains/PaLM-pytorch\n2021\n-\nGopher [39]\nDecoder\nTransformer\n-\n2021\nJMLR\nSwitch [67]\nEncoder-Decoder\nTransformer\nhttps://github.com/tensorflow/mesh\n2022\n-\nLaMDA [236]\nDecoder\nTransformer\nhttps://github.com/.../LaMDA\n2022\n-\nOPT [45]\nDecoder\nTransformer\nhttps://github.com/facebookresearch/metaseq\n2022\n-\nInstructGPT [10]\nDecoder\nTransformer\nhttps://github.com/openai/following-instructions-human-feedback\n2022\n-\nSparrow [46]\nDecoder\nTransformer\n-\n2022\n-\nBLOOM [64]\nDecoder\nTransformer\nhttps://github.com/bigscience-workshop/bigscience\n2022\n-\nMT-NLG [66]\nDecoder\nTransformer\nhttps://github.com/microsoft/DeepSpeed\n2022\nICLR\nHTLM [69]\nEncoder-Decoder\nTransformer\n-\n2022\nACL\nDQ-BART [70]\nEncoder-Decoder\nTransformer\nhttps://github.com/amazon-research/dq-bart\n2022\nICLR\nExT5 [68]\nEncoder-Decoder\nTransformer\nhttps://github.com/google-research/text-to-text-transfer-transformer\n2023\n-\nLLaMA [277]\nDecoder\nTransformer\n-\nTable 2. Major natural language models.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:42\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nA.2\nVision\nYear\nMethod\nArchitecture\nCategory\nCode\n2014\nGAN [29]\nGAN\nTraditional\nhttps://github.com/goodfeli/adversarial\n2015\nLAPGAN [71]\nGAN\nTraditioal\nhttps://github.com/facebook/eyescream\n2015\nDCGANs [73]\nGAN\nTraditioal\nhttps://github.com/carpedm20/DCGAN\n2017\nProgressive GAN [74]\nGAN\nTraditioal\nhttps://github.com/tkarras/progre...\n2019\nSAGAN [75]\nGAN\nTraditioal\nhttps://github.com/brain-research/self\n2018\nBigGAN [76]\nGAN\nTraditioal\nhttps://github.com/ajbrock/BigGAN\n2019\nStyleGAN [77]\nGAN\nTraditioal\nhttps://github.com/NVlabs/stylegan\n2016\nBiGAN [78]\nGAN\nTraditioal\nhttps://github.com/eriklindernoren/GAN\n2018\nAGE [79]\nGAN\nTraditioal\nhttps://github.com/DmitryUlyanov/AGE\n2017\nD2GAN [80]\nGAN\nTraditioal\nhttps://github.com/tund/D2GAN\n2016\nGMAN [81]\nGAN\nTraditioal\nhttps://github.com/zhengchuanpan/GMAN\n2017\nMGAN [82]\nGAN\nTraditioal\nhttps://github.com/qhoangdl/MGAN\n2018\nMAD-GAN [83]\nGAN\nTraditioal\nhttps://github.com/LiDan456/MAD-GANs\n2016\nCoGAN [84]\nGAN\nTraditioal\nhttps://github.com/mingyuliutw/CoGAN\n2016\nInfoGAN [85]\nGAN\nRepresentative variants\nhttps://github.com/eriklindernoren/...GAN\n2014\nCGANs [86]\nGAN\nRepresentative variants\nhttps://github.com/pfnet-research/sngan...\n2018\nC-CycleGAN [87]\nGAN\nRepresentative variants\n-\n2019\nMSGAN [88]\nGAN\nRepresentative variants\nhttps://github.com/HelenMao/MSGAN\n2016\nf-GAN [89]\nGAN\nRepresentative variants\nhttps://github.com/mboudiaf/Mut...\n2017\nWGAN [90]\nGAN\nObjective\nhttps://github.com/daheyinyin/wgan\n2020\nGLS-GAN [91]\nGAN\nObjective\nhttps://github.com/guojunq/lsgan\n2017\nLS-GAN [92]\nGAN\nObjective\nhttps://github.com/xudonmao/LSGAN\n2018\nSNGAN [93]\nGAN\nObjective\nhttps://github.com/pfnet-research/sngan\n2016\nChe et al. [94]\nGAN\nObjective\n-\n2016\nUnrolledGAN [95]\nGAN\nObjective\nhttps://github.com/poolio/unrolledgan\n2018\nRelativisticGAN [96]\nGAN\nObjective\nhttps://github.com/AlexiaJM/RelativisticGAN\n2013\nVAE [30]\nVAE\nTraditional\nhttps://github.com/AntixK/PyTorch-VAE\n2018\nVampPrior [99]\nVAE\nComplex priors\nhttps://github.com/jmtomczak/vaevampprior\n2019\nBIVA[100]\nVAE\nComplex priors\nhttps://github.com/vlievin/biva-pytorch\n2020\nNVAE[101]\nVAE\nComplex priors\nhttps://github.com/NVlabs/NVAE\n2021\nGHVAE [102]\nVAE\nComplex priors\n-\n2019\nRAE [103]\nVAE\nRegularized Autoencoders\nhttps://github.com/ParthaEth/Regul...\n2021\ndGAN [278]\nVAE\nRegularized Autoencoders\nhttps://github.com/topics/discrete...\n2017\nVQ-VAE [104]\nVAE\nRegularized Autoencoders\nhttps://github.com/deepmind/...vqvae\n2019\nVQ-VAE2 [105]\nVAE\nRegularized Autoencoders\nhttps://github.com/deepmind/sonnet\n2014\nNICE [57]\nFlow\nCoupling and autoregressive\nhttps://github.com/EugenHotaj/...nice\n2016\nReal NVP [106]\nFlow\nCoupling and autoregressive\nhttps://github.com/tensorflow/models\n2017\nMAF [107]\nFlow\nCoupling and autoregressive\nhttps://github.com/gpapamak/maf\n2018\nNAF [108]\nFlow\nCoupling and autoregressive\nhttps://github.com/CW-Huang/NAF\n2020\nBNAF [109]\nFlow\nCoupling and autoregressive\nhttps://github.com/nicola-decao/BNAF\n2017\nConvFlow [110]\nFlow\nConvolutional and Residual\n-\n2019\nE-ConvFlow [111]\nFlow\nConvolutional and Residual\nhttps://github.com/ehoogeboom/emerging\n2017\nRevNets [112]\nFlow\nConvolutional and Residual\nhttps://github.com/renmengye/revnet-public\n2018\ni-RevNets [113]\nFlow\nConvolutional and Residual\nhttps://github.com/jhjacobsen/pytorch-i-revnet\n2020\nDDPM [115]\nDiffusion\nTraditional\nhttps://github.com/hojonathanho/diffusion\n2019\nNCSN [31]\nDiffusion\nTraditional\nhttps://github.com/ermongroup/ncsn\n2020\nScore SDE [116]\nDiffusion\nTraining Enhance\nhttps://github.com/yang-song/scoresde\n2022\nSalimans et al. [117]\nDiffusion\nTraining Enhance\nhttps://github.com/Hramchenko/diffusion..distiller\n2022\nTDPM [118]\nDiffusion\nTraining Enhance\nhttps://github.com/jegzheng/truncat..\n2022\nES-DDPM [119]\nDiffusion\nTraining Enhance\nhttps://github.com/zhaoyanglyu/early...\n2022\nFranzese et al. [120]\nDiffusion\nTraining Enhance\n-\n2021\nImproved DDPM [121]\nDiffusion\nTraining Enhance\nhttps://github.com/openai/improved-diffusion\n2021\nSan Roman et al. [122]\nDiffusion\nTraining Enhance\n-\n2020\nDDIM [123]\nDiffusion\nTraining-free Sampling\nhttps://github.com/ermongroup/ddim\n2022\nAnalytic-DPM [124]\nDiffusion\nTraining-free Sampling\nhttps://github.com/baofff/Analytic-DPM\n2021\nWatson et al. [125]\nDiffusion\nTraining-free Sampling\n-\n2022\nWatson et al. [126]\nDiffusion\nTraining-free Sampling\n-\n2021\nNachmani et al. [127]\nDiffusion\nNoise Distribution\n-\n2022\nCold Diffusion [128]\nDiffusion\nNoise Distribution\nhttps://github.com/arpitbansal297/cold-...\n2021\nCCDF [129]\nDiffusion\nNoise Distribution\n-\n2022\nDiffuseVAE [130]\nDiffusion\nMixed Modeling\nhttps://github.com/kpandey008/DiffuseVAE\n2021\nLSGM [131]\nDiffusion\nMixed Modeling\nhttps://github.com/NVlabs/LSGM\n2021\nDenoising diffusion GANs [132]\nDiffusion\nMixed Modeling\nhttps://github.com/NVlabs/denoising\n2021\nDiffFlow [133]\nDiffusion\nMixed Modeling\nhttps://github.com/qsh-zh/DiffFlow\nTable 3. Major vision generative models.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\nA Comprehensive Survey of AI-Generated Content (AIGC):\nA History of Generative AI from GAN to ChatGPT\n111:43\nA.3\nVision Language\nYear\nMethod\nTask\nArchitecture\nCode\n2019\nVisualBERT [134]\nVL Encoders\nConcatenated Encoders\nhttps://github.com/uclanlp/visualbert\n2020\nVL-BERT [136]\nVL Encoders\nConcatenated Encoders\nhttps://github.com/jackroos/VL-BERT\n2020\nUNITER [138]\nVL Encoders\nConcatenated Encoders\nhttps://github.com/ChenRocks/UNITER\n2021\nViLT [279]\nVL Encoders\nConcatenated Encoders\nhttps://github.com/dandelin/vilt\n2022\nSimVLM [135]\nVL Encoders\nConcatenated Encoders\n-\n2019\nLXMERT [139]\nVL Encoders\nCross-aligned Encoders\nhttps://github.com/airsplay/lxmert\n2019\nX-LXMERT [280]\nVL Encoders\nCross-aligned Encoders\nhttps://github.com/allenai/x-lxmert\n2020\nPixelBERT [281]\nVL Encoders\nConcatenated Encoders\nhttps://github.com/microsoft/xpretrain\n2019\nViLBERT [140]\nVL Encoders\nCross-aligned Encoders\n-\n2021\nWenLan [282]\nVL Encoders\nCross-aligned Encoders\nhttps://github.com/BAAI-WuDao/BriVl\n2021\nCLIP [245]\nVL Encoders\nCross-aligned Encoders\nhttps://github.com/openai/CLIP\n2019\nVLP [138]\nTo-text Decoders\nEncoder-Decoders\nhttps://github.com/LuoweiZhou/VLP\n2021\nALBEF [141]\nTo-text Decoders\nEncoder-Decoders\nhttps://github.com/salesforce/ALBEF\n2022\nBLIP [142]\nTo-text Decoders\nEncoder-Decoders\nhttps://github.com/salesforce/lavis\n2023\nBLIP-2 [283]\nTo-text Decoders\nFrozen Decoders\nhttps://github.com/salesforce/lavis\n2021\nFrozen [143]\nTo-text Decoders\nFrozen Decoders\n-\n2022\nFlamingo [144]\nTo-text Decoders\nFrozen Decoders\nhttps://github.com/lucidrains/flamingo-pytorch\n2023\nGrounding [145]\nTo-text Decoders\nFrozen Decoders\nhttps://github.com/kohjingyu/fromage\n2017\nStackGAN [148]\nTo-image Decoders\nGAN Decoders\nhttps://github.com/hanzhanggit/StackGAN\n2018\nAttnGAN [149]\nTo-image Decoders\nGAN Decoders\nhttps://github.com/taoxugit/AttnGAN\n2021\nStyleCLIP [150]\nTo-image Decoders\nGAN Decoders\nhttps://github.com/orpatashnik/StyleCLIP\n2021\nGLIDE [151]\nTo-image Decoders\nDiffusion Decoders\nhttps://github.com/openai/glide-text2im\n2022\nStable-diffusion [13]\nTo-image Decoders\nDiffusion Decoders\nhttps://github.com/compvis/stable-diffusion\n2022\nImagen [152]\nTo-image Decoders\nDiffusion Decoders\nhttps://github.com/lucidrains/imagen-pytorch\n2022\nDALL-E-2 [5]\nTo-image Decoders\nDiffusion Decoders\nhttps://github.com/lucidrains/DALLE2-pytorch\n2021\nDALL-E [1]\nTo-image Decoders\nVAE Decoders\nhttps://github.com/openai/DALL-E\nTable 4. Major vision language models.\nA.4\nText Audio\nYear\nMethod\nTask\nCode\n2021\nAdaSpeech [153]\nText-Audio Generation\nhttps://github.com/rishikksh20/AdaSpeech\n2021\nAdaSpeech2\nText-Audio Generation\nhttps://github.com/rishikksh20/AdaSpeech2\n2020\nLombard [154]\nText-Audio Generation\nhttps://github.com/dipjyoti92/TTS-Style-Transfer\n2019\nZhang et al.[156]\nText-Audio Generation\nhttps://github.com/PaddlePaddle/PaddleSpeech\n2019\nYu et al.[157]\nText-Music Generation\n-\n2018\nJTAV [158]\nText-Music Generation\nhttps://github.com/mengshor/JTAV\n2021\nFerraro et al.[159]\nText-Music Generation\nhttps://github.com/andrebola/contrastive-mir-learning\n2016\nChoi et al.[160]\nText-Music Generation\n-\n2021\nMusCaps [161]\nText-Music Generation\nhttps://github.com/ilaria-manco/muscaps\n2022\nManco et al.[162]\nText-Music Generation\nhttps://github.com/ilaria-manco/mulap\n2022\nCLAP [163]\nText-Music Generation\nhttps://github.com/YuanGongND/vocalsound\n2020\nJukebox [203]\nText-Music Generation\nhttps://github.com/openai/jukebox\nTable 5. Major text audio models.\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n111:44\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S. Yu, and Lichao Sun\nA.5\nText Graph\nYear\nMethod\nTask\nCode\n2016\nLi et al. [165]\nText-to-KG Generation\n-\n2019\nKG-BERT [166]\nText-to-KG Generation\nhttps://github.com/yao8839836/kg-bert\n2020\nMalaviya et al. [167]\nText-to-KG Generation\nhttps://github.com/allenai/commonsense-kg-completion\n2019\nPetroni et al. citepetroni2019language\nText-to-KG Generation\nhttps://github.com/facebookresearch/LAMA\n2020\nShin et al. citeshin2020autoprompt\nText-to-KG Generation\nhttps://github.com/ucinlp/autoprompt\n2021\nLi et al. citeli2021prefix\nText-to-KG Generation\nhttps://github.com/XiangLi1999/PrefixTuning\n2022\nLu et al. [173]\nText-to-KG Generation\nhttps://github.com/universal-ie/UIE\n2022\nGrapher [174]\nText-to-KG Generation\nhttps://github.com/ibm/grapher\n2020\nCycleGT [171]\nText-KG Generation\nhttps://github.com/QipengGuo/CycleGT\n2020\nDualTKB [172]\nText-KG Generation\n-\n2018\nGTR-LSTM [176]\nKG-to-Text Generation\n-\n2018\nSong et al. [177]\nKG-to-Text Generation\nhttps://github.com/freesunshine0316/neural-graph-to-seq-mp\n2020\nDUALENC [175]\nKG-to-Text Generation\nhttps://github.com/zhaochaocs/DualEnc\n2019\nKoncel-Kedziorski et al. [178]\nKG-to-Text Generation\nhttps://github.com/rikdz/GraphWriter\n2020\nRibeiro et al. [180]\nKG-to-Text Generation\nhttps://github.com/UKPLab/kg2text\n2020\nHetGT [181]\nKG-to-Text Generation\nhttps://github.com/QAQ-v/HetGT\n2016\nDong et al. [182]\nSemantic Parsing\nhttps://github.com/donglixp/lang2logic\n2016\nJia et al. [183]\nSemantic Parsing\nhttps://worksheets.codalab.org/...\n2018\nLyu et al. [184]\nSemantic Parsing\nhttps://github.com/...PREDICTION\n2018\nChen et al. [185]\nSemantic Parsing\nhttps://github.com/dongpobeyond/Seq2Act\n2019\nZhang et al. [186]\nSemantic Parsing\nhttps://github.com/sheng-z/stog\n2019\nFancellu et al. [187]\nSemantic Parsing\n-\n2021\nText2Mol [189]\nText-Molecule Generation\nhttps://github.com/cnedwards/text2mol\n2022\nMolT5 [190]\nText-Molecule Generation\nhttps://github.com/blender-nlp/MolT5\n2022\nMoMu [188]\nText-Molecule Generation\nhttps://github.com/bingsu12/momu\nTable 6. Major text graph models.\nA.6\nText Code\nYear\nMethod\nTask\nCode\n2020\nCodeBERT [191]\nText-Code Generation\nhttps://github.com/microsoft/CodeBERT\n2020\nCodeBERT [191]\nText-Code Generation\nhttps://github.com/microsoft/CodeBERT\n2020\nCuBERT [192]\nText-Code Generation\nhttps://github.com/google-research/google-research/tree/master/cubert\n2021\nCodeT5 [193]\nText-Code Generation\nhttps://github.com/salesforce/codet5\n2021\nPLBART [194]\nText-Code Generation\nhttps://github.com/wasiahmad/PLBART\n2017\nYin et al. [195]\nText-Code Generation\nhttps://github.com/pcyin/NL2code\n2018\nDai et al. [196]\nText-Code Generation\nhttps://github.com/Hanjun-Dai/sdvae\n2022\nCODEGEN [198]\nText-Code Generation\nhttps://github.com/salesforce/CodeGen\n2022\nTDUIF [199]\nText-Code Generation\n-\nTable 7. Major text code models.\nReceived 20 February 2007; revised 12 March 2009; accepted 5 June 2009\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2018.\n",
    "2303.11717": "A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5\nAll You Need?\nCHAONING ZHANG, Kyung Hee University, South Korea\nCHENSHUANG ZHANG, KAIST, South Korea\nSHENG ZHENG, Beijing Institute of Technology, China\nYU QIAO, Kyung Hee University, South Korea\nCHENGHAO LI, KAIST, South Korea\nMENGCHUN ZHANG, KAIST, South Korea\nSUMIT KUMAR DAM, Kyung Hee University, South Korea\nCHU MYAET THWAL, Kyung Hee University, South Korea\nYE LIN TUN, Kyung Hee University, South Korea\nLE LUANG HUY, Kyung Hee University, South Korea\nDONGUK KIM, Kyung Hee University, South Korea\nSUNG-HO BAE, Kyung Hee University, South Korea\nLIK-HANG LEE, Hong Kong Polytechnic University, Hong Kong (China)\nYANG YANG, University of Electronic Science and technology, China\nHENG TAO SHEN, University of Electronic Science and technology, China\nIN SO KWEON, KAIST, South Korea\nCHOONG SEON HONG, Kyung Hee University, South Korea\nAs ChatGPT goes viral, generative AI (AIGC, a.k.a AI-generated content) has made headlines everywhere because of its ability to\nanalyze and create text, images, and beyond. With such overwhelming media coverage, it is almost impossible for us to miss the\nopportunity to glimpse AIGC from a certain angle. In the era of AI transitioning from pure analysis to creation, it is worth noting that\nChatGPT, with its most recent language model GPT-4, is just a tool out of numerous AIGC tasks . Impressed by the capability of the\nChatGPT, many people are wondering about its limits: can GPT-5 (or other future GPT variants) help ChatGPT unify all AIGC tasks for\nAuthors\u2019 addresses: Chaoning Zhang, Kyung Hee University, South Korea, chaoningzhang1990@gmail.com; Chenshuang Zhang, KAIST, South Korea,\nzcs15@kaist.ac.kr; Sheng Zheng, Beijing Institute of Technology, China, zszhx2021@gmail.com; Yu Qiao, Kyung Hee University, South Korea, qiaoyu@\nkhu.ac.kr; Chenghao Li, KAIST, South Korea, lch17692405449@gmail.com; Mengchun Zhang, KAIST, South Korea, zhangmengchun527@gmail.com; Sumit\nKumar Dam, Kyung Hee University, South Korea, skd160205@khu.ac.kr; Chu Myaet Thwal, Kyung Hee University, South Korea, chumyaet@khu.ac.kr;\nYe Lin Tun, Kyung Hee University, South Korea, yelintun@khu.ac.kr; Le Luang Huy, Kyung Hee University, South Korea, quanghuy69@khu.ac.kr;\nDonguk kim, Kyung Hee University, South Korea, g9896@khu.ac.kr; Sung-Ho Bae, Kyung Hee University, South Korea, shbae@khu.ac.kr; Lik-Hang Lee,\nHong Kong Polytechnic University, Hong Kong (China), iskweon77@kaist.ac.kr; Yang Yang, University of Electronic Science and technology, China,\ndlyyang@gmail.com; Heng Tao Shen, University of Electronic Science and technology, China, shenhengtao@hotmail.com; In So Kweon, KAIST, South\nKorea, iskweon77@kaist.ac.kr; Choong Seon Hong, Kyung Hee University, South Korea, cshong@khu.ac.kr.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components\nof this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to\nredistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\u00a9 2022 Association for Computing Machinery.\nManuscript submitted to ACM\nManuscript submitted to ACM\n1\narXiv:2303.11717v1  [cs.AI]  21 Mar 2023\n2\nZhang et al.\ndiversified content creation? Toward answering this question, a comprehensive review of existing AIGC tasks is needed. As such, our\nwork comes to fill this gap promptly by offering a first look at AIGC, ranging from its techniques to applications. Modern generative\nAI relies on various technical foundations, ranging from model architecture and self-supervised pretraining to generative modeling\nmethods (like GAN and diffusion models). After introducing the fundamental techniques, this work focuses on the technological\ndevelopment of various AIGC tasks based on their output type, including text, images, videos, 3D content, etc., which depicts the\nfull potential of ChatGPT\u2019s future. Moreover, we summarize their significant applications in some mainstream industries, such as\neducation and creativity content. Finally, we discuss the challenges currently faced and present an outlook on how generative AI\nmight evolve in the near future.\nCCS Concepts: \u2022 Computing methodologies \u2192Computer vision tasks; Natural language generation; Machine learning approaches.\nAdditional Key Words and Phrases: Survey, Generative AI, AIGC, ChatGPT, GPT-4, GPT-5, Text Generation, Image Generation\nACM Reference Format:\nChaoning Zhang, Chenshuang Zhang, Sheng Zheng, Yu Qiao, Chenghao Li, Mengchun Zhang, Sumit Kumar Dam, Chu Myaet Thwal,\nYe Lin Tun, Le Luang Huy, Donguk kim, Sung-Ho Bae, Lik-Hang Lee, Yang Yang, Heng Tao Shen, In So Kweon, and Choong Seon\nHong. 2022. A Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?. 1, 1 (March 2022), 56 pages.\nhttps://doi.org/XXXXXXX.XXXXXXX\nContents\nAbstract\n1\nContents\n2\n1\nIntroduction\n3\n2\nOverview\n5\n2.1\nPopularity indicated by search interest\n5\n2.2\nWhy does it get popular?\n6\n2.2.1\nContent need\n6\n2.2.2\nTechnology conditions\n7\n3\nFundamental techniques behind AIGC\n9\n3.1\nGeneral techniques in AI\n9\n3.1.1\nBackbone architecture\n9\n3.1.2\nSelf-supervised pretraining\n12\n3.2\nCreation techniques in AI\n13\n3.2.1\nLikelihood-based models\n14\n3.2.2\nEnergy-based models\n15\n3.2.3\nTwo star-models: from GAN to diffusion model\n15\n4\nAIGC task: text generation\n17\n4.1\nText to text\n18\n4.1.1\nChatbots\n18\n4.1.2\nMachine translation\n19\n4.2\nMultimodal text generation\n20\n4.2.1\nImage-to-text\n20\n4.2.2\nSpeech-to-Text\n21\n5\nAIGC task: image generation\n22\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n3\n5.1\nImage-to-image\n22\n5.1.1\nImage restoration\n22\n5.1.2\nImage editing\n23\n5.2\nMultimodal image generation\n25\n5.2.1\nText-to-image\n25\n5.2.2\nTalking face\n25\n6\nAIGC task: beyond text and image\n27\n6.1\nVideo\n27\n6.2\n3D generation\n28\n6.3\nSpeech\n28\n6.4\nGraph\n29\n6.5\nOthers\n29\n7\nIndustry Applications\n30\n7.1\nEducation\n30\n7.2\nGame and metaverse\n31\n7.3\nMedia\n31\n7.4\nAdvertising\n32\n7.5\nMovie\n33\n7.6\nMusic\n34\n7.7\nPainting\n34\n7.8\nCode development\n35\n7.9\nPhone apps and features\n35\n7.10\nOther fields\n36\n8\nChallenges and outlook\n36\n8.1\nChallenges\n36\n8.2\nOutlook\n37\nReferences\n38\n1\nINTRODUCTION\nGenerative AI (AIGC, a.k.a AI-generated content) has made headlines with intriguing tools like ChatGPT or DALL-\nE [343], suggesting a new era of AI is coming. Under such overwhelming media coverage, the general public are\noffered many opportunities to have a glimpse of AIGC. However, the content in the media report tends to be biased\nor sometimes misleading. Moreover, impressed by the powerful capability of ChatGPT, many people are wondering\nabout its limits. Very recently, OpenAI released GPT-4 [307] which demonstrates remarkable performance improvement\nover the previous variant GPT-3 as well multimodal generation capability like understanding images. Impressed by\nthe powerful capability of GPT-4 powered by AIGC, many are wondering about its limits: can GPT-5 (or other GPT\nvariants) help next-generation ChatGPT unify all AIGC tasks? Therefore, a comprehensive review of generative AI\nserves as a groundwork to respond to the inevitable trend of AI-powered content creation. More importantly, our work\ncomes to fill this gap in a timely manner.\nManuscript submitted to ACM\n4\nZhang et al.\nThe goal of conventional AI is mainly to perform classification [263] or regression [227]. Such a discriminative\napproach renders its role mainly for analyzing existing data. Therefore conventional AI is also often termed analytical\nAI. By contrast, generative AI differentiates by creating new content. However, generative AI often also requires the\nmodel to first understand some existing data (like text instruction) before generating new content [40, 342]. From this\nperspective, analytical AI can be seen as the foundation of modern generative AI and the boundary between them is\noften ambiguous. Note that analytical AI tasks also generate content. For example, the label content is generated in\nimage classification [216]. Nonetheless, image recognition is often not considered in the category of generative AI\nbecause the label content has low dimensionality. Typical tasks for generative AI involve generating high-dimensional\ndata, like text or images. Such generated content can also be used as synthetic data for alleviating the need for more data\nin deep learning [144]. An overview of the popularity of generative AI as well as its underlying reasons, is presented in\nSec.2.\nAs stated above, what distinguishes generative AI from conventional one lies in its generated content. With this said,\ngenerative AI is conceptually similar to AIGC (a.k.a. AI-generated content) [304]. In the context of describing AI-based\ncontent generation, these two terms are often interchangeable. In this work, we call the content generation tasks AIGC\nfor simplicity. For example, ChatGPT is a tool for the AIGC task termed ChatBot [43], which is the tip of the iceberg\nconsidering the variety of AIGC tasks. Despite the high resemblance between generative AI and AIGC, these two\nterms have a nuanced difference. AIGC focuses on the tasks for content generation, while generative AI additionally\nconsiders the fundamental technical foundations that support the development of various AIGC tasks. In this work, we\ndivide those underlying techniques into two classes. The first class refers to the generative modeling techniques, like\nGAN [124] and diffusion model [156], which are directly related to generative AI for content creation. The second class\nof AI techniques mainly consists of backbone architecture (like Transformer [443]) and self-supervised pretraining (like\nBERT [87] or MAE [141]). Some of them are developed in the context of analytical AI. However, they have also become\nessential for demonstrating competitive performance, especially in challenging AIGC tasks. Considering this, both\nclasses of underlying techniques are summarized in Sec.3.\nOn top of these basic techniques, numerous AIGC tasks have become possible and can be straightforwardly categorized\nbased on the generated content type. The development of various AIGC tasks is summarized in Sec.4, Sec.5 and Sec.6.\nSpecifically, Sec.4 and Sec.5 focus on text output and image output, respectively. For text generation, ChatBot [43] and\nmachine translation [497] are two dominant tasks. Some text generation tasks also take other modalities as the input,\nfor which we mainly focus on image and speech. For image generation, two dominant tasks are image restoration and\nediting [253]. More recently, text-to-image has attracted significant attention. Beyond the above two dominant output\ntypes (i.e. text and image), Sec.6 covers other types of output, such as Video, 3D, Speech, etc.\nAs technology advances, the AIGC performance gets satisfactory for more and more tasks. For example, ChatBot\nused to be limited to answering simple questions. However, the recent ChatGPT has been shown to understand jokes\nand generate code under simple instruction. Text-to-image used to be considered a challenging task; however, recent\nDALL-E 2 [342] and stable diffusion [357] have been able to generate photorealistic images. Therefore, opportunities\nof applying the AIGC to the industry emerge. Sec.7 covers the application of AIGC in various industries, including\nentertainment, digital art, media/advertising, education, etc. Along with the application of AIGC in the real world,\nnumerous challenges like ethical concerns have also emerged and they are disused in Sec.8. Alongside the current\nchallenges, an outlook on how generative AI might evolve is also presented.\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n5\nFig. 1. Search interest of generative AI: Timeline trend (left) and region-wise interest (right). The color darkness on the right part\nindicates the rank interest level.\nOverall, this work conducts a survey on generative AI through the lens of generated content (i.e. AIGC tasks),\ncovering its underlying basic techniques, task-wise technological development, application in the industry as well as its\nsocial impact. An overview of the paper structure is presented in Figure 4.\n2\nOVERVIEW\nAdopting AI for content creation has a long history. IBM made the first public demonstration of a machine translation\nsystem at its head office in New York in 1954. The first computer-generated music came out with the name \u201cIlliac\nSuite\" in 1957. Such early attempts and proof-of-concept successes caused a high expectation of the AI future, which\nmotivated governments and companies to invest numerous resources in AI. Such a high boom in investment, however,\ndid not yield the expected output. After that, a period called AI winter came, which dramatically undermines the\ndevelopment of AI and its applications. Entering the 2010s, AI has again become popular again, especially after the\nsuccess of AlexNet [216] for ImageNet classification in 2012. Entering the 2020s, AI has entered a new era of not only\nunderstanding existing data but also creating new content [40, 342]. This section provides an overview of generative AI\nby focusing on its popularity and why it gets popular.\n2.1\nPopularity indicated by search interest\nA good indicator of \u2018how popular a certain term is\u2019 refers to search interest. Google provides a promising tool to\nvisualize search frequency, called Google trends. Although alternative search engines might provide similar functions,\nwe adopt Google trends because Google is one of the most widely used search engines in the world.\nInterest over time and by region. Figure 1 (left) shows the search interest of generative AI, which indicates that\nthe search interest significantly increased in the past year, especially after October 2022. Entering 2013, this search\ninterest reaches a new height. A similar trend is observed for the term AIGC, see Figure 2 (left). Except for interest over\ntime, Google trends also provides region-wise search interest. The search heatmaps for generative AI and AIGC are\nshown in Figure 1 (right) and Figure 2 (right), respectively. For both terms, the main hot regions include Asia, Northern\nAmerica, and Western Europe. Most notably, for both terms, China ranks highest among all countries with a search\ninterest of 100, followed by around 30 in Northern America and 20 in Western Europe. It is worth mentioning that\nsome small but tech-oriented countries also have a very high search interest in generative AI. For example, the three\ncountries that rank top on the country-wise search interest are Singapore (59), Israel (58), and South Korea (43).\nManuscript submitted to ACM\n6\nZhang et al.\nFig. 2. Search interest of AIGC: Timeline trend (left) and region-wise interest (right). The color darkness on the right part indicates\nthe rank interest level.\nFig. 3. Search interest comparison between generative AI and AIGC: Timeline trend (left) and region-wise interest (right).\nGenerative AI v.s. AIGC. Figure 3 shows a comparison between generative AI and AIGC for the search interest.\nHere, we define the interest ratio of generative AI and AIGC as GAI/AIGC. A major observation is that China prefers to\nuse the term AIGC compared with generative AI with the GAI/AIGC ratio being 15/85. By contrast, the GAI/AIGC in\nthe US is 90/10. In many countries, including Russia and Brazil, the GAI/AIGC is 100/0. Overall, most countries prefer\ngenerative AI to AIGC, which makes generative AI have an overall higher search interest than AIGC. The reason that\nChina becomes the leading country to adopt the term AIGC is not fully clear. A possible explanation is that AIGC is\nshortened to a single word and thus is easier to use. We also search the Chinese version of generative AI and AIGC on\nGoogle trends, however, the current demonstration is not sufficient.\n2.2\nWhy does it get popular?\nThe recent surging interest in generative AI in the last year can be mainly attributed to the emergence of intriguing\ntools like Stable diffusion or ChatGPT. Here, we discuss why generative AI gets popular by focusing on what factors\ncontributed to the advent of such powerful AIGC tools. The reasons are summarized from two perspectives: content\nneed and technology conditions.\n2.2.1\nContent need. The way we communicate and interact with the world has been fundamentally changed by\nthe Internet, for which digital content plays a key role. Over the last few decades, the content on the web has also\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n7\nundergone multiple major changes. In the Web 1.0 era (the 1990s-2004), the Internet was primarily used to access and\nshare information, with websites mainly static. There was little interaction between users and the primary mode of\ncommunication was one-way, with users accessing information but not contributing or sharing their own content.\nThe content was largely text-based and it was mainly generated by professionals in the relative fields, like journalists\ngenerating news articles. Therefore, such content is often called Professional Generated Content (PGC), which has been\ndominated by another type of content, termed User Generated Content (UGC) [214, 322, 427]. In contrast to PGC, UGC\nin Web 2.0 [308] is mainly generated by users on social media, like Facebook [203], Twitter [257], Youtube [159], etc.\nCompared with PGC, the volume of UGC is significantly larger, however, its quality might be inferior.\nWe are currently transitioning from Web 2.0 to Web 3.0 [363]. With defining features of being decentralized and\nintermediary-free, Web 3.0 also relies on a new content generation type beyond PGC and UGC to address the trade-off\nbetween volume and quality. AI is widely recognized as a promising tool for addressing this trade-off. For example, in\nthe past, only those users that have a long period of practice could draw images of decent quality. With text-to-image\ntools (like stable diffusion [357]), anyone can create drawing images with a plain text description. Such a combination of\nuser imagination power and AI execution power makes it possible to generate new types of images at an unprecedented\nspeed. Beyond image generation, AIGC tasks also facilitate generating other types of content.\nAnother change AIGC brings is that the boundary between content consumer and creator becomes vague. In Web\n2.0, Content generators and consumers are often different users. With AIGC in Web 3.0, however, data consumers are\nnow able to become data creators, as they are able to use AI algorithms and technology to generate their own original\ncontent, and it allows them to have more control over the content they produce and consume, making them use their\nown data and AI technology to produce content that is tailored to their specific needs and interests. Overall, the shift\ntowards AIGC has the potential to greatly transform the way data is consumed and produced, giving individuals and\norganizations more control and flexibility in the content they create and consume. In the following, we discuss why\nAIGC has become popular now.\n2.2.2\nTechnology conditions. When it comes to AIGC technology, the first thing that comes into mind is often machine\n(deep) learning algorithm, while overlooking its two important conditions: data access and compute resources.\nAdvances in data access. Deep learning refers to the practice of training a model on data. The model performance\nheavily relies on the size of the training data. Typically, the model performance increases with more training samples.\nTaking image classification as an example, ImageNet [83] with more than 1 million images is a commonly used dataset\nfor training the model and validating the performance. Generative AI often requires an even larger dataset, especially\nfor challenging AIGC tasks like text-to-image. For example, approximately 250M images were used for training DALL-\nE [343]. DALL-E 2 [342], on the other hand, used approximately 650M images. ChatGPT was built on top of GPT3 [40]\npartly trained on CommonCrawl dataset, which has 45TB of compressed plaintext before filtering and 570GB after\nfiltering. Other datasets like WebText2, Books1/2, and Wikipedia are involved in the training of GPT3. Accessing such a\nhuge dataset becomes possible mainly due to the Internet.\nAdvances in computing resources. Another important factor contributing to this development of AIGC is advanced\nin computing resources. Early AI algorithm was run on CPU, which cannot meet the need of training large deep learning\nmodels. For example, AlexNet [216] was the first model trained on full ImageNet and the training was done on Graphics\nProcessing Units (GPUs). GPUs were originally designed for rendering graphics in video games but have become\nincreasingly common in deep learning. GPUs are highly parallelized and can perform matrix operations much faster\nthan CPUs. Nvidia is a leading company in manufacturing GPUs. The computing capability of its CUDA has improved\nManuscript submitted to ACM\n8\nZhang et al.\nFig. 4. An overview of generative AI (AIGC): fundamental techniques, core AIGC tasks, and industrial applications.\nfrom the first CUDA-capable GPU (GeForce 8800) in 2006 to the recent GPU (Hopper) with hundreds of times more\ncomputing power. The price of GPUs can range from a few hundred dollars to several thousand dollars, depending\non the number of cores and memory. Tensor Processing Units (TPUs) are specialized processors designed by Google\nspecifically for accelerating neural network training. TPUs are available on the Google Cloud Platform, and the pricing\nvaries depending on usage and configuration. Overall, the price of computing resources is on the trend of becoming\nmore affordable.\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n9\n3\nFUNDAMENTAL TECHNIQUES BEHIND AIGC\nIn this work, we perceive AIGC as a set of tasks or applications that generates content with AI methods. Before\nintroducing AIGC, we first visit the fundamental techniques behind AIGC, which fall in the scope of generative AI\nat the technical level. Here, we summarize the fundamental techniques by roughly dividing them into two classes:\nGenerative techniques and Creation techniques. Specifically, Creation techniques refer to the techniques that are able\nto generate various contents, e.g., GAN and diffusion model. Meanwhile, General techniques cannot generate content\ndirectly but are essential for the development of AIGC, e.g., the Transformer architecture. In this section, we provide a\nbrief summary of the required techniques for AIGC.\n3.1\nGeneral techniques in AI\nAfter the phenomenal success of AlexNet [216], there is a surging interest in deep learning, which somewhat becomes a\nsynonym for AI. In contrast to traditional rule-based algorithms, deep learning is a data-driven method that optimizes the\nmodel parameters with a stochastic gradient. The success of deep learning in obtaining a superior feature representation\ndepends on better backbone architecture and more data, which greatly accelerates the development of AIGC.\n3.1.1\nBackbone architecture. As two mainstream fields in deep learning, the research on natural language processing\n(NLP) and computer vision (CV) have significantly improved the backbone architectures and inspired various applications\nof improved backbones in other fields, e.g., the speech area. In the NLP field, Transformer [443] has replaced recurrent\nneural networks (RNN) [281, 285] to be the de-facto standard backbone. In the CV area, vision Transformer (ViT) [97]\nhas also shown its power besides the traditional convolutional neural networks (CNN). Here, we will briefly introduce\nhow these mainstream backbones work and their representative variants.\nRNN architecture. RNN is mainly adopted for handling data with time sequences, like language or audio. A vanilla\nRNN has three layers: input, hidden, and output. The information flow in RNN is in two directions. The first direction is\nfrom the input to the hidden layer and then to the output. What captures the recurrent nature of RNN lies in its second\ninformation flow in the time direction. Except for the corresponding input, the current hidden state depends at time\n\ud835\udc61depends on the hidden state at time \ud835\udc61\u22121. This two-flow design well handles the sequence order but suffers from\nexploding or vanishing gradients when the sequence gets long. To mitigate long-term dependency, LSTM [158] was\nintroduced with a cell state that acts like a freeway to facilitate the information flow in the sequence direction. LSTM\nis one of the most popular methods for alleviating the gradient vanishing/exploding issue. With three types of gates,\nhowever, LSTM suffers from high complexity and a higher memory requirement. Gated Recurrent Unit (GRU) [65]\nsimplifies LSTM by merging its cell and hidden states and replacing the forget and input gates with a so-called update\nstate. Unitary RNN [18] handles the gradient issue by implementing unitary matrices. Gated Orthogonal Recurrent\nUnit [184] leverages the merits of both gate and unitary matrices. Bidirectional RNN [376] improves vanilla RNN by\ncapturing both past and future information in the cell, i.e., the state at time \ud835\udc61is calculated based on both time \ud835\udc61\u22121\nand \ud835\udc61+ 1. Depending on the tasks, RNN can have various architectures with a different number of inputs and outputs:\none-to-one, many-to-one, one-to-many, and many-to-many. The many-to-many can be used in machine translation and\nis also called the sequence-to-sequence (seq2seq) model [413]. Attention was introduced in [24] to make the model\ndecoder see every encoder token and automatically decide the weights on them based on their importance.\nTransformer. Different from Seq2seq with attention [24, 267, 315], a new variant of architecture discards the\nseq-2seq architecture and claims that attention is all you need [443]. Such attention is called self-attention, and the\nproposed architecture is termed Transformer [443] (see Figure 5). A standard Transformer consists of an encoder and a\nManuscript submitted to ACM\n10\nZhang et al.\ndecoder and is developed based on residual connection [143] and layer normalization [22]. Except for the Add & Norm\nmodule, the Transformer has two core components: multi-head attention and feed-forward neural network (a.k.a. MLP).\nThe attention module adopts a multi-head design with the self-attention in the form of scaled dot-product defined as:\n\ud835\udc34\ud835\udc61\ud835\udc61\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b(\ud835\udc44, \ud835\udc3e,\ud835\udc49) = \ud835\udc60\ud835\udc5c\ud835\udc53\ud835\udc61\ud835\udc5a\ud835\udc4e\ud835\udc65(\ud835\udc44\ud835\udc3e\ud835\udc47\n\u221a\ufe01\n\ud835\udc51\ud835\udc58.\n)\ud835\udc49\n(1)\nUnlike RNNs, which build positional information by sequentially inputting sentence information, Transformer obtains\npowerful modeling capabilities by constructing global dependencies but also loses information with positional bias.\nTherefore, positional encoding is needed to enable the model to sense the positional information of the input signal.\nThere are two types of positional encoding. Fixed position coding is represented by sinusoids and cosines of different\nfrequencies. The learnable position encoding is composed of a set of learnable parameters. Transformer has become the\nde-facto standard method in NLP tasks.\nFig. 5. Transformer structure (figure obtained from [443]).\nCNN architecture. After introducing RNN and Transformer in NLP field, we start to visit two mainstream backbones\nin CV area, i.e., CNN and ViT. CNNs have become a standard backbone in the field of computer vision. The core of CNN\nlies in its convolution layer. The convolution kernel (also known as filter) in the convolution layer is a set of shared\nweight parameters for operating on images, which is inspired by the biological visual cortex cells. The convolution\nkernel slides on the image and performs correlation operations with the pixel values on the image, finally obtaining\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n11\nthe feature map and realizing the feature extraction of the image. GoogleNet[417], with its Inception module allowing\nmultiple convolutional filter sizes to be chosen in each block, increased the diversity of convolutional kernels, thus the\nperformance of CNN was improved. ResNet[143] was a milestone for CNNs, introducing residual connections that\nstabilized training and enabled the models to achieve better performance through deeper modeling. After that, it became\npart of the binding in CNNs. In order to expand the work of ResNet, DenseNet[165] establishes dense connections\nbetween all the previous layers and the subsequent layers, thus enabling the model to have better modeling ability.\nEfficientNet[418] uses a scaling method which uses a set of fixed scaling coefficients to uniformly scale the width, depth,\nand resolution of the convolutional neural network architecture, thus making the model more efficient.\nFig. 6. ViT structure (figure obtained from [97]).\nViT architecture. Inspired by the success of Transformer in NLP, numerous works have tried to apply Transformer\nto the field of CV with ViT[97] (see Figure 6), being the first of its kind. ViT first flattens the image into a sequence of\n2D patches and inserts a class token at the beginning of the sequence to extract classification information. After the\nembedding position encoding, the token embeddings are fed into a standard Transformer. This simple and effective\nimplementation of ViT makes it highly scalable. Swin [261] efficiently deals with image classification and dense\nrecognition tasks by constructing hierarchical feature maps by merging image blocks at a deeper level, and due to\nits computation of self-attention only within each local window, it reduces computational complexity. DeiT[430]\nuses the teacher-student strategy for training, reducing the dependence of Transformer models on large data, by\nintroducing distillation tokens. CaiT[431] introduces class attention to effectively increase the depth of the model.\nT2T[508] effectively localizes the model by Token Fusion and introduces hierarchical deep and narrow structures through\nthe prior of CNNs by recursively aggregating adjacent Tokens into one Token. Through permutation equivariance,\nTransformers have liberated CNNs from their translation invariance, allowing for long-range dependencies and less\ninductive bias, making them more powerful modeling tools and better transferable to downstream tasks than CNNs. In\nManuscript submitted to ACM\n12\nZhang et al.\nthe current paradigm of large models and large datasets, Transformers have gradually replaced CNNs as the mainstream\nmodel in the field of computer vision.\n3.1.2\nSelf-supervised pretraining. Parallel to better backbone architecture, deep learning also benefits from self-\nsupervised pertaining which can exploit a larger (unlabeled) training dataset. Here, we summarize the most relevant\npretraining techniques to AIGC, and categorize them according to the training data type (e.g., language, vision, and\njoint pretraining).\nLanguage pretraining. There are three major types of language pretraining methods. The first type pretrains an\nencoder with masking, for which the representative work is BERT [87] (see Figure 7). Specifically, BERT predicts the\nmasked language tokens from the unmasked tokens. There is a significant discrepancy between the mask-then-predict\npertaining task and downstream tasks, therefore masked language modeling like BERT is rarely used for text generation\nwithout finetuning. By contrast, autoregressive language pretraining methods are suitable for few-shot or zero-shot\ntext generation. GPT family [40, 338, 339] is the most popular one which adopts a decoder instead of an encoder.\nSpecifically, GPT-1 [338] is the first of its kind with GPT-2 [339] and GPT-3 [40] further investigating the role of massive\ndata and large model in the transfer capacity. Based on GPT-3, the unprecedented success of ChatGPT has attracted\ngreat attention recently. Moreover, a stream of language models adopts both an encoder and decoder as the original\nTransformer. BART [226] perturbed the input with various types of noise and predicted the original clean input, like a\ndenoising autoencoder. MASS [400] and PropheNet [332] follow BERT to take a masked sequence as the input of the\nencoder with the decoder predicting the masked tokens in an autoregressive manner. T5 [340] replaces the masked\ntokens with some random tokens.\nFig. 7. BERT structure (figure obtained from [87]).\nVisual pretraining. To learn better representations of vision data during pretraining, self-supervised learning (SSL)\nhas been widely applied, and we term it visual SSL. Visual SSL has undergone three stages. Early works focused on\ndesigning various pretext tasks like jigsaw puzzles [303] or predicting rotation [121]. Such pretraining yields better\nperformance on the downstream task than training from scratch, which motivates contrastive learning methods [54,\n142, 520]. Contrastive learning adopts joint embedding to minimize the representation distance between augmented\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n13\nimages for learning augmentation-invariant representation. The representation in pure joint embedding can collapse\nto a constant regardless of the inputs, for which contrastive learning simultaneously maximizes the representation\ndistance from negative samples. Negative-free joint-embedding methods have also been investigated in SimSiam [55]\nand BYOL [129]. How SimSiam works without negative samples have been investigated in [521]. Inspired by the success\nof BERT in NLP for pertaining, BEiT [30] applied masking modeling in vision and its success relies on a pre-trained\nVAE to obtain the visual token. Masked autoencoder (MAE) [141] (see Figure 8) simplifies it to an end-to-end denoising\nframework by predicting the masked patches from the unmasked patches. Outperforming contrastive learning and\nnegative-free joint-embedding methods, MAE has become a new variant of the visual SSL framework. Interested readers\ncan refer [519] for more details.\nFig. 8. MAE structure (figure obtained from [141]).\nJoint pretraining. With large datasets of image-text pairs collected from the Internet, multimodal learning [29, 487]\nhas made unprecedented progress to learn data representations, at the front of which is cross-modal matching [115].\nContrastive pretraining is widely used to match the image embedding and text encoding in the same representation\nspace [180, 336, 507]. CLIP [336] (see Figure 9 is a pioneering work in this direction and is used in numerous text-to-\nimage models, such as DALL-E 2 [342], Upainting [241], DiffusionCLIP [206]. ALIGN [180] extended CLIP with noisy\ntext supervision so that the text-image dataset requires no cleaning and can be scaled to a much larger size (from 400M\nto 1.8B). Florence [507] further expands the cross-modal shared representation from coarse scene to dine object and\nfrom static images to dynamic videos, etc. Therefore, the learned shared representation is more universal and shows\nsuperior performance [507].\n3.2\nCreation techniques in AI\nDeep generative models (DGMs) are a group of probabilistic models that use neural networks to generate samples. Early\nattempts at generative modeling focused on pre-training with an autoencoder [28, 154, 365]. A variant of autoencoder\nwith masking has emerged to become a dominant self-supervised learning framework, and interested readers are\nManuscript submitted to ACM\n14\nZhang et al.\nFig. 9. CLIP structure (figure obtained from [336]).\nencouraged to check a survey on masked autoencoder [519]. Unless specified, the use cases of deep generative models\nin this survey only consider generating new data. The generated data is typically high-dimensional, and therefore,\npredicting a label of a sample is not considered discriminative instead of generative modeling even though something\nlike a label is also technically generated.\nNumerous DGMs have emerged and can be categorized into two major groups: likelihood-based and energy-based.\nLikelihood-based probabilistic models, like autoregressive models [126] and flow models [90], have a tractable likelihood\nwhich provides a straightforward method to optimize the model weights w.r.t. the log-likelihood of the observed\n(training) data. The likelihood is not fully tractable in variational autoencoders (VAEs) [210], but a tractable lower\nbound can be optimized, thus VAE is also considered to lie in the likelihood-based group which specifies a normalized\nprobability. By contrast, energy-based models [128, 153] are featured by the unnormalized probability, a.k.a. energy\nfunction. Without the constraint on the tractability of the normalizing constant, energy-based models are more flexible\nin parameterizing but difficult to train [403]. Notably, GAN and diffusion models are highly related to energy-based\nmodels even though are developed from different motivations. In the following, we present an introduction to each\nclass of likelihood-based models, followed by how the energy-based models can be trained as well as the mechanism\nbehind GAN and diffusion models.\n3.2.1\nLikelihood-based models. Autoregressive models. Autoregressive models learn the joint distribution of se-\nquential data and predict each variable in the sequence with previous time-step variables as inputs. As shown in\nEq. 2, autoregressive models assumes that the joint distribution \ud835\udc5d\ud835\udf03(\ud835\udc65) can be decomposed to a product of conditional\ndistributions.\n\ud835\udc5d\ud835\udf03(\ud835\udc65) = \ud835\udc5d\ud835\udf03(\ud835\udc651)\ud835\udc5d\ud835\udf03(\ud835\udc652|\ud835\udc651)...\ud835\udc5d\ud835\udf03(\ud835\udc65\ud835\udc5b|\ud835\udc651,\ud835\udc652, ...,\ud835\udc65\ud835\udc5b\u22121),\n(2)\nAlthough both rely on previous timesteps, autoregressive models differ from RNN architecture since the previous\ntimesteps are given to the model as input instead of hidden states in RNN. In other words, autoregressive models can be\nseen as a feed-forward network that takes all the previous time-step variables as inputs. Early works model discrete\ndata with different functions estimating the conditional distribution, e.g. logistic regression in Fully Visible Sigmoid\nBelief Network (FVSBN) [114] and one hidden layer neural networks in Neural Autoregressive Distribution Estimation\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n15\n(NADE) [221]. The following research further extends to model the continuous variables [437, 438]. Autoregressive\nmethods have been widely applied in multiple areas, including computer vision (PixelCNN [441] and PixelCNN++ [373]),\naudio generation (WaveNet [440]), natural language processing (Transformer [443]).\nVAE. Autoencoders are a family of models that first map the input to a low-dimension latent layer with an encoder\nand then reconstruct the input with a decoder. The entire encoder-decoder process aims to learn the underlying data\npatterns and generate unseen samples [310]. Variational autoencoder (VAE) [210] is an autoencoder that learns the data\ndistribution \ud835\udc5d(\ud835\udc65) from latent space z, i.e., \ud835\udc5d(\ud835\udc65) = \ud835\udc5d(\ud835\udc65|\ud835\udc67)\ud835\udc5d(\ud835\udc67), where \ud835\udc5d(\ud835\udc65|\ud835\udc67) is learned by the decoder. In order to obtain\n\ud835\udc5d(\ud835\udc67), VAE [210] adopts Bayes\u2019 theorem and approximates the posterior distribution \ud835\udc5d(\ud835\udc67|\ud835\udc65) by the encoder. The VAE\nmodel is optimized toward a likelihood goal with regularizer [13].\n3.2.2\nEnergy-based models. With a tractable likelihood, autoregressive models and flow models allow a straightforward\noptimization of the parameters w.r.t. the log-likelihood of the data. This forces the model to be constrained in a certain\nform. For example, the autoregressive model needs to be factorized as a product of conditional probabilities, and the\nflow model must adopt invertible transformation.\nEnergy-baed models specify probability up to an unknown normalizing constant, therefore, they are also known as\nnon-normalzied probabilistic models. Without losing generality by assuming the energy-based model is over a single\nvariable \ud835\udc99, we denote its energy as \ud835\udc38\ud835\udf03(\ud835\udc99). Its probability density is then calculated as\n\ud835\udc5d\ud835\udf03(\ud835\udc99) = exp(\u2212\ud835\udc38\ud835\udf03(\ud835\udc99))\n\ud835\udc67\ud835\udf03\n(3)\nwhere \ud835\udc67\ud835\udf03is the so-called normalizing constant and defined as \ud835\udc67\ud835\udf03=\n\u222b\nexp(\u2212\ud835\udc38\ud835\udf03(\ud835\udc99)) d\ud835\udc99. \ud835\udc67\ud835\udf03is an intractable integral,\nmaking optimizing energy-based models a challenging task.\nMCMC and NCE. Early attempts at optimizing energy-based models opt to estimate the gradient of the log-likelihood\nwith Markov chain Monte Carlo (MCMC) approaches, which require a cumbersome drawing of random samples.\nTherefore, some works aim to improve the efficiency of MCMC a representative work Langevin MCMC [128, 316].\nNonetheless, performing MCMCM to obtain requires large computation and contrastive divergence (CD) [153] is\na popular method to reduce the computation via approximation with various variants: persistent CD [425], mean\nfield CD [468], and multi-grid CD [116]. Another line of work optimizes energy-based models via notice contrastive\nestimation (NCE) [137], which contrasts the probabilistic model with another noise distribution. Specifically, it optimizes\nthe following loss:\nE\ud835\udc5d\ud835\udc51\n\u0014\nln\n\ud835\udc5d\ud835\udf03(\ud835\udc99)\n\ud835\udc5d\ud835\udf03(\ud835\udc99) + \ud835\udc5e\ud835\udf19(\ud835\udc99)\n\u0015\n+ E\ud835\udc5e\ud835\udf19\n\u0014\nln\n\ud835\udc5e\ud835\udf19(\ud835\udc99)\n\ud835\udc5d\ud835\udf03(\ud835\udc99) + \ud835\udc5e\ud835\udf19(\ud835\udc99)\n\u0015\n,\n(4)\nScore matching. For optimizing energy-based models, another popular MCMC-free method minimizes the deriva-\ntives of log probability density between the model and the observed data. The first-order of a log probability density\nfunction is called score of the distribution (\ud835\udc60(\ud835\udc99) = \u2207\ud835\udc99log\ud835\udc5d(\ud835\udc99)), therefore, this method is often termed score matching.\nUnfortunately, the data score function \ud835\udc60\ud835\udc51(\ud835\udc99) is unavailable. Various attempts [314, 374, 389, 401, 402, 446] have been\nmade to mitigate this issue, with a representative method called denoising score matching [446]. Denoising score\nmatching approximates the score of data with noisy samples. The model takes a noisy sample as the input and predicts\nits noise. Therefore, it can be used for sampling clean samples from noise by iterative removing the noise [374, 401].\n3.2.3\nTwo star-models: from GAN to diffusion model. When it comes to deep generative models, what first comes to\nyour mind? The answer depends on your background, however, GAN is definitely one of the most mentioned models.\nManuscript submitted to ACM\n16\nZhang et al.\nGAN stands for generative adversarial network [124] which was first proposed by Ian J. Goodfellow and his team in\n2014 and rated as \u201cthe most interesting idea in the last 10 years in machine learning\" by Yann Lecun in 2016. As the\npioneering work to generate images of reasonably high quality, GAN has been widely regarded as a de facto standard\nmodel for the challenging task of image synthesis. This long-time dominance has been recently challenged by a new\nfamily of deep generative models termed diffusion models [156]. The overwhelming success of diffusion models starts\nfrom image synthesis but extends to other modalities, like video, audio, text, graph, etc. Considering their dominant\ninfluence in the development of generative AI, we first summarize GAN and diffusion models before introducing other\nfamilies of deep generative models.\nGAN. The architecture of GAN is shown in Figure 10. GAN is featured by its two network components: a discriminator\n(D) and a generator (G). D distinguishes real images from those generated by G, while G aims to fool D. Given a\nlatent variable \ud835\udc9b\u223c\ud835\udc5d\ud835\udc9b, the output of G is G(\ud835\udc9b) constituting a probability distribution \ud835\udc5d\ud835\udc88. The goal of GAN is to make\n\ud835\udc5d\ud835\udc88approximate the observed data distribution \ud835\udc5d\ud835\udc85\ud835\udc82\ud835\udc95\ud835\udc82. This objective is achieved through adversarial learning, which\ncan be interpreted as a min-max game [375]:\nmin\n\ud835\udc3amax\n\ud835\udc37\nEx\u223c\ud835\udc5d\ud835\udc51\ud835\udc4e\ud835\udc61\ud835\udc4elog[\ud835\udc37(x)] + Ez\u223c\ud835\udc5dzlog [1 \u2212\ud835\udc37(\ud835\udc3a(z))] .\n(5)\nwhere D is trained to maximize the probability of assigning correct labels to real images and generated ones, and is\nused to guide the optimization of G towards generating more real images. GANs have the weakness of potentially\nunstable training and less diversity in generation due to their adversarial training nature. The basic difference between\nGANs and autoregressive models is that GANs learn implicit data distribution, whereas the latter learns an explicit\ndistribution governed by a prior imposed by model structure.\nFig. 10. A schematic of GAN structure.\nDiffusion model. The use of diffusion models, a special form of hierarchical VAEs, has seen explosive growth in the\npast few years [45, 73, 245, 320, 435]. Diffusion models (Figure 11) are also known as denoising diffusion probabilistic\nmodels (DDPMs) or score-based generative models that generate new data similar to the data on which they are\ntrained [156]. Inspired by non-equilibrium thermodynamics, DDPMs can be defined as a parameterized Markov chain\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n17\nof diffusion steps to slowly add random noise to the training data and learn to reverse the diffusion process to construct\ndesired data samples from the pure noise.\nFig. 11. Diffusion model for image generation (figure obtained from [156]).\nIn the forward diffusion process, DDPM destroys the training data through the successive addition of Gaussian noise.\nGiven a data distribution x0 \u223c\ud835\udc5e(x0), DDPM maps the training data to noise by gradually perturbing the input data.\nThis is formally achieved by a simple stochastic process that starts from a data sample and iteratively generates noisier\nsamples x\ud835\udc47with \ud835\udc5e(x\ud835\udc61| x\ud835\udc61\u22121), using a simple Gaussian diffusion kernel:\n\ud835\udc5e(\ud835\udc651:\ud835\udc47|\ud835\udc650) :=\n\ud835\udc47\n\u00d6\n\ud835\udc61=1\n\ud835\udc5e(\ud835\udc65\ud835\udc61|\ud835\udc65\ud835\udc61\u22121),\n(6)\n\ud835\udc5e(\ud835\udc65\ud835\udc61|\ud835\udc65\ud835\udc61\u22121) := N (\ud835\udc65\ud835\udc61;\n\u221a\ufe01\n1 \u2212\ud835\udefd\ud835\udc61\ud835\udc65\ud835\udc61\u22121, \ud835\udefd\ud835\udc61\ud835\udc3c)\n(7)\nwhere \ud835\udc47and \ud835\udefd\ud835\udc61are the diffusion steps and hyper-parameters, respectively. We only discuss the case of Gaussian noise\nas transition kernels for simplicity, indicated as N in Eq. 7. With \ud835\udefc\ud835\udc61:= 1 \u2212\ud835\udefd\ud835\udc61and \u00af\ud835\udefc\ud835\udc61:= \u00ce\ud835\udc61\n\ud835\udc60=0 \ud835\udefc\ud835\udc60, we can obtain noised\nimage at arbitrary step \ud835\udc61as follows:\n\ud835\udc5e(\ud835\udc65\ud835\udc61|\ud835\udc650) := N (\ud835\udc65\ud835\udc61; \u221a\u00af\ud835\udefc\ud835\udc61\ud835\udc650, (1 \u2212\u00af\ud835\udefc\ud835\udc61)\ud835\udc3c)\n(8)\nDuring the reverse denoising process, DDPM is learning to recover the data by reversing the noising process i.e., it\nundoes the forward diffusion by performing the iterative denoising. This process represents data synthesis and DDPM\nis trained to generate data by converting random noise into real data. It is also formally defined as a stochastic process,\nwhich iteratively denoises the input data starting from \ud835\udc5d\ud835\udf03(\ud835\udc47) and generates \ud835\udc5d\ud835\udf03(\ud835\udc650) which can follow the true data\ndistribution \ud835\udc5e(\ud835\udc650). Therefore, the optimization objective of the model is as follows:\n\ud835\udc38\ud835\udc61\u223cU(1,\ud835\udc47),x0\u223c\ud835\udc5e(x0),\ud835\udf16\u223cN(0,I)\ud835\udf06(\ud835\udc61) \u2225\ud835\udf16\u2212\ud835\udf16\ud835\udf03(x\ud835\udc61,\ud835\udc61)\u22252\n(9)\nBoth the forward and reverse processes of DDPMs often use thousands of steps for gradual noise injection and during\ngeneration for denoising.\n4\nAIGC TASK: TEXT GENERATION\nNLP studies natural language with two fundamental tasks: understanding and generation. These two tasks are not\nexclusively separate because the generation of an appropriate text often depends on the understanding of some text\ninputs. For example, language models often transform a sequence of text into another, which constitutes the core task of\ntext generation, including machine translation, text summarization, and dialogue systems. Beyond this, text generation\nevolves in two directions: controllability and multi-modality. The first direction aims to make the generated content\nManuscript submitted to ACM\n18\nZhang et al.\n4.1\nText to text\n4.1.1\nChatbots. The main task of the dialogue system (chatbots) is to provide better communication between humans\nand machines [85, 299]. According to whether the task is specified in the applications, dialogue system can be divided\ninto two categories : (1) task-oriented dialogue systems (TOD) [323, 502, 533] and (2) open-domain dialogue systems\n(OOD) [4, 532, 541]. Specifically, the task-oriented dialogue systems focus on task completion and solve specific problems\n(e.g., restaurant reservations and ticket booking) [533]. Meanwhile, open-domain dialogue systems are often data-driven\nand aim to chat with humans without task or domain restrictions [353, 533].\nTask-oriented systems. Task-oriented dialogue systems can be divided into modular and end-to-end systems. The\nmodular methods include four main parts: natural language understanding (NLU) [395, 409], dialogue state tracking\n(DST) [382, 462], dialogue policy learning (DPL) [169, 483], and natural language generation (NLG) [25, 99]. After\nencoding the user inputs into semantic slots with NLU, DST, and DPL decide the next action that is then converted to\nnatural language by NLG as the final response. These four modules aim to generate responses in a controllable way and\ncan be optimized individually. However, some modules may not be differentiable, and the improvement of a single\nmodule may not lead to the improvement of the whole system [533]. To solve these problems, end-to-end methods either\nachieve an end-to-end training pipeline by making each module differentiable [139, 162], or use a single end-to-end\nmodule in the system [498, 531]. There still exist several challenges for both modular and end-to-end systems, including\nhow to improve tracking efficiency for DST [208, 312] and how to increase the response quality of end-to-end system\nwith limited data [145, 148, 282].\nFig. 12. A diagram illustrating the three steps of how ChatGPT is trained by OpenAI (figure obtained from [311]).\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n19\nOpen-domain systems. Open-domain systems aim to chat with users without task and domain restrictions [353,\n533], and can be categorized into three types: retrieval-based systems, generative systems, and ensemble systems [533].\nSpecifically, retrieval-based systems always find an existing response from a response corpus, while generative systems\ncan generate responses that may not appear in the training set. Ensemble systems combine retrieval-based and generative\nmethods by either choosing the best response or refining the retrieval-based model with generative one [378, 533, 546].\nPrevious works improve the open-domain systems from multiple aspects, including dialogue context modeling [105, 181,\n250, 282], improving the response coherence [9, 117, 251, 483] and diversity [31, 211, 335, 408]. Most recently, ChatGPT\n(see Figure 12) has achieved unprecedented success and also falls into the scope of open-domain dialogue systems.\nApart from answering various questions, ChatGPT can also be used for paper writing, code debugging, table generation,\nand to name but a few.\nFig. 13. An example of machine translation (figure obtained from [39]).\n4.1.2\nMachine translation. As the term suggests, machine translation automatically translates the text from one\nlanguage to another [171, 497] (see Figure 13). With deep learning replacing rule-based [108] and statistical [212, 213]\nmethods, neural machine translation (NMT) requires minimum linguistic expertise [399, 451] and has become a\nmainstream approach featured by its higher capacity in capturing long dependency in the sentence [62]. The success of\nneural machine learning can be mainly attributed to language models [34], which predicts the probability of a word\nconditioned on previous ones. Seq2seq [413] is a pioneering work to apply encoder-decoder RNN structure [191] to\nmachine translation. When the sentence gets long, the performance of Seq2seq [413] deteriorates, for which an attention\nmechanism was proposed in [24] to help translate the long sentence with additional word alignment. With increasing\nattention, in 2006, Google\u2019s NMT system helped reduce the translation effort of humans by around 60% compared\nto Google\u2019s phrase-based production system, which bridges the gap between Human and machine translation [475].\nCNN-based architectures have also been investigated for NMT with numerous attempts [190, 192], but fail to achieve\nManuscript submitted to ACM\n20\nZhang et al.\ncomparable performance as the RNN boosted by attention [24]. Convolutional Seq2seq [120] makes CNN compatible\nwith the attention mechanism, showing CNN can achieve comparable or even better performance than RNN. However,\nthis improvement was later outperformed by another architecture termed Transformer [443]. With RNN or Transformer\nas the architecture, NMT often utilizes autoregressive generative model, where a greedy search only considers the word\nwith the highest probability for predicting the next work during inference.\nA trend for NMT is to achieve satisfactory performance in low-resource setup, where the model is trained with\nlimited bilingual corpus [458]. One way to mitigate this data scarcity is to utilize auxiliary languages, like multilingual\ntraining with other language pairs [187, 383, 547] or pivot translation with English as the middle pivot language [58, 350].\nAnother popular approach is to utilize pre-trained language models, like BERT [87] or GPT [338]. For example, it\nis shown in [359] that initializing the model weights with BERT [87] or RoBERTa [259] significantly improves the\nEnglish-German translation performance. Without the need for fine-tuning, GPT-family models [40, 338, 339] also\nshow competitive performance. Most recently, ChatGPT has shown its power in machine translation, performing\ncompetitively with commercial products (e.g., Google translate) [182].\n4.2\nMultimodal text generation\n4.2.1\nImage-to-text. Image-to-text, also known as image captioning, refers to describing a given image\u2019s content in\nnatural language (see Figure 14). A seminal work in this area is Neural Image Caption (NIC) [447], which employs CNN\nas an encoder to extract high-level representations of input images and then feed these representations into an RNN\ndecoder to generate image descriptions. This two-step encoder-decoder architecture has been widely applied in later\nworks on image captioning, and we term them as visual encoding [407] and language decoding, respectively. Here, we\nfirst revisit the history and recent trends of both stages in image captioning.\nFig. 14. An example of image captioning (figure obtained from [109]).\nVisual encoding. Extracting an effective representation of images is the main task of visual encoding module. Start\nfrom NIC [447] with GoogleNet [417] extracting the global feature of input image, multiple works adopt various CNN\nbackbones as the encoder, including AlexNet [216] in [195] and VGG network [393] in [92, 272]. However, it is hard for\na language model to generate fine-grained captions with global visual features. Following works introduce attention\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n21\nmechanism for fine-grained visual features, including attention over different grids of CNN features [56, 264, 463, 484]\nor over different visual regions [16, 200, 518]. Another branch of work [500, 536] adopts graph neural networks to\nencode the semantic and spatial relationships between different regions. However, the human-defined graph structures\nmay limit the interactions among elements [407], which can be mitigated by the self-attention methods [231, 501, 530]\n(including ViT [256]) that connects all the elements.\nLanguage decoding. In image captioning, a language decoder generates captions by predicting the probability of a\ngiven word sequence [407]. Inspired by the breakthroughs in the NLP area, the backbones of language decoders evolve\nfrom RNN [200, 264, 447, 456] to Transformer [132, 149, 231], achieving significant performance improvement. Beyond\nthe visual encoder-language decoder architecture, a branch of work adopts BERT-like architecture that fuses the image\nand captions in the early stage of a single model [244, 526, 542]. For example, [542] adopts a single encoder to learn a\nshared space for image and text, which is first pre-tained on large image-text corpus and finetuned, specifically for\nimage captioning tasks.\n4.2.2\nSpeech-to-Text. Speech-to-text generation, also known as automatic speech recognition (ASR), is the process of\nconverting spoken language, specifically a speech signal, into a corresponding text [173, 347] (see Figure 15). With\nmany potential applications such as voice dialing, computer-assisted language learning, caption generation, and virtual\nassistants like Alexa and Siri, ASR has been an exciting field of research [194, 270, 345] since the 1950s, and evolved\nfrom hidden Markov models (HMM) [188, 225] to DNN-based systems [75, 127, 152, 297, 473].\nFig. 15. A example of speech recognition (figure obtained from [46]).\nVarious research topics and challenges. Previous works improved ASR systems in various aspects. Multiple\nworks discuss different feature extraction methods for speech signals [270], including temporal features (e.g., discrete\nwavelet transform [287, 419]) and spectral features such as the most commonly used mel-frequency cepstral coefficients\n(MFCC) [61, 69, 429]. Another branch of work improves the system pipeline [355] from multi-model [268] to end-to-end\nones [161, 233, 234, 296, 453]. Specifically, a multi-model system [268, 270] first learns an acoustic model (e.g., a phoneme\nclassifier that maps the features to phonemes) and then a language model for the word outputs [355]. On the other\nhand, end-to-end models directly predict the transcriptions from the audio input [161, 233, 234, 296, 453]. Although\nend-to-end models achieve impressive performance in various languages and dialects, many challenges still exist.\nFirst, their applications for under-resourced speech tasks remain challenging as it is costly and time-consuming to\nacquire vast amounts of annotated training data [104, 355]. Second, these systems may struggle to handle speech with\nspecialized out-of-vocabulary words and may perform well on the training data but may not generalize well to new or\nunseen data [104, 334]. Moreover, biases in the training data can also affect the performance of supervised ASR systems,\nleading to poor accuracy on certain groups of people or speech styles [35].\nManuscript submitted to ACM\n22\nZhang et al.\nFig. 16. Examples of image restoration (figure obtained from [452]).\nUnder-resourced speech tasks. Researchers work on new technologies to overcome challenges in ASR systems,\namong which we mainly discuss the under-resourced speech problem that lacks data for impaired speech [355]. A\nbranch of work [321, 346] adopts multi-task learning to optimize a shared encoder for different tasks. Meanwhile,\nself-supervised ASR systems have recently become an active area of research without relying on a large number\nof labeled samples. Specifically, self-supervised ASR systems first pre-train a model on huge volumes of unlabeled\nspeech data, then fine-tune it on a smaller set of labeled data to facilitate the efficiency of ASR systems. It can be\napplied for low-resource languages, handling different speaking styles or noise conditions, and transcribing multiple\nlanguages [23, 71, 255, 492].\n5\nAIGC TASK: IMAGE GENERATION\nSimilar to text generation, the task of image synthesis can also be categorized into different classes based on its input\ncontrol. Since the output is images, a straightforward type of control is images. Image-type control induces numerous\ntasks, like super-resolution, deblur, editing, translation, etc. A limitation of image-type control is the lack of flexibility.\nBy contrast, text-guided control enables the generation of any image content with any style at the free will of humans.\nText-to-image falls into the category of cross-modal generation, since the input text is a different modality from the\noutput image.\n5.1\nImage-to-image\n5.1.1\nImage restoration. Image restoration solves a typical inverse problem that restores clean images from their\ncorresponding degraded versions, with examples shown in Figure 16. Such an inverse problem is non-trivial with its\nill-posed nature because there are infinite possible mappings from the degraded image to the clean one. There are two\nsources of degradation: missing information from the original image and adding something undesirable to the clean\nimage. The former type of degradation includes capturing a photo with a low resolution and thus losing some detailed\ninformation, cropping a certain region, and transforming a colorful image to its gray form. Restoration tasks recover them\nin order are image super-resolution, inpainting, and colorization, respectively. Another class of restoration tasks aims to\nremove undesirable perturbations, like denoise, derain, dehaze, deblur, etc. Early restoration techniques primarily use\nmathematical and statistical modeling to remove image degradations, including spatial filters for denoising [123, 392, 529],\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n23\nkernel estimation for deblurring [485, 489]. Lately, deep learning-based methods [42, 59, 93, 177, 248, 252, 481, 486]\nhave become predominant in image restoration tasks due to their versatility and superior visual quality over their\ntraditional counterparts. CNN is widely used as the building block in image restoration [94, 411, 442, 459], while recent\nworks explore more powerful transformer architecture and achieve impressive performance in various tasks, such as\nimage super-resolution [247], colorization [218], and inpainting [240]. There are also works that combine the strength\nof CNNs and Transformers together [103, 534, 535].\nGenerative methods for restoration. Typical image restoration models learn a mapping between the source\n(degraded) and target (clean) images with a reconstruction loss. Depending on the task, training data pairs can be\ngenerated by degrading clean images with various perturbations, including resolution downsampling and grayscale\ntransformation. To keep more high-frequency details and create more realistic images, generative models are widely\nused for restoration, such as GAN in super-resolution [223, 460, 528] and inpainting [42, 252, 298]. However, GAN-based\nmodels typically suffer from a complex training process and mode collapse. These drawbacks and the massive popularity\nof DMs led numerous recent works to adopt DMs for image restoration tasks [199, 232, 265, 349, 367, 369]. Generative\napproaches like GAN and DM can also produce multiple variations of clean output from a single degraded image.\nFrom single-task to multi-task. A majority of existing restoration approaches train separate models for different\nforms of image degradation. This limits their effectiveness in practical use cases where the images are corrupted by a\ncombination of degradations. To address this, several studies [6, 207, 391, 540] introduce multi-distortion datasets that\ncombine various forms of degradation with different intensities. Some studies [207, 258, 505, 509] propose restoration\nmodels in which different sub-networks are responsible for different degradations. Another line of work [228, 242,\n391, 410, 540] relies on attention modules or a guiding sub-network to assist the restoration network through different\ndegradations, allowing a single network to handle multiple degradations.\n5.1.2\nImage editing. In contrast to image restoration for enhancing image quality, image editing refers to modifying\nan image to meet a certain need like style transfer (see Figure 17). Technically, some image restoration tasks like\ncolorization might also be perceived as image editing by perceiving adding color as the desired need. Modern cameras\noften have basic editing features such as sharpness adjustments [524], automatic cropping [525], red eye removal [396],\netc. However, in AIGC, we are more interested in advanced image editing tasks that change the image semantics in\nvarious forms, such as content, style, object attributes, etc.\nA family of image editing targets to modify the attributes (like age) of the main object (like a face) in the image. A\ntypical use case is facial attribute editing which can change the hairstyle, age, or even gender. Based on a pre-trained\nCNN encoder, a line of pioneering works adopt optimization-based approaches [236, 436], which is time-consuming\ndue to its iterative nature. Another line of works adopts learning-based approaches to directly generate the image, with\na trend from single attribute [237, 385] to multiple ones [146, 209, 478]. A drawback of most aforementioned methods is\nthe dependence on annotated labels for attributes, therefore, unsupervised learning has been introduced to disentangle\ndifferent attributes [60, 386].\nAnother family of image editing changes the semantics by combining two images. For example, image morphing [185]\ninterpolates the content of two images, while style transfer [119] yields a new image with the content of one image\nand the style of the other. A naive method for image morphing is to perform interpolation in the pixel space, which\ncauses obvious artifacts. By contrast, interpolating in the latent space can consider the view change and generate a\nsmooth image. The latent space for those two images can be obtained via GAN inversion method [477]. Numerous\nworks [1, 490, 544, 545] have explored the latent place of a pre-trained GAN for image morphing. For the task of style\nManuscript submitted to ACM\n24\nZhang et al.\nFig. 17. Examples of style transfer as a form of image editing (figure obtained from [118]).\ntransfer, a specific style-based variant of GAN termed StyleGAN [197] is a popular choice. From the earlier layers to the\nlatter ones, StyleGAN controls the attributes from coarser-grained (like structure) to finer-grained ones (like texture).\nTherefore, StyleGAN can be used for style transfer by mixing the earlier layer\u2019s latent representation of the content\nimage and the latter layer\u2019s latent representation of the style image [1, 131, 444, 467].\nCompared with restoration tasks, various editing tasks enable a more flexible image generation. However, its diversity\nis still limited, which is alleviated by allowing other text as the input. More recently, image editing based on diffusion\nmodels has been widely discussed and achieved impressive results [48, 150, 206, 450]. DiffusionCLIP [206] is a pioneering\nwork that finetunes a pre-trained diffusion model to align the target image and text. By contrast, LDEdit [48] avoids\nfinetuning based on LDM [357]. A branch of works discusses the mask problem in image editing, including how to\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n25\nconnect a manually designed masked region and background seamlessly [3, 19, 21, 21]. On the other hand, DiffEdit [72]\nproposes to predict the mask automatically that indicates which part to be edited. There are also works editing 3D\nobjects based on diffusion models and text guidance [47, 205, 230].\n5.2\nMultimodal image generation\n5.2.1\nText-to-image. Text-to-image (T2I) task aims to generate images from textual descriptions (see Figure ??.), and\ncan be traced back to image generation from tags or attributes [405, 495]. AlignDRAW [271] is a pioneering work to\ngenerate images from natural language, and it is impressive that AlignDRAW [271] can generate images from novel\ntext like \u2018a stop sign is flying in blue skies\u2019. More recently, advances in text-to-image area can be categorized into three\nbranches, including GAN-based methods, autoregressive methods, and diffusion-based methods.\nGAN-based methods. The limitation of AlignDRAW [271] is that the generated images are unrealistic and re-\nquire an additional GAN for post-processing. Based on a deep convolutional generative adversarial network (DC-\nGAN) [337], [348] is the first end-to-end differential architecture from the character level to the pixel level. To generate\nhigh-resolution images while stabilizing the training process, StackGAN [522] and StackGAN++ [523] propose a multi-\nstage mechanism that multiple generators produce images of different scales, and high-resolution image generation is\nconditioned on the low-resolution images. Moreover, AttnGAN [488] and Controlgan [229] adopt attention networks\nto obtain fine-grained control on the subregions according to relevant words.\nAutoregressive methods. Inspired by the success of autoregressive Transformers [443], a branch of works generates\nimages in an auto-regressive manner by mapping images to a sequence of tokens, among which DALL-E [343] is a\npioneering work. Specifically, DALL-E [343] first converts the images to image tokens with a pre-trained discrete\nvariational autoencoder (dVAE), then trains an auto-regressive Transformer to learn the joint distribution of text and\nimage tokens. A concurrent work CogView [88] independently proposes the same idea with DALL-E [343] but achieves\nsuperior FID [151] than DALL-E [343] on blurred MS COCO dataset. CogView2 [89] extends CogView [88] to various\ntasks, e.g., image captioning, by masking different tokens. Parti [504] further improves the image quality by scaling the\nmodel size to 20 billion.\nDiffusion-based methods. Diffusion model-based methods have achieved unprecedented success and attention\nrecently, which can be categorized by either working on the pixel space directly [300, 368] or the latent space [342, 357].\nGLIDE [300] outperforms DALL-E by extending class-conditional diffusion models to text-conditional settings, while\nImagen [368] improves the image quality further with a pre-trained large language model (e.g., T5) capturing the text\nsemantics. To reduce resource consumption of diffusion models in pixel space, Stable Diffusion [357] first compresses\nthe high-resolution images to a low-dimensional latent space, then trains the diffusion model in the latent space. This\nmethod is also known as Latent Diffusion Models (LDM) [357]. Different from Stable Diffusion [357] that learns the\nlatent space based on only images, DALL-E2 [342] applies diffusion model to learn a prior as alignment between image\nspace and text space of CLIP. Other works also improve the model from multiple aspects, including introducing spatial\ncontrol [20, 449] and reference images [37, 387].\n5.2.2\nTalking face. From the perspective of output, the task of talking face[537] generates a series of image frames\nwhich are thus technically a video (see Figure 19). Different from general video generation (see Sec. 6.1), talking face\nrequires an image face as an identity reference, and edits it based on the speech input. In this sense, talking face is\nmore related to image editing. Moreover, talking face converts a speech clip to a corresponding face image, resembling\nspeech recognition to convert a speech clip to a corresponding word text. With speech recognition recognized as a\nManuscript submitted to ACM\n26\nZhang et al.\nFig. 18. Examples of text-to-image (figure from [300]).\nmultimodal generation text task, this survey considers talking face as a multimodal image generation task. Driven by\ndeep learning models, speech-to-head video synthesis models have attracted wide attention, which can be divided into\n2D-based methods and 3D-based methods.\nWith 2D-based methods, talking face video synthesis mainly relies on landmarks, semantic maps, or similar represen-\ntations. Landmarks are used as an intermediate layer from low-dimensional audio to high-dimensional video, as well as\ntwo decoders to decouple speech and speaker identity for generating video unaffected by speaker identity [66], which\nis also the first work to use deep generative models to create speech faces. In addition, image-to-image translation\ngeneration [178] can also be used for lip synthesis, while the combination of separate audio-visual representations and\nneural networks can also be used to optimize synthesis [404, 539]\nFig. 19. Examples of talking face (image obtained from [51]).\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n27\nAnother line of work is based on building a 3D model and controlling the motion process through rendering\ntechnology [219, 414], with a drawback of high construction cost. Later, many generative talking face models based on\n3DMM parameters [74, 111, 196, 423] were established, using models such as blendshape [74], flame [239], and 3D mesh\n[352], with audio as model input for content generation. At present, most methods are directly reconstructed from\ntraining videos. NeRF uses multi-layer perceptrons to simulate implicit representations, which can store 3D spatial\ncoordinates and appearance information and are used for high-resolution scenes [238, 286, 294]. In addition, a pipeline\nand an end-to-end framework for unrestricted talking face video synthesis have also been proposed [215, 328], taking\nany unidentified video and arbitrary speech as input.\n6\nAIGC TASK: BEYOND TEXT AND IMAGE\n6.1\nVideo\nCompared with image generation, the progress of video generation lags behind largely because of the complexity\nof modeling higher-dimensional video data. Video generation involves not only generating pixels but also ensuring\nsemantic coherence between different frames. Video generation works can be categorized into unguided and guided\ngeneration (e.g., text, images, video, and action classes), with text-guided age (see Figure ??) receiving the most attention\ndue to its high influence.\nFig. 20. Examples of text-guided video generation (figure obtained from [394]).\nUnguided video generation. Early works on extending image generation from single frame to multiple frames are\nlimited to creating monotonous yet regular content like sea waves. The generated dynamic textures [96, 466] often have\nManuscript submitted to ACM\n28\nZhang et al.\na spatially repetitive pattern with time-varying visualization. With the development of generative models, numerous\nworks [2, 68, 305, 370, 433, 448, 512] extend the exploration from naive dynamic textures to real video generation.\nNonetheless, their success is limited to short videos for simple scenes with the availability of low-resolution datasets.\nMore recent works [67, 157, 371, 424] improve the video quality further, among which [157] is regarded as a pioneering\nwork of diffusion models.\nText-guided video generation. Compared to text-to-image models that can create almost photorealistic pictures,\ntext-guided video generation is more challenging. Early works [136, 246, 260, 276, 290, 313] based on VAE or GAN\nconcentrate on creating video in simple settings, such as digit bouncing, and human walking. Given the great success\nof the VQ-VAE model in text-guided image generation, some works [160, 472] extend it to text-guided video generation,\nresulting in more realistic video scenes. To achieve high-quality video, [157] first applies the diffusion model to\ntext-guided video generation, which refreshes the benchmarks of evaluation. After that, Meta and Google propose\nMake-a-Video [394] and Imagen Video [155] based on the diffusion model, respectively. Specifically, Make-a-Video\nextends a diffusion-based text-guided image generation model to video generation, which can speed up the generation\nand eliminate the need for paired text-video data in training. However, Make-a-Video requires a large-scale text-video\ndataset for fine-tuning, which results in a significant amount of computational resources. The latest Tune-a-Video [474]\nproposes one-shot video generation, driven by text guidance and image inputs, where a single text-video pair is used to\ntrain an open-domain generator.\n6.2\n3D generation\nThe tremendous success of deep generative models on 2D images has prompted researchers to explore 3D data generation,\nwhich is actually a modeling of the real physical world. Different from the single format of 2D data, a 3D object can\nbe represented by depth images, voxel grids[476], point clouds[330, 331], meshes[140] and neural fields[283], each of\nwhich has its advantages and disadvantages.\nAccording to the type of input and guidance, 3D objects can be generated from text, images and 3D data. Although\nmultiple methods [112, 175, 262] have explored shape editing guided by semantic tags or language descriptions, 3D\ngeneration is still challenging due to the lack of 3D data and suitable architectures. Based on the diffusion model,\nDreamFusion [326] proposes to solve these problems with a pre-trained text-to-2D model. Another branch of works\nreconstruct the 3D objects from single-view images [33, 122, 243, 432, 457, 510] or multi-view images [63, 167, 454, 480],\ntermed Image-to-3D. A new branch of multi-view 3D reconstruction is Neural Radiance Fields (NeRF) [286] for implicit\nrepresentation of 3D information. The 3D-3D task includes completion from partial 3D data [455] and transformation\n[26], with 3D object retrieval as a representative transformation task.\n6.3\nSpeech\nSpeech synthesis is an important research area in speech processing that aims to make machines generate natural and\nunderstandable speech from text. Methods of traditional speech synthesis include articulatory [217, 380], formant [12,\n377], concatenative synthesis [293, 306], and statistical parametric speech synthesis (SPSS) [198, 292]. These methods\nhave been widely studied and applied, e.g., formant synthesis is still used in the open-source NVDA (one of the leading\nfree screen readers for Windows). However, these generated speeches are identifiable from the human voice, and\nartifacts in synthesis speech reduce intelligibility.\nEarly works [102, 333, 514\u2013516] consist of three modules: text analysis, an acoustic model, and a vocoder. WaveNet [440]\nis a revolution within speech synthesis which can generate the raw waveform from the linguistic features. To improve\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n29\nthe quality of speech and diversity of voices, generative models are introduced in speech synthesis, such as GAN [124].\nCompared with GAN, diffusion models do not require a discriminator, making training more stable and simple. Therefore,\nthe works of speech synthesis adopt diffusion models, becoming a rising trend. A branch of works [57, 168, 220, 479]\nfocuses on efficient speech synthesis, in which different ways are adopted to reduce the generated time by accelerating\ninference, such as combining the schedule and score networks for training, jointly trained GAN. Another branch of\nstudy [52, 289, 361, 390] concentrates on end-to-end models, which directly generate waveform from text without any\nintermediate representations. A fully end-to-end model not only simplifies the training and inference, but also reduces\nthe demand for human annotations. The branch of diffusion-based speech synthesis is not limited to the two mentioned\nabove, such as speech enhancement and guided speech synthesis.\n6.4\nGraph\nGraphs are ubiquitous in the world, which aid in visualizing and defining the relationships between objects in a wide\nrange of domains, from social networks to chemical compounds. Graph generation, which creates new graphs from a\ntrained distribution that is similar to the existing graphs, has received a lot of attention.\nTraditional graph generation works [11, 224, 464] create new graphs with specific features that are related to the\nhand-crafted statistical features of real graphs , which simplifies the process but fails to capture relational structure in\ncomplex scenarios. With the successes of deep learning algorithms, researchers have begun to apply them to graph\ngeneration, which, unlike the traditional methods, can be directly trained by real data and automatically extract features.\nAmong them, works [76, 249, 503] based on autoregressive model create graph structures sequentially in a step-wise\nfashion, which allows for greater scalability but fails to model the permutation invariance and is computationally\nexpensive. Simultaneously, One-shot models [254, 269, 269] such as VAE and flow are incapable of accurately modeling\nstructure information because of ensuring tractable likelihood computation. Although graph generation [80, 183, 278]\nbased on GAN sides step likelihood-based optimization by using a discriminator, the training is unstable.\nRecently, there has been a surging interest in developing diffusion models for graph-structured data. EDP-GNN [302]\nis the pioneering to show the capability of the diffusion model in the Graph generation, with the goal of addressing\nnon-invariant properties. After that, On the one hand, diffusion-based works [138, 166, 186, 266, 445] focus on realistic\ngraph generation, which produces graphs that are similar to a given set of graphs. On the other hand, [14, 388, 482, 513]\nconcentrate on goal-directed graph generation, which generates graphs that optimizes given objects, like molecular and\nmaterial generation.\n6.5\nOthers\nThere are also other interesting tasks generating content in different modalities, e.g., music generation [179] and\nlip-reading [106]. A typical music generation system can be categorized into three representation levels (from top to\nbottom), which generates score, performance, and audio, respectively [179]. With the development of deep learning,\nmusic generation introduces various methods for higher music quality, e.g., MusicVAE [354], MuseGAN [95] and\ntransformer in [170]. Music generation inspires and accelerates the development of computer-assistant composition\nsoftware, including Magenta project from Google and Flow Machine project from Sony Computer Science Laboratories.\nA Lip reading task transforms visual inputs of lip movement to decoded speech [106], and has also shown impressive\nadvances thanks to improved corpora and architectures.\nManuscript submitted to ACM\n30\nZhang et al.\n7\nINDUSTRY APPLICATIONS\nUndoubtedly, AIGC has gone viral on social media since 2022. For example, users are active in sharing their experience\nof using ChatGPT for having an interactive conversation or Stable diffusion for generating images with a text prompt.\nHowever, this hype is expected to dwindle if AIGC cannot be used for practical applications in the industry to demonstrate\nits value. Therefore, we discuss how AIGC might influence various industries.\n7.1\nEducation\nAIGC is changing the paradigm of education by assisting in teaching and learning. Generative AI carries transformative\npotential in teaching, with the application ranging from course materials generation to assessment and evaluation [324,\n517]. Simultaneously, applications of generative models have begun to influence how students learn [27, 420].\nGenerative AI technologies can provide educators with creation of personalized tutoring [517], designing course\nmaterials [324], and assessment and evaluation [27, 517]. A unique foreign language teaching product for young children\nusing generative technologies such as ChatGPT can attract children\u2019s attention, motivate them, and provide a fun\nlearning environment. Higher education needs to embrace the use of AI in higher education, which can create more\nengaging, effective, and efficient learning experiences for students [517]. One of the primary benefits of generated AI\ncourse material generation is that it can save teachers time and effort by automating the process of creating and updating\ncourse material. In addition, ChatGPT could significantly reduce the workload of law school instructors, freeing up time\nto increase academic productivity or develop more complex teaching skills [324]. The benefits of ChatGPT in promoting\nteaching include but are not limited to facilitating personalized and interactive learning. However, some limitations of\nChatGPT, such as generating incorrect information, exacerbating existing biases in data training, and privacy issues, can\nalso appear [27]. Overall, addressing these challenges requires collaborative efforts from policymakers and educators to\nprovide recommendations or guidance for the appropriate use of generative AI tools.\nMoreover, generative AI technologies can help students write essays [420], at-home tests or quizzes [420], comprehend\ncertain theories and concepts, and different language essays and papers in academic issues [27, 517]. Chatbots can\nprovide students with 24/7 support, allowing them to get the help they need when they need it. With the ability to\ncorrect grammar, suggest improvements, and identify weak areas, chatbots like ChatGPT can provide students with\nimmediate feedback on their writing, helping them to learn from their mistakes and improve their writing skills over\ntime. This not only saves students time but also helps them to become better writers [493]. According to a survey\nconducted by an online course provider, 89% of students use ChatGPT to complete their homework, with 50% using it\nfor essays and 48% using it for at-home tests or quizzes [420]. Additionally, generated AI can tailor the course material\nto individual students\u2019 needs, such as learning style and pace, which has the potential to improve student engagement\nand learning outcomes. ChatGPT can also help students comprehend certain theories, concepts, and different language\narticles, making them work more effectively [27, 517]. There are also challenges and concerns associated with generated\nAI course material generation, including the generated material\u2019s quality, and the possibility of bias in the data used to\ntrain the AI. As a result, before using generated course material in an educational context, it is critical to evaluate and\nvalidate it carefully [79].\nWith the use cases mentioned above, AIGC has the potential to revolutionize education by improving the quality and\naccessibility of educational content, increasing student engagement and retention, and providing personalized support\nfor learners. With the continuous advancements in AI, AIGC is poised to become an integral part of the education\nindustry, offering students a more engaging, accessible, and personalized learning experience.\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n31\n7.2\nGame and metaverse\nMost users may not resonate with one-size-fits-all content in the game and metaverse, where personalization yields the\nbest experience. Although games and metaverse provide users with virtual worlds, the content represents the character\nand personality of users. Generative AI makes that possible, which not only allows users to customize their avatars but\nalso provides diverse scenarios and storylines, making the experience more immersive [53, 325, 344, 344].\nAI Dungeon powered by GPT-3 model allows users to generate an open-end story navigated by text, where generative\nAI will produce new events as the response to the different actions of users, creating a one-of-a-kind and unexpected\ngameplay experience [422]. Horizon Worlds, one of the most popular games, allows you to wander into the virtual\nworld related to content consumption and creation. In Horizon, users will have more control over how they want to\ntailor their online experience to meet their individual needs. Specifically, users can design their unqiue avatars and\nscenes using gizmos that include pre-built object and avatar properties [284]. Moreover, the visual novel game Traveler\nconcentrates on generating gorgeous scenarios to present users with visual impact, in which you will embark on a\njourney through a diverse world. When a player explores the game Traveler, the player will be exposed to magnificent\nvisuals and immersive soundscapes. As each scene is unique, the content can range from dark forests to bustling cities,\nall crafted by generative AI [113].\nAlthough the term \u201cmetaverse\" has become a buzzword recently, in the real world, the virtual space created by the\ngame may serve as the portal to the metaverse [301, 344]. Roblox, a sandbox game platform, first included the concept\nof \u201cMetaverse\" in its prospectus and made its market value soar, where players can create their own world beyond their\nimagination [301]. Virtual concert singers have a more comprehensive range of musical styles and talents. Audiences\ncan choose their own favorite styles and even idols, providing them with a more diverse and personalized concert\nexperience. Travis Scott, a well-known American rapper and producer, performed a historic concert inside the Fortnite\ngame, and his avatar guided the players to experience different scenes, ranging from underwater to outer space [465].\nThe University of California, Berkeley, presented its commencement ceremony in \u2018Minecraft\u2019, a popular computer game.\nIn the Minecraft game, students and alumni built a copy of campus using generative AI technology, allowing thousands\nof graduating seniors using their avatars from around the world to attend the event [358]. Overall, AI has played a\nsignificant role in the evolution of the game and metaverse, and its use continues to grow as technology improves and\nbecomes more accessible.\n7.3\nMedia\nWith the ubiquitous growth of generative AI technologies, they play a rising role in media and advertising. AIGC\nnot only promotes the diversity of media, which provides a better experience for audiences, but it also enables media\npractitioners more efficient in their work [44, 84, 107, 222, 288, 439, 527].\nThe media powered with AIGC enables more diversified content and ways of reporting, changing the media mode of\nproduction and organizational structure [204, 273, 527]. AIGC can be applied to a variety of applications in media, such\nas writing robots, news anchors, and caption generation. Traditionally, media outlets have relied on expert journalists to\nwrite new articles and reports, which requires a significant amount of energy and time, resulting in a limited number of\narticles. Moreover, the timeliness of the news is critical, and the news may be eclipsed after an hour. Generative AI can\ngreatly assist journalism by using text generation technologies to make journalism more efficient and responsive [288].\nAssociated Press applies these technologies to generate roughly 40000 stories a year and its articles on company earnings\nincrease from 1200 to 14800 [130]. The Quakebot, a robot reporter of Los Angeles Times News, only takes three minutes\nManuscript submitted to ACM\n32\nZhang et al.\nto complete a related article after the Los Angeles earthquake [309]. Bloomberg News, an international financial media\ncompany, launched Buttetin in 2018, with the goal of providing personally storied whose one-sentence summaries are\ngenerated by chatbots [470].\nAI news anchors have emerged as a result of the deep integration of generative AI in the media [461, 491? ]. AI\nnews anchors, combined with real anchors, make the way to spread information more diverse. AI news anchors can\nbroadcast news based on the text, whose appearance and expression imitate the real anchor. China\u2019s state news agency\nXinhua and Chinese search engine, Sogou, have developed AI news anchors with different profiles and languages. The\nmost impressive is the 3D AI news anchor Xin Xiaowei, whose broadcast form can be presented in all directions from\nvarious angles, significantly improving the sense of three-dimensionality and layering [279]. Additionally, Korea\u2019s cable\nchannel MBN has created the AI news anchor AI Kim, who can quickly respond to various emergencies and even report\nall day [397]. To help the hearing-impaired people to get more information about international sporting events and\nBeijing Winter Olympics, an AI-driven sign language service provider, namely Ling Yu, was developed by giant tech\nTencent, where AIGC tasks are used including 3D digital human modeling, machine translation, image generation, and\nspeech-to-text [511]. Moreover, Migu, a Chinese business dedicated to providing digital information, can offer smart\nsubtitle functions to the live broadcast of Beijing Winter Olympics. Therefore, people with hearing impairments can\nwatch the live broadcast of the sports event, which makes them more immersive.\n7.4\nAdvertising\nVarious AI applications have transformed the advertising industry, giving advertisers powerful tools to create innovative\nand engaging content that connects to consumers at a deeper level [84, 133, 439]. Among the various applications of AI\nin advertising, AIGC is particularly influential by allowing advertisers to create personalized and attractive content\nthat resonates with individual consumers. A creative advertising system (CAS) aligns with the principles of AI for\ngenerating and testing advertising ideas, which helps aspiring and mature creators understand that creativity is not an\nelite privilege, but rather a systematic process that can be assisted through data and computation [439]. Implementing\nprogrammatic advertising has not fully utilized self-generating technology, resulting in different consumers being\nexposed to the same content. Fortunately, a personalized advertising copy intelligent generation system (SGS-PAC)\ncan automatically personalize advertising content to meet individual consumer needs [84]. Advertising posters are\na common form of information display used to promote products. Another intelligent system, Vinci, supports the\nautomatic generation of advertising posters [133]. By inputting product images and slogans specified by users, Vinci\nuses deep-generation models to generate beautiful posters.\nIn addition, Brandmark.io is an AIGC-based tool that automatically generates logos for businesses. The tool creates\nmultiple logo variations based on the user\u2019s preferences and specifications. Advertisers can purchase and use the logos\ncreated by the tool for their businesses, making it an easy and cost-effective solution for logo design [193]. By GAN\nthat forces output to include specific keywords, the approach automates product listing generation likely to attract\npotential buyers [275]. It enhances users\u2019 marketing efforts on peer-to-peer marketplaces. Moreover, technological\ninnovations have provided digital and automated tools to the advertising industry, but have also allowed advertisers\nto automate the production of \u201csynthetic advertising\". As reported by [381], AIGC has transformed the advertising\nindustry by enabling advertisers to create highly personalized and engaging content at scale while saving time and\nresources. We expect to see even more innovative and influential applications of generated AI in advertising.\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n33\n7.5\nMovie\nIt is interesting to see how technology now affects almost every step of movie creation. Research has led to the\ndevelopment of computer-based surroundings that help with editing, labeling, video retrieval, and many more [78,\n125, 295, 317\u2013319, 366, 415, 428, 434]. To start with, AI-powered screenwriting software has significantly impacted the\nmovie-making process. AI has created a new movie experience by integrating visual effects (VFX) [291], improved\nsound effects (SFX), and new viewing platforms. The 4K, IMAX, and 3D movies, as well as animations, are highly\nimpacted by them.\nThe script forms the foundation of how a movie will fare at the ticket counters. AI-generation devices store and\ncompute massive amounts of data to create \u201cideal\" scripts [15]. AI software is also employed to rework old screenplays\ninto polished versions that are then analyzed and improved by the director and writer. It goes beyond just developing\nand analyzing current scripts. Jasper AI [362] and Scalenut [329] are two examples of AI scriptwriters.\nMovies are given visual effects (VFX) to increase spectator appeal. They combine original images with real video to\ncreate engrossing, realistic, contextual depictions that may include digital surroundings, de-aging, and many more.\nThe VFX team of The Curious Case of Benjamin Button [416] put up two arrays of cameras in a bright room and\nutilized the MOVA Contour reality capture technology [82] to construct a three-dimensional database of the hero\u2019s\nfacial expressions. The VFX team next developed high-resolution 3D models of the lead character at various ages and\nlastly employed AI to manipulate the data retrieved from the three-dimensional database to cause the head models\nto age. The outcome was convincing and garnered widespread acclaim across the movie community. In movies like\nBlade Runner 2049 [274] and Gemini Man [360], the VFX team tracked and recorded the protagonist\u2019s facial data with\nthe help of motion capture technology [5]. They then rebuilt the 3D facial data in a computer and further polished it\nto accomplish age deduction. Although this approach takes expensive technology and a vast amount of money, it is\nincredibly precise and adaptable.\nAI is expanding the limits of amusement by bringing back actors who have passed away in movies. Deepfake\ntechnology uses computer visuals and AI to produce incredibly amazing and lifelike fake videos of actual people or\nmade-up characters. Fast and Furious 7 [469] used VFX and vintage video to bring back Paul Walker after he passed\naway in 2013, using the actor\u2019s visage transferred onto his sibling.\nIn addition to the visual effects, subtitles also play a vital role in viewers\u2019 experience. For the benefit of viewers having\nhearing impairments, automated subtitles for the deaf and hard of hearing, also known as SDH [8], include textual\ntranscriptions of speech, speaker changes, and background noise. These benefits substantially increase how much\nmoney movies make. Natural Language Processing (NLP), a kind of AI that focuses on deciphering spoken language,\noffers multilingual subtitles in movies. To produce automated subtitles, Rev [351], a cloud-based program, is widely\nused by movie lovers. AI has also revolutionized the task of speech prediction in silent movies. AI-generated speech\nsynthesis can narrate silent movies and dub movies into multiple languages. Deep learning systems trained on massive\nhuman audio samples can produce natural-sounding voiceovers. Features like LPC (Linear Predictive Coding) [101] and\nmel spectrograms [100] generate high-quality intelligible audio through conversion. Recently, a Tacotron2 model [384]\nvariation for the video-to-audio synthesis was proposed by [327]. [494] suggests an efficient stochastic model that\nproduces endless high-quality audio patterns for a specific silent video, thus effectively encapsulating the multimodality\nof the speech prediction issue. Along with the visual and sound effects, we have Colourlab.Ai [70] for color grading,\nDescript [86] for video editing, and many more tools continuously making waves in the movie industry.\nManuscript submitted to ACM\n34\nZhang et al.\n7.6\nMusic\nAIGC also makes it to the music industry with notable developments [499]. AI can not only spot patterns and trends in\nvast data sets that are challenging for humans to notice, but also allows amateur musicians a cutting-edge technique to\nenhance their creative process, which is a fantastic opportunity. The fusion of AI technology into music is a new trend\nthat many experts, researchers, musicians, and record companies are exploring [280]. Many utilize AIGC to create\nentirely new music, while some software edit compositions in the style of various composers.\nMusic industries are anticipating significant expenditures in this field, whether it is because of using AI to compose\nmusic or to help musicians. A fantastic illustration of an AI melody generator is Google\u2019s Magenta project [172], [10].\nIBM\u2019s Watson Beat is one more example. For composing an original song, it makes use of AI and machine learn-\ning [49], [110]. 2016 saw the successful creation of text-to-speech (TTS) recordings and recordings that resembled\nmusic by DeepMind researchers [421], [496]. AI is also vastly used for the processing and improvement of digital audio.\nLANDR, an incredible AI-powered creative tool that enables musicians to get their music on several streaming services\nlike Spotify and Apple Music, is one such service. A significant problem known as \u201cwriter\u2019s block [379]\" frequently\nconfronts lyricists. But thanks to AI, it\u2019s no longer a problem now. Nowadays, many musicians employ AI to create new\nlyrics for their songs [277]. GPT-2 [7], [538], a text-generating tool, has been created by OpenAI, an AI technology firm.\nNot only can this remarkable text generator produce authentic news, but it can also write lyrics for Beatles songs and\nmusic from all other genres. However, AI is not just capable of producing text; it can also create original soundtracks\nand melodies. The Sony CSL flow machine offers assistance to artists so they can develop original music based on their\nideas [356]. One of the most well-known AI tools for writing unique music is called AIVA [189]. To produce a unique\ntrack, the user first chooses a pre-set style and then modifies a variety of variables, such as the key, instrumentation,\ntime signature, etc. AIVA can deconstruct all the intricate auditory information saved into discrete characteristics while\nreading hundreds of musical compositions by renowned musicians like Bach and Mozart [98]. These qualities may\nthen be interpreted again and used to produce a completely new musical work. Apart from the tools mentioned above,\nthere are so many other applications that made a significant impact on the music industry, such as the iOS-based tool\nAmadeus Code [38], the cloud-based platform Amper [147], Ecrett Music [36], etc.\n7.7\nPainting\nFrom offering automatic painting tools to encouraging creative experimentation, AIGC is revolutionizing the painting\nindustry in many ways. AI programs can analyze pictures to produce color schemes, patterns, and textures that can\nmake artwork. The automatic drawing tools generated using these algorithms are able to apply these patterns and\ntextures to produce distinctive and intricate works of art [548]. AI can also analyze a person\u2019s preferences, interests,\nand style to create customized artwork. Empowering artists to create art specifically suited to their preferences and\ninterests can increase their appeal and value.\nThe artwork created by MidJourney under the title \u2018Space Opera Theatre\u2019 earned first place in the Colorado State Fair\nArt Competition [81], demonstrating the capability of AI painting tools to produce excellent pieces of art. Midjourney\nis an excellent AI image generator with comprehensive functions, which is used by many artists to generate inspiration.\nThe creation of various art forms by generative AI, such as abstract painting generation [235], Chinese shanshui\npainting [543], and Chinese ink paintings [64], undoubtedly promotes the advancement of painting. Moreover, AIGC\ncan assist in conservation and restoration [506], [164]. AI algorithms are capable of analyzing and repairing ruined\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n35\nartwork. These algorithms make it simpler for conservators to return the artwork to its initial state by detecting and\nremoving dust, scratches, and other flaws.\nFor non-professionals unfamiliar with drawing or animation, AIGC is also very helpful because it enables them\nto produce high-quality visual effects. By adding additional constraints to the diffusion model, ControlNet [341] can\nincrease the variability of the produced images. It can describe the generated images along with those other constraints\nof border drawing, depth information, Hough line map, normal map, and posture estimation. AIGC has also started a\nnew era of collaborative artwork [41, 50]. AI algorithms can create collaborative paintings that involve multiple artists\nworking together. These algorithms can analyze the styles of each artist and produce a unified style that incorporates\nelements from all of the artists\u2019 works.\n7.8\nCode development\nGenerative AI can contribute to the field of code development [134, 135, 176, 412], where AIGC can create code without\nthe need for manual coding. The work by [412] explores the interpretability requirements of generative AI for code and\ndemonstrates how human-centered approaches can drive the development of explainable AI (XAI) technologies in new\ndomains. To improve testing efficiency and increase test coverage, it is particularly important to generate high-quality\ntest cases automatically [134, 135]. In order to optimize the efficiency of data engineering, a novel software engineering\napproach based on neural networks for dataset augmentation can be designed [176]. One of the popular applications in\nAI-generated code is Github\u2019s Copilot, an AI tool jointly developed by GitHub and OpenAI. Users can automatically\ncomplete code through GitHub Copilot using software development tools [91]. Moreover, AI-generated technology\ncan also assist in code refactoring, which improves existing code without changing its original functionality. This can\nshorten the time for developers to refactor and improve the quality of the code. A popular code refactoring tool is\nDeepCode [174], an AI-supported code review tool that can inspect your code and provide suggestions for improvement.\nIn addition, AIGC can also make an impact on the e-commerce and finance industries [163]. E-commerce platforms such\nas Amazon, JD.com, and so on can use AI-powered customer service to provide shopping guide services to customers,\nthereby saving costs for enterprises. Financial companies can use virtual investment advisors to advise customers on\nsecurities account opening, financial investment, and other related services.\n7.9\nPhone apps and features\nNumerous AIGC applications have emerged as fun-oriented mobile apps, typically in the form of image and video\nediting. Photoshop is traditionally a common tool for image editing, but manual work is time-consuming and can result\nin unnatural or unrealistic output. In addition, video editing involves analyzing each video clip and making editorial\ndecisions based on both the audio and visual content. This process is time-consuming because the video is a time-based,\ndual-track medium that requires careful consideration of every frame. Fortunately, some work [17, 32, 398] has explored\nthe utilization of AI technologies behind AIGC, to the image or video editing, making the applications in AIGC such as\nface swapping and digital avatar possible.\nSome popular applications based on face swapping are gaining widespread popularity on the Internet. This technology\nuses advanced AI technologies to analyze and swap people\u2019s faces with their favorite celebrities or anyone else in\nseconds, making it easier and faster to use compared to traditional PS technologies. VanceAI, Voila AI Artist and FaceAPP\nare leading figures, with FaceApp being recognized as the best facial photo editing App, winning numerous awards,\nand being downloaded by over 500 million users and counting [372]. Another popular application is voice-changing\ntechnology. This technology can adjust the pitch, timbre, speech rate, and other characteristics of the human voice to\nManuscript submitted to ACM\n36\nZhang et al.\nchange the quality of the human voice. MagicMic [471] and Voicemod [202] are two popular applications for real-time\nvoice modification and soundboard operations, which people can use to change their voices for creating fun content,\nlive streaming, or other purposes, enhancing the enjoyment of communication between people.\nIn addition, another technological trend is to transform individuals into virtual characters, thereby increasing\nentertainment value. virtual characters are digital avatars of people in a virtual world, they can be partial replicas of\nreal people or even completely digital versions. Apple\u2019s first \u201cdigital avatar\" technology, Animoji, focuses mainly on\ngenerating preset cartoon and animal characters and does not support custom generation [426]. The second generation\nof \u201cdigital avatar\" technology represented by iPhone\u2019s Memoji and Xiaomi\u2019s Mimoji started to support personalized\navatar customization, which offers a variety of options, starting from hairstyle, eyes, nose, dresses, etc [406]. This\nupgrade allows users to create an avatar that not only can track their facial movements, but also look like them. Besides\nthat, the created avatars can also be posted as comments in WeChat or Facebook chats, giving users a more personal\nway to express themselves on social media. Since then, digital avatar technology has become one of the standard\nfeatures of smartphones among various smartphone manufacturers.\n7.10\nOther fields\nBeyond the above fields, AIGC is expected to have applications in more fields. For example, the design and development\nof a novel drug are complex, costly, and time-consuming. On average, it takes around $3 billion and more than 10\nyears for a new drug to be accepted by the market [201]. This motivates using AIGC to accelerate the drug discovery\nprocess and reduce costs. In 2018 DeepMind created AlphaFold [364], which can accurately predict the structure of\nproteins and has been considered a milestone for drug discovery and fundamental biology research. Its updated version\nAlphaFold2 was released in 2020 and had higher accuracy than the former. ProteinMPNN[77], designed by Justas\nDauparas, can design protein sequences for specific tasks, generating entirely new proteins quickly in just a few seconds.\nBesides directly exploiting the generated content, AIGC can also help workers in various fields improve their efficiency.\nFor example, in medical consultation, the patient can rely on chatbots for basic medical advice, while turning to the\ndoctor only for more severe cases. In manufacturing design, it is possible to combine AIGC with the widely used\ncomputer-aided design system to minimize the repetitive effort so that the designer can focus on the more meaningful\npart.\n8\nCHALLENGES AND OUTLOOK\n8.1\nChallenges\nEven though AIGC has shown remarkable success in generating realistic and diverse outputs across various domains,\nthere are still numerous challenges in real-world applications. Except for requiring a large amount of training data and\ncompute resources, we list some of the most significant challenges as follows.\n(1) Lack of interpretability. While AIGC models can yield impressive outputs, it remains challenging to understand\nhow the model arrives at the outputs. This is especially a concern when the model generates an undesirable\noutput. Such a lack of interpretability makes it difficult to control the output.\n(2) Ethical and legal concerns. The AIGC model is prone to data bias. For example, a language model mainly\ntrained on the English text can be biased toward western culture. Copyright infringement and privacy violations\nare the underlying legal concerns that cannot be ignored. Moreover, the AIGC model also has the potential for\nmalicious use. For example, students can exploit these tools to cheat on their essay assignments, for which AI\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n37\ncontent detectors are desired. AIGC models can also be used for distributing misleading content for political\ncampaigns.\n(3) Domain-specific technical challenges. At the current and in the near future, different domains require their\nunique AIGC models. Each domain is still faced with its unique challenges. For example, Stable Diffusion, a\npopular text-to-image AIGC tool, occasionally generates output that is far from what the user desires, such as\ndrawing humans as animals, one person as two people, etc. ChatBot, on the other hand, makes factual mistakes\noccasionally.\n8.2\nOutlook\nDespite its unprecedented popularity, generative AI is still in its early stage. Here, we present how AIGC might evolve\nin the near future.\n(1) More flexible control. A major trend of AIGC tasks is to realize more flexible control. Taking image generation\nas an example, early GAN-based models can generate images of high quality, but with little control. The recent\ndiffusion models trained on large text-image data enable control through text instruction. This facilitates the\ngeneration of images that better match the users\u2019 needs. Nonetheless, current text-to-image models still require\nmore fine-grained control so that the images can be generated in a more flexible manner\n(2) From pertaining to finetuning. Currently, the development of AIGC models like ChatGPT focuses on the\npretraining stage. The corresponding technology is relatively mature; however, how to fine-tune these foundation\nmodels for the downstream tasks is an under-explored field. Different from training a model from scratch, the goal\nof finetuning needs to trade-off between the foundation model\u2019s original general capability and its adaptation\nperformance on the new task.\n(3) From big tech companies to startups. At present, AIGC technology has mainly developed big tech companies,\nlike Google and Meta. With the support of big tech companies, some startup companies have emerged to show\nhigh potentials, like OpenAI (supported by Microsoft) and DeepMind (supported by Google). With the focus\ntransition from core technology development to applications, more startup companies are expected to emerge\ndue to increasing demand.\nFig. 21. Deal value and deal count for generative AI funding in the past 6 years (figure obtained from: PitchBook).\nDiscussion: investment, bubble and job opportunities. Technology-wise, there is no doubt that AIGC has\nmade significant progress in the past few years. When a transformative technology emerges, the market tends to be\nManuscript submitted to ACM\n38\nZhang et al.\nover-optimistic about its potential applications and future growth, which also applies to generative AI. According to\nPitchBook (see Fig. 21), the funding for generative AI from venture capital (VC) increased significantly in the last two\nyears. Some critics have concerns that generative AI might be the next bubble. One of their main concerns is that most\nAIGC tools are mainly playful instead of practical. For example, text-to-image models are fun to play with, but how\nthey might generate revenues remains unclear. It is difficult to predict how generative AI might evolve. However, the\nauthors of this work believe that generative AI is unlikely to become the next bubble considering it is a relatively new\nand rapidly growing field with many potential applications. There is also a hot debate about whether generative AI will\nreplace humans, causing the loss of numerous job opportunities. On the other hand, generative AI can also create new\njob opportunities for individuals with skills on AI research and implementation skills. The industries that benefit from\nthe power of AIGC might also boom and generate more job opportunities.\nREFERENCES\n[1] Rameen Abdal, Yipeng Qin, and Peter Wonka. 2019. Image2stylegan: How to embed images into the stylegan latent space?. In Proceedings of the\nIEEE/CVF International Conference on Computer Vision. 4432\u20134441.\n[2] Dinesh Acharya, Zhiwu Huang, Danda Pani Paudel, and Luc Van Gool. 2018. Towards high resolution video generation with progressive growing\nof sliced wasserstein gans. arXiv preprint arXiv:1810.02419 (2018).\n[3] Johannes Ackermann and Minjun Li. 2022. High-resolution image editing via multi-stage blended diffusion. arXiv preprint arXiv:2210.12965 (2022).\n[4] Daniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade,\nYifeng Lu, et al. 2020. Towards a human-like open-domain chatbot. arXiv preprint arXiv:2001.09977 (2020).\n[5] Adobe. 2022. What is motion capture and how does it work? https://www.adobe.com/uk/creativecloud/animation/discover/motion-capture.html\n(2022).\n[6] Namhyuk Ahn, Byungkon Kang, and Kyung-Ah Sohn. 2017. Image distortion detection using convolutional neural network. In 2017 4th IAPR Asian\nConference on Pattern Recognition (ACPR). IEEE, 220\u2013225.\n[7] Open AI. 2019. Blog GPT-2. https://openai.com/blog/tags/gpt-2/ (2019).\n[8] ai media. 2017. Subtitles for the Deaf or Hard-of-Hearing (SDH) - Subtitles, Closed Captions, and SDH. https://blog.ai-media.tv/blog/what-is-sdh\n(2017).\n[9] Reina Akama, Sho Yokoi, Jun Suzuki, and Kentaro Inui. 2020. Filtering noisy dialogue corpora by connectivity and content relatedness. arXiv\npreprint arXiv:2004.14008 (2020).\n[10] Mincer Alaeddine and Anthony Tannoury. 2021. Artificial Intelligence in Music Composition. In Artificial Intelligence Applications and Innovations:\n17th IFIP WG 12.5 International Conference, AIAI 2021, Hersonissos, Crete, Greece, June 25\u201327, 2021, Proceedings 17. Springer, 387\u2013397.\n[11] R\u00e9ka Albert and Albert-L\u00e1szl\u00f3 Barab\u00e1si. 2002. Statistical mechanics of complex networks. Reviews of modern physics 74, 1 (2002), 47.\n[12] Jonathan Allen, Sharon Hunnicutt, Rolf Carlson, and Bjorn Granstrom. 1979. MITalk-79: The 1979 MIT text-to-speech system. The Journal of the\nAcoustical Society of America 65, S1 (1979), S130\u2013S130.\n[13] Jaan Altosaar. 2016. Tutorial - What is a Variational Autoencoder? https://doi.org/10.5281/zenodo.4462916\n[14] Namrata Anand and Tudor Achim. 2022. Protein Structure and Sequence Generation with Equivariant Denoising Diffusion Probabilistic Models.\narXiv preprint arXiv:2205.15019 (2022).\n[15] Nantheera Anantrasirichai and David Bull. 2022. Artificial intelligence in the creative industries: a review. Artificial intelligence review (2022), 1\u201368.\n[16] Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, and Lei Zhang. 2018. Bottom-up and top-down\nattention for image captioning and visual question answering. In Proceedings of the IEEE conference on computer vision and pattern recognition.\n6077\u20136086.\n[17] Dawit Mureja Argaw, Fabian Caba Heilbron, Joon-Young Lee, Markus Woodson, and In So Kweon. 2022. The anatomy of video editing: A dataset\nand benchmark suite for ai-assisted video editing. In Computer Vision\u2013ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23\u201327, 2022,\nProceedings, Part VIII. Springer, 201\u2013218.\n[18] Martin Arjovsky, Amar Shah, and Yoshua Bengio. 2016. Unitary evolution recurrent neural networks. In International conference on machine\nlearning. PMLR, 1120\u20131128.\n[19] Omri Avrahami, Ohad Fried, and Dani Lischinski. 2022. Blended Latent Diffusion. arXiv preprint arXiv:2206.02779 (2022).\n[20] Omri Avrahami, Thomas Hayes, Oran Gafni, Sonal Gupta, Yaniv Taigman, Devi Parikh, Dani Lischinski, Ohad Fried, and Xi Yin. 2022. SpaText:\nSpatio-Textual Representation for Controllable Image Generation. arXiv preprint arXiv:2211.14305 (2022).\n[21] Omri Avrahami, Dani Lischinski, and Ohad Fried. 2022. Blended diffusion for text-driven editing of natural images. In Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition. 18208\u201318218.\n[22] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. 2016. Layer normalization. arXiv preprint arXiv:1607.06450 (2016).\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n39\n[23] Alexei Baevski, Michael Auli, and Abdelrahman Mohamed. 2019. Effectiveness of self-supervised pre-training for speech recognition. arXiv\npreprint arXiv:1911.03912 (2019).\n[24] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint\narXiv:1409.0473 (2014).\n[25] Ashutosh Baheti, Alan Ritter, and Kevin Small. 2020.\nFluent response generation for conversational question answering.\narXiv preprint\narXiv:2005.10464 (2020).\n[26] Song Bai, Xiang Bai, Wenyu Liu, and Fabio Roli. 2015. Neural shape codes for 3D model retrieval. Pattern Recognition Letters 65 (2015), 15\u201321.\n[27] David Baidoo-Anu and Leticia Owusu Ansah. 2023. Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential\nBenefits of ChatGPT in Promoting Teaching and Learning. Available at SSRN 4337484 (2023).\n[28] Dana H Ballard. 1987. Modular learning in neural networks.. In Aaai, Vol. 647. 279\u2013284.\n[29] Tadas Baltru\u0161aitis, Chaitanya Ahuja, and Louis-Philippe Morency. 2018. Multimodal machine learning: A survey and taxonomy. IEEE transactions\non pattern analysis and machine intelligence 41, 2 (2018), 423\u2013443.\n[30] Hangbo Bao, Li Dong, and Furu Wei. 2022. Beit: Bert pre-training of image transformers. ICLR (2022).\n[31] Siqi Bao, Huang He, Fan Wang, Rongzhong Lian, and Hua Wu. 2019. Know more about each other: Evolving dialogue strategy via compound\nassessment. arXiv preprint arXiv:1906.00549 (2019).\n[32] Omer Bar-Tal, Dolev Ofri-Amar, Rafail Fridman, Yoni Kasten, and Tali Dekel. 2022. Text2live: Text-driven layered image and video editing. In\nComputer Vision\u2013ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23\u201327, 2022, Proceedings, Part XV. Springer, 707\u2013723.\n[33] Jan Bednarik, Pascal Fua, and Mathieu Salzmann. 2018. Learning to reconstruct texture-less deformable surfaces from a single view. In 2018\nInternational Conference on 3D Vision (3DV). IEEE, 606\u2013615.\n[34] Yoshua Bengio, R\u00e9jean Ducharme, and Pascal Vincent. 2000. A neural probabilistic language model. Advances in neural information processing\nsystems 13 (2000).\n[35] Mohamed Benzeghiba, Renato De Mori, Olivier Deroo, Stephane Dupont, Teodora Erbes, Denis Jouvet, Luciano Fissore, Pietro Laface, Alfred\nMertins, Christophe Ris, et al. 2007. Automatic speech recognition and speech variability: A review. Speech communication 49, 10-11 (2007),\n763\u2013786.\n[36] Sean Berry. 2019. Ecrett Music uses AI to generate royalty free music for your videos. https://www.videomaker.com/news/ecrett-music-uses-ai-to-\ngenerate-royalty-free-music-for-your-videos/ (2019).\n[37] Andreas Blattmann, Robin Rombach, Kaan Oktay, and Bj\u00f6rn Ommer. 2022. Retrieval-Augmented Diffusion Models. arXiv preprint arXiv:2204.11824\n(2022).\n[38] Amadeus Code Blog. 2019. Artificial intelligence-powered songwriting assistant. https://blog.amadeuscode.com/ (2019).\n[39] Denny Britz, Anna Goldie, Thang Luong, and Quoc Le. 2017. Massive Exploration of Neural Machine Translation Architectures. ArXiv e-prints\n(March 2017). arXiv:1703.03906 [cs.CL]\n[40] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,\nAmanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems (2020).\n[41] Melissa G Bublitz, Tracy Rank-Christman, Luca Cian, Xavier Cortada, Adriana Madzharov, Vanessa M Patrick, Laura A Peracchio, Maura L Scott,\nAparna Sundar, Ngoc To, et al. 2019. Collaborative art: A transformational force within communities. Journal of the Association for Consumer\nResearch 4, 4 (2019), 313\u2013331.\n[42] Weiwei Cai and Zhanguo Wei. 2020. PiiGAN: generative adversarial networks for pluralistic image inpainting. IEEE Access 8 (2020), 48451\u201348463.\n[43] Guendalina Caldarini, Sardar Jaf, and Kenneth McGarry. 2022. A literature survey of recent advances in chatbots. Information 13, 1 (2022), 41.\n[44] Colin Campbell, Kirk Plangger, Sean Sands, and Jan Kietzmann. 2022. Preparing for an era of deepfakes and AI-generated ads: A framework for\nunderstanding responses to manipulated advertising. Journal of Advertising 51, 1 (2022), 22\u201338.\n[45] Hanqun Cao, Cheng Tan, Zhangyang Gao, Guangyong Chen, Pheng-Ann Heng, and Stan Z Li. 2022. A survey on generative diffusion model. arXiv\npreprint arXiv:2209.02646 (2022).\n[46] Nicholas Carlini and David Wagner. 2018. Audio adversarial examples: Targeted attacks on speech-to-text. In 2018 IEEE security and privacy\nworkshops (SPW). IEEE, 1\u20137.\n[47] Eric R Chan, Connor Z Lin, Matthew A Chan, Koki Nagano, Boxiao Pan, Shalini De Mello, Orazio Gallo, Leonidas J Guibas, Jonathan Tremblay,\nSameh Khamis, et al. 2022. Efficient geometry-aware 3D generative adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition. 16123\u201316133.\n[48] Paramanand Chandramouli and Kanchana Vaishnavi Gandikota. 2022. LDEdit: Towards Generalized Text Guided Image Manipulation via Latent\nDiffusion Models. arXiv preprint arXiv:2210.02249 (2022).\n[49] Anna Chaney. 2018. The Watson Beat: Using Machine Learning to Inspire Musical Creativity. https://medium.com/@anna_seg/the-watson-beat-\nd7497406a202 (2018).\n[50] Rong Chang, Xinmiao Song, and Huiwen Liu. 2022. Between Shanshui and Landscape: An AI Aesthetics Study Connecting Chinese and Western\nPaintings. In HCI International 2022 Posters: 24th International Conference on Human-Computer Interaction, HCII 2022, Virtual Event, June 26\u2013July 1,\n2022, Proceedings, Part III. Springer, 179\u2013185.\n[51] Lele Chen, Ross K Maddox, Zhiyao Duan, and Chenliang Xu. 2019. Hierarchical cross-modal talking face generation with dynamic pixel-wise loss.\nIn Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 7832\u20137841.\nManuscript submitted to ACM\n40\nZhang et al.\n[52] Nanxin Chen, Yu Zhang, Heiga Zen, Ron J Weiss, Mohammad Norouzi, Najim Dehak, and William Chan. 2021. WaveGrad 2: Iterative refinement\nfor text-to-speech synthesis. arXiv preprint arXiv:2106.09660 (2021).\n[53] Shu-Ching Chen. 2022. Multimedia research toward the Metaverse. IEEE MultiMedia 29, 1 (2022), 125\u2013127.\n[54] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A simple framework for contrastive learning of visual representations.\nIn ICML.\n[55] Xinlei Chen and Kaiming He. 2021. Exploring simple siamese representation learning. In CVPR.\n[56] Xinpeng Chen, Lin Ma, Wenhao Jiang, Jian Yao, and Wei Liu. 2018. Regularizing rnns for caption generation by reconstructing the past with the\npresent. In Proceedings of the IEEE Conference on computer vision and pattern recognition. 7995\u20138003.\n[57] Zehua Chen, Xu Tan, Ke Wang, Shifeng Pan, Danilo Mandic, Lei He, and Sheng Zhao. 2022. Infergrad: Improving Diffusion Models for Vocoder by\nConsidering Inference in Training. In ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE,\n8432\u20138436.\n[58] Yong Cheng. 2019. Joint training for pivot-based neural machine translation. In Joint training for neural machine translation. Springer, 41\u201354.\n[59] Zezhou Cheng, Qingxiong Yang, and Bin Sheng. 2015. Deep colorization. In Proceedings of the IEEE international conference on computer vision.\n415\u2013423.\n[60] Anton Cherepkov, Andrey Voynov, and Artem Babenko. 2021. Navigating the gan parameter space for semantic image editing. In Proceedings of\nthe IEEE/CVF conference on computer vision and pattern recognition. 3671\u20133680.\n[61] Chung-Cheng Chiu, Tara N Sainath, Yonghui Wu, Rohit Prabhavalkar, Patrick Nguyen, Zhifeng Chen, Anjuli Kannan, Ron J Weiss, Kanishka Rao,\nEkaterina Gonina, et al. 2018. State-of-the-art speech recognition with sequence-to-sequence models. In 2018 IEEE international conference on\nacoustics, speech and signal processing (ICASSP). IEEE, 4774\u20134778.\n[62] Kyunghyun Cho, Bart Van Merri\u00ebnboer, Dzmitry Bahdanau, and Yoshua Bengio. 2014. On the properties of neural machine translation: Encoder-\ndecoder approaches. arXiv preprint arXiv:1409.1259 (2014).\n[63] Christopher B Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, and Silvio Savarese. 2016. 3d-r2n2: A unified approach for single and multi-view 3d\nobject reconstruction. In European conference on computer vision. Springer, 628\u2013644.\n[64] Chieh-Yu Chung and Szu-Hao Huang. 2022. Interactively transforming Chinese ink paintings into realistic images using a border enhance\ngenerative adversarial network. Multimedia Tools and Applications (2022), 1\u201334.\n[65] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on\nsequence modeling. arXiv preprint arXiv:1412.3555 (2014).\n[66] Joon Son Chung, Amir Jamaludin, and Andrew Zisserman. 2017. You said that? arXiv preprint arXiv:1705.02966 (2017).\n[67] Aidan Clark, Jeff Donahue, and Karen Simonyan. 2019. Adversarial video generation on complex datasets. arXiv preprint arXiv:1907.06571 (2019).\n[68] Aidan Clark, Jeff Donahue, and Karen Simonyan. 2019. Efficient video generation on complex datasets. (2019).\n[69] Ronan Collobert, Christian Puhrsch, and Gabriel Synnaeve. 2016. Wav2letter: an end-to-end convnet-based speech recognition system. arXiv\npreprint arXiv:1609.03193 (2016).\n[70] @ColourlabAI. 2023. Powering those \u2018I made that\u2019 moments. https://colourlab.ai/ (2023).\n[71] Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mohamed, and Michael Auli. 2020. Unsupervised cross-lingual representation\nlearning for speech recognition. arXiv preprint arXiv:2006.13979 (2020).\n[72] Guillaume Couairon, Jakob Verbeek, Holger Schwenk, and Matthieu Cord. 2022. Diffedit: Diffusion-based semantic image editing with mask\nguidance. arXiv preprint arXiv:2210.11427 (2022).\n[73] Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, and Mubarak Shah. 2022. Diffusion models in vision: A survey. arXiv preprint\narXiv:2209.04747 (2022).\n[74] Daniel Cudeiro, Timo Bolkart, Cassidy Laidlaw, Anurag Ranjan, and Michael J Black. 2019. Capture, learning, and synthesis of 3D speaking styles.\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 10101\u201310111.\n[75] George E Dahl, Dong Yu, Li Deng, and Alex Acero. 2011. Context-dependent pre-trained deep neural networks for large-vocabulary speech\nrecognition. IEEE Transactions on audio, speech, and language processing 20, 1 (2011), 30\u201342.\n[76] Hanjun Dai, Azade Nazi, Yujia Li, Bo Dai, and Dale Schuurmans. 2020. Scalable deep generative modeling for sparse graphs. In International\nConference on Machine Learning. PMLR, 2302\u20132312.\n[77] Justas Dauparas, Ivan Anishchenko, Nathaniel Bennett, Hua Bai, Robert J Ragotte, Lukas F Milles, Basile IM Wicky, Alexis Courbet, Rob J de Haas,\nNeville Bethel, et al. 2022. Robust deep learning\u2013based protein sequence design using ProteinMPNN. Science 378, 6615 (2022), 49\u201356.\n[78] Marc Davis. 1994. Media streams: representing video for retrieval and repurposing. In Proceedings of the second ACM international conference on\nMultimedia. 478\u2013479.\n[79] Marcelo Zerwes Dawn Gilmore, Anitra Nottingham. 2023. ChatGPT and learning design: what online content creation opportunities does it offer?\nhttps://www.csmonitor.com/Technology/2023/0217/Tremendous-potential-Why-some-disability-advocates-laud-ChatGPT (2023).\n[80] Nicola De Cao and Thomas Kipf. 2018. MolGAN: An implicit generative model for small molecular graphs. arXiv preprint arXiv:1805.11973 (2018).\n[81] Paul DelSignore. 2022. AI Art Wins Competition And Sparks Controversy. https://medium.com/mlearning-ai/ai-art-wins-fine-arts-competition-and-\nsparks-controversy-882f9b4df98c (2022).\n[82] Rick DeMott. 2006. Mova Contour Moves \u201cMotion Capture To Reality Capture\u201d. https://www.awn.com/news/mova-contour-moves-motion-capture-\nreality-capture (2006).\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n41\n[83] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. ImageNet: A large-scale hierarchical image database. In CVPR.\n[84] Shasha Deng, Chee-Wee Tan, Weijun Wang, and Yu Pan. 2019. Smart generation system of personalized advertising copy and its application to\nadvertising practice and research. Journal of Advertising 48, 4 (2019), 356\u2013365.\n[85] Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen, Sophie Rosset, Eneko Agirre, and Mark Cieliebak. 2021. Survey on evaluation\nmethods for dialogue systems. Artificial Intelligence Review 54, 1 (2021), 755\u2013810.\n[86] @descript. 2022. There\u2019s a new way to make video and podcasts. A good way. https://www.descript.com/ (2022).\n[87] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language\nunderstanding. arXiv preprint arXiv:1810.04805 (2018).\n[88] Ming Ding, Zhuoyi Yang, Wenyi Hong, Wendi Zheng, Chang Zhou, Da Yin, Junyang Lin, Xu Zou, Zhou Shao, Hongxia Yang, et al. 2021. Cogview:\nMastering text-to-image generation via transformers. Advances in Neural Information Processing Systems 34 (2021), 19822\u201319835.\n[89] Ming Ding, Wendi Zheng, Wenyi Hong, and Jie Tang. 2022. CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers.\narXiv preprint arXiv:2204.14217 (2022).\n[90] Laurent Dinh, David Krueger, and Yoshua Bengio. 2015. Nice: Non-linear independent components estimation. ICLR 2015 Workshop Track (2015).\n[91] Thomas Dohmke. 2022. GitHub Copilot is generally available to all developers. https://github.blog/2022-06-21-github-copilot-is-generally-available-\nto-all-developers/ (2022).\n[92] Jeffrey Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, and Trevor Darrell. 2015.\nLong-term recurrent convolutional networks for visual recognition and description. In Proceedings of the IEEE conference on computer vision and\npattern recognition. 2625\u20132634.\n[93] Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang. 2014. Learning a deep convolutional network for image super-resolution. In\nEuropean conference on computer vision. Springer, 184\u2013199.\n[94] Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang. 2015. Image super-resolution using deep convolutional networks. IEEE transactions\non pattern analysis and machine intelligence 38, 2 (2015), 295\u2013307.\n[95] Hao-Wen Dong, Wen-Yi Hsiao, Li-Chia Yang, and Yi-Hsuan Yang. 2018. Musegan: Multi-track sequential generative adversarial networks for\nsymbolic music generation and accompaniment. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 32.\n[96] Gianfranco Doretto, Alessandro Chiuso, Ying Nian Wu, and Stefano Soatto. 2003. Dynamic textures. International Journal of Computer Vision 51, 2\n(2003), 91\u2013109.\n[97] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias\nMinderer, Georg Heigold, Sylvain Gelly, et al. 2020. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint\narXiv:2010.11929 (2020).\n[98] Eric Drott. 2021. Copyright, compensation, and commons in the music AI industry. Creative Industries Journal 14, 2 (2021), 190\u2013207.\n[99] Henry Elder, Alexander O\u2019Connor, and Jennifer Foster. 2020. How to make neural natural language generation as reliable as templates in\ntask-oriented dialogue. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2877\u20132888.\n[100] Ariel Ephrat, Tavi Halperin, and Shmuel Peleg. 2017. Improved speech reconstruction from silent video. In Proceedings of the IEEE International\nConference on Computer Vision Workshops. 455\u2013462.\n[101] Ariel Ephrat and Shmuel Peleg. 2017. Vid2speech: speech reconstruction from silent video. In 2017 IEEE International Conference on Acoustics,\nSpeech and Signal Processing (ICASSP). IEEE, 5095\u20135099.\n[102] Yuchen Fan, Yao Qian, Feng-Long Xie, and Frank K Soong. 2014. TTS synthesis with bidirectional LSTM based recurrent neural networks. In\nFifteenth annual conference of the international speech communication association.\n[103] Jinsheng Fang, Hanjiang Lin, Xinyu Chen, and Kun Zeng. 2022. A Hybrid Network of CNN and Transformer for Lightweight Image Super-Resolution.\nIn Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 1103\u20131112.\n[104] Jean Louis K E Fendji, Diane CM Tala, Blaise O Yenke, and Marcellin Atemkeng. 2022. Automatic speech recognition using limited vocabulary: A\nsurvey. Applied Artificial Intelligence 36, 1 (2022), 2095039.\n[105] Shaoxiong Feng, Xuancheng Ren, Hongshen Chen, Bin Sun, Kan Li, and Xu Sun. 2020. Regularizing dialogue generation by imitating implicit\nscenarios. arXiv preprint arXiv:2010.01893 (2020).\n[106] Souheil Fenghour, Daqing Chen, Kun Guo, Bo Li, and Perry Xiao. 2021. Deep learning-based automated lip-reading: A survey. IEEE Access (2021).\n[107] Feyyaz F\u0131rat. 2019. Robot journalism. The International Encyclopedia of Journalism Studies (2019), 1\u20135.\n[108] Mikel L Forcada, Mireia Ginest\u00ed-Rosell, Jacob Nordfalk, Jim O\u2019Regan, Sergio Ortiz-Rojas, Juan Antonio P\u00e9rez-Ortiz, Felipe S\u00e1nchez-Mart\u00ednez, Gema\nRam\u00edrez-S\u00e1nchez, and Francis M Tyers. 2011. Apertium: a free/open-source platform for rule-based machine translation. Machine translation 25, 2\n(2011), 127\u2013144.\n[109] Danny Francis and Benoit Huet. 2021. Image and Video Captioning Using Deep Architectures. Multi-faceted Deep Learning: Models and Data\n(2021), 151\u2013174.\n[110] Emma Frid, Celso Gomes, and Zeyu Jin. 2020. Music creation by example. In Proceedings of the 2020 CHI conference on human factors in computing\nsystems. 1\u201313.\n[111] Ohad Fried, Ayush Tewari, Michael Zollh\u00f6fer, Adam Finkelstein, Eli Shechtman, Dan B Goldman, Kyle Genova, Zeyu Jin, Christian Theobalt, and\nManeesh Agrawala. 2019. Text-based editing of talking-head video. ACM Transactions on Graphics (TOG) 38, 4 (2019), 1\u201314.\nManuscript submitted to ACM\n42\nZhang et al.\n[112] Rao Fu, Xiao Zhan, Yiwen Chen, Daniel Ritchie, and Srinath Sridhar. 2022. Shapecrafter: A recursive text-conditioned 3d shape generation model.\narXiv preprint arXiv:2207.09446 (2022).\n[113] Yocat Games. 2023. Traveler-The AI Story. https://skidrowcracked.com/traveler-the-ai-story/ (2023).\n[114] Zhe Gan, Ricardo Henao, David Carlson, and Lawrence Carin. 2015. Learning deep sigmoid belief networks with data augmentation. In Artificial\nIntelligence and Statistics. PMLR, 268\u2013276.\n[115] Zhe Gan, Linjie Li, Chunyuan Li, Lijuan Wang, Zicheng Liu, Jianfeng Gao, et al. 2022. Vision-language pre-training: Basics, recent advances, and\nfuture trends. Foundations and Trends\u00ae in Computer Graphics and Vision 14, 3\u20134 (2022), 163\u2013352.\n[116] Ruiqi Gao, Yang Lu, Junpei Zhou, Song-Chun Zhu, and Ying Nian Wu. 2018. Learning generative convnets via multi-grid modeling and sampling.\n9155\u20139164.\n[117] Xiang Gao, Yizhe Zhang, Michel Galley, Chris Brockett, and Bill Dolan. 2020. Dialogue response ranking training with large-scale human feedback\ndata. arXiv preprint arXiv:2009.06978 (2020).\n[118] Leon A Gatys, Alexander S Ecker, and Matthias Bethge. 2015. A neural algorithm of artistic style. arXiv preprint arXiv:1508.06576 (2015).\n[119] Leon A Gatys, Alexander S Ecker, and Matthias Bethge. 2016. Image style transfer using convolutional neural networks. In CVPR.\n[120] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N Dauphin. 2017. Convolutional sequence to sequence learning. In International\nconference on machine learning. PMLR, 1243\u20131252.\n[121] Spyros Gidaris, Praveer Singh, and Nikos Komodakis. 2018. Unsupervised representation learning by predicting image rotations. ICLR (2018).\n[122] Vladislav Golyanik, Soshi Shimada, Kiran Varanasi, and Didier Stricker. 2018. Hdm-net: Monocular non-rigid 3d reconstruction with learned\ndeformation model. In International conference on virtual reality and augmented reality. Springer, 51\u201372.\n[123] RC Gonzalez. 2006. Woods. RE,(2002)\u201cDigital Image Processing\u201d.\n[124] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative\nadversarial nets. In NeurIPS.\n[125] Andrew S Gordon and Eric A Domeshek. 1995. Conceptual indexing for video retrieval. In Working Notes of IJCAI Workshop on Intelligent\nMultimedia Information Retrieval, Montreal. 23\u201338.\n[126] Alex Graves. 2013. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850 (2013).\n[127] Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speech recognition with deep recurrent neural networks. In 2013 IEEE\ninternational conference on acoustics, speech and signal processing. Ieee, 6645\u20136649.\n[128] Ulf Grenander and Michael I Miller. 1994. Representations of knowledge in complex systems. Journal of the Royal Statistical Society: Series B\n(Methodological) 56, 4 (1994), 549\u2013581.\n[129] Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires,\nZhaohan Guo, Mohammad Gheshlaghi Azar, et al. 2020. Bootstrap your own latent-a new approach to self-supervised learning. Advances in Neural\nInformation Processing Systems (2020).\n[130] Barbara Gruber. 2022. Facts, Fakes and Figures: How AI is Influencing Journalism. https://www.goethe.de/prj/k40/en/lan/aij.html (2022).\n[131] Shanyan Guan, Ying Tai, Bingbing Ni, Feida Zhu, Feiyue Huang, and Xiaokang Yang. 2020. Collaborative learning for faster stylegan embedding.\narXiv preprint arXiv:2007.01758 (2020).\n[132] Longteng Guo, Jing Liu, Xinxin Zhu, Peng Yao, Shichen Lu, and Hanqing Lu. 2020. Normalized and geometry-aware self-attention network for\nimage captioning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 10327\u201310336.\n[133] Shunan Guo, Zhuochen Jin, Fuling Sun, Jingwen Li, Zhaorui Li, Yang Shi, and Nan Cao. 2021. Vinci: an intelligent graphic design system for\ngenerating advertising posters. In Proceedings of the 2021 CHI conference on human factors in computing systems. 1\u201317.\n[134] Xiujing Guo. 2021. Towards automated software testing with generative adversarial networks. In 2021 51st Annual IEEE/IFIP International Conference\non Dependable Systems and Networks-Supplemental Volume (DSN-S). IEEE, 21\u201322.\n[135] Xiujing Guo, Hiroyuki Okamura, and Tadashi Dohi. 2022. Automated Software Test Data Generation With Generative Adversarial Networks. IEEE\nAccess 10 (2022), 20690\u201320700.\n[136] Tanmay Gupta, Dustin Schwenk, Ali Farhadi, Derek Hoiem, and Aniruddha Kembhavi. 2018. Imagine this! scripts to compositions to videos. In\nProceedings of the European Conference on Computer Vision (ECCV). 598\u2013613.\n[137] Michael Gutmann and Aapo Hyv\u00e4rinen. 2010. Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In\nAISTATS.\n[138] Kilian Konstantin Haefeli, Karolis Martinkus, Nathana\u00ebl Perraudin, and Roger Wattenhofer. 2022. Diffusion Models for Graphs Benefit From\nDiscrete State Spaces. arXiv preprint arXiv:2210.01549 (2022).\n[139] Donghoon Ham, Jeong-Gwan Lee, Youngsoo Jang, and Kee-Eung Kim. 2020. End-to-end neural pipeline for goal-oriented dialogue systems using\nGPT-2. In Proceedings of the 58th annual meeting of the association for computational linguistics. 583\u2013592.\n[140] Rana Hanocka, Amir Hertz, Noa Fish, Raja Giryes, Shachar Fleishman, and Daniel Cohen-Or. 2019. Meshcnn: a network with an edge. ACM\nTransactions on Graphics (TOG) 38, 4 (2019), 1\u201312.\n[141] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. 2022. Masked autoencoders are scalable vision learners. In\nCVPR.\n[142] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. 2020. Momentum contrast for unsupervised visual representation learning. In\nCVPR.\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n43\n[143] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In CVPR.\n[144] Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip Torr, Song Bai, and Xiaojuan Qi. 2022. Is synthetic data from generative\nmodels ready for image recognition? arXiv preprint arXiv:2210.07574 (2022).\n[145] Wanwei He, Min Yang, Rui Yan, Chengming Li, Ying Shen, and Ruifeng Xu. 2020. Amalgamating knowledge from two teachers for task-oriented\ndialogue system with adversarial training. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP).\n3498\u20133507.\n[146] Zhenliang He, Wangmeng Zuo, Meina Kan, Shiguang Shan, and Xilin Chen. 2019. Attgan: Facial attribute editing by only changing what you want.\nIEEE transactions on image processing 28, 11 (2019), 5464\u20135478.\n[147] Brian Heater. 2022. Amper is providing a plug-and-play-solution to digitize manufacturing. https://techcrunch.com/2022/04/22/amper-is-providing-a-\nplug-and-play-solution-to-digitize-manufacturing/ (2022).\n[148] Matthew Henderson, Ivan Vuli\u0107, Daniela Gerz, I\u00f1igo Casanueva, Pawe\u0142 Budzianowski, Sam Coope, Georgios Spithourakis, Tsung-Hsien Wen,\nNikola Mrk\u0161i\u0107, and Pei-Hao Su. 2019. Training neural response selection for task-oriented dialogue systems. arXiv preprint arXiv:1906.01543 (2019).\n[149] Simao Herdade, Armin Kappeler, Kofi Boakye, and Joao Soares. 2019. Image captioning: Transforming objects into words. Advances in neural\ninformation processing systems 32 (2019).\n[150] Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or. 2022. Prompt-to-prompt image editing with cross\nattention control. arXiv preprint arXiv:2208.01626 (2022).\n[151] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. 2017. Gans trained by a two time-scale update rule\nconverge to a local nash equilibrium. Advances in neural information processing systems 30 (2017).\n[152] Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen,\nTara N Sainath, et al. 2012. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE\nSignal processing magazine 29, 6 (2012), 82\u201397.\n[153] Geoffrey E Hinton. 2002. Training products of experts by minimizing contrastive divergence. Neural computation 14, 8 (2002), 1771\u20131800.\n[154] Geoffrey E Hinton and Richard Zemel. 1993. Autoencoders, minimum description length and Helmholtz free energy. NeurIPS (1993).\n[155] Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey Gritsenko, Diederik P Kingma, Ben Poole, Mohammad Norouzi,\nDavid J Fleet, et al. 2022. Imagen video: High definition video generation with diffusion models. arXiv preprint arXiv:2210.02303 (2022).\n[156] Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising diffusion probabilistic models. Advances in Neural Information Processing Systems 33\n(2020), 6840\u20136851.\n[157] Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David J Fleet. 2022. Video diffusion models. arXiv preprint\narXiv:2204.03458 (2022).\n[158] Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735\u20131780.\n[159] Margaret Holland. 2016. How YouTube developed into a successful platform for user-generated content. Elon journal of undergraduate research in\ncommunications 7, 1 (2016).\n[160] Wenyi Hong, Ming Ding, Wendi Zheng, Xinghan Liu, and Jie Tang. 2022. CogVideo: Large-scale Pretraining for Text-to-Video Generation via\nTransformers. arXiv preprint arXiv:2205.15868 (2022).\n[161] Takaaki Hori, Jaejin Cho, and Shinji Watanabe. 2018. End-to-end speech recognition with word-based RNN language models. In 2018 IEEE Spoken\nLanguage Technology Workshop (SLT). IEEE, 389\u2013396.\n[162] Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and Richard Socher. 2020. A simple language model for task-oriented dialogue.\nAdvances in Neural Information Processing Systems 33 (2020), 20179\u201320191.\n[163] Stephanie Houde, Vera Liao, Jacquelyn Martino, Michael Muller, David Piorkowski, John Richards, Justin Weisz, and Yunfeng Zhang. 2020. Business\n(mis) use cases of generative ai. arXiv preprint arXiv:2003.07679 (2020).\n[164] Zhen-jiang Hu. 2022. Analysis of the Impact of Artificial Intelligence Technology-Assisted Environmental Protection on the Integrity of Chinese\nPainting. Journal of Environmental and Public Health 2022 (2022).\n[165] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q. Weinberger. 2017. Densely connected convolutional networks. In CVPR.\n[166] Han Huang, Leilei Sun, Bowen Du, Yanjie Fu, and Weifeng Lv. 2022. GraphGDP: Generative Diffusion Processes for Permutation Invariant Graph\nGeneration. arXiv preprint arXiv:2212.01842 (2022).\n[167] Po-Han Huang, Kevin Matzen, Johannes Kopf, Narendra Ahuja, and Jia-Bin Huang. 2018. Deepmvs: Learning multi-view stereopsis. In Proceedings\nof the IEEE Conference on Computer Vision and Pattern Recognition. 2821\u20132830.\n[168] Rongjie Huang, Zhou Zhao, Huadai Liu, Jinglin Liu, Chenye Cui, and Yi Ren. 2022. ProDiff: Progressive Fast Diffusion Model For High-Quality\nText-to-Speech. arXiv preprint arXiv:2207.06389 (2022).\n[169] Xinting Huang, Jianzhong Qi, Yu Sun, and Rui Zhang. 2020. Semi-supervised dialogue policy learning via stochastic reward estimation. arXiv\npreprint arXiv:2005.04379 (2020).\n[170] Yu-Siang Huang and Yi-Hsuan Yang. 2020. Pop music transformer: Beat-based modeling and generation of expressive pop piano compositions. In\nProceedings of the 28th ACM International Conference on Multimedia. 1180\u20131188.\n[171] William John Hutchins. 1986. Machine translation: past, present, future. Ellis Horwood Chichester.\n[172] Matthew Hutson. 2017. How Google is making music with arti4cial intelligence. (2017).\n[173] Nitin Indurkhya and Fred J Damerau. 2010. Handbook of natural language processing. Chapman and Hall/CRC.\nManuscript submitted to ACM\n44\nZhang et al.\n[174] Prathamesh\nIngle.\n2023.\nTop\nArtificial\nIntelligence\n(AI)\nTools\nThat\nCan\nGenerate\nCode\nTo\nHelp\nProgrammers.\nhttps://www.marktechpost.com/2023/01/01/top-artificial-intelligence-ai-tools-that-can-generate-code-to-help-programmers/ (2023).\n[175] Tansin Jahan, Yanran Guan, and Oliver van Kaick. 2021. Semantics-Guided Latent Space Exploration for Shape Generation. In Computer Graphics\nForum, Vol. 40. Wiley Online Library, 115\u2013126.\n[176] Benjamin Jahi\u0107, Nicolas Guelfi, and Benoit Ries. 2019. Software engineering for dataset augmentation using generative adversarial networks. In\n2019 IEEE 10th International Conference on Software Engineering and Service Science (ICSESS). IEEE, 59\u201366.\n[177] Viren Jain and Sebastian Seung. 2008. Natural image denoising with convolutional networks. Advances in neural information processing systems 21\n(2008).\n[178] Amir Jamaludin, Joon Son Chung, and Andrew Zisserman. 2019. You said that?: Synthesising talking faces from audio. International Journal of\nComputer Vision 127 (2019), 1767\u20131779.\n[179] Shulei Ji, Jing Luo, and Xinyu Yang. 2020. A comprehensive survey on deep music generation: Multi-level representations, algorithms, evaluations,\nand future directions. arXiv preprint arXiv:2011.06801 (2020).\n[180] Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig. 2021. Scaling up\nvisual and vision-language representation learning with noisy text supervision. In ICML.\n[181] Qi Jia, Yizhu Liu, Siyu Ren, Kenny Q Zhu, and Haifeng Tang. 2020. Multi-turn response selection using dialogue dependency relations. arXiv\npreprint arXiv:2010.01502 (2020).\n[182] Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and Zhaopeng Tu. 2023. Is ChatGPT a good translator? A preliminary study. arXiv\npreprint arXiv:2301.08745 (2023).\n[183] Wengong Jin, Kevin Yang, Regina Barzilay, and Tommi Jaakkola. 2018. Learning multimodal graph-to-graph translation for molecular optimization.\narXiv preprint arXiv:1812.01070 (2018).\n[184] Li Jing, Caglar Gulcehre, John Peurifoy, Yichen Shen, Max Tegmark, Marin Soljacic, and Yoshua Bengio. 2019. Gated orthogonal recurrent units:\nOn learning to forget. Neural computation 31, 4 (2019), 765\u2013783.\n[185] Yongcheng Jing, Yezhou Yang, Zunlei Feng, Jingwen Ye, Yizhou Yu, and Mingli Song. 2019. Neural style transfer: A review. IEEE transactions on\nvisualization and computer graphics 26, 11 (2019), 3365\u20133385.\n[186] Jaehyeong Jo, Seul Lee, and Sung Ju Hwang. 2022. Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations.\narXiv preprint arXiv:2202.02514 (2022).\n[187] Melvin Johnson, Mike Schuster, Quoc V Le, Maxim Krikun, Yonghui Wu, Zhifeng Chen, Nikhil Thorat, Fernanda Vi\u00e9gas, Martin Wattenberg, Greg\nCorrado, et al. 2017. Google\u2019s multilingual neural machine translation system: Enabling zero-shot translation. Transactions of the Association for\nComputational Linguistics 5 (2017), 339\u2013351.\n[188] Biing Hwang Juang and Laurence R Rabiner. 1991. Hidden Markov models for speech recognition. Technometrics 33, 3 (1991), 251\u2013272.\n[189] Romain Juillet. 2021. How AI Is Transforming the Music Industry. https://www.bocasay.com/ai-transforming-music-industry/ (2021).\n[190] \u0141ukasz Kaiser and Samy Bengio. 2016. Can active memory replace attention? Advances in Neural Information Processing Systems 29 (2016).\n[191] Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent continuous translation models. In Proceedings of the 2013 conference on empirical methods in\nnatural language processing. 1700\u20131709.\n[192] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Koray Kavukcuoglu. 2016. Neural machine translation\nin linear time. arXiv preprint arXiv:1610.10099 (2016).\n[193] Shitanshu kapadia. 2023. 7 AI Marketing Tools for Business. https://www.entrepreneur.com/science-technology/how-will-chatgpt-change-education-\nand-teaching/445018 (2023).\n[194] S Karpagavalli and Edy Chandra. 2016. A review on automatic speech recognition architecture and approaches. International Journal of Signal\nProcessing, Image Processing and Pattern Recognition 9, 4 (2016), 393\u2013404.\n[195] Andrej Karpathy and Li Fei-Fei. 2015. Deep visual-semantic alignments for generating image descriptions. In Proceedings of the IEEE conference on\ncomputer vision and pattern recognition. 3128\u20133137.\n[196] Tero Karras, Timo Aila, Samuli Laine, Antti Herva, and Jaakko Lehtinen. 2017. Audio-driven facial animation by joint end-to-end learning of pose\nand emotion. ACM Transactions on Graphics (TOG) 36, 4 (2017), 1\u201312.\n[197] Tero Karras, Samuli Laine, and Timo Aila. 2019. A Style-Based Generator Architecture for Generative Adversarial Networks. 4401\u20134410.\n[198] Hideki Kawahara. 2006. STRAIGHT, exploitation of the other aspect of VOCODER: Perceptually isomorphic decomposition of speech sounds.\nAcoustical science and technology 27, 6 (2006), 349\u2013353.\n[199] Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. 2022. Denoising diffusion restoration models. arXiv preprint arXiv:2201.11793\n(2022).\n[200] Lei Ke, Wenjie Pei, Ruiyu Li, Xiaoyong Shen, and Yu-Wing Tai. 2019. Reflective decoding network for image captioning. In Proceedings of the\nIEEE/CVF international conference on computer vision. 8888\u20138897.\n[201] Regina Kelder and Mary Parker. 2021. Why Does Drug Development Take So Long? https://www.criver.com/eureka/why-does-drug-development-\ntake-so-long (2021).\n[202] Tilly Kenyon. 2022. Voicemod: Allowing creators to find their voice. https://technologymagazine.com/ai-and-machine-learning/voicemod-allowing-\ncreators-to-find-their-voice (2022).\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n45\n[203] Angella J Kim and Kim KP Johnson. 2016. Power of consumers using social media: Examining the influences of brand-related user-generated\ncontent on Facebook. Computers in human behavior 58 (2016), 98\u2013108.\n[204] Daewon Kim and Seongcheol Kim. 2017. Newspaper companies\u2019 determinants in adopting robot journalism. Technological Forecasting and Social\nChange 117 (2017), 184\u2013195.\n[205] Gwanghyun Kim and Se Young Chun. 2022. DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative\nModel. arXiv preprint arXiv:2211.16374 (2022).\n[206] Gwanghyun Kim and Jong Chul Ye. 2021. Diffusionclip: Text-guided image manipulation using diffusion models. (2021).\n[207] Sijin Kim, Namhyuk Ahn, and Kyung-Ah Sohn. 2020. Restoring spatially-heterogeneous distortions using mixture of experts network. In Proceedings\nof the Asian Conference on Computer Vision.\n[208] Sungdong Kim, Sohee Yang, Gyuwan Kim, and Sang-Woo Lee. 2019. Efficient dialogue state tracking by selectively overwriting memory. arXiv\npreprint arXiv:1911.03906 (2019).\n[209] Taeksoo Kim, Byoungjip Kim, Moonsu Cha, and Jiwon Kim. 2017. Unsupervised visual attribute transfer with reconfigurable generative adversarial\nnetworks. arXiv preprint arXiv:1707.09798 (2017).\n[210] Diederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).\n[211] Wei-Jen Ko, Avik Ray, Yilin Shen, and Hongxia Jin. 2020. Generating dialogue responses from a semantic latent space. arXiv preprint arXiv:2010.01658\n(2020).\n[212] Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine\nMoran, Richard Zens, et al. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th annual meeting of the\nassociation for computational linguistics companion volume proceedings of the demo and poster sessions. 177\u2013180.\n[213] Philipp Koehn, Franz J Och, and Daniel Marcu. 2003. Statistical phrase-based translation. Technical Report. University of Southern California\nMarina Del Rey Information Sciences Inst.\n[214] Marijn Koolen, Jaap Kamps, Gabriella Kazai, et al. 2013. Social Book Search: The Impact of Professional and User-Generated Content on Book\nSuggestions.. In DIR. 38\u201339.\n[215] Prajwal KR, Rudrabha Mukhopadhyay, Jerin Philip, Abhishek Jha, Vinay Namboodiri, and CV Jawahar. 2019. Towards automatic face-to-face\ntranslation. In Proceedings of the 27th ACM international conference on multimedia. 1428\u20131436.\n[216] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. ImageNet classification with deep convolutional neural networks. In NeurIPS.\n[217] BJ Kr\u00f6ger. 1992. Minimal rules for articulatory speech synthesis. Proceedings of EUSIPCO92 (1) (1992), 331\u2013334.\n[218] Manoj Kumar, Dirk Weissenborn, and Nal Kalchbrenner. 2021. Colorization transformer. arXiv preprint arXiv:2102.04432 (2021).\n[219] Rithesh Kumar, Jose Sotelo, Kundan Kumar, Alexandre de Br\u00e9bisson, and Yoshua Bengio. 2017. Obamanet: Photo-realistic lip-sync from text. arXiv\npreprint arXiv:1801.01442 (2017).\n[220] Max WY Lam, Jun Wang, Dan Su, and Dong Yu. 2022. BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis.\narXiv preprint arXiv:2203.13508 (2022).\n[221] Hugo Larochelle and Iain Murray. 2011. The neural autoregressive distribution estimator. In Proceedings of the fourteenth international conference\non artificial intelligence and statistics. JMLR Workshop and Conference Proceedings, 29\u201337.\n[222] Noam Lemelshtrich Latar. 2018. Robot journalism: Can human journalism survive? World Scientific.\n[223] Christian Ledig, Lucas Theis, Ferenc Husz\u00e1r, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes\nTotz, Zehan Wang, et al. 2017. Photo-realistic single image super-resolution using a generative adversarial network. In Proceedings of the IEEE\nconference on computer vision and pattern recognition. 4681\u20134690.\n[224] Jure Leskovec, Deepayan Chakrabarti, Jon Kleinberg, Christos Faloutsos, and Zoubin Ghahramani. 2010. Kronecker graphs: an approach to\nmodeling networks. Journal of Machine Learning Research 11, 2 (2010).\n[225] Stephen E Levinson, Lawrence R Rabiner, and M Mohan Sondhi. 1983. An introduction to the application of the theory of probabilistic functions of\na Markov process to automatic speech recognition. Bell System Technical Journal 62, 4 (1983), 1035\u20131074.\n[226] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart:\nDenoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461\n(2019).\n[227] Colin Lewis-Beck and Michael Lewis-Beck. 2015. Applied regression: An introduction. Vol. 22. Sage publications.\n[228] Boyun Li, Xiao Liu, Peng Hu, Zhongqin Wu, Jiancheng Lv, and Xi Peng. 2022. All-in-one image restoration for unknown corruption. In Proceedings\nof the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 17452\u201317462.\n[229] Bowen Li, Xiaojuan Qi, Thomas Lukasiewicz, and Philip Torr. 2019. Controllable text-to-image generation. Advances in Neural Information\nProcessing Systems 32 (2019).\n[230] Gang Li, Heliang Zheng, Chaoyue Wang, Chang Li, Changwen Zheng, and Dacheng Tao. 2022. 3DDesigner: Towards Photorealistic 3D Object\nGeneration and Editing with Text-guided Diffusion Models. arXiv preprint arXiv:2211.14108 (2022).\n[231] Guang Li, Linchao Zhu, Ping Liu, and Yi Yang. 2019. Entangled transformer for image captioning. In Proceedings of the IEEE/CVF international\nconference on computer vision. 8928\u20138937.\n[232] Haoying Li, Yifan Yang, Meng Chang, Huajun Feng, Zhi hai Xu, Qi Li, and Yue ting Chen. 2022. SRDiff: Single Image Super-Resolution with\nDiffusion Probabilistic Models. Neurocomputing 479 (2022), 47\u201359.\nManuscript submitted to ACM\n46\nZhang et al.\n[233] Jason Li, Vitaly Lavrukhin, Boris Ginsburg, Ryan Leary, Oleksii Kuchaiev, Jonathan M Cohen, Huyen Nguyen, and Ravi Teja Gadde. 2019. Jasper:\nAn end-to-end convolutional neural acoustic model. arXiv preprint arXiv:1904.03288 (2019).\n[234] Jinyu Li, Yu Wu, Yashesh Gaur, Chengyi Wang, Rui Zhao, and Shujie Liu. 2020. On the comparison of popular end-to-end models for large scale\nspeech recognition. arXiv preprint arXiv:2005.14327 (2020).\n[235] Mao Li, Jiancheng Lv, Jian Wang, and Yongsheng Sang. 2020. An abstract painting generation method based on deep generative model. Neural\nProcessing Letters 52 (2020), 949\u2013960.\n[236] Mu Li, Wangmeng Zuo, and David Zhang. 2016. Convolutional network for attribute-driven and identity-preserving human face generation. arXiv\npreprint arXiv:1608.06434 (2016).\n[237] Mu Li, Wangmeng Zuo, and David Zhang. 2016. Deep identity-aware transfer of facial attributes. arXiv preprint arXiv:1610.05586 (2016).\n[238] Ruilong Li, Matthew Tancik, and Angjoo Kanazawa. 2022. NerfAcc: A General NeRF Acceleration Toolbox. arXiv preprint arXiv:2210.04847 (2022).\n[239] Tianye Li, Timo Bolkart, Michael J Black, Hao Li, and Javier Romero. 2017. Learning a model of facial shape and expression from 4D scans. ACM\nTrans. Graph. 36, 6 (2017), 194\u20131.\n[240] Wenbo Li, Zhe Lin, Kun Zhou, Lu Qi, Yi Wang, and Jiaya Jia. 2022. MAT: Mask-Aware Transformer for Large Hole Image Inpainting. In Proceedings\nof the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 10758\u201310768.\n[241] Wei Li, Xue Xu, Xinyan Xiao, Jiachen Liu, Hu Yang, Guohao Li, Zhanpeng Wang, Zhifan Feng, Qiaoqiao She, Yajuan Lyu, et al. 2022. UPainting:\nUnified Text-to-Image Diffusion Generation with Cross-modal Guidance. arXiv preprint arXiv:2210.16031 (2022).\n[242] Xin Li, Xin Jin, Jianxin Lin, Sen Liu, Yaojun Wu, Tao Yu, Wei Zhou, and Zhibo Chen. 2020. Learning disentangled feature representation for\nhybrid-distorted image restoration. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part\nXXIX 16. Springer, 313\u2013329.\n[243] Xi Li and Ping Kuang. 2021. 3D-VRVT: 3D Voxel Reconstruction from A Single Image with Vision Transformer. In 2021 International Conference on\nCulture-oriented Science & Technology (ICCST). IEEE, 343\u2013348.\n[244] Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan Wang, Houdong Hu, Li Dong, Furu Wei, et al. 2020. Oscar:\nObject-semantics aligned pre-training for vision-language tasks. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August\n23\u201328, 2020, Proceedings, Part XXX 16. Springer, 121\u2013137.\n[245] Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, and Tatsunori B Hashimoto. 2022. Diffusion-LM Improves Controllable Text\nGeneration. arXiv preprint arXiv:2205.14217 (2022).\n[246] Yitong Li, Martin Min, Dinghan Shen, David Carlson, and Lawrence Carin. 2018. Video generation from text. In Proceedings of the AAAI conference\non artificial intelligence, Vol. 32.\n[247] Jingyun Liang, Jiezhang Cao, Guolei Sun, Kai Zhang, Luc Van Gool, and Radu Timofte. 2021. Swinir: Image restoration using swin transformer. In\nProceedings of the IEEE/CVF International Conference on Computer Vision. 1833\u20131844.\n[248] Jianglin Liang and Ruifang Liu. 2015. Stacked denoising autoencoder and dropout together to prevent overfitting in deep neural network. In 2015\n8th international congress on image and signal processing (CISP). IEEE, 697\u2013701.\n[249] Renjie Liao, Yujia Li, Yang Song, Shenlong Wang, Will Hamilton, David K Duvenaud, Raquel Urtasun, and Richard Zemel. 2019. Efficient graph\ngeneration with graph recurrent attention networks. Advances in neural information processing systems 32 (2019).\n[250] Zibo Lin, Deng Cai, Yan Wang, Xiaojiang Liu, Hai-Tao Zheng, and Shuming Shi. 2020. The world is not binary: Learning to rank with grayscale\ndata for dialogue response selection. arXiv preprint arXiv:2004.02421 (2020).\n[251] Pierre Lison and Serge Bibauw. 2017. Not all dialogues are created equal: Instance weighting for neural conversational models. arXiv preprint\narXiv:1704.08966 (2017).\n[252] Hongyu Liu, Ziyu Wan, Wei Huang, Yibing Song, Xintong Han, and Jing Liao. 2021. Pd-gan: Probabilistic diverse gan for image inpainting. In\nProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 9371\u20139381.\n[253] Ming Liu, Yuxiang Wei, Xiaohe Wu, Wangmeng Zuo, and Lei Zhang. 2022. A Survey on Leveraging Pre-trained Generative Adversarial Networks\nfor Image Editing and Restoration. arXiv preprint arXiv:2207.10309 (2022).\n[254] Qi Liu, Miltiadis Allamanis, Marc Brockschmidt, and Alexander Gaunt. 2018. Constrained graph variational autoencoders for molecule design.\nAdvances in neural information processing systems 31 (2018).\n[255] Shuo Liu, Adria Mallol-Ragolta, Emilia Parada-Cabeleiro, Kun Qian, Xin Jing, Alexander Kathan, Bin Hu, and Bjoern W Schuller. 2022. Audio\nSelf-supervised Learning: A Survey. arXiv preprint arXiv:2203.01205 (2022).\n[256] Wei Liu, Sihan Chen, Longteng Guo, Xinxin Zhu, and Jing Liu. 2021. CPTR: Full transformer network for image captioning. arXiv preprint\narXiv:2101.10804 (2021).\n[257] Xia Liu, Alvin C Burns, and Yingjian Hou. 2017. An investigation of brand-related user-generated content on Twitter. Journal of Advertising 46, 2\n(2017), 236\u2013247.\n[258] Xing Liu, Masanori Suganuma, Xiyang Luo, and Takayuki Okatani. 2019. Restoring images with unknown degradation factors by recurrent use of\na multi-branch network. arXiv preprint arXiv:1907.04508 (2019).\n[259] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019).\n[260] Yue Liu, Xin Wang, Yitian Yuan, and Wenwu Zhu. 2019. Cross-modal dual learning for sentence-to-video generation. In Proceedings of the 27th\nACM International Conference on Multimedia. 1239\u20131247.\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n47\n[261] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. 2021. Swin transformer: Hierarchical vision\ntransformer using shifted windows. ICCV.\n[262] Zhengzhe Liu, Yi Wang, Xiaojuan Qi, and Chi-Wing Fu. 2022. Towards Implicit Text-Guided 3D Shape Generation. In Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition. 17896\u201317906.\n[263] Dengsheng Lu and Qihao Weng. 2007. A survey of image classification methods and techniques for improving classification performance.\nInternational journal of Remote sensing 28, 5 (2007), 823\u2013870.\n[264] Jiasen Lu, Caiming Xiong, Devi Parikh, and Richard Socher. 2017. Knowing when to look: Adaptive attention via a visual sentinel for image\ncaptioning. In Proceedings of the IEEE conference on computer vision and pattern recognition. 375\u2013383.\n[265] Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte, and Luc Van Gool. 2022. Repaint: Inpainting using denoising\ndiffusion probabilistic models. 11461\u201311471.\n[266] Tianze Luo, Zhanfeng Mo, and Sinno Jialin Pan. 2022. Fast Graph Generative Model via Spectral Diffusion. arXiv preprint arXiv:2211.08892 (2022).\n[267] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effective approaches to attention-based neural machine translation. arXiv\npreprint arXiv:1508.04025 (2015).\n[268] Christoph L\u00fcscher, Eugen Beck, Kazuki Irie, Markus Kitza, Wilfried Michel, Albert Zeyer, Ralf Schl\u00fcter, and Hermann Ney. 2019. RWTH ASR\nSystems for LibriSpeech: Hybrid vs Attention\u2013w/o Data Augmentation. arXiv preprint arXiv:1905.03072 (2019).\n[269] Kaushalya Madhawa, Katushiko Ishiguro, Kosuke Nakago, and Motoki Abe. 2019. Graphnvp: An invertible flow model for generating molecular\ngraphs. arXiv preprint arXiv:1905.11600 (2019).\n[270] Mishaim Malik, Muhammad Kamran Malik, Khawar Mehmood, and Imran Makhdoom. 2021. Automatic speech recognition: a survey. Multimedia\nTools and Applications 80, 6 (2021), 9411\u20139457.\n[271] Elman Mansimov, Emilio Parisotto, Jimmy Lei Ba, and Ruslan Salakhutdinov. 2016. Generating images from captions with attention. ICLR (2016).\n[272] Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, and Alan Yuille. 2014. Deep captioning with multimodal recurrent neural networks\n(m-rnn). arXiv preprint arXiv:1412.6632 (2014).\n[273] Francesco Marconi. 2020. Newsmakers: Artificial intelligence and the future of journalism. Columbia University Press.\n[274] Rick Marshall. 2018. Behind the breathtaking visual effects of \u2018Blade Runner 2049\u2019. https://www.digitaltrends.com/movies/blade-runner-2049-visual-\neffects-john-nelson/ (2018).\n[275] Richard Diehl Martinez and John Kaleialoha Kamalu. 2018. Using General Adversarial Networks for Marketing: A Case Study of Airbnb. arXiv\npreprint arXiv:1806.11432 (2018).\n[276] Tanya Marwah, Gaurav Mittal, and Vineeth N Balasubramanian. 2017. Attentive semantic video generation using captions. In Proceedings of the\nIEEE international conference on computer vision. 1426\u20131434.\n[277] Alexandra\nKennedy\nMaya\nAckerman.\n2022.\nAI-Powered\nLyrics\nPlatform,\nLyricStudio,\nSurpasses\n1\nMillion\nSongs.\nprweb.com/releases/2022/7/prweb18785303.htm (2022).\n[278] \u0141ukasz Maziarka, Agnieszka Pocha, Jan Kaczmarczyk, Krzysztof Rataj, Tomasz Danel, and Micha\u0142 Warcho\u0142. 2020. Mol-CycleGAN: a generative\nmodel for molecular optimization. Journal of Cheminformatics 12, 1 (2020), 1\u201318.\n[279] Alex McFarland. 2022. China\u2019s State News Agency Introduces New Artificial Intelligence Anchor. https://www.unite.ai/chinas-state-news-agency-\nintroduces-new-artificial-intelligence-anchor/ (2022).\n[280] Alex McFarland. 2023. 8 Best AI Music Generators. https://www.unite.ai/best-ai-music-generators/ (2023).\n[281] Larry R Medsker and LC Jain. 2001. Recurrent neural networks. Design and Applications 5 (2001), 64\u201367.\n[282] Shikib Mehri, Evgeniia Razumovskaia, Tiancheng Zhao, and Maxine Eskenazi. 2019. Pretraining methods for dialog context representation learning.\narXiv preprint arXiv:1906.00414 (2019).\n[283] Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and Andreas Geiger. 2019. Occupancy networks: Learning 3d reconstruc-\ntion in function space. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 4460\u20134470.\n[284] Meta. 2022. What Is Meta Horizon Worlds? https://www.marktechpost.com/2023/01/01/top-artificial-intelligence-ai-tools-that-can-generate-code-to-\nhelp-programmers/ (2022).\n[285] Tomas Mikolov, Martin Karafi\u00e1t, Lukas Burget, Jan Cernock`y, and Sanjeev Khudanpur. 2010. Recurrent neural network based language model.. In\nInterspeech, Vol. 2. Makuhari, 1045\u20131048.\n[286] Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. 2021. Nerf: Representing scenes as\nneural radiance fields for view synthesis. Commun. ACM 65, 1 (2021), 99\u2013106.\n[287] Diego H Milone and Leandro E Di Persia. 2008. Learning hidden Markov models with hidden Markov trees as observation distributions. Inteligencia\nArtificial. Revista Iberoamericana de Inteligencia Artificial 12, 37 (2008), 7\u201313.\n[288] Andrey Miroshnichenko. 2018. AI to bypass creativity. Will robots replace journalists?(The answer is \u201cyes\u201d). Information 9, 7 (2018), 183.\n[289] Gautam Mittal, Jesse Engel, Curtis Hawthorne, and Ian Simon. 2021. Symbolic music generation with diffusion models. arXiv preprint arXiv:2103.16091\n(2021).\n[290] Gaurav Mittal, Tanya Marwah, and Vineeth N Balasubramanian. 2017. Sync-draw: Automatic video generation using deep recurrent attentive\narchitectures. In Proceedings of the 25th ACM international conference on Multimedia. 1096\u20131104.\n[291] Irina Momot. 2022. Artificial Intelligence in Filmmaking Process: future scenarios. (2022).\nManuscript submitted to ACM\n48\nZhang et al.\n[292] Masanori Morise, Fumiya Yokomori, and Kenji Ozawa. 2016. WORLD: a vocoder-based high-quality speech synthesis system for real-time\napplications. IEICE TRANSACTIONS on Information and Systems 99, 7 (2016), 1877\u20131884.\n[293] Eric Moulines and Francis Charpentier. 1990. Pitch-synchronous waveform processing techniques for text-to-speech synthesis using diphones.\nSpeech communication 9, 5-6 (1990), 453\u2013467.\n[294] Thomas M\u00fcller, Alex Evans, Christoph Schied, and Alexander Keller. 2022. Instant neural graphics primitives with a multiresolution hash encoding.\nACM Transactions on Graphics (ToG) 41, 4 (2022), 1\u201315.\n[295] Frank-Michael Nack. 1996. AUTEUR: The application of video semantics and theme representation for automated film editing. Ph. D. Dissertation.\nCiteseer.\n[296] Tomohiro Nakatani. 2019. Improving transformer-based end-to-end speech recognition with connectionist temporal classification and language\nmodel integration. In Proc. Interspeech.\n[297] Ali Bou Nassif, Ismail Shahin, Imtinan Attili, Mohammad Azzeh, and Khaled Shaalan. 2019. Speech recognition using deep neural networks: A\nsystematic review. IEEE access 7 (2019), 19143\u201319165.\n[298] Kamyar Nazeri, Eric Ng, Tony Joseph, Faisal Z Qureshi, and Mehran Ebrahimi. 2019. Edgeconnect: Generative image inpainting with adversarial\nedge learning. arXiv preprint arXiv:1901.00212 (2019).\n[299] Jinjie Ni, Tom Young, Vlad Pandelea, Fuzhao Xue, and Erik Cambria. 2022. Recent advances in deep learning based dialogue systems: A systematic\nsurvey. Artificial intelligence review (2022), 1\u2013101.\n[300] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. 2022. Glide: Towards\nphotorealistic image generation and editing with text-guided diffusion models. ICML (2022).\n[301] Huansheng Ning, Hang Wang, Yujia Lin, Wenxi Wang, Sahraoui Dhelim, Fadi Farha, Jianguo Ding, and Mahmoud Daneshmand. 2021. A Survey on\nMetaverse: the State-of-the-art, Technologies, Applications, and Challenges. arXiv preprint arXiv:2111.09673 (2021).\n[302] Chenhao Niu, Yang Song, Jiaming Song, Shengjia Zhao, Aditya Grover, and Stefano Ermon. 2020. Permutation invariant graph generation via\nscore-based generative modeling. In AISTATS. PMLR, 4474\u20134484.\n[303] Mehdi Noroozi and Paolo Favaro. 2016. Unsupervised learning of visual representations by solving jigsaw puzzles. In ECCV.\n[304] China\nAcademy\nof\nInformation\nand\nCommunications\nTechnology.\n2022.\nWhite\nPaper\non\nAI-Generated\nContent\n(AIGC).\nhttp://www.caict.ac.cn/english/research/whitepapers/202211/t20221111_411288.html (2022).\n[305] Katsunori Ohnishi, Shohei Yamamoto, Yoshitaka Ushiku, and Tatsuya Harada. 2018. Hierarchical video generation from orthogonal information:\nOptical flow and texture. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 32.\n[306] Joseph Olive. 1977. Rule synthesis of speech from dyadic units. In ICASSP\u201977. IEEE International Conference on Acoustics, Speech, and Signal\nProcessing, Vol. 2. IEEE, 568\u2013570.\n[307] OpenAI. 2023. GPT-4 Technical report. arXiv preprint arXiv:2303.08774 (2023).\n[308] Tim O\u2019reilly. 2009. What is web 2.0. \" O\u2019Reilly Media, Inc.\".\n[309] Will Oremus. 2014. The First News Report on the L.A. Earthquake Was Written by a Robot. https://slate.com/technology/2014/03/quakebot-los-\nangeles-times-robot-journalist-writes-article-on-la-earthquake.html (2014).\n[310] Achraf Oussidi and Azeddine Elhassouny. 2018. Deep generative models: Survey. In 2018 International Conference on Intelligent Systems and\nComputer Vision (ISCV). IEEE, 1\u20138.\n[311] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex\nRay, et al. 2022. Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155 (2022).\n[312] Yawen Ouyang, Moxin Chen, Xinyu Dai, Yinggong Zhao, Shujian Huang, and Jiajun Chen. 2020. Dialogue state tracking with explicit slot\nconnection modeling. In Proceedings of the 58th annual meeting of the association for computational linguistics. 34\u201340.\n[313] Yingwei Pan, Zhaofan Qiu, Ting Yao, Houqiang Li, and Tao Mei. 2017. To create what you tell: Generating videos from captions. In Proceedings of\nthe 25th ACM international conference on Multimedia. 1789\u20131798.\n[314] Tianyu Pang, Kun Xu, Chongxuan Li, Yang Song, Stefano Ermon, and Jun Zhu. 2020. Efficient learning of generative models via finite-difference\nscore matching. Advances in Neural Information Processing Systems 33 (2020), 19175\u201319188.\n[315] Ankur P Parikh, Oscar T\u00e4ckstr\u00f6m, Dipanjan Das, and Jakob Uszkoreit. 2016. A decomposable attention model for natural language inference.\narXiv preprint arXiv:1606.01933 (2016).\n[316] Giorgio Parisi. 1981. Correlation functions and computer simulations. Nuclear Physics B 180, 3 (1981), 378\u2013384.\n[317] A Parkes. 1989. Settings and the setting structure: the description and automated propagation of networks for perusing videodisk image states. In\nProceedings of the 12th annual international ACM SIGIR conference on Research and development in information retrieval. 229\u2013238.\n[318] Alan Philip Parkes. 1988. An artificial intelligence approach to the conceptual description of videodisc images. Lancaster University (United Kingdom).\n[319] Alan P Parkes. 1989. The prototype CLORIS system: Describing, retrieving and discussing videodisc stills and sequences. Information processing &\nmanagement 25, 2 (1989), 171\u2013186.\n[320] Santiago Pascual, Gautam Bhattacharya, Chunghsin Yeh, Jordi Pons, and Joan Serr\u00e0. 2022. Full-band General Audio Synthesis with Score-based\nDiffusion. arXiv preprint arXiv:2210.14661 (2022).\n[321] Santiago Pascual, Mirco Ravanelli, Joan Serra, Antonio Bonafonte, and Yoshua Bengio. 2019. Learning problem-agnostic speech representations\nfrom multiple self-supervised tasks. arXiv preprint arXiv:1904.03416 (2019).\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n49\n[322] Steve Paulussen and Pieter Ugille. 2008. User generated content in the newsroom: Professional and organisational constraints on participatory\njournalism. Westminster papers in communication & culture 5, 2 (2008).\n[323] Baolin Peng, Chenguang Zhu, Chunyuan Li, Xiujun Li, Jinchao Li, Michael Zeng, and Jianfeng Gao. 2020. Few-shot natural language generation\nfor task-oriented dialog. arXiv preprint arXiv:2002.12328 (2020).\n[324] Tammy Pettinato Oltz. 2023. ChatGPT, Professor of Law. Professor of Law (February 4, 2023) (2023).\n[325] Cale Plut and Philippe Pasquier. 2020. Generative music in video games: State of the art, challenges, and prospects. Entertainment Computing 33\n(2020), 100337.\n[326] Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall. 2022. Dreamfusion: Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988\n(2022).\n[327] KR Prajwal, Rudrabha Mukhopadhyay, Vinay P Namboodiri, and CV Jawahar. 2020. Learning individual speaking styles for accurate lip to speech\nsynthesis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 13796\u201313805.\n[328] KR Prajwal, Rudrabha Mukhopadhyay, Vinay P Namboodiri, and CV Jawahar. 2020. A lip sync expert is all you need for speech to lip generation in\nthe wild. In Proceedings of the 28th ACM International Conference on Multimedia. 484\u2013492.\n[329] Ash & Pri. 2022. Scalenut Review: Features and How To Use It as a Content Generator. https://ashandpri.com/scalenutreview (2022).\n[330] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. 2017. Pointnet: Deep learning on point sets for 3d classification and segmentation. In\nCVPR.\n[331] Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas. 2017. Pointnet++: Deep hierarchical feature learning on point sets in a metric space.\nAdvances in neural information processing systems 30 (2017).\n[332] Weizhen Qi, Yu Yan, Yeyun Gong, Dayiheng Liu, Nan Duan, Jiusheng Chen, Ruofei Zhang, and Ming Zhou. 2020. Prophetnet: Predicting future\nn-gram for sequence-to-sequence pre-training. arXiv preprint arXiv:2001.04063 (2020).\n[333] Yao Qian, Yuchen Fan, Wenping Hu, and Frank K Soong. 2014. On the training aspects of deep neural network (DNN) for parametric TTS synthesis.\nIn 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 3829\u20133833.\n[334] Long Qin. 2013. Learning out-of-vocabulary words in automatic speech recognition. Ph. D. Dissertation. Carnegie Mellon University.\n[335] Lisong Qiu, Juntao Li, Wei Bi, Dongyan Zhao, and Rui Yan. 2019. Are training samples correlated? learning to generate dialogue responses with\nmultiple references. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. 3826\u20133835.\n[336] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack\nClark, et al. 2021. Learning transferable visual models from natural language supervision. In ICML.\n[337] Alec Radford, Luke Metz, and Soumith Chintala. 2015. Unsupervised representation learning with deep convolutional generative adversarial\nnetworks. arXiv preprint arXiv:1511.06434 (2015).\n[338] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. 2018. Improving language understanding by generative pre-training. (2018).\n[339] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask\nlearners. OpenAI blog (2019).\n[340] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020. Exploring\nthe limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res. 21, 140 (2020), 1\u201367.\n[341] Salvatore Raieli. 2023. ControlNet: control your AI art generation. https://levelup.gitconnected.com/controlnet-control-your-ai-art-generation-\n616c86c88964 (2023).\n[342] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022. Hierarchical text-conditional image generation with clip latents.\narXiv preprint arXiv:2204.06125 (2022).\n[343] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. 2021. Zero-shot text-to-image\ngeneration. In ICML.\n[344] Jeremiah Ratican, James Hutson, and Andrew Wright. 2023. A Proposed Meta-Reality Immersive Development Pipeline: Generative AI Models and\nExtended Reality (XR) Content for the Metaverse. Journal of Intelligent Learning Systems and Applications 15 (2023).\n[345] Pratiksha C Raut and Seema U Deoghare. 2016. Automatic Speech Recognition and its Applications. International Research Journal of Engineering\nand Technology 3, 5 (2016), 2368\u20132371.\n[346] Mirco Ravanelli, Jianyuan Zhong, Santiago Pascual, Pawel Swietojanski, Joao Monteiro, Jan Trmal, and Yoshua Bengio. 2020. Multi-task self-\nsupervised learning for robust speech recognition. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing\n(ICASSP). IEEE, 6989\u20136993.\n[347] D Raj Reddy. 1976. Speech recognition by machine: A review. Proc. IEEE 64, 4 (1976), 501\u2013531.\n[348] Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak Lee. 2016. Generative adversarial text to image\nsynthesis. In International conference on machine learning. PMLR, 1060\u20131069.\n[349] Mengwei Ren, Mauricio Delbracio, Hossein Talebi, Guido Gerig, and Peyman Milanfar. 2022. Image Deblurring with Domain Generalizable\nDiffusion Models. arXiv preprint arXiv:2212.01789 (2022).\n[350] Shuo Ren, Wenhu Chen, Shujie Liu, Mu Li, Ming Zhou, and Shuai Ma. 2018. Triangular architecture for rare language translation. arXiv preprint\narXiv:1805.04813 (2018).\n[351] @rev. 2023. Fast, accurate transcription services. https://www.rev.com/ (2023).\nManuscript submitted to ACM\n50\nZhang et al.\n[352] Alexander Richard, Michael Zollh\u00f6fer, Yandong Wen, Fernando De la Torre, and Yaser Sheikh. 2021. Meshtalk: 3d face animation from speech\nusing cross-modality disentanglement. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 1173\u20131182.\n[353] Alan Ritter, Colin Cherry, and Bill Dolan. 2011. Data-driven response generation in social media. In Empirical Methods in Natural Language\nProcessing (EMNLP).\n[354] Adam Roberts, Jesse Engel, Colin Raffel, Curtis Hawthorne, and Douglas Eck. 2018. A hierarchical latent vector model for learning long-term\nstructure in music. In International conference on machine learning. PMLR, 4364\u20134373.\n[355] Vincent Roger, J\u00e9r\u00f4me Farinas, and Julien Pinquier. 2022. Deep neural networks for automatic speech processing: a survey from large corpora to\nlimited data. EURASIP Journal on Audio, Speech, and Music Processing 2022, 1 (2022), 1\u201315.\n[356] Ben Rogerson. 2020. Sony CSL launches Flow Machines, an AI-assisted music production plugin. https://www.musicradar.com/news/sony-csl-\nlaunches-flow-machines-an-ai-assisted-music-production-plugin (2020).\n[357] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. 2022. High-resolution image synthesis with latent diffusion\nmodels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 10684\u201310695.\n[358] Joe Rosato. 2020. Thousands of UC Berkeley Seniors to Graduate in Minecraft Ceremony. https://www.nbcbayarea.com/news/coronavirus/thousands-\nof-uc-berkeley-seniors-to-graduate-in-minecraft-ceremony/2291312/ (2020).\n[359] Sascha Rothe, Shashi Narayan, and Aliaksei Severyn. 2020. Leveraging pre-trained checkpoints for sequence generation tasks. Transactions of the\nAssociation for Computational Linguistics 8 (2020), 264\u2013280.\n[360] JOSH ROTTENBERG. 2019. How the \u2018Gemini Man\u2019 visual effects team created a young Will Smith. https://www.latimes.com/entertainment-\narts/movies/story/2019-08-27/gemini-man-visual-effects-young-will-smith (2019).\n[361] Simon Rouard and Ga\u00ebtan Hadjeres. 2021. CRASH: Raw audio score-based generative modeling for controllable high-resolution drum sound\nsynthesis. arXiv preprint arXiv:2106.07431 (2021).\n[362] Daniel Ruby. 2023. Jasper AI Review 2023: My Experience After Using For 18 Months. https://www.demandsage.com/jasper-ai-review/ (2023).\n[363] Riaan Rudman and Rikus Bruwer. 2016. Defining Web 3.0: opportunities and challenges. The electronic library (2016).\n[364] Kiersten M Ruff and Rohit V Pappu. 2021. AlphaFold and implications for intrinsically disordered proteins. Journal of Molecular Biology 433, 20\n(2021), 167208.\n[365] David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. 1985. Learning internal representations by error propagation. Technical Report.\nCalifornia Univ San Diego La Jolla Inst for Cognitive Science.\n[366] Warren Sack and Marc Davis. 1994. IDIC: Assembling Video Sequences from Story Plans and Content Annotations.. In ICMCS. 30\u201336.\n[367] Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim Salimans, David Fleet, and Mohammad Norouzi. 2022. Palette:\nImage-to-image diffusion models. In Special Interest Group on Computer Graphics and Interactive Techniques Conference Proceedings. 1\u201310.\n[368] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan,\nS Sara Mahdavi, Rapha Gontijo Lopes, et al. 2022. Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding. arXiv\npreprint arXiv:2205.11487 (2022).\n[369] Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J Fleet, and Mohammad Norouzi. 2022. Image super-resolution via iterative\nrefinement. IEEE Transactions on Pattern Analysis and Machine Intelligence (2022).\n[370] Masaki Saito, Eiichi Matsumoto, and Shunta Saito. 2017. Temporal generative adversarial nets with singular value clipping. In Proceedings of the\nIEEE international conference on computer vision. 2830\u20132839.\n[371] Masaki Saito, Shunta Saito, Masanori Koyama, and Sosuke Kobayashi. 2020. Train sparsely, generate densely: Memory-efficient unsupervised\ntraining of high-resolution temporal gan. International Journal of Computer Vision 128, 10 (2020), 2586\u20132606.\n[372] Rose Salia. 2021. Top 10 Best AI Face Apps Review. https://topten.ai/face-apps-review/ (2021).\n[373] Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P Kingma. 2017. Pixelcnn++: Improving the pixelcnn with discretized logistic mixture\nlikelihood and other modifications. arXiv preprint arXiv:1701.05517 (2017).\n[374] Saeed Saremi, Arash Mehrjou, Bernhard Sch\u00f6lkopf, and Aapo Hyv\u00e4rinen. 2018. Deep energy estimator networks. arXiv preprint arXiv:1805.08306\n(2018).\n[375] Jiirgen Schmidhuber. 1990. Making the World Differentiable: On Using Self-Supervised Fully Recurrent N eu al Networks for Dynamic Reinforcement\nLearning and Planning in Non-Stationary Environm nts. (1990).\n[376] Mike Schuster and Kuldip K Paliwal. 1997. Bidirectional recurrent neural networks. IEEE transactions on Signal Processing 45, 11 (1997), 2673\u20132681.\n[377] P Seeviour, J Holmes, and M Judd. 1976. Automatic generation of control signals for a parallel formant speech synthesizer. In ICASSP\u201976. IEEE\nInternational Conference on Acoustics, Speech, and Signal Processing, Vol. 1. IEEE, 690\u2013693.\n[378] Iulian V Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng Zhang, Zhouhan Lin, Sandeep Subramanian, Taesup Kim, Michael Pieper,\nSarath Chandar, Nan Rosemary Ke, et al. 2017. A deep reinforcement learning chatbot. arXiv preprint arXiv:1709.02349 (2017).\n[379] Quin Sexton. 2023. Film Score: A Breakdown in Composing Music for Film. (2023).\n[380] Christine H Shadle and Robert I Damper. 2001. Prospects for articulatory synthesis: A position paper. In 4th ISCA Tutorial and Research Workshop\n(ITRW) on Speech Synthesis.\n[381] Neil Shah, Sarth Engineer, Nandish Bhagat, Hirwa Chauhan, and Manan Shah. 2020. Research trends on the usage of machine learning and artificial\nintelligence in advertising. Augmented Human Research 5 (2020), 1\u201315.\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n51\n[382] Yong Shan, Zekang Li, Jinchao Zhang, Fandong Meng, Yang Feng, Cheng Niu, and Jie Zhou. 2020. A contextual hierarchical attention network with\nadaptive objective for dialogue state tracking. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 6322\u20136333.\n[383] Itamar Shatz. 2017. Native language influence during second language acquisition: A large-scale learner corpus analysis. In Proceedings of the\nPacific Second Language Research Forum (PacSLRF 2016). 175\u2013188.\n[384] Jonathan Shen, Ruoming Pang, Ron J Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, Rj Skerrv-Ryan,\net al. 2018. Natural tts synthesis by conditioning wavenet on mel spectrogram predictions. In 2018 IEEE international conference on acoustics, speech\nand signal processing (ICASSP). IEEE, 4779\u20134783.\n[385] Wei Shen and Rujie Liu. 2017. Learning residual images for face attribute manipulation. In Proceedings of the IEEE conference on computer vision and\npattern recognition. 4030\u20134038.\n[386] Yujun Shen and Bolei Zhou. 2021. Closed-form factorization of latent semantics in gans. In Proceedings of the IEEE/CVF Conference on Computer\nVision and Pattern Recognition. 1532\u20131540.\n[387] Shelly Sheynin, Oron Ashual, Adam Polyak, Uriel Singer, Oran Gafni, Eliya Nachmani, and Yaniv Taigman. 2022. Knn-diffusion: Image generation\nvia large-scale retrieval. arXiv preprint arXiv:2204.02849 (2022).\n[388] Chence Shi, Shitong Luo, Minkai Xu, and Jian Tang. 2021. Learning gradient fields for molecular conformation generation. 9558\u20139568.\n[389] Jiaxin Shi, Shengyang Sun, and Jun Zhu. 2018. A spectral approach to gradient estimation for implicit distributions. In International Conference on\nMachine Learning. PMLR, 4644\u20134653.\n[390] Ziqiang Shi and Shoule Wu. 2022. IT\u00d4N: End-to-end audio generation with It\u00f4 stochastic differential equations. Digital Signal Processing 132\n(2022), 103781.\n[391] Wooksu Shin, Namhyuk Ahn, Jeong-Hyeon Moon, and Kyung-Ah Sohn. 2022. Exploiting Distortion Information for Multi-degraded Image\nRestoration. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 537\u2013546.\n[392] Suman Shrestha. 2014. Image denoising using new adaptive based median filters. arXiv preprint arXiv:1410.2175 (2014).\n[393] Karen Simonyan and Andrew Zisserman. 2015. Very deep convolutional networks for large-scale image recognition. In ICLR.\n[394] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, et al. 2022.\nMake-a-video: Text-to-video generation without text-video data. arXiv preprint arXiv:2209.14792 (2022).\n[395] Karan Singla, Zhuohao Chen, David Atkins, and Shrikanth Narayanan. 2020. Towards end-2-end learning for predicting behavior codes from\nspoken utterances in psychotherapy conversations. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.\n3797\u20133803.\n[396] Bogdan Smolka, K Czubin, Jon Yngve Hardeberg, Kostas N Plataniotis, Marek Szczepanski, and Konrad Wojciechowski. 2003. Towards automatic\nredeye effect removal. Pattern Recognition Letters 24, 11 (2003), 1767\u20131785.\n[397] Yoon So-Yeon. 2020. MBN introduces Korea\u2019s first AI news anchor. https://koreajoongangdaily.joins.com/2020/11/10/entertainment/television/MBN-\nAI-artificial-intelligence/20201110153900457.html (2020).\n[398] Than Htut Soe. 2021. Automation in Video Editing: Assisted Workflows in Video Editing.. In AutomationXP@ CHI.\n[399] Fei Song and W Bruce Croft. 1999. A general language model for information retrieval. In Proceedings of the eighth international conference on\nInformation and knowledge management. 316\u2013321.\n[400] Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2019. Mass: Masked sequence to sequence pre-training for language generation. arXiv\npreprint arXiv:1905.02450 (2019).\n[401] Yang Song and Stefano Ermon. 2019. Generative modeling by estimating gradients of the data distribution, Vol. 32.\n[402] Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon. 2020. Sliced score matching: A scalable approach to density and score estimation. In\nUncertainty in Artificial Intelligence. PMLR, 574\u2013584.\n[403] Yang Song and Diederik P Kingma. 2021. How to train your energy-based models. arXiv preprint arXiv:2101.03288 (2021).\n[404] Yang Song, Jingwen Zhu, Dawei Li, Xiaolong Wang, and Hairong Qi. 2018. Talking face generation by conditional recurrent adversarial network.\narXiv preprint arXiv:1804.04786 (2018).\n[405] Nitish Srivastava and Russ R Salakhutdinov. 2012. Multimodal learning with deep boltzmann machines. Advances in neural information processing\nsystems 25 (2012).\n[406] Nick Statt. 2019. What are Memoji? How to create an Animoji that looks like you. https://www.theverge.com/2019/7/2/20679241/xiaomi-mimoji-\napple-memoji-clone-copying-smartphone-ar-avatar (2019).\n[407] Matteo Stefanini, Marcella Cornia, Lorenzo Baraldi, Silvia Cascianelli, Giuseppe Fiameni, and Rita Cucchiara. 2021. From show to tell: A survey on\nimage captioning. arXiv preprint arXiv:2107.06912 (2021).\n[408] Hui Su, Xiaoyu Shen, Sanqiang Zhao, Xiao Zhou, Pengwei Hu, Randy Zhong, Cheng Niu, and Jie Zhou. 2020. Diversifying dialogue generation\nwith non-conversational text. arXiv preprint arXiv:2005.04346 (2020).\n[409] Shang-Yu Su, Chao-Wei Huang, and Yun-Nung Chen. 2019. Dual supervised learning for natural language understanding and generation. arXiv\npreprint arXiv:1905.06196 (2019).\n[410] Masanori Suganuma, Xing Liu, and Takayuki Okatani. 2019. Attention-based adaptive selection of operations for image restoration in the presence\nof unknown combined distortions. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 9039\u20139048.\n[411] Jian Sun, Wenfei Cao, Zongben Xu, and Jean Ponce. 2015. Learning a convolutional neural network for non-uniform motion blur removal. In\nProceedings of the IEEE conference on computer vision and pattern recognition. 769\u2013777.\nManuscript submitted to ACM\n52\nZhang et al.\n[412] Jiao Sun, Q Vera Liao, Michael Muller, Mayank Agarwal, Stephanie Houde, Kartik Talamadupula, and Justin D Weisz. 2022. Investigating\nexplainability of generative AI for code through scenario-based design. In 27th International Conference on Intelligent User Interfaces. 212\u2013228.\n[413] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural networks. Advances in neural information processing\nsystems 27 (2014).\n[414] Supasorn Suwajanakorn, Steven M Seitz, and Ira Kemelmacher-Shlizerman. 2017. Synthesizing obama: learning lip sync from audio. ACM\nTransactions on Graphics (ToG) 36, 4 (2017), 1\u201313.\n[415] Deborah Swanberg, Chiao Fe Shu, and Ramesh Jain. 1993. Architecture of a multimedia information system for content-based retrieval. In Network\nand Operating System Support for Digital Audio and Video: Third International Workshop La Jolla, California, USA, November 12\u201313, 1992 Proceedings\n3. Springer, 387\u2013392.\n[416] Laura Sydell. 2009. Building The Curious Faces Of \u2019Benjamin Button\u2019. https://www.npr.org/2009/02/17/100668766/building-the-curious-faces-of-\nbenjamin-button (2009).\n[417] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew\nRabinovich. 2015. Going deeper with convolutions. In CVPR.\n[418] Mingxing Tan and Quoc Le. 2019. Efficientnet: Rethinking model scaling for convolutional neural networks. In International conference on machine\nlearning. PMLR, 6105\u20136114.\n[419] Xian Tang. 2009. Hybrid Hidden Markov Model and artificial neural network for automatic speech recognition. In 2009 Pacific-Asia Conference on\nCircuits, Communications and Systems. IEEE, 682\u2013685.\n[420] Victor Tangermann. 2023.\n89 PERCENT OF COLLEGE STUDENTS ADMIT TO USING CHATGPT FOR HOMEWORK, STUDY CLAIMS.\nhttps://futurism.com/the-byte/students-admit-chatgpt-homework (2023).\n[421] DeepMind Research Team. 2017. DeepMind\u2019s work in 2016: a round-up. https://www.deepmind.com/blog/deepminds-work-in-2016-a-round-up\n(2017).\n[422] Latitude Team. 2020. AI Dungeon: Dragon Model Upgrade. https://aidungeon.medium.com/ai-dungeon-dragon-model-upgrade-7e8ea579abfe (2020).\n[423] Justus Thies, Mohamed Elgharib, Ayush Tewari, Christian Theobalt, and Matthias Nie\u00dfner. 2020. Neural voice puppetry: Audio-driven facial\nreenactment. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XVI 16. Springer,\n716\u2013731.\n[424] Yu Tian, Jian Ren, Menglei Chai, Kyle Olszewski, Xi Peng, Dimitris N Metaxas, and Sergey Tulyakov. 2021. A good image generator is what you\nneed for high-resolution video synthesis. arXiv preprint arXiv:2104.15069 (2021).\n[425] Tijmen Tieleman. 2008. Training restricted Boltzmann machines using approximations to the likelihood gradient. In Proceedings of the 25th\ninternational conference on Machine learning. 1064\u20131071.\n[426] Maggie Tillman. 2022. What are Memoji? How to create an Animoji that looks like you. https://www.pocket-lint.com/phones/news/apple/144743-\nwhat-are-memoji-how-to-create-an-animoji-that-looks-like-you/ (2022).\n[427] Artem Timoshenko and John R Hauser. 2019. Identifying customer needs from user-generated content. Marketing Science 38, 1 (2019), 1\u201320.\n[428] Yoshinobu Tonomura, Akihito Akutsu, Yukinobu Taniguchi, and Gen Suzuki. 1994. Structured video computing. IEEE multimedia 1, 03 (1994),\n34\u201343.\n[429] L\u00e1szl\u00f3 T\u00f3th. 2011. A hierarchical, context-dependent neural network architecture for improved phone recognition. In 2011 IEEE International\nConference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 5040\u20135043.\n[430] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herv\u00e9 J\u00e9gou. 2020. Training data-efficient image\ntransformers & distillation through attention. arXiv preprint arXiv:2012.12877 (2020).\n[431] Hugo Touvron, Matthieu Cord, Alexandre Sablayrolles, Gabriel Synnaeve, and Herv\u00e9 J\u00e9gou. 2021. Going deeper with image transformers. In\nProceedings of the IEEE/CVF International Conference on Computer Vision. 32\u201342.\n[432] Aggeliki Tsoli, Antonis Argyros, et al. 2019. Patch-based reconstruction of a textureless deformable 3d surface from a single rgb image. In\nProceedings of the IEEE/CVF International Conference on Computer Vision Workshops. 0\u20130.\n[433] Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz. 2018. Mocogan: Decomposing motion and content for video generation. In\nProceedings of the IEEE conference on computer vision and pattern recognition. 1526\u20131535.\n[434] Hirotada Ueda, Takafumi Miyatake, Shigeo Sumino, and Akio Nagasaka. 1993. Automatic structure visualization for video editing. In Proceedings of\nthe INTERACT\u201993 and CHI\u201993 Conference on Human Factors in Computing Systems. 137\u2013141.\n[435] Anwaar Ulhaq, Naveed Akhtar, and Ganna Pogrebna. 2022. Efficient Diffusion Models for Vision: A Survey. arXiv preprint arXiv:2210.09292 (2022).\n[436] Paul Upchurch, Jacob Gardner, Geoff Pleiss, Robert Pless, Noah Snavely, Kavita Bala, and Kilian Weinberger. 2017. Deep feature interpolation for\nimage content changes. In Proceedings of the IEEE conference on computer vision and pattern recognition. 7064\u20137073.\n[437] Benigno Uria, Marc-Alexandre C\u00f4t\u00e9, Karol Gregor, Iain Murray, and Hugo Larochelle. 2016. Neural autoregressive distribution estimation. The\nJournal of Machine Learning Research 17, 1 (2016), 7184\u20137220.\n[438] Benigno Uria, Iain Murray, and Hugo Larochelle. 2013. RNADE: The real-valued neural autoregressive density-estimator. Advances in Neural\nInformation Processing Systems 26 (2013).\n[439] Demetrios Vakratsas and Xin Wang. 2020. Artificial intelligence in advertising creativity. Journal of Advertising 50, 1 (2020), 39\u201351.\n[440] A\u00e4ron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew W. Senior, and Koray\nKavukcuoglu. 2016. WaveNet: A Generative Model for Raw Audio. In The 9th ISCA Speech Synthesis Workshop.\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n53\n[441] Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al. 2016. Conditional image generation with pixelcnn\ndecoders. Advances in neural information processing systems 29 (2016).\n[442] Domonkos Varga and Tam\u00e1s Szir\u00e1nyi. 2016. Fully automatic image colorization based on Convolutional Neural Network. In 2016 23rd International\nConference on Pattern Recognition (ICPR). IEEE, 3691\u20133696.\n[443] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is\nall you need. In NeurIPS.\n[444] Yuri Viazovetskyi, Vladimir Ivashkin, and Evgeny Kashin. 2020. Stylegan2 distillation for feed-forward image manipulation. In European conference\non computer vision. Springer, 170\u2013186.\n[445] Clement Vignac, Igor Krawczuk, Antoine Siraudin, Bohan Wang, Volkan Cevher, and Pascal Frossard. 2022. DiGress: Discrete Denoising diffusion\nfor graph generation. arXiv preprint arXiv:2209.14734 (2022).\n[446] Pascal Vincent. 2011. A connection between score matching and denoising autoencoders. Neural computation 23, 7 (2011), 1661\u20131674.\n[447] Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan. 2015. Show and tell: A neural image caption generator. In Proceedings of the\nIEEE conference on computer vision and pattern recognition. 3156\u20133164.\n[448] Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba. 2016. Generating videos with scene dynamics. Advances in neural information processing\nsystems 29 (2016).\n[449] Andrey Voynov, Kfir Aberman, and Daniel Cohen-Or. 2022. Sketch-Guided Text-to-Image Diffusion Models. arXiv preprint arXiv:2211.13752 (2022).\n[450] Bram Wallace, Akash Gokul, and Nikhil Naik. 2022. EDICT: Exact Diffusion Inversion via Coupled Transformations. arXiv preprint arXiv:2211.12446\n(2022).\n[451] Hanna M Wallach. 2006. Topic modeling: beyond bag-of-words. In Proceedings of the 23rd international conference on Machine learning. 977\u2013984.\n[452] Ziyu Wan, Bo Zhang, Dongdong Chen, Pan Zhang, Dong Chen, Fang Wen, and Jing Liao. 2022. Old photo restoration via deep latent space\ntranslation. IEEE Transactions on Pattern Analysis and Machine Intelligence (2022).\n[453] Chengyi Wang, Yu Wu, Yujiao Du, Jinyu Li, Shujie Liu, Liang Lu, Shuo Ren, Guoli Ye, Sheng Zhao, and Ming Zhou. 2019. Semantic mask for\ntransformer based end-to-end speech recognition. arXiv preprint arXiv:1912.03010 (2019).\n[454] Dan Wang, Xinrui Cui, Xun Chen, Zhengxia Zou, Tianyang Shi, Septimiu Salcudean, Z Jane Wang, and Rabab Ward. 2021. Multi-view 3D\nReconstruction with Transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 5722\u20135731.\n[455] Jun Wang, Ying Cui, Dongyan Guo, Junxia Li, Qingshan Liu, and Chunhua Shen. 2022. PointAttN: You Only Need Attention for Point Cloud\nCompletion. arXiv preprint arXiv:2203.08485 (2022).\n[456] Li Wang, Zechen Bai, Yonghua Zhang, and Hongtao Lu. 2020. Show, recall, and tell: Image captioning with recall mechanism. In Proceedings of the\nAAAI conference on artificial intelligence, Vol. 34. 12176\u201312183.\n[457] Nanyang Wang, Yinda Zhang, Zhuwen Li, Yanwei Fu, Wei Liu, and Yu-Gang Jiang. 2018. Pixel2mesh: Generating 3d mesh models from single rgb\nimages. In Proceedings of the European conference on computer vision (ECCV). 52\u201367.\n[458] Rui Wang, Xu Tan, Renqian Luo, Tao Qin, and Tie-Yan Liu. 2021. A survey on low-resource neural machine translation. arXiv preprint arXiv:2107.04239\n(2021).\n[459] Xuejiao Wang, Qiuyan Tao, Lianghao Wang, Dongxiao Li, and Ming Zhang. 2015. Deep convolutional architecture for natural image denoising. In\n2015 International Conference on Wireless Communications & Signal Processing (WCSP). IEEE, 1\u20134.\n[460] Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Yu Qiao, and Chen Change Loy. 2018. Esrgan: Enhanced super-resolution\ngenerative adversarial networks. In Proceedings of the European conference on computer vision (ECCV) workshops. 0\u20130.\n[461] Yuting Wang. 2021. The Application of Artificial Intelligence in Chinese News Media. In 2021 2nd International Conference on Artificial Intelligence\nand Information Systems. 1\u20134.\n[462] Yexiang Wang, Yi Guo, and Siqi Zhu. 2020. Slot attention with value normalization for multi-domain dialogue state tracking. In Proceedings of the\n2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 3019\u20133028.\n[463] Yufei Wang, Zhe Lin, Xiaohui Shen, Scott Cohen, and Garrison W Cottrell. 2017. Skeleton key: Image captioning by skeleton-attribute decomposition.\nIn Proceedings of the IEEE conference on computer vision and pattern recognition. 7272\u20137281.\n[464] Duncan J Watts and Steven H Strogatz. 1998. Collective dynamics of \u2018small-world\u2019networks. nature 393, 6684 (1998), 440\u2013442.\n[465] Andrew Webster. 2020. Travis Scott\u2019s first Fortnite concert was surreal and spectacular. https://www.theverge.com/2020/4/23/21233637/travis-scott-\nfortnite-concert-astronomical-live-report (2020).\n[466] Li-Yi Wei and Marc Levoy. 2000. Fast texture synthesis using tree-structured vector quantization. In Proceedings of the 27th annual conference on\nComputer graphics and interactive techniques. 479\u2013488.\n[467] Tianyi Wei, Dongdong Chen, Wenbo Zhou, Jing Liao, Weiming Zhang, Lu Yuan, Gang Hua, and Nenghai Yu. 2022. E2Style: Improve the efficiency\nand effectiveness of StyleGAN inversion. IEEE Transactions on Image Processing 31 (2022), 3267\u20133280.\n[468] Max Welling and Geoffrey E Hinton. 2002. A new learning algorithm for mean field Boltzmann machines. In International Conference on Artificial\nNeural Networks. Springer, 351\u2013357.\n[469] WIKIPEDIA. 2013. Furious 7 (2015). https://en.wikipedia.org/wiki/Furious_7 (2013).\n[470] Max Willens. 2018. Bloomberg Media has a robot writing story summaries. https://digiday.com/media/bloomberg-media-robot-writing-story-\nsummaries/ (2018).\nManuscript submitted to ACM\n54\nZhang et al.\n[471] Karen William. 2021. Top 6 to Voicemod Alternatives Voice Changer [Windows/Mac/Android/iOS]. https://filme.imyfone.com/audio-edit/voicemod-\nalternative/ (2021).\n[472] Chenfei Wu, Lun Huang, Qianxi Zhang, Binyang Li, Lei Ji, Fan Yang, Guillermo Sapiro, and Nan Duan. 2021. Godiva: Generating open-domain\nvideos from natural descriptions. arXiv preprint arXiv:2104.14806 (2021).\n[473] Jibin Wu, Emre Y\u0131lmaz, Malu Zhang, Haizhou Li, and Kay Chen Tan. 2020. Deep spiking neural networks for large vocabulary automatic speech\nrecognition. Frontiers in neuroscience 14 (2020), 199.\n[474] Jay Zhangjie Wu, Yixiao Ge, Xintao Wang, Weixian Lei, Yuchao Gu, Wynne Hsu, Ying Shan, Xiaohu Qie, and Mike Zheng Shou. 2022. Tune-A-Video:\nOne-Shot Tuning of Image Diffusion Models for Text-to-Video Generation. arXiv preprint arXiv:2212.11565 (2022).\n[475] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus\nMacherey, et al. 2016. Google\u2019s neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint\narXiv:1609.08144 (2016).\n[476] Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 2015. 3d shapenets: A deep representation\nfor volumetric shapes. In Proceedings of the IEEE conference on computer vision and pattern recognition. 1912\u20131920.\n[477] Weihao Xia, Yulun Zhang, Yujiu Yang, Jing-Hao Xue, Bolei Zhou, and Ming-Hsuan Yang. 2022. Gan inversion: A survey. IEEE Transactions on\nPattern Analysis and Machine Intelligence (2022).\n[478] Taihong Xiao, Jiapeng Hong, and Jinwen Ma. 2017. Dna-gan: Learning disentangled representations from multi-attribute images. arXiv preprint\narXiv:1711.05415 (2017).\n[479] Zhisheng Xiao, Karsten Kreis, and Arash Vahdat. 2021. Tackling the generative learning trilemma with denoising diffusion gans. arXiv preprint\narXiv:2112.07804 (2021).\n[480] Haozhe Xie, Hongxun Yao, Xiaoshuai Sun, Shangchen Zhou, and Shengping Zhang. 2019. Pix2vox: Context-aware 3d reconstruction from single\nand multi-view images. In Proceedings of the IEEE/CVF international conference on computer vision. 2690\u20132698.\n[481] Junyuan Xie, Linli Xu, and Enhong Chen. 2012. Image denoising and inpainting with deep neural networks. Advances in neural information\nprocessing systems 25 (2012).\n[482] Tian Xie, Xiang Fu, Octavian-Eugen Ganea, Regina Barzilay, and Tommi Jaakkola. 2021. Crystal diffusion variational autoencoder for periodic\nmaterial generation. arXiv preprint arXiv:2110.06197 (2021).\n[483] Jun Xu, Haifeng Wang, Zheng-Yu Niu, Hua Wu, Wanxiang Che, and Ting Liu. 2020. Conversational graph grounded policy learning for open-domain\nconversation generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 1835\u20131845.\n[484] Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. 2015. Show, attend and\ntell: Neural image caption generation with visual attention. In International conference on machine learning. PMLR, 2048\u20132057.\n[485] Li Xu and Jiaya Jia. 2010. Two-phase kernel estimation for robust motion deblurring. In European conference on computer vision. Springer, 157\u2013170.\n[486] Li Xu, Jimmy S Ren, Ce Liu, and Jiaya Jia. 2014. Deep convolutional neural network for image deconvolution. Advances in neural information\nprocessing systems 27 (2014).\n[487] Peng Xu, Xiatian Zhu, and David A Clifton. 2022. Multimodal learning with transformers: a survey. arXiv preprint arXiv:2206.06488 (2022).\n[488] Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and Xiaodong He. 2018. Attngan: Fine-grained text to image\ngeneration with attentional generative adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition.\n1316\u20131324.\n[489] Xianqiu Xu, Hongqing Liu, Yong Li, and Yi Zhou. 2016. Image deblurring with blur kernel estimation in RGB channels. In 2016 IEEE International\nConference on Digital Signal Processing (DSP). IEEE, 681\u2013684.\n[490] Yangyang Xu, Yong Du, Wenpeng Xiao, Xuemiao Xu, and Shengfeng He. 2021. From continuity to editability: Inverting gans with consecutive\nimages. In Proceedings of the IEEE/CVF International Conference on Computer Vision. 13910\u201313918.\n[491] Ke Xue, Yifei Li, and Hanqing Jin. 2022. What Do You Think of AI? Research on the Influence of AI News Anchor Image on Watching Intention.\nBehavioral Sciences 12, 11 (2022), 465.\n[492] Hemant Yadav and Sunayana Sitaram. 2022. A Survey of Multilingual Models for Automatic Speech Recognition. arXiv preprint arXiv:2202.12576\n(2022).\n[493] Karan Yadav. 2023. How education chatbots can help students and teachers. http://www.eyeshenzhen.com/content/2022-02/08/content_24921512.htm\n(2023).\n[494] Ravindra Yadav, Ashish Sardana, Vinay P Namboodiri, and Rajesh M Hegde. 2021. Speech prediction in silent videos using variational autoencoders.\nIn ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 7048\u20137052.\n[495] Xinchen Yan, Jimei Yang, Kihyuk Sohn, and Honglak Lee. 2016. Attribute2image: Conditional image generation from visual attributes. In European\nconference on computer vision. Springer, 776\u2013791.\n[496] Li-Chia Yang, Szu-Yu Chou, and Yi-Hsuan Yang. 2017. MidiNet: A convolutional generative adversarial network for symbolic-domain music\ngeneration. arXiv preprint arXiv:1703.10847 (2017).\n[497] Shuoheng Yang, Yuxin Wang, and Xiaowen Chu. 2020. A survey of deep learning techniques for neural machine translation. arXiv preprint\narXiv:2002.07526 (2020).\n[498] Shiquan Yang, Rui Zhang, and Sarah Erfani. 2020. Graphdialog: Integrating graph knowledge into end-to-end task-oriented dialogue systems.\narXiv preprint arXiv:2010.01447 (2020).\nManuscript submitted to ACM\nA Complete Survey on Generative AI (AIGC): Is ChatGPT from GPT-4 to GPT-5 All You Need?\n55\n[499] Tiancheng Yang and Shah Nazir. 2022. A comprehensive overview of AI-enabled music classification and its influence in games. Soft Computing 26,\n16 (2022), 7679\u20137693.\n[500] Xu Yang, Kaihua Tang, Hanwang Zhang, and Jianfei Cai. 2019. Auto-encoding scene graphs for image captioning. In Proceedings of the IEEE/CVF\nConference on Computer Vision and Pattern Recognition. 10685\u201310694.\n[501] Xu Yang, Hanwang Zhang, and Jianfei Cai. 2019. Learning to collocate neural modules for image captioning. In Proceedings of the IEEE/CVF\nInternational Conference on Computer Vision. 4250\u20134260.\n[502] Yunyi Yang, Yunhao Li, and Xiaojun Quan. 2021. Ubar: Towards fully end-to-end task-oriented dialog system with gpt-2. In Proceedings of the\nAAAI Conference on Artificial Intelligence, Vol. 35. 14230\u201314238.\n[503] Jiaxuan You, Rex Ying, Xiang Ren, William Hamilton, and Jure Leskovec. 2018. Graphrnn: Generating realistic graphs with deep auto-regressive\nmodels. In International conference on machine learning. PMLR, 5708\u20135717.\n[504] Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan,\net al. 2022. Scaling autoregressive models for content-rich text-to-image generation. arXiv preprint arXiv:2206.10789 (2022).\n[505] Ke Yu, Chao Dong, Liang Lin, and Chen Change Loy. 2018. Crafting a toolchain for image restoration by deep reinforcement learning. In Proceedings\nof the IEEE conference on computer vision and pattern recognition. 2443\u20132452.\n[506] Tianxiu Yu, Cong Lin, Shijie Zhang, Chunxue Wang, Xiaohong Ding, Huili An, Xiaoxiang Liu, Ting Qu, Liang Wan, Shaodi You, et al. 2022. Artificial\nIntelligence for Dunhuang Cultural Heritage Protection: The Project and the Dataset. International Journal of Computer Vision 130, 11 (2022),\n2646\u20132673.\n[507] Lu Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao, Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, et al.\n2021. Florence: A new foundation model for computer vision. arXiv preprint arXiv:2111.11432 (2021).\n[508] Li Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Francis EH Tay, Jiashi Feng, and Shuicheng Yan. 2021. Tokens-to-token vit: Training\nvision transformers from scratch on imagenet. arXiv preprint arXiv:2101.11986 (2021).\n[509] Yuan Yuan, Siyuan Liu, Jiawei Zhang, Yongbing Zhang, Chao Dong, and Liang Lin. 2018. Unsupervised image super-resolution using cycle-in-cycle\ngenerative adversarial networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. 701\u2013710.\n[510] Yi Yuan, Jilin Tang, and Zhengxia Zou. 2021. Vanet: a view attention guided network for 3d reconstruction from single and multi-view images. In\n2021 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 1\u20136.\n[511] Xia Yuanjie. 2022. AI sign language anchor serves at Olympics. http://www.eyeshenzhen.com/content/2022-02/08/content_24921512.htm (2022).\n[512] Vladyslav Yushchenko, Nikita Araslanov, and Stefan Roth. 2019. Markov decision process for video generation. In Proceedings of the IEEE/CVF\nInternational Conference on Computer Vision Workshops. 0\u20130.\n[513] Shehtab Zaman, Ethan Ferguson, Cecile Pereira, Denis Akhiyarov, Mauricio Araya-Polo, and Kenneth Chiu. 2022. ParticleGrid: Enabling Deep\nLearning using 3D Representation of Materials. arXiv preprint arXiv:2211.08506 (2022).\n[514] Heiga Ze, Andrew Senior, and Mike Schuster. 2013. Statistical parametric speech synthesis using deep neural networks. In 2013 ieee international\nconference on acoustics, speech and signal processing. IEEE, 7962\u20137966.\n[515] Heiga Zen. 2015. Acoustic modeling in statistical parametric speech synthesis-from HMM to LSTM-RNN. (2015).\n[516] Heiga Zen and Ha\u015fim Sak. 2015. Unidirectional long short-term memory recurrent neural network with recurrent output layer for low-latency\nspeech synthesis. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 4470\u20134474.\n[517] Aeron Zentner. 2022. Applied Innovation: Artificial Intelligence in Higher Education. Available at SSRN 4314180 (2022).\n[518] Zheng-Jun Zha, Daqing Liu, Hanwang Zhang, Yongdong Zhang, and Feng Wu. 2019. Context-aware visual policy network for fine-grained image\ncaptioning. IEEE transactions on pattern analysis and machine intelligence 44, 2 (2019), 710\u2013722.\n[519] Chaoning Zhang, Chenshuang Zhang, Junha Song, John Seon Keun Yi, Kang Zhang, and In So Kweon. 2022. A survey on masked autoencoder for\nself-supervised learning in vision and beyond. arXiv preprint arXiv:2208.00173 (2022).\n[520] Chaoning Zhang, Kang Zhang, Trung X. Pham, Changdong Yoo, and In-So Kweon. 2022. Dual Temperature Helps Contrastive Learning Without\nMany Negative Samples: Towards Understanding and Simplifying MoCo. In CVPR.\n[521] Chaoning Zhang, Kang Zhang, Chenshuang Zhang, Trung X Pham, Chang D Yoo, and In So Kweon. 2022. How Does SimSiam Avoid Collapse\nWithout Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning. In ICLR.\n[522] Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimitris N Metaxas. 2017. Stackgan: Text to photo-realistic\nimage synthesis with stacked generative adversarial networks. In Proceedings of the IEEE international conference on computer vision. 5907\u20135915.\n[523] Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimitris N Metaxas. 2018. Stackgan++: Realistic image\nsynthesis with stacked generative adversarial networks. IEEE transactions on pattern analysis and machine intelligence 41, 8 (2018), 1947\u20131962.\n[524] Kunai Zhang, Da Huang, and David Zhang. 2017. An optimized palmprint recognition approach based on image sharpness. Pattern Recognition\nLetters 85 (2017), 65\u201371.\n[525] Mingju Zhang, Lei Zhang, Yanfeng Sun, Lin Feng, and Weiying Ma. 2005. Auto cropping for digital photographs. In 2005 IEEE International\nConference on Multimedia and Expo. IEEE, 4\u2013pp.\n[526] Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang, Yejin Choi, and Jianfeng Gao. 2021. Vinvl: Revisiting visual\nrepresentations in vision-language models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 5579\u20135588.\n[527] Weixing Zhang. 2022. Application and development of robot sports news writing by artificial intelligence. In 2022 IEEE 2nd International Conference\non Data Science and Computer Application (ICDSCA). IEEE, 869\u2013872.\nManuscript submitted to ACM\n56\nZhang et al.\n[528] Wenlong Zhang, Yihao Liu, Chao Dong, and Yu Qiao. 2019. Ranksrgan: Generative adversarial networks with ranker for image super-resolution. In\nProceedings of the IEEE/CVF International Conference on Computer Vision. 3096\u20133105.\n[529] Xiaobo Zhang, Xiangchu Feng, Weiwei Wang, Shunli Zhang, and Qunfeng Dong. 2013. Gradient-based Wiener filter for image denoising. Computers\n& Electrical Engineering 39, 3 (2013), 934\u2013944.\n[530] Xuying Zhang, Xiaoshuai Sun, Yunpeng Luo, Jiayi Ji, Yiyi Zhou, Yongjian Wu, Feiyue Huang, and Rongrong Ji. 2021. Rstnet: Captioning with\nadaptive attention on visual and non-visual words. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 15465\u201315474.\n[531] Yichi Zhang, Zhijian Ou, Huixin Wang, and Junlan Feng. 2020. A probabilistic end-to-end task-oriented dialog model with latent belief states\ntowards semi-supervised learning. arXiv preprint arXiv:2009.08115 (2020).\n[532] Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. 2019. Dialogpt:\nLarge-scale generative pre-training for conversational response generation. arXiv preprint arXiv:1911.00536 (2019).\n[533] Zheng Zhang, Ryuichi Takanobu, Qi Zhu, MinLie Huang, and XiaoYan Zhu. 2020. Recent advances and challenges in task-oriented dialog systems.\nScience China Technological Sciences 63, 10 (2020), 2011\u20132027.\n[534] Mo Zhao, Gang Cao, Xianglin Huang, and Lifang Yang. 2022. Hybrid Transformer-CNN for Real Image Denoising. IEEE Signal Processing Letters\n(2022).\n[535] Qian Zhao, Hao Yang, Dongming Zhou, and Jinde Cao. 2022. Rethinking image deblurring via CNN-Transformer multi-scale hybrid architecture.\nIEEE Transactions on Instrumentation and Measurement (2022).\n[536] Wentian Zhao, Yao Hu, Heda Wang, Xinxiao Wu, and Jiebo Luo. 2021. Boosting Entity-aware Image Captioning with Multi-modal Knowledge\nGraph. arXiv preprint arXiv:2107.11970 (2021).\n[537] Rui Zhen, Wenchao Song, Qiang He, Juan Cao, Lei Shi, and Jia Luo. 2023. Human-Computer Interaction System: A Survey of Talking-Head\nGeneration. Electronics 12, 1 (2023), 218.\n[538] Ce Zhou, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, Cheng Ji, Qiben Yan, Lifang He, et al. 2023. A comprehensive survey on\npretrained foundation models: A history from bert to chatgpt. arXiv preprint arXiv:2302.09419 (2023).\n[539] Hang Zhou, Yu Liu, Ziwei Liu, Ping Luo, and Xiaogang Wang. 2019. Talking face generation by adversarially disentangled audio-visual representation.\nIn Proceedings of the AAAI conference on artificial intelligence, Vol. 33. 9299\u20139306.\n[540] Jingyuan Zhou, Chaktou Leong, Minyi Lin, Wantong Liao, and Congduan Li. 2022. Task adaptive network for image restoration with combined\ndegradation factors. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 1\u20138.\n[541] Li Zhou, Jianfeng Gao, Di Li, and Heung-Yeung Shum. 2020. The design and implementation of xiaoice, an empathetic social chatbot. Computational\nLinguistics 46, 1 (2020), 53\u201393.\n[542] Luowei Zhou, Hamid Palangi, Lei Zhang, Houdong Hu, Jason Corso, and Jianfeng Gao. 2020. Unified vision-language pre-training for image\ncaptioning and vqa. In Proceedings of the AAAI conference on artificial intelligence, Vol. 34. 13041\u201313049.\n[543] Le Zhou, Qiu-Feng Wang, Kaizhu Huang, and Cheng-Hung Lo. 2019. An interactive and generative approach for chinese shanshui painting\ndocument. In 2019 International Conference on Document Analysis and Recognition (ICDAR). IEEE, 819\u2013824.\n[544] Jiapeng Zhu, Yujun Shen, Deli Zhao, and Bolei Zhou. 2020. In-domain gan inversion for real image editing. In European conference on computer\nvision. Springer, 592\u2013608.\n[545] Jun-Yan Zhu, Philipp Kr\u00e4henb\u00fchl, Eli Shechtman, and Alexei A Efros. 2016. Generative visual manipulation on the natural image manifold. In\nEuropean conference on computer vision. Springer, 597\u2013613.\n[546] Qingfu Zhu, Lei Cui, Weinan Zhang, Furu Wei, and Ting Liu. 2018. Retrieval-enhanced adversarial training for neural response generation. arXiv\npreprint arXiv:1809.04276 (2018).\n[547] Barret Zoph and Kevin Knight. 2016. Multi-source neural translation. arXiv preprint arXiv:1601.00710 (2016).\n[548] Zhengxia Zou, Tianyang Shi, Shuang Qiu, Yi Yuan, and Zhenwei Shi. 2021. Stylized neural painting. In Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition. 15689\u201315698.\nManuscript submitted to ACM\n",
    "2302.06476": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?\nChengwei Qin\u2020\u2217, Aston Zhang, Zhuosheng Zhang\u2663, Jiaao Chen\u2660,\nMichihiro Yasunaga\u2666, Diyi Yang\u2666\n\u2020Nanyang Technological University,\u2663Shanghai Jiao Tong University\n\u2660Georgia Institute of Technology, \u2666Stanford University\nAbstract\nSpurred by advancements in scale, large lan-\nguage models (LLMs) have demonstrated the\nability to perform a variety of natural language\nprocessing (NLP) tasks zero-shot\u2014i.e., with-\nout adaptation on downstream data. Recently,\nthe debut of ChatGPT 1 has drawn a great deal\nof attention from the natural language process-\ning (NLP) community due to the fact that it\ncan generate high-quality responses to human\ninput and self-correct previous mistakes based\non subsequent conversations. However, it is not\nyet known whether ChatGPT can serve as a gen-\neralist model that can perform many NLP tasks\nzero-shot. In this work, we empirically analyze\nthe zero-shot learning ability of ChatGPT by\nevaluating it on 20 popular NLP datasets cov-\nering 7 representative task categories. With ex-\ntensive empirical studies, we demonstrate both\nthe effectiveness and limitations of the current\nversion of ChatGPT. We find that ChatGPT per-\nforms well on many tasks favoring reasoning\ncapabilities (e.g., arithmetic reasoning) while\nit still faces challenges when solving specific\ntasks such as sequence tagging. We addition-\nally provide in-depth analysis through qualita-\ntive case studies.\n1\nIntroduction\nLarge language models (LLMs) have been shown\nto be able to solve a variety of natural language\nprocessing (NLP) tasks zero shot\u2014i.e., without re-\nlying on any training data for a given downstream\ntask\u2014by conditioning the model on appropriate\nprompts (Brown et al., 2020; Chowdhery et al.,\n2022a). The ability to perform new tasks based\non instructions can be seen as an important step\ntowards artificial general intelligence (Goertzel,\n2014). Despite achieving reasonable performance\n\u2217Correspondence\nto\nChengwei\nQin\n<cheng-\nwei003@e.ntu.edu.sg>\nand\nAston\nZhang\n<az@astonzhang.com>\n1https://chat.openai.com/\nin some cases, current LLMs are still prone to var-\nious mistakes in zero-shot learning. In addition,\nthe format of the prompt can have a substantial\nimpact\u2014for example, simply adding \u201cLet\u2019s think\nstep by step\u201d (Kojima et al., 2022) has been shown\nto significantly improve the performance of In-\nstructGPT (Ouyang et al., 2022) on reasoning tasks.\nThese limitations illustrate that current LLMs are\nnot truly general-purpose language systems.\nRecently, the ChatGPT LLM released by Ope-\nnAI has attracted a great deal of attention from the\nNLP community. ChatGPT was created by train-\ning a GPT-3.5 series model through reinforcement\nlearning from human feedback (RLHF) (Christiano\net al., 2017) (similarly to InstructGPT). RLHF\nmainly includes three steps: training a language\nmodel with supervised learning, collecting compar-\nison data based on human preferences and training\na reward model, and optimizing the language model\nagainst the reward model using reinforcement learn-\ning (Ouyang et al., 2022). Through RLHF training,\nChatGPT has been observed to have impressive ca-\npabilities in various aspects, including generating\nhigh-quality responses to human input, rejecting\ninappropriate questions, and self-correcting previ-\nous errors based on subsequent conversations (Guo\net al., 2023).\nWhile ChatGPT shows strong dialogic capabili-\nties, it still remains unclear to the NLP community\nwhether ChatGPT attains better zero-shot general-\nization compared with existing LLMs. To fill in\nthis research gap, we systematically study the zero-\nshot learning capability of ChatGPT by evaluating\nit on a large collection of NLP datasets covering\n7 representative task categories, including reason-\ning2, natural language inference, question answer-\ning (reading comprehension), dialogue, summa-\nrization, named entity recognition, and sentiment\n2Reasoning abilities can be assessed by means of linguistic\ntasks (Liang et al., 2022), such as with prompt templates and\nchains of thought in the text format.\narXiv:2302.06476v3  [cs.CL]  19 Nov 2023\nMultiArith\nGSM8K\nAddSub\nAQUA-RAT\nSingleEq\nSVAMP\n0\n20\n40\n60\n80\n100\nArithmetic Reasoning\nChatGPT\nGPT-3.5\nFine-tuning\nCSQA\nStrategyQA\nCOPA\n0\n20\n40\n60\n80\nCommonsense Reasoning\nLast Letter\nCoin Flip\n0\n20\n40\n60\n80\n100\nSymbolic Reasoning\nDate\nObject\n0\n20\n40\n60\n80\nLogical Reasoning\nRTE (NLI)\nCB (NLI)\nBoolQ\n(Question Answering)\nMuTual (Dialogue)\nSAMsum\n(Summarization)\nCoNLL03 (NER)\nSST2\n(Sentiment Analysis)\n0\n20\n40\n60\n80\n100\nFigure 1: Performance of ChatGPT, GPT-3.5, and models fine-tuned with task-specific data for 20 different datasets.\nFor each reasoning dataset, the better result between zero-shot and zero-shot chain-of-thought is shown. Measures\nof SAMsum, CoNLL03, and the rest are ROUGE-1/2/L average, F1, accuracy, respectively.\nanalysis. With extensive experiments, we aim to\nanswer the following research questions:\n\u2022 Is ChatGPT a general-purpose NLP task solver?\nOn what types of tasks does ChatGPT perform\nwell?\n\u2022 If ChatGPT fell behind other models on certain\ntasks, why?\nTo answer these questions, we empirically com-\npare the performance of ChatGPT (gpt-3.5-turbo)\nand the previous GPT-3.5 model (text-davinci-\n003). In addition, we report zero-shot, fine-tuned,\nor few-shot fine-tuned results from recent work\nsuch as FLAN (Wei et al., 2021), T0 (Sanh et al.,\n2021b), and PaLM (Chowdhery et al., 2022b).\nKey takeaways\nTo the best of our knowledge,\nthis is the first study of the ChatGPT\u2019s zero-shot\ncapabilities on a diverse range of NLP tasks, aiming\nto provide a profile of ChatGPT. The key findings\nand insights are summarized as follows:\n\u2022 Although ChatGPT shows some capability as\na generalist model that can perform multiple\ntasks (Zhang et al., 2021), it often performs worse\nthan models that are fine-tuned on a given task\n(Section 4.3 and Figure 1).\n\u2022 The superior reasoning capability of ChatGPT\nis empirically substantiated in arithmetic reason-\ning tasks (Section 4.2.1). However, ChatGPT\noften underperforms GPT-3.5 in commonsense,\nsymbolic, and logical reasoning tasks.\n\u2022 ChatGPT outperforms GPT-3.5 for natural lan-\nguage inference tasks (Section 4.2.3) and ques-\ntion answering (reading comprehension) tasks\n(Section 4.2.4) that favor reasoning capabili-\nties, such as in determining logical relationships\nwithin text pairs. Specifically, ChatGPT is bet-\nter at handling factually consistent text (i.e., bet-\nter at classifying entailment rather than non-\nentailment).\n\u2022 ChatGPT is superior to GPT-3.5 for dialogue\ntasks (Section 4.2.5).\n\u2022 ChatGPT generates longer summaries and per-\nforms worse than GPT-3.5 for summarization\ntasks.\nHowever, explicitly limiting summary\nlength in the zero-shot instruction harms the sum-\nmarization quality, leading to even worse perfor-\nmance (Section 4.2.6).\n\u2022 Despite showing promise as generalist models,\nboth ChatGPT and GPT-3.5 face challenges on\ncertain tasks such as sequence tagging (Sec-\ntion 4.2.7).\n\u2022 ChatGPT\u2019s sentiment analysis ability is better\nthan that of GPT-3.5 (Section 4.2.8).\n2\nRelated Work\nThis work mainly explores the zero-shot learning\ncapability of ChatGPT on a diverse collection of\ndatasets including reasoning and classic NLP tasks.\nIn light of this, we review three lines of research\nthat form the basis of this work: large language\nmodels, zero-shot learning, and chain-of-thought\nprompting for reasoning.\n2.1\nLarge Language Models\nEver since Radford et al. (2019); Brown et al.\n(2020) demonstrated that language models can per-\nform a variety of tasks without any gradient up-\ndates by providing the model with a textual in-\nstruction (zero-shot) and/or a few examples (few-\nshot), a great deal of work has focused on devel-\noping better large language models (LLMs). One\nline of work has aimed to explore the benefits of\nscaling up LLMs, including Megatron-turing NLG\n(Smith et al., 2022) with 530 billion parameters,\nGopher (Rae et al., 2021) with 280 billion param-\neters, and PaLM Chowdhery et al. (2022b) with\n540 billion parameters. The benefits of this scale\nhave born out on stronger performance on more\ndifficult tasks, e.g. the finding that PaLM outper-\nformed average humans on the challenging BIG-\nbench benchmark (Srivastava et al., 2022). These\nLLMs also form the basis of better models, such as\nMinerva (Lewkowycz et al., 2022) which achieved\nstate-of-the-art performance on various technical\nbenchmarks. Rather than scaling up model size\nalone, a separate line of research aims to attain\nbetter performance with smaller models through\nlonger training (Hoffmann et al., 2022) or alter-\nnative objectives Tay et al. (2022). One partic-\nularly fruitful direction has been training LLMs\nwith supervision (Sanh et al., 2021b; Wei et al.,\n2021; Mishra et al., 2022; Chung et al., 2022)\nand/or human feedback (Ouyang et al., 2022). The\nstrong performance of LLMs has led to a signif-\nicant amount of work analyzing the abilities and\nbehaviors of LLMs (Webson and Pavlick, 2022;\nQin and Joty, 2022b; Min et al., 2022; Liang et al.,\n2022; Qin et al., 2023a,b).\n2.2\nZero-Shot Learning\nZero-shot learning aims to solve unseen tasks with-\nout labeled training examples. It results in a big\nchallenge for models as they typically rely on large\namounts of training data. Prior methods to solve\nzero-shot learning can be mainly divided into two\ncategories: (i) model-based methods focused on\nhow to directly learn a model for unseen sam-\nples (Fu et al., 2017; Wang et al., 2018); and\n(ii) instance-based methods tried to obtain labeled\ninstances for unseen tasks to improve model learn-\ning (Zhang et al., 2017; Ye and Guo, 2017; Qin\nand Joty, 2022a). More recent work has demon-\nstrated the superiority of LLMs for zero-shot learn-\ning (Brown et al., 2020; Wei et al., 2021; Chowdh-\nery et al., 2022b). The most recent breakthrough of\nLLMs is the debut of ChatGPT, which has shown\namazing ability in various aspects related to dia-\nlogue. Going a step further, we explore the zero-\nshot learning capability of ChatGPT on different\ntasks beyond dialogue in this work.\n2.3\nChain-of-Thought Prompting\nChain-of-thought (CoT) prompting induces LLMs\nto generate intermediate reasoning steps before an-\nswering (Wei et al., 2022). According to whether\nthere are manual demonstrations, current CoT\nprompting methods can be divided into two main\ncategories: manual-CoT and zero-Shot-CoT. In\nmanual-CoT, LLMs perform CoT reasoning with\nmanually designed demonstrations (Wei et al.,\n2022).\nLeast-to-most prompting (Zhou et al.,\n2022) decomposed complex problems into sub-\nproblems and then sequentially solved the sub-\nproblems. Wang et al. (2022b) introduced self-\nconsistency to sample multiple reasoning paths,\nand then conducted a majority vote to determine\nthe final answer. To generate more diverse out-\nputs, Li et al. (2022a) and Wang et al. (2022a) ex-\nplored applying randomness in the input space. In\nzero-Shot-CoT, Kojima et al. (2022) demonstrated\nthat LLMs are decent zero-shot reasoners by lever-\naging self-generated rationales. The effectiveness\nof self-generated rationales was also verified by\nSTaR (Zelikman et al., 2022), which enabled the\nmodel to self-improve through its own generated\nrationales. Zhang et al. (2023a) proposed Auto-\nCoT to automatically generate rationales from test\nquestions. Most recent studies mainly focused on\nhow to improve manual-CoT, including optimizing\nthe demonstration selection (Rubin et al., 2022; Fu\nPlease identify whether the premise entails the hypothesis. \nThe answer should be exact 'entail' or 'not entail'.\npremise: Pibul Songgram was the pro-Japanese military \ndictator of Thailand during World War 2.\nhypothesis: Pibul was the dictator of Thailand.\nanswer: \nSentiment Analysis\nFor each snippet of text, label the sentiment of the text as \npositive or negative. The answer should be exact 'positive' \nor 'negative'.\nText: it 's a stunning lyrical work of considerable force \nand truth.\nLabel: \nNatural Language Inference\nName Entity Recognition\nPlease identify Person, Organization, Location and \nMiscellaneous Entity from the given text.\nText: All four teams are level with one point each from \none game.\nEntity: \nSummarization\nHannah: Hey, do you have Betty's number? Amanda: \nLemme check ... Hannah: Urgh.. Alright Hannah: Bye \nAmanda: Bye bye\nTL;DR: \nQuestion Answering\nPlease answer the given question based on the context. \nThe answer should be exact 'yes' or 'no'.\ncontext: American entry into Canada by land -- Persons \ndriving into Canada must have their vehicle's registration \ndocument and proof of insurance.\nquestion: can u drive in canada with us license?\nanswer: \nDialogue\nQ: f: why all the candles? is the electricity out or \nsomething? m: no, i just thought it would make the place \nsmell nice. f: it does smell nice, but it's still awfully dark. \nWhich choice is correct? Answer Choices: (A) ... (B) ... \n(C) ... (D) ...\nA: Among A through D, the answer is\nFigure 2: Instructions and input formats of six different\ncategories of tasks (sentiment analysis, natural language\ninference, named entity recognition, question answering,\ndialogue, and summarization). The task instructions are\ntaken from or inspired by Brown et al. (2020), Ouyang\net al. (2022), Zhang et al. (2023a) and Ding et al. (2022).\nWe color the instructions in blue. After reading the\nentire input (circled by the green dashed box), the model\ngenerates an answer.\nQ: If 120 is reduced to 96, what is the reduction \npercent? Answer Choices: (A) 30% (B) 40% (C) \n20% (D) 10% (E) 5%\nA: Among A through E, the answer is\nQ: If 120 is reduced to 96, what is the reduction \npercent? Answer Choices: (A) 30% (B) 40% (C) \n20% (D) 10% (E) 5%\nA: Let's think step by step.\nReasoning\nzero-shot\nzero-shot-CoT\nFigure 3: Illustration of reasoning tasks. We show\nthe instruction of AQUA-RAT (Ling et al., 2017) in\nthis figure. Other reasoning tasks have similar instruc-\ntions, e.g., \u201cThe answer (arabic numerals) is\u201d for Mul-\ntiArith (Roy and Roth, 2015). Note that we also con-\nduct zero-shot chain-of-thought (zero-shot-CoT) experi-\nments with ChatGPT and GPT-3.5 for reasoning tasks\n(right part).\net al., 2022; Lu et al., 2022b; Qin et al., 2023c) and\noptimizing the quality of reasoning chains (Khot\net al., 2022; Chen et al., 2022; Zhao et al., 2023). In\naddition, researchers also studied the feasibility of\nadopting CoT in multilingual scenarios (Shi et al.,\n2022) and in smaller language models (Magister\net al., 2022; Ho et al., 2022). More recently, Zhang\net al. (2023b) proposed Multimodal-CoT that incor-\nporates vision features in CoT reasoning, with the\nmodel under 1 billion parameters outperforming\nGPT-3.5 by 16% and even surpassing human per-\nformance on the ScienceQA benchmark (Lu et al.,\n2022a).\n3\nMethodology\nAs mentioned in Section 1, we mainly compare\nthe zero-shot learning performance of ChatGPT\n(gpt-3.5-turbo) and GPT-3.5 (text-davinci-003) on\ndifferent tasks. Given a task instruction P and a\ntest problem X that are concatenated as the input,\nthe model f is expected to generate a target text\nY = f(P, X) to address the test problem. The\ninstructions and input formats of different tasks are\nshown in Figure 2 and 3. For example, when the\nmodel performs sentiment analysis tasks, the task\ninstruction P is \u201cFor each snippet of text, label the\nsentiment of the text as positive or negative. The\nanswer should be exact \u2018positive\u2019 or \u2018negative\u2019.\u201d.\nAfter reading the instruction P and the input X \u201cit\n\u2019s a stunning lyrical work of considerable force and\ntruth.\u201d, the model is expected to generate the output\nY \u201cpositive\u201d.\nDifferent from this single-stage prompting\nmethod, we use the same two-stage prompting\nas Kojima et al. (2022) for zero-shot-CoT. In the\nfirst stage, we adopt \u201cLet\u2019s think step by step.\u201d as\nthe instruction P1 to induce the model to generate\nthe rationale R. In the second stage, we use the self-\ngenerated rationale R along with the original input\nX and the instruction P1 as the new input to guide\nthe model to generate the final answer. A new in-\nstruction P2, e.g., \u201cTherefore, among A through E,\nthe answer is\u201d, serves as the trigger sentence for ex-\ntracting the answer. All task instructions are taken\nfrom or inspired by Brown et al. (2020), Ouyang\net al. (2022), Zhang et al. (2023a) and Ding et al.\n(2022).\n4\nExperiments\nIn this section, we first describe the tasks and\ndatasets, and then present the experimental results.\n4.1\nTasks and Datasets\nWe evaluate ChatGPT and GPT-3.5 with 20 dif-\nferent datasets covering 7 representative task cat-\negories: reasoning (MultiArith (Roy and Roth,\n2015), GSM8K (Cobbe et al., 2021), AddSub (Hos-\nseini et al., 2014), AQUA-RAT (Ling et al.,\n2017), SingleEq (Koncel-Kedziorski et al., 2015),\nSVAMP (Patel et al., 2021), CSQA (Talmor\net al., 2019), StrategyQA (Geva et al., 2021),\nCOPA (Roemmele et al., 2011), Last Letter Con-\ncatenation (Wei et al., 2022), Coin Flip (Wei et al.,\n2022), Date Understanding, and Tracking Shuf-\nfled Objects (Srivastava et al., 2022)), natural lan-\nguage inference (RTE (Dagan et al., 2006) and\nCB (De Marneffe et al., 2019)), question answer-\ning (BoolQ (Clark et al., 2019)), dialogue (Mu-\nTual (Cui et al., 2020)), summarization (SAM-\nArithmetic\nCommonsense\nSymbolic\nMultiArith GSM8K AddSub AQuA SingleEq SVAMP CSQA StrategyQA\nCOPA\nLetter\nCoin\nMeasure\nAccuracy\n# Samples\n600\n1319\n395\n254\n508\n1000\n1221\n2290\n100\n500\n500\nLogical\nNLI\nQA\nDialogue\nSum\nNER\nSentiment\nDate\nObject\nRTE\nCB\nBoolQ\nMuTual\nSAMSum CoNLL\nSST2\nMeasure\nAccuracy\nROUGE\nF1\nAccuracy\n# Samples\n369\n750\n277\n56\n3270\n886\n819\n3453\n872\nTable 1: Information of different datasets. # Samples refers to the number of test samples.\nQ: Wendy was playing a video game and had 43 lives. In \na hard part of the game she lost 8 lives. If she got 39 more \nlives in the next level, how many lives would she have?\nA: The answer (arabic numerals) is\nChatGPT\nResponse: 74 lives.\n \nQ: Wendy was playing a video game and had 43 lives. In \na hard part of the game she lost 8 lives. If she got 39 more \nlives in the next level, how many lives would she have?\nA: The answer (arabic numerals) is\nGPT-3.5\nResponse: 120 lives.\n \nFigure 4: A case where ChatGPT corrects the mistake\nmade by GPT-3.5. We color the correct and wrong\nresponses in green and red, respectively.\nSum (Gliwa et al., 2019)), named entity recognition\n(CoNLL03 (Sang and De Meulder, 2003)), and\nsentiment analysis (SST2 (Socher et al., 2013)).\nAmong these datasets, there are 4 categories of rea-\nsoning tasks: arithmetic, commonsense, symbolic,\nand logical reasoning. The information of different\ndatasets is shown in Table 1. By default we use the\ntest split for all datasets if the labels are available\nfor evaluation. For COPA and CommonsenseQA,\nwe use the validation split. For StrategyQA, we\nuse the open-domain setting (question-only set)\nfrom BIG-bench collaboration (2021) following\nWei et al. (2022); Zhang et al. (2023a); Kojima et al.\n(2022).\n4.2\nExperimental Results\nWe now present and analyze the empirical results\nof different categories of tasks.\n4.2.1\nArithmetic Reasoning\nThe accuracy of ChatGPT and GPT-3.5 without\nor with chain-of-thought (CoT) on six arithmetic\nreasoning datasets is shown in Table 2. ChatGPT\noutperforms GPT-3.5 on five out of six datasets\nwithout CoT, demonstrating its strong arithmetic\nreasoning ability. Figure 4 shows a case where\nGPT-3.5 gives a wrong answer. On the left part of\nthe figure, ChatGPT accurately understands \u201clost\n8 lives\u201d and \u201cgot 39 more lives\u201d, resulting in the\ncorrect answer \u201c74 lives\u201d. However, GPT-3.5 gen-\nerates a wrong answer \u201c120 lives\u201d that is irrelevant\nto the information provided, indicating that GPT-\n3.5 does not understand the input question. Further-\nmore, ChatGPT achieves much better performance\nthan GPT-3.5 when using CoT in all cases.\n4.2.2\nCommonsense, Symbolic, and Logical\nReasoning\nTable 3 reports the accuracy of ChatGPT compared\nwith popular LLMs on seven commonsense, sym-\nbolic and logical reasoning datasets. We make two\nkey observations as follows:\nFirst, using CoT may not always provide bet-\nter performance in commonsense reasoning tasks.\nAccording to the analysis in Kojima et al. (2022),\nCoT methods often produce flexible and reason-\nable rationales but the final prediction is not correct\nin commonsense reasoning tasks. The results im-\nply that commonsense reasoning tasks may require\nmore fine-grained background knowledge and the\nissue can be mitigated by scaling model size (Wei\net al., 2022), mixture of denoisers (Tay et al., 2022),\nand majority voting on multiple predictions (self-\nconsistency) (Wang et al., 2022b).\nSecond, different from arithmetic reasoning,\nChatGPT performs worse than GPT-3.5 in many\ncases, indicating that the corresponding capabilities\nof GPT-3.5 are stronger.\n4.2.3\nNatural Language Inference\nIt is worth mentioning that different from senti-\nment analysis tasks (Section 4.2.8), after specifying\nthe desired output format (\u201centail\u201d or \u201cnot entail\u201d)\nof natural language inference in task instructions,\nChatGPT and GPT-3.5 can produce responses that\nexactly follow the requirement. Table 4 presents\nthe results of different models on two natural lan-\nguage inference tasks: RTE and CB. We can see\nthat ChatGPT can achieve much better performance\nthan GPT-3.5, FLAN, T0, and PaLM under the\nzero-shot setting. This demonstrates the superior\nzero-shot capability of ChatGPT to infer sentence\nModel\nMultiArith\nGSM8K\nAddSub\nAQUA-RAT\nSingleEq\nSVAMP\nN/A\nCoT\nN/A\nCoT\nN/A\nCoT\nN/A\nCoT\nN/A\nCoT\nN/A\nCoT\nZero-Shot Performance\ntext-davinci-002\n22.7\n78.7\n12.5\n40.7\n77.0\n74.7\n22.4\n33.5\n78.7\n78.7\n58.8\n63.7\ntext-davinci-003\n24.2\n83.7\n12.6\n59.5\n87.3\n81.3\n28.0\n40.6\n82.3\n86.4\n64.7\n73.6\nChatGPT\n79.8\n95.8\n23.8\n78.9\n88.6\n83.5\n28.0\n53.5\n89.4\n91.5\n74.8\n77.5\nFew-Shot Performance\nUL2\n5.0\n10.7\n4.1\n4.4\n18.5\n18.2\n20.5\n23.6\n18.0\n20.2\n10.1\n12.5\nLaMDA\n7.6\n44.9\n6.5\n14.3\n43.0\n51.9\n25.5\n20.6\n48.8\n58.7\n29.5\n37.5\ntext-davinci-002\n33.8\n91.7\n15.6\n46.9\n83.3\n81.3\n24.8\n35.8\n82.7\n86.6\n65.7\n68.9\nCodex\n44.0\n96.2\n19.7\n63.1\n90.9\n90.9\n29.5\n45.3\n86.8\n93.1\n69.9\n76.4\nPaLM\n42.2\n94.7\n17.9\n56.9\n93.9\n91.9\n25.2\n35.8\n86.5\n92.3\n69.4\n79.0\nTable 2: Accuracy (%) of different models without CoT (N/A) and with CoT on arithmetic reasoning datasets.\nFew-shot results are from Wei et al. (2022). We compare ChatGPT with popular techniques including UL2-20B,\nLaMDA-137B, PaLM-540B, and the different GPT-3.5 variants.\nModel\nCommonsense\nSymbolic\nLogical\nCSQA\nStrategyQA\nCOPA\nLast Letter\nCoin Flip\nDate\nObject\nN/A\nCoT\nN/A\nCoT\nN/A\nCoT\nN/A\nCoT\nN/A\nCoT\nN/A\nCoT\nN/A\nCoT\nZero-Shot Performance\ntext-davinci-002\n72.6\n64.6\n54.3\n54.8\n74.0\n85.0\n0.2\n57.6\n53.8\n91.4\n49.3\n67.5\n31.3\n52.9\ntext-davinci-003\n74.9\n70.0\n57.2\n61.1\n93.0\n64.0\n0.0\n54.4\n49.0\n97.8\n56.6\n77.0\n27.1\n39.7\nChatGPT\n73.7\n71.5\n61.1\n55.5\n78.0\n82.0\n0.4\n70.2\n21.8\n65.8\n48.0\n72.6\n31.6\n58.7\nFew-Shot Performance\nUL2\n34.2\n51.4\n59.0\n53.3\n-\n-\n0.6\n18.8\n70.4\n67.1\n13.5\n14.0\n-\n-\nLaMDA\n53.6\n57.9\n62.4\n65.4\n-\n-\n5.8\n77.5\n49.0\n99.6\n21.5\n26.8\n-\n-\ntext-davinci-002\n79.5\n73.5\n65.9\n65.4\n-\n-\n0.2\n59.0\n57.2\n97.2\n43.8\n52.1\n-\n-\nCodex\n82.3\n77.9\n67.1\n73.2\n-\n-\n-\n-\n-\n-\n49.0\n64.8\n-\n-\nPaLM\n78.1\n79.9\n68.6\n77.8\n95.0\n-\n7.6\n99.4\n98.1\n100.0\n49.0\n65.3\n23.9\n-\nTable 3: Accuracy (%) of different models without CoT (N/A) and with CoT on commonsense, symbolic and logical\nreasoning datasets. Few-shot results are from Wei et al. (2022). We compare ChatGPT with popular techniques\nincluding UL2-20B, LaMDA-137B, PaLM-540B, and the different GPT-3.5 variants.\nModel\nZero-Shot\nFine-Tuned\nChatGPT\nGPT-3.5\nFLAN\nT0\nPaLM\nPaLM\nRTE\n85.9\n80.1\n84.1\n80.8\n72.9\n95.8\nCB\n89.3\n83.9\n83.9\n70.1\n51.8\n100.0\nTable 4: Accuracy (%) of different models on natu-\nral language inference tasks (RTE and CB). We com-\npare zero-shot ChatGPT with recent models including\nGPT-3.5 (zero-shot) (Brown et al., 2020), FLAN (zero-\nshot) (Wei et al., 2021), T0 (zero-shot) (Sanh et al.,\n2021a), PaLM (zero-shot) (Chowdhery et al., 2022b)\nand PaLM-540B (fine-tuned) (Chowdhery et al., 2022b).\nModel\nChatGPT\nGPT-3.5\nEntailment\n92.5\n70.6\nNot Entailment\n78.6\n90.8\nTable 5: Per-class accuracy (%) of ChatGPT and GPT-\n3.5 on RTE.\nrelations.\nTo take a closer look at why ChatGPT outper-\nforms GPT-3.5 by a large margin, we report the\nper-class accuracy of both models in Table 5. Chat-\nGPT performs much better than GPT-3.5 when the\npremise does entail the hypothesis (+21.9%). How-\nModel\nZero-Shot\nFine-Tuned\nChatGPT\nGPT-3.5\nGopher\nChinchilla\nFLAN\nPaLM\nCompassMTL\nT5-11B\nDeBERTa\nAccuracy(%)\n87.3\n84.7\n79.3\n83.7\n82.9\n88.0\n88.3\n91.2\n90.4\nTable 6: Accuracy of different models on question an-\nswering (BoolQ). We compare ChatGPT with popular\nmethods including (i) zero-shot methods: Gopher (Rae\net al., 2021), Chinchilla (Hoffmann et al., 2022), GPT-\n3.5, FLAN (Wei et al., 2021), and PaLM (Chowd-\nhery et al., 2022b); (ii) fine-tuned models:\nCom-\npassMTL (Zhang et al., 2022), T5 (Raffel et al., 2020),\nDeBERTa (He et al., 2020).\never, it underperforms GPT-3.5 on the class \u201cNot\nEntailment\u201d (-12.2%). So we can see that ChatGPT\nis better at handling factual input (also favored by\nhumans in general), which might be related to the\npreference of the human feedback in its own RLHF\ndesign during model training.\n4.2.4\nQuestion Answering\nWe report the accuracy of different models on the\nBoolQ dataset (reading comprehension) in Table 6.\nChatGPT outperforms GPT-3.5 by over 2%. This\nis consistent with the results on natural language\nModel\nChatGPT\nGPT-3.5\nYes\n88.9 (+7.8)\n81.1\nNo\n84.6 (-6.0)\n90.6\nTable 7: Per-class accuracy (%) of ChatGPT and GPT-\n3.5 on BoolQ. The number in parentheses indicates the\nimprovement over GPT-3.5.\nQ: f : dad , can you lend jenny and me some money ? m : \nfor what ? f : we want to get tickets for a rock concert . \nwe 'll pay you back after a few days . m : how much are \nthese tickets ? f : $ 18.00 each . m : $ 18.00 ? that 's a \nlot of money . Which choice is correct ? Answer Choices: \n(A) f : actually , $ 18 in total . (B) f : yes , all in all , two \ntickets cost $ 44 . (C) f : yes , $ 36 in total . but $ 2 \ndiscount for two tickets , that is $ 36 in total . (D) f : yes , \n$ 36 in total .\nA: Among A through D, the answer is\nChatGPT\nResponse: D: f : yes, $ 36 in total.\n \nQ: f : dad , can you lend jenny and me some money ? m : \nfor what ? f : we want to get tickets for a rock concert . \nwe 'll pay you back after a few days . m : how much are \nthese tickets ? f : $ 18.00 each . m : $ 18.00 ? that 's a \nlot of money . Which choice is correct ? Answer Choices: \n(A) f : actually , $ 18 in total . (B) f : yes , all in all , two \ntickets cost $ 44 . (C) f : yes , $ 36 in total . but $ 2 \ndiscount for two tickets , that is $ 36 in total . (D) f : yes , \n$ 36 in total .\nA: Among A through D, the answer is\nGPT-3.5\nResponse: C: f : yes, $ 36 in total. but $ 2 discount for \ntwo tickets, that is $ 36 in total.\nFigure 5: A case where ChatGPT answers correctly\nwhile GPT-3.5 makes mistakes. The correct and wrong\nresponses are colored in green and red, respectively.\nGPT-3.5 appends irrelevant information \u201c$2 discount\nfor two tickets\u201d which is not mentioned in the context.\ninference. As illustrated in Clark et al. (2019), the\nquestions in BoolQ require difficult entailment-like\ninference to solve. Therefore, ChatGPT can better\nhandle tasks favoring reasoning capabilities.\nTable 7 shows the per-class accuracy of Chat-\nGPT and GPT-3.5. We can see that ChatGPT sig-\nnificantly outperforms GPT-3.5 on the class \u201cYes\u201d,\nindicating that ChatGPT prefers handling factual\ninput. In addition, although we require ChatGPT to\noutput \u201cYes\u201d or \u201cNo\u201d via task instructions, it still\ngenerates some other responses, e.g., \u201cIt is unclear\u201d,\nwhich could be one of the reasons why ChatGPT\nperforms worse than PaLM.\n4.2.5\nDialogue\nWe show the accuracy of ChatGPT and GPT-3.5 on\nthe MuTual dataset (multi-turn dialogue reasoning)\nin Table 8. As expected, ChatGPT achieves better\nperformance than GPT-3.5\u2014this is consistent with\nthe impressive dialogue ability of ChatGPT that\nhas already been observed in the community.\nAs a concrete example, Figure 5 shows a case\nwhere ChatGPT answers correctly while GPT-3.5\nis struggling. We can see that ChatGPT is able\nto reason more effectively about the given context\nwithout adding irrelevant information. This reiter-\nates the superior reasoning capability of ChatGPT.\n4.2.6\nSummarization\nFor the summarization task, the ROUGE scores of\nChatGPT and GPT-3.5 on the SAMSum dataset\nare reported in Table 9. Surprisingly, ChatGPT\nLabel: Eric and Rob are going to watch a stand-up on \nyoutube.\nGPT-3.5: Eric and Rob are going to watch some of a \ncomedian's stand-up on YouTube.\nChatGPT: Eric and Rob are discussing a stand-up \ncomedy routine involving a machine, and they find it \nfunny. They plan to watch more of the comedian's stand-\nup on YouTube and say \"TTYL\" before ending the \nconversation.\nLabel: Mark lied to Anne about his age. Mark is 40.\nGPT-3.5: Anne found out that Mark lied to her about \nhis age.\nChatGPT: Anne discovered that Mark, who she was \ndating, lied about his age and is actually 40, not 30 as \nhe had previously claimed. Irene expresses sympathy for \nAnne's situation.\nFigure 6: Comparison of summaries generated by GPT-\n3.5 and ChatGPT.\nunderperforms GPT-3.5 across all measures. We\nhypothesize that this is due to the fact that we do\nnot explicitly control the output length of ChatGPT.\nThe responses from ChatGPT are usually more\nverbose than those from GPT-3.5, resulting in lower\nROUGE scores.\nTo test our hypothesis, we calculate the average\nnumber of words for ground truth (20.0), GPT-3.5\u2019s\nresponses (23.3), and ChatGPT\u2019s responses (36.6).\nObviously, ChatGPT\u2019s responses are much longer.\nThis may result from its RLHF design. Figure 6\nshows several cases where the output of ChatGPT\nis much longer than that of GPT-3.5. We can ob-\nserve that there is much redundant information in\nthe output of ChatGPT.\nFurthermore, we conduct controlled experiments\nwith a new instruction that explicitly limits the out-\nput length: \u201cPlease summarize the given conver-\nsation in no more than 25 words.\u201d Although the\naverage number of words in ChatGPT\u2019s answers\nis reduced to 22.8, the average score of ROUGE-\n1/2/L drops from 31.0 to 30.6. So we conclude that\ncontrolling the length of summaries via zero-shot\ninstructions may harm ChatGPT\u2019s summarization\nability.\n4.2.7\nNamed Entity Recognition\nTable 10 reports the zero-shot performance of Chat-\nGPT and GPT-3.5 on CoNLL03, a widely-used\nnamed entity recognition dataset. We can see that\nthe overall performance of ChatGPT and GPT-3.5\nis quite similar. Unfortunately, they fail to achieve\nsatisfactory results on each named entity type com-\npared to previous fine-tuning methods. This shows\nthat current LLMs, although deemed as general-\nist models, still face challenges in solving specific\ntasks, such as sequence tagging.\nSpecifically, ChatGPT outperforms GPT-3.5 for\nclasses \u201cPer\u201d (\u201cPerson\u201d) and \u201cOrg\u201d (\u201cOrganiza-\ntion\u201d) while performing worse than GPT-3.5 on the\nclass \u201cLoc\u201d (\u201cLocation\u201d). Neither model shows\npractical value in identifying the \u201cMisc\u201d (\u201cMiscel-\nlaneous Entity\u201d) class. Figure 7 illustrates several\nfailure cases of \u201cMisc\u201d. On the left part of the fig-\nModel\nZero-Shot\nUnsupervised\nFine-Tuned\nChatGPT GPT-3.5\nTF-IDF\nDual LSTM DAM SMN BERT RoBERTa GPT-2-FT MDFN BiDeN\nAccuracy (%)\n76.2\n75.2\n27.6\n26.6\n23.9\n27.4\n65.7\n69.5\n39.8\n92.3\n93.5\nTable 8: Accuracy on the dialogue task (MuTual). Besides GPT-3.5, we also compare ChatGPT with previous\npopular methods including (i) unsupervised method: TF-IDF (Lowe et al., 2015); (ii) fine-tuned models: Dual\nLSTM (Lowe et al., 2015), DAM (Zhou et al., 2018), SMN (Wu et al., 2017), BERT (Devlin et al., 2019),\nRoBERTa (Liu et al., 2019), fine-tuned GPT-2 (GPT-2-FT) (Radford et al., 2019), MDFN (Liu et al., 2021), and\nBiDeN (Li et al., 2022b).\nModel\nzero-shot\nfine-tuned\nChatGPT\nGPT-3.5\nBART\nCODA\nROUGE-1\n42.4\n44.0\n49.1\n50.1\nROUGE-2\n17.6\n18.5\n24.3\n24.6\nROUGE-L\n33.0\n34.7\n45.8\n46.9\nTable 9: ROUGE scores of different models on the\nsummarization dataset: SAMSum. We compare zero-\nshot ChatGPT with GPT-3.5 (Zero-Shot), BART-large\n(Fine-Tuned) (Lewis et al., 2019), and CODA (fine-\ntuned) (Chen and Yang, 2021).\nModel\nZero-Shot\nFine-Tuned\nChatGPT\nGPT-3.5\nFlair\nLUKE\nACE\nAll\n53.2\n53.5\n93.0\n93.9\n94.6\nLoc\n66.7\n67.1\n94.0\n-\n-\nPer\n87.2\n78.0\n97.4\n-\n-\nOrg\n51.4\n50.0\n91.9\n-\n-\nMisc\n4.1\n4.8\n83.0\n-\n-\nTable 10: F1 scores of different models on named\nentity recognition (CoNLL03). \u201cLoc\u201d, \u201cPer\u201d, \u201cOrg\u201d,\nand \u201cMisc\u201d stand for \u201cLocation\u201d, \u201cPerson\u201d, \u201cOrga-\nnization\u201d, and \u201cMiscellaneous Entity\u201d, respectively.\nWe also compare the zero-shot ChatGPT with GPT-\n3.5 (zero-shot) and recent state-of-the-art named entity\nrecognition models including Flair (Akbik et al., 2018),\nLUKE (fine-tuned) (Yamada et al., 2020), and ACE\n(fine-tuned) (Wang et al., 2020).\nure, LLMs recognize \u201cBowling\u201d as a miscellaneous\nentity while the ground truth is \u2018None\u2019. However,\n\u201cBowling\u201d does belong to the entity type \u201cball\u201d,\nwhich can be regarded as a miscellaneous type.\nOn the right part, although \u201cAMERICAN FOOT-\nBALL CONFERENCE\u201d is indeed an organization,\nit is not recognized by the ground truth annotation,\nindicating that the ground truth annotation might\nneed cleaning (although in rare cases). Therefore,\nthe poor performance on the class \u201cMiscellaneous\nEntity\u201d may be partly due to the different under-\nstanding on the scope of entities between LLMs\nand the ground truth annotation of the specific task\ndataset.\nIn addition, we design new instructions that\nguide GPT-3.5 to generate different types of entities\nseparately, leading to a much lower F1 score (34.8).\nInput: Bowling : Wasim Akram 8.1-0-43-3 ( 9w , 1nb ) , \nWaqar Younis \nLabel: Miscellaneous: None\nResponse: Miscellaneous: Bowling \nInput: AMERICAN FOOTBALL CONFERENCE\nLabel: Miscellaneous: AMERICAN\nResponse: Organization: American Football Conference\n  Miscellaneous: None\nFigure 7: Example failure cases for the \u201cMiscellaneous\nEntity\u201d class (left for ChatGPT and right for GPT-3.5).\nThis reiterates the challenges faced by LLMs in\nsolving sequence tagging tasks.\n4.2.8\nSentiment Analysis\nTable 12 compares the accuracy of different models\non the sentiment analysis dataset: SST2. ChatGPT\nachieves much better performance than GPT-3.5.\nTo look into why ChatGPT outperforms GPT-3.5,\nwe calculate the per-class accuracy of both mod-\nels. We can observe that the performance of Chat-\nGPT on different classes is unbalanced. It outper-\nforms GPT-3.5 by a large margin on negative sam-\nples while the performance on positively-labeled\ndata comes close to that of GPT-3.5. We hypothe-\nsize that this difference is caused by the different\ntraining data of ChatGPT and GPT-3.5. In addi-\ntion, although we explicitly specified that the an-\nswer should be exact \u201cpositive\u201d or \u201cnegative\u201d in\ntask instructions (Figure 2), ChatGPT and GPT-3.5\nstill output some other answers, e.g., \u201cneutral\u201d and\n\u201cmixed\u201d, which partly explains why they perform\nmuch worse than FLAN.\n4.3\nChatGPT v.s. Full-Set or Few-Shot\nFine-Tuning\nTable 11 shows the performance comparison be-\ntween ChatGPT and the best previous full-set or\nfew-shot fine-tuning method (among those reported\nin this work) for each individual task. ChatGPT un-\nderperforms previous fine-tuning methods in most\ncases, indicating that ChatGPT is still far from a\nperfect generalist.\n5\nConclusion\nWe have empirically studied the zero-shot learning\ncapabilities of ChatGPT on a large, diverse collec-\nModel\nArithmetic\nSymbolic\nLogical\nMultiArith\nGSM8K\nAddSub\nAQUA-RAT\nSingleEq\nSVAMP\nLast Letter\nCoin Flip\nDate\nObject\nAccuracy\nAccuracy\nAccuracy\nChatGPT\n95.8\n78.9\n88.6\n53.5\n91.5\n77.5\n70.2\n65.8\n72.6\n58.7\nGPT-3.5\n83.7\n59.5\n87.3\n40.6\n86.4\n73.6\n54.4\n97.8\n77.0\n39.7\nFine-tuning\n96.2\n63.1\n93.9\n45.3\n93.1\n79.0\n99.4\n100.0\n65.3\n23.9\nModel\nCommonsense\nNLI\nQA\nDialogue\nSummarization\nNER\nSentiment\nCSQA\nStrategyQA\nCOPA\nRTE\nCB\nBoolQ\nMuTual\nSAMsum\nCoNLL03\nSST2\nAccuracy\nAccuracy\nAccuracy\nAccuracy\nROUGE\nF1\nAccuracy\nChatGPT\n73.7\n61.1\n82.0\n85.9\n89.3\n87.3\n76.2\n31.0\n53.2\n93.7\nGPT-3.5\n74.9\n61.1\n93.0\n80.1\n83.9\n84.7\n75.2\n32.4\n53.5\n88.8\nFine-tuning\n82.3\n77.8\n95.0\n95.8\n100.0\n91.2\n93.5\n40.5\n94.6\n97.5\nTable 11: Performance of ChatGPT, GPT-3.5 and the best previous full-set or few-shot fine-tuning method (among\nthose investigated in this work) on different tasks. For each reasoning dataset, the better result between zero-shot\nand zero-shot chain-of-thought is shown.\nModel\nZero-Shot\nFine-Tuned\nChatGPT\nGPT-3.5\nFLAN\nT5-11B\nAll\n93.7\n88.8\n94.6\n97.5\nPos\n90.8\n88.1\n-\n-\nNeg\n96.7\n89.5\n-\n-\nTable 12: Accuracy (%) of different models on senti-\nment analysis (SST2). We compare zero-shot Chat-\nGPT with recent models including GPT-3.5 (zero-\nshot) (Brown et al., 2020), FLAN (zero-shot) (Wei et al.,\n2021), and T5-11B (fine-tuned) (Raffel et al., 2019).\ntion of datasets covering representative task cate-\ngories. Extensive experimental results and analysis\ndemonstrated the effectiveness and current limita-\ntions of ChatGPT in different types of NLP tasks.\nFor example, as a powerful generalist model, on\none hand, ChatGPT is good at reasoning and dia-\nlogue tasks; on the other hand, ChatGPT still faces\nchallenges when solving specific tasks, such as se-\nquence tagging. We hope that this study can inspire\nfuture works, such as leveraging the reasoning and\ndialogue capabilities of ChatGPT in NLP tasks and\naddressing limitations of generalist models in tasks\nwhere they currently struggle with.\nLimitations\nThis work is an empirical study on the zero-shot\nlearning ability of ChatGPT3, and it has several\nlimitations. First, due to the cost of ChatGPT, this\nwork excludes larger-scale datasets and more task\ncategories, which might prevent further insights.\nBesides, we report the best result in the correspond-\ning paper for models that are not publicly available\n(e.g., PaLM) and report the result based on the\nbest prompt found for public models, which is con-\n3experiments done between 06/15/2023 and 06/21/2023\nsistent with the previous work (Wei et al., 2022;\nKojima et al., 2022; Tay et al., 2022). A further im-\nprovement could be to explore more diverse prompt\ntemplates. Finally, it still remains unclear to us how\nChatGPT\u2019s few-shot in-context learning capability\ncompares with its zero-shot learning ability across\ndifferent tasks.\nReferences\nAlan Akbik, Duncan Blythe, and Roland Vollgraf. 2018.\nContextual string embeddings for sequence labeling.\nIn Proceedings of the 27th international conference\non computational linguistics, pages 1638\u20131649.\nBIG-bench collaboration BIG-bench collaboration.\n2021. Beyond the imitation game: Measuring and\nextrapolating the capabilities of language models.\nhttps://github.com/google/BIG-bench.\n\"Ac-\ncessed: 2022-05-07\".\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-Voss,\nGretchen Krueger, Tom Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\nClemens Winter, Christopher Hesse, Mark Chen, Eric\nSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\nJack Clark, Christopher Berner, Sam McCandlish,\nAlec Radford, Ilya Sutskever, and Dario Amodei.\n2020. Language models are few-shot learners. In Ad-\nvances in Neural Information Processing Systems 33:\nAnnual Conference on Neural Information Process-\ning Systems 2020, NeurIPS 2020, December 6-12,\n2020, virtual.\nJiaao Chen and Diyi Yang. 2021. Simple conversa-\ntional data augmentation for semi-supervised abstrac-\ntive dialogue summarization. In Proceedings of the\n2021 Conference on Empirical Methods in Natural\nLanguage Processing, pages 6605\u20136616, Online and\nPunta Cana, Dominican Republic. Association for\nComputational Linguistics.\nWenhu Chen, Xueguang Ma, Xinyi Wang, and\nWilliam W Cohen. 2022.\nProgram of thoughts\nprompting: Disentangling computation from reason-\ning for numerical reasoning tasks. arXiv preprint\narXiv:2211.12588.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts,\nPaul Barham, Hyung Won Chung, Charles Sutton,\nSebastian Gehrmann, Parker Schuh, Kensen Shi,\nSasha Tsvyashchenko, Joshua Maynez, Abhishek\nRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-\nodkumar Prabhakaran, Emily Reif, Nan Du, Ben\nHutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\nToju Duke, Anselm Levskaya, Sanjay Ghemawat,\nSunipa Dev, Henryk Michalewski, Xavier Garcia,\nVedant Misra, Kevin Robinson, Liam Fedus, Denny\nZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,\nBarret Zoph, Alexander Spiridonov, Ryan Sepassi,\nDavid Dohan, Shivani Agrawal, Mark Omernick, An-\ndrew M. Dai, Thanumalayan Sankaranarayana Pil-\nlai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,\nRewon Child, Oleksandr Polozov, Katherine Lee,\nZongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark\nDiaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy\nMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,\nand Noah Fiedel. 2022a. Palm: Scaling language\nmodeling with pathways.\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin,\nMaarten Bosma, Gaurav Mishra, Adam Roberts, Paul\nBarham, Hyung Won Chung, Charles Sutton, Se-\nbastian Gehrmann, et al. 2022b.\nPalm: Scaling\nlanguage modeling with pathways. arXiv preprint\narXiv:2204.02311.\nPaul F Christiano, Jan Leike, Tom Brown, Miljan Mar-\ntic, Shane Legg, and Dario Amodei. 2017. Deep\nreinforcement learning from human preferences. Ad-\nvances in neural information processing systems, 30.\nHyung Won Chung, Le Hou, Shayne Longpre, Bar-\nret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al.\n2022. Scaling instruction-finetuned language models.\narXiv preprint arXiv:2210.11416.\nChristopher Clark, Kenton Lee, Ming-Wei Chang,\nTom Kwiatkowski, Michael Collins, and Kristina\nToutanova. 2019. BoolQ: Exploring the surprising\ndifficulty of natural yes/no questions. In Proceedings\nof the 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long and\nShort Papers), pages 2924\u20132936, Minneapolis, Min-\nnesota. Association for Computational Linguistics.\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian,\nMark Chen, Heewoo Jun, Lukasz Kaiser, Matthias\nPlappert, Jerry Tworek, Jacob Hilton, Reiichiro\nNakano, Christopher Hesse, and John Schulman.\n2021. Training verifiers to solve math word prob-\nlems.\nLeyang Cui, Yu Wu, Shujie Liu, Yue Zhang, and Ming\nZhou. 2020. MuTual: A dataset for multi-turn dia-\nlogue reasoning. In Proceedings of the 58th Annual\nMeeting of the Association for Computational Lin-\nguistics, pages 1406\u20131416, Online. Association for\nComputational Linguistics.\nIdo Dagan, Oren Glickman, and Bernardo Magnini.\n2006. The pascal recognising textual entailment chal-\nlenge. In Machine Learning Challenges. Evaluat-\ning Predictive Uncertainty, Visual Object Classifi-\ncation, and Recognising Tectual Entailment: First\nPASCAL Machine Learning Challenges Workshop,\nMLCW 2005, Southampton, UK, April 11-13, 2005,\nRevised Selected Papers, pages 177\u2013190. Springer.\nMarie-Catherine De Marneffe, Mandy Simons, and Ju-\ndith Tonhauser. 2019. The commitmentbank: Inves-\ntigating projection in naturally occurring discourse.\nIn proceedings of Sinn und Bedeutung, volume 23,\npages 107\u2013124.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4171\u20134186, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nBosheng Ding, Chengwei Qin, Linlin Liu, Lidong Bing,\nShafiq Joty, and Boyang Li. 2022. Is gpt-3 a good\ndata annotator? arXiv preprint arXiv:2212.10450.\nYao Fu, Hao Peng, Ashish Sabharwal, Peter Clark,\nand Tushar Khot. 2022. Complexity-based prompt-\ning for multi-step reasoning.\narXiv preprint\narXiv:2210.00720.\nZhenyong Fu, Tao Xiang, Elyor Kodirov, and Shao-\ngang Gong. 2017. Zero-shot learning on semantic\nclass prototype graph. IEEE transactions on pattern\nanalysis and machine intelligence, 40(8):2009\u20132022.\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot,\nDan Roth, and Jonathan Berant. 2021. Did aristotle\nuse a laptop? a question answering benchmark with\nimplicit reasoning strategies. Transactions of the\nAssociation for Computational Linguistics, 9:346\u2013\n361.\nBogdan Gliwa, Iwona Mochol, Maciej Biesek, and Alek-\nsander Wawer. 2019. Samsum corpus: A human-\nannotated dialogue dataset for abstractive summa-\nrization. arXiv preprint arXiv:1911.12237.\nBen Goertzel. 2014. Artificial general intelligence: con-\ncept, state of the art, and future prospects. Journal of\nArtificial General Intelligence, 5(1):1.\nBiyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang,\nJinran Nie, Yuxuan Ding, Jianwei Yue, and Yupeng\nWu. 2023. How close is chatgpt to human experts?\ncomparison corpus, evaluation, and detection. arXiv\npreprint arXiv:2301.07597.\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and\nWeizhu Chen. 2020. Deberta: Decoding-enhanced\nbert with disentangled attention.\narXiv preprint\narXiv:2006.03654.\nNamgyu Ho, Laura Schmid, and Se-Young Yun. 2022.\nLarge language models are reasoning teachers. arXiv\npreprint arXiv:2212.10071.\nJordan Hoffmann, Sebastian Borgeaud, Arthur Men-\nsch, Elena Buchatskaya, Trevor Cai, Eliza Ruther-\nford, Diego de Las Casas, Lisa Anne Hendricks,\nJohannes Welbl, Aidan Clark, et al. 2022. Train-\ning compute-optimal large language models. arXiv\npreprint arXiv:2203.15556.\nMohammad Javad Hosseini, Hannaneh Hajishirzi, Oren\nEtzioni, and Nate Kushman. 2014. Learning to solve\narithmetic word problems with verb categorization.\nIn Proceedings of the 2014 Conference on Empirical\nMethods in Natural Language Processing (EMNLP),\npages 523\u2013533, Doha, Qatar. Association for Com-\nputational Linguistics.\nTushar Khot, Harsh Trivedi, Matthew Finlayson, Yao\nFu, Kyle Richardson, Peter Clark, and Ashish Sab-\nharwal. 2022. Decomposed prompting: A modular\napproach for solving complex tasks. arXiv preprint\narXiv:2210.02406.\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\ntaka Matsuo, and Yusuke Iwasawa. 2022. Large lan-\nguage models are zero-shot reasoners. In Thirty-sixth\nConference on Neural Information Processing Sys-\ntems (NeurIPS 2022).\nRik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish\nSabharwal, Oren Etzioni, and Siena Dumas Ang.\n2015. Parsing algebraic word problems into equa-\ntions. Transactions of the Association for Computa-\ntional Linguistics, 3:585\u2013597.\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan\nGhazvininejad, Abdelrahman Mohamed, Omer Levy,\nVes Stoyanov, and Luke Zettlemoyer. 2019. Bart: De-\nnoising sequence-to-sequence pre-training for natural\nlanguage generation, translation, and comprehension.\nAitor Lewkowycz, Anders Andreassen, David Dohan,\nEthan Dyer, Henryk Michalewski, Vinay Ramasesh,\nAmbrose Slone, Cem Anil, Imanol Schlag, Theo\nGutman-Solo, et al. 2022.\nSolving quantitative\nreasoning problems with language models. arXiv\npreprint arXiv:2206.14858.\nYifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen,\nJian-Guang Lou, and Weizhu Chen. 2022a. On the\nadvance of making language models better reasoners.\narXiv preprint arXiv:2206.02336.\nYiyang Li, Hai Zhao, and Zhuosheng Zhang. 2022b.\nBack to the future: Bidirectional information decou-\npling network for multi-turn dialogue modeling. In\nThe 2022 Conference on Empirical Methods in Natu-\nral Language Processing (EMNLP 2022).\nPercy Liang, Rishi Bommasani, Tony Lee, Dimitris\nTsipras, Dilara Soylu, Michihiro Yasunaga, Yian\nZhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-\nmar, et al. 2022. Holistic evaluation of language\nmodels. ArXiv preprint, abs/2211.09110.\nWang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-\nsom. 2017. Program induction by rationale genera-\ntion: Learning to solve and explain algebraic word\nproblems. In Proceedings of the 55th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers), pages 158\u2013167, Vancouver,\nCanada. Association for Computational Linguistics.\nLongxiang Liu, Zhuosheng Zhang, Hai Zhao, Xi Zhou,\nand Xiang Zhou. 2021. Filling the gap of utterance-\naware and speaker-aware representation for multi-\nturn dialogue.\nIn Proceedings of the AAAI Con-\nference on Artificial Intelligence, volume 35, pages\n13406\u201313414.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692.\nRyan Lowe, Nissan Pow, Iulian Vlad Serban, and Joelle\nPineau. 2015. The ubuntu dialogue corpus: A large\ndataset for research in unstructured multi-turn dia-\nlogue systems. In Proceedings of the 16th Annual\nMeeting of the Special Interest Group on Discourse\nand Dialogue, pages 285\u2013294.\nPan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-\nWei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter\nClark, and Ashwin Kalyan. 2022a. Learn to explain:\nMultimodal reasoning via thought chains for science\nquestion answering. ArXiv preprint, abs/2209.09513.\nPan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu,\nSong-Chun Zhu, Tanmay Rajpurohit, Peter Clark,\nand Ashwin Kalyan. 2022b. Dynamic prompt learn-\ning via policy gradient for semi-structured mathemat-\nical reasoning. arXiv preprint arXiv:2209.14610.\nLucie Charlotte Magister, Jonathan Mallinson, Jakub\nAdamek, Eric Malmi, and Aliaksei Severyn. 2022.\nTeaching small language models to reason. ArXiv\npreprint, abs/2212.08410.\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer. 2022.\nRethinking the role of demonstra-\ntions: What makes in-context learning work? arXiv\npreprint arXiv:2202.12837.\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, and\nHannaneh Hajishirzi. 2022. Cross-task generaliza-\ntion via natural language crowdsourcing instructions.\nIn Proceedings of the 60th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 3470\u20133487.\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-\nroll L Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022.\nTraining language models to follow in-\nstructions with human feedback.\narXiv preprint\narXiv:2203.02155.\nArkil Patel, Satwik Bhattamishra, and Navin Goyal.\n2021. Are NLP models really able to solve simple\nmath word problems? In Proceedings of the 2021\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, pages 2080\u20132094, Online.\nAssociation for Computational Linguistics.\nChengwei Qin and Shafiq Joty. 2022a. Continual few-\nshot relation learning via embedding space regular-\nization and data augmentation. In Proceedings of the\n60th Annual Meeting of the Association for Compu-\ntational Linguistics (Volume 1: Long Papers), pages\n2776\u20132789, Dublin, Ireland. Association for Compu-\ntational Linguistics.\nChengwei Qin and Shafiq Joty. 2022b. LFPT5: A uni-\nfied framework for lifelong few-shot language learn-\ning based on prompt tuning of t5. In International\nConference on Learning Representations.\nChengwei Qin, Shafiq Joty, and Chen Chen. 2023a.\nLifelong sequence generation with dynamic mod-\nule expansion and adaptation.\narXiv preprint\narXiv:2310.09886.\nChengwei Qin, Shafiq Joty, Qian Li, and Ruochen Zhao.\n2023b. Learning to initialize: Can meta learning\nimprove cross-task generalization in prompt tuning?\nIn Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics (Volume 1:\nLong Papers), pages 11802\u201311832, Toronto, Canada.\nAssociation for Computational Linguistics.\nChengwei Qin, Aston Zhang, Anirudh Dagar, and\nWenming Ye. 2023c. In-context learning with it-\nerative demonstration selection.\narXiv preprint\narXiv:2310.09881.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, Ilya Sutskever, et al. 2019. Language\nmodels are unsupervised multitask learners. OpenAI\nblog, page 9.\nJack W Rae, Sebastian Borgeaud, Trevor Cai, Katie\nMillican, Jordan Hoffmann, Francis Song, John\nAslanides, Sarah Henderson, Roman Ring, Susan-\nnah Young, et al. 2021. Scaling language models:\nMethods, analysis & insights from training gopher.\narXiv preprint arXiv:2112.11446.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2019. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer.\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J. Liu. 2020. Exploring the limits\nof transfer learning with a unified text-to-text trans-\nformer. JMLR, 21(140):1\u201367.\nMelissa Roemmele, Cosmin Adrian Bejan, and An-\ndrew S Gordon. 2011.\nChoice of plausible alter-\nnatives: An evaluation of commonsense causal rea-\nsoning. In AAAI spring symposium: logical formal-\nizations of commonsense reasoning, pages 90\u201395.\nSubhro Roy and Dan Roth. 2015. Solving general arith-\nmetic word problems. In Proceedings of the 2015\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 1743\u20131752, Lisbon, Portu-\ngal. Association for Computational Linguistics.\nOhad Rubin, Jonathan Herzig, and Jonathan Berant.\n2022. Learning to retrieve prompts for in-context\nlearning. In Proceedings of the 2022 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, pages 2655\u20132671.\nErik F Sang and Fien De Meulder. 2003. Introduction\nto the conll-2003 shared task: Language-independent\nnamed entity recognition. arXiv preprint cs/0306050.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H.\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja,\nManan Dey, M Saiful Bari, Canwen Xu, Urmish\nThakker, Shanya Sharma Sharma, Eliza Szczechla,\nTaewoon Kim, Gunjan Chhablani, Nihal Nayak, De-\nbajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang,\nHan Wang, Matteo Manica, Sheng Shen, Zheng Xin\nYong, Harshit Pandey, Rachel Bawden, Thomas\nWang, Trishala Neeraj, Jos Rozen, Abheesht Sharma,\nAndrea Santilli, Thibault Fevry, Jason Alan Fries,\nRyan Teehan, Tali Bers, Stella Biderman, Leo Gao,\nThomas Wolf, and Alexander M. Rush. 2021a. Mul-\ntitask prompted training enables zero-shot task gen-\neralization.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Teven Le Scao, Arun\nRaja, et al. 2021b. Multitask prompted training en-\nables zero-shot task generalization. arXiv preprint\narXiv:2110.08207.\nFreda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang,\nSuraj Srivats, Soroush Vosoughi, Hyung Won Chung,\nYi Tay, Sebastian Ruder, Denny Zhou, et al. 2022.\nLanguage models are multilingual chain-of-thought\nreasoners. arXiv preprint arXiv:2210.03057.\nShaden Smith, Mostofa Patwary, Brandon Norick,\nPatrick LeGresley, Samyam Rajbhandari, Jared\nCasper, Zhun Liu, Shrimai Prabhumoye, George\nZerveas, Vijay Korthikanti, et al. 2022. Using deep-\nspeed and megatron to train megatron-turing nlg\n530b, a large-scale generative language model. arXiv\npreprint arXiv:2201.11990.\nRichard Socher, Alex Perelygin, Jean Wu, Jason\nChuang, Christopher D. Manning, A. Ng, and\nChristopher Potts. 2013. Recursive deep models for\nsemantic compositionality over a sentiment treebank.\nIn Conference on Empirical Methods in Natural Lan-\nguage Processing.\nAarohi Srivastava, Abhinav Rastogi, Abhishek Rao,\nAbu Awal Md Shoeb, Abubakar Abid, Adam Fisch,\nAdam R Brown, Adam Santoro, Aditya Gupta,\nAdri\u00e0 Garriga-Alonso, et al. 2022.\nBeyond the\nimitation game: Quantifying and extrapolating the\ncapabilities of language models.\narXiv preprint\narXiv:2206.04615.\nAlon Talmor, Jonathan Herzig, Nicholas Lourie, and\nJonathan Berant. 2019. CommonsenseQA: A ques-\ntion answering challenge targeting commonsense\nknowledge. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers), pages\n4149\u20134158, Minneapolis, Minnesota. Association for\nComputational Linguistics.\nYi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Gar-\ncia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng,\nNeil Houlsby, and Donald Metzler. 2022. Unify-\ning language learning paradigms.\narXiv preprint\narXiv:2205.05131.\nXiaolong Wang, Yufei Ye, and Abhinav Gupta. 2018.\nZero-shot recognition via semantic embeddings and\nknowledge graphs. In Proceedings of the IEEE con-\nference on computer vision and pattern recognition,\npages 6857\u20136866.\nXinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang,\nZhongqiang Huang, Fei Huang, and Kewei Tu. 2020.\nAutomated concatenation of embeddings for struc-\ntured prediction.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc\nLe, Ed Chi, and Denny Zhou. 2022a. Rationale-\naugmented ensembles in language models. arXiv\npreprint arXiv:2207.00747.\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,\nEd Chi, and Denny Zhou. 2022b. Self-consistency\nimproves chain of thought reasoning in language\nmodels. arXiv preprint arXiv:2203.11171.\nAlbert Webson and Ellie Pavlick. 2022. Do prompt-\nbased models really understand the meaning of their\nprompts? In Proceedings of the 2022 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, pages 2300\u20132344, Seattle, United States.\nAssociation for Computational Linguistics.\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin\nGuu, Adams Wei Yu, Brian Lester, Nan Du, An-\ndrew M Dai, and Quoc V Le. 2021. Finetuned lan-\nguage models are zero-shot learners. arXiv preprint\narXiv:2109.01652.\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Chi, Quoc Le, and Denny Zhou. 2022.\nChain of thought prompting elicits reasoning in large\nlanguage models. In Thirty-sixth Conference on Neu-\nral Information Processing Systems (NeurIPS 2022).\nYu Wu, Wei Wu, Chen Xing, Ming Zhou, and Zhoujun\nLi. 2017. Sequential matching network: A new archi-\ntecture for multi-turn response selection in retrieval-\nbased chatbots. In Proceedings of the 55th Annual\nMeeting of the Association for Computational Lin-\nguistics (Volume 1: Long Papers), pages 496\u2013505.\nIkuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki\nTakeda, and Yuji Matsumoto. 2020. Luke: Deep con-\ntextualized entity representations with entity-aware\nself-attention.\nMeng Ye and Yuhong Guo. 2017. Zero-shot classifi-\ncation with discriminative semantic representation\nlearning. In Proceedings of the IEEE conference\non computer vision and pattern recognition, pages\n7140\u20137148.\nEric Zelikman, Yuhuai Wu, and Noah D Goodman.\n2022. Star: Bootstrapping reasoning with reason-\ning. arXiv preprint arXiv:2203.14465.\nAston Zhang, Zachary C Lipton, Mu Li, and Alexander J\nSmola. 2021. Dive into deep learning. arXiv preprint\narXiv:2106.11342.\nLi Zhang, Tao Xiang, and Shaogang Gong. 2017. Learn-\ning a deep embedding model for zero-shot learning.\nIn Proceedings of the IEEE conference on computer\nvision and pattern recognition, pages 2021\u20132030.\nZhuosheng Zhang, Shuohang Wang, Yichong Xu,\nYuwei Fang, Wenhao Yu, Yang Liu, Hai Zhao, Chen-\nguang Zhu, and Michael Zeng. 2022. Task compass:\nScaling multi-task pre-training with task prefix. In\nFindings of The 2022 Conference on Empirical Meth-\nods in Natural Language Processing (EMNLP 2022).\nZhuosheng Zhang, Aston Zhang, Mu Li, and Alex\nSmola. 2023a. Automatic chain of thought prompt-\ning in large language models. In The Eleventh In-\nternational Conference on Learning Representations\n(ICLR 2023).\nZhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao,\nGeorge Karypis, and Alex Smola. 2023b.\nMulti-\nmodal chain-of-thought reasoning in language mod-\nels. arXiv preprint arXiv:2302.00923.\nRuochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei\nQin, and Lidong Bing. 2023. Verify-and-edit: A\nknowledge-enhanced chain-of-thought framework.\nIn Proceedings of the 61st Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers), pages 5823\u20135840, Toronto, Canada.\nAssociation for Computational Linguistics.\nDenny Zhou, Nathanael Sch\u00e4rli, Le Hou, Jason Wei,\nNathan Scales, Xuezhi Wang, Dale Schuurmans,\nOlivier Bousquet, Quoc Le, and Ed Chi. 2022.\nLeast-to-most prompting enables complex reason-\ning in large language models.\narXiv preprint\narXiv:2205.10625.\nXiangyang Zhou, Lu Li, Daxiang Dong, Yi Liu, Ying\nChen, Wayne Xin Zhao, Dianhai Yu, and Hua Wu.\n2018. Multi-turn response selection for chatbots with\ndeep attention matching network. In Proceedings\nof the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 1118\u20131127.\nA\nAppendix\nA.1\nExample Input and Output Pairs of\nChatGPT\nTable 13: Example input and output pairs for MultiArith (arithmetic reasoning).\nQ: Bianca had 45 coloring books. If she gave away 6 of them, but then bought 20 more, how many\nwould she have total?\nA: The answer (arabic numerals) is 59.\nQ: Janet was playing a video game and had 47 lives. In a hard part of the game she lost 23 lives. If\nshe got 46 more lives in the next level, how many lives would she have?\nA: The answer (arabic numerals) is 70 lives. You can find this by starting with the number of lives\nshe had at the beginning (47) and subtracting the number of lives she lost (23). Then add the number\nof lives she gained (46) to that number: 47 - 23 + 46 = 70.\nQ: A toy store had 17 giant stuffed bears in stock when they got another shipment with 10 bears in it.\nThe put the bears onto shelves with 9 on each shelf. How many shelves did they use?\nA: The answer (arabic numerals) is 3. Explanation: The toy store started with 17 bears, and got\nanother 10, for a total of 17+10 = 27 bears. To put these bears on shelves, they need 27 bears / 9 bears\nper shelf = 3 shelves.\nQ: A group of 3 friends went into a restaurant. The chef already had 6 chicken wings cooked but\ncooked 3 more for the group. If they each got the same amount how many would each person get?\nA: The answer (arabic numerals) is 3 chicken wings per person.\nQ: George had 28 socks. If he threw away 4 old ones that didn\u2019t fit and bought 36 new ones, how\nmany socks would he have?\nA: The answer (arabic numerals) is 60. George would have 60 socks. (28 + 36 = 60)\nQ: At the town carnival Billy rode the ferris wheel 7 times and the bumper cars 3 times. If each ride\ncost 5 tickets, how many tickets did he use?\nA: The answer (arabic numerals) is 40 tickets.\nQ: Kaleb had saved up 21 dollars. If he received another 15 dollars for his allowance, how many 6\ndollar toys could he buy?\nA: The answer (arabic numerals) is 5. He would have a total of 21 + 15 = 36 dollars, and could buy\n36 / 6 = 6 toys.\nQ: Tom was putting his spare change into piles. He had 2 piles of quarters and 4 piles of dimes. If\neach pile had 5 coins in it, how many coins did he have total?\nA: The answer (arabic numerals) is 50 coins. (2 piles of quarters * 5 coins per pile = 10 quarters) + (4\npiles of dimes * 5 coins per pile = 20 dimes) = 50 coins.\nQ: Isabel uploaded 25 pictures to Facebook. She put 10 pics into one album and put the rest into 5\ndifferent albums. How many pictures were in each album?\nA: The answer (arabic numerals) is 10 in one album and 5 in each of the other 5 albums.\nQ: For homework Faye had 13 math problems and 2 spelling problems. If she can finish 3 problems\nin an hour how long will it take her to finish all the problems?\nA: The answer (arabic numerals) is 8 hours. You can get this by adding the number of math problems\n(13) and spelling problems (2) to get a total of 15 problems. Then divide the total number of problems\n(15) by the number of problems Faye can finish in an hour (3) to get 5. Finally, divide 5 by 1 hour to\nget the answer of 5 hours.\nTable 14: Example input and output pairs for MultiArith with chain-of-thought (arithmetic reasoning).\nQ: Bianca had 45 coloring books. If she gave away 6 of them, but then bought 20 more, how many\nwould she have total?\nA: Let\u2019s think step by step. First, Bianca had 45 coloring books. Then, she gave away 6 of them, so\nshe had 45 - 6 = 39 coloring books. Finally, she bought 20 more, so she has 39 + 20 = 59 coloring\nbooks. Therefore, the answer (arabic numerals) is 59\nQ: Janet was playing a video game and had 47 lives. In a hard part of the game she lost 23 lives. If\nshe got 46 more lives in the next level, how many lives would she have?\nA: Let\u2019s think step by step. Janet had 47 lives, then lost 23, so she had 47-23=24 lives. Then, she got\n46 more lives, so she had 24+46=70 lives. Therefore, the answer (arabic numerals) is 70\nQ: A toy store had 17 giant stuffed bears in stock when they got another shipment with 10 bears in it.\nThe put the bears onto shelves with 9 on each shelf. How many shelves did they use?\nA: Let\u2019s think step by step. 17 + 10 = 27 bears. 27 bears / 9 bears/shelf = 3 shelves. Therefore, the\nanswer (arabic numerals) is 3\nQ: A group of 3 friends went into a restaurant. The chef already had 6 chicken wings cooked but\ncooked 3 more for the group. If they each got the same amount how many would each person get?\nA: Let\u2019s think step by step. Each person would get 3 chicken wings. Therefore, the answer (arabic\nnumerals) is 3\nQ: George had 28 socks. If he threw away 4 old ones that didn\u2019t fit and bought 36 new ones, how\nmany socks would he have?\nA: Let\u2019s think step by step. George had 28 socks, then threw away 4, so he has 28-4=24. Then he\nbought 36 new ones, so he has 24+36=60 socks. Therefore, the answer (arabic numerals) is 60.\nQ: At the town carnival Billy rode the ferris wheel 7 times and the bumper cars 3 times. If each ride\ncost 5 tickets, how many tickets did he use?\nA: Let\u2019s think step by step. Billy rode the ferris wheel 7 times, so he used 7 * 5 = 35 tickets. He also\nrode the bumper cars 3 times, so he used 3 * 5 = 15 tickets. Therefore, Billy used 35 + 15 = 50 tickets.\nTherefore, the answer (arabic numerals) is 50\nQ: Kaleb had saved up 21 dollars. If he received another 15 dollars for his allowance, how many 6\ndollar toys could he buy?\nA: Let\u2019s think step by step. Kaleb had 21 + 15 = 36 dollars. He can buy 36 / 6 = 6 toys. Therefore,\nthe answer (arabic numerals) is 6\nQ: Tom was putting his spare change into piles. He had 2 piles of quarters and 4 piles of dimes. If\neach pile had 5 coins in it, how many coins did he have total?\nA: Let\u2019s think step by step. Tom had 2 piles of quarters, which means he had 2 * 5 = 10 quarters. He\nalso had 4 piles of dimes, so he had 4 * 5 = 20 dimes. The total number of coins he had is 10 + 20 =\n30 coins. Therefore, the answer (arabic numerals) is 30\nQ: Isabel uploaded 25 pictures to Facebook. She put 10 pics into one album and put the rest into 5\ndifferent albums. How many pictures were in each album?\nA: Let\u2019s think step by step. Isabel put 10 pics into one album, so each of the 5 other albums had\n25-10=15 pics. Answer: 15 pics/album. Therefore, the answer (arabic numerals) is 15.\nQ: For homework Faye had 13 math problems and 2 spelling problems. If she can finish 3 problems\nin an hour how long will it take her to finish all the problems?\nA: Let\u2019s think step by step. 13 math problems + 2 spelling problems = 15 problems. 15 problems / 3\nproblems per hour = 5 hours. Therefore, the answer (arabic numerals) is 5 hours.\nTable 15: Example input and output pairs for GSM8K (arithmetic reasoning).\nQ: A store offers sandwiches in 3 different package sizes: the first package with 2 sandwiches for $3,\nthe second with 4 sandwiches for $6, and a third with 8 sandwiches, but the price is not indicated.\nKnowing that the prices are proportional, how much will the package with 8 sandwiches cost?\nA: The answer (arabic numerals) is 12 dollars.\nQ: The ratio of the electric poles and electric wires needed to connect and supply the electricity in a\ncertain neighborhood is 1:3. If the total number of electric wires needed to connect the electricity in\nthe neighborhood is 45, calculate the total number of electric poles required by an electric company\nto supply the electricity in the neighborhood.\nA: The answer (arabic numerals) is 15 electric poles are required. This is calculated by dividing the\ntotal number of electric wires (45) by the ratio of electric poles to electric wires (1:3). 45 / (1/3) = 45\n* 3 = 135, and 45 electric poles are needed.\nQ: My kitchen floor has a total area of 200 SqFt. I want to install new square floor tiles that cost $12\neach, and each tile side is 1ft in length. How much will it cost me to renovate my kitchen floor?\nA: The answer (arabic numerals) is 2400 dollars. Explanation: The area of the kitchen floor is 200\nsq ft, and each tile is 1 sq ft in area (1 ft x 1 ft = 1 sq ft). So the number of tiles needed to cover the\nkitchen floor is 200 sq ft / 1 sq ft/tile = 200 tiles. At a cost of $12 per tile, the total cost to cover the\nkitchen floor with these tiles would be 200 tiles x $12/tile = $2400.\nQ: Jeff and Brad are trying to divide 100 dollars between them. Jeff gets 4 times as much as Brad.\nHow much does Jeff get in dollars?\nA: The answer (arabic numerals) is 80 dollars.\nQ: To fund his store, Mr. Josue solicited money from two banks. The first bank gave him $4000, and\nthe second company gave him twice as much. If he initially had $5000 in capital, how much capital\ndoes he have now?\nA: The answer (arabic numerals) is $12000. The second bank gave him $4000 x 2 = $8000, so in\ntotal he received $4000 + $8000 = $12000 from the banks. Adding this to his initial capital of $5000,\nhe now has a total of $12000 + $5000 = $17000.\nQ: John drives for 3 hours at a speed of 60 mph and then turns around because he realizes he forgot\nsomething very important at home. He tries to get home in 4 hours but spends the first 2 hours in\nstandstill traffic. He spends the next half-hour driving at a speed of 30mph, before being able to drive\nthe remaining time of the 4 hours going at 80 mph. How far is he from home at the end of those 4\nhours?\nA: The answer (arabic numerals) is It is not possible to determine the distance John is from home at\nthe end of the 4 hours based on the information provided. This is because the information provided\nonly describes the time and speed of John\u2019s travel, but not the distance.\nQ: Mazie has 52 marbles and gives them to twins, Dallas and Darla. If Dallas has a total of 21 marbles\nafter dropping 4 of them in the playground, how many did Mazie give to Darla?\nA: The answer (arabic numerals) is 31 marbles.\nQ: There are 96 fourth-graders at Small Tree School. 43 of them are girls. On Friday, 5 fourth-grade\ngirls and 4 fourth-grade boys were absent. How many fourth grade boys were at Small Tree School\non Friday?\nA: The answer (arabic numerals) is 43 boys. To find out, you can start with the total number of\nfourth-graders (96) and subtract the number of girls (43) to find the number of boys. Then subtract\nthe number of absent boys (4) from that number to find the number of boys present on Friday. 96\nfourth-graders - 43 girls = 53 boys. 53 boys - 4 absent boys = 49 present boys.\nTable 16: Example input and output pairs for GSM8K with chain-of-thought (arithmetic reasoning).\nQ: A store offers sandwiches in 3 different package sizes: the first package with 2 sandwiches for $3,\nthe second with 4 sandwiches for $6, and a third with 8 sandwiches, but the price is not indicated.\nKnowing that the prices are proportional, how much will the package with 8 sandwiches cost?\nA: Let\u2019s think step by step. The first package costs $3 for 2 sandwiches, so each sandwich costs $3/2\n= $1.50. The second package costs $6 for 4 sandwiches, so each sandwich costs $6/4 = $1.50. Since\nthe price of each sandwich is the same, the third package with 8 sandwiches will cost 8 * $1.50 = $12.\nTherefore, the answer (arabic numerals) is $12\nQ: Jeff and Brad are trying to divide 100 dollars between them. Jeff gets 4 times as much as Brad.\nHow much does Jeff get in dollars?\nA: Let\u2019s think step by step. First, let\u2019s call Brad\u2019s share \"x\". If Jeff gets 4 times as much as Brad,\nthen Jeff gets 4x dollars. So, we know that x + 4x = 100 dollars. Combining like terms, we get 5x =\n100 dollars. Dividing both sides by 5, we find that x = 20 dollars. So, Jeff gets 4 * 20 = 80 dollars.\nTherefore, the answer (arabic numerals) is Jeff gets 80 dollars.\nQ: To fund his store, Mr. Josue solicited money from two banks. The first bank gave him $4000, and\nthe second company gave him twice as much. If he initially had $5000 in capital, how much capital\ndoes he have now?\nA: Let\u2019s think step by step. The first bank gave Mr. Josue $4000. The second bank gave him twice as\nmuch, which is 2*$4000 = $8000. So Mr. Josue received a total of $4000 + $8000 = $12000 from the\ntwo banks. Adding this to his initial capital of $5000, he now has a total of $12000 + $5000 = $17000\nin capital. Therefore, the answer (arabic numerals) is 17000.\nQ: John drives for 3 hours at a speed of 60 mph and then turns around because he realizes he forgot\nsomething very important at home. He tries to get home in 4 hours but spends the first 2 hours in\nstandstill traffic. He spends the next half-hour driving at a speed of 30mph, before being able to drive\nthe remaining time of the 4 hours going at 80 mph. How far is he from home at the end of those 4\nhours?\nA: Let\u2019s think step by step. First, John drove for 3 hours at 60 mph, so he covered a distance of\n3*60 = 180 miles. Then, he turned around and drove for 2 hours in standstill traffic, which covered\nno distance. After that, he drove for 0.5 hours at 30 mph, covering a distance of 0.5*30 = 15 miles.\nFinally, he drove for 1.5 hours at 80 mph, covering a distance of 1.5*80 = 120 miles. So in total, he\ncovered a distance of 180 + 0 + 15 + 120 = 315 miles. Therefore, the answer (arabic numerals) is 315\nmiles.\nQ: Mazie has 52 marbles and gives them to twins, Dallas and Darla. If Dallas has a total of 21 marbles\nafter dropping 4 of them in the playground, how many did Mazie give to Darla?\nA: Let\u2019s think step by step. Dallas originally had 21 + 4 = 25 marbles. So, the total number of marbles\nMazie gave to both twins is 25 + (total number of marbles Darla has) = 52. Therefore, Darla has 52 -\n25 = 27 marbles. Therefore, the answer (arabic numerals) is 27.\nQ: There are 96 fourth-graders at Small Tree School. 43 of them are girls. On Friday, 5 fourth-grade\ngirls and 4 fourth-grade boys were absent. How many fourth grade boys were at Small Tree School\non Friday?\nA: Let\u2019s think step by step. First, we know that there are 43 girls in the fourth grade at Small Tree\nSchool. If 5 of them were absent on Friday, then there were 43 - 5 = 38 girls present. Next, we\nknow that there are 96 fourth-graders total, and we know that 43 of them are girls. So, 96 - 43 = 53\nfourth-grade boys. Finally, if 4 of the 53 fourth-grade boys were absent on Friday, then 53 - 4 = 49\nfourth-grade boys were present on Friday. Therefore, the answer (arabic numerals) is 49.\nTable 17: Example input and output pairs for AddSub (arithmetic reasoning).\nQ: Shannon and her family use up a lot of strawberry and blueberry jelly , since they eat toast every\nmorning . At the moment , they have a combined total of 6310 grams of jelly . If they have 4518\ngrams of blueberry jelly , how many grams of strawberry jelly do they have ?\nA: The answer (arabic numerals) is 1792 grams.\nQ: Students at Arcadia schools are participating in a coat drive . 9437 coats have been collected so far\n. 6922 coats were collected from the high schools , and the rest from the elementary schools . How\nmany coats were collected at the elementary schools ?\nA: The answer (arabic numerals) is 2515 coats were collected at the elementary schools. This can\nbe found by subtracting the number of coats collected from the high schools (6922) from the total\nnumber of coats collected (9437). 9437 - 6922 = 2515.\nQ: An oil pipe in the sea broke . Before engineers started to fix the pipe , 6522 liters of oil leaked into\nthe water . While the engineers worked , the pipe leaked 5165 liters of oil . In all , how many liters of\noil leaked into the water ?\nA: The answer (arabic numerals) is 11,687 liters of oil leaked into the water. This can be determined\nby adding the initial amount of oil leaked (6522 liters) to the amount leaked while the engineers\nworked (5165 liters).\nQ: Tim \u2019s cat had kittens . He gave 3 to Jessica and 6 to Sara . He now has 9 kittens . How many\nkittens did he have to start with ?\nA: The answer (arabic numerals) is 18. Tim gave away 3 kittens to Jessica and 6 kittens to Sara, which\ntotals 9 kittens. To find out how many kittens he had to start with, you add the number of kittens he\ngave away to the number he still has, which is 9 + 9 = 18 kittens.\nQ: Mike went to 15 basketball games this year , but missed 41 . He went to 39 games last year . How\nmany basketball games did Mike go to in total ?\nA: The answer (arabic numerals) is 53 games. (Mike went to 15 games this year + 39 games last year\n= 54 games - the 1 game he missed = 53 games total)\nQ: A waitress put leftover tarts into the fridge on Thursday night . She noticed that the restau-\nrant had 0.08333333333333333 tart filled with cherries , 0.75 tart filled with blueberries , and\n0.08333333333333333 tart filled with peaches . How many leftover tarts did the restaurant have in all\n?\nA: The answer (arabic numerals) is 1.0833333333333333 tarts total.\nQ: There are 7 crayons in the drawer and 6 crayons on the desk . Sam placed 4 crayons and 8 scissors\non the desk . How many crayons are now there in total ?\nA: The answer (arabic numerals) is 15 crayons.\nQ: Bonnie \u2019s science class recorded the rainfall each day . They recorded 0.16666666666666666\ncentimeter of rain on Monday , 0.4166666666666667 centimeter of rain on Tuesday , and\n0.08333333333333333 centimeter of rain on Wednesday . How many centimeters of rain did the class\nrecord in all ?\nA: The answer (arabic numerals) is 0.7 centimeters of rain.\nTable 18: Example input and output pairs for AddSub with chain-of-thought (arithmetic reasoning).\nQ: Shannon and her family use up a lot of strawberry and blueberry jelly , since they eat toast every\nmorning . At the moment , they have a combined total of 6310 grams of jelly . If they have 4518\ngrams of blueberry jelly , how many grams of strawberry jelly do they have ?\nA: Let\u2019s think step by step. The total amount of jelly they have is 6310 grams, and of that, 4518 grams\nis blueberry jelly. To find out how much strawberry jelly they have, we can subtract the amount of\nblueberry jelly from the total amount of jelly: 6310 grams (total jelly) - 4518 grams (blueberry jelly)\n= 1792 grams (strawberry jelly). Therefore, the answer (arabic numerals) is 1792.\nQ: Students at Arcadia schools are participating in a coat drive . 9437 coats have been collected so far\n. 6922 coats were collected from the high schools , and the rest from the elementary schools . How\nmany coats were collected at the elementary schools ?\nA: Let\u2019s think step by step. Coats collected at elementary schools = Total coats collected - Coats\ncollected at high schools = 9437 - 6922 = 2515. Answer: 2515. Therefore, the answer (arabic\nnumerals) is 2515.\nQ: Tim \u2019s cat had kittens . He gave 3 to Jessica and 6 to Sara . He now has 9 kittens . How many\nkittens did he have to start with ?\nA: Let\u2019s think step by step. Tim had 9 kittens remaining after giving 3 to Jessica and 6 to Sara. To\nfind out how many kittens he had to start with, we need to add the number of kittens he gave away\nto the number of kittens he still has. 9 (remaining kittens) + 3 (kittens given to Jessica) + 6 (kittens\ngiven to Sara) = 18 total kittens. Therefore, Tim had 18 kittens to start with. Therefore, the answer\n(arabic numerals) is 18.\nQ: Mike went to 15 basketball games this year , but missed 41 . He went to 39 games last year . How\nmany basketball games did Mike go to in total ?\nA: Let\u2019s think step by step. Mike went to 15 games this year + 39 games last year = 54 total games.\nTherefore, the answer (arabic numerals) is 54.\nQ: There are 7 crayons in the drawer and 6 crayons on the desk . Sam placed 4 crayons and 8 scissors\non the desk . How many crayons are now there in total ?\nA: Let\u2019s think step by step. There were 7 crayons in the drawer and 6 crayons on the desk, for a total\nof 7 + 6 = 13 crayons. Sam placed 4 crayons and 8 scissors on the desk, bringing the total number\nof crayons on the desk to 6 + 4 = 10. Therefore, there are now a total of 13 (initial total) + 10 (new\ncrayons on the desk) = 23 crayons in total. Therefore, the answer (arabic numerals) is 23 crayons.\nQ: Bonnie \u2019s science class recorded the rainfall each day . They recorded 0.16666666666666666\ncentimeter of rain on Monday , 0.4166666666666667 centimeter of rain on Tuesday , and\n0.08333333333333333 centimeter of rain on Wednesday . How many centimeters of rain did the class\nrecord in all ?\nA: Let\u2019s think step by step. Monday: 0.16666666666666666 cm. Tuesday: 0.4166666666666667\ncm. Wednesday: 0.08333333333333333 cm. Total: 0.6666666666666666 cm. Therefore, the answer\n(arabic numerals) is 0.67 cm.\nTable 19: Example input and output pairs for AQUA-RAT (arithmetic reasoning).\nQ: A car finishes a journey in 20 hours at the speed of 60 km/hr. If the same distance is to be covered\nin 10 hours, how much speed does the car gain? Answer Choices: (A) 80 kmph (B) 50 kmph (C) 120\nkmph (D) 70 kmph (E) 80 kmph\nA: Among A through E, the answer is C) 120 kmph.\nQ: Q is as much younger than R as he is older than T. If the sum of the ages of R and T is 50 years.\nWhat is definitely the difference between R and Q\u2019s age? Answer Choices: (A) 22 (B) 27 (C) 29 (D)\nCannot be determined (E) None of the above\nA: Among A through E, the answer is (D) Cannot be determined. The information provided does not\ngive enough information to determine the specific difference between R and Q\u2019s age.\nQ: What is 60% of 30% of 1400 grams? Answer Choices: (A) 450 gms (B) 100 gms (C) 252 gms (D)\n240 gms (E) None of these\nA: Among A through E, the answer is (C) 252 gms. To calculate this, first calculate 30% of 1400\ngrams which is (30/100)*1400 = 420 grams. Then take 60% of 420 grams which is (60/100)*420 =\n252 grams.\nQ: An electric pole, 14 metres high, casts a shadow of 10 metres. Find the height of a tree that casts a\nshadow of 15 metres under similar conditions. Answer Choices: (A) 21 (B) 22 (C) 20 (D) 23 (E) 24\nA: Among A through E, the answer is (B) 22. This is a similar triangles problem. If we let \"x\" be the\nheight of the tree, then we can set up the following proportion: (14/10) = (x/15) Solving for x, we get:\nx = (14*15)/10 x = 21 Therefore, the height of the tree is 22m.\nQ: Alice wants to put up fencing around three sides of her rectangular yard and leave one side of 10\nmeters unfenced. If the yard has an area of 240 square meters, how many meters of fencing does she\nneed? Answer Choices: (A) 58 (B) 62 (C) 66 (D) 70 (E) 74\nA: Among A through E, the answer is (C) 66 meters of fencing.\nQ: At my favorite fruit stand, an orange costs 18 dollars, a pineapple costs 27 dollars, and a grape\ncosts 15 dollars. Using the same logic, can you tell how much a mango costs? Answer Choices: (A)\n22 dollars (B) 15 dollars (C) 20 dollars (D) 18 dollars (E) 10 dollars\nA: Among A through E, the answer is I\u2019m sorry, I am not able to determine the cost of a mango\nbased on the given information. The prices of the orange, pineapple, and grape do not provide enough\ninformation to infer the cost of a mango.\nQ: A rectangle has a length of 8 centimeters and a width of 3 centimeters. Find the perimeter. Answer\nChoices: (A) 18cm (B) 22cm (C) 20cm (D) 30cm (E) 28cm\nA: Among A through E, the answer is (E) 28cm. To find the perimeter of a rectangle, you add up the\nlengths of all four sides. In this case, the two sides of length 8cm and the two sides of width 3cm, so:\n8cm + 8cm + 3cm + 3cm = 28cm\nTable 20: Example input and output pairs for AQUA-RAT with chain-of-thought (arithmetic reasoning).\nQ: A car finishes a journey in 20 hours at the speed of 60 km/hr. If the same distance is to be covered\nin 10 hours, how much speed does the car gain? Answer Choices: (A) 80 kmph (B) 50 kmph (C) 120\nkmph (D) 70 kmph (E) 80 kmph\nA: Let\u2019s think step by step. We know that the car\u2019s original speed is 60 km/hr and it took 20 hours to\ncomplete the journey. To find the distance the car traveled, we can use the formula: distance = speed\nx time. So, distance = 60 km/hr x 20 hours = 1200 km. Now, we know that the car wants to cover the\nsame distance in 10 hours. To find the new speed, we can use the same formula, but with the new\ntime: speed = distance / time = 1200 km / 10 hours = 120 km/hr. Therefore, the car gains a speed of\n120 km/hr - 60 km/hr = 60 km/hr. So, the answer is (C) 120 kmph. Therefore, among A through E,\nthe answer is (C) 120 kmph.\nQ: Last year, a Home Appliance Store sold an average(arithmetic mean) of 42 microwave ovens per\nmonth. In the first 10 months of this year,the store has sold an average(arithmetic mean) of only 20\nmicrowave ovens per month. What was the average number of microwave ovens sold per month\nduring the entire 22 months period ? Answer Choices: (A) 21 (B) 30 (C) 31 (D) 32 (E) None of the\nabove\nA: Let\u2019s think step by step. The total number of microwave ovens sold in the first 10 months of\nthis year is 20*10 = 200. The total number of microwave ovens sold last year is 42*12 = 504. The\ntotal number of months is 10+12 = 22. So, the average number of microwave ovens sold per month\nduring the entire 22 months period is (504+200)/22 = 704/22 = 32. Therefore, the answer is (D) 32.\nTherefore, among A through E, the answer is (D) 32.\nQ: An electric pole, 14 metres high, casts a shadow of 10 metres. Find the height of a tree that casts a\nshadow of 15 metres under similar conditions. Answer Choices: (A) 21 (B) 22 (C) 20 (D) 23 (E) 24\nA: Let\u2019s think step by step. We can use the proportion of the shadow lengths to determine the height\nof the tree. We know that the electric pole\u2019s shadow is 14/10 = 7/5 the length of the electric pole\u2019s\nheight. So, if the tree\u2019s shadow is 15 metres, and we assume the same ratio of shadow to height as\nthe electric pole, we can set up the equation: (Tree\u2019s height) / 15 = (Electric pole\u2019s height) / (Electric\npole\u2019s shadow) Cross-multiplying and solving for the tree\u2019s height, we get: (Tree\u2019s height) = (15\n* Electric pole\u2019s height) / (Electric pole\u2019s shadow) = (15 * 14) / 10 = 21 So the answer is (A) 21.\nTherefore, among A through E, the answer is (A) 21.\nQ: At my favorite fruit stand, an orange costs 18 dollars, a pineapple costs 27 dollars, and a grape\ncosts 15 dollars. Using the same logic, can you tell how much a mango costs? Answer Choices: (A)\n22 dollars (B) 15 dollars (C) 20 dollars (D) 18 dollars (E) 10 dollars\nA: Let\u2019s think step by step. It is not possible to determine the cost of a mango based on the given\ninformation alone. The prices of the orange, pineapple, and grape do not provide any information\nabout how the cost of a mango might be determined. Additional information would be needed to\nmake an estimate. Therefore, among A through E, the answer is none of the above.\nQ: A rectangle has a length of 8 centimeters and a width of 3 centimeters. Find the perimeter. Answer\nChoices: (A) 18cm (B) 22cm (C) 20cm (D) 30cm (E) 28cm\nA: Let\u2019s think step by step. Perimeter is the sum of all sides of a shape. In the case of a rectangle, it is\nthe sum of the length and width multiplied by 2. So, the perimeter of a rectangle with a length of 8\ncentimeters and a width of 3 centimeters would be (8 + 3) x 2 = 11 x 2 = 22 centimeters. Therefore,\nthe answer is (B) 22cm. Therefore, among A through E, the answer is (B) 22cm.\nTable 21: Example input and output pairs for SingleEq (arithmetic reasoning).\nQ: Wendy ran 19.833333333333332 miles and walked 9.166666666666666 miles. How much farther\ndid Wendy run than walk?\nA: The answer (arabic numerals) is 10.666666666666666 miles.\nQ: The junior ranger asked Christian to help him place 420 seedlings in packets. If every packet\nneeds to contain 7 seeds, how many packets do they need?\nA: The answer (arabic numerals) is 60 packets. This can be found by dividing the total number of\nseedlings (420) by the number of seeds per packet (7), which equals 60.\nQ: In Shannon\u2019s apartment complex, 0.16666666666666666 of the apartments are one-bedroom\napartments and 0.3333333333333333 are two-bedroom apartments. What fraction of the apartments\nare either one- or two-bedroom apartments?\nA: The answer (arabic numerals) is 0.5 (or 50%). To get this answer, you add the fractions of\none-bedroom and two-bedroom apartments: 0.16666666666666666 + 0.3333333333333333 = 0.5.\nThis represents half of the apartments in the complex.\nQ: Maria needs 21 cartons of berries to make a berry cobbler. She already has 4 cartons of strawberries\nand 8 cartons of blueberries. How many more cartons of berries should Maria buy?\nA: The answer (arabic numerals) is 9 cartons. Maria already has 4 cartons of strawberries and 8\ncartons of blueberries for a total of 4+8 = 12 cartons. To make the cobbler she needs 21 cartons, so\nshe needs to buy 21-12 = 9 more cartons of berries.\nQ: During a visit to an orchard, Charlie picked 0.16666666666666666 of a bag of Golden Delicious\napples, 0.16666666666666666 of a bag of Macintosh apples, and 0.3333333333333333 of a bag of\nCortland apples. How many bags of fruit did Charlie pick in total?\nA: The answer (arabic numerals) is 1 bag. You can add the fractions of each bag of fruit together to\nget 0.16666666666666666 + 0.16666666666666666 + 0.3333333333333333 = 0.6666666666666666,\nwhich simplifies to 1 bag.\nQ: For his long distance phone service Milan pays a 2 dollars monthly fee plus 12 cents per minute.\nLast month , Milan \u2019s long distance bill was 23.36 dollars. For how many minutes was Milan billed\nfor ?\nA: The answer (arabic numerals) is 194 minutes.\nQ: When Joan was visited by the toothfairy, she received 14 each of quarters, half-dollars, and dimes.\nHow much money did the toothfairy leave Joan?\nA: The answer (arabic numerals) is $11.50. Explanation: The toothfairy left Joan 14 quarters, which is\n14 x $0.25 = $3.50 The toothfairy left Joan 14 half-dollars, which is 14 x $0.50 = $7.00 The toothfairy\nleft Joan 14 dimes, which is 14 x $0.10 = $1.40 So in total, the toothfairy left Joan $3.50 + $7.00 +\n$1.40 = $11.50.\nQ: In one week, an airplane pilot flew 1134 miles on Tuesday and 1475 miles on Thursday. If the\npilot flies the same number of miles 3 weeks in a row, how many miles does the pilot fly in all?\nA: The answer (arabic numerals) is 9408 miles. This can be calculated by taking the number of miles\nflown on Tuesday and Thursday (1134 + 1475 = 2609) and multiplying it by 3 (2609 x 3 = 9408).\nTable 22: Example input and output pairs for SingleEq with chain-of-thought (arithmetic reasoning).\nQ: Wendy ran 19.833333333333332 miles and walked 9.166666666666666 miles. How much farther\ndid Wendy run than walk?\nA: Let\u2019s think step by step. Wendy ran 19.833333333333332 miles and walked 9.166666666666666\nmiles. To find the difference between the two, we can subtract the number of miles walked from the\nnumber of miles ran: 19.833333333333332 - 9.166666666666666 = 10.666666666666664 miles.\nSo Wendy ran 10.666666666666664 miles farther than she walked. Therefore, the answer (arabic\nnumerals) is 10.67 miles.\nQ: The junior ranger asked Christian to help him place 420 seedlings in packets. If every packet\nneeds to contain 7 seeds, how many packets do they need?\nA: Let\u2019s think step by step. They need to place 420 seedlings in packets. To find out how many\npackets they need, we need to divide 420 by 7 (the number of seeds per packet). 420 divided by 7 is\n60. So they need 60 packets. Therefore, the answer (arabic numerals) is 60.\nQ: In Shannon\u2019s apartment complex, 0.16666666666666666 of the apartments are one-bedroom\napartments and 0.3333333333333333 are two-bedroom apartments. What fraction of the apartments\nare either one- or two-bedroom apartments?\nA: Let\u2019s think step by step. 0.16666666666666666 + 0.3333333333333333 = 0.5, so 0.5 of the\napartments are either one- or two-bedroom apartments. Therefore, the answer (arabic numerals) is\n0.5.\nQ: Maria needs 21 cartons of berries to make a berry cobbler. She already has 4 cartons of strawberries\nand 8 cartons of blueberries. How many more cartons of berries should Maria buy?\nA: Let\u2019s think step by step. Maria has 4 + 8 = 12 cartons of berries already. She needs 21 - 12 = 9\nmore cartons of berries. Therefore, the answer (arabic numerals) is 9.\nQ: For his long distance phone service Milan pays a 2 dollars monthly fee plus 12 cents per minute.\nLast month , Milan \u2019s long distance bill was 23.36 dollars. For how many minutes was Milan billed\nfor ?\nA: Let\u2019s think step by step. First, we can subtract the monthly fee from the total bill to find the cost of\nthe minutes: $23.36 - $2 = $21.36. Next, we can divide this amount by the cost per minute to find\nthe number of minutes: $21.36 / $0.12/minute = 178 minutes. Therefore, Milan was billed for 178\nminutes. Therefore, the answer (arabic numerals) is 178 minutes.\nQ: When Joan was visited by the toothfairy, she received 14 each of quarters, half-dollars, and dimes.\nHow much money did the toothfairy leave Joan?\nA: Let\u2019s think step by step. The toothfairy left Joan 14 quarters, which is 14 * $0.25 = $3.50. She\nalso left 14 half-dollars, which is 14 * $0.50 = $7.00. And 14 dimes, which is 14 * $0.10 = $1.40.\nAdding all these amounts, the total amount of money the toothfairy left Joan is $3.50 + $7.00 + $1.40\n= $12.00. Therefore, the answer (arabic numerals) is 12.00.\nQ: In one week, an airplane pilot flew 1134 miles on Tuesday and 1475 miles on Thursday. If the\npilot flies the same number of miles 3 weeks in a row, how many miles does the pilot fly in all?\nA: Let\u2019s think step by step. The pilot flew 1134 miles on Tuesday and 1475 miles on Thursday, so in\none week they flew a total of 1134 + 1475 = 2609 miles. If the pilot flies the same number of miles 3\nweeks in a row, they would fly a total of 2609 miles x 3 = 7827 miles. Therefore, the answer (arabic\nnumerals) is 7827.\nTable 23: Example input and output pairs for SVAMP (arithmetic reasoning).\nQ: Because of the decision Sofia asked the students to suggest specific types of food. If 479 students\nsuggested adding mashed potatoes while 489 suggested adding bacon to the menu How many more\nstudents suggested bacon than those that suggested mashed potatoes?\nA: The answer (arabic numerals) is 10 more students suggested bacon than those that suggested\nmashed potatoes.\nQ: Matthew gave equal numbers of crackers to his 18 friends. If he had 36 crackers How many\ncrackers did each person eat?\nA: The answer (arabic numerals) is 2 crackers per person. (Matthew divided 36 crackers equally\namong 18 friends, so each person received 36/18 = 2 crackers.)\nQ: Josh had some marbles in his collection. He lost 21 marbles. If he has 12 marbles now How many\nmarbles did he have in his collection?\nA: The answer (arabic numerals) is 33 marbles. (Josh had 12 marbles + 21 marbles lost = 33 marbles\ntotal in his collection)\nQ: Because of the decision Sofia asked the students to suggest specific types of food. 457 students\nsuggested adding mashed potatoes while others suggested adding bacon to the menu. If 63 more\nstudents suggested adding mashed potatoes than those that suggested bacon How many students\nsuggested bacon?\nA: The answer (arabic numerals) is 194 students suggested adding bacon to the menu. You can use\nalgebra to solve this problem: Let x be the number of students who suggested adding bacon. We know\nthat x + 63 = 457 (because 63 more students suggested mashed potatoes than bacon) So x = 457 - 63.\nx = 394\nQ: For Gwen\u2019s birthday she received 2 dollars from her mom. Her dad gave her 4 more dollars. If she\nspent 3 dollars. How much money did she still have?\nA: The answer (arabic numerals) is 5 dollars. Explanation: Gwen starts with 2 dollars from her mom\n+ 4 dollars from her dad = 6 dollars. Then she spent 3 dollars, so she still has 6 dollars - 3 dollars = 5\ndollars left.\nQ: Rachel had to complete 8 pages of math homework. If she had to complete 3 more pages of math\nhomework than reading homework How many pages did she have to complete in all?\nA: The answer (arabic numerals) is unknown, as the number of pages of reading homework that\nRachel had to complete is not provided.\nQ: In a school there are 868 girls and the rest are boys. If there are 281 more girls than boys How\nmany pupils are there in that school?\nA: The answer (arabic numerals) is 1247 pupils. To find out, you can use the information given in the\nproblem to set up an equation: x = number of boys. 868 = number of girls. x + 868 = total number of\npupils. You also know that there are 281 more girls than boys: 868 - x = 281. You can substitute the\nsecond equation into the first equation: x + 868 = x + 868 + 281. Solving for x gives you the number\nof boys, which you can then add to the number of girls to find the total number of pupils. x = 868 -\n281. x = 587. 868 + 587 = 1255\nTable 24: Example input and output pairs for SVAMP with chain-of-thought (arithmetic reasoning).\nQ: Because of the decision Sofia asked the students to suggest specific types of food. If 479 students\nsuggested adding mashed potatoes while 489 suggested adding bacon to the menu How many more\nstudents suggested bacon than those that suggested mashed potatoes?\nA: Let\u2019s think step by step. The difference in the number of students who suggested adding bacon\nand those who suggested adding mashed potatoes is 489 - 479 = 10 students. So, 10 more students\nsuggested adding bacon than those that suggested mashed potatoes. Therefore, the answer (arabic\nnumerals) is 10.\nQ: Matthew gave equal numbers of crackers to his 18 friends. If he had 36 crackers How many\ncrackers did each person eat?\nA: Let\u2019s think step by step. Matthew had 36 crackers and gave them to 18 friends, so we can divide\n36 by 18 to find out how many crackers each person received. 36 \u00f7 18 = 2. So, each person ate 2\ncrackers. Therefore, the answer (arabic numerals) is 2.\nQ: Mary is baking a cake. The recipe calls for 11 cups of sugar 6 cups of flour and 9 cups of salt. She\nalready put in 12 cups of flour. How many more cups of sugar than cups of salt does she need to add\nnow?\nA: Let\u2019s think step by step. She needs 6 cups of flour - 12 cups of flour = -6 cups of flour. So, she\ndoes not need to add any more flour. She needs to add 11 cups of sugar - the amount she already\nadded = 11 cups of sugar. She needs to add 9 cups of salt - the amount she already added = 9 cups of\nsalt. Therefore, she needs 11 cups of sugar - 9 cups of salt = 2 more cups of sugar than salt. Therefore,\nthe answer (arabic numerals) is 2.\nQ: Josh had some marbles in his collection. He lost 21 marbles. If he has 12 marbles now How many\nmarbles did he have in his collection?\nA: Let\u2019s think step by step. Josh originally had 21 + 12 = 33 marbles in his collection before he lost\nany. Therefore, the answer (arabic numerals) is 33.\nQ: For Gwen\u2019s birthday she received 2 dollars from her mom. Her dad gave her 4 more dollars. If she\nspent 3 dollars. How much money did she still have?\nA: Let\u2019s think step by step. Gwen received 2 dollars from her mom + 4 dollars from her dad = 6\ndollars total. Then if she spent 3 dollars, she would have 6 dollars - 3 dollars = 3 dollars remaining.\nTherefore, the answer (arabic numerals) is 3 dollars.\nQ: Rachel had to complete 8 pages of math homework. If she had to complete 3 more pages of math\nhomework than reading homework How many pages did she have to complete in all?\nA: Let\u2019s think step by step. Rachel had to complete 3 more pages of math homework than reading\nhomework, so if we let x be the number of pages of reading homework she had to complete, then\nthe number of pages of math homework she had to complete is x+3. Therefore, the total number of\npages she had to complete is x+ (x+3) = 8 pages. So, 2x + 3 = 8. Solving for x, we get x = 2.5. So\nRachel had to complete 2.5 pages of reading homework and 5.5 pages of math homework (3 more\nthan reading homework) in all. Therefore, the answer (arabic numerals) is 10 pages.\nQ: In a school there are 868 girls and the rest are boys. If there are 281 more girls than boys How\nmany pupils are there in that school?\nA: Let\u2019s think step by step. The number of boys in the school is 868 girls - 281 girls = 587 boys. The\ntotal number of pupils in the school is 868 girls + 587 boys = 1455 pupils. Therefore, the answer\n(arabic numerals) is 1455.\nTable 25: Example input and output pairs for CSQA (commonsense reasoning).\nQ: What are candles good for eliminating? Answer Choices: (A) shelf (B) board (C) church (D) table\n(E) dark\nA: Among A through E, the answer is E) dark. Candles are often used to provide light in dark places,\nsuch as during power outages or in camping situations.\nQ: How does going jogging generally affect one\u2019s self esteem? Answer Choices: (A) feel better (B)\nfeel pride (C) sweating (D) ocean (E) arthritis\nA: Among A through E, the answer is A) feel better. Going jogging can have a positive impact\non one\u2019s self esteem as it can release endorphins, also known as \"feel-good\" chemicals, which can\nimprove mood and reduce stress. It also can help to improve the physical appearance and overall\nphysical health, which can boost self-confidence and self-esteem.\nQ: James know that committing murder was wrong, but he thought that he could get away with it. He\nwas really troubled and fearful because of what? Answer Choices: (A) happiness (B) problems (C)\nprosecution (D) distress (E) misery\nA: Among A through E, the answer is (C) prosecution.\nQ: How can someone die from eating hamburger? Answer Choices: (A) gas (B) getting full (C) mad\ncow disease (D) death (E) feel full\nA: Among A through E, the answer is (C) mad cow disease. Mad cow disease, also known as bovine\nspongiform encephalopathy (BSE), is a rare but serious condition that can occur in cattle. When a\nperson eats meat from a cow infected with BSE, they can develop a similar disease called variant\nCreutzfeldt-Jakob disease (vCJD). vCJD is a fatal neurological disorder.\nQ: If there is a pond with trees around it, where it it likely located? Answer Choices: (A) ground (B)\nbathroom (C) forest (D) countryside (E) rural area\nA: Among A through E, the answer is (D) countryside or (E) rural area. A pond with trees around\nit is most likely found in a natural setting such as the countryside or a rural area, rather than in a\nman-made structure like a bathroom or indoors on the ground.\nQ: Why would a woman kill a stranger she met in a dark alley? Answer Choices: (A) being raped (B)\nget rid of (C) they didn\u2019t know the passcode (D) get revenge (E) were evil\nA: Among A through E, the answer is D) get revenge. The woman may have felt that the stranger had\nwronged her in some way and wanted to take revenge. However, it is important to note that without\nmore information, it is impossible to say for certain why the woman killed the stranger. Additionally,\nit should be noted that violence is not an acceptable form of revenge and there are other ways to\nresolve conflicts.\nQ: What would you do if you have curiosity but are blind and paralyzed? Answer Choices: (A) hear\nnews (B) analyse (C) go somewhere (D) examine thing (E) see favorite show\nA: Among A through E, the answer is A and B. I would hear news and analyze it as I am a language\nmodel, and I can process and understand spoken or written information.\nQ: You should watch out for snakes if floating down what African body of water? Answer Choices:\n(A) wet grass (B) western texas (C) high grass (D) amazon river (E) tree\nA: Among A through E, the answer is (C) high grass. Snakes are often found in tall grass and can be\na danger if floating down a body of water that has a lot of high grass along the banks.\nTable 26: Example input and output pairs for CSQA with chain-of-thought (commonsense reasoning).\nQ: What are candles good for eliminating? Answer Choices: (A) shelf (B) board (C) church (D) table\n(E) dark\nA: Let\u2019s think step by step. Candles are commonly used to provide light, so (E) dark is a good answer\nchoice. Therefore, among A through E, the answer is (E) dark.\nQ: How does going jogging generally affect one\u2019s self esteem? Answer Choices: (A) feel better (B)\nfeel pride (C) sweating (D) ocean (E) arthritis\nA: Let\u2019s think step by step. A: (A) feel better, (B) feel pride. Therefore, among A through E, the\nanswer is A: (A) feel better, (B) feel pride.\nQ: James know that committing murder was wrong, but he thought that he could get away with it. He\nwas really troubled and fearful because of what? Answer Choices: (A) happiness (B) problems (C)\nprosecution (D) distress (E) misery\nA: Let\u2019s think step by step. James committed murder and was aware that it was wrong. He thought he\ncould get away with it, but was troubled and fearful. Based on this information, the answer would be\n(C) prosecution. Therefore, among A through E, the answer is (C) prosecution.\nQ: How can someone die from eating hamburger? Answer Choices: (A) gas (B) getting full (C) mad\ncow disease (D) death (E) feel full\nA: Let\u2019s think step by step. (C) mad cow disease. Therefore, among A through E, the answer is (C)\nmad cow disease. Mad cow disease, also known as bovine spongiform encephalopathy (BSE), is a\nrare but serious condition that can be transmitted to humans who eat contaminated beef. In severe\ncases, it can cause a variant of Creutzfeldt-Jakob disease, which can be fatal.\nQ: If there is a pond with trees around it, where it it likely located? Answer Choices: (A) ground (B)\nbathroom (C) forest (D) countryside (E) rural area\nA: Let\u2019s think step by step. (D) countryside or (E) rural area. Therefore, among A through E, the\nanswer is (D) countryside or (E) rural area.\nQ: What would you do if you have curiosity but are blind and paralyzed? Answer Choices: (A) hear\nnews (B) analyse (C) go somewhere (D) examine thing (E) see favorite show\nA: Let\u2019s think step by step. Option A: Hear news - this is a good choice as it would allow you to stay\ninformed and engaged with current events. Option B: Analyze - This could also be a good choice as\nit would allow you to engage your mind and think critically. Option C: Go somewhere - This may\nnot be a feasible option as you are paralyzed. Option D: Examine things - This may not be a feasible\noption as you are blind. Option E: See favorite show - This may not be a feasible option as you are\nblind. Considering the limitations you have, options A and B may be the most feasible for you to\nsatisfy your curiosity. Therefore, among A through E, the answer is A and B: Hear news and Analyze.\nQ: You should watch out for snakes if floating down what African body of water? Answer Choices:\n(A) wet grass (B) western texas (C) high grass (D) amazon river (E) tree\nA: Let\u2019s think step by step. The answer is (D) the Nile River. Therefore, among A through E, the\nanswer is (E) tree, as this is the only one that is not a body of water.\nTable 27: Example input and output pairs for StrategyQA (commonsense reasoning).\nQ: Did mercenaries fight for England in the Glorious Revolution?\nA: The answer (Yes or No) is No. The Glorious Revolution of 1688-1689 in England was primarily\nfought by English and Scottish troops, and did not involve the use of mercenaries. It was a relatively\nbloodless conflict that saw the overthrow of King James II and the replacement of the Catholic\nmonarchy with the Protestant monarchy of William and Mary. The revolution was primarily driven by\npolitical and religious motives and was not fought for mercenary gain.\nQ: Does a sea otter eat spiders?\nA: The answer (Yes or No) is No. Sea otters are carnivorous marine mammals and primarily eat fish,\ncrustaceans, and mollusks. Spiders are not a part of their diet.\nQ: Did Modern Family win a Slammy award?\nA: The answer (Yes or No) is No, Modern Family did not win a Slammy award. The Slammy Awards\nare an annual awards show presented by the professional wrestling promotion WWE, and Modern\nFamily is a television sitcom.\nQ: Did Ice make people rich?\nA: The answer (Yes or No) is Yes, the Ice trade has made people rich. The Ice trade refers to the\ncommercial harvesting, transport and sale of natural ice, and it was a major industry in the 19th\ncentury. Ice was harvested from frozen rivers and lakes during the winter, and then stored in ice\nhouses for use during the summer. The ice was then transported by ship or train to cities and towns,\nwhere it was sold to individuals and businesses for use in refrigeration. The ice trade was particularly\nprofitable for those who controlled the ice harvesting and transportation operations.\nQ: Are the headquarters of All Nippon Airways near a beach?\nA: The answer (Yes or No) is No. The headquarters of All Nippon Airways (ANA) is located in\nTokyo, Japan, which is not near a beach.\nQ: Would a baby gray whale fit in a tractor-trailer?\nA: The answer (Yes or No) is No, a baby gray whale would not fit in a tractor-trailer as they typically\nmeasure around 15-20 feet in length and weigh around 2,000-3,000 pounds at birth. Tractor-trailers\nare not designed to hold such large animals.\nQ: Is Tange Sazen hypothetically an ideal choice for a secretary job?\nA: The answer (Yes or No) is unknown as Tange Sazen is a fictional character and it is not clear what\nqualifications or abilities they possess that would make them a suitable candidate for a secretary job.\nQ: Would JPEG be a good format for saving an image of Da Vinci\u2019s Vitruvian Man?\nA: The answer (Yes or No) is Yes, JPEG is a good format for saving an image of Da Vinci\u2019s Vitruvian\nMan. It is a lossy compression format that is well-suited for photographs and other images with many\ncolors and subtle gradations. It can reduce the file size of an image without significantly degrading its\nquality. Additionally, JPEG is a widely supported format that can be opened by most image editing\nsoftware and web browsers.\nQ: Does Pantheon in Paris have a unique name?\nA: The answer (Yes or No) is Yes. The Pantheon in Paris is officially known as the \"Pantheon of\nParis\" or the \"Pantheon in the Latin Quarter.\" It is a famous landmark and tourist destination in the\ncity, known for its architectural significance and historical importance.\nTable 28: Example input and output pairs for StrategyQA with chain-of-thought (commonsense reasoning).\nQ: Did mercenaries fight for England in the Glorious Revolution?\nA: Let\u2019s think step by step. Yes, mercenaries fought for England in the Glorious Revolution of 1688.\nTherefore, the answer (Yes or No) is Yes.\nQ: Does a sea otter eat spiders?\nA: Let\u2019s think step by step. No, sea otters primarily feed on shellfish and other marine animals, not\nspiders. Therefore, the answer (Yes or No) is No\nQ: Did Modern Family win a Slammy award?\nA: Let\u2019s think step by step. Modern Family is a popular TV show that aired from 2009 to 2020. The\nSlammy Awards are annual awards given by the professional wrestling promotion WWE. It is unlikely\nthat Modern Family won a Slammy Award. Therefore, the answer (Yes or No) is No.\nQ: Did Ice make people rich?\nA: Let\u2019s think step by step. ICE (Intercontinental Exchange) is a financial and commodity market\noperator, it does not directly make people rich. The financial market\u2019s performance and individual\ninvestments determine an individual\u2019s wealth. However, ICE operates various marketplaces, including\nstock exchanges, which provide opportunities for investors to potentially grow their wealth. Therefore,\nthe answer (Yes or No) is No.\nQ: Are the headquarters of All Nippon Airways near a beach?\nA: Let\u2019s think step by step. No, the headquarters of All Nippon Airways (ANA) is located in Shiodome\nCity Center, Minato-ku, Tokyo, Japan, which is not near a beach. Therefore, the answer (Yes or No)\nis No.\nQ: Would a baby gray whale fit in a tractor-trailer?\nA: Let\u2019s think step by step. Gray whales reach up to 50 feet in length and can weigh up to 40 tons. A\nstandard tractor-trailer is about 53 feet long and typically has a capacity of around 40-45 feet in length,\nso no, a baby gray whale would not fit in a tractor-trailer. Therefore, the answer (Yes or No) is No.\nQ: Is Tange Sazen hypothetically an ideal choice for a secretary job?\nA: Let\u2019s think step by step. Tange Sazen is a fictional character and therefore, it is not possible to\ndetermine if they would be an ideal choice for a secretary job. Additionally, as a language model AI, I\ndo not have any personal opinions on the matter. Therefore, the answer (Yes or No) is Not applicable.\nQ: Is a cory catfish likely to eat another living fish?\nA: Let\u2019s think step by step. Yes, cory catfish may eat other living fish if they are small enough and\ncan fit in their mouth. It is important to consider the size of the tank, the size of the fish, and their\nfeeding habits when keeping them together. Therefore, the answer (Yes or No) is Yes.\nQ: Does Pantheon in Paris have a unique name?\nA: Let\u2019s think step by step. The Pantheon in Paris is officially known as the \"Pantheon of Paris\" or\nsimply \"The Pantheon.\" It is not known by a unique name. Therefore, the answer (Yes or No) is No.\nTable 29: Example input and output pairs for COPA (commonsense reasoning).\npremise: The pair of students came under scrutiny by the teacher.\nWhat is the cause?\nchoice1: The students both received excellent grades.\nchoice2: Their responses on the assignment were identical.\nanswer: Choice 2: Their responses on the assignment were identical.\npremise: The boy threw a temper tantrum.\nWhat is the cause?\nchoice1: His brother took his toys from him.\nchoice2: He shared his toys with his brother.\nanswer: choice1: His brother took his toys from him.\npremise: The woman read the newspaper.\nWhat is the effect?\nchoice1: She discovered the outcome of the election.\nchoice2: She casted a vote in the election.\nanswer: choice1: She discovered the outcome of the election.\npremise: The woman was in a bad mood.\nWhat is the effect?\nchoice1: She engaged in small talk with her friend.\nchoice2: She told her friend to leave her alone.\nanswer: choice2: She told her friend to leave her alone.\npremise: The woman banished the children from her property.\nWhat is the cause?\nchoice1: The children hit a ball into her yard.\nchoice2: The children trampled through her garden.\nanswer: It is not specified in the premise what the cause of the woman banishing the children from\nher property is. The choices \"The children hit a ball into her yard\" and \"The children trampled through\nher garden\" are possible causes, but without more information it is not possible to determine which, if\neither, is correct.\npremise: The woman retired.\nWhat is the effect?\nchoice1: She received her pension.\nchoice2: She paid off her mortgage.\nanswer: The effect of the woman retiring is not specified in the premise, so it is not possible to\ndetermine if either choice is correct. More information is needed to determine the specific effects of\nher retirement.\npremise:The computer was expensive to fix.\nWhat is the effect?\nchoice1: I got it repaired.\nchoice2: I bought a new one.\nanswer: The effect of the computer being expensive to fix is either choice1: getting it repaired or\nchoice2: buying a new one.\nTable 30: Example input and output pairs for COPA with chain-of-thought (commonsense reasoning).\npremise: The boy threw a temper tantrum.\nWhat is the cause?\nchoice1: His brother took his toys from him.\nchoice2: He shared his toys with his brother.\nLet\u2019s think step by step. The cause of the boy\u2019s temper tantrum is not specified in the premise, so it is\nunclear whether the cause is choice 1 or choice 2. More information is needed to determine the cause.\nTherefore, between choice1 and choice2, the answer is unclear.\npremise: The woman read the newspaper.\nWhat is the effect?\nchoice1: She discovered the outcome of the election.\nchoice2: She casted a vote in the election.\nLet\u2019s think step by step. The effect of the woman reading the newspaper is choice1: She discovered\nthe outcome of the election. Reading the newspaper would provide her with information, such as the\nresults of an election. Choice 2: She casted a vote in the election is not a direct effect of reading the\nnewspaper as it is not mentioned in the premise. Therefore, between choice1 and choice2, the answer\nis choice1: She discovered the outcome of the election.\npremise: The woman banished the children from her property.\nWhat is the cause?\nchoice1: The children hit a ball into her yard.\nchoice2: The children trampled through her garden.\nLet\u2019s think step by step. The cause of the woman banishing the children from her property is not\nspecified in the premise. The choices provided, \"The children hit a ball into her yard\" and \"The\nchildren trampled through her garden,\" are potential causes but they are not confirmed. Therefore,\nbetween choice1 and choice2, the answer is unknown.\npremise: The woman retired.\nWhat is the effect?\nchoice1: She received her pension.\nchoice2: She paid off her mortgage.\nLet\u2019s think step by step. The effect of the woman retiring is that she is no longer actively working and\nmay be eligible for retirement benefits such as a pension or social security. Choice 1, \"She received\nher pension,\" is a potential outcome of her retirement. Choice 2, \"She paid off her mortgage,\" is\nnot directly related to her retirement and would likely have been affected by other factors such as\nincome and savings. Therefore, between choice1 and choice2, the answer is choice1: She received\nher pension.\npremise:The computer was expensive to fix.\nWhat is the effect?\nchoice1: I got it repaired.\nchoice2: I bought a new one.\nLet\u2019s think step by step. Choice 1: The effect of \"I got it repaired\" would likely be that the computer\nis now functional again, but the cost of the repair may have been significant. Choice 2: The effect of\n\"I bought a new one\" would likely be that you now have a functioning computer, but the cost of the\nnew one plus the cost of repairing the old one may have been significant. Additionally, you would\nno longer have the old computer. Therefore, between choice1 and choice2, the answer is that both\noptions result in a functioning computer, but both options may have significant costs and choice 2\nwould mean that you no longer have the old computer.\nTable 31: Example input and output pairs for Last Letter Concatenation (symbolic reasoning).\nQ: Take the last letters of each words in \"Skyler Oliver Cristy Sierra\" and concatenate them.\nA: The answer is \"r r y a\"\nQ: Take the last letters of each words in \"Felipe Heidi Nino Bradley\" and concatenate them.\nA: The answer is \"e i o y\"\nQ: Take the last letters of each words in \"Nico Lorenzo Johanna Teresita\" and concatenate them.\nA: The answer is \"o o a a\"\nQ: Take the last letters of each words in \"Jason Betty Elisa Jay\" and concatenate them.\nA: The answer is \"n y a y\"\nQ: Take the last letters of each words in \"Bob Aman Richie Sana\" and concatenate them.\nA: The answer is bncieana\nQ: Take the last letters of each words in \"Marian Joanne Darrin Rohit\" and concatenate them.\nA: The answer is \"nntrh\"\nQ: Take the last letters of each words in \"Justin Neal Jt Lucia\" and concatenate them.\nA: The answer is \"ntljtcia\"\nQ: Take the last letters of each words in \"Carla Dolores Cooper Damion\" and concatenate them.\nA: The answer is \"lrcprdmn\"\nTable 32: Example input and output pairs for Last Letter Concatenation with chain-of-thought (symbolic reasoning).\nQ: Take the last letters of each words in \"Skyler Oliver Cristy Sierra\" and concatenate them.\nA: Let\u2019s think step by step. A: yroiverstyreri. Therefore, the answer is yroiverstyreri.\nQ: Take the last letters of each words in \"Felipe Heidi Nino Bradley\" and concatenate them.\nA: Let\u2019s think step by step. A: \"Felipe Heidi Nino Bradley\" -> \"eipeideinradley\" Therefore, the\nanswer is \"eipeideinradley\".\nQ: Take the last letters of each words in \"Nico Lorenzo Johanna Teresita\" and concatenate them.\nA: Let\u2019s think step by step. \"Nico Lorenzo Johanna Teresita\" -> \"oc ozenro hannajo atesiti\" ->\n\"colojhatesit\". Therefore, the answer is \"colojhatesit\".\nQ: Take the last letters of each words in \"Jason Betty Elisa Jay\" and concatenate them.\nA: Let\u2019s think step by step. The last letters of each word are: \"n\", \"y\", \"a\", \"y\". Concatenating them\nresults in \"nyay\". Therefore, the answer is \"nyay\".\nQ: Take the last letters of each words in \"Bob Aman Richie Sana\" and concatenate them.\nA: Let\u2019s think step by step. \"Bob Aman Richie Sana\" -> \"bob\" \"aman\" \"richie\" \"sana\" -> \"b\" \"n\" \"e\"\n\"a\" -> \"bnea\" Therefore, the answer is \"bnea\".\nQ: Take the last letters of each words in \"Marian Joanne Darrin Rohit\" and concatenate them.\nA: Let\u2019s think step by step. A: ntnhtjrdro. Therefore, the answer is ntnhtjrdro.\nQ: Take the last letters of each words in \"Justin Neal Jt Lucia\" and concatenate them.\nA: Let\u2019s think step by step. \"Justin Neal Jt Lucia\" -> \"niatn leaJ ttJ acilu\" -> \"naltjtacilu\". Therefore,\nthe answer is \"naltjtacilu\".\nQ: Take the last letters of each words in \"Carla Dolores Cooper Damion\" and concatenate them.\nA: Let\u2019s think step by step. Last letters of each word: \"alr ores ooper amion\". Concatenated result:\n\"alroresooperamion\". Therefore, the answer is \"alroresooperamion\".\nTable 33: Example input and output pairs for Coin Flip (symbolic reasoning).\nQ: A coin is heads up. Wilmer flips the coin. Valerie does not flip the coin. Melissa flips the coin.\nEloisa flips the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: The answer (Yes or No) is No, if the coin is flipped four times, the probability that it will be heads\nup is very low. Each flip has a 50% chance of resulting in the coin landing heads up or tails up. The\ncoin is likely to end up in a tails up position after four flips.\nQ: A coin is heads up. Katia does not flip the coin. Mina does not flip the coin. Cam does not flip the\ncoin. Ronda does not flip the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: The answer (Yes or No) is Yes. Since none of the individuals (Katia, Mina, Cam, and Ronda)\nflipped the coin, the coin would still be heads up.\nQ: A coin is heads up. Forrest does not flip the coin. Juanito does not flip the coin. Allan does not\nflip the coin. Candice does not flip the coin. Is the coin still heads up? Note that \"flip\" here means\n\"reverse\".\nA: The answer (Yes or No) is Yes, the coin is still heads up.\nQ: A coin is heads up. Tomas does not flip the coin. Nic flips the coin. Zoila flips the coin. Calvin\ndoes not flip the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\"\nA: The answer (Yes or No) is Yes, the coin is still heads up. Since Tomas and Calvin did not flip the\ncoin, it remains in its original state. Nic and Zoila flipping the coin would only change the current\nstate of the coin.\nQ: A coin is heads up. Jeff does not flip the coin. Jen flips the coin. Giselle flips the coin. Noel does\nnot flip the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: The answer (Yes or No) is unknown without additional information about the outcome of Jen and\nGiselle flipping the coin. If both Jen and Giselle flipped the coin and it landed heads up each time,\nthen it would still be heads up. If either of them flipped the coin and it landed tails up, then the coin\nwould no longer be heads up.\nQ: A coin is heads up. Amy flips the coin. Ella does not flip the coin. Amilcar does not flip the coin.\nRoman does not flip the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: The answer (Yes or No) is Yes, the coin is still heads up. Since Amy, Ella, Amilcar, and Roman\ndid not flip the coin, the coin\u2019s initial state of being heads up remains unchanged.\nQ: A coin is heads up. Lara does not flip the coin. Greg does not flip the coin. Ethan flips the coin.\nTerrence flips the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: The answer (Yes or No) is unknown, as we do not know the outcome of Ethan and Terrence\nflipping the coin. If Ethan and Terrence both flipped the coin and it landed heads up each time, then\nthe coin would still be heads up. If either of them flipped the coin and it landed tails up, then the coin\nwould no longer be heads up.\nQ: A coin is heads up. Ronnie flips the coin. Kiki flips the coin. Alan flips the coin. Remy flips the\ncoin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: The answer (Yes or No) is No. Each flip of the coin has a 50% chance of resulting in the coin being\nheads up or tails up. Since the coin was initially heads up and each flip has a 50% chance of reversing\nthe current state of the coin, it is likely that the coin will end up as tails up after multiple flips.\nTable 34: Example input and output pairs for Coin Flip with chain-of-thought (symbolic reasoning).\nQ: A coin is heads up. Wilmer flips the coin. Valerie does not flip the coin. Melissa flips the coin.\nEloisa flips the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: Let\u2019s think step by step. At the start, the coin is heads up. When Wilmer flips the coin, it will be\ntails up. When Valerie does not flip the coin, it remains tails up. When Melissa flips the coin, it will\nbe heads up again. Finally, when Eloisa flips the coin, it will be tails up again. Therefore, after all\nfour flips, the coin is tails up. Therefore, the answer (Yes or No) is No.\nQ: A coin is heads up. Katia does not flip the coin. Mina does not flip the coin. Cam does not flip the\ncoin. Ronda does not flip the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: Let\u2019s think step by step. Yes, the coin is still heads up. None of the individuals mentioned (Katia,\nMina, Cam, Ronda) flipped the coin, so its original state (heads up) remains unchanged. Therefore,\nthe answer (Yes or No) is Yes.\nQ: A coin is heads up. Forrest does not flip the coin. Juanito does not flip the coin. Allan does not\nflip the coin. Candice does not flip the coin. Is the coin still heads up? Note that \"flip\" here means\n\"reverse\".\nA: Let\u2019s think step by step. Yes, the coin is still heads up as long as none of the individuals flip the\ncoin, the coin\u2019s current state will remain the same. Therefore, the answer (Yes or No) is Yes.\nQ: A coin is heads up. Tomas does not flip the coin. Nic flips the coin. Zoila flips the coin. Calvin\ndoes not flip the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\"\nA: Let\u2019s think step by step. First, the coin is heads up before any flipping occurs. When Nic flips the\ncoin, the coin will now be tails up. Then, when Zoila flips the coin, the coin will be heads up again.\nFinally, since Calvin does not flip the coin, the coin remains heads up. So, the final answer is yes, the\ncoin is still heads up. Therefore, the answer (Yes or No) is Yes.\nQ: A coin is heads up. Jeff does not flip the coin. Jen flips the coin. Giselle flips the coin. Noel does\nnot flip the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: Let\u2019s think step by step. If Jeff does not flip the coin, it remains heads up. Then, when Jen flips the\ncoin, it would become tails up. Finally, when Giselle flips the coin, it would become heads up again.\nSo, the final state of the coin after all these actions is heads up. Therefore, the answer (Yes or No) is\nYes.\nQ: A coin is heads up. Amy flips the coin. Ella does not flip the coin. Amilcar does not flip the coin.\nRoman does not flip the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: Let\u2019s think step by step. Yes, the coin is still heads up, as none of the people mentioned flipped the\ncoin, meaning it remained in its original state. Therefore, the answer (Yes or No) is Yes.\nQ: A coin is heads up. Lara does not flip the coin. Greg does not flip the coin. Ethan flips the coin.\nTerrence flips the coin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: Let\u2019s think step by step. Initially, the coin is heads up. If Lara and Greg do not flip the coin, then\nthe coin remains heads up. However, if Ethan and Terrence both flip the coin, the coin will now be\ntails up. So, the final state of the coin will depend on whether Ethan and Terrence flipped it or not.\nTherefore, the answer (Yes or No) is No.\nQ: A coin is heads up. Ronnie flips the coin. Kiki flips the coin. Alan flips the coin. Remy flips the\ncoin. Is the coin still heads up? Note that \"flip\" here means \"reverse\".\nA: Let\u2019s think step by step. The initial state of the coin is heads up. When Ronnie flips the coin, it\nbecomes tails up. When Kiki flips the coin, it becomes heads up again. When Alan flips the coin, it\nbecomes tails up. And when Remy flips the coin, it becomes heads up again. So, the final state of the\ncoin is heads up. Therefore, the answer (Yes or No) is Yes.\nTable 35: Example input and output pairs for Date Understanding (logical reasoning).\nQ: Today is Christmas Eve of 1937. What is the date tomorrow in MM/DD/YYYY? Answer Choices:\n(A) 12/25/2006 (B) 12/11/1937 (C) 12/25/1937 (D) 12/04/1937 (E) 07/25/1937 (F) 01/04/1938\nA: Among A through F, the answer is C) 12/25/1937 as Christmas Eve is December 24th and the next\nday is Christmas Day December 25th.\nQ: The day before yesterday was 11/23/1933. What is the date yesterday in MM/DD/YYYY?\nAnswer Choices: (A) 11/25/1933 (B) 11/24/2020 (C) 12/22/1933 (D) 10/27/1933 (E) 11/24/1933 (F)\n12/27/1933\nA: Among A through F, the answer is (E) 11/24/1933. The day before yesterday was 11/23/1933 and\nyesterday would be one day later, which is 11/24/1933.\nQ: Jane visits the bookstore on the 16th of each month starting from the October of 2009. It is her 5th\nvisit to the bookstore today. What is the date 24 hours later in MM/DD/YYYY? Answer Choices: (A)\n02/16/2010 (B) 02/17/2010 (C) 02/21/2010 (D) 03/27/2010 (E) 02/23/2010 (F) 02/03/2010\nA: Among A through F, the answer is B) 02/17/2010. Explanation: Since Jane visits the bookstore on\nthe 16th of each month and today is her 5th visit, it is currently February 16th 2010. 24 hours later\nwould be February 17th 2010.\nQ: The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What\nis the date 10 days ago in MM/DD/YYYY? Answer Choices: (A) 10/23/1942 (B) 05/21/1943 (C)\n07/01/1943 (D) 05/23/1943 (E) 05/24/1943\nA: Among A through F, the answer is (D) 05/23/1943. The concert was delayed by one day, so 10\ndays ago from 06/01/1943 would be 05/23/1943.\nQ: On May 9th, 2017 Jane bought 40 eggs. She ate one per day. Today she ran out of eggs. What\nis the date 10 days ago in MM/DD/YYYY? Answer Choices: (A) 06/08/1933 (B) 06/14/2017 (C)\n06/08/2017 (D) 06/22/2017 (E) 06/06/2017 (F) 05/15/2017\nA: Among A through F, the answer is (B) 06/14/2017. If Jane ate one egg per day and today she ran\nout of eggs, then 10 days ago is when she would have finished her 40th egg, and the date 10 days ago\nwould be June 14th, 2017.\nQ: On May 9th, 2017 Jane bought 40 eggs. She ate one per day. Today she ran out of eggs. What\nis the date tomorrow in MM/DD/YYYY? Answer Choices: (A) 06/25/2017 (B) 08/05/2017 (C)\n06/19/2017 (D) 06/13/2017 (E) 06/18/2017 (F) 06/21/2017\nA: Among A through F, the answer is D) 06/13/2017. Since Jane ate one egg per day, and she ran out\nof eggs on the day you asked the question, and it is the day she ran out of eggs, the date would be 40\ndays from the date she bought the eggs, which is May 9th + 40 days = June 13th, 2017.\nQ: Jane was born on the last day of February in 2000. Today is her 16-year-old birthday. What\nis the date 10 days ago in MM/DD/YYYY? Answer Choices: (A) 02/19/1979 (B) 02/12/2016 (C)\n02/19/2105 (D) 01/09/2016 (E) 02/20/2016 (F) 02/19/2016\nA: Among A through F, the answer is D) 01/09/2016. Since Jane is 16 years old today and was born\non the last day of February in 2000, 10 days ago would be January 9th, 2016.\nQ: Today\u2019s meeting is rescheduled to 11 am tomorrow, 10/16/1924. What is the date today in\nMM/DD/YYYY? Answer Choices: (A) 10/15/1835 (B) 10/14/1924 (C) 09/17/1924 (D) 10/15/1924\n(E) 10/29/1924\nA: Among A through F, the answer is None of the above. The date today is not October 16th, 1924 as\nstated in the question. It is the present day, which is January 27th, 2023.\nTable 36: Example input and output pairs for Date Understanding with chain-of-thought (logical reasoning).\nQ: Today is Christmas Eve of 1937. What is the date tomorrow in MM/DD/YYYY? Answer Choices:\n(A) 12/25/2006 (B) 12/11/1937 (C) 12/25/1937 (D) 12/04/1937 (E) 07/25/1937 (F) 01/04/1938\nA: Let\u2019s think step by step. Today is Christmas Eve, which means tomorrow is Christmas Day. The\ncurrent year is 1937. So the date tomorrow is 12/25/1937. Therefore, among A through F, the answer\nis (C) 12/25/1937.\nQ: The day before yesterday was 11/23/1933. What is the date yesterday in MM/DD/YYYY?\nAnswer Choices: (A) 11/25/1933 (B) 11/24/2020 (C) 12/22/1933 (D) 10/27/1933 (E) 11/24/1933 (F)\n12/27/1933\nA: Let\u2019s think step by step. The day before yesterday was 11/23/1933. So yesterday would be\n11/24/1933. So the answer is (E) 11/24/1933. Therefore, among A through F, the answer is (E)\n11/24/1933.\nQ: The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What\nis the date 10 days ago in MM/DD/YYYY? Answer Choices: (A) 10/23/1942 (B) 05/21/1943 (C)\n07/01/1943 (D) 05/23/1943 (E) 05/24/1943\nA: Let\u2019s think step by step. The concert was delayed by one day, so if today is 06/01/1943, the original\nscheduled date would be 06/01/1943 - 1 day = 05/31/1943. 10 days ago from 06/01/1943 would be\n06/01/1943 - 10 days = 05/22/1943. So, the answer is (B) 05/21/1943. Therefore, among A through F,\nthe answer is (B) 05/21/1943.\nQ: On May 9th, 2017 Jane bought 40 eggs. She ate one per day. Today she ran out of eggs. What\nis the date 10 days ago in MM/DD/YYYY? Answer Choices: (A) 06/08/1933 (B) 06/14/2017 (C)\n06/08/2017 (D) 06/22/2017 (E) 06/06/2017 (F) 05/15/2017\nA: Let\u2019s think step by step. If Jane ate one egg per day, and she ran out of eggs today, then the number\nof days since she bought the eggs is equal to the number of eggs she bought, which is 40. If today is\nthe day she ran out of eggs, then ten days ago would be 40 days - 10 days = 30 days. So the date 10\ndays ago would be May 9th, 2017 + 30 days = June 8th, 2017. Therefore, the correct answer is (C)\n06/08/2017. Therefore, among A through F, the answer is (C) 06/08/2017.\nQ: On May 9th, 2017 Jane bought 40 eggs. She ate one per day. Today she ran out of eggs. What\nis the date tomorrow in MM/DD/YYYY? Answer Choices: (A) 06/25/2017 (B) 08/05/2017 (C)\n06/19/2017 (D) 06/13/2017 (E) 06/18/2017 (F) 06/21/2017\nA: Let\u2019s think step by step. (D) 06/13/2017 is the correct answer. If Jane bought 40 eggs on May 9th\nand ate one per day, then 40 days later on June 18th she would have no eggs left. The next day would\nbe June 13th. Therefore, among A through F, the answer is (D) 06/13/2017.\nQ: Jane was born on the last day of Feburary in 2000. Today is her 16-year-old birthday. What\nis the date 10 days ago in MM/DD/YYYY? Answer Choices: (A) 02/19/1979 (B) 02/12/2016 (C)\n02/19/2105 (D) 01/09/2016 (E) 02/20/2016 (F) 02/19/2016\nA: Let\u2019s think step by step. Today is Jane\u2019s 16th birthday, so that means she was born 16 years ago.\nSince the year 2000 is a leap year, February has 29 days. So, her birthday is on 02/29/2000. If we\ngo back 10 days from her birthday, that would be 02/19/2016. Therefore, the correct answer is (F)\n02/19/2016. Therefore, among A through F, the answer is (F) 02/19/2016.\nTable 37: Example input and output pairs for Tracking Shuffled Objects (logical reasoning).\nQ: Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of\nthe semester, they each buy one new book: Alice gets Moby Dick, Bob gets The Great Gatsby, and\nClaire gets Lolita. As the semester proceeds, they start trading around the new books. First, Claire\nand Bob swap books. Then, Alice and Claire swap books. Finally, Alice and Bob swap books. At the\nend of the semester, Bob has\nWhich choice is true ? Answer Choices: (A) Moby Dick. (B) The Great Gatsby. (C) Lolita.\nA: Among A through C, the answer is (B) The Great Gatsby.\nQ: Alice, Bob, and Claire are playing a game. At the start of the game, they are each holding a ball:\nAlice has a green ball, Bob has a purple ball, and Claire has a blue ball. As the game progresses, pairs\nof players trade balls. First, Bob and Alice swap balls. Then, Claire and Bob swap balls. Finally, Bob\nand Alice swap balls. At the end of the game, Bob has the\nWhich choice is true ? Answer Choices: (A) green ball. (B) purple ball. (C) blue ball.\nA: Among A through C, the answer is B) purple ball.\nQ: Alice, Bob, and Claire are holding a white elephant gift exchange. At the start of the event, they\nare each holding a present of a different color: Alice has a yellow present, Bob has a white present,\nand Claire has a purple present. As the event progresses, pairs of people swap gifts. First, Alice and\nBob swap their gifts. Then, Bob and Claire swap their gifts. Finally, Bob and Alice swap their gifts.\nAt the end of the event, Bob has the\nWhich choice is true ? Answer Choices: (A) yellow present. (B) white present. (C) purple present.\nA: Among A through C, the answer is (B) white present.\nQ: Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start\nof the semester, they each buy one new book: Alice gets Catch-22, Bob gets Lolita, and Claire gets\nHound of the Baskervilles. As the semester proceeds, they start trading around the new books. First,\nBob and Alice swap books. Then, Bob and Claire swap books. Finally, Alice and Claire swap books.\nAt the end of the semester, Claire has\nWhich choice is true ? Answer Choices: (A) Catch-22. (B) Lolita. (C) Hound of the Baskervilles.\nA: Among A through C, the answer is (C) Hound of the Baskervilles.\nQ: Alice, Bob, and Claire are playing a game. At the start of the game, they are each holding a ball:\nAlice has a purple ball, Bob has a yellow ball, and Claire has a orange ball. As the game progresses,\npairs of players trade balls. First, Claire and Bob swap balls. Then, Bob and Alice swap balls. Finally,\nClaire and Bob swap balls. At the end of the game, Alice has the\nWhich choice is true ? Answer Choices: (A) purple ball. (B) yellow ball. (C) orange ball.\nA: Among A through C, the answer is B) yellow ball.\nQ: Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of\nthe semester, they each buy one new book: Alice gets Hound of the Baskervilles, Bob gets Catch-22,\nand Claire gets The Pearl. As the semester proceeds, they start trading around the new books. First,\nClaire and Bob swap books. Then, Bob and Alice swap books. Finally, Claire and Alice swap books.\nAt the end of the semester, Claire has\nWhich choice is true ? Answer Choices: (A) Hound of the Baskervilles. (B) Catch-22. (C) The Pearl.\nA: Among A through C, the answer is (A) Hound of the Baskervilles.\nTable 38: Example input and output pairs for Tracking Shuffled Objects with chain-of-thought (logical reasoning).\nQ: Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of\nthe semester, they each buy one new book: Alice gets Moby Dick, Bob gets The Great Gatsby, and\nClaire gets Lolita. As the semester proceeds, they start trading around the new books. First, Claire\nand Bob swap books. Then, Alice and Claire swap books. Finally, Alice and Bob swap books. At the\nend of the semester, Bob has\nWhich choice is true ? Answer Choices: (A) Moby Dick. (B) The Great Gatsby. (C) Lolita.\nA: Let\u2019s think step by step. At the start of the semester, Bob has (B) The Great Gatsby. After the\nfirst trade, Claire and Bob swap books, so Bob now has (C) Lolita. After the second trade, Alice\nand Claire swap books, so Bob now has (A) Moby Dick. After the final trade, Alice and Bob swap\nbooks, so Bob now has (B) The Great Gatsby. Therefore, the correct answer is (B) The Great Gatsby.\nTherefore, among A through C, the answer is (B) The Great Gatsby.\nQ: Alice, Bob, and Claire are playing a game. At the start of the game, they are each holding a ball:\nAlice has a green ball, Bob has a purple ball, and Claire has a blue ball. As the game progresses, pairs\nof players trade balls. First, Bob and Alice swap balls. Then, Claire and Bob swap balls. Finally, Bob\nand Alice swap balls. At the end of the game, Bob has the\nWhich choice is true ? Answer Choices: (A) green ball. (B) purple ball. (C) blue ball.\nA: Let\u2019s think step by step. At the start of the game, Bob has a purple ball. In the first trade, Bob and\nAlice swap balls, so Bob now has a green ball. In the second trade, Claire and Bob swap balls, so Bob\nnow has a blue ball. In the final trade, Bob and Alice swap balls again, so Bob ends the game with\nthe green ball. Therefore, the correct answer is (A) green ball. Therefore, among A through C, the\nanswer is (A) green ball.\nQ: Alice, Bob, and Claire are holding a white elephant gift exchange. At the start of the event, they\nare each holding a present of a different color: Alice has a yellow present, Bob has a white present,\nand Claire has a purple present. As the event progresses, pairs of people swap gifts. First, Alice and\nBob swap their gifts. Then, Bob and Claire swap their gifts. Finally, Bob and Alice swap their gifts.\nAt the end of the event, Bob has the\nWhich choice is true ? Answer Choices: (A) yellow present. (B) white present. (C) purple present.\nA: Let\u2019s think step by step. A: (A) yellow present. Therefore, among A through C, the answer is A)\nyellow present.\nQ: Alice, Bob, and Claire are friends and avid readers who occasionally trade books. At the start of\nthe semester, they each buy one new book: Alice gets Hound of the Baskervilles, Bob gets Catch-22,\nand Claire gets The Pearl. As the semester proceeds, they start trading around the new books. First,\nClaire and Bob swap books. Then, Bob and Alice swap books. Finally, Claire and Alice swap books.\nAt the end of the semester, Claire has\nWhich choice is true ? Answer Choices: (A) Hound of the Baskervilles. (B) Catch-22. (C) The Pearl.\nA: Let\u2019s think step by step. At the start of the semester, Claire has The Pearl. Then, Claire and Bob\nswap books, so Claire now has Catch-22. Next, Bob and Alice swap books, so Bob now has Hound of\nthe Baskervilles and Claire still has Catch-22. Finally, Claire and Alice swap books, so Claire now\nhas Hound of the Baskervilles and Alice has Catch-22. Therefore, the correct answer is (A) Hound of\nthe Baskervilles. Therefore, among A through C, the answer is (A) Hound of the Baskervilles.\nTable 39: Example input and output pairs for RTE (natural language inference).\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019entail\u2019 or\n\u2019not entail\u2019.\npremise: Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44,\naccording to the Christopher Reeve Foundation.\nhypothesis: Christopher Reeve had an accident.\nanswer: Not entail.\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019entail\u2019 or\n\u2019not entail\u2019.\npremise: Security forces were on high alert after an election campaign in which more than 1,000\npeople, including seven election candidates, have been killed.\nhypothesis: Security forces were on high alert after a campaign marred by violence.\nanswer: Entail.\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019entail\u2019 or\n\u2019not entail\u2019.\npremise: Steve Jobs was attacked by Sculley and other Apple executives for not delivering enough\nhot new products and resigned from the company a few weeks later.\nhypothesis: Steve Jobs worked for Apple.\nanswer: Entail.\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019entail\u2019 or\n\u2019not entail\u2019.\npremise: Nokia, Texas Instruments and other leading makers of mobile phones have formally\ncomplained to Brussels that Qualcomm, the US mobile chipmaker, has unfairly used its patents on 3G\ntechnologies.\nhypothesis: Texas Instruments produces mobile phones.\nanswer: Not entail.\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019entail\u2019 or\n\u2019not entail\u2019.\npremise: Ssangyong Motor was taken over by creditors after it collapsed under heavy debts during\nthe 1997-98 Asian financial crisis.\nhypothesis: Asian financial crisis takes over Ssangyong Motor\nanswer: Entail\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019entail\u2019 or\n\u2019not entail\u2019.\npremise: At the same time the Italian digital rights group, Electronic Frontiers Italy, has asked the\nnation\u2019s government to investigate Sony over its use of anti-piracy software.\nhypothesis: Italy\u2019s government investigates Sony.\nanswer: Entail.\nTable 40: Example input and output pairs for CB (natural language inference).\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019yes\u2019, \u2019no\u2019 or\n\u2019neutral\u2019.\npremise: Valence the void-brain, Valence the virtuous valet. Why couldn\u2019t the figger choose his own\nportion of titanic anatomy to shaft? Did he think he was helping?\nhypothesis: Valence was helping\nanswer: No.\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019yes\u2019, \u2019no\u2019 or\n\u2019neutral\u2019.\npremise: And I don\u2019t want to have to lie to them. The kidnappers have given us until October the\neleventh to deliver the document and I haven\u2019t despaired of finding it before then. But if the police\nlearn I \u2019ve been to America they \u2019ll ask why.\nhypothesis: he\u2019s been to America\nanswer: yes\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019yes\u2019, \u2019no\u2019 or\n\u2019neutral\u2019.\npremise: B: how\u2019d you like to own a piece of property where your lake is going sour because of acid\nrain. A: Right. Right. B: It\u2019s, uh, really a serious issue for those of us up in this, uh, sector up here. A:\num, or do you hypothesize that most of the, uh, smog or air pollution comes from vehicles\nhypothesis: most of the smog or air pollution comes from vehicles\nanswer: neutral\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019yes\u2019, \u2019no\u2019 or\n\u2019neutral\u2019.\npremise: A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I\nthought was interesting was that the critics, apparently it\u2019s going to win everything. B: Really? A: Uh,\nand I had been told, you know, you wouldn\u2019t notice that it was three hours long, and all this, kind of,\nhypothesis: it was three hours long\nanswer: neutral\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019yes\u2019, \u2019no\u2019 or\n\u2019neutral\u2019.\npremise: A: I do too, so she couldn\u2019t possibly turn them out like some of these popular writers, B:\nHuh-uh. A: but oh, her books are just incredible. I don\u2019t think they\u2019ve ever made a movie, do you?\nhypothesis: they\u2019ve ever made a movie\nanswer: neutral\nPlease identify whether the premise entails the hypothesis. The answer should be exact \u2019yes\u2019, \u2019no\u2019 or\n\u2019neutral\u2019.\npremise: What had brought Gharr and Ten-huc and Pulvidon to the planet at the same time? Why\nwere all of them so interested in why I was there? And if they somehow suspected that I was picking\nup something valuable why would any of them try to kill me before the pick-up?\nhypothesis: she was picking up something valuable\nanswer: neutral\nTable 41: Example input and output pairs for BoolQ (question answering).\nPlease answer the given question based on the context. The answer should be exact \u2019yes\u2019 or \u2019no\u2019.\ncontext: Phantom pain \u2013 Phantom pain sensations are described as perceptions that an individual\nexperiences relating to a limb or an organ that is not physically part of the body. Limb loss is a result\nof either removal by amputation or congenital limb deficiency. However, phantom limb sensations\ncan also occur following nerve avulsion or spinal cord injury.\nquestion: is pain experienced in a missing body part or paralyzed area\nanswer: Yes.\nPlease answer the given question based on the context. The answer should be exact \u2019yes\u2019 or \u2019no\u2019.\ncontext: American entry into Canada by land \u2013 Persons driving into Canada must have their vehicle\u2019s\nregistration document and proof of insurance.\nquestion: can u drive in canada with us license\nanswer: Yes.\nPlease answer the given question based on the context. The answer should be exact \u2019yes\u2019 or \u2019no\u2019.\ncontext: Gambling in Australia \u2013 Gamblers\u2019 winnings in Australia are not taxed . There are 3 main\nreasons for that:\nquestion: do you pay tax on gambling winnings in australia\nanswer: No.\nPlease answer the given question based on the context. The answer should be exact \u2019yes\u2019 or \u2019no\u2019.\ncontext: Cloak \u2013 Ladies may wear a long (over the shoulders or to ankles) cloak usually called a cape,\nor a full-length cloak. Gentlemen wear an ankle-length or full-length cloak. Formal cloaks often have\nexpensive, colored linings and trimmings such as silk, satin, velvet and fur.\nquestion: is a cape and a cloak the same\nanswer: No\nPlease answer the given question based on the context. The answer should be exact \u2019yes\u2019 or \u2019no\u2019.\ncontext: Donna Pinciotti \u2013 In the final episode, Eric returns to Point Place for the New Year and he\nand Donna kiss. It is presumed that they end up together again at the end of the series and the end of\nthe 1970s.\nquestion: do donna and eric end up getting married\nanswer: It is not specified if Donna and Eric end up getting married in the series \"That \u201970s Show.\"\nPlease answer the given question based on the context. The answer should be exact \u2019yes\u2019 or \u2019no\u2019.\ncontext: Cold Case \u2013 Due to the use of contemporary music in each episode, none of the seasons are\npresently available on DVD, due to music licensing issues. However, the entire series, incorporating\nthe contemporary music, was previously released on DVD as Cold Case: The Complete Edition, by\nCBS Productions (ISBN 8-5857-9659-6), on 44 dual-layer disks, in a single boxed set. This set is out\nof print.\nquestion: will cold case ever be released on dvd\nanswer: It is unclear if Cold Case will ever be released on DVD again.\nTable 42: Example input and output pairs for MuTual (dialogue).\nQ: f : why all the candles ? is the electricity out or something ? m : no , i just thought it would make\nthe place smell nice . f : it does smell nice , but it \u2019s still awfully dark . Which choice is correct ?\nAnswer Choices: (A) m : yes . the candles smell terrible . (B) m : yes . the candles are not bright\nenough and they smells bad . (C) m : yes . the room is still dark even the candles were lit . (D) m :\nyes . the candles are better than electricity because they are very bright .\nA: Among A through D, the answer is C: m : yes . the room is still dark even the candles were lit .\nQ: m : is it ok if i pay for this book by visa ? i have n\u2019t got much cash on me . f : we ca n\u2019t really take\ncards for amounts under 5 pounds . that one \u2019s only 3.99 pounds , is n\u2019t it ? Which choice is correct ?\nAnswer Choices: (A) m : yes . why do you have to use a credit card ? (B) m : yes . you need to pay\nby cash . (C) m : yes . you pay 3.99 pounds by check ? (D) m : yes . you need to pay for this t-shirt\nby cash .\nA: Among A through D, the answer is (B) m : yes . you need to pay by cash .\nQ: m : what color should we paint the walls of the babies room , red ? f : i do n\u2019t like the color red .\nwhat about blue or yellow ? m : i do n\u2019t like yellow very much . i \u2019m sorry , but the first one you\nmentioned sounds fine . Which choice is correct ? Answer Choices: (A) f : okay , then we will pick\nblue . (B) f : as your wish , we will choose your favorite color yellow . (C) f : same as you , i prefer\nred . (D) f : blue for the ceiling ? do n\u2019t be ridiculous .\nA: Among A through D, the answer is A: f : okay, then we will pick blue.\nQ: f : dad , can i go out tonight ? m : no , i \u2019m sorry . you ca n\u2019t . f : can i ask nancy for dinner ? m\n: ok , but you ca n\u2019t let your brother alone . Which choice is correct ? Answer Choices: (A) f : ok.\nthen i will ask nancy for dinner tonight . (B) f : i will stay at home alone because i do n\u2019t want ask\nnancy for dinner . (C) f : ok. so i can ask nancy for dinner tonight if i do n\u2019t have to have my brother\ncompanied . (D) f : i have to stay home with me brother because i will not ask nancy to have dinner .\nA: Among A through D, the answer is (C) f : ok. so i can ask nancy for dinner tonight if i do n\u2019t have\nto have my brother companied .\nQ: f : i \u2019m very disappointed at the new house . i expected it to be much better . m : you ca n\u2019t say\nthat , rose . i think it \u2019s much better than mine . Which choice is correct ? Answer Choices: (A) f :\nwhy do you think my house is astonishing but still not better than yours ? (B) f : why do you think\nmy house is much better than yours ? you are so satisfying with my house . (C) f : why do you think\nmy house is disappointing ? (D) f : why do you think your house is much better than mine ? you are\nso satisfying with your house .\nA: Among A through D, the answer is C) f : why do you think my house is disappointing?\nQ: f : you mistook the salt for sugar ? i told you the salt was in the black container and the sugar was\nin the white one . m : yes , that was so silly of me . i forgot that you told me and i could n\u2019t tell the\ndifference at the time . this coffee is terrible now . Which choice is correct ? Answer Choices: (A) f :\ni \u2019m sorry . i gave you the wrong information . (B) f : you put the sugar in the black container . my\ngod . (C) f : you added salt to your coffee . oh , no . (D) f : you added salt to you coffee . no ! you\nadded salt to mine ?\nA: Among A through D, the answer is (D) f: you added salt to you coffee. no! you added salt to\nmine?\nTable 43: Example input and output pairs for SAMSum (summarization).\nEric: MACHINE! Rob: That\u2019s so gr8! Eric: I know! And shows how Americans see Russian ;) Rob:\nAnd it\u2019s really funny! Eric: I know! I especially like the train part! Rob: Hahaha! No one talks to the\nmachine like that! Eric: Is this his only stand-up? Rob: Idk. I\u2019ll check. Eric: Sure. Rob: Turns out\nno! There are some of his stand-ups on youtube. Eric: Gr8! I\u2019ll watch them now! Rob: Me too! Eric:\nMACHINE! Rob: MACHINE! Eric: TTYL? Rob: Sure :)\nTL;DR: Eric and Rob are discussing a stand-up comedy routine involving a machine, and they find\nit funny. They plan to watch more of the comedian\u2019s stand-up on YouTube and say \"TTYL\" before\nending the conversation.\nBeatrice: I am in town, shopping. They have nice scarfs in the shop next to the church. Do you want\none? Leo: No, thanks Beatrice: But you don\u2019t have a scarf. Leo: Because I don\u2019t need it. Beatrice:\nLast winter you had a cold all the time. A scarf could help. Leo: I don\u2019t like them. Beatrice: Actually,\nI don\u2019t care. You will get a scarf. Leo: How understanding of you! Beatrice: You were complaining\nthe whole winter that you\u2019re going to die. I\u2019ve had enough. Leo: Eh.\nTL;DR: Leo is shopping in town with Beatrice and a friend. The friend suggests buying a scarf, but\nLeo does not want one because he does not like them. Beatrice insists on buying him one despite his\nreluctance, citing that he was constantly cold last winter and complained about it.\nJeff: Should we go to the village party? Lia: I\u2019m too tired after hiking Mico: I\u2019d like to go, there may\nbe some hot boys! Lia: I doubt Jim: like a real village boy? Jim: who doesn\u2019t even speak English?\nMico: yes, the dummer, the better Jim: haha, stupid fucks good, they say Mico: I confirm! Lia: not\nmy cup of tea Mico: I\u2019ll go there, who wants to join? Jeff: I\u2019ll go as well Mico: wanna drive? Jeff: so\nyou could drink? Mico: would be nice, hahah Jeff: not excited, but ok Mico: thanks!\nTL;DR: Mico and Jeff want to go to a village party, Lia is tired from hiking and not interested, Jim\nmakes a derogatory comment about the village people and Mico agrees. Mico wants to drink at the\nparty and asks Jeff to drive.\nLisa: Hello Peter. What have you been doing off late? Peter: Bit busy with work. Lisa: Too much of\nwork, huh? Peter: Not really, I\u2019ve been working out Lisa: Ohh, trying to get in shape? Peter: Nah, I\ndon\u2019t have much of weight to lose, just want to improve my health. Lisa: That\u2019s a good thought. I\nwas also thinking of working out a bit. What do you do? Do you go to a Gym? Peter: Yes, I hold a\nmembership with the one near our office. Lisa: Which exercises do you do regularly? Peter: I do\nweights and run on the treadmill. Lisa: Besides exercises, I think I need to eat better to help me keep\nin shape. Peter: Another major requirement for good health is sleep. On an average one requires at\nleast 7-8 hours of sleep. Lisa: There are a lot of things we can do to stay healthy. Peter: Yes. One\nneeds to maintain a regime to stay healthy for a long term.\nTL;DR: Peter and Lisa are discussing their recent activities, with Peter mentioning that he has been\nbusy with work but also working out to improve his health. He holds a membership at a gym near their\noffice and regularly does weights and runs on the treadmill. Lisa also expresses interest in working\nout and eating better to stay in shape. Peter also mentions that getting enough sleep is important for\noverall health and that maintaining a regime is key to long-term health.\nTable 44: Example input and output pairs for CoNLL03 (named entity recognition).\nPlease identify Person, Organization, Location and Miscellaneous Entity from the given text.\nText: State Street Bank and Trust Company\nEntity:\nPerson: None\nOrganization: State Street Bank and Trust Company\nLocation: None\nMiscellaneous: None\nPlease identify Person, Organization, Location and Miscellaneous Entity from the given text.\nText: Fourteen years after he bludgeoned and shot a man whose trailer home he robbed in 1982 , John\nMills Jr .\nEntity:\nPerson: John Mills Jr.\nOrganization: None\nLocation: None\nMiscellaneous: None\nPlease identify Person, Organization, Location and Miscellaneous Entity from the given text.\nText: Voeks , who was already on probation for prior pig thefts , pleaded that he was trying to pay\nbills for his ex-wife and children .\nEntity:\nPerson: Voeks\nOrganization: None\nLocation: None\nMiscellaneous: pig thefts, probation, ex-wife, children, bills\nPlease identify Person, Organization, Location and Miscellaneous Entity from the given text.\nText: NYMEX natgas ends sharply lower on weather outlook .\nEntity:\n- Person: None\n- Organization: NYMEX (New York Mercantile Exchange)\n- Location: None\n- Miscellaneous: natgas (natural gas), weather outlook\nPlease identify Person, Organization, Location and Miscellaneous Entity from the given text.\nText: He was fined and ordered to pay a total of 175 pounds to two members of staff injured in the\nfracas in an east London restaurant in October .\nEntity:\nPerson: He\nOrganization: None\nLocation: east London\nMiscellaneous: None\nPlease identify Person, Organization, Location and Miscellaneous Entity from the given text.\nText: Offerings light .\nEntity:\nI\u2019m sorry, I cannot identify any entities from the given text as it is not a complete sentence and does\nnot contain enough context to make any determinations. Can you please provide more information or\na more complete sentence?\nTable 45: Example input and output pairs for SST2 (sentiment analysis).\nFor each snippet of text, label the sentiment of the text as positive or negative. The answer should be\nexact \u2019positive\u2019 or \u2019negative\u2019.\nText: it \u2019s played in the most straight-faced fashion , with little humor to lighten things up .\nLabel: Negative\nFor each snippet of text, label the sentiment of the text as positive or negative. The answer should be\nexact \u2019positive\u2019 or \u2019negative\u2019.\nText: although german cooking does not come readily to mind when considering the world \u2019s best\ncuisine , mostly martha could make deutchland a popular destination for hungry tourists .\nLabel: positive\nFor each snippet of text, label the sentiment of the text as positive or negative. The answer should be\nexact \u2019positive\u2019 or \u2019negative\u2019.\nText: at times , the suspense is palpable , but by the end there \u2019s a sense that the crux of the mystery\nhinges on a technicality that strains credulity and leaves the viewer haunted by the waste of potential .\nLabel: Negative\nFor each snippet of text, label the sentiment of the text as positive or negative. The answer should be\nexact \u2019positive\u2019 or \u2019negative\u2019.\nText: ramsay , as in ratcatcher , remains a filmmaker with an acid viewpoint and a real gift for teasing\nchilly poetry out of lives and settings that might otherwise seem drab and sordid .\nLabel: positive\nFor each snippet of text, label the sentiment of the text as positive or negative. The answer should be\nexact \u2019positive\u2019 or \u2019negative\u2019.\nText: may be far from the best of the series , but it \u2019s assured , wonderfully respectful of its past and\nthrilling enough to make it abundantly clear that this movie phenomenon has once again reinvented\nitself for a new generation .\nLabel: Negative\nFor each snippet of text, label the sentiment of the text as positive or negative. The answer should be\nexact \u2019positive\u2019 or \u2019negative\u2019.\nText:american chai encourages rueful laughter at stereotypes only an indian-american would recognize\n.\nLabel: positive\nFor each snippet of text, label the sentiment of the text as positive or negative. The answer should be\nexact \u2019positive\u2019 or \u2019negative\u2019.\nText: whether you like rap music or loathe it , you ca n\u2019t deny either the tragic loss of two young men\nin the prime of their talent or the power of this movie .\nLabel: Negative\nFor each snippet of text, label the sentiment of the text as positive or negative. The answer should be\nexact \u2019positive\u2019 or \u2019negative\u2019.\nText: so , too , is this comedy about mild culture clashing in today \u2019s new delhi .\nLabel: It is not clear from this text snippet alone whether the sentiment expressed is positive or\nnegative. The text is simply describing the subject of a comedy. Additional context would be needed\nto determine the sentiment.\n",
    "1908.02591": "Anti-Money Laundering in Bitcoin: Experimenting with Graph\nConvolutional Networks for Financial Forensics\nMark Weber\u2217\nMIT-IBM Watson AI Lab\nmrweber@mit.edu\nGiacomo Domeniconi\u2217\nIBM Research\nGiacomo.Domeniconi1@ibm.com\nJie Chen\nMIT-IBM Watson AI Lab\nchenjie@us.ibm.com\nDaniel Karl I. Weidele\nIBM Research AI\ndaniel.karl@ibm.com\nClaudio Bellei\nElliptic\nclaudio@elliptic.co\nTom Robinson\nElliptic\ntom@elliptic.co\nCharles E. Leiserson\nMIT CSAIL\ncel@mit.edu\nABSTRACT\nAnti-money laundering (AML) regulations play a critical role in\nsafeguarding financial systems, but bear high costs for institutions\nand drive financial exclusion for those on the socioeconomic and\ninternational margins. The advent of cryptocurrency has intro-\nduced an intriguing paradox: pseudonymity allows criminals to\nhide in plain sight, but open data gives more power to investigators\nand enables the crowdsourcing of forensic analysis. Meanwhile\nadvances in learning algorithms show great promise for the AML\ntoolkit. In this workshop tutorial, we motivate the opportunity to\nreconcile the cause of safety with that of financial inclusion. We\ncontribute the Elliptic Data Set, a time series graph of over 200K\nBitcoin transactions (nodes), 234K directed payment flows (edges),\nand 166 node features, including ones based on non-public data;\nto our knowledge, this is the largest labelled transaction data set\npublicly available in any cryptocurrency. We share results from a\nbinary classification task predicting illicit transactions using varia-\ntions of Logistic Regression (LR), Random Forest (RF), Multilayer\nPerceptrons (MLP), and Graph Convolutional Networks (GCN),\nwith GCN being of special interest as an emergent new method for\ncapturing relational information. The results show the superiority\nof Random Forest (RF), but also invite algorithmic work to combine\nthe respective powers of RF and graph methods. Lastly, we consider\nvisualization for analysis and explainability, which is difficult given\nthe size and dynamism of real-world transaction graphs, and we\noffer a simple prototype capable of navigating the graph and ob-\nserving model performance on illicit activity over time. With this\ntutorial and data set, we hope to a) invite feedback in support of\nour ongoing inquiry, and b) inspire others to work on this societally\nimportant challenge.\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nKDD \u201919 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA\n\u00a9 2019 Association for Computing Machinery.\nCCS CONCEPTS\n\u2022 Security and privacy \u2192Database activity monitoring; \u2022 Com-\nputing methodologies \u2192Machine learning; \u2022 Applied com-\nputing \u2192Network forensics.\nKEYWORDS\nGraph Convolutional Networks, Anomaly Detection, Financial\nForensics, Cryptocurrency, Anti-Money Laundering, Visualization\nACM Reference Format:\nMark Weber, Giacomo Domeniconi, Jie Chen, Daniel Karl I. Weidele, Claudio\nBellei, Tom Robinson, and Charles E. Leiserson. 2019. Anti-Money Laun-\ndering in Bitcoin: Experimenting with Graph Convolutional Networks for\nFinancial Forensics. In Proceedings of ACM Conference (KDD \u201919 Workshop\non Anomaly Detection in Finance). ACM, New York, NY, USA, 7 pages.\n1\nTOWARD FINANCIAL INCLUSION\n\u201cIt\u2019s expensive to be poor.\u201d This is a common credo among advocates\nfor financial inclusion. It speaks to the fact that those on the margins\nof society suffer from restricted access to the financial system and\nhigher relative costs of participation.\nThe problem of restricted access (e.g. the ability to sign up for\na bank account) is, in part, an unintended consequence of increas-\ningly stringent anti-money laundering (AML) regulations, which,\nwhile essential for safeguarding the financial system, have a dis-\nproportionately negative effect on low-income people, immigrants,\nand refugees [16]. Approximately 1.7 billion adults are unbanked\n[7]. The problem of higher relative costs is also, in part, a function\nof AML policy, which enforces high fixed costs of compliance on\nmoney service businesses (MSBs) along with the fear of criminal\nand monetary penalties for noncompliance \u2013 \u201clow value\" customers\njust aren\u2019t worth the risk. Consider global remittances to low-and-\nmiddle-income countries, which reached a record high $529 billion\nin 2018, far outpacing the global aid contribution of $153 billion.\nThe current average cost of sending $200 is an expensive 7 per-\ncent, with some countries suffering rates of over 10 percent. The\nUnited Nations Sustainable Development Goal number 10.7 targets\na reduction to 3 percent by 2030.[12]\nAnd yet AML regulations cannot be summarily dismissed as over\nburdensome. Multi-billion dollar illicit industries like drug cartels,\nhuman trafficking, and terrorist organizations cause intense human\narXiv:1908.02591v1  [cs.SI]  31 Jul 2019\nKDD \u201919 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA\nWeber and Domeniconi, et al.\nsuffering around the world. The recent 1Malaysia Development\nBerhad (1MDB) money laundering scandal robbed the Malaysian\npeople of over $11 billion in taxpayer funds earmarked for the na-\ntion\u2019s development [22], with mega-fines and criminal indictments\nfor Goldman Sachs among others implicated in the wrongdoing.\nThe even more recent Danske Bank money laundering scandal in\nEstonia, which served as a hub for an estimated $200 billion in illicit\nmoney flows from Russia and Azerbaijan, similarly extracted an\nincalculable toll on innocent citizens of these countries and served\nimplicated institutions like Danske Bank and Deutsche Bank with\nbillions of dollars in losses [23].\nMoney laundering is not a victimless crime, and current methods\nfor the traditional financial system are doing a poor job of stopping\nit. Without reducing this complex challenge to data analysis alone,\nwe pose the question: with the right tools and open data, can we help\nreconcile the need for safety with the cause of financial inclusion?\n1.1\nAML in a cryptocurrency world\nThe advent of cryptocurrency introduced by Bitcoin [17] ignited an\nexplosion of technological and entrepreneurial interest in payment\nprocessing. Around the world, money transfer startups spun up to\ncompete with legacy banks and MSBs like Western Union. They\nfocused on enabling low-cost, peer-to-peer transfers of cash within\nand across borders using Bitcoin and other cryptocurrencies as the\n\u201crails\u201d (a commonly used term in this space). Many explicitly tar-\ngeted remittances and championed the cause of financial inclusion.\nAlongside these entrepreneurs grew a community of academics and\npolicy advocates supporting updated regulatory considerations for\ncryptocurrency.\nDampening this excitement was Bitcoin\u2019s bad reputation. Many\ncriminals used Bitcoin\u2019s pseudonymity to hide in plain sight, con-\nducting ransomware attacks and operating dark marketplaces for\nthe exchange of illegal goods and services.\nIn May 2019, the Financial Crimes Enforcement Network (Fin-\nCEN) of the United States issued new guidance on how the Bank\nSecrecy Act (BSA) of 1970 applies to cryptocurrency, or what Fin-\nCEN calls convertible virtual currencies (CVC) [18]. Consistent\nwith the BSA, the guidance calls for MSBs to generate individual-\nized risk assessments measuring exposure to money laundering,\nterrorism finance, and other financial crime. These assessments are\nbased on customer composition, geographies served, and financial\nproducts or services offered. The assessments must inform the man-\nagement of customer relationships, including the implementation\nof controls commensurate with risk; in other words, MSBs must not\nonly report suspicious accounts, but must also take action against\nthem (e.g. freeze them or shut them down). The guidance defines a\n\u201cwell-developed risk assessment\u201d as \u201cassisting MSBs in identifying\nand providing a comprehensive analysis of their individual risk\nprofile.\u201d Reinforcing the Know Your Customer (KYC) requirements\nof the BSA, the guidance requires MSBs to \u201cknow enough about\ntheir customers to be able to determine the risk level they represent\nto the institution.\u201d\nWhat it means to \u201cknow enough\u201d about one\u2019s customer is the\nsubject of much debate in compliance and policy circles. In practice,\none of the most challenging aspects of this is an implicit but effec-\ntively enforced requirement to not only know your customer, but to\nknow your customer\u2019s customer. In the fragmented data ecosystem\nof traditional finance, this aspect of compliance is often executed\nby phone calls between MSBs. But in the open system of Bitcoin,\nthe full graph transaction network data is publicly available, albeit\nin pseudonymous and unlabelled form.\nTo meet the opportunity this public data presents, cryptocur-\nrency intelligence companies have emerged to provide AML solu-\ntions tailored to the cryptocurrency domain. Whereas the pseudonymity\nof Bitcoin is an advantage for criminals, the public availability of\ndata is a key advantage for investigators.\n2\nTHE ELLIPTIC DATA SET\nElliptic is a cryptocurrency intelligence company focused on safe-\nguarding cryptocurrency ecosystems from criminal activity. For\nthis tutorial and as a contribution to the research community, we\npresent The Elliptic Data Set, a graph network of Bitcoin transac-\ntions with handcrafted features. As a contribution to the research\nand AML communities, Elliptic has agreed to share this data set pub-\nlicly. To our knowledge, it constitutes the world\u2019s largest labelled\ntransaction data set publicly available in any cryptocurrency.\n2.1\nGraph Construction\nThe Elliptic Data Set maps Bitcoin transactions to real entities\nbelonging to licit categories (exchanges, wallet providers, miners,\nlicit services, etc.) versus illicit ones (scams, malware, terrorist\norganizations, ransomware, Ponzi schemes, etc.). From the raw\nBitcoin data, a graph is constructed and labelled such that the nodes\nrepresent transactions and the edges represent the flow of Bitcoin\ncurrency (BTC) going from one transaction to the next one. A given\ntransaction is deemed licit (versus illicit) if the entity initiating the\ntransaction (i.e., the entity controlling the private keys associated\nwith the input addresses of a specific transaction) belongs to a licit\n(illicit) category1. Importantly, all features are constructed using\nonly publicly available information.\n2.1.1\nNodes and Edges. There are 203,769 node transactions and\n234,355 directed edge payments flows. For perspective, using the\nsame graph representation the full Bitcoin network has approxi-\nmately 438M nodes and 1.1B edges as of this writing. In the Elliptic\nData Set, two percent (4,545) are labelled class1 (illicit). Twenty-one\npercent (42,019) are labelled class2 (licit). The remaining transac-\ntions are not labelled with regard to licit versus illicit, but have\nother features.\n2.1.2\nFeatures. Each node has associated 166 features. The first 94\nfeatures represent local information about the transaction \u2013 includ-\ning the time step, number of inputs/outputs, transaction fee, output\nvolume and aggregated figures such as average BTC received (spent)\nby the inputs/outputs and average number of incoming (outgoing)\ntransactions associated with the inputs/outputs. The remaining 72\nfeatures, called aggregated features, are obtained by aggregating\ntransaction information one-hop backward/forward from the cen-\nter node - giving the maximum, minimum, standard deviation and\ncorrelation coefficients of the neighbour transactions for the same\ninformation data (number of inputs/outputs, transaction fee, etc.).\n1Note that for simplicity, this argument ignores mixer transactions where the inputs\nare controlled by multiple entities.\nAnti-Money Laundering in Bitcoin\nKDD \u201919 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA\nFigure 1: (Top) Fraction of illicit vs. licit nodes at different time steps in the data set. (Bottom) Number of nodes vs. time step.\n2.1.3\nTemporal Information. A time stamp is associated with each\nnode, representing an estimate of the time when the transaction is\nconfirmed by the Bitcoin network. There are 49 distinct time steps,\nevenly spaced with an interval of about two weeks. Each time\nstep contains a single connected component of transactions that\nappeared on the blockchain within less than three hours between\neach other; there are no edges connecting different time steps.\nClearly the nodes in a specific time step have associated time stamps\nvery close to each other, so effectively each one of them can be\nthought of as an instantaneous \u201csnapshot\u201d in time. The number of\nnodes for each time step is reasonably uniform over time (ranging\nfrom 1,000 to 8,000 nodes). See Figure 1.\n2.2\nNotes on Feature Construction\nThe licit versus illicit labelling process is informed by a heuristics-\nbased reasoning process. For example, a higher number of in-\nputs and the reuse of the same address is commonly associated\nwith higher address-clustering [10], which results in a degrade of\nanonymity for the entity signing the transaction. On the other hand,\nconsolidating funds controlled by multiple addresses in one single\ntransaction provides benefits in terms of transaction costs (fee). It\nfollows that entities eschewing anonymity-preserving measures for\nlarge volumes of user requests are likely to be licit (e.g. exchanges).\nIn contrast, illicit activity may tend to favor transactions with a\nlower number of inputs to reduce the impact of de-anonymizing\naddress-clustering techniques.\nAdditionally, there are two major challenges in building features\nfor Bitcoin transactions. The first is rooted in the size of the Bitcoin\nblockchain amounting to 200GB of compressed data and about 400\nmillion addressed transactions. Though not all transactions are\nincluded in the subset used in this study, it is still necessary to\naccess the complete blockchain in order to observe the full history\nof wallets participating in the selected transactions. To overcome\nthis, Elliptic uses a high-performance all-in-memory graph engine\nfor the computation of features.\nThe second challenge arises from the underlying graph structure\nof the data and the heterogeneity in the number of neighbors a\ntransaction can have. In building the 72 aggregated features, the\nproblem of heterogeneous neighborhoods is addressed by naively\nconstructing statistical aggregates (minimum, maximum, etc.) of the\nlocal features of a neighbor transaction. In general, this solution is\nsub-optimal because it carries a significant loss of information. We\naddress this in our forthcoming discussion of graph deep learning\nmethods, which may better account for the local graph topology.\n3\nTASK AND METHODS\nAt a high level, AML analytics is an anomaly detection challenge of\naccurately classifying a small number of illicit transactions in mas-\nsive, ever-growing data sets. Industry standard high false positive\nrates of upwards of 90% inhibit this effort. We want to reduce false\npositive rates without increasing false negative rates, i.e. include\nmore innocent people without allowing more criminals. Logistic\nRegression and Random Forest are among the benchmark methods\nfor this task. Graph deep learning has also emerged as potential\ntool for AML [21].\nIn the case of the Elliptic Data Set, the task to be performed\non this data is transaction screening for assessing the risk associ-\nated with a given transaction to-and-from cryptocurrency wallets.\nSpecifically, each unlabelled Bitcoin transaction is to be classified\nillicit or licit.\nKDD \u201919 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA\nWeber and Domeniconi, et al.\n3.1\nBenchmark Methods\nGiven the features previously described, benchmark machine learn-\ning methods use the first 94 features in supervised learning for\nbinary classification. Such techniques include Logistic Regression\n[1], Multilayer Perceptron (MLP) (ibid), and Random Forest [2]. In\nMLP, each input neuron takes in a data feature and the output is a\nsoftmax with a probability vector for each class. Logistic Regression\nand Random Forest are popular for AML, especially when used in\nconcert with one another for their respective advantages\u2014Random\nForest for accuracy and Logistic Regression for explainability. These\nmethods, however, do not leverage any graph information.\nIn the Elliptic Data Set, the local features are enhanced with a set\nof 72 features that contain information about the immediate neigh-\nbourhood. We will see the utilization of these features improves\nperformance. While this approach shows the graph structure carries\nin the binary classification problem, and that this can be used with\nstandard machine learning techniques, it is challenging to extend\nthe purely feature-based method beyond the immediate neighbour-\nhood. This drawback motivates the use of Graph Convolutional\nNetworks.\n3.2\nGraph Convolutional Networks (GCN)\nDeep learning on graph structured data is a subject of rapidly in-\ncreasing interest [3, 6, 8, 9, 14]. Dealing with combinatorial com-\nplexity inherent to graph structures poses scalability challenges\nfor practical applications, and significant strides have been made\nin addressing these challenges [5, 11, 24]. Specifically, we consider\nGraph Convolutional Networks (GCNs). A GCN consists of multiple\nlayers of graph convolution, which is similar to a perceptron but\nadditionally uses a neighborhood aggregation step motivated by\nspectral convolution.\nConsider the Bitcoin transaction graph from the Elliptic Data\nSet as G = (N, E), where N is the set of node transactions and E is\nthe set of edges representing the flow of BTC. The l-th layer of the\nGCN takes the adjacency matrix A and the node embedding matrix\nH(l) as input, and uses a weight matrix W (l) to update the node\nembedding matrix to H(l+1) as output. Mathematically, we write\nH(l+1) = \u03c3(b\nAH(l)W (l)),\n(1)\nwhere b\nA is a normalization of A defined as:\nb\nA = eD\u22121\n2 e\nAeD\u22121\n2 ,\ne\nA = A + I,\neD = diag\n \u00d5\nj\ne\nAij\n!\n,\nand \u03c3 is the activation function (typically ReLU) for all but the\noutput layer. The initial embedding matrix comes from the node\nfeatures; i.e., H(0) = X. Let there be L layers of graph convolutions.\nIn the case of node classification, the output layer is the softmax,\nwhere H(L) consists of prediction probabilities.\nOne sees a graph convolution layer is similar to a feed forward\nlayer, except for the multiplication with b\nA in the front. This matrix\nis motivated by spectral graph filtering on the graph Laplacian\nmatrix and it results from a linear functional of the Laplacian. On\nthe other hand, one may also interpret the multiplication with b\nA as\nan aggregation of the transformed embeddings of the neighboring\nnodes. The parameters of the GCN are the weight matrices W (l),\nfor different layers l.\nA 2-layer GCN, as often used, can be neatly written as\nH(2) = softmax(b\nA \u00b7 ReLU(b\nAXW (0)) \u00b7W (1)).\nA \u201cskip\u201d variant, which we find practically useful, inserts a skip con-\nnection between the intermediate embeddingH(1) = ReLU(b\nAXW (0))\nand the input node features X, resulting in the architecture\neH(2) = softmax(b\nA \u00b7 ReLU(b\nAXW (0)) \u00b7W (1) + X e\nW (1)),\nwhere e\nW (1) is a weight matrix for the skip connection. We call this\narchitecture Skip-GCN. When W (0) and W (1) are zero, Skip-GCN\nis equivalent to Logistic Regression. Hence, Skip-GCN should be at\nleast as powerful as Logistic Regression.\n3.3\nTemporal Modeling\nFinancial data are inherently temporal as transactions are time\nstamped. It is reasonable to assume there exists certain dynamics,\nalbeit hidden, that drive the evolution of the system. A prediction\nmodel will be more useful if it is designed in a manner to capture the\ndynamism. This way, a model trained on a given time period may\nbetter generalize to subsequent time steps. The better the model\ncaptures system dynamics, which are also evolving, the longer\nhorizon it can forest into.\nA temporal model that extends GCN is EvolveGCN [19], which\ncomputes a separate GCN model for each time step. These GCNs\nare then connected through a recurrent neural network (RNN) to\ncapture the system dynamics. Hence, the GCN model for a future\ntime step is evolved from those in the past, where the evolution\ncaptures the dynamism.\nIn EvolveGCN, the GCN weights are collectively treated as the\nsystem state. The model is updated upon an input to the system\nevery time, by using an RNN (e.g., GRU). The input is the graph\ninformation at the current time step. The graph information may\nbe instantiated in many ways; in EvolveGCN, it is represented by\nthe embeddings of the top-k influential nodes in the graph.\n4\nEXPERIMENTS\nHere we show experimental results obtained on the Elliptic Data\nSet. We performed a 70:30 temporal split of training and test data,\nrespectively. That is, the first 34 time steps are used for training\nthe model and the last 15 for test. We use a temporal split because\nit reflects the nature of the task. As such, GCN is trained in an\ninductive setting.\nWe first tested standard classification models for the licit/illicit\nprediction using three standard approaches: Logistic Regression\n(with default parameters from the scikit-learn Python package [4]),\nRandom Forest (also from scikit-learn, with 50 estimators and 50\nmax features), and Multilayer Perceptron (implemented in PyTorch).\nOur MLP had one hidden layer of 50 neurons and was trained for\n200 epochs by using the Adam optimizer and a learning rate of\n0.001.\nWe evaluated these models by using all the 166 features (referred\nto as AF), as well as only the local ones, i.e., the first 94 (referred to\nas LF). The results are summarized in the top part of Table 1.\nThe bottom part of Table 1 reports the results achieved when\nwe leveraged the graph structure of the data. We trained the GCN\nmodel for 1000 epochs using the Adam optimizer with a learning\nAnti-Money Laundering in Bitcoin\nKDD \u201919 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA\nFigure 2: Illicit F1 results over test time span.\nTable 1: Illicit classification results. Top part of the table\nshows results without the leverage of the graph information,\nfor each model are shown results with different input: AF\nrefers to all features, LF refers to the local features, i.e. the\nfirst 94, and NE refers to the node embeddings computed by\nGCN. Bottom part of the table shows results with GCN.\nIllicit\nMicroAVG\nMethod\nPrecision\nRecall\nF1\nF1\nLogistic RegrAF\n0.404\n0.593\n0.481\n0.931\nLogistic RegrAF+N E\n0.537\n0.528\n0.533\n0.945\nLogistic RegrLF\n0.348\n0.668\n0.457\n0.920\nLogistic RegrLF+N E\n0.518\n0.571\n0.543\n0.945\nRandomForestAF\n0.956\n0.670\n0.788\n0.977\nRandomForestAF+N E\n0.971\n0.675\n0.796\n0.978\nRandomForestLF\n0.803\n0.611\n0.694\n0.966\nRandomForestLF+N E\n0.878\n0.668\n0.759\n0.973\nMLPAF\n0.694\n0.617\n0.653\n0.962\nMLPAF+N E\n0.780\n0.617\n0.689\n0.967\nMLPLF\n0.637\n0.662\n0.649\n0.958\nMLPLF+N E\n0.6819\n0.5782\n0.6258\n0.986\nGCN\n0.812\n0.512\n0.628\n0.961\nSkip-GCN\n0.812\n0.623\n0.705\n0.966\nrate of 0.001. In our experiment we used a 2-layer GCN and, after\nhyper-parameter tuning, we set the size of the node embeddings to\nbe 100.\nThe task is a binary classification and the two classes are im-\nbalanced (see Figure 1). For AML, more important is the minority\nclass (i.e., the illicit class). Hence, we trained the GCN model using\na weighted cross entropy loss to provide higher importance to the\nillicit samples. After hyperparameter tuning, we opted for a 0.3/0.7\nratio for the licit and illicit classes. Table 1 shows the testing results\nin term of precision, recall, and F1 score for the illicit class. For the\nsake of completeness, we also show the micro-averaged F1 score.\nNote that GCN and the variant Skip-GCN outperform Logistic\nRegression, indicating the usefulness of the graph-based method\ncompared to one agnostic to graph information. On the other hand,\nin this case, the input features are quite informative already. Using\nthese features alone, Random Forest achieves the best F1 score. The\nrepresentation power of the input features is also reflected by the\ngain of Skip-GCN over GCN.\nAnother insight from Table 1 is obtained from the comparison\nbetween methods trained on all the features (AF) and those on\nonly the 94 local features (LF). For all the three evaluated mod-\nels, the aggregated information led to higher accuracy, indicating\nthe importance of the graph structure in this context. With this\nobservation, we further evaluated the methods with an enhanced\ninput feature set. The goal of this experiment was to show that\ngraph information was useful to enhance the representation of a\ntransaction. In this setting, we concatenated the node embeddings\nobtained from GCN with the original features X. Results show that\nwith the enhanced feature set the accuracy of the model improves,\nfor both full features (AF + NE) and local features (LF + NE).\nTable 2 compares the prediction performance between the non-\ntemporal GCN and the temporal EvolveGCN. EvolveGCN consis-\ntently outperforms GCN, although the improvement is not substan-\ntial for this data set. One avenue of further investigation is the use\nof alternative forms of system input to drive the recurrent update\ninside GRU.\nTable 2: GCN v.s. EvolveGCN\nGCN\nEvolveGCN\nPrecis.\nRecall\nF1\nPrecis.\nRecall\nF1\nIllicit\n0.812\n0.623\n0.705\n0.850\n0.624\n0.720\nMicroAVG\n0.966\n0.966\n0.966\n0.968\n0.968\n0.968\nThe Dark Market Shutdown. An important consideration for\nAML is the robustness of a prediction model with respect to emerg-\ning events. One interesting aspect of this data set is the sudden\nclosure of a dark market occurring during the time span of the data\n(at time step 43). As seen in Figure 2, this event causes all methods\nto perform poorly after the shutdown. Even a Random Forest model\nre-trained after every test time step, assuming the availability of\nground truth after each time, is not able to reliably capture new\nillicit transactions after the dark market shutdown. The robustness\nof methods to such events emerges as a major challenge to address.\nKDD \u201919 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA\nWeber and Domeniconi, et al.\n5\nDISCUSSION\nWe have seen Random Forest significantly outperforms Logistic\nRegression; in fact, it also outperforms GCN even though the latter\nis empowered by the graph structure information. Random Forest\nuses a voting mechanism to ensemble the prediction results from\na number of decision trees, each trained by using a subsample of\nthe data set. GCN, in contrast, like most deep learning models,\nuses Logistic Regression as the final output layer; hence, it can be\nconsidered a nontrivial generalization of Logistic Regression.\nThe question arises: Is it possible to combine a Random Forest\nwith a graph neural network? One simple idea is to augment the\nnode features with the embeddings computed from GCN before\nrunning Random Forest. This idea helps only marginally according\nto prior experimentation. Another idea, as proposed by [13], is to\nparameterize every node in the decision tree(s) by using a feed-\nforward neural network. This idea organically combines Random\nForest with neural networks, but it does not suggest how graph in-\nformation can be incorporated. One possible approach is to replace\nthe Logistic Regression output layer in GCN by this differentiable\nversion of the decision tree, so that end-to-end training is enabled.\nWe leave the execution of this idea as future investigation.\n6\nGRAPH VISUALIZATION\nLastly, in support of analysis and explainability, which are impor-\ntant for AML compliance, we have created a visualization prototype\ncalled Chronograph. Visualizing a high-dimensional graph imposes\na layer of complexity on top of plain feature vectors with respect to\nexplaining model performance. Chronograph aims to address this\nby supporting the human analyst with an integrated representation\nof the model.\n6.1\nVisual Investigation of the Elliptic Data Set\nIn Chronograph, transactions are visualized as nodes of a graph\nwith edges representing the flow of BTC from one transaction to\nthe next. Node coordinates are computed simultaneously across all\ntime steps using the projection technique UMAP [15]. This global\ncomputation makes layouts comparable across time. The time step\nslider control at the top of the interface allows the user to navigate\nthrough time by rendering only nodes in the selected time step.\nIllicit transactions are dyed red; licit ones are blue. Unclassified\ntransactions are not colored.\nWhen clicking a transaction node, or entering a transaction ID\nin the control on the left (filters as substring) the visualization\nhighlights the selected transaction(s) in orange, and all neighboring\ntransactions (in-or-out-flowing) in green. On the left of the interface,\nthe user can see general statistics on the graph and a table about\ntransfer numbers between different transaction classes.\nIn this simple prototype, Chronograph enables simple explo-\nration scenarios to visually inspect clusters and their existence\nover time, observe conspicuous transfer patterns, or detect other\ndeviations like single outliers. As a more involved use case we addi-\ntionally facilitate the degree of freedom of the input to the UMAP\ncomputation: raw transaction feature data (Figure 4a), as well as\nneuron activations of the last layer of the network (Figure 4b) seem\nto be two interesting alternatives; similar approaches have been\nproposed for general neural networks Rauber et al. [20]. Differences\nin the resulting visualizations would then hint towards peculiarities\nof the model, i.e. we postulate shifts in similarities among the data\ncan be indicative to explain which underlying features matter to\nthe model.\nFigure 4 shows the results from the two alternative inputs for\na single time step, with raw feature data in the top and model\nactivations in the bottom row. We further dye the nodes using\nactual labels in the left column, and GCN-predicted labels in the\nright column, and obtain a total of 4 network visualizations.\nIn the model-based layout illicit nodes are less scattered but\nmore concentrated, which seems to be a desirable property: illicit\nnodes should share some important characteristics, and similarity\nof nodes yields closer proximity in the layout. However, since they\nare not perfectly collapsing in one location it is quite plausible\nthere are qualitative differences within the set of illicit nodes. The\nvisualizations further reveals where exactly the model is unable to\ndetect illicit nodes. In case of multiple erroneous predictions in a\nnearby area this could further hint to a systemic underperformance\nof the the model. Studying the characteristics of such transactions\nin detail could inspire the discussion from new angles and lead to\nfurther model improvements.\na) Projection of raw transaction feature vectors\nb) Projection of last GCN layer activations\nFigure 3: Two alternative inputs to UMAP projection. Left:\ncolored by input labels; right: colored by GCN prediction.\n7\nSUMMARY\nIn summary, we have set forth cryptocurrency forensics, and specif-\nically Bitcoin, as a unique ecosystem for crowdsourcing the develop-\nment of new methods to fight criminal activity. We have contributed\na large, labelled transaction data set to the AML community, the\nlikes of which has never before been publicly available. We have\nAnti-Money Laundering in Bitcoin\nKDD \u201919 Workshop on Anomaly Detection in Finance, August 2019, Anchorage, AK, USA\nFigure 4: Chronograph User Interface: User can navigate\nthrough time-sliced transaction data and observe transac-\ntion patterns and patterns of change. Illicit transactions are\ndyed red. Further statistics are displayed on the left.\nshared early experimental results using a variety of methods includ-\ning Graph Convolutional Networks, and discussed possible next\nsteps for algorithmic advances. We have provided a prototype for\nvisualization of such data and models for augmenting human anal-\nysis and explainability. Most important, we hope to have inspired\nothers to work on this societally important challenge of making\nour financial systems safer and more inclusive.\nACKNOWLEDGMENTS\nThis work was funded by the MIT-IBM Watson AI Lab (mitibm.mit.edu),\na joint research initiative between the Massachusetts Institute of\nTechnology and IBM Research. Data and domain expertise were\nprovided by Elliptic (www.elliptic.co).\nREFERENCES\n[1] Christopher Bishop. 2006. Pattern Recognition and Machine Learning. Springer-\nVerlag.\n[2] Leo Breiman. 2001. Random forests. Machine learning 45, 1 (2001), 5\u201332.\n[3] Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral\nNetworks and Locally Connected Networks on Graphs. In ICLR.\n[4] Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa, Andreas\nMueller, Olivier Grisel, Vlad Niculae, Peter Prettenhofer, Alexandre Gramfort,\nJaques Grobler, Robert Layton, Jake VanderPlas, Arnaud Joly, Brian Holt, and Ga\u00ebl\nVaroquaux. 2013. API design for machine learning software: experiences from\nthe scikit-learn project. In ECML PKDD Workshop: Languages for Data Mining\nand Machine Learning. 108\u2013122.\n[5] Jie Chen, Tengfei Ma, and Cao Xiao. 2018. FastGCN: Fast Learning with Graph\nConvolutional Networks via Importance Sampling. In ICLR.\n[6] Micha\u00ebl Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convo-\nlutional Neural Networks on Graphs with Fast Localized Spectral Filtering. In\nNIPS.\n[7] Demirguc-Kunt, Leora Klapper, Dorothe Singer, Sinya Ansar, and Jake Hess. 2017.\nThe Global Findex Database 2017: Measuring Financial Inclusion and the Fintech\nRevolution.\n[8] Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E.\nDahl. 2017. Neural Message Passing for Quantum Chemistry. In ICML.\n[9] William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive Representation\nLearning on Large Graphs. In NIPS.\n[10] Martin Harrigan and Christoph Fretter. 2016. The unreasonable effectiveness\nof address clustering. In 2016 Intl IEEE Conferences on Ubiquitous Intelligence &\nComputing, Advanced and Trusted Computing, Scalable Computing and Commu-\nnications, Cloud and Big Data Computing, Internet of People, and Smart World\nCongress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld). IEEE, 368\u2013373.\n[11] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with\nGraph Convolutional Networks. In ICLR.\n[12] Knomad and World Bank Group. 2019. Migration and Remittances: Recent\nDevelopments and Outlook. Migration and Development Brief 31.\n[13] Peter Kontschieder, Madalina Fiterau, Antonio Criminisi, and Samuel Rota Bulo.\n2015. Deep Neural Decision Forests. In ICCV.\n[14] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2016. Gated\nGraph Sequence Neural Networks. In ICLR.\n[15] Leland McInnes, John Healy, and James Melville. 2018. Umap: Uniform man-\nifold approximation and projection for dimension reduction. arXiv preprint\narXiv:1802.03426 (2018).\n[16] Daniel J. Mitchell. 2012. World Bank Study Shows How Anti-Money Laundering\nRules Hurt the Poor. Forbes.\n[17] Satoshi Nakamoto. 2008. Bitcoin: A peer-to-peer electronic cash system. (2008).\n[18] Financial Crimes Enforcement Network. 2019. Application of FinCEN\u00e2\u0102\u0179s\nRegulations to Certain Business Models Involving Convertible Virtual Currencies.\nFIN-2019-G001 (May 2019).\n[19] Aldo Pareja, Giacomo Domeniconi, Jie Chen, Tengfei Ma, Toyotaro Suzumura, Hi-\nroki Kanezashi, Tim Kaler, and Charles E. Leiserson. 2019. EvolveGCN: Evolving\nGraph Convolutional Networks for Dynamic Graphs. Preprint arXiv:1902.10191.\n[20] Paulo E Rauber, Samuel G Fadel, Alexandre X Falcao, and Alexandru C Telea. 2016.\nVisualizing the hidden activity of artificial neural networks. IEEE transactions on\nvisualization and computer graphics 23, 1 (2016), 101\u2013110.\n[21] Mark Weber, Jie Chen, Toyotaro Suzumura, Aldo Pareja, Tengfei Ma, Hiroki\nKanezashi, Tim Kaler, Charles E. Leiserson, and Tao B. Schardl. 2018. Scalable\nGraph Learning for Anti-Money Laundering: A First Look. CoRR abs/1812.00076\n(2018). arXiv:1812.00076 http://arxiv.org/abs/1812.00076\n[22] Wikipedia. [n. d.]. 1Malaysia Development Berhad scandal.\n[23] Wikipedia. [n. d.]. Danske Bank money laundering scandal.\n[24] Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton,\nand Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-Scale\nRecommender Systems. In KDD.\n",
    "2307.01411": "Web3Recommend\nDecentralised recommendations with trust and relevance\n\u2014 MSc. Thesis \u2014\nRohan Madhwal\nDelft University of Technology\nDelft, The Netherlands\nR.Madhwal@student.tudelft.nl\nJohan Pouwelse\nDelft University of Technology\nDelft, The Netherlands\nJ.A.Pouwelse@tudelft.nl\nAbstract\u2014Web3Recommend is a decentralized Social Recom-\nmender System implementation that enables Web3 Platforms\non Android to generate recommendations that balance trust\nand relevance. Generating recommendations in decentralized\nnetworks is a non-trivial problem because these networks lack\na global perspective due to the absence of a central authority.\nFurther, decentralized networks are prone to Sybil Attacks in\nwhich a single malicious user can generate multiple fake or\n\u201cSybil\u201d identities. Web3Recommend relies on a novel graph-\nbased content recommendation design inspired by GraphJet, a\nrecommendation system used in Twitter enhanced with Meri-\ntRank, a decentralized reputation scheme that provides Sybil-\nresistance to the system. By adding MeritRank\u2019s decay param-\neters to the vanilla Social Recommender Systems\u2019 personalized\nSALSA graph algorithm, we can provide theoretical guarantees\nagainst Sybil Attacks in the generated recommendations. Similar\nto GraphJet, we focus on generating real-time recommendations\nby only acting on recent interactions in the social network,\nallowing us to cater temporally contextual recommendations\nwhile keeping a tight bound on the memory usage in resource-\nconstrained devices, allowing for a seamless user experience.\nAs a proof-of-concept, we integrate our system with Music-\nDAO, an open-source Web3 music-sharing platform, to generate\npersonalized, real-time recommendations. Thus, we provide the\nfirst Sybil-resistant Social Recommender System, allowing real-\ntime recommendations beyond classic user-based collaborative\nfiltering. The system is also rigorously tested with extensive\nunit and integration tests. Further, our experiments demonstrate\nthe trust-relevance balance of recommendations against multiple\nadversarial strategies in a test network generated using data from\nreal music platforms.\nAuthor\u2019s note: The source code, tests, and experiments performed\nherein are open-source and can be found on GitHub1\nI. INTRODUCTION\nThe recent decade has witnessed an explosion of user-\ngenerated data on the Internet. According to a study from IBM\ncalled \u201cThe Big Data Problem\u201d, users generate 2.5 quintillion\nbytes of data daily. In fact, 90 percent of the data in the world\ntoday was created in the last two years alone. [1]\nWhile this explosive growth in the amount of digital infor-\nmation available online provides a plethora of options for a\ndiverse range of users and interests, it also results in the hin-\ndrance of timely access to items of interest and relevance since\n1github.com/rmadhwal/trustchain-superapp/tree/TrustedRecommendations\nfinding anything useful requires time-intensive sifting through\ntroves of data, a majority of which is often entirely irrelevant.\n[2], [3] In the words of neuroscientist Daniel J. Levitin, \u201cThe\ninformation age is drowning us with an unprecedented deluge\nof data\u201d. [4]\nThe harms of information overload exceed beyond simple\ntime wastage with studies showing that it can lead to a\ndecrease in efficiency, increased stress, and even ill-health. [5]\nThe problem is exacerbated in social media platforms in\nthe modern age, where anyone can be a content creator.\n[6] Statistics from the popular social media platform TikTok\nwhich boasts over 1 billion monthly active users show that\n83% of the platform\u2019s users have published a video. [7]\nThe cardinal objective of a social media platform that\naims to be successful and vibrant is an active and engaged\nuser base. Achieving user engagement boils down to pre-\nsenting the most engaging and relevant content to each user.\nHowever, popularity and success are a double-edged sword\nsince the abundance of users and content on these platforms\nfloods users with huge amounts of information, posing a\ngreat challenge regarding information overload. While search\ncapabilities alleviate the problem, users often need help to\nexpress keywords that convey requirements about the type of\ncontent they would be interested in. Further, users tend to have\ndiverse tastes, and the quality of content may be subjective\ndepending on the user searching for it. Therefore, beyond\nsimple searching capabilities, personalization is also required\nto make the content attractive and relevant to each user. [8],\n[9]\nA Social Recommender System is an intelligent system that\nfilters the massive amounts of information on social media\nplatforms and recommends useful items and information to\nusers based on their personalized needs, which are inferred\nthrough unique explicit and implicit interactions within the\nsocial network. In this way, Social Networks and their Recom-\nmender Systems tend to have a symbiotic relationship since\nthe quality of recommendations catered to users allows the\nnetworks to grow, providing more interactions and higher-\nquality recommendations. [10]\nGraphJet [11] is an example of a graph-based Social Recom-\n1\narXiv:2307.01411v1  [cs.DC]  4 Jul 2023\nmender System used to generate Twitter content recommen-\ndations. GraphJet can provide personalized, real-time content\nrecommendations for Twitter users, i.e., for a given user, it can\nrecommend tweets that the user may be interested in based\non the user\u2019s history and social interactions. To serve these\nrecommendations, a personalized SALSA algorithm [12] is\nrun on a bi-partite graph of interactions between users and\ntweets. The system assumes that a single server can store the\nentire graph in its memory.\nHowever, existing Social Recommender Systems such as\nGraphJet are designed to work in traditional centralized social\nnetworks. In these centralized networks, users trust third-party\nservice providers (such as Meta/Twitter/Google) with their\ndata and provide them with recommendations. Recently, there\nhas been an erosion in this trust due to user privacy violations,\nwhether intentional violations through the sale of data to third\nparties [13] or unintentional violations through the loss of data\nthrough hacking breaches in the platforms. [14]\nThis erosion of trust has led to a rise in the popularity of\n\u201cWeb3\u201d, which leverages decentralized technologies such as\ndistributed ledgers to offer decentralized alternatives to central-\nized platforms. [15] Web3 platforms allow direct interactions\nbetween users without third-party intermediaries or centralized\nservers by leveraging communal infrastructure and resources\nprovided by the participating individuals.\nThis\npaper\naddresses\nthe\nchallenges\nof\ngenerating\nrecommendations\nin\nWeb3\nplatforms\nby\npresenting\nWeb3Recommend, a novel distributed Social Recommender\nSystem. Our approach integrates a graph-based content\nrecommendation\nalgorithm\ninspired\nby\nGraphJet\nwith\nMeritRank\n[16],\na\nSybil\ntolerant\nfeedback\naggregation\nmechanism. By leveraging a personalized SALSA algorithm\nenhanced with Sybil-resistant random walks, we aim to\nbalance trustworthiness and relevance in recommendations.\nWeb3Recommend contributes to the existing body of re-\nsearch by providing an end-to-end implementation that can\nbe seamlessly integrated into any Web3 platform running on\nAndroid. We fully implemented the recommender to generate\nmusic recommendations for users of MusicDAO [17], an open-\nsource Web3 music-sharing platform that offers a decentral-\nized alternative to Spotify/Apple Music.\nFirst, we describe the problem that our system aims to\nsolve in section II. Next, we present the key features of our\nsolution in section III. Then we provide some background on\nthe concepts discussed and techniques used in our solution\nin sections IV, V, and VI. Our system\u2019s model, assumptions,\nand limitations are discussed in section VII. In section VIII\nwe detail the implementation of the significant components\nin Web3Recommend. The details on how we combined the\ntwo systems to generate our recommendations are presented\nin section IX.\nFinally, in section XI, we demonstrate the trust-relevance\nbalance of recommendations through four sets of experiments.\nThe first two sets of experiments show that the recommenda-\ntions generated are relevant and that the relevance of non-Sybil\nnodes is not too greatly diminished with increasing MeritRank\ndecay parameters. The last two sets of experiments involve\nadversarial Sybil attacks, which allow us to demonstrate the\nSybil resistance of the social recommender system.\nFig. 1: Recommendations generated in MusicDAO\nII. PROBLEM DESCRIPTION\nGenerating recommendations in Web3 platforms poses\nunique challenges compared to traditional centralized models.\nTwo of the main challenges are discussed below:\n1) Lack of a global perspective: Decentralized systems\nrequire more design, planning, and management than their\ncentralized counterparts. The main technical problem that\ndecentralized systems face is their lack of global (centralized)\nknowledge. In any single node inside the system, it is difficult\nto have a holistic view about the rest of the network. [18]\nThis problem is exacerbated by the lack of a single leader\nwho can make ad-hoc decisions in the networks, requiring all\nrules of the system to be pre-determined before the system\ngoes live, further complicating the design space.\n2\n2) The Sybil Attack: In conventional Social Recommender\nSystems, a user\u2019s prior experience can be viewed as a vote in\nfavor of certain items. Using a Sybil Attack [19], an attacker\ncan create a potentially unlimited number of fake identities (or\nSybils) to cast misleading votes.\nThus, by creating malicious users or identities, a bad actor\ncould mislead the system into recommending their desired\nitems. The problem becomes important when considering the\nprevalence of abuse, fraud, and spam on online social media\nplatforms. [20] Carrying out such an attack is not incredibly\ncomplicated, with existing solutions such as Tube Automator\nmaking such attacks readily available to malicious users. [21]\nRecommender systems in centralized networks are relatively\nmore secure from Sybil attacks due to the centralized nature of\nthe system. Centralized systems often require user authentica-\ntion and verification, making it more difficult for malicious ac-\ntors to create multiple fake accounts to manipulate the ranking\nof items. Additionally, centralized systems have the advantage\nof monitoring user behavior and detecting anomalies, such as\nunusual activity patterns or highly repetitive actions, which\ncould indicate the presence of a Sybil attack. This detection is\npossible because of the many skilled attendants dedicated to\nmaintaining and improving system capabilities in centralized\nsystems. These attendants can develop measures to prevent\nSybil attacks, such as restricting the number of user actions\nthat can be performed within a specific time frame or intro-\nducing identity verification requirements.\nFurther, the decentralized nature of Web3 platforms, cou-\npled with their pseudonymity and anonymity, creates an en-\nvironment where Sybil attacks can occur more easily. Unlike\ncentralized systems, where user identities are typically veri-\nfied, Web3 platforms prioritize user privacy and allow users\nto operate under multiple pseudonyms, making establishing\nusers\u2019 authenticity and credibility challenging.\nTherefore, creating a trustable and reliable decentralized\nrecommender system for Web3 platforms is challenging due to\nthe lack of centralized infrastructure, making it easier for mali-\ncious users to create and control multiple identities, manipulate\nthe ranking of items, and compromise the trustworthiness of\nrecommendations. Therefore, creating decentralized recom-\nmender systems requires new approaches that can address the\nchallenges of decentralized networks, including Sybil attacks,\nlimited resources, and lack of trust among users. [22]\nIII. KEY FEATURES OF WEB3RECOMMEND\n1) Based on Monte Carlo-type methods relying on ran-\ndom walks\nWeb3Recommend uses personalized ego-centric random\nwalks to perform computations of estimated Personalized\nPage Rank and SALSA values for nodes in the network.\nThese values are then used to generate recommendations\nin the system. It has been shown that Monte Carlo\nmethods can provide very good probabilistic estimations\nfor Page Rank and SALSA. They are also much faster\nand parallelizable than the conventional power iteration\nmethod, making them a good choice for an online recom-\nmendation system. [23] Additionally, by enhancing the\nrandom walks in these methods with decay parameters\nfrom MeritRank, Web3Recommend is also able to limit\nthe influence of Sybils in these estimations. They also al-\nlow us to create a simple, understandable, yet sufficiently\nexpressive system to generate relevant, trustworthy rec-\nommendations. Random walks allow us to define a large\ndesign space, allowing room for customization to various\nuse cases in different applications (e.g., social search)\nand contexts. Further, random walks act as \u201csocial proof\u201d\nfor the recommendations, allowing users to understand\nbetter why certain items were recommended, leading to\nhigher user engagement. There is also room for further\nincreasing the quality of generated recommendations by\nfeeding the output from our random walks as input to\nmachine learning models. Still, in our case, the direct\noutput is sufficient for user consumption.\n2) Each node stores the entire interaction graph between\nusers and items, which is synchronized using an edge\ngossiping mechanism\nWhile readers might find storing the entire graph in a\nsingle node/device strange, graph partitioning remains a\ncomplex problem in large, dynamically changing graphs\ndespite much work and progress in the field. [24] Achiev-\ning graph partitioning would require implementing a\nfully-distributed graph progressing engine and further add\nhigh communication costs to the system. Additionally, in\na P2P Web3 platform, users are not expected to be always\navailable/online. Thus, like GraphJet, Web3Recommend\nassumes that all nodes store the entire graph in memory.\nOur compact graph serialization techniques enable storing\nup to a billion edges in less than 8GB of memory. Given\nthe hardware present in modern devices and Moore\u2019s Law,\nthis assumption is not very unreasonable.\n3) Bootstrapping mechanisms\nThe \u201cnew user\u201d problem in Social Recommender systems\n[25] necessitates bootstrapping mechanisms to introduce\nnew users to the network. Web3Recommend includes\ntwo bootstrapping mechanisms: 1) A similarity-based\nmechanism for finding similar users, allowing new users\nto find users they can trust 2) A personalized page\nrank for creating a circle of trust which can be used\nfor recommending relevant items to users who haven\u2019t\nconsumed many items and thus don\u2019t have any existing\nedges in the interaction graph\nIV. BACKGROUND ON TRUST\nThe system presented in this paper relies on the (incre-\nmental) computation of personalized PageRank and SALSA\naugmented with principles from MeritRank. We also build on\ntop of the GraphJet recommender system by Twitter. In this\nsection, we provide a quick review of these methods.\n3\nA. PageRank\nOne of the world\u2019s most widely known ranking systems is\nGoogle\u2019s PageRank [26], which is still used (along with other\nalgorithms) to rank websites for user queries on Google.\nPageRank determines a rough estimate of the relative im-\nportance of a website by computing a ranking for every web\npage. The underlying assumption of PageRank is that a more\nimportant website is more likely to receive links from other\nwebsites than a less important website i.e., that the existence of\na hyperlink u \u2192v implies that the page u votes for the quality\nof page v and hence, the most important page receives most\nvotes. PageRank gave birth to topic-sensitive or personalized\nranking and other hyperlink-based centrality measures. [27]\nMore formally, let V represent the set of all web pages in a\nnetwork. A web graph is the directed graph which consists of\nthe vertex set V , and the hyperlinks between pages represent\nthe edges in the network. Further, let r be the preference vector\nwhich induces a probability distribution over V , and c \u2208(0, 1)\nbe the reset probability.\nThen, the PageRank vector p is the solution of the following\nequation: [28]\np = (1 \u2212c) \u00d7 pA + c \u00d7 r\n(1)\nIf r is uniform over V then p is referred to as the global\nPageRank vector. In this paper, the special case where for\nsome web page x, the xth coordinate of r is 1, and the\nrest of the coordinates are 0, the solution of r represents\nthe Personalized PageRank of web page x and is denoted as\nPPR(x).\nNote that it is also equivalent to interpret PageRank with\nthe Random Surfer model [29] where PageRank is simply the\nstationary distribution of a random walk where at each step,\nassuming we are at a specific web page u, with probability c\nwe jump to a random web page v, and with probability 1 \u2212c\nwe follow a randomly chosen outgoing edge (or hyperlink)\nfrom u to a new web page w. In this model, Personalized\nPage Rank is the same as PageRank except that all random\nwalks start and jump randomly to the seed node x for which\nwe are personalizing the PageRanks. [30]\nB. SALSA\nStochastic Approach for Link-Structure Analysis or SALSA\nis a web page ranking algorithm similar to PageRank and\nHITS [31], which attempts to extract information from the\nlink structure of a networked environment to associate two\nscores with every node v, the hub score hv and authority\nscore ax. As the name suggests, ax reflects how much of an\nauthority a node is on a specific topic. While the notion of\nauthority is pretty broad, the intuitive idea is that in the context\nof a particular query, links from one node to another express\na considerable amount of latent human judgment, and that\njudgment is precisely what is needed to formulate the notion of\nauthority. Hence, if many nodes point to another node, it will\npossess a high authority score. hv, on the other hand, reflects\nhow well nodes point to authorities, so if a node largely links\nto other nodes that are considered very authoritative, it will\nhave a high hv.\nMore formally, if E is the set of all edges in the graph and\nindeg(x) and outdeg(v) are the in-degrees and out-degrees\nof the node respectively then:\nhv =\nX\n{x|(v,x)\u2208E}\nax\nindeg(x)\n(2)\nax =\nX\n{v|(v,x)\u2208E}\nhv\noutdeg(v)\n(3)\nIt is worth noting that, unlike PageRank, where we only\nhave forward random walks, SALSA consists of a forward-\nbackward random walk where the walk alternates between\nforward and backward steps.\nSimilar to Personalized PageRanks, we also have Personal-\nized SALSA, which tailors the hub and authority scores to\na single root node. As in Personalized PageRank, we can\nhave random jumps to the seed node in the personalized\nversion of SALSA. Assuming that the seed node is u, hv,u,\nthe personalized SALSA hub score and ax,u, the personalized\nSALSA authority score can be represented as:\nhv,u = c \u00d7 \u03b4u,v + (1 \u2212c) \u00d7\nX\n{x|(v,x)\u2208E}\nax\nindeg(x)\n(4)\nax,u =\nX\n{v|(v,x)\u2208E}\nhv\noutdeg(v)\n(5)\nNotice that in this setting, the hub and authority scores\ncan be interpreted as the similarity and relevance scores,\nrespectively. This ability of personalized SALSA to create\ntailored recommendations for specific root nodes is used later\non inside our recommendation system.\nC. GraphJet\nGraphJet is a graph-based system for generating real-time\ntweet recommendations on Twitter. The recommendation al-\ngorithm is based on an adaptation of personalized SALSA,\nwhich involves random walks in a bi-partite graph of users\nand tweets. Formally, GraphJet manages a dynamic, sparse,\nundirected bipartite graph G = (U, T, E) where U represents\nusers in Twitter, T represents tweets, and E represents inter-\nactions between the users and tweets over a temporal window.\nHence, the bipartite graph G consists of two sets of nodes\nU and T. Users from U are always on the left side of the\nrandom walk and represent hubs, while tweets from T are on\nthe right side and represent authorities. Figure 2 demonstrates\na sample bi-partite graph used by GraphJet, where the left\nside consists of users from the \u201ccircle of trust\u201d of the user\nwhose recommendations are being generated, and the right\nside includes tweets the users in the circle interacted with. The\ncircle of trust is constructed using a personalized PageRank\nalgorithm.\nGraphJet maintains and updates the bipartite graph by\nkeeping track of user-tweet interactions over the most recent n\n4\nhours. Periodically, edges older than n hours are discarded to\nensure that memory consumption doesn\u2019t increase boundlessly.\nExperiments show that this pruning does not have a noticeable\nimpact on the system\u2019s recommendation quality. The system\nsupports high-performance ingestion of real-time interactions\nand generations of recommendations.\nBelow is a simplified description of the SALSA algorithm\nrun inside GraphJet:\n1) The random walk begins from the vertex u in the left-\nhand side of the bi-partite graph corresponding to the\nquerying user\n2) An incident node from u to the right-hand side of the\ngraph is uniformly selected to a tweet t on the right-hand\nside of the bi-partite graph\n3) From t, an incident edge is selected uniformly back to\nthe left-hand side to another node v\n4) This is repeated an odd number of steps\nFigure 3 demonstrates a sample random walk in one iter-\nation of the above SALSA algorithm. To introduce person-\nalization, a reset probability as described in IV-B above is\nused, which restarts the random walk from vertex u to ensure\nthat the random walk doesn\u2019t \u201cstray\u201d too far from the query\nvertex. Further, it may also be possible that the querying user\ndoesn\u2019t have any existing interactions in the bi-partite graph,\neither because the last interaction was more than n hours ago\nor because they are a new user. In this case, the random walk\ncould start from a seed set instead of from the query user\u2019s\nnode. This seed set is configurable, but the usual choice is to\nuse the user\u2019s circle of trust constructed using Personalized\nPageRank.\nAfter constructing the bi-partite graph, multiple instances\nof the SALSA algorithm are run, assigning hub scores to the\nleft side and authority scores to the right. The vertices on\nthe right-hand side are then ranked and presented as tweet\nrecommendations to the user. The vertices on the left-hand\nside are also ranked and, based on the homophily principle,\ncan be additionally catered as \u201csimilar user\u201d recommendations.\nThe GraphJet paper suggests that the algorithm is effective\nbecause it is able to capture the recursive nature of the user\nrecommendation problem. A user u is also bound to like tweets\nliked by users similar to u. These users are in turn similar to u\nif they follow the same (or similar) users. Personalized SALSA\noperationalizes this idea, providing similar users to u on the\nleft-hand side and tweets they like on the right-hand side. The\nrandom walk in SALSA also ensures equitable distribution of\nscores out of the vertices in both directions.\nV. BACKGROUND ON DECENTRALISATION\nA. Decentralisation\nThe term \u201cdecentralized network\u201d was initially introduced\nby Paul Baran, one of the pioneers of packet switching.\nNetworks can generally be classified into two types: \u201cstar\u201d\nor centralized networks, and \u201cgrid\u201d or distributed networks.\nIn a star/centralized network, all nodes are connected to a\ncentral node, requiring participants to go through this central\nFig. 2: Example of bi-partite graph used in GraphJet\nFig. 3: Example of a random walk in GraphJet\u2019s\nPersonalized SALSA\ncomponent to interact with one another. In contrast, distributed\nnetworks have no central node, enabling direct communication\nbetween nodes without reliance on a centralized point.\nBaran termed networks that utilized a combination of cen-\ntralized and distributed components as \u201cdecentralized\u201d since\nthey lacked a single, central point of failure. [32] Figure 4\nillustrates these differerent network types.\nIn contemporary literature, the term \u201cdecentralized network\u201d\nrefers to networks where instead of relying on large centralised\nplatforms, participants and contributors control the technology,\ncontent, and infrastructure. This control manifests in various\nways, such as participants managing specific parts of the\ninfrastructure, collaborators owning their own private data silos\nthat are queried during network discovery, and participants\n5\nFig. 4: a) Centralized network b) Decentralised network c) Distributed network\nCardinal architectural insight from Baran\u2019s 1964 paper [32]\nhaving autonomy in determining the operational details of the\nnetwork. [33]\nTwitter serves as an example of a centralized network, where\nthe platform owns all user-generated content. Conversely,\nTribler, a peer-to-peer file-sharing system that builds upon the\nBitTorrent protocol, exemplifies a decentralized network. Tri-\nbler enables users to discover content using keyword searches\nand incorporates a reputation-management system to foster\ncollaboration. [34]\nB. Web3\nThe term \u201cWeb2.0\u201d was initially introduced by Tim\nO\u2019Reilly in 2007 to describe a new iteration of the Internet\nthat empowered users to publish, consume, and interact with\ncontent and each other. [35] It aimed to expand upon the earlier\nversion, \u201cWeb1.0\u201d, which primarily featured static pages for\ninformation display. While \u201cWeb1.0\u201d was often referred to as\nthe \u201cread web\u201d, \u201cWeb2.0\u201d aimed to be the \u201cread-write web\u201d.\nCritics, including Tim Berners-Lee, the inventor of the\nWorld Wide Web, argue that \u201cWeb2.0\u201d failed to fulfill the\nvision of a secure, decentralized exchange of public and\nprivate data. Instead, users\u2019 data became increasingly stored\nin corporate data silos, raising concerns about data ownership\nand security. Berners-Lee and others advocate for users to own\ntheir data to ensure data security. [36]\nIn\n2014,\nGavin\nWood,\nco-founder\nof\nPolkadot\nand\nEthereum, introduced the term \u201cWeb3.0\u201d to describe an In-\nternet that is decentralized, open, and transparent. The Web3\nmovement seeks to transform the platform-oriented \u201cWeb2.0\u201d\ninto a decentralized web ecosystem with the following goals:\n1) Avoiding content discovery and propagation monopolies\nby large centralized entities, 2) Supporting immersive web\ndevelopment, 3) Combating the spread of misinformation, and\n4) Enabling platform users to create, exchange, and react to\ninformation securely, privately, and freely. [37]\nC. EigenTrust\nEstablishing trust among peers in decentralized networks is\ncrucial for secure and reliable interactions. Trust mechanisms\nplay a vital role in determining the credibility of peers and\nensuring that transactions occur only with trustworthy coun-\nterparts.\nEigenTrust [38] was one of the pioneering methods to ad-\ndress this trust challenge in decentralized networks. EigenTrust\nprovides a distributed algorithm that calculates a global trust\nvalue for each peer, reflecting the collective experience of all\npeers in the network, enabling peers to make informed deci-\nsions about the trustworthiness of their counterparts, thereby\nfostering trustworthy interactions. In this section, we discuss\nthe workings of EigenTrust and its significance in decentral-\nized network environments.\nThe primary objective of the algorithm is to determine a\nunique global trust value, denoted as \u2212\u2192t , for each peer in the\nnetwork. This value encapsulates the overall experience of all\npeers with a given peer and serves as a reference for evaluating\nthe trustworthiness of other peers. Furthermore, EigenTrust\nincorporates mechanisms to prevent malicious groups of col-\nlaborating peers from providing deceptive trust ratings for their\nadvantage.\nSimilar to eBay\u2019s reputation system [39], EigenTrust re-\nquires each peer to rate its transactions with other peers,\nthereby generating a local trust value, denoted as s, for each\npeer. The value sij represents the trust level of peer i towards\npeer j, based on their previous transactions. A suggested\napproach for calculating sij is through the following formula:\nsij = sat(i, j) \u2212unsat(i, j)\n(6)\n6\nHere, sat(i, j) and unsat(i, j) represent the number of\nsatisfactory and unsatisfactory transactions that peer i has\nconducted with peer j. These localized trust values, sij,\nare normalized to obtain cij, ensuring that trust values fall\nbetween 0 and 1. This normalization prevents malicious peers\nfrom arbitrarily assigning extremely high trust values to other\nmalicious peers while assigning low values to trustworthy\npeers, thereby exploiting the system.\nTo derive the global trust value, t, these local trust values\nare aggregated within each peer using the equation:\ntik =\nX\nj\ncijcjk\n(7)\nThis calculation can be interpreted as peer i seeking opin-\nions from its acquaintances regarding how much they trust\ntheir acquaintances. However, this process needs to be iterated\nto reflect the experiences of acquaintances\u2019 acquaintances. The\nauthors of the EigenTrust paper demonstrate that the final trust\nvector, denoted as \u2212\u2192\nti , will converge to the same vector \u2212\u2192t for\nevery peer i in the network, representing the left principal\neigenvector of the matrix [cij].\nEigenTrust calculates \u2212\u2192t in a distributed manner. The au-\nthors establish that the algorithm can be executed relatively\nefficiently in networks with a small number of active peers,\nas each peer engages in a limited number of transactions.\nEigenTrust addresses the primary challenge of designing\ndistributed reputation systems\u2014aggregating local trust values\ninto global trust values and by doing so, introduced the concept\nof \u201ctransitive trust\u201d.\nAlthough EigenTrust presents a robust method for establish-\ning trust in decentralized networks, it necessitates an initial\nnotion of trust, which typically comprises a group of known\ntrustworthy peers. The authors suggest that this initial group\ncould consist of the early adopters and designers of a peer-to-\npeer network, as they are less likely to engage in fraudulent\nbehavior within a network they helped create.\nBy employing EigenTrust or similar trust mechanisms,\ndecentralized networks can establish a foundation of trust\namong their peers, enabling secure, reliable, and transparent\ninteractions that are not reliant on centralized authorities.\nHowever, while EigenTrust allows the calculation of trust\nin other users, the transitive trust calculated by it is not\nSybil-resistant i.e., Sybil attacks can be used to increase the\nperceived trust in Sybil identities inside the system.\nD. MeritRank\nMeritRank [40] aims to bound the benefits of Sybil attacks\ninstead of preventing them altogether. The system is based on\nthe assumption that peers observe and evaluate each others\u2019\ncontributions. Each peer\u2019s evaluation is stored in a personal\nledger and modeled in a feedback graph where the feedback\nto each user is modeled as a special token value accumulating\nover time. It is also assumed that each peer can discover the\nfeedback graph, for example, through a gossip protocol.\nTo limit the influence of Sybils, three main types of Sybil\nattack strategies are identified in MeritRank. These are illus-\ntrated in Fig. 5.\nMeritRank manages to achieve Sybil tolerance by imposing\nthe following constraints on how reputation can be gained\ninside the feedback graph when using any of the above\nstrategies:\n1) Transitivity \u03b1 decay\nThis constraint limits the ability of an entity to create a\nserial Sybil attack by terminating random walks in the\nfeedback graph with a probability \u03b1\n2) Connectivity \u03b2 decay\nSybil attack edges in a feedback graph are often bridges\ni.e., their cut creates two separate components. This\nconstraint introduces punishment for a node for being in\na separate component\nA trust graph modeled using these MeritRank\u2019s constraints\nwill satisfy:\nlim\n|S|\u2192\u221e\nw+(\u03c3s)\nw\u2212(\u03c3s) \u2264c\n(8)\nwhere, w+(\u03c3s) is the profit gained by the Sybil Attack \u03c3s,\nw\u2212(\u03c3s) is the cost of the Sybil attack, S is the set of Sybils\nand c is some constant value such that c > 0. Thus, MeritRank\ncan provide a reputation system with feedback that is Sybil\ntolerant.\nVI. RELATED WORK\nIn this section, we cover broad categories of existing work\nin research which attempt to solve similar problems and show\nwhy they do not achieve the goals that we try to fulfill. Thus,\nwe demonstrate the relevancy of our work by pointing out\nhow it serves the interesting niche of generating trustworthy\nand relevant recommendations in Web3 platforms.\nA. Bounding Identity Creation against Sybils\nA popular method to defend against Sybil attacks is to lever-\nage defenses that bound the ability of malicious attackers to\ncreate Sybil identities and hence indirectly limit the influence\nof the Sybil attack by limiting the votes that a Sybil attack\ncan cast. The most rudimentary method of achieving this is\nensuring that all unique identities on platforms correspond\nto real human beings. This can be achieved using a trusted\ncentral authority to verify information about users unique to\nhuman beings, such as passports, phone numbers, credit cards,\netc. Other approaches involve using graphical challenges such\nas CAPTCHA to ensure the user is a human. [41] Such\napproaches are flawed in the context of Web3 for multiple rea-\nsons. First, users of Web3 platforms employing such methods\nmay be hindered from using them because of privacy concerns.\nThe anonymity guarantees of these platforms are often the\nprimary reason many users choose to use these platforms.\nSecond, using a centralized third party for verification is\nantithetical to the idea of decentralization that Web3 platforms\nstand for, and further, maintaining a centralized server adds too\nmuch complexity to the system\u2019s design.\n7\nFig. 5: Sybil attack strategies [40]\nDecentralized approaches to the same problem have been\nsuggested in research, such as limited identities from specific\nIP addresses/prefixes [42], creating resource-based challenges\n[43] and remote issuing of certificates to verify identity based\non network/location coordinates [44]. While these approaches\nmake it harder to create Sybil identities, they do not entirely\nstop Sybil attacks, and a powerful adversary with enough\nincentive could easily surpass these mechanisms to generate\nsignificant influence on the recommendations in the network.\nFurther, bounding identity creation can also have the unin-\ntended effect of making it frustrating for non-Sybil users to use\nthe platform. Therefore, our work does not rely on bounding\nuser creation to limit Sybil influence indirectly. Instead, it\ndirectly limits Sybil influence by effectively detecting Sybils\nand restricting the influence of their votes.\nB. Reputation Systems\nReputation Systems [45] allow the collection of feedback\nfrom different users in the network to determine which peers\ncan be trusted based on their past behavior. A famous example\nof a reputation system is the \u201cFeedback Forum\u201d on eBay [46] :\nafter a transaction is completed, a buyer or seller can rate each\nother (1, 0 or -1) and leave comments. A participant in eBay\naccumulates such points over time, which are displayed next\nto their screen name. A buyer can view a seller\u2019s points and\ncomments left by other users to create a \u201cshadow of the future\u201d\ninto the transaction they can expect to have if they buy an item\nfrom the seller. Many other online forums and marketplaces,\nsuch as Amazon and Stack Overflow, rely on similar reputation\nsystems. However, while reputation systems are a strong\nmechanism to determine whether certain users are trustworthy,\nthey do not provide a way to generate recommendations based\non trustworthy users.\nC. Social Network-based Sybil Defense\nOther works have utilized the power of feedback from\nsocial networks to limit Sybil influence. Popular examples\nare SybilGuard [47], SybilLimit [48], Ostra [49] and SumUp\n[50]. Similar to our work, these methods can establish an ap-\nproximate notion of trust among users using the properties of\ngraphs and often assume global knowledge of the dynamically\nchanging social network. Using these properties, the influence\nof Sybil identities in the votes is limited. However, similar to\nvanilla Reputation Systems, while these approaches are great\nfor generating trust in the network, on their own, they cannot\nensure that the non-Sybil items they identify are relevant to the\nuser for whom the recommendations are being generated. We\nachieve this by building on personalized SALSA and ensuring\nthat the recommended item is trustworthy (i.e., non-Sybil) yet\nalso relevant to the user for which the recommendations are\nbeing tailored.\nD. Machine Learning-based approaches\nExisting machine learning-based approaches to recom-\nmender systems attempt to apply techniques from the mul-\ntiarmed bandit problem [51] or the contextual bandit problem\n[52] where contextual information is used to group users that\nbelong to the same cluster via classification or clustering\ntechniques. The problem with this approach is that they assume\nthe presence of considerable existing feedback from users on\nwhat items they like and the \u201cgoodness\u201d of various objects\nsince these models are only as good as the data they are trained\non. Web3 is an emerging technology, and in many platforms\n(especially new platforms), this data needs to be more sizable\nto train decent models, leading to poor recommendations or\nthe inability to have such models altogether. [22]\nE. Other approaches\nAnother notable system worth mentioning is Dsybil [22].\nThe system presented in the paper utilizes similar mechanisms\nfor diminishing Sybil influence and generating recommenda-\ntions as our paper. They can achieve this by: i) exploiting\nthe heavy-tail distribution of the typical voting behavior of\nthe honest identities and ii) carefully identifying whether the\nsystem is already getting \u201cenough help\u201d from the voters,\nand hence, if Sybil votes are only latching on to existing\nvotes. While they demonstrate an impressive Sybil tolerance,\na notable drawback of their paper is its reliance on only\nexplicit feedback through voting on items that need to be\nrecommended. However, explicit feedback is not always avail-\nable, and in fact, most of the feedback on social networks\nis implicit rather than explicit. [53] Our system incorporates\nimplicit feedback from users to generate recommendations.\nFurther, like many other mentioned papers, the system focuses\npurely on trust and not on generating relevant, personalized\nrecommendations.\n8\nVII. SYSTEM MODEL, ASSUMPTIONS AND LIMITATIONS\nA. Items, Users and Votes\nWeb3Recommends recommends items (e.g., songs/albums\nin Spotify, movies in Netflix, posts in Reddit, etc.) to the\nplatform\u2019s users based on the experience of the users with\nthe items. A user\u2019s preference for an item serves as a vote for\nthe item. Therefore, if enough users like a particular item, it\nis likely to have more votes by virtue of being visited more in\nrandom walks inside the personalized SALSA algorithm and,\ntherefore, more likely to be recommended to other users.\nB. Target Application/Scenario\nRecommendation Systems are a broad concept; different\nsystems differ in their goals and details. [54] Therefore, a\nsolution that works in one scenario may not work in another\nscenario because the platform requires a different purpose from\nits Recommendation System. For example, a Recommendation\nSystem in an online retailer such as eBay may be required to\ngenerate all products that a user may be interested in so that the\nuser has multiple choices. In contrast, the system in modern\nmedia applications such as TikTok would only be required to\ngenerate a single recommendation to autoplay as the next item\nfor the user.\nWeb3Recommend aims to cover a broad range of use cases\nby providing a system that can rank all items available to a\nparticular user. For this, it assumes scenarios where:\n1) The objects to be recommended can be uniquely identi-\nfied and are always available to the user (the exact method\nof availability could vary from peer-to-peer distribution\nto provision by a central server)\n2) The lifespans of the users in the network are not incredi-\nbly short-lived, allowing them to establish trust relation-\nships with other users\n3) Users can initially discover trusted users using social\ndiscovery mechanisms, or an initial set of trusted users\nare provided to the user by the platform\nThe final assumption is a significant limitation of our work\nsince it\u2019s impossible to build trust out of nothing, and a new\nuser can end up trusting Sybil users via bootstrap threats. Note\nthat this is not an uncommon assumption with EigenTrust V-C\nimposing a similar assumption.\nWhile relying on a selected group of peers shares a lot of\nproblems as relying on a centralised entity, this problem can\nbe alleviated by dynamically calculating the trusted users in\nthe network instead of using a static set, similar to the solution\npresented in HonestPeer. [55]\nC. Network Assumptions\nWeb3Recommend assumes that the application utilizing\nit leverages a peer-to-peer architecture [56] with each user\noperating their node and possessing the ability to communicate\ndirectly with any other node and item in the network. We\nassume that all users in the network follow the protocol\nhonestly and cannot tamper with it in any way. We also\nassume that communication occurs over privacy-preserving,\ncryptographically secure protocols.\nWhile the system presented in this paper relies on Gossiping\nVIII-C over a content overlay network to synchronize its\ndata, it is essential to acknowledge that it currently lacks\nsufficient security measures to protect against spoofing of\ngossip. However, it is worth exploring the potential of enhanc-\ning the system\u2019s security by implementing a certificate-based\napproach. By utilizing certificates for each node within the\ncontent overlay network, it becomes possible to establish a se-\ncure communication framework. These certificates can verify\nthe authenticity and integrity of gossip messages exchanged\nbetween nodes, ensuring that only trusted and authorized\nnodes participate in the synchronization process. Moreover, by\nincorporating individual certificates for each user, the system\ncan prevent users from pretending to be another user and\nsigning actions on their behalf. This significantly raises the\nbar for spoofing attempts, enhancing the overall security of\nthe gossiping process.\nFurther, we rely on timestamps to detect when edges were\ncreated, thus we assume that the clocks across different nodes\nare synchronized to prevent ordering issues.\nD. Affinity and Trust\nWeb3Recommend uses two distinct concepts, affinity and\ntrust, to model user-to-user and user-to-item relationships\nrespectively.\nA user u\u2019s affinity for item i is expressed by Af(u, i) and\nis calculated by:\nAf(u, i) =\nPC(u, i)\nP\nx\u2208Iu PC(u, x)\n(9)\nWhere PC(u, i) is the play count of user u for item i i.e.\nthe number of times the user has consumed item i, and Iu\nis the set of all items that have been consumed by user u.\nTherefore, Af(u, i) is a value between 0 and 1 and serves as\na measure of the user u\u2019s preference for item i compared to\nall the items that they have consumed.\nThis definition of affinity may only suit some use cases,\nand more fine-grained metrics, such as the ratio of the item\u2019s\nplaytime to the total playtime could be more appropriate.\nLike in reputation systems, a user\u2019s trust in another user is\nincreased when the user performs valuable work for the other,\nwhich in this case of our recommendation systems means\nproviding a recommendation that the other user likes, i.e., ends\nup developing an affinity for. Therefore, affinity and trust are\ninherently linked since as a user\u2019s affinity for an item increases,\nthe user\u2019s trust in other users who recommended the item also\nincreases.\nSince, in our system, recommendations are calculated using\nrandom walks inside a personalized SALSA algorithm, recom-\nmending an item to another user means that the recommender\n\u201cvoted\u201d for the item in the random walk by having a high\naffinity for it.\nNote that modeling trust this way ensures that Sybil users\ncannot simply piggyback on popular items to increase the\n9\npopularity of their Sybil items since: 1) if they have a high\naffinity for popular items, their Sybil items are less likely to\nbe visited 2) On the other hand, if they have a low affinity\nfor those popular items, the random walk is less likely to\nvisit them 3) Many users are likely to have a high affinity\nfor popular items thus, Sybils are less likely to benefit from\nfollowing this strategy 4) To gain trust, the Sybils still need to\neffectively perform \u201cuseful work\u201d by recommending items that\nother users like. Hence, They cannot simply reap rewards from\nitems that have already been recommended to other users.\nVIII. WEB3RECOMMEND ARCHITECTURE AND DESIGN\nWeb3Recommend is a Social Recommender System de-\nsigned to provide recommendations for any application run-\nning on a decentralized network. The central data structure in\nthe network is the TrustNetwork which stores information\nabout user-to-user and user-to-item relationships across the\nentire network.\nTwo random-walk based algorithms are run on top of the\nTrustNetwork: 1) A Personalized Page Rank calculates a\nglobal trust value for each user using the notion of \u201ctransitive\ntrust\u201d as presented in EigenTrust V-C 2) A Personalized\nSALSA algorithm that calculates a recommendation score for\neach item in the network\nThe random walks in both these algorithms are augmented\nwith MeritRank to provide Sybil-resistance.\nEach node maintains a personal copy of a TrustNetwork,\nand updates to the network are synchronized through a\ntimestamp-biased edge gossiping mechanism, ensuring that\nrecommendations are based on recent, global information\ninside the network. The system design also includes a simple\nbootstrapping mechanism that allows new users to find similar\nusers in the network. However, it is worth noting that malicious\nusers can exploit this bootstrap mechanism. In an actual\napplication, we assume that users are able to bootstrap through\nthe social discovery of trusted peers or through the provision\nof trustworthy nodes by the application itself. The following\nis an in-depth description of the various components of the\nsystem:\nA. TrustNetwork\nAs mentioned before, TrustNetwork is the central data\nstructure of Web3Recommend. TrustNetwork consists of two\ntypes of nodes: users, U, and items, I. Further, there are two\ntypes of edges in the network: directed user-to-user weighted\nedges representing the trust a user places in another user,\nand undirected user-to-item weighted edges representing the\naffinity of a user for an item. In practice, this is implemented\nusing a combination of two graph structures:\n1) User to User Graph\nThe user-to-user graph is a weighted directed acyclic\ngraph in which the graph\u2019s vertex set consists of all users\nin the network, and the edge set consists of trust rela-\ntionships between the users. To ensure efficient memory\nusage and to guarantee that an edge between two users\nonly exists if they trust each other, only the top 5 edges\nin terms of trust/weight are retained for each user.\n2) User to Item Graph\nThe user-to-item graph is a weighted undirected acyclic\nbi-partite graph in which the vertex set of the graph\nconsists of all users and items in the network and the edge\nset consists of affinity relationships between the users and\nitems\nAll algorithms in Web3Recommend operate on top of the\nTrustNetwork. In our Kotlin implementation, we use JGraphT\n[57] to efficiently implement both graph data structures.\nB. Recommendation Algorithm\nThe main component of Web3Recommend is its elegant\nrecommendation algorithm. The algorithm is inspired by\nGraphJet\u2019s algorithm presented in IV-C.\nWe present three modifications to the personalized SALSA\nused in the original algorithm.\n1) Weighted Random Walks\nInstead of using uniform probabilities to decide which\nnode to walk to in our random walks, we perform walks\nusing the affinity metric defined earlier. Hence, when\nwalking from a node to an item the affinity for the item\nbiases the walk, so if a user u prefers an item ij two\ntimes more than item ik, the random walk is also twice\nmore likely to visit ij from u than ik. We believe this\nis a reasonable assumption that aligns with our goal of\nrecommending items that similar users like. Similarly,\nwhen walking back from an item to a user, the walks\nare biased by the user\u2019s affinity for the item. Hence, we\nare more likely to travel to a user with a higher affinity\nfor the item. Again, finding similar users boils down to\nfinding users who like the same items, so it\u2019s reasonable\nto bias our walks this way.\n2) Add MeritRank decays to limit the influence of Sybil\nattacks\nAlpha and beta decays from MeritRank are added to\nthe system to add Sybil tolerance. In IX, we explain\nhow the decays are calculated and used to provide Sybil-\nresistant recommendations. In our experiments, we vary\nthese decay values to measure their influence on trust\n(Sybil tolerance) and the relevancy of recommendations.\n3) Generate \u201ctrusted\u201d random walks\nWhile GraphJet\u2019s personalized SALSA algorithm allows\nthe generation of personalized, relevant recommenda-\ntions, the recommendations generated are not guaranteed\nto be trustworthy. This is because when performing a\nrandom walk from an item to a user, it\u2019s possible to\nwalk to a nontrusted (Sybil) user who also claims to\nlike the item. In Web3Recommend, we modify the walk\nback from an item to a user to be limited to users who\nthe original voter of the item trusts. This ensures that if\nwe reach a Sybil user in a random walk, it\u2019s through\na malicious user or another Sybil user. Hence, their\ninfluence on voting can be detected and limited through\nMeritRank\u2019s decays.\n10\nA simplified version of a random walk in our personalized\nSALSA algorithm is illustrated in 6.\nC. Timestamp Biased Edge Gossiping\nSince Web3Recommend relies on each user storing a local\ncopy of a TrustNetwork each, a mechanism for synchro-\nnizing the TrustNetworks across different users is required.\nGossiping [58] has proved to be a successful mechanism for\nsupporting dynamic and complex information exchange among\ndistributed peers. Gossiping-based mechanisms are great for\nbuilding and maintaining the network topology and supporting\na pervasive diffusion of the information injected into the\nnetwork. [59] Gossiping takes inspiration from the human\nsocial behavior of spreading information through peers who\nare in direct contact.\nOur gossiping mechanism relies on randomly gossiping\nuser-to-user edges and user-to-item edges to other users in\nthe network. In addition to gossiping, we leverage Semantic\nOverlay Networks (SON) [60], which guarantee that the users\nwe gossip to share similar interests.\nGraphJet only generates recommendations based on recent\ninteractions between users and tweets. Thus, only the n latest\ninteractions in the network between users and tweets are\nstored. Doing this has two advantages:\n1) It allows the creation of temporally contextual (real-time)\nrecommendations which have a profound impact in retail,\nmedia, entertainment, and other contexts [61]\n2) It provides a mechanism for limiting the memory usage\non a device by using n as a tunable hyper-parameter, thus\nallowing the recommendation algorithm to also be feasi-\nble in resource-limited devices such as older smartphones\nWeb3Recommend achieves this by adding a timestamp to\nall edges and removing older user-to-item edges after the\nnetwork\u2019s total number of user-to-item edges exceeds n.\nNote that while user-to-item edges are deleted after a time\nwindow, user-to-user edges are persisted and only deleted\neither: 1) When they receive gossip with a more recently\ncreated version of the edge or 2) The user to user edges of\nthe user exceeds a threshold in which case the edge with the\nsmallest weight is deleted. This is reasonable since, in most\nmedia platforms, the number of items dramatically exceeds\nthe number of users; hence, the memory cost of this design\nchoice should be low. Further, it allows us to persist long-term\ntrust relationships between users, which are used in VIII-D.\nWe also want to ensure that newly created edges have a\nhigher chance of being gossiped. To do this, we construct a\nmapping of edges to their delta from the oldest edge in the\nnetwork. Then, the array is softmax which produces weight\nvalues that provide the bias by which an edge is gossiped.\nHence, a newer edge is much more likely to be gossiped than\nan older one.\nD. Bootstrap\nRecommender Systems suffer from the \u201ccold start\u201d problem,\nwhere the systems meet a new user for the first time. Since\nthe system has no history of the user\u2019s interactions, it can\u2019t\nestablish the user\u2019s personal preference. In a real-time recom-\nmendation system like ours, this problem is compounded since\nan inactive user querying for recommendations may not exist\nin the interaction graph.\n1) Circle of Trust: GraphJet solves this problem by starting\nthe random walks from a seed set instead of a single node. The\nseed set could be provided by the network or be constructed\nfrom the user\u2019s trusted users called the \u201ccircle of trust\u201d.\nIn a social network like Twitter, this circle of trust can be\ncalculated using the user\u2019s social connections/follows. In our\nsystem, we calculate the circle of trust using an Incremental\nPersonalized Page Rank [30] algorithm that ranks nodes in\nthe network in order of their trustability while ensuring that\nsubsequent random walks are incrementally computed instead\nof recomputing all the random walks every time edges are\nupdated.\nSince, unlike user-to-item edges, user-to-user edges are per-\nsisted over time, inactive users can still be served personalized\nrecommendations in this manner.\nWe implement the selection inside the seed set dynamically,\nensuring that as the user has more user-to-item interactions,\nrandom walks are more likely to start from the user rather\nthan the seed set. Hence, it serves as a bootstrap measure to\nacquaint the user with the network.\n2) New User: The previous bootstrap mechanism relied on\nthe user\u2019s prior interactions or social trust in the network. For\na fresh user, neither of these exists, and hence a different\nbootstrap mechanism is required to acquaint them with the\nnetwork.\nFor this, we provide a User Collaborative Filtering algorithm\nbased on the work from [62] for finding similar users in the\nnetwork. Initially, users are provided with \u201cdivisive\u201d content in\nthe network, which can be used to find more information about\ntheir taste profile. This helps establish user-to-song edges that\ncan be used to measure similarity between other users.\nThe similarity sim(a, b) between two users (a, b) \u2208U\nwhere U is set of all users is calculated as:\nsim(a, b) = Nsim(a, b) \u00d7 \u03c4 + (1 \u2212\u03c4) \u00d7 Dsim(a, b) (10)\nWhere Nsim(a, b) is calculated as:\nNsim(a, b) = cf(a, b) \u00d7 sim(a, b)\n(11)\nHere, sim(a, b) is the Pearson Correlation Coefficient [63]\nof the two user\u2019s item ratings calculated as:\nsim(a, b) =\nP\ni\u2208Iab ra,irb,i\nqP\ni\u2208Iab r2\na,i\nqP\ni\u2208Iab r2\nb,i\n(12)\nWhere Ia,b is the set of common rated items between users\na and b. ra,i = Ra,i \u2212avga, Ra,i is the rating given by user\na to item i and avga the average of all ratings by a.\ncf(a, b) is the common preference degree between user a\nand b:\ncf(a, b) =\n|Ia \u2229Ib|\nmaxx\u2208U|Ia \u2229Ix|\n(13)\n11\n|Ia \u2229Ib| is the count of common rated items between users\na and b.\nHence, Nsim 11 uses the traditional measure of similarity\nbetween users modified by the degree of common preference\nbetween the two users.\nDsim is a measure of similarity calculated using the rating\ndifference of users on their common items (i.e., items that\nboth users have an existing, established affinity for). It helps\ncalculate a more fine-tuned similarity metric than coarsely\ncomparing items both users have interacted with. The exact\nformula has been omitted for space limitations. The code\nimplementation can be found here.\nHence, sim(a, b) is used to compare a similarity metric to\nother users in every user and therefore serves as a bootstrap\nmeasure for new users.\nNote that this strategy requires that the users being intro-\nduced to the new user are non-Sybil. If the strategy is run\nnaively against all users, it is prone to bootstrap threats as\nmentioned in VII-B.\nE. Compact Serialization\nSince Android devices often have limited resources, it\u2019s\nessential to be able to store networks compactly. Once a user\ndisconnects from the network, the TrustNetwork is serialized\nand stored on the device.\nOur design is inspired by the DIMACSFormat in JGraphT,\nwhich is based on the format used in the 2nd DIMACS\nchallenge [64].\nThe details of the serialization have been omitted due to\nsize limitations, but the implementation is self-documenting,\nrigorously tested, and can be found here.\nIX. USING MERITRANK DECAYS TO GENERATE\nRECOMMENDATIONS\nAs covered in V-D, MeritRank provides two main mecha-\nnisms for Sybil-resistance, Alpha and Beta decays. Each decay\nis tunable and used to limit the gains of a Sybil Attack.\nA. Alpha Decay\nThe alpha decay works precisely like the reset probability\ndescribed in IV. The random walk in the user interaction graph\nstops with probability \u03b1. Setting an alpha decay reduces the\neffectiveness of Sybil attacks that rely on long walks that get\nstuck inside a segment of Sybil users, as described in [40].\nB. Beta Decay\nBeta Decay punishes Sybils for being isolated from the rest\nof the network. Our system achieves this by measuring the\ndiversity of users voting for a song. Assuming the system\u2019s\nbeta decay is set to \u03b2, the item beta decay b[i] is calculated\nfor each item i \u2208I with the following formula:\nb[i] =\n(\n1 \u2212\u03b2\nif \u2203u \u2208U : div(u, i) > \u03c4\n1\nelse\n(14)\nWhere U is the set of all users, \u03c4 is the beta decay threshold\nand div(u, i) is defined as:\ndiv(u, i) =\nP\nr\u2208R(i)\n(\n1\nif \u2203u \u2208U : (u \u2208r) \u2229(r[u] < r[i]))\n0\nelse\n|R(i)|\n(15)\nWhere R(i) is the set of all random walks that contain item\ni, note that SALSA random walks can include both users and\nitems. r[x \u2208U \u222aI] is the index of a user or item in a random\nwalk, hence, the step in the random walk when it was walked\nto. So, each vote item i received in a random walk measures\nwhat percentage of times user u led up to the vote.\nTherefore, in 14 we measure the diversity in recommenders\nleading up to a vote and compare the \u201cSybilness\u201d of item i to\nthe threshold \u03c4 and if it\u2019s deemed Sybil, it is assigned a beta\ndecay of 1 \u2212\u03b2.\nThe rankings of the items in the system are performed\nusing a modified aggregation of random walks. A personalized\nranking score s[i] is calculated for each item i \u2208I using the\nfollowing formula:\ns[i] =\n|R(i)|\nP\nx\u2208I|R(x)|b[i]\n(16)\nThe highest-ranked items are then presented to the user as\nrecommendations.\nIn our implementation, we provide two methods of calcu-\nlating beta decays. First, a relatively faster option, which gains\nits speed by iterating through each random walk linearly and\npre-computing the number of times a user is involved in a\nspecific vote for each item. This can be performed in linear\nruntime relative to the size of random walks. But the space cost\nof the algorithm makes it prohibitively expensive on devices\nwith limited memory. Hence, we also provide an on-the-fly\nimplementation that is more time-consuming but has a tiny\nmemory footprint.\nX. EXPERIMENT SETUP\nA. Dataset and Test Network Generation\nTo demonstrate Sybil resistance, it was important to create\na network of non-Sybil users on which we could mount Sybil\nattacks. We used the dataset from the taste profile subset of\nthe Million Song Dataset [65], [66] to generate this non-Sybil\nnetwork. The original dataset was sourced from The Echo\nNest, an online resource that provides music applications on\nthe web, smartphones, etc. Therefore, using this data from real\nmusic platforms, we could generate a network that emulates\nthe behavior of non-Sybil users in Web3Recommend. The taste\nprofile subset provides us with:\n1) Users\n2) Songs\n3) User-Song-Play Count Triplet\nFor the test network generation, user-song edges were\ncreated using the user-song-play count triplet to estimate\nuser-song affinity as described in VII-D. User-User edges\nwere created using the same user-based collaborative filtering\n12\nmethod we used to bootstrap trust relationships for new users.\nThis is reasonable since all the users in this network were\nassumed to be non-Sybil; hence, the trust between them is\nsimply a function of their similarity.\nFigure 7 shows some statistics of the test network.\nB. Metrics used for experiments\n1) Top x Ranking: The goal of Web3Recommend is to rank\nitems available to a user in order of increasing relevance and\ntrust to them. However, in most consumer-driven recommenda-\ntion systems, only the top few recommendations are important\nsince those are the only ones the user would usually look at\nto choose the next item to consume. Therefore, in most of our\nexperiments, we measure the influence on the system\u2019s top\n100/1000/10000 ranked items.\nSpecifically, for the experiments which measure Sybil re-\nsistance we were interested in measuring how many Sybil\nsongs ended up in these rankings. For example, a Sybil item\nbeing the highest-ranked recommendation to a user is much\nworse than two Sybil items ranked much lower. Therefore, we\ndefine a metric Sybil influence of top x ranking or SITR(x),\nwhich measures the influence of Sybils in the top x category\nof ranking using the follow formula:\nSITR(x) =\ni=x\nX\ni=0\n(\nx \u2212i\nif DRankedI(i) \u2208S\n0\nelse\n(17)\nWhere, DRankedI is the array of all items sorted in\ndescending order of their ranking and S is the set of all Sybil\nitems. Hence, for example, if there is only one Sybil item in\nthe network but it is the highest ranked item, the SITR(100)\nwill be 100.\n2) Ranked Biased Overlap: In order to measure the effect\nof decay parameters on the ranking of the items, we use\nRanked Biased Overlap [67] between two sets of ranking\nto compare how similar they are. Ranked Biased Overlap is\nspecifically constructed to be a similarity measure between\nincomplete ranking lists and hence fits our use case very well.\nRBO outputs a value between 0.0 and 1.0, where 1.0 represents\ntwo identical sets while 0.0 represents completely different\nsets.\nXI. EXPERIMENTS\nA. Leave one out cross validation\nIn this set of experiments, we follow the below process:\n1) 100 users from the User to Song graph are sampled\nrandomly\n2) For each user, we remove an existing user to song edge\n3) We run the personalized SALSA algorithm with alpha\ndecay value set to \u03b1\n4) We measure: 1) The ranking score of the song whose edge\nwas removed 2) In how many percent of trials the missing\nsong shows up in the Top 100/1000/10000 rankings\nWhile the goal of our paper is focused on limiting Sybil\ninfluence, this experiment helps demonstrate that the foun-\ndational recommendation algorithm can provide reasonable\npersonalized recommendations. The result of our algorithm\nis also compared to the result of a simple vanilla personalized\nSALSA implementation to show that our algorithm performs\njust as well, if not better in terms of recommendations for our\ndataset.\nB. Effect on the ranking of increasing decays\nIn this set of experiments, we follow the below process:\n1) 100 users from the User to Song graph are sampled\nrandomly\n2) For each user, we run the personalized SALSA algorithm\nfor a specific alpha decay value \u03b1 \u22080.1, 1.0/beta decay\nvalue \u03b2 \u22080.1, 1.0\n3) For each ranking with increasing \u03b1 or \u03b2 values, we\ncalculate the Ranked Biased Offset compared to the\noriginal ranking\nThis experiment helps to measure the influence on ranking\nwith increasing decay values, showing us how growing decays\nin the network and hence, increasing trust by reducing the\ninfluence of Sybils impacts the relevance of recommendations.\nThis could also be interpreted as the \u201cfalse positive\u201d rate of\nSybil detection.\nC. Single Sybil attack\nAs mentioned earlier, MeritRank provides Sybil resistance\nby limiting Sybil influence through:\nlim\n|S|\u2192\u221e\nw+(\u03c3s)\nw\u2212(\u03c3s) \u2264c\n(18)\nIn this experiment, we prove this property in our network by\nconstructing multiple Sybil attacks where an adversary with an\nexisting trust edge to non-Sybil users starts mounting a Sybil\nattack by creating multiple Sybil identities. Thus, if we can\nprove that after a certain threshold of identities, the benefit\nto the adversary of creating more Sybils is negligible, we can\nshow that our system offers Sybil resistance.\nTherefore, in this experiment, we follow the below process:\n1) In our test network, we randomly sample a user\n2) A trusted neighbor of the user is converted to a traitor\nwho mounts either a: 1) linear Sybil attack or 2) parallel\nSybil attack as defined in V-D\n3) The traitor mounts attacks with an increasing number of\nSybils and for each attack we measure the gain in total\nranking score in our personalized SALSA algorithm of\nthe Sybil items created by the adversary\nD. Giga Sybil attack\nIn a real network, multiple users could potentially mount\na Sybil attack. Hence, it is worth evaluating the performance\nof our network as an increasing percentage of all users in\nthe network become malicious users. For the first half of the\nexperiments, we set 50% of all the nodes to Sybil nodes and\nmeasured the influence gained for Sybil songs over sampled\nusers with varying decay parameters like in the previous\nexperiments. This allows us to measure the gain for Sybils\nfrom a \u201cgiga Sybil\u201d attack with different decay parameters.\n13\nHowever, after the % Sybil users in the network pass a\ncertain threshold, our system\u2019s ranking mechanism can\u2019t work\neffectively since the only items that random walks could\npotentially discover would be Sybil items and hence, due to\nthe influence of beta decays, the rankings produced by our\nsystem will be effectively random. Our experiments found this\nthreshold to be around 0.6 for the chosen dataset.\nXII. EXPERIMENT RESULTS\nA. Leave one out cross validation\nFig. 8: Leave out one experiment with \u03b1 = 0.1 and \u03b2 = 0.0\nAs shown in 8 with alpha decay set to 0.1, in more than\nhalf of the sampled users, the missing song is within the top\n100 recommendations (the dataset consists of 386213 songs,\nso this is top 0.0003% of the results) and about 80% of the\ntimes it is in the top 10000 (top 33% recommendations).\nNext, we compare our system\u2019s performance to a vanilla\npersonalized SALSA recommendation system that doesn\u2019t\ninclude any enhancements mentioned in VIII. Figures 9, 10,\nand 11 compare the performance of both systems in measuring\n% of missing songs in top X recommendations. While in the\ntop 1000 and 10000 recommendations, our system performs\nsimilarly to the vanilla algorithm, in the top 100 recommen-\ndations, it performs much better. We believe that the top 100\nrecommendations metric is also the most significant since\nusers often only look at the highest recommendations.\nFig. 9: % of missing songs in top 100 recommendations in\nboth strategies with varying levels of alpha decay\nFig. 10: % of missing songs in top 1000 recommendations in\nboth strategies with varying levels of alpha decay\nFig. 11: % of missing songs in top 10000 recommendations\nin both strategies with varying levels of alpha decay\nB. Effect on the ranking of increasing decays\nFig. 12: RBO similarity of non-Sybil recommendations with\nincreasing Beta Decay\n14\nFig. 13: RBO similarity of non-Sybil recommendations with\nincreasing Alpha Decay\nAs shown in figures 12 and 13, the false positive impact\nincreases slightly with increasing Alpha Decay while increas-\ning Beta Decay seems to have an almost negligible impact.\nThus, a real implementation would be better suited to use a\nlow Alpha Decay and a high Beta Decay. In the MusicDAO\nimplementation, we set Alpha Decay to 0.1 and Beta Decay\nto 0.8.\nC. Single Sybil attack\nFig. 14: Ranking score gained for a malicious node with\nincreasingly larger linear Sybil attacks (Alpha Decay: 0.0)\nFig. 15: Ranking score gained for a malicious node with\nincreasingly larger linear Sybil attacks (Alpha Decay: 0.1)\nFig. 16: Ranking score gained for a malicious node with\nincreasingly larger parallel Sybil attacks (Beta Decay: 0.8)\nFirst, in 14, we show how an adversary can gain a the-\noretically infinite amount of ranking scores through linear\nSybil attacks without Alpha Decay. Then in 15, we rerun\nthe experiment with Alpha Decay set to 0.1. After a certain\nnumber of Sybils, the reputation gain for the adversary remains\nthe same, hence creating more Sybils doesn\u2019t provide any\nadditional benefit to the attacker. In 16, we demonstrate the\nsame effect with Beta Decay set to 0.8 against parallel attacks.\n15\nD. Giga Sybil attack\nFig. 17: Cumulative Score for Sybil songs in Giga Sybil\nAttack with increasing Alpha Decay\nFig. 18: Cumulative Score for Sybil songs in Giga Sybil\nAttack with increasing Beta Decay\nFigures 17 and 18 show the change in combined ranking\nscore for Sybil songs in our Giga Sybil Attack with varying\nAlpha and Beta decays respectively. Both mechanisms are able\nto limit Sybil gain as expected.\nFig. 19: SITR(100) for Sybil songs in Giga Sybil Attack\nwith increasing Alpha Decay\nFig. 20: SITR(100) for Sybil songs in Giga Sybil Attack\nwith increasing Beta Decay (Alpha Decay:0.1)\nFigures 19 and 20 show the effect of increasing the decay\nvalues on the SITR(100). Note that even though with beta\ndecays, we can completely eliminate Sybil attack edges, in a\ngiga Sybil attack, the majority of the items detected are Sybil\nitems, and hence even though their score is 0, since non-Sybil\nsongs were starved of random walks, they have a much lower\nscore too. However, as shown in the graphs, adding the decay\nvalues can noticeably reduce the giga Sybil attack\u2019s gain even\nif it doesn\u2019t eliminate it.\nXIII. TESTING\nAll the mentioned components of Web3Recommend\u2019s\nKotlin implementation are tested using JUnit.\nXIV. REAL WORLD DEPLOYMENT\nOutside\nexperiments,\nas\na\nproof\nof\nconcept,\nWeb3Recommend\nwas\nalso\nintegrated\ninto\nMusicDAO,\na peer-to-peer music-sharing application that aims to rival\nSpotify. Figure 1 shows recommendations being generated in\nthe application in a network of 3 connected users. The code\nfor MusicDAO is open source and it is freely available to be\ndownloaded through the Android store.\n16\nXV. FURTHER WORK\nFuture research directions could explore further improve-\nments to the recommendation algorithm, such as enhancing\nthe scalability of the graph-based algorithms.\nWe acknowledge that in our paper the definiton of \u201ctrust\u201d\nis simply limited to Sybil-resistance, while in the real world,\nuntrustworthy content also includes content that is malicious\nin other ways such as through being divisive, containing\nunfactual content (fake news), being gory, part of a scam/ponzi\nscheme, etc. Investigating the integration of additional repu-\ntation mechanisms could increase trust beyond simple Sybil-\nresistance\nFurther real-world deployments could be used to evaluate\nthe system\u2019s performance and usability in more diverse settings\nthan only in the context of music sharing.\nFinally, in VII we list a lot of assumptions and limitations\nstated in the system and how future implementations can\naddress these.\nXVI. CONCLUSION\nIn this paper, we presented Web3Recommend, a decen-\ntralized Social Recommender System designed to generate\ntrustworthy and relevant recommendations in Web3 platforms\non Android. We addressed the challenges posed by decentral-\nized networks, such as the lack of a global perspective and\nsusceptibility to Sybil Attacks.\nBy integrating the MeritRank decentralized reputation\nscheme into our graph-based recommendation design, we\nachieved Sybil-resistance in the generated recommendations.\nOur experiments included evaluations against multiple adver-\nsarial strategies. The results demonstrated the trust-relevance\nbalance of our recommendations, showcasing the system\u2019s\nability to generate personalized, real-time recommendations.\nIn summary, Web3Recommend represents a significant\nadvancement in Social Recommender Systems. Combining\ndecentralized network principles, the MeritRank reputation\nscheme, and efficient graph-based algorithms, we have created\na Sybil-resistant recommendation system capable of generat-\ning real-time recommendations in Web3 platforms. Our work\ncontributes to the research community and offers practical\nbenefits to users by enhancing their Web3 platform experience.\nWith the increasing adoption of Web3 technologies, the\ndevelopment of trustworthy and relevant recommender sys-\ntems will continue to play a crucial role in enabling users to\ndiscover valuable content and build meaningful connections\nwithin Web3 platforms.\nREFERENCES\n[1] R. Lu, H. Zhu, X. Liu, J. K. Liu, and J. Shao, \u201cToward efficient and\nprivacy-preserving computing in big data era,\u201d IEEE Network, vol. 28,\nno. 4, pp. 46\u201350, 2014.\n[2] F. O. Isinkaye, Y. O. Folajimi, and B. A. Ojokoh, \u201cRecommendation\nsystems: Principles, methods and evaluation,\u201d Egyptian informatics\njournal, vol. 16, no. 3, pp. 261\u2013273, 2015.\n[3] D. Shenk, \u201cData smog: Surviving the information glut,\u201d 1999.\n[4] D. J. Levitin, The organized mind: Thinking straight in the age of\ninformation overload.\nPenguin, 2014.\n[5] D. Bawden and L. Robinson, \u201cInformation overload: An overview,\u201d\n2020.\n[6] P. Hemp, \u201cDeath by information overload,\u201d Harvard business review,\nvol. 87, pp. 82\u20139, 121, 10 2009.\n[7] Admin, \u201cTiktok statistics - everything you need to know [mar 2023\nupdate],\u201d Mar 2023. [Online]. Available: https://wallaroomedia.com/\nblog/social-media/tiktok-statistics/\n[8] P. Gupta, A. Goel, J. Lin, A. Sharma, D. Wang, and R. Zadeh, \u201cWtf:\nThe who to follow service at twitter,\u201d in Proceedings of the 22nd\ninternational conference on World Wide Web, 2013, pp. 505\u2013514.\n[9] D. Das, L. Sahoo, and S. Datta, \u201cA survey on recommendation system,\u201d\nInternational Journal of Computer Applications, vol. 160, no. 7, 2017.\n[10] I. Guy and D. Carmel, \u201cSocial recommender systems,\u201d in Proceedings of\nthe 20th international conference companion on World wide web, 2011,\npp. 283\u2013284.\n[11] A. Sharma, J. Jiang, P. Bommannavar, B. Larson, and J. Lin, \u201cGraphjet:\nReal-time content recommendations at twitter,\u201d Proceedings of the VLDB\nEndowment, vol. 9, no. 13, pp. 1281\u20131292, 2016.\n[12] R. Lempel and S. Moran, \u201cSalsa: the stochastic approach for link-\nstructure analysis,\u201d ACM Transactions on Information Systems (TOIS),\nvol. 19, no. 2, pp. 131\u2013160, 2001.\n[13] A. Chaabane, Y. Ding, R. Dey, M. A. Kaafar, and K. W. Ross, \u201cA\ncloser look at third-party osn applications: are they leaking your personal\ninformation?\u201d in Passive and Active Measurement: 15th International\nConference, PAM 2014, Los Angeles, CA, USA, March 10-11, 2014,\nProceedings 15.\nSpringer, 2014, pp. 235\u2013246.\n[14] A. Hassan, \u201cReplication and availability in decentralised online social\nnetworks,\u201d 2017.\n[15] J. Bambacht and J. Pouwelse, \u201cWeb3: A decentralized societal in-\nfrastructure for identity, trust, money, and data,\u201d arXiv preprint\narXiv:2203.00398, 2022.\n[16] B. Nasrulin, G. Ishmaev, and J. Pouwelse, \u201cMeritrank: Sybil tolerant\nreputation for merit-based tokenomics,\u201d in 2022 4th Conference on\nBlockchain Research & Applications for Innovative Networks and Ser-\nvices (BRAINS).\nIEEE, 2022, pp. 95\u2013102.\n[17] T. Wissel, \u201cFairness and freedom for artists: Towards a robot economy\nfor the music industry,\u201d 2021.\n[18] J. N. Gray, \u201cAn approach to decentralized computer systems,\u201d IEEE\nTransactions on Software Engineering, no. 6, pp. 684\u2013692, 1986.\n[19] J. R. Douceur, \u201cThe sybil attack,\u201d in Peer-to-Peer Systems: First Inter-\nnationalWorkshop, IPTPS 2002 Cambridge, MA, USA, March 7\u20138, 2002\nRevised Papers 1.\nSpringer, 2002, pp. 251\u2013260.\n[20] M. Apte, G. K. Palshikar, and S. Baskaran, \u201cFrauds in online social\nnetworks: A review,\u201d Social networks and surveillance for society, pp.\n1\u201318, 2019.\n[21] Contributor,\n\u201cStat\ngaming\nservices\ncome\nto\nyoutube,\u201d\nAug\n2007.\n[Online].\nAvailable:\nhttps://techcrunch.com/2007/08/23/\nmyspace-style-profile-gaming-comes-to-youtube/\n[22] H. Yu, C. Shi, M. Kaminsky, P. B. Gibbons, and F. Xiao, \u201cDsybil:\nOptimal sybil-resistance for recommendation systems,\u201d in 2009 30th\nIEEE Symposium on Security and Privacy.\nIEEE, 2009, pp. 283\u2013298.\n[23] K. Avrachenkov, N. Litvak, D. Nemirovsky, and N. Osipova, \u201cMonte\ncarlo methods in pagerank computation: When one iteration is suffi-\ncient,\u201d SIAM Journal on Numerical Analysis, vol. 45, no. 2, pp. 890\u2013904,\n2007.\n[24] J. Leskovec, K. J. Lang, A. Dasgupta, and M. W. Mahoney, \u201cCommunity\nstructure in large networks: Natural cluster sizes and the absence of large\nwell-defined clusters,\u201d 2008.\n[25] A. M. Rashid, I. Albert, D. Cosley, S. K. Lam, S. M. McNee, J. A.\nKonstan, and J. Riedl, \u201cGetting to know you: learning new user prefer-\nences in recommender systems,\u201d in Proceedings of the 7th international\nconference on Intelligent user interfaces, 2002, pp. 127\u2013134.\n[26] L. Page, S. Brin, R. Motwani, and T. Winograd, \u201cThe pagerank citation\nranking: Bringing order to the web.\u201d Stanford InfoLab, Tech. Rep., 1999.\n[27] A. Borodin, G. O. Roberts, J. S. Rosenthal, and P. Tsaparas,\n\u201cFinding authorities and hubs from link structures on the world\nwide web,\u201d in Proceedings of the 10th International Conference on\nWorld Wide Web, ser. WWW \u201901.\nNew York, NY, USA: Association\nfor Computing Machinery, 2001, p. 415\u2013429. [Online]. Available:\nhttps://doi-org.tudelft.idm.oclc.org/10.1145/371920.372096\n[28] D. Fogaras, B. R\u00b4acz, K. Csalog\u00b4any, and T. Sarl\u00b4os, \u201cTowards scaling fully\npersonalized pagerank: Algorithms, lower bounds, and experiments,\u201d\nInternet Mathematics, vol. 2, no. 3, pp. 333\u2013358, 2005.\n17\n[29] A. Blum, T. H. Chan, and M. R. Rwebangira, \u201cA random-surfer web-\ngraph model,\u201d in 2006 Proceedings of the Third Workshop on Analytic\nAlgorithmics and Combinatorics (ANALCO).\nSIAM, 2006, pp. 238\u2013\n246.\n[30] B. Bahmani, A. Chowdhury, and A. Goel, \u201cFast incremental and\npersonalized pagerank,\u201d arXiv preprint arXiv:1006.2880, 2010.\n[31] J. M. Kleinberg, \u201cAuthoritative sources in a hyperlinked environment,\u201d\nJournal of the ACM (JACM), vol. 46, no. 5, pp. 604\u2013632, 1999.\n[32] P. Baran, \u201cOn distributed communications networks,\u201d IEEE Transactions\non Communications Systems, vol. 12, no. 1, pp. 1\u20139, 1964.\n[33] G. Korpal and D. Scott, \u201cDecentralization and web3 technologies,\u201d\n5 2022. [Online]. Available: https://www.techrxiv.org/articles/preprint/\nDecentralization and web3 technologies/19727734\n[34] J. Pouwelse, P. Garbacki, J. Wang, A. Bakker, J. Yang, A. Iosup,\nD. Epema, M. Reinders, M. van Steen, and H. Sips, \u201cTribler: a social-\nbased peer-to-peer system,\u201d Concurrency and Computation: Practice\nand Experience, vol. 20, pp. 127 \u2013 138, 02 2008.\n[35] T. O\u2019reilly, \u201cWhat is web 2.0: Design patterns and business models for\nthe next generation of software,\u201d Communications & strategies, no. 1,\np. 17, 2007.\n[36] \u201cHome \u00b7 solid.\u201d [Online]. Available: https://solidproject.org/\n[37] G. Wood. [Online]. Available: http://gavwood.com/dappsweb3.html\n[38] S. Kamvar, M. Schlosser, and H. Garcia-molina, \u201cThe eigentrust al-\ngorithm for reputation management in p2p networks,\u201d The EigenTrust\nAlgorithm for Reputation Management in P2P Networks, 04 2003.\n[39] P. Kollock et al., \u201cThe production of trust in online markets,\u201d Advances\nin group processes, vol. 16, no. 1, pp. 99\u2013123, 1999.\n[40] B. Nasrulin, G. Ishmaev, and J. Pouwelse, \u201cMeritrank: Sybil tolerant\nreputation for merit-based tokenomics,\u201d 2022. [Online]. Available:\nhttps://arxiv.org/abs/2207.09950\n[41] N. Borisov, \u201cComputational puzzles as sybil defenses,\u201d in Sixth IEEE\nInternational Conference on Peer-to-Peer Computing (P2P\u201906).\nIEEE,\n2006, pp. 171\u2013176.\n[42] E. Damiani, D. C. di Vimercati, S. Paraboschi, P. Samarati, and F. Vi-\nolante, \u201cA reputation-based approach for choosing reliable resources in\npeer-to-peer networks,\u201d in Proceedings of the 9th ACM conference on\nComputer and communications security, 2002, pp. 207\u2013216.\n[43] H. Rowaihy, W. Enck, P. McDaniel, and T. La Porta, \u201cLimiting sybil\nattacks in structured p2p networks,\u201d in IEEE INFOCOM 2007-26th IEEE\nInternational Conference on Computer Communications.\nIEEE, 2007,\npp. 2596\u20132600.\n[44] R. A. Bazzi and G. Konjevod, \u201cOn the establishment of distinct identities\nin overlay networks,\u201d in Proceedings of the twenty-fourth annual ACM\nsymposium on Principles of distributed computing, 2005, pp. 312\u2013320.\n[45] P. Resnick, K. Kuwabara, R. Zeckhauser, and E. Friedman, \u201cReputation\nsystems,\u201d Communications of the ACM, vol. 43, no. 12, pp. 45\u201348, 2000.\n[46] P. Resnick, R. Zeckhauser, J. Swanson, and K. Lockwood, \u201cThe value of\nreputation on ebay: A controlled experiment,\u201d Experimental economics,\nvol. 9, pp. 79\u2013101, 2006.\n[47] H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman, \u201cSybilguard:\ndefending against sybil attacks via social networks,\u201d in Proceedings of\nthe 2006 conference on Applications, technologies, architectures, and\nprotocols for computer communications, 2006, pp. 267\u2013278.\n[48] H. Yu, P. B. Gibbons, M. Kaminsky, and F. Xiao, \u201cSybillimit: A near-\noptimal social network defense against sybil attacks,\u201d in 2008 IEEE\nSymposium on Security and Privacy (sp 2008).\nIEEE, 2008, pp. 3\u201317.\n[49] A. Mislove, A. Post, P. Druschel, and P. K. Gummadi, \u201cOstra: Lever-\naging trust to thwart unwanted communication.\u201d in Nsdi, vol. 8, 2008,\npp. 15\u201330.\n[50] D. N. Tran, B. Min, J. Li, and L. Subramanian, \u201cSybil-resilient online\ncontent voting.\u201d in NSDI, vol. 9, no. 1, 2009, pp. 15\u201328.\n[51] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire, \u201cThe non-\nstochastic multiarmed bandit problem,\u201d SIAM journal on computing,\nvol. 32, no. 1, pp. 48\u201377, 2002.\n[52] L. Li, W. Chu, J. Langford, and R. E. Schapire, \u201cA contextual-bandit\napproach to personalized news article recommendation,\u201d in Proceedings\nof the 19th international conference on World wide web, 2010, pp. 661\u2013\n670.\n[53] L. Guo, J. Ma, Z. Chen, and H. Zhong, \u201cLearning to recommend with\nsocial contextual information from implicit feedback,\u201d Soft Computing,\nvol. 19, pp. 1351\u20131362, 2015.\n[54] J. Bobadilla, F. Ortega, A. Hernando, and A. Guti\u00b4errez, \u201cRecommender\nsystems survey,\u201d Knowledge-based systems, vol. 46, pp. 109\u2013132, 2013.\n[55] H. A. Kurdi, \u201cHonestpeer: An enhanced eigentrust algorithm for repu-\ntation management in p2p systems,\u201d Journal of King Saud University-\nComputer and Information Sciences, vol. 27, no. 3, pp. 315\u2013322, 2015.\n[56] M. Ripeanu, \u201cPeer-to-peer architecture case study: Gnutella network,\u201d\nin Proceedings first international conference on peer-to-peer computing.\nIEEE, 2001, pp. 99\u2013100.\n[57] D. Michail, J. Kinable, B. Naveh, and J. V. Sichi, \u201cJgrapht\u2014a java\nlibrary for graph data structures and algorithms,\u201d ACM Transactions on\nMathematical Software (TOMS), vol. 46, no. 2, pp. 1\u201329, 2020.\n[58] M.\nJelasity,\nS.\nVoulgaris,\nR.\nGuerraoui,\nA.-M.\nKermarrec,\nand\nM. Van Steen, \u201cGossip-based peer sampling,\u201d ACM Transactions on\nComputer Systems (TOCS), vol. 25, no. 3, pp. 8\u2013es, 2007.\n[59] R. Baraglia, P. Dazzi, M. Mordacchini, and L. Ricci, \u201cA peer-to-peer\nrecommender system for self-emerging user communities based on\ngossip overlays,\u201d Journal of Computer and System Sciences, vol. 79,\nno. 2, pp. 291\u2013308, 2013.\n[60] A. Crespo and H. Garcia-Molina, \u201cSemantic overlay networks for p2p\nsystems,\u201d in International Workshop on Agents and P2P Computing.\nSpringer, 2004, pp. 1\u201313.\n[61] Y. Ma, B. Narayanaswamy, H. Lin, and H. Ding, \u201cTemporal-contextual\nrecommendation in real-time,\u201d in Proceedings of the 26th ACM SIGKDD\ninternational conference on knowledge discovery & data mining, 2020,\npp. 2291\u20132299.\n[62] B. Zhang and B. Yuan, \u201cImproved collaborative filtering recommenda-\ntion algorithm of similarity measure,\u201d in AIP Conference Proceedings,\nvol. 1839, no. 1.\nAIP Publishing LLC, 2017, p. 020167.\n[63] I. Cohen, Y. Huang, J. Chen, J. Benesty, J. Benesty, J. Chen, Y. Huang,\nand I. Cohen, \u201cPearson correlation coefficient,\u201d Noise reduction in\nspeech processing, pp. 1\u20134, 2009.\n[64] D. S. Johnson and M. A. Trick, Cliques, coloring, and satisfiabil-\nity: second DIMACS implementation challenge, October 11-13, 1993.\nAmerican Mathematical Soc., 1996, vol. 26.\n[65] T. Bertin-Mahieux, D. P. Ellis, B. Whitman, and P. Lamere, \u201cThe million\nsong dataset,\u201d 2011.\n[66] B. McFee, T. Bertin-Mahieux, D. P. Ellis, and G. R. Lanckriet, \u201cThe\nmillion song dataset challenge,\u201d in Proceedings of the 21st International\nConference on World Wide Web, ser. WWW \u201912 Companion.\nNew\nYork, NY, USA: Association for Computing Machinery, 2012, p.\n909\u2013916. [Online]. Available: https://doi-org.tudelft.idm.oclc.org/10.\n1145/2187980.2188222\n[67] W. Webber, A. Moffat, and J. Zobel, \u201cA similarity measure for indefinite\nrankings,\u201d ACM Transactions on Information Systems (TOIS), vol. 28,\nno. 4, pp. 1\u201338, 2010.\n18\n1: function RANDOMWALK(currentNode, lastNode, userToUserGraph, userToItemGraph)\n2:\nif currentNode is a User then\n3:\nWalkToSong(currentNode, lastNode, userToItemGraph)\n4:\nelse\n5:\nWalkToUser(currentNode, lastNode, userToUserGraph, userToItemGraph)\n6:\nend if\n7: end function\n8: function WALKTOSONG(currentNode, lastNode, userToItemGraph)\n9:\nuserEdgesWeight \u21900\n10:\nfor all edge e \u2208{edges of currentNode} do\n11:\nuserEdgesWeight \u2190userEdgesWeight + userToItemGraph.WeightOf(e)\n12:\nend for\n13:\np \u2190userEdgesWeight \u2217RandomDoubleBetween(0, 1)\n14:\ncumulativeP \u21900\n15:\nfor all edge e \u2208{edges of currentNode} do\n16:\ncumulativeP \u2190cumulativeP + userToItemGraph.WeightOf(e)\n17:\nif p \u2264cumulativeP then\n18:\nlastNode \u2190currentNode\n19:\ncurrentNode \u2190userToItemGraph.GetSongForEdge(e)\n20:\nbreak\n21:\nend if\n22:\nend for\n23: end function\n24: function WALKTOUSER(currentNode, lastNode, userToUserGraph, userToItemGraph)\nRequire: currentNode is an Item and lastNode is User with neighbor currentNode\n25:\nlastNodeNeighbors \u2190userToUserGraph.neighborsOf(lastNode)\n26:\nlastNodeNeighborsWithEdgeToCurrentNode \u2190filterNodesWithMissingEdge(lastNodeNeighbors, currentNode)\n27:\nsongEdgesWeight \u21900\n28:\nfor all edge e \u2208{edges of currentNode} do\n29:\nif userToItemGraph.GetUserForEdge(e) \u2208lastNodeNeighborsWithEdgeToCurrentNode then\n30:\nsongEdgesWeight \u2190songEdgesWeight + userToItemGraph.WeightOf(e)\n31:\nend if\n32:\nend for\n33:\np \u2190userEdgesWeight \u2217RandomDoubleBetween(0, 1)\n34:\ncumulativeP \u21900\n35:\nfor all edge e \u2208{edges of currentNode} do\n36:\nif userToItemGraph.GetUserForEdge(e) \u2208lastNodeNeighborsWithEdgeToCurrentNode then\n37:\ncumulativeP \u2190cumulativeP + userToItemGraph.WeightOf(e)\n38:\nif p \u2264cumulativeP then\n39:\nlastNode \u2190currentNode\n40:\ncurrentNode \u2190userToItemGraph.GetUserForEdge(e)\n41:\nbreak\n42:\nend if\n43:\nend if\n44:\nend for\n45: end function\nFig. 6: Simplified Web2Recommend SALSA Random Walk\n19\nFig. 7: Test Network Stats (Note that UtU stands for User to User and UtS stands for User to Song)\n20\n",
    "2105.07447": "Non-Fungible Token (NFT): Overview,\nEvaluation, Opportunities and Challenges\n(Tech ReportV2)\nQin Wang\u22c62,4, Rujia Li\u22c61,3, Qi Wang1, Shiping Chen4\n1 Southern University of Science and Technology\n2 Swinburne University of Technology\n3 University of Birmingham\n4 CSIRO Data61\nAbstract. The Non-Fungible Token (NFT) market is mushrooming in\nrecent years. The concept of NFT originally comes from a token stan-\ndard of Ethereum, aiming to distinguish each token with distinguishable\nsigns. This type of token can be bound with virtual/digital properties\nas their unique identi\ufb01cations. With NFTs, all marked properties can be\nfreely traded with customized values according to their ages, rarity, liq-\nuidity, etc. It has greatly stimulated the prosperity of the decentralized\napplication (DApp) market. At the time of writing (May 2021), the total\nmoney used on completed NFT sales has reached 34, 530, 649.86 USD.\nThe thousandfold return on its increasing market draws huge attention\nworldwide. However, the development of the NFT ecosystem is still in\nits early stage, and the technologies of NFTs are pre-mature. Newcom-\ners may get lost in their frenetic evolution due to the lack of systematic\nsummaries. In this technical report, we explore the NFT ecosystems in\nseveral aspects. We start with an overview of state-of-the-art NFT so-\nlutions, then provide their technical components, protocols, standards,\nand desired proprieties. Afterwards, we give a security evolution, with\ndiscussions on the perspectives of their design models, opportunities and\nchallenges. To the best of our knowledge, this is the \ufb01rst systematic study\non the current NFT ecosystems.\nKeywords: Blockchain \u00b7 NFT \u00b7 DApp \u00b7 Smart contract\n1\nIntroduction\nNon-Fungible Token (NFT) is a type of cryptocurrency [82] that is derived by the\nsmart contracts of Ethereum [119]. NFT was \ufb01rstly proposed in Ethereum Im-\nprovement Proposals (EIP)-721 [116] and further developed in EIP-1155 [117].\nNFT di\ufb00ers from classical cryptocurrencies [105] such as Bitcoin [98] in their\nintrinsic features. Bitcoin [98] is a standard coin in which all the coins are\n\u22c6These authors contributed equally to the work.\nEmail: qinwang@swin.edu.au and rxl635@bham.ac.uk.\narXiv:2105.07447v3  [cs.CR]  25 Oct 2021\nequivalent and indistinguishable. In contrast, NFT is unique which cannot be\nexchanged like-for-like (equivalently, non-fungible), making it suitable for iden-\ntifying something or someone in a unique way. To be speci\ufb01c, by using NFTs\non smart contracts (in Ethereum [119]), a creator can easily prove the existence\nand ownership of digital assets in the form of videos, images, arts [83], event\ntickets [103], etc. Furthermore, the creator can also earn royalties each time of a\nsuccessful trade on any NFT market or by peer-to-peer exchanging. Full-history\ntradability, deep liquidity, and convenient interoperability enable NFT to be-\ncome a promising intellectual property (IP)-protection solution. Although, in\nessence, NFTs represent little more than code, but the codes to a buyer have\nascribed value when considering its comparative scarcity as a digital object. It\nwell secures selling prices of these IP-related products that may have seemed\nunthinkable for non-fungible virtual assets.\nIn recent years, NFTs have garnered remarkable attention from both the indus-\ntrial and scienti\ufb01c communities. It was reported that the 24-hour trading volume\non average of the NFT market is 4, 592, 146, 914 USD1, while the 24-hour trad-\ning volume of the entire cryptocurrency market is 341, 017, 001, 809 USD. The\nliquidity of NFT-related solutions has accounted for 1.3% of the entire cryp-\ntocurrency market in such a short period (5 months). Early investors obtain\nthousandfold returns by selling unique digital collectibles. At the time of writing\n(May 2021), the NFTs-related market has signi\ufb01cantly increased compared to\none year ago (January 2020). Speci\ufb01cally, the total number of sales is 25, 729\nand their total amounts spent on completed sales reach 34, 530, 649.86 USD2.\nIn particular, the total number of primary-market sales occupies 17, 140, while\nthe number of secondary sales (user-to-user) is 8, 589. Correspondingly, the total\nUSD used on primary market sales is 8, 816, 531.10. Besides, the active market\nwallets achieve 12, 836, which is still increasing at a high speed as time goes.\nSurprisingly, the sale of NFTs was estimated at 12 million (December 2020) but\nexploded to 340 million within just two months (February 2021). Such skyrock-\neting development makes NFT become a craze, or even be described by some as\nthe future of digital assets.\nBesides the above data, people have expressed interest in various types of NFTs.\nThey participate in NFT-related games or trades with enthusiasm. CryptoPunks\n[20], one of the \ufb01rst NFT on Ethereum, has created more than 10, 000 collectible\npunks (6039 males and 3840 females) and further promoted the ERC-721 stan-\ndard to become popular. CryptoKitties [19] o\ufb03cially put NFTs on notice, and hit\nthe market in 2017 with the gami\ufb01cation of the breeding mechanics. Participants\n\ufb01ercely competed at high prices to auction the rare cats, and the highest price\nreaches more than 999 ETH3 (equally 3M USD). Another outstanding instance\nis NBA Top Shot [44], which is an NFT trading platform used to buy/sell digital\nshort videos of NBA moments. Thousands of NBA fans from around worldwide\n1 Data source from Coingecko (May, 2021) https://www.coingecko.com/en/nft\n2 Data captured from https://nonfungible.com/market/history\n3 Price available: https://www.cryptokitties.co/kitty/1866420\n2\nhave collected over 7.6 million top shot moments, building the roster of rookies,\nvets, and rising star players. Following projects also enjoy great success including\nPicasso Punks [51], Hashmasks [31], 3DPunks [4], uno\ufb03cial punks [63], Polkamon\n[52], Chubbies [14], Bullrun Babes [12], Aavegotchi [5], CryptoCats [18], Moon\nCats Rescue [42], NFT box [46], etc. There is no doubt that there is a hype cycle\nsurrounding NFTs where most of products can be sold with high prices, some\neven hundreds or thousands of ETHs. Besides games and collectibles, NFTs also\npromote the development of art [108], ticketing event [103], value [77],[78], IoT\n[100], and \ufb01nance [80][97]. Other types of surrounding markets play important\nroles as well to provide instant information and secure environments like statistic\nwebsites (e.g. NonFungible [49], DappRadar [24], NFT bank[45], De\ufb01Pulse [26],\nCoingecko [15]), trading marketplace (cryptoslam [21], Opensea [50], SuperRare\n[59], Nifty Gateway [48], Rarible [55], Zora [69]) and so-called NFT ecosystem\n(such as Dego [25]).\nDespite NFTs have a tremendous potential impact on the current decentralized\nmarkets and future business opportunities, the NFT technologies are still in the\nvery early stage. Some potential challenges are required to be carefully tack-\nled, while some promising opportunities should be highlighted. Further, even\nthough much literature on NFTs, from blogs, wikis, forum posts, codes and\nother sources, are available to the public, a systematic study is absent. This\npaper aims to draw attention to these questions insofar as observed and focus\non summarising current NFT solutions. We provide a detailed analysis of its\ncore components, technology roadmap status, opportunities and challenges. The\ncontributions are provided as follows.\n- Firstly, we abstract the design models of current NFT solutions. Speci\ufb01cally,\nwe identify the core technical components that are used to construct NFTs.\nThen, we present their protocols, standards and targeted properties.\n- Secondly, we give a security evaluation of current NFT systems. We adopt\nthe STRIDE threat and risk evaluation [106] to investigate potential security\nissues. Based on that, we also discuss the corresponding defense measures\nfor the issues.\n- Thirdly, we explore some future opportunities of NFTs in many \ufb01elds. Ap-\nplying NFTs to real scenarios will boost a wide range of new applications.\nWe give a set of practical instances (projects) leveraging NFTs with great\nsuccess or prosperous markets.\n- Finally, we highlight a series of open challenges in NFT ecosystems. Blockchain-\nbased NFT systems still confront unavoidable problems like privacy issues,\ndata inaccessibility, etc. We outline open challenges existed in state-of-the-\nart NFT solutions.\nThe rest part of this work is organized as follows. Section 2 provides the technical\ncomponents used to build NFTs. Section 3 presents the protocols and standards.\nBased on that, Section 4 gives our security evaluation. Section 5 discusses the\n3\nfuture opportunities, while Section 6 outlines the open challenges. Finally, Sec-\ntion 7 concludes this work. Appendix A gives our version updates. Appendix B\nand Appendix C provide NFT collectible ranking and an overview of existing\nNFT projects, respectively. Appendix D presents a detailed instance analysis.\n2\nTechnical Components\nIn this part, we show technical components related to the NFT\u2019s activities. These\ncomponents lay the building foundations of a fully functional NFT scheme.\nBlockchain. Blockchain was originally proposed by Nakamoto [98], where Bit-\ncoin uses the proof of work (PoW) [87] algorithm to reach an agreement on\ntransaction data in a decentralized network. Blockchain is de\ufb01ned as a dis-\ntributed and attached-only database that maintains a list of data records linked\nand protected using cryptographic protocols [86]. Blockchain provides a solu-\ntion to the long-standing Byzantine problem [92], which has been agreed upon\nwith a large network of untrusted participants. Once the shared data on the\nblockchain is con\ufb01rmed in most distributed nodes, it becomes immutable be-\ncause any changes in the stored data will invalidate all subsequent data. The\nmost prevailing blockchain platform used in NFT schemes is Ethereum [119],\nproviding a secure environment for executing the smart contracts. In addition,\nseveral solutions drop their customized chain-engines or blockchain platforms to\nsupport their specialized applications, and some of them are Flow [2], EOS [67],\nHyperledger [89][70], and Fast Box [28][111].\nSmart Contract. Smart contracts were originally introduced by Szabo [107],\naiming to accelerate, verify or execute digital negotiation. Ethereum [119] further\ndeveloped smart contracts in the blockchain system [84][71]. Blockchain-based\nsmart contracts adopt Turing-complete scripting languages to achieve compli-\ncated functionalities and execute thorough state transition replication over con-\nsensus algorithms to realize \ufb01nal consistency. Smart contracts enable unfamil-\niar parties and decentralized participants to conduct fair exchanges without a\ntrusted third party and further propose a uni\ufb01ed method to build applications\nacross a wide range of industries. The applications operating on top of smart\ncontracts are based on state-transition mechanisms. The states that contain the\ninstructions and parameters are shared by all the participants, thus guaranteeing\ntransparency of the execution of these instructions. Also, the positions between\nstates have to stay the same across distributed nodes, which is important to its\nconsistency. Most NFT solutions [20][19][44][51][31][4] rely on smart contract-\nbased blockchain platforms to ensure their order-sensitive executions.\nAddress and Transaction. Blockchain address and transaction are the essen-\ntial concepts in cryptocurrencies. A blockchain address is a unique identi\ufb01er for\na user to send and receive the assets, which is similar to a bank account when\nspending the assets in the bank. It consists of a \ufb01xed number of alphanumeric\ncharacters generated from a pair of public key and private key. To transfer NFTs,\n4\nthe owner must prove in possession of the corresponding private key and send\nthe assets to another address(es) with a correct digital signature. This simple op-\neration is usually performed using a cryptocurrency wallet and is represented as\nsending a transaction to involve smart contracts in the ERC-777 [90] standard.\nData Encoding. Encoding is the process of converting data from one form to\nanother. Normally, many \ufb01les are often encoded into either e\ufb03cient, compressed\nformats for saving disk space or into an uncompressed format for high quali-\nty/resolution. In the mainstream blockchain systems such as Bitcoin [98] and\nEthereum [119], they employ hex values to encode transaction elements such as\nthe function names, parameters and return values. This implies that the raw\nNFT data must follow these rules. If one claims s/he owns the NFT-based in-\ntellectual property, s/he essentially owns the original piece of hex values signed\nby the creator. Others can freely copy the raw data, but they cannot claim\nownership of the property. Based on that, we can observe that the NFT-related\nactivities (e.g. buy/sell/trade/auction) have to be processed under these four\nphases, similar to the basic processing procedure of smart contracts.\n3\nProtocols, Standards and Properties\nThis section presents two basic models of NFT schemes, with emphasis on their\nprotocols, token standards and key properties.\n3.1\nProtocols\nThe establishment of NFT requires an underlying distributed ledger for records,\ntogether with exchangeable transactions for trading in the peer-to-peer network.\nThis report primarily treats the distributed ledger as a special type of database\nto store NFT data. In particular, we assume that the ledger has basic secu-\nrity consistency, completeness, and availability characteristics. Based on that,\nwe identify two design patterns for the NFT paradigm. The former protocol is\nestablished from top to bottom with a very simple yet classical path: building\nNFTs from the initiator, and then sell them to the buyer. In contrast, the later\nroute (e.g. Loot [34], detailed analysis in Appendix D) reverses this path: setting\na NFT template, and every user can create their unique ontop NFTs. We sep-\narately provide detailed protocols of these two design patterns as below. To be\nnoted, for both of them, they still follow a very similar work\ufb02ow when executed\non blockchain systems (cf. Fig.1), meaning that di\ufb00erent designs will not change\nthe underlying operating mechanism.\nTop to Bottom. For the \ufb01rst design (e.g., CryptoPunks [20]), an NFT protocol\nconsists of another two roles: NFT owner and NFT buyer.\n- NFT Digitize. An NFT owner checks that the \ufb01le, title, description are\ncompletely accurate. Then, s/he digitizes the raw data into a proper format.\n5\nFig. 1: Work\ufb02ow of NFT Systems\n- NFT Store. An NFT owner stores the raw data into an external database\noutside the blockchain. Note that, s/he is also allowed to store the raw data\ninside a blockchain, despite this operation is gas-consuming.\n- NFT Sign. The NFT owner signs a transaction, including the hash of NFT\ndata, and then sends the transaction to a smart contract.\n- NFT Mint&Trade. After the smart contract receives the transaction with\nthe NFT data, the minting and trading process begins. The main mecha-\nnism behind NFTs is the logic of the Token Standards that can be found in\nSection 3.2.\n- NFT Con\ufb01rm. Once the transaction is con\ufb01rmed, the minting process\ncompletes. By this approach, NFTs will forever link to a unique blockchain\naddress as their persistence evidence.\nBottom to Top. For this design (e.g., Loot [34]), the protocol consists of two\nroles: NFT creator and NFT buyer. In most cases, a buyer can also act as a\ncreator because an NFT product is created based on random seeds when a buyer\nbids for it. This extends the functions in terms of user customization. Here, we\nuse the superscript \u2217to highlight di\ufb00erences compared with the previous one.\n- Template Create\u2217. The project founder initiates a template via the smart\ncontract to set up several basic rules, such as di\ufb00erent features (character\nstyle, weapons, or accessories) in the game.\n- NFT Randomize\u2217. Once a buyer bids for an NFT, s/he can customize\nthe NFT product with a set of additional features on top of basic lines.\nThese additional features are randomly selected from a database that was\nprede\ufb01ned at the initial state.\n- NFT Mint&Trade. The minting and trading process starts once the cor-\nresponding smart contract is triggered.\n6\n- NFT Con\ufb01rm. All the procedures are conducted through smart contracts.\nThe generated NFT will be persistently stored on-chain when the consensus\nprocedure has been completed.\nIn a blockchain system, each block has a limited capacity. When the capacity in\none block becomes full, other transactions will enter a future block linked to the\noriginal data block. In the end, all linked blocks have created a long-term history\nthat remains permanent. The NFT system, in essence, is a blockchain-based\napplication. Whenever an NFT is minted or sold, a new transaction is required\nto send to invoke the smart contract. After the transaction is con\ufb01rmed, the NFT\nmetadata and ownership details are added to a new block, thereby ensuring that\nthe history of the NFT remains unchanged and the ownership is preserved.\n3.2\nToken Standards\nIn this part, we clarify token standards related to NFTs, including ERC-20 [81],\nERC-721 [115], and ERC-1155 [118] (see Algorithm 1). These standards have a\ngreat impact on the ongoing NFT schemes. We discuss them as follows.\nAlgorithm 1: NFT Standard Interfaces (with selected functions)\ninterface ERC721 {\nfunction ownerOf(uint256 tokenId) external view returns (address);\nfunction transferFrom(address from, address to, uint256 tokenId)\nexternal payable; ...\n}\ninterface ERC1155 {\nfunction balanceOf(address owner, uint256 id) external view returns\n(address);\nfunction balanceOfBatch(address calldata owners, uint256 calldata\nids) external view returns (uint256 memory);\nfunction transferFrom(address from, address to, uint256 id, uint256\nquantity) external payable; ...\n}\nThe most prevailing token standard comes from ERC-20 [81]. It introduces the\nconcept of fungible tokens that can be issued on top of Ethereum once satisfying\nthe requirements. The standard makes tokens the same as another one (in terms\nof both type and value). An arbitrary token is always equal to all the other\ntokens. This stimulates the hype of Initial Coin O\ufb00ering (ICO) from 2015 to\npresent. A lot of public chains and various blockchain-based DApps [75][102]\ngain su\ufb03cient initial fundings in this way. In contrast, ERC-721 [115] introduces\na non-fungible token standard that di\ufb00ers from the fungible token. This type of\ntoken is unique that can be distinguished from another token. Speci\ufb01cally, every\n7\nNFT has a uint256 variable called tokenId, and the pair of contract address\nand uint256 tokenId is globally unique. Further, the tokenId can be used as an\ninput to generate special identi\ufb01cations such as images in the form of zombies\nor cartoon characters.\nAnother standard ERC-1155 (Multi Token Standard) [118] extends the repre-\nsentation of both fungible and non-fungible tokens. It provides an interface that\ncan represent any number of tokens. In previous standards, every tokenId in\ncontact only contains a single type of tokens. For instance, ERC-20 makes each\ntoken type deployed in separate contracts. As well, ERC-721 deploys the group\nof non-fungible tokens in a single contract with the same con\ufb01gurations. In con-\ntrast, ERC-1155 extends the functionality of tokenId, where each of them can\nindependently represent di\ufb00erent con\ufb01gurable token types. The \ufb01eld may con-\ntain its customized information such as the metadata, lock-time, date, supply,\nor any other attributes. Here, we provide an illustration (see Fig.2) to show their\nstructures and aforementioned di\ufb00erences.\nFig. 2: NFT-related Token Standards\n3.3\nNFTs Desired Proprieties\nNFT schemes are essentially decentralized applications [74], and thus enjoy the\nbene\ufb01ts/properties from their underlying public ledgers. We summarise the key\nproperties as follows.\n- Veri\ufb01ability. The NFT with its token metadata and its ownership can be\npublicly veri\ufb01ed.\n- Transparent Execution. The activities of NFTs include minting, selling\nand purchasing are publicly accessible.\n- Availability. The NFT system never goes down. Alternatively, all the tokens\nand issued NFTs are always available to sell and buy.\n8\n- Tamper-resistance. The NFT metadata and its trading records are persis-\ntently stored and cannot be manipulated once the transactions are deemed\nas con\ufb01rmed.\n- Usability. Every NFT has the most up-to-date ownership information, which\nis user-friendly and information-clearly.\n- Atomicity. Trading NFTs can be completed in one atomic, consistent, iso-\nlated, and durable (ACID) transaction. The NFTs can run in the same shared\nexecution state.\n- Tradability. Every NFTs and its corresponding products can be arbitrarily\ntraded and exchanged.\n4\nSecurity Evaluation\nAn NFT system is a combination technology that consists of blockchain, storage\nand web application. Security evaluation on the NFT system is challenging since\neach component may become an attacking interface that makes the whole system\nreally vulnerable against the attacker. Thus, we adopt the STRIDE threat and\nrisk evaluation [106], which covers all security aspects of a system: authenticity,\nintegrity, non-repudiability, availability and access control. We investigate the\npotential security issues and propose some of the corresponding defense measures\nto address these issues (see Table 1).\nSpoo\ufb01ng. Spoo\ufb01ng is the ability to impersonate another entity (for example,\nanother person or computer) on the system, which corresponds to authenticity.\nWhen a user interacts to mint or sells NFTs, a malicious attacker may exploit\nauthentication vulnerabilities or steal the user\u2019s private key to transfer the own-\nership of NFTs illegally. Thus, we recommend having a formal veri\ufb01cation for the\nNFT smart contract and to use the cold wallet to prevent private key leakage.\nTampering. Tampering refers to the malicious modi\ufb01cation of NFT data, which\nviolates integrity. Assume that the blockchain is a robust public transaction\nledger [85,86] and a hash algorithm is preimage resistance and second preimage\nresistance [104]. The metadata and ownership of NFTs cannot be maliciously\nmodi\ufb01ed after the transaction is con\ufb01rmed. However, the data stored outside\nblockchain may be manipulated. Therefore, we recommend users to send both the\nhash data as well as the original data to the NFT buyer when trading/exchanging\nNFT-related properties.\nRepudiation. Repudiation refers to the situation where the author of a state-\nment cannot dispute [121], which is related to the security property of non-\nrepudiability [95]. In particular, the fact that a user sends NFT to another user\ncannot deny. This is guaranteed by the security of the blockchain and the un-\nforgeability property of a signature scheme. However, the hash data may be\ntampered by a malicious attacker, or the hash data may bind with an attacker\u2019s\n9\naddress. Thus, we believe that using a multi-signature contract can partly solve\nthis issue since each binding must be con\ufb01rmed by more than one participant.\nInformation Disclosure. Information leakage occurs when information is ex-\nposed to unauthorized users, which violates con\ufb01dentiality [95]. In the NFT\nsystem, the state information and the instruction code in the smart contracts\nare entirely transparent, and any state and its changes are publicly accessible\nby any observer. Even if the user only puts the NFT hash into the blockchain,\nthe malicious attackers can easily exploit the linkability of the hash and transac-\ntion. Thus, we recommend the NFT developer to use privacy-preserving smart\ncontracts [93][94] instead of plain smart contracts to protect the user\u2019s privacy.\nTable 1: Potential Security Issues and Corresponding Solutions of NFTs.\nSTRIDE\nSecurity Issues\nSolutions\nSpoo\ufb01ng\n(Authenticity)\n\u2022 An attacker may exploit au-\nthentication vulnerabilities\n\u2022 An attacker may steal a\nuser\u2019s private key.\n\u2022 A formal veri\ufb01cation on the\nsmart contract.\n\u2022 Using the cold wallet to pre-\nvent the private key leakage.\nTampering\n(Integrity)\n\u2022 The data stored outside the\nblockchain may be manipu-\nlated.\n\u2022\nSending\nboth\nthe\norigi-\nnal data and hash data to\nthe NFT buyer when trading\nNFTs.\nRepudiation\n(Non-\nrepudiability)\n\u2022 The hash data may bind\nwith an attacker\u2019s address.\n\u2022 Using a multi-signature con-\ntract partly.\nInformation\ndisclosure\n(Con\ufb01dentiality)\n\u2022 An attacker can easily ex-\nploit the hash and transaction\nto link a particular NFT buyer\nor seller.\n\u2022\nUsing\nprivacy-preserving\nsmart\ncontracts\ninstead\nof\nsmart contracts to protect the\nuser\u2019s privacy.\nDenial of service\n(Availability)\n\u2022 The NFT data may be-\ncome unavailable if the asset is\nstored outside the blockchain.\n\u2022 Using the hybrid blockchain\narchitecture with weak consen-\nsus algorithm.\nElevation of\nprivilege\n(Authorization)\n\u2022 A poorly designed smart\ncontract may make NFTs lose\nsuch properties.\n\u2022 A formal veri\ufb01cation on the\nsmart contracts.\nDenial of Service (DoS). DoS attack [96] is a type of network attack in\nwhich a malicious attacker aims to render a server unavailable to its intended\nusers by interrupting the normal functions. DoS violates the availability and\nbreaks down the NFT service, which can indeed be used by unauthorized users.\nFortunately, the blockchain guarantees the high availability of user\u2019s operations.\n10\nLegitimate users can use the required information when needed and will not\nlose data resources due to accidental errors. However, DoS can also be used to\nattack the centralized web applications or the raw data outside the blockchain,\nresulting in denial-of-service to NFT service. Recently, a new hybrid blockchain\narchitecture with weak consensus algorithm was proposed [111], by which this\narchitecture solves the availability issues using two algorithms.\nElevation of Privilege. Elevation of Privilege [106] is a property that is related\nto the authorization. In this type of threat, an attacker may gain permissions\nbeyond those initially granted. In the NFT system, the selling permissions are\nmanaged by a smart contract. Again, a poorly designed smart contract may\nmake NFTs lose such properties.\n5\nOpportunities\nThis section explores the opportunities of NFTs. We discuss several typical \ufb01elds\nwhich may get bene\ufb01ts from NFTs.\nBoosting Gaming Industry. NFT has great potential in the gaming indus-\ntry. There already exist some crypto games are CrytpoKitties [19], Cryptocats\n[18], CryptoPunks [20], Meebits [38], Axie In\ufb01nity [9], Gods Unchanged [29], and\nTradeStars [61]. A fascinating feature of such games is the \u201cbreeding\u201d mecha-\nnism. Users can personally raise pets and spend much time breeding new o\ufb00-\nspring. They can also purchase the limited/rare edition virtual pets, and then\nsell them at a high price. The extra reward attracts lots of investors to join the\ngames, making NFTs come to prominence. Another exciting functions of the\nNFT are that it provides ownership records of items in the games and promotes\neconomic marking place in the ecosystem, bene\ufb01ting both developers and play-\ners. In particular, game developers who are NFT publishers of the features (e.g.,\nweapons and skins) can earn royalties each time their items are (re-)sold on the\nopen market. The players can obtain personal exclusivity game items. This will\ncreate a mutually bene\ufb01cial business model in which both players and develop-\ners pro\ufb01t from the secondary NFT market. After that, blockchain communities\nextend NFTs to a large extent that covers various types of digital assets.\nFlourishing Virtual Events. Traditional online events rely on centralized\ncompanies that provide trust and technology. Although blockchain takes over\nseveral types of activities like raising money (either by ICO/IFO/IEO/etc.),\nits applications are still constrained in a small range of events. NFTs greatly\nextend the scope of blockchain applications with the help of their additional\nproperties (uniqueness, ownership, liquidity). This enables each individual to\nlink to a speci\ufb01c event just like the patterns in our real life. We give the instance\nof the ticketing event. When buying tickets in a traditional event ticket market,\nconsumers must trust the third party. Therefore, there is a risk of buying fraud-\nulent or invalid tickets, which are possibly counterfeit or might be cancelled.\nThe same ticket may be sold many times or obtained by extracting from ticket\n11\nimages posted online in an extreme case. \u201cNFT-based ticket\u201d represents a ticket\nissued by the blockchain to demonstrate entitlement to access to any event such\nas culture or sports. An NFT-based ticket is unique and scarce, meaning that the\nticket holder cannot resell the ticket after it is sold. The blockchain-based smart\ncontract provides a transparent ticket trading platform for the stakeholders such\nas the event organizer and the customer. Consumers can buy and sell the crypto\nticket from the smart contract rather than rely on third parties in an e\ufb03cient\nand reliable way.\nProtecting Digital Collectibles. Digital collectibles contain a variety of types,\nranging from trading cards, wines [68], digital images [59], videos [44], virtual\nreal estate [1], domain names [27][64], diamonds [32][47], crypto stamps [17]\nand other real/intellectual properties. We take the \ufb01eld of arts as an example.\nFirstly, artists in traditional ways have very few channels to display the works.\nThe prices cannot re\ufb02ect the true value of their works due to the absence of at-\ntention. Even worse, their published work on social networks has been charged\nwith intermediary fees by platforms and advertisements. NFTs transform their\nwork into digital formats with integrated identities. Artists do not have to trans-\nfer ownership and contents to agents. This provides them impetus with lots of\npro\ufb01ts. Typical instances include Mad Dog Jones\u2019s REPLICATOR (selling with\n4.1 million USD [36]), Grimes\u2019s work (selling in total around 6 million USD [30])\nand other works from great crypto-artists like Beeple [10] / Trevor Jones [62].\nFurthermore, artists in general cases cannot receive royalties from future sales\nof their works. In contrast, NFTs can be programmed so that the artist receives\na predetermined royalty fee each time when his digital artwork exchanges in the\nmarkets (e.g. [33], SuperRare [59], MakersPlace [37], Rare Art Lab[54], VIV3\n[65]). This is an e\ufb03cient way to manage and protect digital masterpieces. In ad-\ndition, several platforms (e.g. Mintbase [41], Mintable [40]) have even established\ntools to support ordinary people to create their own NFT works easily.\nInspiring the Metaverse. Metaverse is a collective virtual shared space that\nallows all types of digital activities. Generally, it covers a set of techniques like\naugmented reality and the Internet to establish the virtual world. The concept\nstems from the last decades and has a great progress with the rapid development\nof blockchain. Blockchain provides an ideal decentralized environment for the vir-\ntual online world. Participants under this blockchain-fueled alternative realities\n[50] can have many types of intriguing use cases like enjoying games, displaying\nself-made arts, trading assets and virtual properties (arts, land parcels, names,\nvideo shots, wearables), etc. In addition, users also have opportunities to get\npro\ufb01ts from the virtual economy. They can lease the buildings (such as o\ufb03ces)\nto others to earn the bond or raise rare pets and sell them to get the rewards.\nPrimary blockchain-empowered projects are Decentraland [1], Cryptovoxels [22],\nSomnium Space [57], MegaCryptoPolis [39] and Sandbox [3]. In fact, the meta-\nverse ecosystem covers all aforementioned applications. We list it separately here\nsimply because it is still in an early stage due to the complexity.\n12\n6\nChallenges\nTo enable the development of the above NFT applications, a series of barriers\nhave to be overcome as with any nascent technologies. We discuss some typical\nchallenges from the perspectives of usability, security, governance, and extensi-\nbility, covering both the system level issues caused by blockchain-based platforms\nand human factors such as governs, regulation, and society.\n6.1\nUsability Challenges\nUsability is to measure the users\u2019 e\ufb00ectiveness, e\ufb03ciency, and satisfaction when\ntesting a speci\ufb01c product/design. Most NFT schemes are built on top of Ethereum.\nTherefore, it is obvious that the main drawbacks of Ethereum still exist. We dis-\ncuss two major challenges that have direct impacts on the user experience.\n- Slow Con\ufb01rmation. NFT-related procedures are tyically conducted by\nsending transactions via the smart contract for reliable and transparent man-\nagement (such as mint, sell, exchange). However, current NFT systems are\nclosely coupled with their underlying blockchain platforms, which makes\nthem su\ufb00er from low performance (Bitcoin reaches merely 7 TPS [109] while\nEthereum only 30 TPS). This results in extremely slow con\ufb01rmation of\nNFTs. Conquering this issue requires a redesign of blockchain systems [113],\noptimization of its structure [110][88] or improvement on the consensus mech-\nanisms [71]. Existing blockchain systems cannot ful\ufb01l such requirements.\n- High Gas Prices. High gas prices have become a major problem for NFT\nmarketplaces, especially when minting the NFTs at a large scale that requires\nuploading the metadata to the blockchain network. Every NFT-related trans-\nactions are more expensive than a simple transfer transaction because smart\ncontracts involve computational resources and storage to be processed. At\nthe time of writing, to mine an NFT token costs over USD 60 (equivalently\nin around 5 \u00d7 102wei) 1. To complete a simple NFT trade can run between\nUSD 60 and USD 100 for each transaction. Expensive fees caused by complex\noperations and high congestion greatly limit its wide adoption.\n6.2\nSecurity and Privacy Issues\nThe security of user data pose the \ufb01rst priority of systems. However, the data\n(stored o\ufb00-chain but relates to on-chain tags) confronts the risk of losing linkage\nor being misused by malicious parties. We give details as follows.\n- NFT Data Inaccessibility. In the mainstream NFT projects [2,1,3], a\ncryptographic \u201chash\u201d as the identi\ufb01er, instead of a copy of the \ufb01le, will be\ntagged with the token and then recorded on the blockchain to save the gas\n1 Source calculated from https://coinmarketcap.com/ and https://ethereum.org\n/en/developers/docs/gas/\n13\nconsumption. This makes the user lose con\ufb01dence in the NFT because the\noriginal \ufb01le might be lost or damaged. Several NFT projects integrate their\nsystem with a specialized \ufb01le storage system such as IPFS [72] in which\nIPFS addresses allow users to \ufb01nd a piece of content so long as someone\nsomewhere on the IPFS network is hosting it. Inevitably, such systems have\n\ufb02aws. When the users \u201cupload\u201d NFT metadata to IPFS nodes, there is no\nguarantee that their data will be replicated among all the nodes. The data\nmay become unavailable if the asset is stored on IPFS and the only node\nstoring it is disconnected from the network [73]. This issue has been reported\nby DECRYPT.IO [73] and CHECKMYNFT.COM [76]. Also, an NFT might\npoint to an erroneous \ufb01le address. If that is the case, a user cannot prove\nthat s/he actually owns the NFT. In a word, relying on an external system\nas the core component (storage) for an NFT system is vulnerable.\n- Anonymity/Privacy. In the current stage, the anonymity and privacy of\nNFTs are still understudied. Most NFT transactions rely on their underly-\ning Ethereum platform, which only provides pseudo-anonymity rather than\nstrict anonymity or privacy. Users can partially hide their identities if the\nlinks between their real identities and corresponding addresses are unknown\nby the public. Otherwise, all the activities of users under the exposed address\nare observable. Existing privacy-preserving solutions (e.g. homomorphic en-\ncryption [112], zero-knowledge proof [114], ring signature [99], multi-party\ncomputation [101]) have not been yet applied to the NFT-related schemes\ndue to their complicated cryptographic primitives and security assumptions.\nSimilar to other types of blockchain-based systems, decreasing expensive\ncomputation costs becomes the key to implement privacy-promised schemes.\n6.3\nGovernance Consideration\nSimilar to the situations of most cryptocurrencies, NFTs also confront the bar-\nriers like strict management from the government. On the other side, how to\nproperly regulate this nascent technology with the corresponding market is also\na challenge. We discuss two typical issues from both sides.\n- Legal Pitfalls. NFTs confront legal and policy issues across a wide range\nof areas [82][91]. Potential concerned areas cover commodities, cross-border\ntransactions, KYC (Know Your Customer) data, etc. It is important to un-\nderstand the related regulatory scrutiny and litigation before moving into\nthe NFT tracks. In some countries, such as Indian and China, the legal sit-\nuation is strict for cryptocurrencies, and also for NFT sales. Exchanging,\ntrading, selling, or buying NFTs have to overcome the di\ufb03culties of gov-\nernance. Legally, users can only trade derivates on authorized exchanges\nsuch as stocks and commodities or exchange tokens with someone person-to-\nperson. Several countries, such as Malta and France, are trying to implement\nsuitable laws with the aim to regulate the service of digital assets. Elsewhere,\nissues are resolved by using existing laws. They require buyers to follow com-\n14\nplex or even contradictory terms. Therefore, undertaking due diligence is a\nnecessity before investing serious tokens in NFTs.\n- Taxable property Issues. IP-related products (including arts, books, do-\nmain names, etc.) are treated as taxable property under the current legal\nframework. However, NFT-based sales stay out of this scope. Although few\ncountries, such as the U.S. (internal revenue service, IRS), tax cryptocur-\nrencies as property, most areas worldwide have not yet considered it. This\nmay greatly increase the \ufb01nancial crimes under cover of NFT trading. The\ngovernments would love to make the sale of NFTs reliable with tax conse-\nquences. Speci\ufb01cally, the individual participants should have the tax liability\non any capital gains that are related to NFT properties. Also, NFT-for-NFT,\nNFT-for-IP, and Eth-for-NFT (or vice versa) exchanges should be taxed.\nFurthermore, for high-pro\ufb01t properties, or collectibles, a higher tax bracket\nshould be applied. Thus, NFT-related trades are suggested to seek more\nadvice from professional tax departments after the profound discussions.\n6.4\nExtensibility Issues\nThe extensibility of NFT schemes is two-fold. The \ufb01rst is to stress whether a\nsystem can interact with other ecosystems. The second focuses on whether NFT\nsystems can obtain updates when the current version is left behind.\n- NFT Interoperability (cross-chain). Existing NFT ecosystems are iso-\nlated from each other. Users once have selected one type of product can only\nsell/buy/trade them within the same ecosystem/network. This is due to the\nreason of its underlying blockchain platform. Interoperability and cross-chain\ncommunication are always the handicaps for the wide adoption of DApps.\nBased on the observations from [120], cross-chain communications can only\nbe implemented with the help of external trusted parties. The decentral-\nization property, in this way, has been inevitably lost to some extent. But\nfortunately, most of the NFT-related projects adopt Ethereum as their un-\nderlying platform. This indicates that they share a similar data structure\nand can exchange under the same rules.\n- Updatable NFTs. Transitional blockchains update their protocols through\nsoft forks (minor modi\ufb01cations that are compatible forwards) and hard forks\n(signi\ufb01cant modi\ufb01cations that may con\ufb02ict with previous protocols). A for-\nmal discussion has been provided in [79] stating the di\ufb03culties and trade-\no\ufb00s when applying the updates to an existing blockchain. Despite using the\ngeneric model, a new version still faces strict requirements such as toler-\nating speci\ufb01c adversarial behaviours and staying online during the update\nprocess. NFT schemes closely rely on their underlying platforms and keep\nconsistent with them. Although the data are often stored in separate com-\nponents (such as the IPFS \ufb01le system), the most important logic and tokeId\nare still recorded on-chain. Properly updating the system with improvements\nwill be a necessity.\n15\n7\nConclusion\nNon-Fungible Token (NFT) is an emerging technology prevailing in the blockchain\nmarket. In this report, we explore the state-of-the-art NFT solutions which may\nre-shape the market of digital/virtual assets stepping forward. We \ufb01rstly ana-\nlyze the technical components and provide the design models and properties.\nThen, we evaluate the security of current NFTs systems and further discuss the\nopportunities and potential applications that adopt the NFT concept. Finally,\nwe outline existing research challenges that require to be solved before achieving\nmass-market penetration. We hope this report delivers timely analysis and sum-\nmary of existing proposed solutions and projects, making it easier for newcomers\nto keep up with the current progress.\nReferences\n1. Decentraland (mana). Project accessible: https://decentraland.org/ (2020)\n2. Flow. Project accessible: https://www.onflow.org/ (2020)\n3. Sandbox. Project accessible: https://www.sandbox.game/en/ (2020)\n4. 3d punks. Project Accessible: http://www.3dpunks.com/ (2021)\n5. Aavegotchi. Project Accessible: https://aavegotchi.com/ (2021)\n6. Alien worlds. Project Accessible: https://alienworlds.io/ (2021)\n7. Art blocks. Project Accessible: https://artblocks.io/ (2021)\n8. Async art. Project Accessible: https://async.art/ (2021)\n9. Axie in\ufb01nity. Project Accessible: https://axieinfinity.com/ (2021)\n10. Beeple. Project Accessible: https://www.beeple-crap.com/ (2021)\n11. Bored ape yacht club. Project Accessible: https://boredapeyachtclub.com/#/\n(2021)\n12. Bullrun babes. Project Accessible: https://opensea.io/collection/bullrunb\nabestoken (2021)\n13. Cargo. Project Accessible: https://cargo.build/ (2021)\n14. Chubbies. Project Accessible: https://chubbies.io/ (2021)\n15. Coingecko website. Accessible: https://coingecko.com/en (2021)\n16. Cometh. Project Accessible: https://www.cometh.io/ (2021)\n17. Crypto stamp. Project Accessible: https://crypto.post.at/ (2021)\n18. Cryptocats. Project Accessible: https://cryptocats.thetwentysix.io/ (2021)\n19. Cryptokitties. Project Accessible: https://www.cryptokitties.co/ (2021)\n20. Cryptopunks. Accessible: https://www.larvalabs.com/cryptopunks (2021)\n21. Cryptoslam. Project Accessible: https://cryptoslam.io/ (2021)\n22. Cryptovoxels. Project Accessible: https://www.cryptovoxels.com/ (2021)\n23. Cryptowine. Project Accessible: https://grap.finance/#/ (2021)\n24. Dappradar website. Accessible: https://dappradar.com/ (2021)\n25. Dego. Project Accessible: https://dego.finance/ (2021)\n26. Deipulse website. Accessible: https://defipulse.com/ (2021)\n27. Ens domains. Project Accessible: https://app.ens.domains/ (2021)\n28. Fast box. Project Accessible: https://www.fastbox.cc/ (2021)\n29. Gods unchanged. Project Accessible: https://godsunchained.com/ (2021)\n30. Grimes\nsold\n$6\nmillion\nworth\nof\ndigital\nart\nas\nnfts.\nNews\nsource:\nhttps://www.theverge.com/2021/3/1/22308075/grimes-nft-6-million-\nsales-nifty-gateway-warnymph (2021)\n16\n31. Hashmasks. Project Accessible: https://www.thehashmasks.com/ (2021)\n32. Icecap. Project Accessible: https://icecap.diamonds/ (2021)\n33. Known origin. Project Accessible: https://www.knownorigin.io/ (2021)\n34. Loot contract code. https://etherscan.io/address/0xff9c1b15b16263c61d017\nee9f65c50e4ae0113d7#code (2021)\n35. Loot talk. https://loot-talk.com/ (2021)\n36. Mad dog jones. News source: https://www.phillips.com/detail/mad-dog-jone\ns/NY090121/1 (2021)\n37. Makersplace. Project Accessible: https://makersplace.com/ (2021)\n38. Meebits. Project Accessible: https://meebits.larvalabs.com/ (2021)\n39. Megacryptopolis. Project Accessible: https://mcp3d.com/ (2021)\n40. Mintable. Project Accessible: https://mintable.app/ (2021)\n41. Mintbase. Project Accessible: https://www.mintbase.io/ (2021)\n42. Moon cats rescue. Project Accessible: https://mooncatrescue.com/ (2021)\n43. Mycryptoheroes. Project Accessible: https://www.mycryptoheroes.net/ (2021)\n44. Nba top shot. Accessible: https://nbatopshot.com/ (2021)\n45. Nft bank. Project Accessible: https://nftbank.ai/ (2021)\n46. Nft box. Project Accessible: https://nftboxes.io/ (2021)\n47. Nft diamonds. Project Accessible: https://nftdiamonds.co/ (2021)\n48. Nifty gateway. Project Accessible: https://niftygateway.com/ (2021)\n49. Nonfungible website. Accessible: https://NonFungible.com (2021)\n50. Opensea platform. Accessible: https://opensea.io/ (2021)\n51. Picasso\npunks.\nAccessible:\nhttps://opensea.io/collection/picassopunks\n(2021)\n52. Polkamon. Project Accessible: https://polkamon.com/ (2021)\n53. R planet. Project Accessible: https://rplanet.io/ (2021)\n54. R.a.r.e art lab. Project Accessible: https://www.lagelnd.com/rare (2021)\n55. Rarible. Project Accessible: https://rarible.com/ (2021)\n56. Skyweaver. Project Accessible: https://www.skyweaver.net/ (2021)\n57. Somnium space. Project Accessible: https://somniumspace.com/ (2021)\n58. Sorare. Project Accessible: https://sorare.com/ (2021)\n59. Superrare. Project Accessible: https://superrare.co/ (2021)\n60. Topps mlb. Project Accessible: https://toppsmlb.com/ (2021)\n61. Tradestars. Project Accessible: https://tradestars.app/ (2021)\n62. Trevorjonesart. Project Accessible: https://www.trevorjonesart.com/ (2021)\n63. Uno\ufb03cial punks. Project Accessible: https://opensea.io/collection/unoffi\ncialpunks (2021)\n64. Unstoppable domains. Accessible: https://unstoppabledomains.com/ (2021)\n65. Viv3. Project Accessible: https://VIV3.com (2021)\n66. Wax: Worldwide asset exchange. Accessible: https://on.wax.io/wax-io/ (2021)\n67. Wax:worldwide asset exchange. Project Accessible: https://github.com/world\nwide-asset-exchange/whitepaper (2021)\n68. Wiv. Project Accessible: https://www.wiv.io/ (2021)\n69. Zora. Project Accessible: https://zora.co/ (2021)\n70. Bal, M., Ner, C.: Nftracer: a non-fungible token tracking proof-of-concept using\nhyperledger fabric. arXiv preprint arXiv:1905.04795 (2019)\n71. Bano, S., Sonnino, A., Al-Bassam, M., Azouvi, S., McCorry, P., Meiklejohn, S.,\nDanezis, G.: Sok: Consensus in the age of blockchains. In: Proceedings of the 1st\nACM Conference on Advances in Financial Technologies. pp. 183\u2013198 (2019)\n72. Benet, J.: Ipfs-content addressed, versioned, p2p \ufb01le system. arXiv preprint\narXiv:1407.3561 (2014)\n17\n73. Benson, J.: Your nfts can go missing\u2014here\u2019s what you can do about it. https:\n//decrypt.co/62037/missing-or-stolen-nfts-how-to-protect (2021)\n74. Buterin, V., et al.: A next-generation smart contract and decentralized application\nplatform. white paper 3(37) (2014)\n75. Cai, W., Wang, Z., et al.: Decentralized applications: The blockchain-empowered\nsoftware system. IEEE Access 6, 53019\u201353033 (2018)\n76. CH21: Check my nft. https://checkmynft.com/ (2021)\n77. Chevet, S.: Blockchain technology and non-fungible tokens: Reshaping value\nchains in creative industries. Available at SSRN 3212662 (2018)\n78. Chohan, U.W.: Non-fungible tokens: Blockchains, scarcity, and value. Critical\nBlockchain Research Initiative (CBRI) Working Papers (2021)\n79. Ciampi, M., et al.: Updatable blockchains. In: European Symposium on Research\nin Computer Security. pp. 590\u2013609. Springer (2020)\n80. Dowling, M.M.: Fertile land: Pricing non-fungible tokens. Available at SSRN\n3813522 (2021)\n81. Fabian, V., Vitalik, B.: Eip-20: Erc-20 token standard. Accessible: https://eips\n.ethereum.org/EIPS/eip-20 (2015)\n82. Fair\ufb01eld, J.: Tokenized: The law of non-fungible tokens and unique digital prop-\nerty. Indiana Law Journal, Forthcoming (2021)\n83. Franceschet, M., Colavizza, G., Smith, T., et al.: Crypto art: A decentralized\nview. Leonardo pp. 1\u20138 (2020)\n84. Garay, J., Kiayias, A.: Sok: A consensus taxonomy in the blockchain era. In:\nCryptographers\u2019 Track at the RSA Conference. pp. 284\u2013318. Springer (2020)\n85. Garay, J., Kiayias, A., Leonardos, N.: The bitcoin backbone protocol: Analysis and\napplications. In: Annual International Conference on the Theory and Applications\nof Cryptographic Techniques (EUROCRYPT). pp. 281\u2013310. Springer (2015)\n86. Garay, J., Kiayias, A., Leonardos, N.: The bitcoin backbone protocol with chains\nof variable di\ufb03culty. In: CRYPTO. pp. 291\u2013323. Springer (2017)\n87. Gervais, A., et al.: On the security and performance of proof of work blockchains.\nIn: Proceedings of the 2016 ACM SIGSAC Conference on Computer and Com-\nmunications Security. pp. 3\u201316. ACM (2016)\n88. Gudgeon, L., Moreno-Sanchez, P., Roos, S., McCorry, P., Gervais, A.: Sok: Layer-\ntwo blockchain protocols. In: International Conference on Financial Cryptography\nand Data Security. pp. 201\u2013226. Springer (2020)\n89. Hong, S., Noh, Y., Park, C.: Design of extensible non-fungible token model in\nhyperledger fabric. In: Proceedings of the 3rd Workshop on Scalable and Resilient\nInfrastructures for Distributed Ledgers. pp. 1\u20132 (2019)\n90. Jacques, D., Jordi, B., Thomas, S.: Eip-777: Erc-777 token standard. Accessible:\nhttps://eips.ethereum.org/EIPS/eip-777 (2017)\n91. Johnson, K.N.: Decentralized \ufb01nance: Regulating cryptocurrency exchanges.\nWilliam & Mary Law Review 62 (2021)\n92. Lamport, L., Shostak, R., Pease, M.: The byzantine generals problem. In: Con-\ncurrency: the Works of Leslie Lamport, pp. 203\u2013226 (2019)\n93. Li, R., Galindo, D., Wang, Q.: Auditable credential anonymity revocation based\non privacy-preserving smart contracts. In: Data Privacy Management, Cryptocur-\nrencies and Blockchain Technology, pp. 355\u2013371. Springer (2019)\n94. Li, R., et al.: An accountable decryption system based on privacy-preserving\nsmart contracts. In: International Conference on Information Security. pp. 372\u2013\n390. Springer (2020)\n95. Menezes, A.J., Van Oorschot, P.C., Vanstone, S.A.: Handbook of applied cryp-\ntography. CRC press (2018)\n18\n96. Moore, D., Voelker, G., Savage, S.: Inferring internet denial-of-service activity.\nACM Trans. Comput. Syst. 24, 115\u2013139 (2006)\n97. Musan, D.I., William, J., Gervais, A.: Nft. \ufb01nance leveraging non-fungible tokens\n(2020)\n98. Nakamoto, S.: Bitcoin: A peer-to-peer electronic cash system. Tech. rep., Manubot\n(2019)\n99. Noether, S.: Ring signature con\ufb01dential transactions for monero. IACR Cryptol.\nePrint Arch. 2015, 1098 (2015)\n100. Omar, A.S., Basir, O.: Capability-based non-fungible tokens approach for a de-\ncentralized aaa framework in iot. In: Blockchain Cybersecurity, Trust and Privacy,\npp. 7\u201331. Springer (2020)\n101. Raman, R.K., et al.: Trusted multi-party computation and veri\ufb01able simulations:\nA scalable blockchain approach. arXiv preprint arXiv:1809.08438 (2018)\n102. Raval, S.: Decentralized applications: harnessing Bitcoin\u2019s blockchain technology.\n\u201d O\u2019Reilly Media, Inc.\u201d (2016)\n103. Regner, F., Urbach, N., Schweizer, A.: Nfts in practice\u2013non-fungible tokens as\ncore component of a blockchain-based event ticketing application (2019)\n104. Rogaway, P., Shrimpton, T.: Cryptographic hash-function basics: De\ufb01nitions, im-\nplications, and separations for preimage resistance, second-preimage resistance,\nand collision resistance. In: FSE. pp. 371\u2013388. Springer (2004)\n105. Shirole, M., Darisi, M., Bhirud, S.: Cryptocurrency token: An overview. IC-BCT\n2019 pp. 133\u2013140 (2020)\n106. Shostack, A.: Experiences threat modeling at microsoft. MODSEC@ MoDELS\n2008 (2008)\n107. Szabo, N.: Smart contracts: building blocks for digital markets. EXTROPY: The\nJournal of Transhumanist Thought,(16) 18(2) (1996)\n108. Trautman, L.J.: Virtual art and non-fungible tokens. Available at SSRN 3814087\n(2021)\n109. Valdeolmillos, D., et al.: Blockchain technology: a review of the current challenges\nof cryptocurrency. In: International Congress on Blockchain and Applications. pp.\n153\u2013160. Springer (2019)\n110. Wang, G., et al.: Sok: Sharding on blockchain. In: Proceedings of the 1st ACM\nConference on Advances in Financial Technologies. pp. 41\u201361 (2019)\n111. Wang, Q., Li, R.: A weak consensus algorithm and its application to high-\nperformance blockchain. In: IEEE INFOCOM 2021-IEEE Conference on Com-\nputer Communications (INFOCOM). IEEE (2021)\n112. Wang, Q., Qin, B., Hu, J., Xiao, F.: Preserving transaction privacy in bitcoin.\nFuture Generation Computer Systems 107, 793\u2013804 (2020)\n113. Wang, Q., Yu, J., Chen, S., Xiang, Y.: Sok: Diving into dag-based blockchain\nsystems. arXiv preprint arXiv:2012.06128 (2020)\n114. Wang, Y., Kogan, A.: Designing con\ufb01dentiality-preserving blockchain-based\ntransaction processing systems. International Journal of Accounting Information\nSystems 30, 1\u201318 (2018)\n115. William, E., Dieter, S., Jacob, E., Nastassia, S.: Eip-721: Erc-721 non-fungible\ntoken standard. Accessible: https://eips.ethereum.org/EIPS/eip-721 (2018)\n116. William, E., Dieter, S., Jacob, E., Nastassia, S.: Erc-721 non-fungible token stan-\ndard. Ethereum Improvement Protocol, EIP-721, Accessible: https://eips.eth\nereum.org/EIPS/eip-721. (2018)\n117. Witek, R., Andrew, C., Philippe, C., James, T., Eric, B., Ronan, S.: Eip-1155:\nErc-1155 multi token standard. Ethereum Improvement Protocol, EIP-1155, Ac-\ncessible: https://eips.ethereum.org/EIPS/eip-1155. (2018)\n19\n118. Witek, R., et al.: Eip-1155: Erc-1155 multi token standard. Accessible: https:\n//eips.ethereum.org/EIPS/eip-1155 (2018)\n119. Wood, G., et al.: Ethereum: A secure decentralised generalised transaction ledger.\nEthereum project yellow paper 151(2014), 1\u201332 (2014)\n120. Zamyatin, A., et al.: Sok: communication across distributed ledgers. (2019)\n121. Zhou, J., Gollman, D.: A fair non-repudiation protocol. In: Proceedings 1996\nIEEE Symposium on Security and Privacy. pp. 55\u201361. IEEE (1996)\nAppendix A. Version Control\nThis work is an ongoing updated technique report. In the future, we will add the\nlandmark events from in the wild NFT projects to inspire technique movements\nand developments. Dynamic data (like prices, sales, or market cap) will remain\nas it is in the current snapshot [as of May 2021].\nTable 2: Version Updates\nVersion\nDate\nUpdates\nV1\nMay 2021\nMain body construction\nV2\nOctober 2021\nAdding the bottom to top model in Section 3\nAdding the instance analysis of the Loot project in Appendix D\nRevisions of unclear sentences and paragraphs\nAppendix B. Top Sales of NFT Properties\nTable 3: NFT Collectible Ranking by Sales Volume (All-time)\nRank Product\nSales\nBuyers\nTxns\nOwners\n1\nNBA Top Shot [44]\n$573,815,060.38\n285,306\n4,877,975\n498,659\n2\nCryptoPunks [20]\n$316,956,115.15\n2,716\n13,231\n2,282\n3\nMeebits [38]\n$54,750,807.84\n1,336\n2,995\n4,436\n4\nHashmasks [31]\n$49,713,202.76\n3,165\n11,322\n4,254\n5\nSorare [58]\n$39,807,257.19\n16,435\n225,909\n18,050\n6\nCryptoKitties [19]\n$33,230,422.66\n100,624\n762,562\n7\nArt Blocks [7]\n$18,824,119.18\n2,052\n10,907\n4,521\n8\nAlien Worlds [6]\n$17,239,575.21\n165,818\n2,280,968\n1,124,901\n9\nBored Ape Yacht Club [11] $11,844,235.71\n2,281\n5,786\n2,697\n10\nTopps MLB [60]\n$10,205,104.07\n12,706\n365,963\n36,283\nData captured on May 10, 20201, source from: https://cryptoslam.io/\n20\nAppendix C. Overview of Existing NFT solutions\nTable 4: Existing NFTs Projects (May, 2021)\nTypes\nProjects\nPlatform\nKey Words\nCollectible\nNBA Top Shot [44]\nFlow [2]\nBasketball moments\nCryptoPunks [20]\nEthereum The \ufb01rst NFT products\nCryptoWine [23]\nEthereum Mining by graps / Trading wines\nHashmask [31]\nEthereum Digital arts / Blind boxes\nCards\nSorare [58]\nEthereum Football star cards\nSkyweaver [56]\nEthereum Card game\nCometh [16]\nEthereum Galaxy background\nGods Unchained [29]\nEthereum Trading card game / Hearthstone\nTopps MLB [60]\nWAX [66] Baseball cards\nR Planet [53]\nWAX\nRed planet background\nRaising Pets\nCryptoKitties [19]\nEthereum The \ufb01rst game with hype in Ethereum\nCryptoCats [18]\nEthereum\nRaising pets and sell with high prices\nAxie In\ufb01nity [9]\nEthereum\nVirtual World\nSandbox [3]\nEthereum\nCreate, explore and trade in the virtual\nworld owned by users, also make money\nby selling the properties.\nDecentraland [1]\nEthereum\nSommnium Space [57] Ethereum\nCryptovoxels [22]\nEthereum\nAlien Worlds [6]\nWAX\nMyCryptoHeros [43]\nEthereum Historical story / Japan made\nReal Properties\nCrypto stamp [17]\nEthereum NFTs on stamps\nDiamonds [47]\nEthereum NFTs on diamonds\nIcecap [32]\nEthereum\nWiv [68]\nEthereum NFTs on wine\nArt Market\nSuperRare [59]\n-\nA marketplace to create, collect and\ntrade unique, single-edition artworks.\nEvery artwork is authentically created\nby artists, and tokenized as a crypto-\ncollectible digital item.\nRarible [55]\n-\nCargo [13]\n-\nAsync Art [8]\n-\nNifty Gateway [48]\n-\nKnownOrigin [33]\n-\nStatistic Web\nNonFungible [49]\n-\nTrace and monitor NFT-related\nprojects or generic types of\ncryptocurrencies by providing timely\nstatistical data to show trends.\nDappRadar [24]\n-\nNFT bank[45]\n-\nDe\ufb01Pulse [26]\n-\nCoingecko [15]\n-\nExchanges\nCryptoslam [21]\nA marketplace to trade unique,\nsingle-edition NFT-based properties.\nOpensea [50]\n-\nZora [69])\n-\nSources from NonFungible, Cryptoslam, De\ufb01Pulse, Coingecko, and DappRadar.\n21\nAppendix D. Analysis of Loot\nLoot [34][35] is a type of NFT product that uses ERC protocol on Ethererum,\nwith totally 8, 000 entries (7778 for trading, 222 for team incentives). The project\npresents all their products in the form of TEXT, removing functionalities of\nimages, stats, or any representative formats. Users can only see eight lines of\nsentences, describing the attributes of game gears (e.g., weapons, armor, neck-\nlaces, Rings). In order to create scarcity, Loot adds randomized pre\ufb01xes (with\n42% probability) or su\ufb03xes (8.7%) for each line of attributes (see the following\ncode, line 2), according to the assigned tokenID from users. Users can only use\nEtherscan\u2019s smart contract to cast loot, rather than its o\ufb03cial website.\nSelected code in Loot project\n1\nfunction\npluck(tokenId , keyPrefix , sourceArray ) internal\nview\nreturns (string\nmemory) {\n2\nuint256\nrand = random(string(abi. encodePacked (keyPrefix , toString(tokenId\n))));\n3\nstring\nmemory\noutput = sourceArray [rand % sourceArray . length ];\n4\nuint256\ngreatness = rand % 21;\n5\nif (greatness\n> 14) {\n6\noutput = string(abi. encodePacked (output , \" \", suffixes[rand %\nsuffixes . length ]));\n7\n}\n8\nif (greatness\n>= 19) {\n9\nstring [2]\nmemory\nname;\n10\nname [0] = namePrefixes [rand % namePrefixes . length ];\n11\nname [1] = nameSuffixes [rand % nameSuffixes . length ];\n12\nif (greatness\n== 19) {\n13\noutput = string(abi. encodePacked (\u2019\"\u2019, name [0], \u2019 \u2019, name [1], \u2019\" \u2019\n, output));\n14\n} else {\n15\noutput = string(abi. encodePacked (\u2019\"\u2019, name [0], \u2019 \u2019, name [1], \u2019\" \u2019\n, output , \" +1\"));\n16\n}\n17\n}\n18\nreturn\noutput;\n19 }\nAs faced by other NFTs, Loot confronts many drawbacks either. Firstly, the\nvalue of NFT is uncertain. Loot is still in the early stage of development in\nthe current stage. Despite the price continuing to rise, there is no lack of hype.\nThe real consensus from communities should be maintained for a long period.\nSecondly, di\ufb03culty in minting and high gas cost retard its wide participant.\nLoot does not have a front-end Dapps, which can only be minted in the Web3\nbrowser. Complex steps become a big challenge for newcomers. Meanwhile, the\nhigh gas fee of operations in Ethereum keeps many people away from this game.\nThe trading or minting fees can reach up to tens of hundreds of dollars for each\noperation. Thirdly, the extensibility needs further improvements. The current\nversion (experimental stage) merely covers eight explicit attributes in the RPG\ngame. Also, there is no space for on-top applications. The only future might be\nto develop more attributes and slots for sale.\n22\n",
    "2101.08778": "SoK: Decentralized Finance (DeFi)\nSam Werner\nImperial College London\nDaniel Perez\nImperial College London\nLewis Gudgeon\nImperial College London\nAriah Klages-Mundt\nCornell University\nDominik Harz\nInterlay\nWilliam J. Knottenbelt\nImperial College London\nABSTRACT\nDecentralized Finance (DeFi), a blockchain powered peer-to-peer\nfinancial system, is mushrooming. Two years ago the total value\nlocked in DeFi systems was approximately 700m USD, now, as of\nApril 2022, it stands at around 150bn USD. The frenetic evolution\nof the ecosystem has created challenges in understanding the basic\nprinciples of these systems and their security risks. In this Sys-\ntematization of Knowledge (SoK) we delineate the DeFi ecosystem\nalong the following axes: its primitives, its operational protocol\ntypes and its security. We provide a distinction between technical\nsecurity, which has a healthy literature, and economic security,\nwhich is largely unexplored, connecting the latter with new models\nand thereby synthesizing insights from computer science, econom-\nics and finance. Finally, we outline the open research challenges in\nthe ecosystem across these security types.\nKEYWORDS\nDecentralized Finance, DeFi, Ethereum, Blockchain\n1\nDEFI: FINANCE 2.0?\nConsider two views on the promise of Decentralized Finance (DeFi).\nFor the DeFi Optimist, DeFi amounts to a breakthrough techno-\nlogical advance, offering a new financial architecture that is non-\ncustodial, permissionless, openly auditable, (pseudo)anonymous,\nand with potentially new capital efficiencies. According to this\nview, DeFi generalizes the promise at the heart of the original Bit-\ncoin whitepaper [109], extending the innovation of non-custodial\ntransactions to complex financial operations. In contrast, the DeFi\nPessimist is concerned that, inter alia, the unregulated, hack-prone\nDeFi ecosystem serves to facilitate unfettered and novel forms of fi-\nnancial crime. The pseudo-anonymous nature of DeFi permits cryp-\ntocurrency attackers, scammers, and money launderers to move,\nclean, and earn interest on capital. A critical part of the debate\nbetween the DeFi Optimist and the DeFi Pessimist, but outside of\nthe scope of this paper, is moral in nature. This SoK leaves this im-\nportant facet aside, focusing instead on synthesizing and evaluating\nthe technical innovations of DeFi, seeking to allow newcomers to\nthe field to discover the essential features and problems of the DeFi\nterrain.\nDeFi, in its ideal form, exhibits four properties. DeFi is:\n(1) Non-custodial: participants have full control over their funds\nat any point in time\n(2) Permissionless: anyone can interact with financial services\nwithout being censored or blocked by a third party\n(3) Openly auditable: anyone can audit the state of the system,\ne.g., to verify that it is healthy\n(4) Composable: its financial services can be arbitrarily composed\nsuch that new financial products and services can be created\n(similar to how one is able to conceive new Lego models\nbased on a few basic building blocks)\nDeFi has grown rapidly, going from around 700m USD in total\nvalue locked (TVL, or analogously \u201cassets under management\u201d) at\nthe start of 2020 to over 150bn USD as of April 2022. Ethereum\nalone accounts for 75bn USD in TVL, with the most capitalized use\ncases being collateralized lending, constituting c.54%, of the TVL,\nand decentralized exchange (DEXs), constituting c.31% of the TVL\nas of April 2022 [48]. In turn, this rise led to the 24 hour volume\non a decentralized cryptoasset exchange [156], overtaking that of a\nmajor centralized cryptoasset exchange [34] for the first time [69].\nYet, as with any nascent technology, DeFi is not without its risks.\nThe decentralized nature of DeFi necessarily allows any actor to\nwrite unaudited and even malicious smart contracts, where user\nfunds can be lost through programming error or stolen. Moreover,\nthe audit process itself is no guarantee of safety, with many audited\nprotocols (e.g., [10, 75, 101, 138, 166]) suffering serious exploits.\nThis paper. For DeFi to fulfill the vision of the DeFi Optimist,\nit must first be secure. The central contribution of this SoK is to\ncleanly and exhaustively delineate the DeFi security challenge into\ntechnical security and economic security. The delineation centers\non atomicity: whether the attack is near-instantaneous and can\ncostlessly fail (and therefore risk-free), or has a non-instantaneous\nduration and where failure comes with a cost. This categorization\nhas the benefit of cleanly mapping different types of models to\neach type of security and clarifying previously vague terms of\n\u201ceconomic risk\u201d that have been commonly misapplied to exploits\nthat are better understood as technical in nature (e.g., DEX sandwich\nattacks). Prior to this paper, economic security risks were largely\nunexplored, in part because they require synthesizing insights from\nacross computer science, economics, and finance.\nThis SoK is structured as follows. We outline DeFi primitives\nin Sec. 2 and systematize existing DeFi protocols by six types of\noperations in Sec. 3. We provide a definition of DeFi exploits in\nSection 4. We then define a novel functional categorization of tech-\nnical and economic security risks in DeFi and classify different\nattacks for each security type in Sections 5 and 6, respectively. We\nthen propose a set of six primary open research challenges for DeFi\ngoing forward that build on these security types in Sec. 7.\nRelated work. Several surveys and other SoKs exist on specific\nDeFi protocol types.1 We direct the reader, when appropriate, to\nsuch SoKs for further material (e.g., [15, 41]). One well-structured\nsurvey on DeFi has been published after our pre-print [144], which\n1Most have been pre-printed since our paper was originally released.\narXiv:2101.08778v6  [cs.CR]  15 Sep 2022\ncategorizes DeFi protocols but focuses on high level risk and reg-\nulatory challenges. None of these works delineate the new types\nof security challenges across DeFi, which is the main focus of our\nSoK.\n2\nDEFI PRIMITIVES\nDeFi protocols require an underlying distributed ledger such as a\nblockchain, a peer-to-peer distributed append-only record of trans-\nactions. We take the underlying distributed ledger layer solely\nas an input into DeFi and refer the reader to existing work (no-\ntably [14, 25, 71, 171]) for a fuller exposition of the blockchain layer\nitself. We assume that the ledger has the basic security properties\nof consistency, integrity and availability [175]. Without these secu-\nrity properties, DeFi protocols built on top of such a ledger would\nthemselves become inherently insecure.\nIn this section, we draw attention to features of the underlying\nblockchain layer that are most pertinent to DeFi.\n2.1\nSmart Contracts and Transactions\nSmart Contracts. The most important provision is that the un-\nderlying ledger offers the ability to use smart contracts, which\nare program objects that live on the blockchain. These are able to\ncommunicate with one-another, via message-calls, within the same\nexecution context and support atomicity, i.e., a transaction either\nsucceeds fully (state update) or fails entirely (state remains unal-\ntered), such that no execution can result in an invalid state. In some\ncases, bundles of transactions, in which transactions are grouped\ntogether in a given sequence, can also be executed atomically (e.g.,\n[61]).\nSmart contracts rely on blockchains that are transaction-based\nstate machines, whereby an agent can interact with smart contracts\nvia transactions. Once a transaction is confirmed, the contract code\nis run by all nodes in the network and the state is updated. The\nunderlying cost to state updates comes in the form of transaction\nfees charged to the sender. For instance, the Ethereum Virtual\nMachine (EVM) [165] on the Ethereum [27] blockchain is a stack\nmachine which uses a specific set of instructions for task execution.\nThe EVM maintains a fixed mapping of how much gas, an Ethereum-\nspecific unit that denominates computational cost, is consumed per\ninstruction. The total amount of gas consumed by a transaction is\nthen paid for by the sender [121, 162].\nIn order for DeFi protocols to function on top of them, smart\ncontracts must:\n\u2022 be expressive enough to encode protocol rules\n\u2022 allow conditional execution and bounded iteration\n\u2022 be able to communicate with one-another, via message-calls,\nwithin the same execution context (typically a transaction)\n\u2022 support atomicity, i.e., a transaction either succeeds fully\n(state update) or fails entirely (state remains unaltered), such\nthat no execution can result in an invalid state\nThese properties provide composability, where smart contracts can\nbe snapped together like Lego bricks (\u201cMoney Lego\" [47]), with\nthe possibility of building complex financial architectures. This\nis similar to as was envisaged in [82]. While promising, the side-\neffects of smart contracts interactions and the space of all possible\ninteractions is vast. In a setting focused on financial applications,\nsuch complexity brings with it a great burden to understand the\nemergent security properties of composed smart contracts. We\ndiscuss this in more detail in Sections 5 and 6. One particularly\ncommon use of smart contracts is to implement tokens, on-chain\nassets.\nTransaction Execution. When a blockchain network participant\nwishes to make a transaction, the details of the unconfirmed trans-\naction are first broadcast to a network of peers, validated, and then\nstored in a waiting area (the mempool of a node). This mempool\nis then propagated among the network nodes. Participants of the\nunderlying ledger responsible for ensuring consensus, miners, then\nchoose which transactions to include in a given block, based in part\non the transaction fee attached to each transaction. Transactions in\na block are executed sequentially in the order in which the miner\nof the respective block included them. For a detailed treatment of\nhow this process works, we refer the reader to [109, 110, 123, 165].\nMiners have the ability to control the sequence in which transac-\ntions are executed. Hence, miners can order transactions in ways\nthat will earn them revenues and even insert their own transactions\nto extract further revenues. Miners can even be bribed to under-\ntake such transaction re-ordering [107, 164]. The value that miners\ncan extract is known as Miner Extractable Value (MEV) [46]. We\nconsider these issues in detail in Sec. 6.2.\n2.2\nKeepers\nProtocols may rely on their on-chain state being continually up-\ndated for their security. In transaction-based systems, updating the\non-chain state requires transactions that are triggered externally.\nSince smart contracts are not able to create transactions program-\nmatically, protocols must rely on external entities to trigger state\nupdates. These entities, keepers, are generally financially incen-\ntivized to trigger such state updates. For instance, if for whatever\nreason a protocol requires a user\u2019s collateral to be automatically\nliquidated under certain conditions, the protocol will incentivize\nkeepers to initiate transactions to trigger such liquidation.\n2.3\nOracles\nAn oracle is a mechanism for importing off-chain data into the\nblockchain virtual machine so that it is readable by smart contracts.\nThis includes off-chain asset prices, such as ETH/USD, as well as off-\nchain information needed to verify outcomes of prediction markets.\nOracles are relied upon by various DeFi protocols (e.g. [2, 97, 104,\n125, 146]).\nOracle mechanisms differ by design and their risks, as discussed\nin [90, 100]. A centralized oracle requires trust in the data provider\nand bears the risk that the provider behaves dishonestly should\nthe reward from supplying manipulated data be more profitable\nthan from behaving honestly. Decentralized oracles offer an alterna-\ntive. As the correctness of off-chain data is not verifiable on-chain,\ndecentralized oracles tend to rely on incentives for accurate and\nhonest reporting of off-chain data. However, they come with their\nown shortcomings. We provide a detailed overview of oracle manip-\nulation risks and on the shortcomings of on and off-chain oracles\nin Sections 5.2 and 6.4.\n2\n2.4\nGovernance\nGovernance refers to the process through which a system is able\nto effect change to the parameters which establish the terms on\nwhich interactions between participants within the system take\nplace [90]. Such changes can be performed either algorithmically or\nby agents. While there is existing work on governance in relation to\nblockchains more broadly (e.g. [16, 94, 130]), there is still a limited\nunderstanding of the properties of different mechanisms that can\nbe used both for blockchains and DeFi.\nPresently, a common design pattern for governance schemes is\nfor a DeFi protocol to be instantiated with a benevolent dictator\n\u2014sometimes distributing power over a small council or \u201cmultisig\u201d\u2014\nwho has control over governance parameters, with a promise made\nby the protocol to eventually decentralize its governance process.\nSuch decentralization of the governance process is most commonly\npursued through the issuance of a governance token (e.g. [13, 36, 44,\n105]), an ERC-20 token which entitles token holders to participate\nin protocol governance via voting on and possibly proposing pro-\ntocol updates. This token represents ownership in a decentralized\nautonomous organization (DAO) that is taksed with stewardship of\nthe protocol.\nProtocol upgrades in the DAO setting come through proposals\nin the form of executable code, on which governance token holders\nvote. In order to propose protocol updates, the proposer has to hold\nor have been delegated a threshold number of governance tokens.\nFor a protocol upgrade to be executed, a minimum number of votes\nis required, which is commonly called a \u201cquorum\u201d in this setting.\n3\nDEFI PROTOCOLS\nWe now present DeFi protocols categorized by the type of operation\nthey provide (for an illustration see Fig. 1).\n3.1\nOn-chain Asset Exchange\nDecentralized exchanges (DEXs) [81, 99] are a class of DeFi protocol\nthat facilitate the non-custodial exchange of digital assets, where all\ntrades are settled on-chain and thus publicly verifiable. While DEXs\ninitially only supported assets native to the chain on which they\noperate, wrapped tokens, such as wBTC [21] (wrapped Bitcoin), and\nnovel cross chain solutions [52, 167, 171, 172] have enabled DEXs to\novercome this limitation. Today, based on the mechanism for price\ndiscovery, DEXs come in different variants, such as order book DEXs\n(including individual [80, 161] and batch settlement [17, 68], see\nAppendix C for the latter) and automated market makers (AMMs)\n(e.g., [54, 106, 157]). Due to their widespread adoption and novelty\nin DeFi, we specifically focus on AMMs.\nIn traditional finance, market makers are liquidity providers that\nboth quote a bid and ask price, selling from their own book, while\nmaking a profit from the bid-ask spread. Optimal market making\nstrategies quickly become sophisticated optimization problems. In\ncontrast, AMMs provide liquidity algorithmically through simple\npricing rules with on-chain liquidity pools in place of order books\nand have been previously studied in algorithmic game theory, e.g.,\nlogarithmic market scoring rule (LMSR) [73] in prediction markets.\nWhile they have largely remained unimplemented in traditional\nfinance, they have become popular in DeFi for a several reasons:\n(1) they allow easy provision of liquidity on minor assets, (2) they\nA\nDistributed \nLedger\nSmart Contracts\nToken(s)\nLiquid Markets\nCollateral\nArbitrage\nGovernance\nOracle\nProtocol\nProtocol\nProtocol\nComposability\nLiquidations\nDerivatives\nStablecoins\nAsset \nExchange\nLoanable Funds \nMarkets\nPortfolio \nManagement\nB\nMarket Mechanism\nMixers\nFigure 1: A conceptual overview of the different constructs within\nthe DeFi ecosystem.\nallow anyone to become a market maker, even if the market making\nreturns are suboptimal, (3) AMM pools can be separately useful as\nautomatically rebalancing portfolios, (4) maintaining an order book\non-chain is inefficient.\nIn an AMM liquidity pool, reserves for two or more assets are\nlocked into a smart contract, where for a given pool, each liquidity\nprovider receives newly minted liquidity tokens to represent the\nshare of liquidity they have provided. A trade is then performed\nby trading against a smart contract\u2019s liquidity reserve for an as-\nset, whereby liquidity is added to the reserves of one token and\nwithdrawn from the reserves of one or more other pool tokens. A\ntrading fee is retained by a liquidity pool and paid out proportion-\nally to the amount of liquidity provided by each liquidity token\nholder. Liquidity providers are required to give up their liquidity\ntokens in order to redeem their share of liquidity and accrued fees.\nWith an AMM, the price of an asset is deterministic and decided\nby a formula, not an order book, and thus depends on the relative\nsizes of the provided liquidity on each side of a currency pair. If\nthe liquidity is thin, a single trade can cause a significant fluctua-\ntion in asset prices relative to the overall market, and arbitrageurs\ncan profit by closing the spread. Arbitrage refers to the process\nof buying or selling the same asset in different markets to profit\nfrom differences in price. Parties who undertake this process are\narbitrageurs, and play a critical role in DeFi protocols. Arbitrage\nis used to ensure that the price for an asset on an AMM is at par-\nity with the price on the open market. Note that as the reserve\nratios for a pool\u2019s assets change as liquidity is added and with-\ndrawn, a liquidity provider may receive a different token ratio upon\nwithdrawing his liquidity share compared to the ratio he initially\ndeposited. For a more focused and formal analysis of AMM design\n3\nand the underlying market making mechanism, we direct the reader\nto [3\u20136, 176].\n3.2\nLoanable Funds Markets for On-chain\nAssets\nLending and borrowing of on-chain assets is facilitated through\nprotocols for loanable funds (PLFs) [72], which refer to DeFi lending\nprotocols that establish distributed ledger-based markets for loan-\nable funds of cryptoassets by pooling deposited funds in a smart\ncontract. In the context of a PLF, a market refers to the total sup-\nplied and total borrowed amounts of a token, where the available\ndeposits make up a market\u2019s liquidity. An agent may directly bor-\nrow against the smart contract reserves, assuming the market for\nthe token is sufficiently liquid, where the cost of borrowing is given\nby the market\u2019s interest rate.\nOn PLFs, loans are generally of two forms: over-collateralized\nloans and flash loans. With an over-collateralized loan, a borrower is\nrequired to post collateral, i.e., provide something of value as secu-\nrity to cover the value of the debt, where the value of the collateral\nposted exceeds the value of the debt. In this way, collateralization\nsimultaneously ensures that the lender (likely a smart contract)\ncan recover their loaned value and provides the borrower with an\nincentive to repay the loan. In case the value of the locked collateral\nfalls below some liquidation threshold, so-called liquidators, a type\nof keeper, are able to purchase the locked collateral at a discount\nand close the borrower\u2019s debt position [122].\nAn alternative to over-collateralized loans are flash loans. These\nare uncollateralized loans for the duration of a single transaction,\nrequiring the borrower to repay the full borrowed amount plus inter-\nest by the end of the transaction. Flash loans leverage a blockchain\u2019s\natomicity (i.e., the transaction fails if the loan is not repaid in the\nsame transaction) and offer several use cases, such as decentralized\nexchange arbitrage and collateral swaps. However, they can also\nbe used in attacks [127]. For a more detailed discussion and formal\nanalysis of PLFs, we direct the reader to [15, 72].\n3.3\nStablecoins\nNon-custodial stablecoins are cryptoassets which aim to be price\nstable relative to a target currency, commonly the USD, and seek\nto achieve this via additional economic mechanisms. Note that\ncustodial stablecoins, such as USDT [98] are not within the scope of\nDeFi, since these principally rely on a trusted third-party to operate,\nthough they may be among the assets used in other DeFi protocols.\nIn the decentralized setting, the challenge for the protocol de-\nsigner is to construct a stablecoin which achieves price stability in\nan economically secure and stable way and wherein all required\nparties can profitably continue to participate [90]. Price-stability is\npursued via the use of on-chain collateral, providing a foundation\nof secured loans from which the stablecoin derives its economic\nvalue.\nThe core components of a non-custodial stablecoin are as fol-\nlows [90].\n\u2022 Collateral. This is the store of primary value for a stable-\ncoin. Collateral can be exogenous (e.g., ETH in Maker [105]),\nwhere the collateral is primarily used externally to the sta-\nblecoin, endogenous (e.g., SNX in Synthetix [147]), where\nthe collateral was created to be collateral or implicit (e.g.,\nNubits [95]), where the design lacks an explicit store of col-\nlateral.\n\u2022 Agents. Agents form at least two roles in a non-custodial\nstablecoin: (1) risk absorption, for instance by providing col-\nlateral that is intended to absorb price risk, and (2) stablecoin\nusers.\n\u2022 Governance. A mechanism and set of parameters that gov-\nerns the protocol as a whole (either performed by agents or\nalgorithmically).\n\u2022 Issuance. A mechanism to control the issuance of stablecoins\nagainst or using the collateral (either performed by agents\nor algorithmically).\n\u2022 Oracles. A mechanism to import data external to the blockchain\nonto the blockchain, such as price-feeds.\nSee [90, 177] for a more complete discussion of stablecoin designs,\nmodels, and challenges.\n3.4\nPortfolio Management\nFor liquidity providers seeking to maximize their returns, liquidity\nallocation can be an onerous task given the complex and expansive\nspace of yield-generating options. The management of on-chain\nassets can thus be automated through DeFi protocols which serve\nas decentralized investment funds, where tokens are deposited into\na smart contract and an investment strategy that entails transacting\nwith other DeFi protocols (e.g., PLFs) is encoded in the contract.\nYield in DeFi is generated through interest (including accrued fees\nearned) and token rewards. For the latter, a protocol (e.g., PLF or\nAMM) distributes native tokens to its liquidity providers and/or\nusers as rewards for the provision of deposits and/or protocol adop-\ntion. These protocol-native token rewards are similar to equity in\nthe sense that they serve as a right to participate in the protocol\u2019s\ngovernance, as well as often represent a claim on protocol-generated\nearnings. The distribution model for token rewards in exchange\nfor supplied liquidity may vary across protocols, yet is commonly\nproportional to how much liquidity an agent has supplied on a pro-\ntocol. Therefore, smart contract-encoded investment strategies of\non-chain assets are tailored around yield generating mechanisms of\ndifferent protocols with the sole aim of yield aggregation and maxi-\nmization. In practice, on-chain management of assets may range\nfrom automatic rebalancing of a token portfolio [59] to complex\nyield aggregating strategies [42].\n3.5\nDerivatives\nDerivatives are financial contracts which derive their value from the\nperformance of underlying assets. As of March 2022, the derivatives\nmarket represents about 62% of the entire cryptoassets trading\nmarket [43]. While about 99% of the derivative trading volume is\nachieved on centralized exchanges, a number of DeFi protocols have\nemerged which provide similar functionality [53, 113, 113, 163],\nwith a particular focus on synthetic assets, futures, perpetual swaps\nand options. We lay out the adoption four different basic types of\nderivatives popular in the cryptoasset space2:\n2For an introduction to derivatives, we refer the reader to [78]\n4\n(1) Synthetic assets. In DeFi, synthetic assets typically repli-\ncate off-chain assets on-chain (e.g., the USD in protocols like\nMaker and Synthetix [147]). Though less used at present,\nanother mechanism for constructing synthetic assets is to\nuse AMMs that enact dynamic portfolio rebalancing strate-\ngies to replicate derivative payoffs. These bear a resemblance\nto synthetic portfolio insurance (see Ch. 13 in [78]) in tra-\nditional finance and have been explored more specifically\nusing constant product market makers in [33, 57].\n(2) Futures. Futures have seen little adoption in DeFi yet. Likely\nthis is caused by the high volatility of the underlying cryp-\ntoassets making it hard to determine the risk taken by traders\nwriting the futures.\n(3) Perpetual Swaps. These are similar to futures, however,\nthey have no set expiry date or settlement and were specifi-\ncally created and popularized for cryptoasset markets [22].\nPerpetuals allow traders to decide (typically on a daily ba-\nsis, e.g., [53]) to keep the position by providing a funding\ntransaction in case their position is underfunded. Due to\nthe frequent price discovery, the price of perpetuals trades\ntypically closer to the underlying in comparison to futures.\nMoreover, perpetuals are more capital efficient than trading\nthe underlying itself since platforms require less than 100%\ncollateral be posted by traders.\n(4) Options. Currently, the DeFi market for options is very early\nwith basic call and put options (e.g., [113, 163]). The cause for\nthe limited adoption of options is three-fold. First, current\noption platforms are at least 100% collateralized. In compari-\nson to their centralized counter-parts, this represents large\ncapital inefficiency. Second, derivatives with set expiry dates\nlike futures and options are hard to price on AMMs. Most\nAMM platforms (e.g., Uniswap [156]) do not account for a\ntime dimension in the asset. This causes an issue specifically\nwith option trading since the value of the option is subject\nto time decay. Possible remedies are more nuanced AMM\ndesigns like [111] that aim to incorporate such a time di-\nmension. Also, complex value functions in the AMM like\nBalancer [13] allow replicating strategies that combine the\nunderlying and a derivative into a single asset [57]. Third,\noptions require a liquid market for efficient price discovery.\nAdoption will require solving the above problems to boot-\nstrap the required liquidity that allows efficient pricing of\nthose options.\n3.6\nPrivacy-preserving Mixers\nMixers are methods to prevent the tracing of cryptocurrency trans-\nactions. These are important to preserve user privacy, as the trans-\naction ledger is otherwise public information; however, this also\nmeans they could be used to obscure the source of illicit funds. Mix-\ners work by developing a \u201cshielded pool\u201d of assets that are difficult\nto trace back before entering the pool. They typically take one of\ntwo forms: (1) mixing funds from a number of sources so that indi-\nvidual coins can\u2019t easily be traced back to address individually (also\ncalled a \u201ccoinjoin\u201d, e.g., [159]), or (2) directly shielding the contents\nof transactions using zero knowledge proofs of transaction validity\n(e.g., [153, 173]). Mixers serve as a DeFi-like application itself and\nadditionally as a piece that could be included within other DeFi\nprotocols.\n4\nWHAT IS A DEFI EXPLOIT?\nWe define what we consider an exploit to be in the DeFi context.\nTo do this, we first need to set out a taxonomy of blockchain in-\nformation. Let \ud835\udc61denote the ordering of events. At any point \ud835\udc61in\nthis sequence of events, there are three categories of information\nrelevant to a DeFi protocol:\n\u2022 Off-chain ground truth, denoted G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n. For example, true\nwind speed or the true equilibrium prices of assets traded in\noff-chain venues;\n\u2022 On-chain ground truth, denoted G\ud835\udc42\ud835\udc41\n\ud835\udc61\n. For example, on-chain\nasset ownership;\n\u2022 On-chain estimates of off-chain ground truth, denoted \u02c6G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n.\nFor example, oracle reported prices.\nA smart contract only has access to G\ud835\udc42\ud835\udc41\n\ud835\udc61\nand \u02c6G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n. Now con-\nsider that a set of smart contracts (e.g., constituting a DeFi protocol),\n\ud835\udc46, has a set of intended properties, \ud835\udc43\ud835\udc46. Each intended property is\na function of the information up until the current state in the se-\nquence such that\n\ud835\udc43\ud835\udc46\u0010\nG\ud835\udc42\ud835\udc41\n\ud835\udc61\n, G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n\u0011\n=\nn\n\ud835\udc43\ud835\udc46\n0\n\u0010\nG\ud835\udc42\ud835\udc41\n\ud835\udc61\n, G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n\u0011\n, . . . , \ud835\udc43\ud835\udc46\n\ud835\udc5b\n\u0010\nG\ud835\udc42\ud835\udc41\n\ud835\udc61\n, G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n\u0011o\n.\nFor a particular property, it can either hold or not hold at any given\nstate, as intended, such that the properties are Boolean. Some ex-\namples of these properties include the achievement of an invariant\nrule for an AMM or ensuring that debt positions remaining over-\ncollateralized in accordance with a collateral factor in a Protocol\nfor Loanable Funds (PLF).\nFor a smart contract to execute as intended, first, the smart-\ncontract program must actually implement the intended logic (i.e.,\nit must be free of implementation bugs). Second, since smart con-\ntracts often heavily depend on G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n, on-chain estimates of off-\nchain information, \u02c6G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n, must be sufficiently accurate to ensure\nthat \ud835\udc43\ud835\udc56(G\ud835\udc42\ud835\udc41\n\ud835\udc61\n, G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n) = \ud835\udc43\ud835\udc56(G\ud835\udc42\ud835\udc41\n\ud835\udc61\n, \u02c6G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n). Such estimates can be ma-\nnipulated: for example, smart contract states can experience \u2018flash\u2019\nmanipulation, where an artificial state is set up at the beginning\nof a transaction and unwound at the end of a transaction. Such\nmanipulation can result in G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\nand \u02c6G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\ndiverging.\nThe different categories of exploit now follow from this state-\nment of what is required for a smart contract to reliably execute as\nintended. An exploit can arise from an attacker gaining, or seeking\nto gain from:\n(1) Seizing upon a difference between the actual implementation\nof a smart contract and the intended implementation. See\nSection 5.1.\n(2) Seizing upon an incidental difference between G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\nand\n\u02c6G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n. For example, in November 2020 an incidental devia-\ntion in the Dai price reported by Coinbase triggered liquida-\ntions on Compound[35].3\n(3) Creating a deliberate difference between G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\nand \u02c6G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n.\nFor examples, see 5.2 and 5.3.\n3Where such incidental differences are not seized upon this might more properly\nbe considered a system failure, but we group these together as both are relevant for\nanalyzing protocol security\n5\nIn exploits of types (2) and (3), a protocol\u2019s operation is made to\ndeviate from its intended properties, i.e., for some \ud835\udc56,\ud835\udc61,\n\ud835\udc43\ud835\udc56\n\u0010\nG\ud835\udc42\ud835\udc41\n\ud835\udc61\n, G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n\u0011\n\u2260\ud835\udc43\ud835\udc56\n\u0010\nG\ud835\udc42\ud835\udc41\n\ud835\udc61\n, \u02c6G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n\u0011\n.\nNote the importance of the notion of intention in this delineation\nof exploit types. For example, when prices on an AMM and prices\noff-chain differ, this does not amount to an exploit because an\nintended property of an AMM is that arbitrage will rebalance the\nAMM pool according to the AMM\u2019s pricing rule. However, when a\nprotocol uses an AMM price as a price oracle, its operation is relying\non information from \u02c6G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n. When this information is significantly\ndifferent from the true information in G\ud835\udc42\ud835\udc39\ud835\udc39\n\ud835\udc61\n(e.g., if an attacker\nmanipulates the oracle price), this can cause the protocol to behave\nin unintended ways, which would amount to an exploit.\nExploits are usually worrisome when they are either profitable\n(i.e., an attacker can get more assets out of the exploit than they\nare spending to execute the exploit, usually from stealing assets) or\nwhen they cause high losses for protocols or users for low cost of\nexecution (which itself is often profitable by short selling the token\nof a protocol to be exploited).\nIn the following two sections we delineate between two general\ntypes of exploits in a novel way that simultaneously distinguishes\nhow the exploit is performed, the type of risks taken on by an\nattacker, and the types of tools and models required to analyze se-\ncurity in the two contexts. Note that some attacks on DeFi protocols\nmay not be categorized as security exploits at all. For example, the\ncollapse of the Terra stablecoin [24] (and related collapses like the\nIron stablecoin before it [49]) may be better described as currency\nruns/attacks as opposed to security exploits considering that they\nresult from breaching the economic limits of a mechanism without\nnecessarily exploiting the formal properties of smart contracts.\n5\nTECHNICAL SECURITY\nWe define a DeFi security risk to be technical if an agent can atomi-\ncally exploit a protocol. In a technical exploit, an attacker effectively\nfinds a sequence of contract calls, whether in a single transaction or\na bundle of transactions, that leads to a profit through a violation\nof a protocol\u2019s intended properties (as visualized in Fig. 2). Such\nexploits can be performed risk-free (and often in a sense \u2018instanta-\nneously\u2019) because the outcomes for the attacker are binary: either\nthe attack is successful and the attacker profits or the transaction\nreverts (effectively the attack doesn\u2019t happen) and the attacker only\nloses some gas fees.\nContract 1\nContract 2\nContract N\nContract 3\n$$\nFigure 2: Diagram of a technical exploit.\nIn current blockchain implementations, this coincides with (1)\nmanipulating an on-chain system within a single transaction, which\nis risk-free for anyone, and (2) manipulating transactions within\nthe same block, which is risk-free for the miner generating that\nblock or for an attacker who creates a bundle of transactions that\nare required to execute atomically in the order given. By exploiting\ntechnical structure, the underlying blockchain system allows no\nopportunity for markets or other agents to react in the course of\nsuch exploits (when such reaction is possible, we enter the domain\nof economic security problems in the next section). When there is\ncompetition to perform these exploits, they will factor into the game\ntheory of blockchain mining (e.g., [20]) as part of MEV extraction\n(as discussed in [46]); however, attempting these exploits will be\nrisk-free (minus potential gas fees) for any attacker. We identify\nthree categories of attacks that fall within technical security risks\nof DeFi protocols: attacks exploiting smart contract vulnerabilities,\nattacks relying on the execution order of transactions in a block,\nas well as attacks which are executed within a single transaction.\nThese security risks are often addressable with program analysis\nand formal models to specify protocols, although these problems\ncan quickly become complex to formulate and computationally\nhard.\nTechnical Security\nA DeFi protocol is technically secure if it is not possible for an\nattacker to atomically exploit the protocol at the expense of value\nheld by the protocol or its users. Due to atomicity, these attacks\ncan generate risk-free profit. A common property of technical ex-\nploits is that they occur within a single transaction or a bundle of\ntransactions in a block.\nExamples of past DeFi protocol exploits that fall into the pre-\nsented attack categories of technical security are given in Table 1\nin Appendix A.\n5.1\nSmart Contract Vulnerabilities\nSmart contract vulnerabilities have been extensively discussed in\nthe literature [8, 120, 155] and we will therefore not give an exten-\nsive list of all the known vulnerabilities but rather focus on the one\nwhich have already been exploited in the DeFi context.\nReentrancy. A contract is potentially vulnerable to a reentrancy\nattack if it delegates control to an untrusted contract, by calling\nit with a large enough gas limit, while its state is partially modi-\nfied [140]. A trivial example is a contract with a withdraw function\nthat checks for the internal balance of a user, sends them money\nand updates the balance. If the receiver is a contract, it can then re-\npeatedly re-enter the victim\u2019s contract to drain the funds. Although\nthis attack is already very well-known, it has been successfully\nused several times against DeFi protocols[40, 51].\nIn practice, reentrancy vulnerabilities are generally simple to\ndetect and fix by using static analysis tools [103, 155]. There are\ntwo main ways to prevent this vulnerability: (1) using a reentrancy\nguard that prevents any call to a given function until the end of\nits execution or (2) finalizing all the state updates before passing\nexecution control to an untrusted contract.\nInteger Manipulation. Almost every DeFi application manipu-\nlates monetary amounts in some way or another. This often involves\n6\nnot only adding and subtracting to balances but also converting\ninto different units or to different currencies. We present the two\nmost common types of integer manipulation issues.\nThe first issue, which has been extensively studied in the liter-\nature [86, 154], is integer over- and underflow. As the Ethereum\nVirtual Machine (EVM) [165] does not raise any exception in case\nof over- or underflow, this will often result in failed transactions\nand cause the smart contract to misbehave [120].\nThe second issue is unit error during integer manipulation. The\nmain language used to develop DeFi applications on Ethereum at\nthe time of writing is Solidity [62], which has a limited type system\nand no support for operator overloading. In addition, the EVM\nonly supports a single type, 32 byte integers, and has no built-in\nsupport for fixed-point numbers. To work around this limitation,\neach protocol decides on an arbitrary power of 10 to use as its base\nunit, often 1018, and all the computations are performed in terms of\nthis unit. However, given the limitations of the type-system, most\nprograms elect to use exclusively 32 byte integers. Arithmetic on\ntwo units accidentally on different scales would not be caught by\nthe compiler.\nLogical Bugs. There are a large number of exploits that are rooted\nin simple programming errors in the smart contracts. While logical\nbugs are by no means unique to smart contracts, but common to\nany type of software, the consequences for smart contracts, where\nimmutability underpins the system, can be much more severe than\nfor many other genres of software and result in unrecoverable\nfinancial losses.\nA large share of the bugs found in Table 1 are also very sim-\nple mistakes that have been overlooked in both the development\nprocess and professional contract audits. We discuss in Section 7\npotential mitigation techniques to these issues.\n5.2\nSingle Transaction Attacks\nWe refer to attacks which can be successfully executed, independent\nof knowing about some other pending transaction, as single trans-\naction attacks. This category of attack is leveraging transaction\natomicity and composability of smart contracts.\nGovernance Attacks. Protocols that implement decentralized gov-\nernance mechanisms tend to rely upon governance tokens, which\nempower token holders to propose and vote on protocol upgrades.\nThe technical structure of these governance mechanisms can some-\ntimes be exploited. For instance, many governance designs allow\nupdates to be instantaneously proposed and approved and the pro-\ntocol code upgraded within a single transaction. In this setting, an\nattacker may obtain an amount of governance tokens sufficient to\npropose and execute malicious contract code and steal a contract\u2019s\nfunds, all while circumventing the usual governance process in\nwhich other participants can react [70]. The attacker may even\nobtain the share of governance tokens instantaneously within the\nsame transaction (i.e., they may not be a long-term participant)\nthrough flash loans from PLFs and swaps from AMMs. In fact, large\nquantities of governance tokens can be obtained easily in these\nways today, and such attacks have been executed in practice [102].\nThe direct problem can usually be sorted by applying a timelock\nto the governance process so that updates cannot be performed\ninstantaneously and other participants have a chance to react. How-\never, as we will see in the economic security section, this often does\nnot solve the incentive issues completely, it just resolves the techni-\ncal issue.\nSingle Transaction Sandwich Attacks. In a single transaction\nsandwich attack, an attacker manipulates an instantaneous AMM\nprice in order to exploit a smart contract that uses that price. An\nattacker first creates an imbalance in an AMM, exploits composable\ncontracts which rely on the manipulated price, and then reverses\nthe imbalance to cancel out the cost of the first step. The whole\nsequence can be performed atomically in a single transaction risk-\nfree. Creating an imbalance typically requires access to a large\namount of capital. In a system with flash loans/minting, all agents\neffectively have such access, although we stress that these attacks\nare still possible for large capital holders regardless of whether\nflash loans/minting are widespread. In practice, this type of attack\nhas occurred multiple times [118, 131]. One of the most prominent\nsingle transaction sandwich attacks in terms of seized funds was\nperformed against the Harvest protocol [56]. The attacker took out\na $50m USDT flash loan from Uniswap and used part of the funds to\ncreate an imbalance in the liquidity reserves of USDC and USDT on\nCurve [44] (an AMM) to increase the AMM\u2019s virtual price of USDT.\nAs the price of USDT on Curve was used as an on-chain oracle\nby the Harvest protocol, the attacker was able to mint Harvest\nLP tokens (i.e., tokens a liquidity provider receives in exchange\nfor depositing funds into a protocol) by depositing 60.6m USDT,\nbefore reversing the imbalance on Curve and withdrawing 61.1m\nUSDT from Harvest. The attacker was able to withdraw more USDT\nthan deposited, as at the time of the withdrawal, the USDT price\ngiven by Curve was less than the deposit price, and therefore one\nHarvest LP token was worth more USDT during withdrawal. The\nattacker repeated this attack 32 times, draining a total of $33.8m of\nthe protocol\u2019s funds.\nTo protect against such manipulations, AMMs include a limit\namount (or maximum slippage) that a trade can incur, though this\nonly prevents manipulations above this amount.\n5.3\nTransaction Ordering Attacks\nIn traditional finance, the act of front-running refers to taking prof-\nitable actions based on non-public information on upcoming trades\nin a market. In the context of blockchain, front-running a transac-\ntion refers to submitting a transaction which is solely intended to\nbe executed before some other pending transaction [55]. As trans-\nactions are executed sequentially according to how they have been\nordered in a block, an agent may financially benefit from front-\nrunning one or more transactions, by having their transaction exe-\ncuted before a victim transaction. Similarly, an agent may pursue\nback-running, whereby a transaction is intended to be executed\nafter some designated transaction. As the majority of Ethereum\nminers order transactions by their gas price [179], an agent can set\na higher or lower gas price relative to some target transaction, in\norder to have his transaction executed before or after the target, re-\nspectively. In the case of multiple agents attempting to front-run the\nsame transaction, front-running results in priority gas auctions [46],\ni.e. the competitive bidding of transaction fees to obtain execution\npriority.\n7\nWe refer to attacks which involve front- and/or back-running\nwithin a single block, thereby undermining the technical security\nof DeFi protocols, as transaction ordering attacks. Note that an at-\ntacker does not need to be a miner in order to execute the following\nattacks but such attacks can be undertaken risk-free if the attacker\nis a miner.\nDisplacement Attacks. In a displacement attack, an attacker front-\nruns some target transaction, where the success of the attack does\nnot depend on whether the target transaction is executed after-\nwards [55]. A simple example of such an attack would be an attacker\nfront-running a transaction that registers a domain name [85]. A\nmore severe risk comes in the form of generalized front-runners [139],\nwhich are bots that parse all unconfirmed transactions in the mem-\npool, trying to identify, duplicate, modify and lastly front-run any\ntransaction which would result in a financial profit to the front-\nrunner. Examples of transactions vulnerable to generalized front-\nrunners would be reporting a bug as part of a bug bounty scheme to\nclaim a reward [26] and trying to \u2018rescue\u2019 funds from an exploitable\nsmart contract [139, 143].\nMulti-transaction Sandwich Attacks. In a \u201csandwich attack\", an\nattacker alters the deterministic price on an AMM prior to and after\nsome other target transaction has been executed in order to profit\nfrom temporary imbalances in the AMM\u2019s liquidity reserves. In\nsimple cases (e.g., Uniswap), the instantaneous AMM price is simply\na ratio of AMM reserves and imbalances can be created simply\nby changing this ratio (e.g., by providing single-sided liquidity or\nperforming a large swap through the AMM). This is how these\nAMMs are designed to work: swaps create imbalances, which, if left\nunbalanced, incentivize arbitrageurs to perform the reverse actions\nto balance the AMM pool.\nAn attacker may target another user\u2019s transaction (e.g., to profit\nfrom triggering large slippage in another user\u2019s swap) by trying to\nplace adjacent transactions that set up the imbalance right before\nthe swap and close out the imbalance right after the swap [145, 179].\nThis can be achieved through front-running the user\u2019s swap trans-\naction by setting a higher gas price on the transaction creating the\nimbalance. By setting a lower gas price on the transaction closing\nthe imbalance, the attacker can back-run the user\u2019s transaction and\ncomplete the attack. Note that setting high and low transaction fees\ndoes not guarantee the attack to succeed, as ultimately it is up to a\ntransaction\u2019s miner to determine the order of execution.\nA variant of this attack [179] can be performed if instead of\nbeing a liquidity taker, the attacker is a liquidity provider for the\nrespective AMM. The attacker can front-run a victim transaction\nthat swaps token \ud835\udc34for token \ud835\udc35and remove liquidity, exposing\nthe victim to higher slippage. Subsequently, the attacker can back-\nrun the victim transaction, and resupply the previously withdrawn\nliquidity. In a third transaction that swaps \ud835\udc35for \ud835\udc34, the attacker\nobtains a profit in \ud835\udc35. A formal analysis of sandwich attacks is given\nin [179].\n6\nECONOMIC SECURITY\nWe define a DeFi security risk to be economic if an attacker can\nperform a strictly non-atomic exploit to realize a profit at the ex-\npense of value held by the protocol or its users. In an economic\nexploit, an attacker performs multiple actions at different places in\nProtocol\nLoss\nAudit Attack\nDate\nRef.\nbZx\n0.35m\n\u2713TX sandwich Feb-15-2020\n[65]\nbZx\n0.63m\n\u2713TX sandwich Feb-18-2020\n[11]\nUniswap\n0.30m\n\u2713Reentrancy\nApr-18-2020\n[40]\ndForce\n25.00m\n\u2717Reentrancy\nApr-19-2020\n[64]\nHegic\n0.05m\n\u2717Logical bug\nApr-25-2020 [148]\nBalancer\n0.50m\n\u2713TX sandwich Jun-28-2020\n[1]\nOpyn\n0.37m\n\u2713Logical bug\nAug-04-2020 [114]\nYam\n0.75m\n\u2717Logical bug\nAug-12-2020\n[32]\nbZx\n8.10m\n\u2713Logical bug\nSep-14-2020\n[10]\nEminence\n15.00m\n\u2717TX sandwich Sep-29-2020\n[74]\nMakerDAO\n-\n\u2713Governance\nOct-26-2020 [102]\nHarvest\n33.80m\n\u2713TX sandwich Oct-26-2020\n[75]\nPercent\n0.97m\n\u2713Logical bug\nNov-04-2020 [119]\nCheese Bank\n3.3m\n\u2713TX sandwich Nov-06-2020 [126]\nAkropolis\n2.00m\n\u2713Reentrancy\nNov-12-2020 [166]\nValue DeFi\n7.00m\n\u2717TX sandwich Nov-14-2020 [118]\nOrigin\n7.00m\n\u2713Reentrancy\nNov-17-2020 [101]\n88mph\n0.01m\n\u2713Logical bug\nNov-17-2020 [116]\nPickle\n19.70m\n\u2717Logical bug\nNov-21-2020 [149]\nCompounder\n10.80m\n\u2713Logical bug\nDec-02-2020\n[63]\nWarp Finance\n7.80m\n\u2713TX sandwich Dec-18-2020 [132]\nCover\n9.40m\n\u2713Logical bug\nDec-28-2020 [138]\nYearn\n11.00m\n\u2717TX sandwich Feb-05-2021 [137]\nGrowth DeFi\n1.30m\n\u2713Logical bug\nFeb-09-2021 [133]\nMeerkat\n32.00m\n\u2717Logical bug\nMar-04-2021 [135]\nPaid Network\n27.00m\n\u2717Logical bug\nMar-05-2021 [136]\nDODO\n2.00m\n\u2717Logical bug\nMar-09-2021 [134]\nCream\n130.00m\n\u2713TX sandwich Oct-27-2021 [170]\nTable 1: An overview of empirical technical security exploits in DeFi\nprotocols for the period February 2020 to March 2021. The included\nexploits are explicitly limited to technical exploits and exclude any\ndeliberate protocol scams that may have occurred. Note that the\namount of funds seized per exploit is denominated in USD as of the\ntime of the exploit and does not account for any losses that may\nhave been recovered.\nthe transaction sequence but doesn\u2019t control what happens between\ntheir actions in the sequence, which means that there is no guaran-\ntee that the final action is profitable (as visualized in Fig 3 and in\ncomparison to the technical exploit in Fig 2). Economic security is\neffectively about an exploiting agent who tries to manipulate a mar-\nket or incentive structure over some time period (even if short, it is\nnot instantaneous). Compared to technical exploits, since economic\nexploits are non-atomic, they come with upfront tangible costs,\na probability of attack failure and risk related to mis-estimating\nthe market response. Thus they are not risk-free and commonly\ninvolve manipulations over many transactions or blocks.\nIn addition to comparing the structures in Figures 2 and 3, we\nprovide a simple example to help illustrate the distinction between\ntechnical and economic security. Consider a protocol that uses an\ninstantaneous AMM price as an oracle. An attacker can perform a\n(atomic) sandwich attack to steal assets, which amounts to a tech-\nnical exploit. If instead the protocol used a time-weighted average\n8\nt = 0\nContract 1\nContract N\n...\nMarket conditions change\nt = i\nContract 1\nContract 2\nContract N\nContract 3\n$$ ?\nFigure 3: Diagram of an economic exploit.\nAMM price as an oracle, then the attacker could manipulate this\nprice over time (non-atomically) and may still be able to steal assets,\nwhich would amount to an economic exploit.\nEconomic risks are inherently a problem of economic design\nand cannot be solved by technical means alone. To illustrate, while\nthese attacks could be performed atomically (and risk-free) in a\nvery poorly constructed system that allowed it, they are not solved,\nfor example, just by adding a time delay that ensures they are not\nexecuted in the same block. Even if all technical issues are sorted,\nwe are often left with remaining economic problems about how\nmarkets or other incentive structures could be manipulated over\ntime to exploit protocols. From a practical perspective, progress on\nthese economic problems inherently requires economic models of\nthese market equilibria and the design of better protocol incentive\nstructures. These models differ considerably from traditional secu-\nrity models and are sparsely studied. As a result, defensive measures\nfor economic security risks are also not as well established.\nIn this way also, technical security must be a first bar: if a protocol\nis not technically secure, then it will break in the presence of rational\nagents. Economic security only makes sense if technical security\nis achieved. For instance, if a protocol\u2019s funds can be exploited\nbecause it is not technically secure, then in an economic sense no\nrational agents should participate.\nEconomic Security\nA DeFi protocol is economically secure if it is economically infeasible\n(e.g., unprofitable) for an attacker to perform exploits that are\nstrictly non-atomic at the expense of value held by the protocol\nor its users. As economic exploits are non-atomic (or else they are\nbetter described as technical), they are not risk-free.\nEconomic Rationality. A central assumption in considering the\nclass of economic security attacks is that of economic rationality.\nFollowing the standard game theoretic approach, we denote the\nstrategy for player \ud835\udc56as \ud835\udc60\ud835\udc56. A strategy is a plan for what to do at\neach decision node (equivalently, information set) that the agent\nis aware they might reach. For example, a strategy would define\nwhat action an agent would take in the event that it finds itself in a\nprotocol that becomes undercollateralized. A strategy \ud835\udc601,\ud835\udc56\u2208\u00a7\ud835\udc56for\nplayer \ud835\udc56strictly dominates another strategy \ud835\udc602,\ud835\udc56\u2208\u00a7\ud835\udc56if regardless\nof the actions of other agents, strategy \ud835\udc601,\ud835\udc56will always result in a\nhigher payoff to the agent. Economic rationality is then defined as\nfollows.\nEconomic Rationality\nAn agent is rational iff they will never play a strictly dominated\nstrategy (i.e., they are profit optimizing).\nMoreover, common knowledge of rationality means that all\nagents know no agent will play a strictly dominated strategy.\nWhile most economic security analysis ought to consider attack-\ners who have profit-maximizing objectives, it can also be important\nto consider attackers with other objectives. For instance, an attacker\nwho wishes to shut down the system may decide to attack as long as\nthe cost is of a moderate level. In this sense, the economic security\ndepends on system interruptions being too costly to effect.\nIncentive Compatibility. Incentive compatibility is originally a\nconcept from game theory (e.g., [141], but as a concept has seen\nsome adaption in the context of cryptoeconomics and in particular\nDeFi.\nIn the cryptoeconomic setting, a mechanism is defined as incen-\ntive compatible if agents are incentivized to execute the mechanism\nas intended (see e.g. [142]).\nCryptoeconomic Incentive Compatibility\nA mechanism (or protocol) is incentive compatible iff agents are\nincentivized to execute the game as intended by the protocol\ndesigner.\nA central question in the context of incentive compatibility, con-\nsidered in [90], is the sustainability of the mechanism implemented\nby a system (i.e., will the incentives arising from the system allow\nthe system to be economically secure and stable long-term). In\n[90], for stablecoins, this is separated into a question of incentive\nsecurity, which is included in our concept of economic security,\nand a question of economic stability, which is a further question of\nwhether an economically secure system actually plays out to the\ndesired equilibrium envisioned by the designers.\nWe primarily focus on the direct security questions in this paper;\nhowever, similar questions to economic stability apply to protocols\nother than stablecoins as well. For instance, when designing syn-\nthetic derivatives built using dynamic portfolios (and implemented\nas AMM pools), a lingering question is how well these designs\ncan replicate the derivative payoffs under extreme conditions. As a\ncomparison, synthetic portfolio insurance in traditional markets\ncan break down when markets move too fast for the strategy to\nrebalance (See Ch. 13 in [78]). AMM pools aim to rebalance over\nmuch shorter timescales, and so may have an advantage here, but\nare also suboptimal in other areas of rebalancing.\n6.1\nOvercollateralization as Security\nCollateralization is one of the primary devices to ensure economic\nsecurity in a protocol. In general, collateral serves as a potential\nrepercussion against misbehaving agents [76] and allows creat-\ning protocols such as stablecoins, loanable funds, or decentralized\ncross-chain protocols. As asset prices evolve over time, these sys-\ntems generally allow automated deleveraging: if an agent\u2019s level\n9\nof collateralization (value of collateral / value of borrowing) falls\nbelow a protocol-defined threshold, an arbitrager in the system can\nreduce the agent\u2019s borrowing exposure in return for a portion of\ntheir collateral at a discounted valuation. This aims to keep the\nsystem fully collateralized.\nOvercollateralization is not without risks, however. For instance,\nas explored in [70, 87], times of financial crisis (wherein there are\npersistent negative shocks to collateral asset prices) can result in\nthin, illiquid markets, in which loans may become undercollateral-\nized despite an automated deleveraging process. In such settings, it\ncan become unprofitable for liquidators, a type of keeper, to initiate\nliquidations. Should this occur, rational agents will leave their debt\nunpaid as that results in a greater payoff.\nAnother form of deleveraging risk arises when the borrowed\nasset has endogenous price effects, for instance when its price is\naffected by other agents\u2019 decisions in the system or when it is ma-\nnipulable. This is the case in non-custodial stablecoins like Dai that\nare based on leverage markets (Dai is created by \u201cborrowing\u201d it\nagainst collateral and similarly must be returned to later release\nthe collateral). As explored in [91, 92], such stablecoins can have\ndeleveraging feedback effects that lead to volatility in the stablecoin\nitself. In regions of instability, the stablecoin will tend to become\nilliquid and appreciate in price (more so as they need to be pur-\nchased for liquidations), which can force speculative agents who\nhave leveraged their positions to pay premium prices to delever-\nage. This causes their collateral to drawdown faster than may be\nexpected, which makes the system in total less healthy and may\nlead to shortfalls in collateralization. This was later directly ob-\nserved in Dai on \u201cBlack Thursday\u201d [66]. As further discussed in\n[92], such a stablecoin requires uncorrelated collateral assets to be\nfully stabilized from such deleveraging effects as stable regions are\nrelated to submartingales (i.e., agents expect collateral asset prices\nto appreciate). However, current uncorrelated assets are primarily\ncentralized/custodial, which poses a challenge for non-custodial\ndesigns.\n6.2\nThreats from Miner Extractable Value\nAn assumption by many blockchain protocols is that the block\nreward is sufficient to incentivize \u201ccorrect\" miner behavior. How-\never, there are consensus layer risks should the MEV exceed the\nblock reward. The simplest example of MEV is double spending\nof coins, which is commonly considered in base layer incentives.\nDeFi applications give rise to many new sources of MEV. For in-\nstance, (1) DEXs present atomic arbitrage opportunities between\ndifferent trading pairs, as explored in [46], and (2) stablecoins built\non leverage markets (like Dai) present arbitrage opportunities in\nliquidating leveraged positions, as explored in [91]. Similarly, other\nprotocols, like PLFs, that utilize liquidation mechanisms also create\nMEV opportunities. Further, MEV can arise when miners are in-\ncentivized to re-order or exclude transactions based on cross-chain\npayments happening on other chains [83].\nThese are not exhaustive; there are additionally many other ways\nin which miners could manipulate DeFi protocols to extract value.\nIt\u2019s worth noting that these are not just hypothetical concerns,\nthey have actually been observed\u2013e.g., [12, 23]\u2013and shown to be\nsufficiently profitable, e.g., [178].\nThe practicality of MEV threats have been highlighted in [46],\nwhere the prevalent dangers of undercutting and time-bandit attacks\nare presented. In an undercutting attack [29], an adversarial miner\nwould fork off a block with high MEV, while holding back some of\nthe extractable value in order to incentivize other miners to direct\ntheir computational efforts towards the adversary\u2019s chain. In a time-\nbandit attack [46], an attacker forks from some previous block and\nsources expected MEV to increase his computational power and\npursue a 51% attack until the expected MEV is realized. Hence,\ntime-bandit attacks are a consensus layer risk and can be a direct\nconsequence of historic on-chain actions which could profit a miner\nat some later point. A further threat is that miners could collude to\nset up more MEV opportunities over time, for instance by censoring\ntransactions to top up collateral in crises and thus creating more\nliquidation events, as discussed in [91]. This is very similar to events\non Black Thursday, in which mempool manipulations contributed\nto inefficient liquidation auctions in Maker [23].\n6.3\nGovernance Risks and Governance\nExtractable Value\nProtocol governance often introduces means to update system pa-\nrameters and even redefine entire contracts. In many cases, this\nmay be a necessary component for the system to evolve over time.\nHowever, governance can also introduce manipulation vectors that\naffect security. Governance of a DeFi protocol is typically tied to\nholders of governance tokens, which can often be thought of as\nshares in the protocol. In systems where there is large flexibility\nfor governance to change the system, an important question is\nwhere governance token value comes from. A typical aim is for\nthe protocol to incentivize good stewardship from its governance\ntoken holders by compensating governance with cashflows from\nthe system. In this case, governance token value is derived from\nfuture discounted cashflows. Another possibility is that governance\nis directly aligned with underlying users\u2013e.g., because they are the\nsame.\nHowever, if these incentives are not of sufficient size, then it may\nbe more profitable for governance token holders to extract value\nin less desirable ways, which we term governance extractable value\n(GEV).4 An example of GEV is for governors to effect changes to\nthe protocol in ways that provide outside benefits to themselves\nbut may be harmful to the overall system health. For instance,\nthe Cream protocol governance added high levels of very risky\ncollateral assets that they had an outside stake in, arguably to their\nbenefit but against the interests of the protocol [129].\nGEV also includes explicit governance attacks. An instance of an\nexplicit attack was the governance takeover of the Build Finance\nDAO, where a malicious actor passed a proposal to take control of\nthe Build token contract and was thereby not only able to drain\nvarious AMM pools by minting and swapping Build tokens, but\nto ultimately remove the DAO from any form of control over the\ncore protocol [60]. A hypothetical GEV attack to indirectly extract\ncollateral value is described in [89]. In cases like these, governance\nmay not be incentive compatible. And if the value of governance\ntokens from incentive compatible sources crashes, the region of\n4GEV may be interpreted as a generalization of MEV with miners being a specific type\nof governor tasked with ordering transactions on the base layer.\n10\nincentive compatibility also shrinks, and it may become profitable\nfor a new coalition of governors to form to attack the protocol.\nThis is increasingly problematic given the ease and low cost with\nwhich governance tokens may be obtained via flash loans and PLFs.\nOther complications arise in the need to protect minority rights\nwithin the protocol\u2013e.g., building in limitations so that a majority\nof governors cannot unilaterally change the game to, for instance,\nsteal all value of the other minority or users. See [96] for further\ndiscussion of GEV.\nThere is limited literature in modeling GEV incentives in the\nDeFi setting (as opposed to modeling governance in the underlying\nblockchain itself). The capital structure-like models developed in\n[79, 90] can be applied more generally to DeFi protocols to model\ngovernance security and incentive compatibility around these is-\nsues. As can be understood in those models, these issues essentially\narise because there may not be outside recourse (e.g., legal) in the\npseudo-anonymous setting to disincentivize attacks and manipula-\ntions compared to the (idealized) traditional finance setup. Further,\n[90] conjectures that in the case of a fully decentralized stablecoin\nwith multiple classes of interested parties and with a high degree of\nflexibility for governance design, there exists no long-term incen-\ntive compatible equilibrium. Intuitively, there are resulting costs of\nanarchy in such systems, which can be too much to bear. In such\na case, rational agents would choose not to participate. However,\nthey also conjecture that other DeFi systems, such as DEXs, may\nhave wider incentive compatibility in similar situations due to the\ndifferent structure of such systems. These models have inspired\nnew mechanisms such as Optimistic Approval [96], which provides\nan optional veto over governance updates to protocol users, as a\nnew defensive measure to to reduce costs of anarchy and GEV.\n6.4\nMarket and Oracle Manipulation\nAs the suppliers of off-chain information, oracles pose a fundamen-\ntal component of DeFi protocols, particularly for sourcing price\nfeeds [84]. However, it is important to distinguish between (1) a\nprice that is manipulated yet correctly supplied by an oracle and\n(2) an oracle itself being manipulated. While we present each form\nof manipulation, note that the latter can be essentially modeled as\na separate governance-type risk as discussed in [90].\nMarket Manipulation. We wish to quantify economic risks stem-\nming from price manipulations in underlying markets while as-\nsuming the oracle follows a best practice implementation and is\nnon-malicious. An adversary may manipulate the market price (on-\nchain or off-chain) of an asset over a certain time period if a profit\ncan be realized as a consequence of the price manipulation\u2013e.g.,\nby taking positions in a DeFi protocol that uses that market price\nas an oracle. As discussed in the Section 5, instantaneous AMM\nprices are easily manipulable with near zero cost and, as a result,\nshould not be used as price oracles. Market manipulation problems\npersist even when we assume the oracle is not an instantaneous\nAMM price. In this case, there is a cost to market manipulation\nrelated to maintaining a market imbalance over time, whether in\nan AMM (e.g., to manipulate a time-weighted average price) or\nthrough filling unfilled orders in an order book. Depending on\nwhether the market for an asset is thick or thin, the cost for an\nattacker to significantly change the asset\u2019s price will be higher or\nlower, respectively. An instance of this form of market manipula-\ntion was seen with Inverse Finance, where a malicious actor first\nmanipulated the used Sushiswap price oracle to quote a higher\nprice for the Inverse token, only to exploit the protocol a block\nlater by borrowing various assets against the Inverse token using\nthe manipulated price before MEV bots arbitraged the manipulated\nprice back [19]. A further example of such an attack would be to\ntrigger liquidations by manipulating an asset\u2019s price, as discussed\nin the context of stablecoins in [91]. An attacker could profit either\nby purchasing liquidated collateral at a discount or shorting the\ncollateral asset by speculating on a liquidation spiral. Such attacks\nare similar to short-squeezes in traditional markets. However, un-\nlike with single transaction sandwich attacks, the aforementioned\nattack is not risk-free and could bring substantial losses to the at-\ntacker should it fail. In particular, markets and agents may react to\nsuch attacks in unpredictable ways.\nTo illustrate the potential of such attacks, the stablecoin DAI,\nwhich historically has thin liquidity, traded at a temporary price of\n$1.30 over a course of about 20 minutes on Coinbase Pro, a major\ncentralized cryptoasset exchange, before returning to its intended\n$1 peg [88]. As a result, the Compound Open Price Feed [37], a\ncryptoasset price oracle which is in part based on prices signed\nby Coinbase, reported a DAI price of $1.23 to Compound for a\nshort period of time. This incident triggered (arguably wrongful)\nliquidations on collateral worth approximately $89m, costing the\nliquidated Compound borrowers 23% (from the imbalanced DAI\nprice) plus an additional 5% (the Compound liquidation incentive,\ni.e., the discount at which collateral is sold at during a liquidation)\non their liquidated assets.\nOracle Manipulation. Centralized oracles serve as a single point\nof failure and despite trusted execution environments [174] they re-\nmain vulnerable to the provider behaving maliciously if incentives\nare sufficient for manipulating the source of a data feed. Decentral-\nized price oracles may use on-chain data, most notably on DEXs\n(specifically AMMs) for crypto-to-crypto price data. However, as\noutlined in Section 5.2, prices may be manipulable through inten-\ntionally created imbalances and thinly traded markets. Furthermore,\non-chain DEX oracles inherently can not price off-chain assets and\nfiat currencies.\nAs discussed in [90], decentralized oracle solutions for off-chain\ndata exist. However, they are yet imperfect solutions, tending to rely\non Schelling point games, in which agents vote on the correct price\nvalues and are incentivized against having their stake slashed if their\nvote deviates from the consensus. Tying incentives to consensus,\nwhen the correctness of the consensus decision is not objectively\nverifiable (as in this case), paves a vector for game theoretic attacks,\nlike in Keynesian beauty contests.\n7\nOPEN RESEARCH CHALLENGES\nThere are many open research challenges in DeFi stemming from\nthe technical and economic security issues presented in Sections 5\nand 6.\n11\n7.1\nComposability Risks\nCryptoassets can be easily and repeatedly tokenized and inter-\nchanged between DeFi protocols in a manner akin to rehypotheca-\ntion. This offers the potential to construct complex, inter-connected\nfinancial systems, yet bears the danger of exposing agents to com-\nposability risks, which are as of yet mostly unquantified. An exam-\nple of composability risk is the use of flash loans for manipulating\ninstantaneous AMMs and financially exploiting protocols that use\nthose AMMs as price feeds. This has repeatedly been exploited in\npast attacks (e.g. [75, 126, 150]). However, the breadth of compos-\nability risks spans far beyond the negative externalities stemming\nfrom instantaneous AMM manipulations. For instance, there re-\nmain open questions about the consequences of the following types\nof exploitations on connecting systems: the accumulation of gov-\nernance tokens to execute malicious protocol updates, the failure\nof non-custodial stablecoin incentives to ensure price stability, and\nfailure of PLF systems to remain solvent. Note, however, that this\nlist is far from exhaustive. These become increasingly important\nissues as more complex token wrapping structures [158] stimulate\nhigher degrees of protocol interconnectedness. For example, the\nuse of PLF deposit tokens (as opposed to the tokens in their original\nforms) within AMM pools and strategies to earn yield on underly-\ning assets through leverage by borrowing non-custodial stablecoins\nand depositing into PLFs or AMMs.\nRecent works [72, 108] begin to explore protocol interdepen-\ndence, while [152] propose a process-algebraic technique that al-\nlows for property verification by modeling DeFi protocols in a\ncompositional manner. Nonetheless, a critical gap in DeFi research\ntoward taxonimizing and formalizing models to quantify compos-\nability risks remains. This problem is elevated as a holistic view\non the integrated protocols is necessary: failures might arise from\nboth technical and economic risks. Ensuring safety of protocol com-\nposition will be close to impossible for any protocol designer and\nforms a major challenge for DeFi going forward.\n7.2\nGovernance\nWe identify important research directions in governance and GEV.\nA general direction is modeling incentive compatibility of gover-\nnance in various systems with GEV. For instance, setting up models,\nfinding equilibria, and understanding how other agents in the sys-\ntem respond. The models in [90] get this started in the context of\nstablecoins and additionally discuss how to extend to other DeFi\nprotocols. There is moreover a range of discussions around sim-\nulating and formalizing governance incentives through tools like\ncadCAD [112].\nThere remain unanswered questions with regards to the general\ndesign of governance incentives. For instance, how to structure\ngovernance incentives to reward good stewardship: e.g., intrinsic\nvs. monetary reward, reward per vote vs. reward per token holder,\nand measures of good stewardship. Furthermore, there lies potential\nin formally evaluating protection of minority agents in systems\nwith flexible governance and large GEV.\nFor systems utilizing governance tokens, we identify research\ngaps rooted in security risks of the ability to borrow governance to-\nkens via flash loans and PLFs. Specifically, we identify opportunities\nto formally explore how (1) technical security can be compromised\nand (2) from an economic security point of view, incentive com-\npatibility is further complicated by the borrowing of governance\ntokens.\n7.3\nOracles\nWe highlight a few open challenges about oracle design and security.\nNote that, in many cases, the oracle problem can also be directly\nrelated to the governance problem, as governors are often tasked\nwith choosing the oracles that are used.\nA more general open challenge lies in how to structure oracle\nincentives to maintain incentive compatibility to report correct\nprices. This is similar to governance design in some ways and needs\nto take into account the possible game theoretic manipulations that\ncould be profitable.\nWe identify a further research opportunity in designing and eval-\nuating the security of various oracle strengthening methods. While\nthere exist several works examining oracle designs on both a gen-\neral and empirical basis\u2013e.g. [84, 100]\u2013 a formal security analysis\nof, e.g., medianizers, reputation systems, and grounding reported\nprices based on on-chain verifiable metrics is yet to be done.\n7.4\nMiner Extractable Value\nWhile research on MEV and the extraction of it is being put for-\nward [46], methodologies to quantify negative externalities of MEV\u2013\ne.g., from wasted gas per block, upward gas price pressure\u2013and\nthe full extent of MEV opportunities remain scarce. For the latter,\nwe conjecture that the miner\u2019s problem to optimize the MEV they\nextract in a block is NP-hard and additionally hard to approximate.\nTo support this, it is quite easy to reduce a simplified version of\nthe problem, in which the MEV of each transaction is fixed, to the\nknapsack problem. Note that while the knapsack problem is NP-\nhard, it is easy to approximate. In fact, we expect a more realistic\nversion of the miner\u2019s problem to be harder than knapsack because\nthe transaction ordering the miner chooses also changes the MEV\nof the transactions (i.e., swapping two elements might change their\nweight in knapsack).\nWith regards to quantifying extractable value, [9] introduce\nClockwork Finance Framework, a novel framework that applies\nformal verification to reason about DeFi security properties with\nrespect to the profit that is extractable by an actor in a given system.\nIt should be noted that the definition of economic security as defined\nin [9] would be closer to what we refer to as technical security or\natomic MEV and that modeling non-atomic MEV requires economic\nmodels of the underlying markets, as discussed in Section 6.\nThere are interesting questions regarding how the emergence of\nMEV opportunities endogenously affects agents\u2019 behavior within\nDeFi protocols. Models for this are started in the context of stable-\ncoins in [90].\nA further open challenge remains with respect to designing pro-\ntective mechanisms against (1) consensus layer instability risks that\nare induced by high MEV incentives and (2) time bandit attacks that\nseek to rewrite the recent transaction history\u2013for example, which\ncould aim to trigger and profit from increased protocol liquidations.\nOn this point, [91] suggests that oracle price validity could be tied\nto recent block hashes to prevent such reorderings from extracting\n12\nthe protocol value, though potentially with costs to the economic\nsecurity of the protocol in other ways.\n7.5\nProgram Analysis\nThere exists a large amount of work [77], both in academia [103,\n124, 155] and industry [39, 58], to analyze smart contract bugs and\nvulnerabilities. While smart contracts analysis tools keep improving,\nthe number and scale of smart contract exploits are showing no\nsign of decrease and are, on the contrary, becoming more frequent.\nAlthough program analysis tools are no silver bullet and cannot\nprevent all exploits, Table 1 and the discussed exploits in Section 5\nand in Appendix B hint that there are some recurring patterns that\ncould be automatically detected and prevented.\nCurrent program analysis tools can mainly be divided into two\ncategories: (1) fully automatic tools checking for program invariants\nand (2) semi-automated verification tools checking for user-defined\nproperties [7, 31, 124]. While the latter allows to verify business\nlogic in ways that are not fully automatable, they are typically\nnon-trivial to setup and require knowledge of software verification,\nwhich limits their use to projects with enough resources. On the\nother hand, fully automatic tools, which can be very easily setup\nand ran, usually focus on checking properties of a single contract in\nisolation [38, 58, 154, 155], such as unchecked exceptions or integer\noverflows. However, they have not evolved yet to embrace the\ncomposable nature of smart contracts, which makes it impossible\nfor such tools to reason about scenarios where the issue happens\ndue to a change in something external to the smart contracts, such as\na sudden change in a price returned by an oracle. Further, most tools\nreason very little about semantic properties of the smart contracts,\nsuch as how a particular execution path can influence ERC-20\ntoken balances. We believe that improvements in these areas will\nallow auditors and developers to analyze and deploy their contracts\nwith more confidence, reducing the number of technical security\nexploits.\n7.6\nAnonymity and Privacy\nThe anonymity and privacy of DeFi protocols is at present a signifi-\ncantly understudied area. There is a tension between user\u2019s privacy\nbeing valuable in itself, while at the same time helping malicious\nusers to escape the consequences of their actions. At present, a\nlarge proportion of DeFi transactions occurs in protocols built on\nEthereum, wherein agents at best have pseudoanonymity. This\nmeans that if an agent\u2019s real-world identity can be linked to an on-\nchain address, all the actions undertaken by the agent through that\naddress are observable. While recent advances in zero-knowledge\nproofs [115, 160] and multi-party computations [18, 128] hold many\npromises, these technologies are yet to gain traction in the context\nof DeFi. One of the main friction points is the large computational\ncost of these technologies, which make them very expensive to use\nand deploy in the context of DeFi. A decrease of computational cost\nof the underlying blockchain will be key to how widely privacy-\npreserving technologies can be deployed by DeFi protocols.\n8\nCONCLUSION\nIn this SoK we have considered DeFi from two points of view, the\nDeFi Optimist and the DeFi Pessimist, and examined the workings\nof DeFi systematically. First, we laid out the primitives for DeFi\nbefore categorizing DeFi protocols by the type of operation they\nprovide. After distinguishing between different types of information\nrelevant to a DeFi protocol, we provided a working definition of\nan exploit. We established economic security on the same level as\ntechnical security and created a novel functional categorization\nof the different types of risk therein. Further, we provided clear\ndefinitions of these risks as well as insights into the types of models\nthat are needed to understand and defend against these risks. Finally,\nwe drew the attention to open research challenges that require a\nholistic understanding of both the technical and economic risks.\nWhile DeFi may have the potential to creating a permissionless\nand non-custodial financial system, the opinion put forward by the\nDeFi optimist, the open technical and economic security challenges\nremain strong. The DeFi pessimist is, at least for now, on firm\nground: solving these challenges in a robust and scalable way is\na central challenge for researchers and DeFi practitioners. In the\nend, however, it is the blend between promise and challenge \u2014\nthe tension between the views of the DeFi optimist and the DeFi\npessimist \u2014 that makes DeFi a worthwhile and exciting area for\nresearch.\nACKNOWLEDGMENTS\nWe thank the anonymous reviewers for their feedback and sugges-\ntions. This project received partial funding from EPSRC Standard\nResearch Studentship (DTP) (EP/R513052/1), the Ethereum Foun-\ndation, the Brevan Howard Centre for Financial Analysis, Smart\nContract Research Forum, and a Bloomberg Fellowship.\nREFERENCES\n[1] 1inch: Balancer pool with sta deflationary token incident (2020), https://1inch-\nexchange.medium.com/balancer-hack-2020-a8f7131c980e\n[2] AAVE: Aave: Protocol whitepaper v1.0 (2020), https://github.com/aave/aave-\nprotocol/blob/master/docs/Aave_Protocol_Whitepaper_v1_0.pdf, accessed:\n13-08-2020\n[3] Angeris, G., Chitra, T.: Improved price oracles: Constant function market makers.\nProceedings of the 2nd ACM Conference on Advances in Financial Technologies\n(2020)\n[4] Angeris, G., Evans, A., Chitra, T.: When does the tail wag the dog? Curvature\nand market making. arXiv preprint arXiv:2012.08040 (2020)\n[5] Angeris, G., Evans, A., Chitra, T.: Replicating market makers. arXiv preprint\narXiv:2103.14769 (2021)\n[6] Angeris, G., Kao, H.T., Chiang, R., Noyes, C., Chitra, T.: An analysis of uniswap\nmarkets. Cryptoeconomic Systems Journal (2019)\n[7] Annenkov, D., Spitters, B.: Towards a smart contract verification framework in\ncoq. arXiv preprint arXiv:1907.10674 (2019)\n[8] Atzei, N., Bartoletti, M., Cimoli, T.: A survey of attacks on ethereum smart\ncontracts (sok). In: International conference on principles of security and trust.\npp. 164\u2013186. Springer (2017)\n[9] Babel, K., Daian, P., Kelkar, M., Juels, A.: Clockwork finance: Automated analysis\nof economic security in smart contracts. arXiv preprint arXiv:2109.04347 (2021)\n[10] Baker, P.: Defi lender bzx loses $8m in third attack this year. CoinDesk (2020),\nhttps://www.coindesk.com/defi-lender-bzx-third-attack\n[11] Baker, P.: Defi project bzx exploited for second time in a week, loses $630k in\nether. CoinDesk (2020), https://www.coindesk.com/defi-project-bzx-exploited-\nfor-second-time-in-a-week-loses-630k-in-ether\n[12] Baker, P.: Miners trick stablecoin protocol pegnet, turning 11 into almost 7m\nhoard. CoinDesk (2020), https://www.coindesk.com/miners-trick-stablecoin-\nprotocol-pegnet-turning-11-into-almost-7m-hoard\n[13] Balancer Labs: BAL \u2013 balancer governance token (2020), https://docs.balancer.\nfinance/protocol/bal-balancer-governance-token, accessed: 20-08-2020.\n[14] Bano, S., Sonnino, A., Al-Bassam, M., Azouvi, S., McCorry, P., Meiklejohn, S.,\nDanezis, G.: Sok: Consensus in the age of blockchains. In: Proceedings of the 1st\nACM Conference on Advances in Financial Technologies. pp. 183\u2013198 (2019)\n[15] Bartoletti, M., Chiang, J.H.y., Lluch-Lafuente, A.: Sok: Lending pools in decen-\ntralized finance. arXiv preprint arXiv:2012.13230 (2020)\n13\n[16] Beck, R., M\u00fcller-Bloch, C., King, J.L.: Governance in the blockchain economy:\nA framework and research agenda. Journal of the Association for Information\nSystems 19(10), 1 (2018)\n[17] Bene\u0161, N.: Introducing the dutchx (2017), https://blog.gnosis.pm/introducing-\nthe-gnosis-dutch-exchange-53bd3d51f9b2\n[18] Benhamouda, F., Halevi, S., Halevi, T.: Supporting private data on hyperledger\nfabric with secure multiparty computation. IBM Journal of Research and Devel-\nopment 63(2/3), 3\u20131 (2019)\n[19] bertcmiller: Tweet (2 April 2022), https://twitter.com/bertcmiller/status/1510249\n220967739398?t=Cf2PvmdsWyraKHNqOzYhwQ&s=19\n[20] Biais, B., Bisiere, C., Bouvard, M., Casamatta, C.: The blockchain folk theorem.\nThe Review of Financial Studies 32(5), 1662\u20131715 (2019)\n[21] Bitcoin, W.: Wbtc wrapped bitcoin an erc20 token backed 1:1 with bitcoin (2020),\nhttps://wbtc.network/\n[22] BitMEX: Bitmex perpetual contracts guide (2020), https://www.bitmex.com/app\n/perpetualContractsGuide\n[23] Blocknative: Evidence of mempool manipulation on black thursday: Ham-\nmerbots, mempool compression, and spontaneous stuck transactions (2020),\nhttps://www.blocknative.com/blog/mempool-forensics\n[24] Bloomberg: How $60 Billion in Terra Coins Went Up in Algorithmic Smoke.\nhttps://www.bloomberg.com/graphics/2022-crypto-luna-terra-stablecoin-\nexplainer/ (20 May 2022)\n[25] Bonneau, J., Miller, A., Clark, J., Narayanan, A., Kroll, J.A., Felten, E.W.: Sok:\nResearch perspectives and challenges for bitcoin and cryptocurrencies. In: 2015\nIEEE symposium on security and privacy. pp. 104\u2013121. IEEE (2015)\n[26] Breidenbach, L., Daian, P., Tram\u00e8r, F., Juels, A.: Enter the hydra: Towards prin-\ncipled bug bounties and exploit-resistant smart contracts. In: 27th {USENIX}\nSecurity Symposium ({USENIX} Security 18). pp. 1335\u20131352 (2018)\n[27] Buterin, V.: A next-generation smart contract and decentralized application\nplatform. white paper 3(37) (2014)\n[28] bZx Network: bZx, The most powerful open finance protocol (2020), https:\n//bzx.network/\n[29] Carlsten, M., Kalodner, H., Weinberg, S.M., Narayanan, A.: On the instability\nof bitcoin without the block reward. In: Proceedings of the 2016 ACM SIGSAC\nConference on Computer and Communications Security. pp. 154\u2013167 (2016)\n[30] CertiK: Yam finance smart contract bug analysis & future prevention (2020),\nhttps://certik.io/blog/technology/yam-finance-smart-contract-bug-analysis-\nfuture-prevention\n[31] Chen, X., Park, D., Ro\u015fu, G.: A language-independent approach to smart contract\nverification. In: International Symposium on Leveraging Applications of Formal\nMethods. pp. 405\u2013413. Springer (2018)\n[32] Claburn, T.: Single-line software bug causes fledgling yam cryptocurrency to\nimplode just two days after launch (2020), https://www.theregister.com/2020/0\n8/13/yam_cryptocurrency_bug_governance/\n[33] Clark, J.: The replicating portfolio of a constant product market. Available at\nSSRN 3550601 (2020)\n[34] Coinbase: Coinbase (2020), https://www.coinbase.com/\n[35] Cointelegraph: Compound liquidator makes $4m as oracles post inflated dai\nprice (2020), https://cointelegraph.com/news/compound-liquidator-makes-4m-\nas-oracles-post-inflated-dai-price\n[36] Compound: Compound finance (2019), https://compound.finance/\n[37] Compound: Open price feed (2020), https://compound.finance/prices, accessed:\n06-12-2020.\n[38] ConsenSys: Mythril (2021), https://github.com/ConsenSys/mythril\n[39] Consensys: Mythx: Smart contract security service for ethereum (2021), https:\n//mythx.io/\n[40] Cooper, T.: imbtc uniswap pool drained for \u223c$300k in eth (2020), https://defirat\ne.com/imbtc-uniswap-hack/, accessed: 20-01-2021.\n[41] Cousaert, S., Xu, J., Matsui, T.: Sok: Yield aggregators in defi. arXiv preprint\narXiv:2105.13891 (2021)\n[42] Cronje, A.: yEARN (2020), https://yearn.finance\n[43] CryptoCompare: Cryptocompare exchange review, march 2022 (2022), https:\n//www.cryptocompare.com/media/40124872/cryptocompare_exchange_revie\nw_2022_03_vf2.pdf\n[44] Curve Finance: Curve.fi (2020), https://www.curve.fi/, accessed: 20-08-2020.\n[45] Dafflon, J., Baylina, J., Shababi, T.: Eip-777: Erc777 token standard (2017), https:\n//eips.ethereum.org/EIPS/eip-777\n[46] Daian, P., Goldfeder, S., Kell, T., Li, Y., Zhao, X., Bentov, I., Breidenbach, L.,\nJuels, A.: Flash boys 2.0: Frontrunning, transaction reordering, and consensus\ninstability in decentralized exchanges. arXiv preprint arXiv:1904.05234 (2019)\n[47] DeFi Pulse: What is defi? (2019), https://defipulse.com/blog/what-is-defi/\n[48] DeFi Pulse: The decentralized finance leaderboard at defi pulse (2020), https:\n//defipulse.com/\n[49] Defiant: Iron Finance Implodes After \u2018Bank Run\u2019. https://thedefiant.io/iron-\nfinance-implodes-after-bank-run (17 June 2021)\n[50] Defiant, T.: Bsc\u2019s venus protocol left with bad debt after liquidations (May 20,\n2021), https://thedefiant.io/bscs-venus-protocol-left-with-bad-debt-after-\nliquidations/\n[51] dForce: dforce (2020), https://dforce.network/\n[52] Dubovitskaya, A., Ackerer, D., Xu, J.: A game-theoretic analysis of cross-ledger\nswaps with packetized payments (2021)\n[53] dYdX: dydx (2019), https://dydx.exchange/\n[54] Egorov, M.: Stableswap - efficient mechanism for stablecoin liquidity (2019),\nhttps://www.curve.fi/stableswap-paper.pdf\n[55] Eskandari, S., Moosavi, S., Clark, J.: Sok: Transparent dishonesty: front-running\nattacks on blockchain. In: International Conference on Financial Cryptography\nand Data Security. pp. 170\u2013189. Springer (2019)\n[56] ETH Tx Decoder: Transaction analysis (2020), https://ethtx.info/mainnet/0x9d0\n93325272701d63fdafb0af2d89c7e23eaf18be1a51c580d9bce89987a2dc1, accessed:\n13-01-2021.\n[57] Evans, A.: Liquidity provider returns in geometric mean markets. arXiv preprint\narXiv:2006.08806 (2020)\n[58] Feist, J.: Slither \u2013 a solidity static analysis framework (2018), https://blog.trailof\nbits.com/2018/10/19/slither-a-solidity-static-analysis-framework/\n[59] Feng, F., Weickmann, B.: Set: A protocol for baskets of tokenized assets (2019),\nhttps://www.setprotocol.com/pdf/set_protocol_whitepaper.pdf\n[60] Finance, B.: Tweet (14 February 2022), https://twitter.com/finance_build/status/\n1493223330685591558\n[61] Flashbots: Flashbots Docs: Understanding Bundles. https://docs.flashbots.net/f\nlashbots-auction/searchers/advanced/understanding-bundles (2022)\n[62] Foundation, E.: Solidity v0.8.0 documentation (2020), https://docs.soliditylang.\norg/en/v0.8.0/index.html, accessed: 12-01-2020.\n[63] Foxley, W.: $10.8m stolen, developers implicated in alleged smart contract \u2018rug\npull\u2019. CoinDesk (2020), https://www.coindesk.com/compounder-developers-\nimplicated-alleged-smart-contract-rug-pull\n[64] Foxley, W., De, N.: Weekend attack drains decentralized protocol dforce of $25m\nin crypto. CoinDesk (2020), https://www.coindesk.com/attacker-drains-\ndecentralized-protocol-dforce-of-25m-in-weekend-attack\n[65] Foxley, W.: Exploit during ethdenver reveals experimental nature of decentral-\nized finance. CoinDesk (2020), https://www.coindesk.com/exploit-during-\nethdenver-reveals-experimental-nature-of-decentralized-finance\n[66] Frangella, E.: Crypto black thursday: The good, the bad, and the ugly. https:\n//medium.com/aave/crypto-black-thursday-the-good-the-bad-and-the-ugly-\n7f2acebf2b83 (2020), accessed: 20-01-2021.\n[67] Gnosis: API3 IDO incident - post mortem (2020), https://hackmd.io/@n6YCqow\nrQduQ5u25wSoRXw/Hylnk7SjD\n[68] Gnosis: Introduction to gnosis protocol (2020), https://docs.gnosis.io/protocol/\ndocs/introduction1/\n[69] Godbole, O.: Defi flippening comes to exchanges as uniswap topples coinbase in\ntrading volume. CoinDesk (2020), https://www.coindesk.com/defi-flippening-\nuniswap-topples-coinbase-trading-volume\n[70] Gudgeon, L., Perez, D., Harz, D., Livshits, B., Gervais, A.: The decentralized\nfinancial crisis. In: 2020 Crypto Valley Conference on Blockchain Technology\n(CVCBT). pp. 1\u201315 (2020)\n[71] Gudgeon, L., Moreno-Sanchez, P., Roos, S., McCorry, P., Gervais, A.: Sok: Off\nthe chain transactions. IACR Cryptol. ePrint Arch. 2019, 360 (2019)\n[72] Gudgeon, L., Werner, S.M., Perez, D., Knottenbelt, W.J.: Defi protocols for loan-\nable funds: Interest rates, liquidity and market efficiency. In: Proceedings of the\n2nd ACM Conference on Advances in Financial Technologies. p. 92\u2013112 (2020)\n[73] Hanson, R.: Combinatorial information market design. Information Systems\nFrontiers 5(1), 107\u2013119 (2003)\n[74] Harper, C.: Defi degens hit hard by eminence exploit will be partially compen-\nsated. CoinDesk (2020), https://www.coindesk.com/eminence-exploit-defi-\ncompensated\n[75] Harvest Finance: Harvest flashloan economic attack post-mortem (2020), https:\n//medium.com/harvest-finance/harvest-flashloan-economic-attack-post-\nmortem-3cf900d65217, accessed: 29-12-2020.\n[76] Harz, D., Gudgeon, L., Gervais, A., Knottenbelt, W.J.: Balance: Dynamic adjust-\nment of cryptocurrency deposits. In: Proceedings of the 2019 ACM SIGSAC\nConference on Computer and Communications Security. pp. 1485\u20131502 (2019)\n[77] Harz, D., Knottenbelt, W.: Towards safer smart contracts: A survey of languages\nand verification methods. arXiv preprint arXiv:1809.09805 (2018)\n[78] Hull, J., et al.: Options, futures and other derivatives/John C. Hull. Upper Saddle\nRiver, NJ: Prentice Hall, (2009)\n[79] Huo, L., Klages-Mundt, A., Minca, A., Munter, F., Wind, M.: Decentralized Gov-\nernance of Stablecoins with Closed Form Valuation. In Mathematical Research\nfor Blockchain Economy. https://arxiv.org/abs/2109.08939 (2022)\n[80] IDEX: Idex 2.0: The next generation ofnon-custodial trading. URL:\nhttps://idex.io/document/IDEX-2-0-Whitepaper-2019-10-31.pdf (2019)\n[81] Index: Index: A comprehensive list of decentralized exchanges (dex)., https:\n//distribuyed.github.io/index/\n[82] Jones, S.P., Eber, J.M., Seward, J.: Composing contracts: an adventure in financial\nengineering. ACM SIG-PLAN Notices 35(9), 280\u2013292 (2000)\n[83] Judmayer, A., Stifter, N., Zamyatin, A., Tsabary, I., Eyal, I., Gazi, P., Meiklejohn, S.,\nWeippl, E.: Pay to win: Cheap, crowdfundable, cross-chain algorithmic incentive\nmanipulation attacks on pow cryptocurrencies. Cryptology ePrint Archive,\n14\nReport 2019/775 (2019), https://eprint.iacr.org/2019/775\n[84] Kaleem, M., Shi, W.: Demystifying pythia: A survey of chainlink oracles usage\non ethereum. arXiv preprint arXiv:2101.06781 (2021)\n[85] Kalodner, H.A., Carlsten, M., Ellenbogen, P., Bonneau, J., Narayanan, A.: An\nempirical study of namecoin and lessons for decentralized namespace design.\nIn: WEIS. Citeseer (2015)\n[86] Kalra, S., Goel, S., Dhawan, M., Sharma, S.: ZEUS: analyzing safety of smart\ncontracts. In: 25th Annual Network and Distributed System Security Symposium,\nNDSS 2018, San Diego, California, USA, February 18-21, 2018. The Internet\nSociety (2018), http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25\n/2018/02/ndss2018_09-1_Kalra_paper.pdf\n[87] Kao, H.T., Chitra, T., Chiang, R., Morrow, J.: An analysis of the market risk to\nparticipants in the compound protocol. In: Third International Symposium on\nFoundations and Applications of Blockchains (2020)\n[88] Khatri, Y.: Dai price increase led to a massive $88 million worth of liquidations\nat defi protocol compound (2020), https://www.theblockcrypto.com/post/85850/\ndai-compound-dydx-liquidations-defi, accessed: 14-01-2021.\n[89] Klages-Mundt, A.: Vulnerabilities in maker: oracle-governance attacks, attack\ndaos, and (de)centralization (Nov 14, 2019), https://link.medium.com/VZG64f\nhmr6\n[90] Klages-Mundt, A., Harz, D., Gudgeon, L., Liu, J.Y., Minca, A.: Stablecoins 2.0:\nEconomic foundations and risk-based models. In: Proceedings of the 2nd ACM\nConference on Advances in Financial Technologies. pp. 59\u201379 (2020)\n[91] Klages-Mundt, A., Minca, A.: (in) stability for the blockchain: Deleveraging\nspirals and stablecoin attacks. Cryptoeconomic Systems (2021)\n[92] Klages-Mundt, A., Minca, A.: While stability lasts: A stochastic model of non-\ncustodial stablecoins. Mathematical Finance (2022)\n[93] Koeppelmann, M.: Tweet (18 July 2020), https://twitter.com/koeppelmann/stat\nus/1284502534208528385\n[94] Lee, B.E., Moroz, D.J., Parkes, D.C.: The political economy of blockchain gover-\nnance. Available at SSRN 3537314 (2020)\n[95] Lee, J.: Nubits (2014), https://nubits.com/NuWhitepaper.pdf\n[96] Lee, L., Klages-Mundt, A.: Governance extractable value (Apr 23, 2021), https:\n//ournetwork.substack.com/p/our-network-deep-dive-2\n[97] Leshner, R., Hayes, G.: Compound: The money market protocol (2019), https:\n//compound.finance/documents/Compound.Whitepaper.pdf\n[98] Limited, T.: Tether: Fiat currencies on the bitcoin blockchain (2016), https:\n//tether.to/wp-content/uploads/2016/06/TetherWhitePaper.pdf, accessed:\n08-06-2020\n[99] Lin, L.X., Budish, E., Cong, L.W., He, Z., Bergquist, J.H., Panesir, M.S., Kelly, J.,\nLauer, M., Prinster, R., Zhang, S., et al.: Deconstructing decentralized exchanges.\nStanford Journal of Blockchain Law & Policy (2019)\n[100] Liu, B., Szalachowski, P.: A first look into defi oracles (2020)\n[101] Liu, M.: Urgent: Ousd was hacked and there has been a loss of funds (2020),\nhttps://medium.com/originprotocol/urgent-ousd-has-hacked-and-there-has-\nbeen-a-loss-of-funds-7b8c4a7d534c, accessed: 29-12-2020.\n[102] LongForWisdom: [urgent] flash loans and securing the maker protocol (2020),\nhttps://forum.makerdao.com/t/urgent-flash-loans-and-securing-the-maker-\nprotocol/490\n[103] Luu, L., Chu, D.H., Olickel, H., Saxena, P., Hobor, A.: Making smart contracts\nsmarter. In: Proceedings of the 2016 ACM SIGSAC conference on computer and\ncommunications security. pp. 254\u2013269 (2016)\n[104] Maker: The maker protocol: Makerdao\u2019s multi-collateral dai (mcd) system, https:\n//makerdao.com/en/whitepaper/, accessed: 08-06-2020\n[105] MakerDAO: Makerdao (2019), https://makerdao.com/en/\n[106] Martinelli, F., Mushegian, N.: Balancer whitepaper: A non-custodial portfolio\nmanager, liquidity provider, and price sensor. (2019), https://balancer.finance/w\nhitepaper/, accessed: 26-08-2020.\n[107] McCorry, P., Hicks, A., Meiklejohn, S.: Smart contracts for bribing miners. In:\nInternational Conference on Financial Cryptography and Data Security. pp.\n3\u201318. Springer (2018)\n[108] Nadler, M., Sch\u00e4r, F.: Decentralized finance, centralized ownership? an itera-\ntive mapping process to measure protocol token distribution. arXiv preprint\narXiv:2012.09306 (2020)\n[109] Nakamoto, S.: Bitcoin: A peer-to-peer electronic cash system (2008)\n[110] Narayanan, A., Bonneau, J., Felten, E., Miller, A., Goldfeder, S.: Bitcoin and cryp-\ntocurrency technologies: a comprehensive introduction. Princeton University\nPress (2016)\n[111] Niemerg, A., Robinson, D., Livnev, L.: Yieldspace. https://yield.is/YieldSpace.pdf\n(2020)\n[112] OpenCollective: cadcad (2020), https://cadcad.org/\n[113] Opyn: Opyn (2020), https://opyn.co/#/\n[114] opyn: Opyn eth put exploit (2020), https://medium.com/opyn/opyn-eth-put-\nexploit-c5565c528ad2\n[115] Panja, S., Roy, B.K.: A secure end-to-end verifiable e-voting system using zero\nknowledge based blockchain. IACR Cryptol. ePrint Arch. 2018, 466 (2018)\n[116] PeckShield: 88mph incident: Root cause analysis (2020), https://peckshield.med\nium.com/88mph-incident-root-cause-analysis-ce477e00a74d\n[117] PeckShield: bzx hack full disclosure (with detailed profit analysis) (2020), https:\n//medium.com/@peckshield/bzx-hack-full-disclosure-with-detailed-profit-\nanalysis-e6b1fa9b18fc\n[118] Peckshield: Value defi incident: Root cause analysis (2020), https://peckshield.m\nedium.com/value-defi-incident-root-cause-analysis-fbab71faf373, accessed:\n13-01-2021.\n[119] Percent Finance: Important announcement (2020), https://percent-finance.med\nium.com/important-announcement-d35f9a0df112\n[120] Perez, D., Livshits, B.: Smart contract vulnerabilities: Does anyone care? arXiv\npreprint arXiv:1902.06710 (2019)\n[121] Perez, D., Livshits, B.: Broken metre: Attacking resource metering in EVM. In:\n27th Annual Network and Distributed System Security Symposium, NDSS 2020,\nSan Diego, California, USA, February 23-26, 2020. The Internet Society (2020),\nhttps://www.ndss-symposium.org/ndss-paper/broken-metre-attacking-\nresource-metering-in-evm/\n[122] Perez, D., Werner, S.M., Xu, J., Livshits, B.: Liquidations: Defi on a knife-edge.\narXiv preprint arXiv:2009.13235 (2020)\n[123] Perez, D., Xu, J., Livshits, B.: Revisiting transactional statistics of high-scalability\nblockchains. p. 535\u2013550. IMC \u201920, Association for Computing Machinery, New\nYork, NY, USA (2020). https://doi.org/10.1145/3419394.3423628, https://doi.org/\n10.1145/3419394.3423628\n[124] Permenev, A., Dimitrov, D., Tsankov, P., Drachsler-Cohen, D., Vechev, M.: Verx:\nSafety verification of smart contracts. In: 2020 IEEE Symposium on Security\nand Privacy, SP. pp. 18\u201320 (2020)\n[125] Peterson, J., Krug, J.: Augur: a decentralized, open-source platform for prediction\nmarkets. arXiv preprint arXiv:1501.01042 (2015)\n[126] Pirus, B.: Cheese bank\u2019s multi-million-dollar hack explained by security firm\n(2020), https://cointelegraph.com/news/cheese-bank-s-multi-million-dollar-\nhack-explained-by-security-firm, accessed: 29-12-2020.\n[127] Qin, K., Zhou, L., Livshits, B., Gervais, A.: Attacking the defi ecosystem with\nflash loans for fun and profit (2020)\n[128] Raman, R.K., Vaculin, R., Hind, M., Remy, S.L., Pissadaki, E.K., Bore, N.K.,\nDaneshvar, R., Srivastava, B., Varshney, K.R.: Trusted multi-party computa-\ntion and verifiable simulations: A scalable blockchain approach. arXiv preprint\narXiv:1809.08438 (2018)\n[129] Rate, D.: Cream finance partially delists ftt amidst governance contention (2021),\nhttps://defirate.com/cream-ftt-delisting/\n[130] Reijers, W., O\u2019Brolch\u00e1in, F., Haynes, P.: Governance in blockchain technologies\n& social contract theories. Ledger 1, 134\u2013151 (2016)\n[131] Rekt: Harvest finance - rekt (2020), https://rekt.ghost.io/harvest-finance-rekt/\n[132] Rekt: Warp finance - rekt (2020), https://rekt.eth.link/warp-finance-rekt/\n[133] Rekt: The big combo (growth defi - rekt) (2021), https://rekt.eth.link/the-big-\ncombo/\n[134] Rekt: Dodo - rekt (2021), https://rekt.eth.link/au-dodo-rekt/\n[135] Rekt: Meerkat finance - bsc - rekt (2021), https://rekt.eth.link/meerkat-finance-\nbsc-rekt/\n[136] Rekt: Paid network - rekt (2021), https://rekt.eth.link/paid-rekt/\n[137] Rekt: Yearn - rekt (2021), https://rekt.eth.link/yearn-rekt/\n[138] Reynolds, K., Pan, D.: Cover protocol attack perpetrated by \u2018white hat,\u2019 funds\nreturned, hacker claims. CoinDesk (2020), https://www.coindesk.com/cover-\nprotocol-attack-perpetrated-by-white-hat-all-funds-returned-hacker-claims\n[139] Robinson, D.: Etherum is a dark forest (2020), https://medium.com/@danrobins\non/ethereum-is-a-dark-forest-ecc5f0505dff, accessed: 24-11-2020.\n[140] Rodler, M., Li, W., Karame, G.O., Davi, L.: Sereum: Protecting existing smart\ncontracts against re-entrancy attacks. In: Proceedings of 26th Annual Network\n& Distributed System Security Symposium (NDSS) (February 2019), http://tubi\nblio.ulb.tu-darmstadt.de/111410/\n[141] Roughgarden, T.: Algorithmic game theory. Communications of the ACM 53(7),\n78\u201386 (2010)\n[142] Roughgarden, T.: Transaction fee mechanism design for the ethereum\nblockchain: An economic analysis of eip-1559. arXiv preprint arXiv:2012.00854\n(2020)\n[143] samczsun: Escaping the dark forest (2020), https://samczsun.com/escaping-the-\ndark-forest, accessed: 24-11-2020.\n[144] Sch\u00e4r, F.: Decentralized finance: On blockchain-and smart contract-based finan-\ncial markets. FRB of St. Louis Review (2021)\n[145] Swende, M.: Blockchain frontrunning (2017), https://swende.se/blog/Frontrunn\ning.html\n[146] Synthetix: Litepaper (2020), https://docs.synthetix.io/litepaper/, accessed:\n06-12-2020\n[147] Synthetix: Synthetix | decentralised synthetic assets (2020), https://www.synthe\ntix.io\n[148] Tarasov, A.: Millions lost: The top 19 defi cryptocurrency hacks of 2020 (2020),\nhttps://cryptobriefing.com/50-million-lost-the-top-19-defi-cryptocurrency-\nhacks-2020/\n[149] Thompson, P.: Defi project pickle finance exploited for $20 million (2020), https:\n//coingeek.com/defi-project-pickle-finance-exploited-for-20-million/\n15\n[150] Thurman, A.: Value defi protocol suffers $6 million flash loan exploit (2020),\nhttps://cointelegraph.com/news/value-defi-protocol-suffers-6-million-flash-\nloan-exploit, accessed: 29-12-2020.\n[151] Tokenlon: imbtc (2020), https://tokenlon.im/imBTC#/\n[152] Tolmach, P., Li, Y., Lin, S.W., Liu, Y.: Formal analysis of composable defi protocols.\narXiv preprint arXiv:2103.00540 (2021)\n[153] Tornado: Tornado (2021), https://tornado.cash/\n[154] Torres, C.F., Sch\u00fctte, J., State, R.: Osiris: Hunting for integer bugs in ethereum\nsmart contracts. In: Proceedings of the 34th Annual Computer Security Ap-\nplications Conference. p. 664\u2013676. ACSAC \u201918, Association for Computing\nMachinery, New York, NY, USA (2018). https://doi.org/10.1145/3274694.3274737,\nhttps://doi.org/10.1145/3274694.3274737\n[155] Tsankov, P., Dan, A., Drachsler-Cohen, D., Gervais, A., Buenzli, F., Vechev, M.:\nSecurify: Practical security analysis of smart contracts. In: Proceedings of the\n2018 ACM SIGSAC Conference on Computer and Communications Security. pp.\n67\u201382 (2018)\n[156] Uniswap: Uniswap (2020), https://app.uniswap.org/#/swap\n[157] Uniswap: Uniswap whitepaper (2020), https://hackmd.io/@HaydenAdams/HJ9\njLsfTz#%F0%9F%A6%84-Uniswap-Whitepaper, accessed: 26-08-2020.\n[158] von Wachter, V., Jensen, J.R., Ross, O.: Measuring asset composability as a proxy\nfor ecosystem integration. arXiv preprint arXiv:2102.04227 (2021)\n[159] Wallet, W.: Wasabi wallet (2021), https://wasabiwallet.io/\n[160] Wang, Y., Kogan, A.: Designing confidentiality-preserving blockchain-based\ntransaction processing systems. International Journal of Accounting Information\nSystems 30, 1\u201318 (2018)\n[161] Warren, W., Bandeali, A.: 0x: An open protocol for decentralized exchange on\nthe ethereum blockchain. URL: https://github.com/0xProject/whitepaper (2017)\n[162] Werner, S.M., Pritz, P.J., Perez, D.: Step on the gas? A better approach for rec-\nommending the ethereum gas price. arXiv preprint arXiv:2003.03479 (2020)\n[163] Wintermute, M.: Hegic: On-chain options trading protocol on ethereum powered\nby hedge contracts and liquidity pools (2020), https://ipfs.io/ipfs/QmWy8x6vE\nunH4gD2gWT4Bt4bBwWX2KAEUov46tCLvMRcME, accessed: 13-11-2020.\n[164] Winzer, F., Herd, B., Faust, S.: Temporary censorship attacks in the presence of\nrational miners. In: 2019 IEEE European Symposium on Security and Privacy\nWorkshops (EuroS&PW). pp. 357\u2013366. IEEE (2019)\n[165] Wood, G., et al.: Ethereum: A secure decentralised generalised transaction ledger.\nEthereum project yellow paper 151(2014), 1\u201332 (2014)\n[166] Wright, T.: Akropolis defi protocol \u2018paused\u2019 as hackers get away with $2m in\ndai (2020), https://cointelegraph.com/news/akropolis-defi-protocol-paused-as-\nhackers-get-away-with-2m-in-dai, accessed: 29-12-2020.\n[167] Xu, J., Ackerer, D., Dubovitskaya, A.: A game-theoretic analysis of cross-chain\natomic swaps with htlcs (2020)\n[168] YAM: Yam finance (2020), https://yam.finance/\n[169] YAM Finance: Yam post-rescue attempt update (2020), https://medium.com/@y\namfinance/yam-post-rescue-attempt-update-c9c90c05953f\n[170] yearn: Incident disclosure 2021-10-27. https://github.com/yearn/yearn-security\n/blob/master/disclosures/2021-10-27.md (Oct 27, 2021)\n[171] Zamyatin, A., Al-Bassam, M., Zindros, D., Kokoris-Kogias, E., Moreno-Sanchez,\nP., Kiayias, A., Knottenbelt, W.J.: Sok: communication across distributed ledgers.\nIACR Cryptol. ePrint Arch. (2020)\n[172] Zamyatin, A., Harz, D., Lind, J., Panayiotou, P., Gervais, A., Knottenbelt, W.:\nXclaim: Trustless, interoperable, cryptocurrency-backed assets. In: 2019 IEEE\nSymposium on Security and Privacy (SP). pp. 193\u2013210. IEEE (2019)\n[173] Zcash: Zcash (2021), https://z.cash/\n[174] Zhang, F., Cecchetti, E., Croman, K., Juels, A., Shi, E.: Town crier: An authenti-\ncated data feed for smart contracts. In: Proceedings of the 2016 aCM sIGSAC\nconference on computer and communications security. pp. 270\u2013282 (2016)\n[175] Zhang, R., Xue, R., Liu, L.: Security and privacy on blockchain. ACM Computing\nSurveys (CSUR) 52(3), 1\u201334 (2019)\n[176] Zhang, Y., Chen, X., Park, D.: Formal specification of constant product (xy= k)\nmarket maker model and implementation (2018), https://github.com/runtimeve\nrification/verified-smart-contracts/blob/uniswap/uniswap/x-y-k.pdf\n[177] Zhao, W., Li, H., Yuan, Y.: Understand volatility of algorithmic stablecoin: Mod-\neling, verification and empirical analysis. arXiv preprint arXiv:2101.08423 (2021)\n[178] Zhou, L., Qin, K., Cully, A., Livshits, B., Gervais, A.: On the just-in-time\ndiscovery of profit-generating transactions in defi protocols. arXiv preprint\narXiv:2103.02228 (2021)\n[179] Zhou, L., Qin, K., Torres, C.F., Le, D.V., Gervais, A.: High-frequency trading on\ndecentralized on-chain exchanges. arXiv preprint arXiv:2009.14021 (2020)\n16\nA\nDEFI PROTOCOLS\nTable 2: DeFi Protocols: A selection of prominent DeFi protocols\nclassified according to the proposed protocol types.\nExchanges\nPLFs\nStablecoins\nPortfolio\nManagers\nDerivatives\nCurve\nCompound\nMaker\nHarvest\nOpyn\nUniswap\nAave\nUnit\nYearn\nHegic\nSushiswap\ndYdX\nReflexer\nSet\nSynthetix\nBalancer\nCream\nFei\nAlpha\nBancor\n1inch\nB\nEMPIRICAL EXPLOITS\nThere have been a range of exploits in DeFi applications. This is\na non-exhaustive list of some of the exploits and vulnerabilities\nreferenced in Sections 5 and 6.\nReentrancy Exploits.\n\u2022 dForce: One of the most prominent examples of this ex-\nploit was against the dForce protocol [51], which features\na PLF, in April 2020 to drain around 25 million USD worth\nof funds [64].The attacker used imBTC [151], which is an\nERC-777 token [45], to perform the attack. A particularity of\nERC-777 tokens, as opposed to ERC-20 tokens, is that they\nhave a hook calling the receiver when the receiver receives\nfunds. This means that any ERC-777 tokens will indirectly\nresult in the receiver having control of the execution. In the\ndForce attack, the attacker used this reentrancy pattern to\nrepeatedly increase their ability to borrow without enough\ncollateral to back up their borrow position, effectively drain-\ning the protocol\u2019s funds.\n\u2022 imBTC Uniswap Pool: Despite the fact that Uniswap does not\nsupport ERC-777 tokens [157], an imBTC Uniswap [156] pool\nworth roughly 300 000 USD was drained using the reentrancy\nattack.\nInteger Manipulation Exploits.\n\u2022 YAM: In August 2020, the YAM protocol [168], which had\nlocked almost 500 million USD worth of tokens in a very\nshort period of time, realized that there was an arithmetic-\nrelated bug.Two integers scaled to their base unit were mul-\ntiplied and the result not scaled back, making the result\norders of magnitude too large [30, 32].This prevented the\ngovernance to reach quorum and locked all the funds in the\nprotocol\u2019s treasury contract, effectively locking over 750 000\nUSD worth of tokens [169] indefinitely.\nLogical Bug Exploits.\n\u2022 bZx: In September 2020, the bZx protocol [28], a lending\nprotocol, suffered a loss of over 8 million USD due to a trivial\nlogic error [117], despite having been through two indepen-\ndent audits. The bZx protocol uses its own ERC-20 tokens,\nwhich are minted by locking collateral and repaid to redeem\nthe locked collateral. As other ERC-20 tokens, bZx tokens\nallow users to transfer the tokens. However, due to a logi-\ncal bug, when a user transferred tokens to themselves, the\namount transferred would effectively only be added to their\nbalance, and not correctly subtract from it, allowing a user\nto double his amount of tokens at will. The tokens created\ncould then be used to withdraw funds that the attacker never\nowned or locked.\nMarket Manipulation.\n\u2022 Venus: Since pre-printing this paper, a clear exploit that ma-\nnipulated this market structure was performed on the Venus\nprotocol [50]. In this exploit, the attacker manipulated the\nthinly traded XVS market and borrowed large amounts of\nBTC against XVS collateral at the manipulated high prices.\nThis led to $100m of bad debt (effectively, the profit for the\nattacker) in the protocol when the XVS market equilibrated\nto normal pricing.\nC\nBATCH SETTLEMENT SYSTEMS\nIn Gnosis exchange [68], trades are matched algorithmically in peri-\nodic batches maintained by decentralized keepers. Keepers compete\nto solve a complicated matching problem. They submit solutions\non-chain, from which the protocol executes the best solution, by\nsome metric. If this keeper market is competitive, trades should\nbe settled at fair prices, though issues can arise when the keeper\nmarket is not competitive [93] or if the method for choosing the\nbest keeper solution can be gamed [67].\n17\n",
    "2109.06836": "Security, Privacy, and Decentralization in Web3\nPhilipp Winter\nBrave Software\nAnna Harbluk Lorimer\nBrave Software\nPeter Snyder\nBrave Software\nBenjamin Livshits\nBrave Software\nImperial College London\nABSTRACT\nMuch of the recent excitement around decentralized finance (DeFi)\ncomes from hopes that DeFi can be a secure, private, less centralized\nalternative to traditional finance systems. However, people moving\nto DeFi sites in hopes of improving their security and privacy may\nend up with less of both as recent attacks have demonstrated.\nIn this work, we improve the understanding of DeFi by con-\nducting the first Web measurements of the security, privacy, and\ndecentralization properties of popular DeFi front ends. We find\nthat DeFi applications\u2014or dapps\u2014suffer from the same security and\nprivacy risks that frequent other parts of the Web but those risks\nare greatly exacerbated considering the money that is involved in\nDeFi. Our results show that a common tracker can observe user\nbehavior on over 56% of websites we analyzed and many trackers\non DeFi sites can trivially link a user\u2019s Ethereum address with pii\n(e.g., user name or demographic information), or phish users by\ninitiating fake Ethereum transactions. Lastly, we establish that de-\nspite claims to the opposite, because of companies like Amazon\nand Cloudflare operating significant Web infrastructure, DeFi as a\nwhole is considerably less decentralized than previously believed.\nCCS CONCEPTS\n\u2022 Information systems \u2192Web applications; \u2022 Security and\nprivacy \u2192Privacy protections.\nKEYWORDS\nWeb 3.0, DeFi, PII, Ethereum, security, privacy, decentralization\nACM Reference Format:\nPhilipp Winter, Anna Harbluk Lorimer, Peter Snyder, and Benjamin Livshits.\n2018. Security, Privacy, and Decentralization in Web3. In Proceedings of Make\nsure to enter the correct conference title from your rights confirmation emai\n(Conference acronym \u2019XX). ACM, New York, NY, USA, 11 pages. https:\n//doi.org/XXXXXXX.XXXXXXX\n1\nINTRODUCTION\nWe are witnessing a movement in finance whose goal is to replace\nlong-standing institutions with code. More than 25 billion U.S. dol-\nlars are currently locked in decentralized finance (DeFi) [9]. Guided\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\n\u00a9 2018 Association for Computing Machinery.\nACM ISBN 978-1-4503-XXXX-X/18/06...$15.00\nhttps://doi.org/XXXXXXX.XXXXXXX\nby the principles of decentralization and self-custody, DeFi appli-\ncations implement numerous instruments from traditional finance\nlike insurance, loans, or exchanges which are now steered by al-\ngorithms rather than human intervention. DeFi applications differ\nsignificantly in their architecture from traditional websites: Instead\nof a complex Web front end that communicates with a database\nback end, DeFi applications expose a lightweight front end that\ninteracts with a blockchain-based back end using wallet software\nthat runs in the user\u2019s browser. This unorthodox design\u2014coupled\nwith the substantial and ever-increasing amount of money pouring\ninto DeFi\u2014raises several questions related to security and privacy:\nWhat is the attack surface that attackers could exploit to steal funds?\nHow well do DeFi sites protect the user\u2019s financial information?\nWhat is the role of third-party trackers? This work sets out to\nanswer these questions. While smart contract security has been\nstudied extensively [34, \u00a7 5.1], the above questions have received\nlittle attention.\nWe begin by compiling a list of 78 popular DeFi sites and proceed\nto study the problem through the lens of well-established Web\nsecurity and privacy methods. In particular, we identify what third-\nparty providers DeFi sites use, what user data those providers can\nobtain, and how those providers could misbehave.\nOur results show that 66% of DeFi sites rely on scripts from\nthird-party providers and more than half of all DeFi sites rely on\nanalytics scripts from Google, which gives the advertising company\nsubstantial insight into how users interact with DeFi sites. We also\nfind that 17% of DeFi sites leak the user\u2019s Ethereum address to\nthird parties, which constitutes a significant privacy issue. We also\nlook at problems that are caused by the architectural design of\nDeFi applications: The scripts that a DeFi site embeds are able to\ninteract with the user\u2019s wallet api, which facilitates phishing attacks.\nLast, we find that DeFi sites frequently fall short of being truly\ndecentralized, jeopardizing security, governance, and reliability. For\nexample, Cloudflare hosts almost half of all sites and therefore has\ncomprehensive data on how users interact with DeFi applications.\nMotivated by the infamous event-stream vulnerability [10], we\nstudy the software dependencies of DeFi front ends in an attempt\nto understand what software packages are popular, and to get a\nsense of the potential for injecting malicious code in any of these\ndependencies.\nContributions: This paper makes the following contributions:\n(1) We compiled a list of 78 popular DeFi sites and built a\nJavaScript crawler that visits these sites and extracts the\nWeb requests that they make before and after a user con-\nnects her wallet to the DeFi site. We make our code and this\ndata set publicly available.\n1\narXiv:2109.06836v2  [cs.CR]  6 Feb 2023\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nPhilipp Winter, Anna Harbluk Lorimer, Peter Snyder, and Benjamin Livshits\n(2) We analyzed the aforementioned data set for privacy and\nsecurity problems. Our analysis revealed cross-site Ethereum\naddress leaks and it showed that Google can track Web3 users\nacross the marketing funnel and do conversion analysis. We\nalso studied the dependencies of DeFi front ends (finding that\nthe average front end relies on a median of 53 dependencies)\nand the underlying hosting infrastructure of DeFi front ends.\n(3) We performed measurements of the different dimensions\nof decentralization within our data set and concluded that\nthe lack of decentralization is a surprising Achilles heel of\na domain that claims to be significantly decentralized. For\ninstance, we find that Cloudflare and aws are responsible\nfor more than 80% of DeFi site front ends.\nPaper organization: In the rest of this work, Section 2 provides\nbackground on DeFi, followed in Section 3 by an explanation of\nthe privacy and security issues we discovered. We then measure\nthe prevalence of these issues on popular DeFi sites in Section 4.\nSection 5 discusses this work\u2019s limitations and makes recommenda-\ntions to both users and DeFi developers. We conclude this work in\nSection 6 by contrasting it with past research and summarize our\nfindings in Section 7.\n2\nBACKGROUND\n2.1\nWeb Tracking\nUsers are typically tracked on the Web by third parties that use\neither explicit or implicit information to track users across sites.\nHistorically, third-party cookies have been a popular way of track-\ning users but browsers like Firefox and Safari have recently started\nblocking third-party cookies by default [37, 35], which makes them\na less effective tracking vector. Numerous alternative tracking vec-\ntors exist though, like browser fingerprinting, whose idea is to\nuniquely identify users based on the nuances of their browser\u2019s\nconfiguration, e.g., screen resolution, available fonts, or installed\nextensions.\n2.2\nEthereum\nEthereum\u2019s native currency is called Ether and users often manage\n(some of) their Ether in software wallets that are implemented as\nbrowser extensions. These extensions store the user\u2019s private key1\nand provide a UI for managing the user\u2019s funds.\nUnlike Bitcoin, Ethereum implements an account-based model,\nsimilar to bank accounts. All transactions from and to a given\nEthereum account are eternalized on the blockchain and can easily\nbe linked to the user\u2019s account (but not necessarily their real-world\nidentity), which means that at best, users enjoy pseudonymity. It is\nhowever straightforward to create multiple Ethereum accounts to\ncompartmentalize one\u2019s financial activity. While privacy layers have\nbeen proposed on top of Ethereum, their usage remains scarce [3,\n26, 30].\nUsers are encouraged to keep their Ethereum address secret\nbecause knowing an address reveals the owner\u2019s funds (which\nmay paint a target on one\u2019s back) and transaction history (which\nmay reveal sensitive relationships). Regardless, many users freely\n1Note that one can also store the private key in a hardware wallet and manage it via a\nsoftware wallet.\nDeFi site\n  Browser\nWallet extension\nDeFi site\n1\n2\nUser\n3\n4\n5\nEthereum node\n6\nBlockchain\n7\nJSON\nRPC API\nEthereum\nprovider API\nFigure 1: The conceptual flow of DeFi sites: \u2776Users visit\na DeFi site, \u2777click the \u201cconnect wallet\u201d button, \u2778which\nprompts the DeFi site to ask the user\u2019s wallet for permission.\n\u2779The user then grants permission in the UI, \u277aafter which\nthe DeFi site can access the user\u2019s Ethereum account, and\ncreate transactions that make it \u277bvia an Ethereum node \u277c\nto the blockchain.\nshare their Ethereum address online and, of course, users needs to\nreveal their address to some parties (e.g., Ethereum nodes) to use\nthe network meaningfully. Given Ethereum\u2019s emerging financial\necosystem, online advertisers have an incentive to obtain users\u2019\nEthereum address for targeted advertisement; this advertisement\ncan include traditional e-commerce if wallet transactions are used\nfor online marketplaces or, more likely, crypto-focused ads for nfts\nor services such as crypto-friendly debit cards, for instance.\n2.3\nDecentralized Finance Software Stack\nCentralized exchanges, like Coinbase, run counter to the philosophy\nof decentralization that is at the core of cryptocurrencies, which is\nwhy decentralized alternatives have emerged. Typically referred to\nas DeFi, these applications allow users to invest in liquidity pools,\nexchange tokens, send payments, or lend money. A particularly\npopular example is Uniswap, a site that allows users to swap erc-20\ntokens and invest in liquidity pools\u2014tasks that have historically\nonly been offered by centralized exchanges like Coinbase.\nAs illustrated in Figure 1, DeFi applications essentially consist of\na Web interface that bridges the gap between a user\u2019s Ethereum wal-\nlet (e.g., MetaMask [23]) and the DeFi application\u2019s smart contract.\nDeFi sites therefore need to interact with the Ethereum blockchain\nand the user\u2019s wallet. Both types of interactions can (but don\u2019t need\nto) take place via the Ethereum provider api [13]\u2014a JavaScript api\nthat the MetaMask extension injects into the DeFi site\u2019s dom. The\nDeFi site can then interact with the api via the window.ethereum\nJavaScript object. A subset of the Ethereum provider api is han-\ndled directly by MetaMask, e.g. the signing of transactions. The\nremaining api calls are not handled by MetaMask and forwarded\nto an Ethereum node, e.g. to an Ethereum-as-a-service provider\nlike Infura [16]. Note that a DeFi site does not have to rely on\nMetaMask to interact with an Ethereum node; it could simply talk\nto an Ethereum node directly\u2014many DeFi sites do\u2014and limit the\ninteraction with the Ethereum provider api to the signing of trans-\nactions. Unlike MetaMask, Ethereum nodes expose a json-based\nrpc interface. This interface consists of several dozen functions to\ncall smart contracts, fetch gas prices, or obtain the number of the\nmost recent Ethereum block.\nNote that MetaMask makes available some of its api functions\nonly after the user gave permission\u2014typically by manually clicking\n2\nSecurity, Privacy, and Decentralization in Web3\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nthe \u201cconnect wallet\u201d button2 (to prevent unauthorized sites from\naccessing the user\u2019s Ethereum account information [6]), which\nprompts the DeFi site to ask MetaMask for permission, followed\nby a UI dialog asking the user to confirm the DeFi site\u2019s request.\nOnce the user gave permission, the DeFi site is able to access the\nuser\u2019s Ethereum address and balance, and create transactions (that\nstill need to be signed off by the user). For a more comprehensive\noverview of DeFi, refer to Werner et al.\u2019s 2021 arXiv report [34].\n3\nISSUES AND ATTACKS IN WEB3 SITES\nIn this section, we briefly outline the privacy and security issues we\ndiscovered among DeFi sites by using the example of 1inch.exchange\n(in short: 1inch). None of those issues are new\u2014we could summa-\nrize them as \u201cthe past comes back to bite us again.\u201d What makes\nthose issues relevant is the nature of DeFi sites, which differs from\ntraditional websites in that (i) substantial amounts of money are\ninvolved and all that stands between a malicious DeFi site and the\nuser\u2019s funds is often just a layer of JavaScript; (ii) a user\u2019s Ethereum\naddress is effectively a unique, long-term identifier that is linked\nto the user\u2019s publicly visible financial history\u2014ideal conditions for\nonline tracking. A summary of issues and attacks covered below is\nshown in Table 1.\nPrivacy: 1inch\u2019s landing page embeds scripts from several third\nparties, one of which is Google Analytics. This reveals arguably sen-\nsitive financial browsing activity to Google because 1inch encodes\nin its urls what tokens the user is interested in exchanging, e.g. the\nurl https://app.1inch.io/#/1/swap/COMP/USDC (which makes\nits way to Google Analytics) reveals that the user selected the comp\nand usdc token to swap. Furthermore, the use of Google Analyt-\nics also leaks the user\u2019s Ethereum address because 1inch happens\nto put the user\u2019s Ethereum address in an \u201cevent label\u201d on Google\nAnalytics. This allows Google to link the user\u2019s Ethereum address\nwith the pii the company likely already has about the user. Worse,\nGoogle\u2014and other analytics providers\u2014also play a role in other\nDeFi sites, making it possible to track users across sites.\nAnalytics providers enjoy widespread use thanks to the conve-\nnience and insight that they provide but the nature of data they\nleak to third parties is highly sensitive in the context of DeFi.\nSecurity: 1inch embeds a chat widget that allows users to contact\n1inch support staff. The widget is provided by a third party and\nconsists of JavaScript that is embedded in 1inch\u2019s first party context\nand therefore has full control over 1inch\u2019s dom. That by itself is\nnot surprising\u2014virtually all major websites embed scripts but once\nthe user connects her MetaMask wallet to 1inch, both 1inch and\nthe embedded chat widget are able to interact with the Ethereum\nprovider api that\u2019s injected by MetaMask. Crucially, the chat wid-\nget (or whoever compromised its distribution infrastructure) can\nmodify 1inch\u2019s dom to phish the user in an attempt to steal funds,\nor directly make a transaction via the user\u2019s wallet. While this\ntransactions would have to be approved by the user, we argue that\na well-crafted transaction at the right time would fool many users.\nFirst-party script inclusion always brings with it a certain risk but\nwe believe that this risk is highly elevated in the context of DeFi\nconsidering the amount of money that is at stake.\n2E.g., via the following JavaScript call:\nwindow.ethereum.request({method: \u2019eth_requestAccounts\u2019})\nTable 1: A summary of the potential attacks and issues this\npaper presents.\nIssue type\nDescription\nPrivacy (\u00a7 4.2)\n\u2022 Ethereum address leaks to third\nparties.\n\u2022 Third-party trackers can track\nDeFi users across sites.\nSecurity (\u00a7 4.3, \u00a7 4.4)\n\u2022 DeFi sites heavily rely on third-\nparty scripts (and sometimes\niframes) that could phish the user.\n\u2022 Front ends rely on a large number\nof Node dependencies.\nDecentralization (\u00a7 4.5)\n\u2022 Front ends and hosting infrastruc-\nture are mostly centralized.\nExcessive centralization: 1inch\u2019s front end is made available via\nCloudflare\u2019s cdn and so are most other DeFi sites. The issue here\nis twofold: (i) centralizing front ends among only a few hosting\nproviders can lead to a substantial amount of funds being effectively\nunavailable should an outage occur; and (ii) centralized hosting\nproviders gain (and potentially monetize) a lot of insight into how\nusers interact with DeFi. Besides, governments can coerce central-\nized hosting providers into ceasing operations which is not difficult\nto imagine considering how the U.S. government sanctioned the\npopular mixer Tornado Cash [32].\n4\nMEASUREMENTS\nHaving introduced potential privacy and security issues, we now\nturn to understanding how common those issues are. How many\nDeFi sites exhibit one or more of those issues? How common is the\npresence of Google Analytics?\nWe begin by discussing our measurement method (\u00a7 4.1), fol-\nlowed by an analysis of how often a user\u2019s Ethereum address leaks\nto third parties (\u00a7 4.2). We then take a step back and determine\nwhat third parties DeFi sites rely on and what this implies (\u00a7 4.3).\nNext, we study what software packages DeFi sites depend on (\u00a7 4.4)\nand the degree of decentralization among DeFi hosting providers\n(\u00a7 4.5).\n4.1\nData Set and Method\nWe begin by compiling a list of DeFi sites to inspect from DeFi\nPulse [9], which lists the top DeFi sites ranked by \u201ctotal value\nlocked,\u201d i.e. the amount of money that is currently \u201clocked\u201d inside\nthe respective smart contracts\u2014an apt proxy for the popularity\nof DeFi sites. We added the top 50 sites as of 2021-08-26 and aug-\nmented the list with 26 sites that we found of interest, resulting\nin a list of 78 DeFi sites, shown in full in Table 10 in Appendix A.\nWe then manually turned the list of domains into urls so that\nwhen clicked, the browser lands directly on the page that asks\nusers to connect their wallet, e.g. we turned compound.finance into\nhttps://app.compound.finance.\n3\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nPhilipp Winter, Anna Harbluk Lorimer, Peter Snyder, and Benjamin Livshits\nTable 2: DeFi sites that leaked our Ethereum address to third\nparties.\nDeFi site\n# of leaks\nyearn.finance\n4\ndefisaver.com\n3\nbifi.finance\n3\nzerion.io\n3\nloopring.io\n2\nbancor.network\n2\ndodoex.io\n2\nsablier.finance\n1\nreflexer.finance\n1\nimpermax.finance\n1\n1inch.io\n1\njelly.market\n1\nrarible.com\n1\nIn the next step, we set out to visit each site and record the\nrequests that it makes. To facilitate that, we built a Puppeteer-based\ncrawler that spawns an instance of Google Chrome 92.0.4515.159\non Linux, sequentially visits all urls in our DeFi list for 30 seconds,\nand records each request that the respective site makes. We used a\nfresh Chrome profile for our experiment, installed the MetaMask\n10.0.3 extension, and completed MetaMask\u2019s onboarding process,\nresulting in a new Ethereum address. We are particularly interested\nin what requests a site makes after the user connects her wallet,\nwhich is why we manually click on the \u201cconnect wallet\u201d button\nonce our crawler visits a new site. It took less than one hour to\ncomplete these semi-automatic measurements.\nFor each site, our crawler created a json file that contains meta-\ndata about the respective site and a list of Web requests, each con-\nsisting of (i) the request context (e.g., the site itself, or an iframe),\n(ii) the requested url, and (iii) the type of request (e.g., a fetch,\nimage, or script request). Below is an example from Uniswap: A\nWeb request to app.tryroll.com for a list of tokens.\n{\n\"requestContext\": [\n\"https://app.uniswap.org/#/\"\n],\n\"url\": \"https://app.tryroll.com/tokens.json\",\n\"type\": \"fetch\"\n},\n4.2\nEthereum Address Leaks\nHaving recorded all requests of the most popular DeFi sites, we ask:\nDo any of these requests leak our Ethereum address to third parties?\nFor example, did foo.finance send an xhr request containing our\nEthereum address to bar.finance? To answer this question, we filter\nour data for requests (i) whose destination has a different etld+1\nthan the origin3 and (ii) whose url contains our Ethereum address.\n3We added a special case for the sites 1inch.exchange and balancer.fi because they also\noperate 1inch.io and balancer.finance, respectively\u2014different etld+1 domains that are\nrun by the same organization.\nTable 3: Top ten third party sites whose scripts were embed-\nded the most.\nThird party\n# of sites\ngoogletagmanager.com\n28\ngoogle-analytics.com\n21\nintercomcdn.com\n8\nintercom.io\n8\nairswap.io\n6\ncloudflareinsights.com\n5\nfacebook.net\n3\ncrisp.chat\n3\ngoogle.com\n2\ngstatic.com\n2\nTable 2 contains the DeFi sites that leaked our Ethereum address,\nalong with the number of leaks we found. Our script detected that\n13 out of our 78 sites (17%) leaked our Ethereum address to third-\nparty domains. Yearn issued four fetch requests to api.zapper.fi\u2014\nto retrieve \u201cYearn Vaults\u201d and token balances; DeFi Saver issued\nfetch requests to defiexplore.com and api.compound.finance; BiFi re-\nquested four images from heapanalytics.com whose url contained\nour Ethereum address; and Zerion issued three fetch requests to\nipfs.3box.io and maker.ifttt.com.\nFor the most part, this behavior represents standard Web devel-\nopment: many sites use third-party apis to submit and retrieve user\ninformation. We must however hold DeFi front ends to a higher stan-\ndard, similar to traditional financial institutions, because a user\u2019s\nEthereum address constitutes sensitive financial information.\n4.3\nCross-origin Dependencies\nRecall from Section 3 that DeFi sites\u2014like traditional banking sites\u2014\nmust be particularly careful about what external scripts they embed\nbecause those scripts can see wallet balances and potentially phish\nthe user by modifying the page\u2019s dom, which raises the question:\nhow many DeFi sites embed scripts from third parties? We answer\nthis question by extracting script requests from our DeFi list whose\ndestination etld+1 differs from the site\u2019s origin.\nOur data shows that 48 DeFi sites (66%) embed at least one script\nfrom a total of 34 third parties. Table 3 shows the top ten third\nparties that are embedded the most. Google\u2019s Tag Manager can\nbe found on 28 DeFi sites, followed by Google Analytics on 21\nsites. Intercom provides a chat support widget that can be found\non 8 DeFi sites. Google\u2019s presence among DeFi sites is pervasive:\nOur data shows that 41 DeFi sites (56%) embed at least one script\nprovided by Google.\nConversion analysis: Is Google able to monetize Alice\u2019s behav-\nioral data as she navigates DeFi sites? For example, several DeFi\nsites leak their users\u2019 Ethereum address directly to Google Analyt-\nics, giving the company the opportunity to link a user\u2019s real-world\nidentity (which is pii) to her Ethereum address. What else can\nGoogle and other third party trackers learn about Alice?\nAdvertising companies have an incentive to track users through\nconversion funnels\u2014an e-commerce term that refers to a user\u2019s\n4\nSecurity, Privacy, and Decentralization in Web3\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\njourney from first hearing about a product, to considering a pur-\nchase, to finally purchasing the product. Applied to the space of\ncryptocurrency, this could mean tracking Alice in each step as she\n(i) sees an \u201cad\u201d for a currency or a token on a news site, (ii) inspects\nthe asset\u2019s price chart on a price discovery site, and (iii) purchases\nthe asset on a DeFi site. A concrete funnel could look as follows:\nAlice browses the popular news site CoinDesk where she learns\nabout a new token that recently appreciated in value. To learn more\nabout the token\u2019s price performance, she visits the price listing site\nCoinGecko. Having gained faith in the token\u2019s performance, Alice\ndecides to invest in it and visits Uniswap to make the purchase.\nAn advertisement company tracking Alice through the funnel can\nenrich its profile about Alice, allowing for more effective targeted\nadvertisement.\nTo answer these questions, we need websites representing the top\nand middle part of the conversion funnel\u2014a list of cryptocurrency\nnews sites and of price discovery sites. We already have a list of\nDeFi sites, which constitutes the bottom part of the funnel. We\nobtained a list of five news sites and six price discovery sites (see\nTable 4) by selecting the top Google search results for the keywords\n\u201ccryptocurrency price\u201d and \u201ccrypto news.\u201d Equipped with three lists\nof sites, a subset of which Alice would traverse until she eventually\nconducts a transaction, we now turn to understanding what entities\ncan track Alice.\nFor each of the sites in our three categories, we determine the\nthird parties (identified by their etld+1) from which the sites embed\nscripts. We then determine what third parties can track users in all\nthree categories\u2014news site, price discovery, and purchase. Finally,\nwe select the subset of entities that is able to track on at least 1%\nof sites in each of the three categories. In other words, we select\nentities that can track on at least 1% of news sites and on at least 1%\nof price discovery sites, and on at least 1% of DeFi sites. Table 5\nlists the five companies that survived our selection criteria, and the\nrespective percentage of sites per category that they can track on.\nWhat stands out is that Google is virtually omnipresent, ob-\nserving all news and price discovery sites and most DeFi sites.\nCloudflare, Facebook, Hotjar, and LinkedIn are all only present on\nless than 10% of DeFi sites, resulting in less opportunity to track\nusers through the conversion funnel.\nOur set of news, price discovery, and DeFi sites is incomplete\nbut we don\u2019t expect a larger set to change our results significantly\nbecause of the prevalence of Facebook, Cloudflare, and especially\nGoogle. We may however see other sites take the place of the less\npopular Hotjar and LinkedIn.\n4.4\nComplexity of Software Dependencies\nNode\u2019s ecosystem has fallen prey to several high-impact supply\nchain attacks over the last few years. The year 2018 brought the\nevent-stream incident in which an attacker used social engineering\nto gain write access to the event-stream module, which the attacker\nlater used to add a dependency to a malicious module [10]. More\nrecently, in 2021, an attacker managed to compromise the npm\naccount of a package maintainer, and used it to publish malicious\nupdates [4]. Zahan et al. systematically studied the problem of\nsupply chain attacks in the Node ecosystem [40].\nUpon inspecting the source code of DeFi front ends, we noticed\nthat they rely heavily on Node\u2019s ecosystem. A security issue in a\nfront end dependency could jeopardize the funds of DeFi users if the\ndependency affects the way transactions are crafted. To understand\nthe scope of the problem, we first study the number of dependencies\nthat DeFi front ends rely on. We searched for the front end code of\neach DeFi site in our list and cloned the respective repositories of\n22 (28%) out of our 78 DeFi sites. All front ends are built using Node.\nIn the next step, we determined the number of immediate depen-\ndencies and transitive dependencies, which includes the (recursive)\ndependencies of immediate dependencies. We determined immedi-\nate dependencies by counting the number of package names in the\n\u201cdependencies\u201d object in the package.json file and we determined\ntransitive dependencies by counting the number of dependencies in\nthe yarn.lock or package-lock.json file\u2014whichever a project used.\nOur code normalizes all transitive dependencies by removing\nversion numbers to make sure that no dependency is counted more\nthan once. Table 6 illustrates the results. With the exception of\ntinlake.centrifuge.io, all DeFi sites have at least 37 direct and more\nthan 1,000 transitive dependencies. A large number of dependencies\ndoes increase a DeFi site\u2019s attack surface but a vulnerability in\na dependency does not automatically jeopardize the security of\nEthereum transactions. For example, we inspected vulnerabilities\nspecific to app.aave.com by running npm\u2019s audit feature over the\nfront end code. The audit feature found a critical vulnerability in\nimmer [7], one of Aave\u2019s transitive dependencies.4\nNext, we seek to identify dependencies that are shared across\nDeFi sites. Such dependencies constitute particularly fruitful targets\nconsidering their prevalence across DeFi sites. Table 7 shows the\nnpm packages that are shared by at least eight of the seventeen DeFi\nsites whose front end code we analyzed. Unsurprisingly, almost all\nDeFi sites depend on the popular user interface library React. Al-\nmost as popular is ethers [28]\u2014an Ethereum wallet implementation\nthat allows DeFi sites to connect to Ethereum nodes via wallets like\nMetaMask.\n4.5\nFront End Decentralization\nDeFi applications are built on top of a decentralized back end\u2014the\nblockchain\u2014but the corresponding front ends are often centralized\nand under the full control of the organization working on the DeFi\napplication. At first glance, this does not look like a problem because\nfront ends are interchangeable: Anyone can create a front end\nfor an existing smart contract, so if the \u201cprimary\u201d front end for\na DeFi application were to go down, alternatives would spin up.\nThis however does not reflect how less technical users interact with\nwebsites. Users are conditioned to remember canonical domains and\ndon\u2019t do well in evaluating the trustworthiness of alternatives [36,\n\u00a7 5.2.5]. Besides, there is a financial incentive for third-party front\nends to embed malicious code that could hijack transactions. Non-\ntechnical users are in a poor position to avoid such scams. There\nare several compelling reasons to decentralize front ends:\nSecurity A single controlling organization could inject malicious\ncode at will.\n4The dependency path consists of the npm packages\nreact-scripts \u2192react-dev-utils \u2192immer.\n5\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nPhilipp Winter, Anna Harbluk Lorimer, Peter Snyder, and Benjamin Livshits\nTable 4: The list of cryptocurrency news sites and price discovery sites that we use in our analysis.\nNews sites\nPrice discovery sites\nhttps://www.coindesk.com\nhttps://www.coingecko.com/en\nhttps://cointelegraph.com\nhttps://coinmarketcap.com\nhttps://decrypt.co\nhttps://coinranking.com\nhttps://cryptonews.com\nhttps://coincodex.com\nhttps://www.theblockcrypto.com\nhttps://coincheckup.com\nhttps://www.cointracker.io/price\nTable 5: Companies whose scripts are embedded in at least\n1% of sites of each of our three funnels parts\u2014consisting of\nnews sites, price discovery sites, and DeFi sites.\nThird party\n% of\n% of\n% of\nnews sites\nprice sites\nDeFi sites\nGoogle\n100\n100\n56\nCloudflare\n20\n50\n7\nFacebook\n60\n33\n4\nHotjar\n40\n33\n3\nLinkedIn\n20\n17\n1\nGovernance A single controlling organization could act against\nthe community\u2019s will [29].\nReliability An outage could render funds unavailable to many\nusers not knowledgeable enough to use alternative front\nends.\nWe now quantify the centralization of DeFi front ends by deter-\nmining the underlying hosting providers, which gives us an idea\nof the above reliability attribute. In particular, we determined the\nhosting provider for each of the sites on our list. We resolved each\ndomain in our list of DeFi sites to its corresponding IP address\nand queried Team Cymru\u2019s IP-to-ASN mapping tool to map an IP\naddress to its autonomous system number [17]. We then extract the\nautonomous system name that is also provided by Team Cymru\u2019s\nservice. Table 8 summarizes the results. Cloudflare and aws (Ama-\nzon) hosted a significant number of the sites on our list, indicating a\ntrend towards front ends being centralized behind large, corporate\nhosting providers.\nOf the 78 sites surveyed, more than half were hosted by Cloud-\nflare; aws hosted approximately a third of the sites; Digital Ocean\nhosted only four, and other hosting providers covered a negligible\nnumber of the sites. As seen with Cloudflare\u2019s 2019 outage that\nresulted in an 80% drop of Cloudflare\u2019s traffic volume [15], having\nthe majority of DeFi sites behind one provider risks a majority of\nservices being unavailable in the event of a large outage.\nCloudflare and aws clearly play an important role but what\namount of funds would become unavailable if one of the above\nhosting providers had a global outage? We refer to DeFi Pulse\u2019s\nestimates to approximate an answer, listed in Table 9. Cloudflare\nand aws together host front ends that allow the management of\napproximately 90 billion usd worth of funds. Those funds would not\nbe lost entirely\u2014manual transactions or alternative Web interfaces\nhosted via different means would still facilitate fund management.\nTable 6: The number of immediate and transitive Node de-\npendencies of the DeFi sites whose front end was publicly\navailable. The last column represents the git commit ID we\ninspected.\nDeFi site\nImm.\nTrans.\nCommit ID\ndeps.\ndeps.\nairswap.io\n50\n2,243\n8a60e193\napp.aave.com\n66\n2,176\nf34f1cfc\napp.balancer.fi\n107\n1,664\n0b470019\napp.bancor.network\n47\n1,838\nbe27a821\napp.barnbridge.com\n46\n2,067\n0811cae7\napp.compound.finance\n53\n1,525\n36549ad6\napp.pickle.finance\n79\n1,197\nccf5512f\napp.rari.capital\n66\n1,963\nf95a64b9\napp.ribbon.finance\n41\n2,115\n53ac542a\napp.sushi.com\nn/a\n1,806\ncd611221\napp.tornado.cash\n39\n2,187\na83fae07\napp.uniswap.org\n115\n2,389\n4806c690\ndmm.exchange\n37\n2,597\n8a3174f6\nexchange.loopring.io\n54\n3,511\n6bd6d6ab\nimpermax.finance\n44\n2,289\nbdb74ef4\ninverse-web.vercel.app\n39\n1,143\n7a77d459\noasis.app\n113\n3,611\n6c78d7df\npancakeswap.finance\n55\n2,602\n571b2092\nsaddle.exchange\n52\n1,793\ndee6e290\nstaking.synthetix.io\n90\nn/a\n7b43a7de\ntinlake.centrifuge.io\n4\n4,438\nda02df19\nyearn.finance\n63\n2,578\nc57fcb3e\nWhile uncommon, large-scale hosting provider outages are not\nunheard of: Cloudflare [15], aws [24], and DigitalOcean [27] have\nall suffered substantial outages in the past.\nThe damage that could be done by violation of the above security\nand governance attributes is harder to quantify.\n5\nDISCUSSION\nIn this section we discuss our work\u2019s limitations (\u00a7 5.1) and issue\nrecommendations for both DeFi developers and users (\u00a7 5.2).\n5.1\nLimitations\nOur measurement method from Section 4.1 revealed some Ethereum\naddress leaks to third parties but it is unable to reveal deliberately\n6\nSecurity, Privacy, and Decentralization in Web3\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nTable 7: The immediate npm dependencies (left column) and\nthe number of DeFi sites (right column) that share the re-\nspective dependency.\nImmediate dependencies\nShared by (#)\nreact\n14\nreact-dom\n14\n@web3-react/core\n10\nethers\n9\nbignumber.js\n9\n@web3-react/injected-connector\n9\nreact-redux\n8\nlodash\n8\n@web3-react/walletconnect-connector\n7\ngraphql\n7\nreact-router-dom\n7\nreact-scripts\n7\nstyled-components\n7\n@reduxjs/toolkit\n7\nTable 8: The providers (as well as the number and percent-\nage) that host the 78 DeFi sites in our list.\nHosting provider\n# of sites\n% of sites\nCloudflare\n34\n44\naws\n30\n38\nDigital Ocean\n5\n6\nFastly\n3\n4\nOther\n6\n8\nTable 9: The amount of funds that would become potentially\nunavailable if one of the hosting providers had an outage.\nThese numbers are estimates as the exact amount of locked\nin value behind DeFi sites is difficult to determine.\nHosting provider\nAffected (usd)\nCloudflare\n61.6 B\naws\n28.1 B\nFastly\n2.4 B\nDigital Ocean\n0.9 B\nOther\n0.8 B\ndisguised address leaks. For example, unsophisticated address encod-\ning schemes like Base64 could have evaded our detection method.\nIn this paper, we focused on 78 DeFi sites\u2014most of which are\namong the most popular sites according to \u201ctotal value locked.\u201d The\ntotal population of DeFi sites is much larger though and our results\nprovide no insight into the privacy and security issues of the long\ntail of DeFi sites. Considering the little care and effort that goes into\nmany DeFi sites, we expect the long tail to exhibit more problems\nthan popular sites like Uniswap or Compound. We therefore believe\nthat our work represents a lower bound of security and privacy\nissues. Future work could take a more comprehensive and (perhaps\nlongitudinal) approach to studying the problem.\nFinally, our list of DeFi sites may exhibit selection bias, i.e. it\nmay differ from the general population of DeFi sites in crucial\naspects. For example, our list of popular DeFi sites may exhibit\nfewer security and privacy issues than the lesser-known long tail\nof DeFi sites.\n5.2\nRecommendations\nWhat can DeFi developers do to improve security and privacy for\ntheir users, and guarantee the \u201cDe\u201d in DeFi? How can users protect\nthemselves? Below, we issue a set of recommendations for both DeFi\ndevelopers and users. For DeFi users, we recommend the following:\nBlock analytics scripts: To prevent analytics providers from link-\ning Ethereum addresses to real-world identities, we recom-\nmend browser extensions like Privacy Badger or browsers\nlike Brave, or Tor Browser.\nDon\u2019t connect your wallet unless you have to: We recommend\ntreating one\u2019s Ethereum address like credit card or bank ac-\ncount information, i.e. only revealing it selectively and when\nnecessary.\nFor developers of DeFi sites, we recommend the following:\nUse self-hosted analytics: We recommend using self-hosted an-\nalytics scripts instead of third-party services to minimize\nexposure to third parties. If a DeFi site does use third party\nproviders, it should ensure that no sensitive information like\nEthereum addresses leak to the analytics providers.\nAddress privacy as design goal: Our work shows that many DeFi\nsites don\u2019t consider Ethereum addresses private.5 We rec-\nommend that DeFi developers treat Ethereum addresses like\ncredit card information.\nDecentralize front ends: Section 4.5 highlighted the centraliza-\ntion among DeFi front ends. To improve reliability in the\nface of outages and DoS attacks, DeFi site operators should\nconsider making available their front ends over alternative\ninfrastructure such as ipfs or Tor onion services, which also\ncome with desirable security properties such as end-to-end\nencryption.\nRevise threat models: Our results show that well-established Web\ndevelopment methods like the use of innocuous support wid-\ngets can open the gates to phishing attacks.6 We recommend\nthat DeFi developers carefully consider what third parties\nshould be allowed to modify their site\u2019s dom. Not only does\none have to trust that these third parties are benign; one\nalso has to trust that they are competent and able to secure\ntheir infrastructure from compromise\u2014a high bar that may\nbe difficult to meet if substantial amounts of money are at\nstake.\n5For example, 1inch\u2019s referral code contains the inviting user\u2019s Ethereum address,\nwhich is exposed to the invitee.\n6Phishing constitutes a pervasive problem taking on numerous forms, ranging from\nscammers masquerading as support staff [38] or \u201chelpful\u201d social media users [39] to\nfake [18] or compromised wallet software [25].\n7\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nPhilipp Winter, Anna Harbluk Lorimer, Peter Snyder, and Benjamin Livshits\n6\nRELATED WORK\nWe conclude this paper by contrasting it with related work, which\nwe divide into online privacy related to third-party tracking and\ncryptocurrencies, and finally user perception of cryptocurrencies.\nOnline Privacy and Third-Party Tracking: Advertisers take ad-\nvantage of a plethora of ways to track users online [1, 12, 11]. One\nof the most pervasive ways to do this is via third party trackers\nsuch as Google Analytics, which uses http requests and first party\ncookies in addition to information about the user\u2019s browser and\nsystem to compile a profile of a user\u2019s online activity [31].\nOnline Privacy and Security of Cryptocurrencies: Past work\non Bitcoin privacy has mostly focused on the linkability of ad-\ndresses [22] (along with some exploration of network-layer is-\nsues [2]), a PoPETs\u201918 paper [14] by Goldfeder et al. takes a first\nlook at the intersection between Bitcoin and online privacy. An\nincreasing number of online vendors now support payment by\nBitcoin but the authors show that online trackers often collect suf-\nficient sensitive information to link a purchase to its subsequent\nblockchain transaction. Worse, by taking into account auxiliary\ninformation, attackers could link together Bitcoin transactions that\nwere anonymized via CoinJoin\u2014a popular mixer at the time. We\nbuild on Goldfeder et al.\u2019s first foray into the intersection of cryp-\ntocurrency and online privacy, showing that both third and first\nparty scripts can facilitate security and privacy issues in DeFi sites.\nA 2020 technical report by B\u00e9res et al. [5] takes a look at privacy\nin Ethereum, showing how attackers can profile and deanonymize\nusers. The authors show that one can link several Ethereum ad-\ndresses to the same owner by taking into account the time of day\nthese addresses are typically used, the gas price, and unrelated\naddresses that are transacted with. Even mixers like the popular\nTornado Cash are no panacea because they are frequently misused.\nFor example, not understanding the nuances of mixers, some users\nuse the same Ethereum address for deposit and withdrawal, effec-\ntively deanonymizing themselves. We expand on B\u00e9res et al.\u2019s work\nby pointing out how common Web development methods lead to\nprivacy and security issues in DeFi applications.\nLi et al. reveal in their ndss\u201921 paper [20] a DoS attack that\nmakes it possible to disable rpc services that DApps rely on\u2014e.g. to\nget the upper hand in an auction by preventing competing bidders\nfrom placing their bids. The attack exploits the fact that many rpc\nservices don\u2019t impose a gas limit on the eth_call method, making\nit possible to make the rpc service engage in heavy computation,\nthus preventing it from serving other clients. Refer to Werner et\nal.\u2019s arXiv report [34] for a comprehensive overview of DeFi and\nthe state of open research questions around DeFi.\nIn their 2021 arXiv report, Das et al. study security issues in\nnfts [8] by drawing on data from eight nft market places. The\nauthors document security issues in market places, fraudulent user\nbehavior, and the \u201cdecay\u201d in nfts whose content (but not the on-\nchain reference) disappears over time.\nUser Perception: In a FC\u201916 paper [19], Krombholz et al. surveyed\n990 Bitcoin users about their understanding of Bitcoin security, pri-\nvacy, and anonymity. Interestingly, nobody stored wallet backups\non an air-gapped computer but several respondents used encrypted\nbackups. 32% of respondents believe that Bitcoin is per-se anony-\nmous but 80% think that it is possible to follow their transactions.\nThe study\u2019s respondents were no strangers to loss of Bitcoin: 22%\nreport that they have lost Bitcoins at least once\u2014due to hardware\nor software failure, or because they lost access to their private keys.\nFinally, respondents saw vulnerabilities in hosted wallets as the top\nthreat right after Bitcoin value fluctuation.\nUser misconceptions go beyond mixers. Drawing on data from\ntwenty interviews with cryptocurrency users and non-users, Voskobo-\njnikov et al. show in their FC\u201920 paper [33] that users express con-\nfusion about the concept of \u201cgas prices,\u201d mistakenly believe that\nthey own the private key for funds stored by the company Coin-\nbase, or don\u2019t understand the idea behind public and private keys\naltogether. Faulty mental models can lead to critical mistakes like\nthe loss of funds, highlighting the importance of safe defaults that\nprotect users. This work contributes to our understanding of what\nprivacy-preserving safe defaults look like.\nMost recently, a soups\u201920 paper by Mai et al. [21] qualitatively\nstudied cryptocurrency users\u2019 (N=29) mental models and how these\nmodels are in conflict with security and privacy goals. Corroborat-\ning the findings of Voskobojnikov et al., the authors find that the\nidea of cryptographic keys is a frequent source of misunderstand-\ning, prompting some participants to believe that miners or \u201cthe\nblockchain\u201d create private keys. Other participants exhibit misun-\nderstandings about the blockchain, believing that old transactions\nare eventually deleted, or that transactions are confidential and\ncannot be seen by third parties. This highlights that some users\nmay have incorrect expectations of privacy.\n7\nCONCLUSIONS\nThis work is the first to study the privacy, security, and decentral-\nization properties of popular DeFi sites. We conclude that despite\nthe lightweight nature of DeFi front ends, well-understood security\nand privacy risks are as widespread on DeFi applications as on\nother parts of the Web\u2014but carry greater risk in DeFi given the\nmoney that is involved. The carelessness with which DeFi sites\nhandle users\u2019 Ethereum addresses suggests that problems are not\nonly technical but also cultural: The popular technology ethos of\n\u201cmove fast and break things\u201d conflicts with the care that is necessary\nwhen processing sensitive financial information. We also establish\nthat despite claims to the opposite, because of several companies\nlike Amazon and Cloudflare running much of Web\u2019s infrastructure,\nDeFi as a whole is considerably less decentralized than previously\nbelieved.\nAVAILABILITY\nOur data set and source code is available at:\nhttps://github.com/brave-experiments/defi-privacy-measurements\nREFERENCES\n[1]\nGunes Acar, Christian Eubank, Steven Englehardt, Marc\nJuarez, Arvind Narayanan, and Claudia Diaz. \u201cThe Web\nNever Forgets: Persistent Tracking Mechanisms in the Wild\u201d.\nIn: CCS. ACM, 2014. url: https://securehomes.esat.ku\nleuven.be/~gacar/persistent/the_web_never_forgets.\npdf.\n8\nSecurity, Privacy, and Decentralization in Web3\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\n[2]\nMaria Apostolaki, Cedric Maire, and Laurent Vanbever. \u201cPeri-\nmeter: A network-layer attack on the anonymity of cryp-\ntocurrencies\u201d. In: FC. Springer, 2021. url: https : / / nsg .\nee . ethz . ch / fileadmin / user _ upload / publications /\nfc21final97.pdf.\n[3]\nAztec. url: https://aztec.network (visited on 09/07/2021).\n[4]\nAdam Bannister. Popular NPM package UA-Parser-JS poisoned\nwith cryptomining, password-stealing malware. Oct. 2021. url:\nhttps://portswigger.net/daily- swig/popular- npm-\npackage-ua-parser-js-poisoned-with-cryptomining-\npassword-stealing-malware (visited on 01/14/2022).\n[5]\nFerenc B\u00e9res, Istv\u00e1n A. Seres, Andr\u00e1s A Bencz\u00far, and Mik-\nerah Quintyne-Collins. Blockchain is Watching You: Profiling\nand Deanonymizing Ethereum Users. arXiv: 2005.14051v2\n[cs.CR]. url: https://arxiv.org/pdf/2005.14051.pdf.\n[6]\nPaul Bouchon and Erik Marks. Opt-in account exposure. url:\nhttps://github.com/ethereum/EIPs/blob/master/EIPS/\neip-1102.md (visited on 09/07/2021).\n[7]\nCVE-2020-28477. url: https://nvd.nist.gov/vuln/detai\nl/CVE-2020-28477 (visited on 01/30/2022).\n[8]\nDipanjan Das, Priyanka Bose, Nicola Ruaro, Christopher\nKruegel, and Giovanni Vigna. Understanding Security Issues\nin the NFT Ecosystem. arXiv: 2111.08893v1 [cs.CR]. url:\nhttps://arxiv.org/pdf/2111.08893.\n[9]\nDeFi Pulse. url: https://www.defipulse.com (visited on\n10/03/2022).\n[10]\nDetails about the event-stream incident. Nov. 2018. url: https:\n//blog.npmjs.org/post/180565383195/details-about-\nthe-event-stream-incident (visited on 01/14/2022).\n[11]\nSteven Englehardt and Arvind Narayanan. \u201cOnline Tracking:\nA 1-Million-Site Measurement and Analysis\u201d. In: CCS. ACM,\n2016. url: https://www.cs.princeton.edu/~arvindn/\npublications/OpenWPM_1_million_site_tracking_meas\nurement.pdf.\n[12]\nSteven Englehardt, Dillon Reisman, Christian Eubank, Peter\nZimmerman, Jonathan Mayer, Arvind Narayanan, and Ed-\nward W. Felten. \u201cCookies That Give You Away: The Surveil-\nlance Implications of Web Tracking\u201d. In: WWW. ACM, 2015.\nurl: https://senglehardt.com/papers/www15_cookie_\nsurveil.pdf.\n[13]\nEthereum Provider API. url: https://docs.metamask.io/\nguide / ethereum - provider . html # table - of - contents\n(visited on 09/13/2021).\n[14]\nSteven Goldfeder, Harry Kalodner, Dillon Reisman, and Arvind\nNarayanan. \u201cWhen the cookie meets the blockchain: Privacy\nrisks of web payments via cryptocurrencies\u201d. In: PoPETs\n2018.4 (2018). url: https://www.petsymposium.org/2018/\nfiles/papers/issue4/popets-2018-0038.pdf.\n[15]\nJohn Graham-Cumming. Details of the Cloudflare outage on\nJuly 2, 2019. July 2019. url: https://blog.cloudflare.com/\ndetails-of-the-cloudflare-outage-on-july-2-2019/\n(visited on 08/30/2021).\n[16]\nInfura. url: https://infura.io (visited on 10/12/2022).\n[17]\nIP to ASN Mapping Service. url: https://www.team-cymru.\ncom/ip-asn-mapping (visited on 10/06/2022).\n[18]\nYogita Khatri. \u201cFake MetaMask App on Google Play Store\nHosted Crypto Malware\u201d. In: CoinDesk (Feb. 2019). url: h\nttps://www.coindesk.com/markets/2019/02/11/fake-\nmetamask-app-on-google-play-store-hosted-crypto-\nmalware/ (visited on 08/31/2021).\n[19]\nKatharina Krombholz, Aljosha Judmayer, Matthias Gusen-\nbauer, and Edgar Weippl. \u201cThe Other Side of the Coin: User\nExperiences with Bitcoin Security and Privacy\u201d. In: Financial\nCryptography. Springer, 2016. url: https://fc16.ifca.ai/\npreproceedings/33_Krombholz.pdf.\n[20]\nKai Li, Jiaqi Chen, Xianghong Liu, Yuzhe Tang, XiaoFeng\nWang, and Xiapu Luo. \u201cAs Strong As Its Weakest Link: How\nto Break Blockchain DApps at RPC Service\u201d. In: NDSS. The\nInternet Society, 2021. url: https://www.ndss-symposium.\norg/wp-content/uploads/ndss2021_3C-1_23108_paper.\npdf.\n[21]\nAlexandra Mai, Katharina Pfeffer, Matthias Gusenbauer, Edgar\nWeippl, and Katharina Krombholz. \u201cUser Mental Models of\nCryptocurrency Systems - A Grounded Theory Approach\u201d.\nIn: SOUPS. USENIX, 2020. url: https://www.usenix.org/\nsystem/files/soups2020-mai.pdf.\n[22]\nSarah Meiklejohn, Marjori Pomarole, Grant Jordan, Kirill\nLevchenko, Damon McCoy, Geoffrey M. Voelker, and Ste-\nfan Savage. \u201cA Fistful of Bitcoins: Characterizing Payments\nAmong Men with No Names\u201d. In: IMC. ACM, 2013. url:\nhttps://cseweb.ucsd.edu/~smeiklejohn/files/imc13.\npdf.\n[23]\nMetaMask. url: https://metamask.io (visited on 10/13/2022).\n[24]\nJay Peters. \u201cProlonged AWS outage takes down a big chunk\nof the internet\u201d. In: The Verge (Nov. 2020). url: https://www.\ntheverge.com/2020/11/25/21719396/amazon-web-servi\nces-aws-outage-down-internet (visited on 08/30/2021).\n[25]\nAndrey Shevchenko. \u201cFounder of DeFi protocol Nexus Mu-\ntual gets hacked for $8M\u201d. In: Cointelegraph (Dec. 2020). url:\nhttps://cointelegraph.com/news/founder- of- defi-\nprotocol-nexus-mutual-gets-hacked-for-8m (visited on\n08/31/2021).\n[26]\nStarkEx. url: https://starkware.co/product/starkex/\n(visited on 09/07/2021).\n[27]\nDigitalOcean Status. Our engineering team has identified the\nissue, and are working to resolve connectivity issues to our\nDNS servers.... 2016. url: https://twitter.com/DOStatus/\nstatus/713043871559655424 (visited on 08/30/2021).\n[28]\nThe Ethers Project. url: https://www.npmjs.com/package/\nethers (visited on 01/29/2022).\n[29]\nToken access on app.uniswap.org. July 2021. url: https://uni\nswap.org/blog/token-access-app (visited on 01/19/2022).\n[30]\nTornado Cash. url: https : / / tornado . cash (visited on\n09/07/2021).\n[31]\nTracking Code Overview. June 2018. url: https : / / deve\nlopers . google . com / analytics / resources / concepts /\ngaConceptsTrackingOverview (visited on 08/31/2021).\n[32]\nU.S. Treasury Sanctions Notorious Virtual Currency Mixer Tor-\nnado Cash. Aug. 2022. url: https://home.treasury.gov/\nnews/press-releases/jy0916 (visited on 10/04/2022).\n[33]\nArtemij Voskobojnikov, Borke Obada-Obieh, Yue Huang,\nand Konstantin Beznosov. \u201cSurviving the Cryptojungle: Per-\nception and Management of Risk Among North American\nCryptocurrency (Non)Users\u201d. In: Financial Cryptography.\n9\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nPhilipp Winter, Anna Harbluk Lorimer, Peter Snyder, and Benjamin Livshits\nSpringer, 2020. url: https://fc20.ifca.ai/preproceedin\ngs/20.pdf.\n[34]\nSam M. Werner, Daniel Perez, Lewis Gudgeon, Ariah Klages-\nMundt, Dominik Harz, and William J. Knottenbelt. SoK: De-\ncentralized Finance (DeFi). arXiv: 2101 . 08778v3 [cs.CR].\nurl: https://arxiv.org/pdf/2101.08778.\n[35]\nJohn Wilander. Full Third-Party Cookie Blocking and More.\nMar. 2020. url: https://webkit.org/blog/10218/full-\nthird- party- cookie- blocking- and- more/ (visited on\n10/04/2022).\n[36]\nPhilipp Winter, Anne Edmundson, Laura M. Roberts, Ag-\nnieszka Dutkowska-\u017buk, Marshini Chetty, and Nick Feam-\nster. \u201cHow Do Tor Users Interact With Onion Services?\u201d In:\nUSENIX Security. USENIX, 2018. url: https://www.usenix.\norg/system/files/conference/usenixsecurity18/sec\n18-winter.pdf.\n[37]\nMarissa Wood. Today\u2019s Firefox Blocks Third-Party Tracking\nCookies and Cryptomining by Default. Sept. 2019. url: https:\n/ / blog . mozilla . org / en / products / firefox / todays -\nfirefox-blocks-third-party-tracking-cookies-and-\ncryptomining-by-default/ (visited on 10/04/2022).\n[38]\nwuzz1e. $75,000 just disappeared from my Coinbase wallet.\nMay 2021. url: https://www.reddit.com/r/CoinBase/\ncomments/nhug9u/75000_just_disappeared_from_my_\ncoinbase_wallet/ (visited on 08/31/2021).\n[39]\nMartin Young. \u201cMetaMask warns of new phishing bot\u201d. In:\nCointelegraph (May 2021). url: https://cointelegraph.c\nom/news/metamask-warns-of-new-phishing-bot (visited\non 08/31/2021).\n[40]\nNusrat Zahan, Laurie Williams, Thomas Zimmermann, Patrice\nGodefroid, Brendan Murphy, and Chandra Maddila. What are\nWeak Links in the npm Supply Chain? arXiv: 2112.10165v1\n[cs.CR]. url: https://arxiv.org/pdf/2112.10165.pdf.\nA\nLIST OF URLS\nReceived 20 February 2007; revised 12 March 2009; accepted 5 June 2009\n10\nSecurity, Privacy, and Decentralization in Web3\nConference acronym \u2019XX, June 03\u201305, 2018, Woodstock, NY\nTable 10: Our list of 78 DeFi sites.\nhttps://activate.codefi.network/staking/airswap/governance\nhttps://app.1inch.io\nhttps://app.aave.com/markets\nhttps://app.alchemix.fi\nhttps://app.badger.finance\nhttps://app.balancer.fi\nhttps://app.bancor.network/eth/data\nhttps://app.barnbridge.com\nhttps://app.bifi.finance\nhttps://app.bifi.finance/lend\nhttps://app.boringdao.com\nhttps://app.compound.finance\nhttps://app.coverprotocol.com\nhttps://app.cream.finance\nhttps://app.defisaver.com\nhttps://app.dodoex.io\nhttps://app.enzyme.finance/depositor/leaderboard\nhttps://app.fei.money\nhttps://app.flexa.network\nhttps://app.impermax.finance\nhttps://app.jelly.market\nhttps://app.mai.finance\nhttps://app.maple.finance\nhttps://app.nexusmutual.io/swap\nhttps://app.pickle.finance\nhttps://app.rampdefi.com\nhttps://app.rari.capital\nhttps://app.rari.capital\nhttps://app.reflexer.finance\nhttps://app.reflexer.finance\nhttps://app.ribbon.finance\nhttps://app.rulerprotocol.com\nhttps://app.sushi.com\nhttps://app.swapswap.org/#/swap\nhttps://app.tornado.cash\nhttps://app.truefi.io\nhttps://app.truefi.io/home\nhttps://app.uniswap.org\nhttps://app.vesper.finance\nhttps://app.warp.finance\nhttps://app.yield.is\nhttps://app.zerion.io\nhttps://beta.curve.fi\nhttps://curve.fi\nhttps://dashboard.keep.network/overview\nhttps://debank.com\nhttps://defi.instadapp.io\nhttps://dmm.exchange/#/about\nhttps://exchange.dfyn.network\nhttps://exchange.loopring.io/swap\nhttps://flash.wing.finance\nhttps://for.tube/market/index\nhttps://foundation.app\nhttps://harvest.finance\nhttps://homora-v2.alphafinance.io\nhttps://idle.finance\nhttps://inverse.finance/anchor\nhttps://liquity.app\nhttps://moonswap.fi/exchange/swap\nhttps://notional.finance/portfolio\nhttps://o3swap.com/swap\nhttps://oasis.app/dashboard\nhttps://opensea.io/assets\nhttps://pancakeswap.finance\nhttps://pay.sablier.finance\nhttps://rarible.com\nhttps://saddle.exchange\nhttps://staking.synthetix.io\nhttps://tinlake.centrifuge.io\nhttps://trade.dydx.exchange\nhttps://trader.airswap.io/\nhttps://v2.opyn.co\nhttps://wasabix.finance/#/app\nhttps://www.akropolis.io/app/home\nhttps://www.convexfinance.com\nhttps://www.indexcoop.com\nhttps://yearn.finance\nhttps://zapper.fi/dashboard\n11\n",
    "2308.05282": "Decentralized Finance (DeFi): A Survey\nErya Jiang\u2217, Bo Qin\u2217, Qin Wang\u00b6, Zhipeng Wang\u00a7, Qianhong Wu\u2020, Jian Weng\u2021\nXinyu Li\u2217, Chenyang Wang\u2217, Yuhang Ding\u2217, Yanran Zhang\u2217\n\u2217Renmin University of China, China\n\u00b6University of New South Wales, Australia\n\u00a7Imperial College London, UK\n\u2020Beihang University, China\n\u2021Jinan University, China\nAbstract\nDecentralized Finance (DeFi) is a new paradigm in the cre-\nation, distribution, and utilization of financial services via the\nintegration of blockchain technology. Our research conducts\na comprehensive introduction and meticulous classification\nof various DeFi applications. Beyond that, we thoroughly\nanalyze these risks from both technical and economic per-\nspectives, spanning multiple layers. We point out research\ngaps and revenues, covering technical advancements, innova-\ntive economics, and sociology and ecology optimization.\n1\nIntroduction\nWith blockchain\u2019s rise, Decentralized Finance (DeFi) [1] has\nemerged as a disruptive financial paradigm in the middle\nof 2020 (a period known as the DeFi summer), challenging\ntraditional finance [2]. DeFi utilizes blockchain for creating,\ndistributing, and utilizing financial services [3], surpassing\ntraditional finance in various aspects:\n\u2022 Trustless. DeFi protocols eliminate centralized interme-\ndiaries like brokerages, banks, and insurance companies,\nwhich come with defects such as high costs, cumbersome\nprocesses, account opening restrictions, e.g., Know Your\nCustomer (KYC), and lack of transparency.\n\u2022 Non-human intervention. DeFi\u2019s trading rules are pre-\nwritten, making automation and immutability key fea-\ntures [4] while running on-chain that reduces counter-\nparty risk and eliminates the single point of failure.\n\u2022 Maximal availability. Most DeFi products have no down-\ntime, enabling 24/7 financial services to everyone.\n\u2022 Borderless. DeFi enables global accessibility without\nbeing restricted by national boundaries, allowing any-\none from anywhere including those from low economic\nlevels or underserved regions to leverage its services.\n\u2022 Permissionless. Deployed in a decentralized manner\nacross peer-to-peer (P2P) networks, opens new oppor-\ntunities for organizations, e.g., DAOs [5] to areas previ-\nously accessible only to licensed institutions.\n\u2022 Extensibility. DeFi\u2019s open-source nature encourages user\ncontributions, facilitating the emergence of novel finan-\ncial concepts such as flash loans [6,7].\nAs of Aug. 2023, the total locked value (TLV)1 in DeFi\nmarkets has reached US$40.257b, following a peak value of\nUS$253b in Dec. 2021 (also claimed in [8]). This substantial\ninvestment has sparked numerous innovations, including de-\ncentralized exchanges (DEXs, e.g., Uniswap [9], dYdX [10]),\nlending (Compound [11], Aave [12]), yield aggregators (Con-\nvex [13], Harvest [14]), liquid staking (Lido [15], Rocket\nPool [16]), and various other developments [1].\nPrevious investigations. We highlight several recent studies\nthat have elegantly reviewed DeFi-related concepts. Wener\net al. [1] conducted the first systematic studies focusing on\ngeneral DeFi protocols, covering layer-based protocols and\nservices. Moin et al. [17] classified major stablecoin designs,\nwhile Zhao et al. [18] specifically explored algorithmic sta-\nblecoins. Bartoletti et al. [19] introduced lending protocols\nusing a formal model that describes their transitions as a state\nmachine reflecting user interactions. Xu et al. [20] presented\na general business model for a small corpus of DeFi proto-\ncols, including protocols for loanable funds, DEXs, and yield\naggregators. Li et al. [21] describe the picture of confidential\nsmart contrast that can be used for DeFi privacy. Xu et al. [22]\ncomprehensively reviewed DEXs and their corresponding au-\ntomated market maker (AMM) protocols. Erinle et al. [23]\nprovided a comprehensive overview of cryptocurrency wallets\nthat support DeFi services. Lastly, Zhou et al. [8] thoroughly\ninvestigated a range of attacks and incidents in the DeFi space.\nAdditionally, a series of research works have drawn their focus\non MEV extractions [24,25] and frontrunning attacks [26\u201328].\nThis paper follows the burgeoning prosperity of DeFi and\nextends its research horizons. We explore the mechanisms of\nDeFi apps and investigate the security risks from technologi-\ncal and economic perspectives (cf. Figure 1). In particular,\n\u2022 We conduct a comprehensive statistical analysis of the\nliterature in the DeFi field. According to the analyti-\n1Data source: https://defillama.com [Aug. 2023], marked as #DefiLlama.\n1\narXiv:2308.05282v2  [cs.CR]  30 Nov 2023\ncal methods (Section 2), we obtain more than 10,000\nDeFi-related research articles and conduct qualitative\nand quantitative analyses.\n\u2022 We propose a DeFi classification frame based on the\ncomplexity of financial services. The frame (summarized\nin Table 1) classifies DeFi applications into three cate-\ngories (Section 3): tool level, basic functionality level,\nand service level. We detail the structure of DeFi appli-\ncations and related research insights in each category.\n\u2022 We discuss the security of DeFi applications from two\npillars: technical (Section 4) and economic perspectives\n(Section 5). Our discussions are grounded in relevant\nacademic papers and real-world incidents, outlining a\nbroad spectrum of DeFi risks, possible losses, implemen-\ntations, and possible defenses (summarized in Table 2).\n\u2022 We provide information on the gap between existing DeFi\nrealizations and the ideal state. We conclude by propos-\ning technological, sociological, and economic research\ndirections (Section 6).\nRisks of DeFi\nSection 6-\nOpen \nResearch \nChallenges\nSection 3-DeFi Applications\nTools of DeFi\nBasic Functins of DeFi\nServices of DeFi\nInfrastructural Layer\nApplication Layer\nProtocol Layer\nSection 4-Technical Security Risks\nSection 2-Methodology\nSection 5-Economic Security Risks\nLiquidity Depletion\nGovernance Risk\nMarket Manipulation\nFlashloan Attack\nDeath Spiral and Instability\nPonzi and Fraud\nCeFi Impact\nFigure 1: Paper Structure\n2\nMethodology\nWe provide the analytical approach of statistical literature\nanalysis and outline the corresponding modeling process. The\nresults based on quantitative and qualitative analysis will be\npresented in the following sections.\nOur analysis started with retrieving academic papers and\nresearch articles related to DeFi from IEEE Xplore, ACM,\nand Springer. After keyword screening and manual checking,\nwe obtained a total of 15,598 relevant articles.\nIn reviewing the existing literature, we realized that an ef-\nfective way to classify the themes of existing works is based\non the financial complexity of the DeFi application, as shown\nin Figure 2. According to this classification, DeFi applica-\ntions can be classified as digital assets, wallets, oracles and\nasset bridges at infrastructural level, stablecoins, lending, and\nexchanges at functional level, and diverse derivatives at ser-\nvice level. In addition, we have screened and classified the\nliterature that offers DeFi security risk solutions.\nWe utilized quantitative techniques including employing\ndescriptive statistics and other tools to establish relationships,\ntrends, and statistical significance to analyze the data. We also\nemployed qualitative analysis to complement the quantitative\nanalysis. This allowed us to gain a holistic understanding of\nthe subject matter and capture nuanced insights.\nDigital Asset\ntoken\nfungible\nsemi-fungible\nnon-fungible\ncryptocurrency\nWallet\nhot \nwallet\ncold \nwallet\nOracles\noff-chain polymerization\non-chain generation\nAsset Bridge\nsidechains\nrelay\natomic swaps\nStablecoin\noff-chain reserve\non-chain reserve\nover-collateralized issue\nalgorithm issue\nLending\npool lending\nflash loan\nDerivative\noption\ninsurance\nperpetual contract\nprediction market\nasset management\nactive\npositive\nExchange\nreserve pool\nautomatic market \nmaker (AMM)\norder\nbook\non-chain\noff-chain\nhigh\nFinancial Service Complexity\nlow\nTools\nLevel\nBasic Functions \nLevel\nService\nLevel\ndata source\nstandard\nunderlying asset\nmanagement tool\nFigure 2: DeFi Ecological Structure\n3\nDeFi Applications\nWe conducted a statistical analysis on over 10,000 DeFi-apps-\nrelated literature pieces that we obtained.\nObservation. DeFi research literature availability correlates\nwith proximity to blockchain logic. We observe that research\non DeFi tools and functionalities closely tied to blockchain\nemerged earlier and has more quantity. For example, digital\nassets research, due to the native token-blockchain consensus\nrelationship, is the most abundant in DeFi.\nInsight. Initially, DeFi research focused on fundamental\ntools and logic. This is because establishing a reliable and\nsecure blockchain infrastructure was crucial during the early\nstages of blockchain and DeFi development. This involved\ncore technologies like decentralized development, consensus\nalgorithms, network security, and smart contract platforms\nfor automated financial functions. These studies deepened\nthe understanding of blockchain\u2019s underlying logic, resulting\nin extensive literature. As the infrastructure was established,\nexploration and development of complex DeFi tools and appli-\ncations followed. Early research mirrored the developmental\nprocess of the financial system, which begins with establish-\ning basic tools and infrastructure before expanding to a wider\nrange of products and services. Similarly, DeFi progressed\nfrom infrastructure construction to the research and develop-\nment of diverse tools and applications.\nObservation. DeFi research has seen a significant increase,\nespecially in 2022 and 2023. These papers explore previously\nunexplored aspects of DeFi, such as DeFi derivatives.\nInsight. The research boom in DeFi since 2022 is attributed\nto several factors, including the maturation and expansion\nof the DeFi market, technological innovations, and increased\ninvolvement of institutions and enterprises. As the DeFi mar-\nket matures, there is a rising demand for diverse and complex\n2\nDeFi products, including derivatives. The validation of DeFi\u2019s\npotential through industry practices has also played a role.\nIntroduction of new technologies like Layer-2 scaling solu-\ntions, cross-chain technologies, and privacy protection has\nopened up new possibilities. Additionally, the participation\nof enterprises and the regulatory measures and resources they\nbring have further fueled research in DeFi.\nDigital Asset\nWallet\nOracle\nAsset Bridge\nStablecoin\nLending\nExchange\nOption\nInsurance\nAsset Management\nPerpetual Contract\nPrediction Market\nbefore\n2016 2016 2017 2018 2019 2020 2021 2022 2023\nFigure 3: Trend of Research Literature on DeFi Applications\n(Log10 Scale): We illustrate the trends of literature related\nto different DeFi apps over time. Notably, literature on asset\nmanagement, prediction markets, and perpetual contracts is\nlimited, leading to overlapping lines with the horizontal axis.\nObservation. Technical solutions constitute the main type of\nliterature in the DeFi field.\nInsight. Technical solutions being the focus of researchers\nand practitioners is inherent as DeFi is driven by technology\npractice and application. They play a key role in transforming\ntheories into practical tools and platforms.\nAsset Bridge\n100\n80\n60\n40\n20\n0\nSA\nES\nTS\nOracle\n900\n720\n540\n360\n180\n0\nSA\nES\nTS\nPrediction Market\n50\n40\n30\n20\n10\n0\nSA\nES\nTS\nLending\n100\n80\n60\n40\n20\n0\nSA\nES\nTS\nWallet\n250\n200\n150\n100\n50\n0\nSA\nES\nTS\nAsset Management\n50\n40\n30\n20\n10\n0\nSA\nES\nTS\nStablecoin\n100\n80\n60\n40\n20\n0\nSA\nES\nTS\n50\n40\n30\n20\n10\n0\nSA\nES\nTS\nInsurance\nDigital Asset\n4000\n3200\n2400\n1600\n800\n0\nSA\nES\nTS\nOption\n50\n40\n30\n20\n10\n0\nSA\nES\nTS\nExchange\n250\n200\n150\n100\n50\n0\nSA\nES\nTS\nPerpetual Contract\n50\n40\n30\n20\n10\n0\nSA\nES\nTS\n3952\n1018\n755\n179\n39\n60\n813\n53\n32\n34\n0\n7\n54\n35\n21\n78\n25\n5\n145\n20\n56\n5\n0\n1\n3\n0\n1\n1\n0\n0\n0\n1\n1\n37\n1\n15\nFigure 4: Publications of Literature Type: We classify the lit-\nerature into three categories: review articles (blue), empirical\nstudies (green), and technical solutions (yellow). We summa-\nrize the distribution of different types of literature.\nObservation. Review articles often assess from a single dis-\nciplinary perspective, restricting comprehensive evaluations.\nInsight. DeFi encompasses multiple disciplines, including\neconomics, information security, law, and more. When review\narticles lean towards a single disciplinary perspective, they\ntend to be influenced by specific viewpoints and limitations.\nThis ultimately stems from the fact that authors may be in-\nfluenced by their own disciplinary viewpoints, leading to a\nlack of understanding of other disciplines. This reflects the in-\nsufficient depth of collaboration among different disciplinary\ntalents, highlighting the need to cultivate interdisciplinary\ntalents with a comprehensive perspective.\nObservation. Empirical research lacks a macro perspective\nand broader significance in investigating DeFi apps. Apart\nfrom empirical research in the field of digital assets, which\nincludes market data analysis, other areas rely more on case\nstudies investigating specific projects, resulting in a lack of\nmacro perspectives and broader empirical investigations.\nInsight. Due to the novelty of DeFi, empirical research in\nthis domain faces challenges. Inconsistent definitions and\nunclear models complicate empirical investigations. Privacy\nand data protection concerns surrounding DeFi apps make it\ndifficult to acquire sufficient data for macro perspectives and\nbroad empirical studies. The rapid emergence of new DeFi\napps and models also poses challenges in keeping up with the\npace of innovation and conducting comprehensive research.\nConsequently, empirical research in DeFi tends to focus more\non specific case studies rather than broader investigations.\n3.1\nTools of DeFi\nDigital Asset. Native cryptocurrencies and derivative tokens\nconstitute the money flowing in DeFi.\nNative cryptocurrency. Native cryptocurrency refers to the\nprimary digital asset of a blockchain. Prominent exam-\nples include Bitcoin [29], Ethereum [30], Litecoin [31],\nMonero [32\u201334], and Zcash [35, 36], all operating on stan-\ndalone blockchains and incentivized within their respective\neconomies. These cryptocurrencies can be directly transferred\non the chain that hosts them and used for paying transaction\nfees, serving various functions within its ecosystem.\nDerivative Token. Many DeFi apps issue tokens representing\nthe ownership of the assets corresponding to the app. Addi-\ntionally, DeFi app-issued tokens can perform in lending [12],\nstaking [16], and insuring [37], and be empowered to par-\nticipate in governance. Tokens in physical form represent\nownership of real-world assets like real estate and collectibles.\nEthereum has a wide range of token standards for various\nDeFi apps. The widely known ERC-20 standard is fungible\nand interchangeable and used for currencies, voting tokens,\nand pledge tokens. Other Ethereum token standards are tai-\nlored for specific scenarios, such as non-fungible token stan-\ndard ERC-721 used in artwork and digital collections, and\nsemi-fungible token standard ERC-1155 utilized in GameFi\nand copyright. ERC-998 is designed to combine ERC-20\nand ERC-721, enabling compatibility and interoperability.\n3\nOther blockchain platforms like Binance Smart Chain (BSC),\nAvalanche, and Bitcoin have also introduced their own token\nstandards, such as BEP-20, BEP-721, ARC-721, and BRC-20,\nfollowing similar rules to the ERC standards.\nThere is controversy regarding the classification of DeFi\ntokens as currencies, commodities, or securities. Some DeFi\ntokens exhibit currency attributes, possessing wide usability\nand circulation, while others may be classified as securities\ndue to their characteristics of representing ownership, div-\nidends, or investment returns. The classification also relies\non regulatory standards, which are varied across regions and\ncontinuously adjusted given the technical complexity of DeFi.\nThe digital asset research field within DeFi emerged early\nand has a wealth of literature. Quantitative and predictive\nresearch, specifically focused on the cryptocurrency market,\nis a significant area of study. Quantitative research employs\nhistorical market data to develop trading strategies and al-\ngorithms based on technical analysis indicators, statistical\nmodels, and machine learning methods. Predictive research,\non the other hand, involves constructing forecasting models\nusing time series analysis, machine learning, and deep learn-\ning techniques. Notably, the integration of machine learning\nand deep learning, along with comprehensive consideration\nof market characteristics and risks, are prominent features\nwithin this research field.\nWallet. A wallet is a tool for managing the keys and addresses\nof digital asset holders. Wallets serve to interact with the\nblockchain instead of storing on-chain assets. In DeFi, users\ncan manage multiple accounts from a single wallet.\nTypically, a wallet has three basic functions: recording, re-\nceiving, and transferring currencies. With the development,\nits functions have evolved from simple transfers to encompass\nmulti-chain management, asset custody, and other scenarios.\nNumerous academic research and industry examples on the\nfunctional expansion of wallets exist. Software wallets like\nimToken [38], Bip [39], Wetez [40], TrustWallet [41], and\nhardware wallets like Ledger [42] and Trezor [43] have ex-\nplored and implemented these functionalities. In the industry,\nmulti-chain wallets are typically developed by creating in-\nterfaces for different blockchains. Some multi-chain wallets\nhave even introduced \u201cflash exchange\u201d functionality, utilizing\nexchange rates as a medium for transactions.\nWallet security is a critical consideration, encompassing\nkey preservation, recovery procedures, and risk mitigation.\nCold wallets offer physical isolation but carry the risk of loss,\nwhich has led to the development of hot and non-custodial\nwallets. Multi-factor authentication, such as biometrics and\nbehavioral features, has been implemented to enhance security.\nSecret sharing and Trusted Third Party (TTP) verification have\nalso been employed to strengthen security of key recovery.\nOracle. The execution of smart contracts requires meeting\nconditions specified in the contracts, while also requiring sup-\nport from external data. Oracle provides external data sources\nfor smart contracts on the blockchain, supplying them with\ndata information. As of Oct. 2023, the total value of all oracles\nreached US$25b, with Chainlink holding nearly half of the\nmarket among more than 40 different oracles (#DefiLlama).\nTo ensure trustworthy on-chain data, the accuracy of data is\nthe main concern [44]. We have observed that review articles\nin this field generally classify oracles based on their opera-\ntional mechanisms, which can be broadly categorized into\nprovider identity-based and voting-based oracles. Identity-\nbased oracles involve specific implementation methods such\nas setting whitelists/blacklists, incorporating identity verifica-\ntion in transport layer protocols, or using machine learning\ntechniques to identify reliable and cost-effective oracles [45].\nMakerDao [46] is an example of this type of oracle. On the\nother hand, voting-based oracles incentivize providers to ex-\nhibit economically rational behavior and provide accurate\ndata through monetary rewards and penalties. Implementation\nmethods for voting-based oracles include peer-to-peer pre-\ndiction [47,48], reputation mechanisms [49], game-theoretic\napproach for price data verification [50,51], and others.\nWhile different approaches have been implemented, chal-\nlenges remain in ensuring data security. Identity-based oracles\nare vulnerable to single points of failure and bribery attacks.\nVoting-based oracles have limited applicability due to the\nneed for data verification, which restricts them to publicly\naccessible information. These oracles also face challenges\nlike data latency and high verification costs. Furthermore, the\ntimeliness and freshness of time-sensitive data are often over-\nlooked in current research, creating a dilemma in balancing\nsecurity and timeliness.\nAsset Bridge. Heterogeneous blockchains present a chal-\nlenge to achieving smooth interoperability in DeFi. Asset\nbridge is a solution for asset transfer and interoperability be-\ntween different blockchains. In the days that have passed in\n2023, the average daily trading volume of the asset bridge\nexceeded $214 million, with the highest daily trading volume\nreaching $1.232b (#DefiLlama), reflecting active trading ac-\ntivity in the business. The functioning of an asset bridge varies\ndepending on the implementation. Atomic swaps allow the\ndirect exchange of cryptocurrency across blockchains [52].\nRipple introduced the InterLedger protocol (ILP) in 2012,\nfacilitating cross-ledger interactions through third-party no-\ntaries. Pegged sidechains were proposed by the Bitcoin Core\ndevelopment team in 2014. Interoperability platforms such\nas Cosmos [53]and Polkadot [54] realize cross-chain commu-\nnication and interaction through relay chains or side chains.\nIn 2015, Joseph Poon and Thaddeus Dryja conceptualized\nthe Bitcoin Lightning Network. In 2016, BTC-Relay [55], a\ncross-chain solution based on a relay chain, achieved one-way\ncross-chain connectivity between Ethereum and Bitcoin [56].\nVitalik Buterin [57]\u2019s effort provided an in-depth analysis of\nblockchain interoperability issues. Notable cross-chain DeFi\napplications include Thorswap [58] and Chainswap [59].\n4\n3.2\nBasic Functions of DeFi\nStablecoin. The prices of cryptocurrencies are highly volatile,\nbut stablecoins offer price stability as they are pegged to fiat\ncurrencies, which is exactly why stablecoins were born. As\na foundational currency, stablecoins support liquidity pools,\nlending, insurance, and other financial activities [60], mitigat-\ning the risks associated with market fluctuations. As of Oct.\n2023, the stablecoin market contains a total market capitaliza-\ntion of over $120b and over 100 projects (#DefiLlama).\nStablecoins circulation involves reserve, insurance, and\nother essential links.Methods of forming stablecoins include\noff-chain reserves, such as USDT [61], USDC [62], and\nGUSD [63], on-chain collateralization like Dai [46] and\nLUSD [64], and algorithmic stablecoins without collater-\nalization such as AMPL [65], Basis [66], FRAX [67], and\nUST [68]. Among them, we have found that algorithmic sta-\nblecoins are a controversial object of research. While hav-\ning the advantages of high transparency and low/no collat-\neral rates, multiple algorithmic stablecoin crashes, including\nLuna-UST collapse in 2022 [69], have cast a shadow over this\nsolution. To address this challenge, Klages Mundt et al. [70]\npropose modeling-based approaches to enhance stablecoin\ndesign and resilience, ensuring price stability even amidst\nmarket shocks. Fu et al. [71] propose a rational Ponzi model\nto analyze the sustainability of algorithmic stablecoins.\nA critical issue we identified in stablecoin research is the\nlack of widely accepted definitions for stablecoins. Existing\nliterature often lacks clarity in defining what precisely consti-\ntutes a stablecoin. While some review articles discuss various\nimplementation approaches, they do not provide a definitive\ncore definition. Many papers focus on highlighting the desired\ncharacteristics and advantages of an ideal stablecoin, without\ndelving into a concrete definition. Only a few studies examine\nstablecoin definitions from a legislative perspective or attempt\nto model specific types of stablecoins.\nLending. DeFi lending abandons the centralized credit as-\nsessment framework but relies on recognized collateral for\npooling liquidity, enabling low-cost lending and arbitrage,\nand improving the transferability of debt holdings. DeFi lend-\ning has a large market, with a TLV of $14.782b and 300+\nApps (#DefiLlama). It allows borrowers to engage in trading\nactivities, while lenders can earn additional revenue via collat-\neral rates [72]. The primary motivation for users to use DeFi\nlending is to obtain participation rewards, such as governance\ntokens. In extreme cases, investors can form a borrowing\nspiral [73] or leverage spiral [74] to maximize benefit.\nDeFi lending apps typically involve collateralization, lend-\ning, and liquidation. Based on such a model, apps like Com-\npound [11] and AAVE [12], enable over-collateralized, trust-\nless DeFi lending. But out of the demand for low/zero collat-\neralization and regulatory requirements, undercollateralized\nlending is born, building credit on the blockchain and setting\nthe constraints for using the borrowed assets [75]. Solutions\nbased on credit assessment models [76,77] and incentive pun-\nishment mechanisms [78] are proposed, respectively. In the\nindustry, TrueFi [79], DeFi Passport [80], and CreDA [81]\nhave carried out the practice of on-chain credit assessment.\nFlash loans are DeFi\u2019s innovative non-collateralized lend-\ning tool and have various use cases, such as arbitrage, collat-\neral swapping, and self-liquidation [6]. Flash swaps provide\nsimilar services to flash loans within DEXs. Both flash loans\nand flash swaps leverage the atomicity of transactions, uti-\nlizing optimistic transfers that enable collateral-free loans or\ntoken exchange transactions as long as the loan is repaid by\nthe end of the block (illustrated in Figure 3).\nExchange. In traditional exchanges, market makers summa-\nrize trades based on the seller\u2019s request and the buyer\u2019s of-\nfer on the order book. Decentralized exchanges (DEXs) de-\ncentralize aggregation, clearing, and market making through\nblockchain [82,83]. More than 1000 apps have made DEXs\nthe most abundant application type in DeFi, with a TLV of\nUS$11.498b (#DefiLlama).\nDEX can be divided into different models based on the\nimplementation of trading pair discovery and order match-\ning [84]. These models include on-chain order book model\nas implemented by Stellar, off-chain order book model as\nimplemented by 0x [85], AirSwap [86], IDEX [87] and\ndYdX [10, 88], and non-order book model which is one\nof the most important innovations of DeFi. Methods of\nno-order book model, including reserve pool (implemented\nby KyberNetwork [89]) and algorithms of AMM like con-\nstant mean (adopted by Balancer [90]), constant product\n(adopted by Uniswap [9]), dynamic weighting(adopted by\nBancor [91]) and mixed-function algorithm(adopted by the\nCurve Finance [92]), have been implemented in the indus-\ntry. This is also one of the hottest research areas, includ-\ning reviews that categorically evaluate different implemen-\ntations [22, 93, 94] and specific algorithms that have been\nput into practice in the industry. We observe that empirical\nresearch is a kind of literature that is relatively lacking. There\nare some case studies on individual algorithms like [95], but\nthere is a lack of empirical studies based on extensive data.\n3.3\nServices of DeFi\nInspired by traditional derivatives, DeFi offers on-chain op-\ntions, asset management, and decentralized insurance by re-\nplacing traditional processes with on-chain automatic execu-\ntions [3]. New financial derivatives, such as perpetuity con-\ntracts and prediction markets, have also emerged.\nDeFi derivatives are a recent development in both industry\nand academia. However, compared to the industry\u2019s quick im-\nplementation and over US$1.8b TLV (#DefiLlama), research\non DeFi derivatives is limited, with only a few available pa-\npers. Empirical research in this field is almost non-existent,\nand most review articles focus on discussing the feasibility\nof DeFi derivatives. They emphasize the benefits compared\n5\nTable 1: DeFi Construction and Classification\nFeature\nProperty\nProject\nType\nTrust Model\nConnected Chains\nCentralization\nAnonymous\nTokenization\nTechnique\nStability\nScalability\nComplexity\nDigital Assets\nBitcoin [29]\nNative Crypocurrency\n-\nOne\n-\nM.\n-\nBC\n-\n-\n-\nEthereum [30]\n-\nOne\n-\nM.\n-\nBC\n-\n-\n-\nLitecoin\n-\nOne\n-\nM.\n-\nBC\n-\n-\n-\nMonero [96]\n-\nOne\n-\nH.\n-\nRing-sig, Stealth Address\n-\n-\n-\nZcash [97]\n-\nOne\n-\nH.\n-\nzk-Snark, Multi-sig\n-\n-\n-\nERC-20 [98]\nToken Standard\n-\nOne\nUp to Apps\nM.\n-\nSC\n-\n-\n-\nWallets\nLedger [42]\nCold Wallet\n-\nMultiple\n-\nM.\n-\nTEE\n-\n-\n-\nTrezor [43]\n-\nMultiple\n-\nH.\n-\nMulti-sig, 2FA\n-\n-\n-\nMetamask [99]\nHot Wallet\n-\nMultiple\n-\nH.\n-\nOffline Storage\n-\n-\n-\nZengo [100]\nTTP\nMultiple\n-\nM.\n-\nMPC-TSS, 3FA\n-\n-\n-\nArgent [101]\nTTP\nMultiple\n-\nH.\n-\nMulti-sig, 2FA\n-\n-\n-\nOracle\nMakerDao [46]\nAlliance Oracle, Stablecoin\nTTP\nOne\nDAO\nM.\nDai, MKR\nAllowlist\nH.\nM.\nL.\nChainlink [49]\nOff-chain Input\n-\nMultiple\n-\nM.\nLINK\nReputation, Staking\nH.\nH.\nM.\nNEST [51]\nFact Generation\n-\nOne\n-\nM.\nQP Token\nGame Theory\nH.\nM.\nH.\nBridges\nCosmos [53]\nBC Engine\nTTP\nMultiple\nHub\nH.\nATOM\nIBC\n-\nH.\nL.\nPolkadot [54]\nTTP\nMultiple\nValidator\nM.\nDOT\nParachain\n-\nH.\nL.\nBTC-relay [55]\nRelay\nTTP\nTwo\nMainchain\nM.\nETH-BTC\nSPV\n-\nM.\nM.\nPolygon Bridge [102]\nDApps Based\n-\nMultiple\n-\nM.\nPOL\nLock&Mint\n-\n-\n-\nThorSwap [58]\n-\nMultiple(Cosmos)\n-\nM.\nRUNE\nThird Party Chains, LP\n-\n-\n-\nStablecoins\nTether [61]\nOff-chain Reserve\n-\nMultiple\nIssuer\nL.\nUSDT\n-\nH.\nH.\nL.\nLiquity [64]\nOver-collateral\n-\nOne\n-\nM.\nLQTY, LUSD\n-\nM.\nM.\nM.\nAmpleforth [65]\nAlgorithmic\n-\nMultiple\n-\nM.\nAMPL\nQTM-based Algorithmic\nL.\nL.\nH.\nFrax Finance [67]\n-\nOne\n-\nM.\nFRAX, FXS\nAlgorithmic Seigniorage\nL.\nL.\nH.\nBasis [66]\n-\nOne\n-\nM.\nBAC, BAS, BAB\nAlgorithmic Seigniorage\nL.\nL.\nH.\nTerra [68]\n-\nOne\n-\nM.\nUST, LUNA\nParachain\nL.\nM.\nH.\nLendings\nAAVE [12]\nOver-collateral\n-\nMultiple\nNo\nM.\nAave\n-\n-\n-\n-\nCompound [11]\n-\nMultiple\nNo\nM.\nCOMP\n-\n-\n-\n-\nTrueFi [79]\nUnder-collateral\nTTP\nOne\nStaker\nM.\nTRU\n-\n-\n-\n-\nMaple Finance [103]\nTTP\nOne\nPool Delegates\nL.\nMPL\n-\n-\n-\n-\nExchanges\nStellar [104]\nOn-chain Orderbook\n-\nMultiple\n-\nM.\nXLM\nManual Matching\n-\nL.\n-\n0x [85]\nOff-chain Orderbook\n-\nMultiple\nOrderbook\nM.\nZRX\nManual Matching\n-\nM.\n-\ndYdX [10]\n-\nMultiple(Cosmos)\nOrderbook\nM.\nDYDX\nManual Matching\n-\nM.\n-\nKyberNetwork [89]\nNon-orderbook\n-\nOne\n-\nM.\nKNC\nReserve Pool\n-\nH.\n-\nBancor [91]\n-\nOne\n-\nM.\nBNT\nConstant product\n-\nH.\n-\nUniswap [9]\n-\nMultiple\n-\nM.\nUNI\nConstant mean\n-\nH.\n-\nBalancer [90]\n-\nOne\n-\nM.\nBAL\nDynamic weight\n-\nH.\n-\nCurve Finance [92]\n-\nOne\n-\nM.\nCRV\nHybrid function\n-\nH.\n-\nDerivatives\nOpium [105]\nOption\nTTP\nOne\nOrderbook\nM.\nOPIUM\nOff-chain Orderbook\n-\n-\n-\nOpyn [106]\n-\nOne\n-\nM.\nSqueeth\nAMM\n-\n-\n-\nHegic [107]\n-\nOne\n-\nM.\nHEGIC\nPeer-to-Pool\n-\n-\n-\nEnzyme [108]\nAsset Management\nTTP\nOne\nDAO/Manager\nM.\nMLN\nActive Asset Management\n-\n-\n-\nSet [109]\n-\nOne\n-\nM.\n-\nPassive Strategy, Social Trading\n-\n-\n-\nNexus Manual [37]\nInsurance\n-\nOne\n-\nM.\n-\nRisk Sharing Pool\n-\nH.\n-\nVouchForMe [110]\nTTP\nOne\n-\nM.\n-\nSocial Network Proof\n-\nH.\n-\nAugur [111]\n-\nOne\n-\nM.\nREP\nPrediction Market\n-\nH.\n-\nCDx [112]\n-\nOne\n-\nM.\nCDX, Cred\nTokenized CDS\n-\nL.\n-\nTokens [106]\n-\nOne\n-\nM.\noToken\nPut Option\n-\nL.\n-\nAugur [111]\nPrediction Market\n-\nOne\nStaker\nM.\nREP\nVoting\n-\n-\n-\nOmen [113]\n-\nOne\n-\nM.\nOWL\nConditional Tokens\n-\n-\n-\n\u2212= Does not provide property;\nAbbr.: BC = Blockchain; Tx = Transaction; SC = Smart Contracts; QTM = Quantity Theory of Money;\nLP = Liquity Pool; IBC = Inter-Blockchain Protocol; CDS = Credit Default Swap; H./M./L. = High/Medium/Low.\nto traditional solutions but lack evaluations of implemented\nsolutions. This may be related to the novelty of the field.\nAdditionally, there is a more substantial and earlier body\nof research related to DeFi insurance, possibly because of\nthe high level of decentralization and collateral involved in\nthe DeFi space, making risk management a crucial concern.\nFurthermore, frequent DeFi incidents have raised significant\nconcerns about the security of funds. Insurance is seen as a\nsignificant tool to mitigate risk and enhance capital security,\nwhich is why it received earlier attention and exploration. In\ncontrast, research on other types of DeFi derivatives, such as\noptions, perpetual contracts, and asset management, is rela-\n6\ntively scarce. This may be because insurance is a traditional\nfinancial instrument with well-established concepts and ap-\nplications, while other derivatives such as perpetual contracts\nare still in relatively early stages of development, involving\nmore technical and compliance challenges.\nOption. DeFi options enable the buying or selling of an asset\nat a predetermined price in the future through decentralized\nplatforms. The process is automated by smart contracts and\ninvolves two main participants: the buyer and the seller. DeFi\nmarkets offer higher efficiency and liquidity compared to tradi-\ntional options trading. These decentralized options protocols\ncater to investors seeking high-risk, high-leverage cryptocur-\nrencies for speculation, as well as traders looking for hedging\nand protection against volatile cryptocurrencies.\nThe workflow of DeFi options trading is similar to tradi-\ntional options, with two main players facilitated by smart con-\ntracts. Various solutions exist based on the matching process,\nincluding off-chain order matching models like Opium [105],\nwhere orders are handled off-chain and settled on-chain.\nAMM mechanisms are implemented by Opyn [106], while\nHegic adopts liquid sharing pools [107]. DeFi options en-\ncompass standardized European options, some non-standard\noptions, and over-the-counter (OTC) options. Deribit [114],\nOKEx [115], and other exchanges have launched standardized\noptions trading services. MatrixPort [116] offers \"watch cur-\nrency rise\" OTC options, while Babel Finance [117] provides\na \u201csharkfin\u201d capital-protected income management product\nbased on barrier options.\nAsset Management. DeFi asset management combines func-\ntions of digital assets, oracles, lending, and more DeFi apps\nto achieve asset management, portfolio management, and risk\nmanagement. It allows investors to delegate investment deci-\nsions to third parties while maintaining trustless functional-\nity. Smart contracts handle investments, trades, and portfolio\nadjustments based on investor requirements. DeFi asset man-\nagement offers low start-up costs, and quick set-up times, and\nenables anyone to become a fund manager or investor.\nDeFi asset management can be categorized as active or\npassive. Active asset management involves a professional\nteam making investment decisions and trades, for example,\nEnzyme [108]\u2019s managers or DAO members and Babylon\nFinance [118]\u2019s community governance. Passive asset man-\nagement such as Set [109] and Index Coop [119], on the other\nhand, allows users to create their own indices, structured prod-\nucts, and more in the form of smart contracts. Integrated\nplatforms combine active and passive ways, offering quantita-\ntive analysis with machine learning, such as SW DAO [120],\nKava DeFi Platform [121], and DAOventures [122].\nInsurance. DeFi insurance has the same working aspects as\ntraditional insurance, including creation, purchase, and claim\nof insurance. The differences between DeFi insurance and\ntraditional are that DeFi insurance enables all users to create\ntheir own insurance content as can be seen in Etherisc [123]\nand turns the decision on insurance claims into a transpar-\nent and verifiable process achieved through implementing\nshared pool models(e.g. Nexus Mutual [37]), social proof en-\ndorsement(e.g. VouchForMe [110]) or prediction markets(e.g.\nAugur [111]) and financial derivatives(e.g. oTokens [106]).\nInsurance is one of the most widely studied applications\nin DeFi derivatives. The review literature has discussed the\npotential [124] and risk [125] of blockchain technology in\nthe insurance industry and the possible application for the\nentire insurance process [126]. Various solutions have also\nbeen proposed including the construction of the entire frame-\nwork [127] and the enhancement of efficiency [128], verifia-\nbility [129], traceability [130] and other performance.\nPerpetual Contract. DeFi perpetual contracts allow partici-\npants to speculate or hedge against the price movements of an\nunderlying asset, similar to leveraged spot trades, but without\nan expiration date, and use a fund fee mechanism to track\nthe price index of the underlying asset. DeFi perpetual con-\ntracts are usually implemented as NFTs by smart contracts\nand can be traded in DEXs. Participants can be incentivized\nby providing liquidity and receiving rewards.\nPrediction Market. Prediction markets involve the creation,\ntrading, and settlement based on real-world event outcomes\nusing smart contracts. Participants are motivated by profit-\nsharing for accurate predictions and liquidity rewards. The\nrevenue in prediction markets is directly impacted by event\noutcomes, making it a significant incentive. To determine\nevent outcomes, prediction markets use incentive mechanisms\nlike reward and punishment or oracles providing real-world\ndata. Augur [111], for example, incentivizes accurate report-\ning through a dispute mechanism where the winner receives\nthe loser\u2019s staked tokens. Omen Prediction Market [113] intro-\nduced Reality.eth, a decentralized oracle challenging previous\nuser results to approach the truth.\n4\nTechnical Security Risks\nWe identified three types of technical security risks based on\nDeFi architectural design (Table 2): infrastructure layer risk,\nprotocol layer risk, and application layer attacks.\n4.1\nDeFi Infrastructural Layer\nRisks in Network Communication. DeFi relies on network\nprotocols like TCP/IP, which directly impact the security of\nnetworks. Attackers can exploit vulnerabilities, manipulate\nmessages, or control network service providers, posing risks\nto the security of transactions. Denial of Service (DoS) attacks\npose a threat where attackers may leverage network conges-\ntion to flood the system with invalid transactions or consume\nexcessive bandwidth and computing resources. Additionally,\nnode transparency risks such as Eclipse attacks [131] and\nSybil attacks [132] and centralized control by a few entities in\n7\n51% attacks [133] can undermine trust, security, and stability.\nResearchers have proposed various approaches to analyze\nnetwork security, including attack graph analysis [134,135]\nand mathematical models quantifying parameters like risk,\nvulnerability, and threat [136].\nRisks in Consensus Algorithm. Consensus algorithms en-\nable nodes to reach agreement on tasks such as transaction\nordering, block generation, and data validation. Nodes are in-\ncentivized with block rewards and transaction fees. However,\nthis decision-making power introduces uncertainty regarding\nthe transactions included in a block, which can be exploited\nby attackers through Miner Extractable Value (MEV) [24].\nWhile MEV can have legitimate uses, such as ensuring timely\nliquidation in lending protocols, facilitating accurate price\nformation, and arbitraging in DEX, it also creates problems\nfor users. MEV can result in advantageous forks over the\nmain chain [137, 138]. Attackers utilize MEV for front-\nrunning [139,140] or sandwich attacks [27], compromising\nfairness [141] and colluding with nodes for profit.\nForks. A fork occurs when the main chain splits into two\nseparate chains. The forked chain may have different security\nand stability, making it more susceptible to new vulnerabili-\nties and attacks. This can disrupt the compatibility of smart\ncontracts on both chains, requiring redevelopment and migra-\ntion. In DeFi, chain forks can fragment markets and reduce\nliquidity. Users may lose funds by mistakenly operating on\nthe wrong chain. Attackers can exploit forks to gain unearned\nrewards by overtaking and overwriting the main chain.\nFront-running. Front-running attacks (cf. Figure 5a) occur\nwhen an attacker predicts or monitors a user\u2019s transactions and\nsubmits their own transactions with higher priority, blocking\nothers and altering outcomes for additional profit [26,142].\nThey exploit blockchain transparency and transaction latency.\nThe bZx lending platform suffered a front-running attack in\nFeb. 2020, where attackers borrowed assets and sold them\nat manipulated prices, earning significant profits. Mitigation\nfront-running risks solutions include lightning networks for\noff-chain transactions, batch order processing to narrow the\nwindow and raise costs for attackers, sealed transactions to\nprevent eavesdropping, and fee market efficiency improve-\nment to reduce MEV and front-running profitability [143,144].\nFaaS like Flashbots enables traders to directly send transac-\ntions to miners, aiming to reduce front-running risks and give\nusers more control. However, Weintraub et al. [145] found\nthat over 80% of Ethereum\u2019s MEV occurs through Flashbots,\nraising questions about the feasibility of FaaS and potential\ncompetitive concerns for other participants.\nSandwich Attack. A sandwich attack [27] (cf. Figure 5b)\nis an exploitation tactic where an attacker executes coun-\nterparty trades before and after a target trade to profit from\nprice discrepancies and illiquidity. The attacker manipulates\nthe price by squeezing the low-cost trade between the target\ntrade [146]. Attackers monitor DEX order books and trading\nactivity to identify profitable opportunities and swiftly submit\nmempool\n           \ufffd\ufffd1\napprove Eve \n100 Token\n40 Gwei\nAlice\n          \ufffd\ufffd3\napprove Eve \n50 Token\n40 Gwei\n           \ufffd\ufffd2\nrevoke approve \nEve 50 Token\n40 Gwei\nEve\n\u2462 scan\n        \ufffd\ufffd\ufffd1  \ntransfer From\nAlice to Eve \n100 Token\n45 Gwei\n          \ufffd\ufffd\ufffd2\ntransfer From\nAlice to Eve \n50 Token\n40 Gwei\nBlock i\nBlock i+k\nExpected \norder\nActual \norder\n\u2463 discorver\n\u2460\n\u2461\n\u2464\n\ufffd\ufffd1\n\u2714\n\u2714\n\ufffd\ufffd\ufffd1\n\u2714\n\ufffd\ufffd3\n\u2714\n\u2714\n\ufffd\ufffd\ufffd2\n\u2714\n\ufffd\ufffd2\n\u2714\n\uff01\n(a) Front-running Attack\nmempool\n        \ufffd\ufffd1    use TokenB\n                 buy  x  Token\ufffd\n                 gas  g   Gwei\nAlice\nEve\n\u2461 scan\n        \ufffd\ufffd\ufffd1   use  TokenB\n                  buy  x  TokenA\n                  gas  g+1  Gwei\n        \ufffd\ufffd\ufffd2   sell  Token\ufffd\n                  for   TokenB\n                  gas   g   Gwei\nBlock i\nBlock i+k\n\ufffd\ufffd\ufffd1\n\ufffd\ufffd1\n\ufffd\ufffd\ufffd2\norder\n\u2462 discover\n   Token\ufffd\n   TokenB\n   Price1\n   Price2\n   Price3\n\u2463\n\u2460\n(b) Sandwich Attack\nFigure 5: Front-running and Sandwich Attack\ncounterparty trades for additional revenue. The main differ-\nence between sandwich attacks and front-running attacks is\nthe timing of target transaction execution and their respective\ntargets. Sandwich attacks impact prices by executing counter-\nparty trades simultaneously, causing unfair trading losses for\nthe target trader. Front-running attacks gain an advantage by\nsubmitting trades before execution, resulting in unfair trading\ncosts for other traders. Although confirming specific sand-\nwich attacks can be challenging, there have been reports of\nnumerous DeFi sandwich attacks exploiting illiquidity, price\nslippage, and execution delays on DEXs for additional profit.\n4.2\nDeFi Protocol Layer\nSmart contracts are vital for implementing and securing DeFi\nfunctions. However, they are vulnerable to common vulnera-\nbilities, which have been recognized by academia [147] and\nindustry [148]. Beyond coding, improper protocol design can\nalso introduce security risks.\nRisks in Writing Smart Contracts. Coding errors such as\narithmetic errors, conversion errors, inconsistent access con-\ntrol, and functional reentry are some representative vulnera-\nbilities in smart contracts [149,150].\nReentry. A reentry attack is a significant threat to smart con-\ntract security. Attackers exploit this vulnerability by repeat-\nedly executing a specific contract function and invoking ma-\nlicious contracts during each execution [151]. The attacker\ndeploys a malicious contract with callable functions into the\n8\ntarget contract and re-invokes it multiple times by calling a\nfunction of the target contract. This attack allows unautho-\nrized access to contract funds, modifies the contract status, or\nperforms other malicious actions. The DAO, a community-\nbased investment and fund allocation platform, experienced a\nreentry attack in 2016. The attacker successfully steals mil-\nlions of Ether by repeatedly calling the withdrawal function\nthrough a malicious contract. To prevent reentry attacks, the\nEthereum community has implemented improvements such\nas a \"backward transfer\" mode, modifiers to restrict external\ncontract calls, locking mechanisms, status markers, state vari-\nables, and lock flags to track and prevent re-calls of functions.\nOverflow. Overflow is common in smart contracts and can re-\nsult in unexpected money transfers, contract lockouts, or DoS.\nThese vulnerabilities include integer overflow, array overflow,\nand memory overflow. Attackers exploit integer overflow to\nalter contract states or transfer funds. Array overflow allows\nattackers to access other data in a contract\u2019s memory, leading\nto data tampering. Memory overflow can cause contract exe-\ncution failure. In 2018, attackers exploited an integer overflow\nvulnerability in BeautyChain, an Ethereum-based platform,\nresulting in the theft of approximately $3 million in cryp-\ntocurrency. Similarly, Meerkat Finance, a BSC-based lending\nprotocol, suffered a loss of $31 million in Mar. 2021 due to\nan overflow vulnerability. To prevent such vulnerabilities, de-\nvelopers should focus on boundary checking during coding\nand conduct thorough code reviews.\nRandom Numbers Misuse. Misuse of random numbers in\nsmart contracts can lead to security and fairness issues [152]\n[153]. Attackers exploit this vulnerability to predict or manip-\nulate outcomes, gaining unfair advantages. In 2018, hackers\nmanipulated the random number generator of the EOSPlay\ngambling contract on the EOS blockchain, receiving signifi-\ncant rewards. Insecure random numbers in functions like key\ngeneration compromise encryption algorithms. To prevent\nmisuse, developers should carefully assess the need for ran-\ndom numbers. Verifiable generators like Blockchain-based\nRandom Number Generators (BRNGs) and protocols like Dis-\ntributed Random Number Generation (DRNG) can enhance\nsecurity. Security audits and code reviews are also essential.\nRisks in Updating Smart Contracts. Smart contract up-\ndates pose potential issues and security risks such as contract\nmisbehavior, funds loss, contract unavailability, or reduced\nsecurity. Incompatibility between new and previous versions\ncan introduce vulnerabilities, hinder data migration, or disrupt\ncontract dependencies. Incorrect configuration parameters or\ntampering can lead to contract failures or unexpected out-\ncomes [154]. New permission mechanisms or access control\nrules may result in incorrect or overly permissive configu-\nrations, enabling unauthorized actions. Mismanagement of\nmultiple contract versions can lead to inconsistencies. For\ninstance, in April 2021, Uranium Finance on BSC suffered\nan attack due to neglected parameter changes during a con-\ntract upgrade. To prevent such issues, developers should plan,\ntest, audit upgrades, establish monitoring, and rollback mech-\nanisms to detect and mitigate problems promptly.\nRisks in Design of Protocols. Alongside code vulnerabili-\nties, security risks can arise from inadequate protocol design,\nincluding logical vulnerabilities, flawed economic models,\ninsufficient risk management, and inappropriate authorization.\nComplex algorithms or models may overlook specific scenar-\nios, impeding proper functionality. Economic models with\ninflationary, deflationary, or unfair revenue sharing may lead\nto revenue loss or instability. Insufficient risk management\nmeasures hinder responses to adverse events and risk miti-\ngation. In Jun. 2021, Iron Finance faced a crisis due to its\neconomic model when its governing token TITAN\u2019s price\ncollapsed. Massive selling of both TITAN and its stablecoin\nIRON triggered a mechanism that minted more TITAN as\nIRON\u2019s price dropped, intensifying the price drop and caus-\ning a death spiral. Furthermore, flawed designs may grant\nadministrators undue control, enabling manipulation or Rug\nPull. The Compounder Finance team misused administrator\nprivileges to replace audited contracts with malicious ones,\nresulting in the misappropriation of user funds.\n4.3\nDeFi Application Layer\nThe security risks of DeFi extend beyond the system\u2019s internal\nworkings to include external attacks towards asset bridges,\nirregular services provided by auxiliary applications like ora-\ncles, and users\u2019 misconceptions about smart contracts.\nRisks in Cross-chain. Cross-chain attacks exploit the mecha-\nnism of cross-chain transactions, posing risks to the security\nand stability of cross-chain DeFi apps. These attacks can lead\nto asset loss, transaction delays, and information tampering.\nThere are two main types of cross-chain attacks: native-chain\nattacks and inter-chain attacks. Native-chain attacks include\ndouble-spend attacks, false proof attacks, vulnerability ex-\nploits, reverse transaction attacks, and replay attacks [178].\nInter-chain attacks encompass relay blocking and inter-chain\nroute hijacking [181]. Payment channels may also be vulner-\nable to wormhole attacks, where intermediate node fees can\nbe stolen [183]. DeFi cross-chain applications face unique\nsecurity risks. Cross-chain smart contracts in DeFi apps are\nexposed to vulnerabilities in their own code and the calling\nrelationship between contracts. Price manipulation attacks\nand repeated borrowing and lending attacks are examples of\ncross-chain attacks faced by DeFi apps, as seen in the case of\nthe attack on PancakeSwap in Apr. 2021.\nRisks in Auxiliary Tools. Auxiliary services are entities that\npromote efficiency but are external to the system.\nOracle Manipulate. Oracle manipulation by hackers involves\nproviding false data to smart contracts, leading to improper\nbenefits or disruption of normal operations [187]. This manip-\nulation can result in negative consequences, including stable-\ncoin unanchoring, malicious carry trades, forced liquidation,\n9\nTable 2: Concerns and Solutions in DeFi Applications and Open Research Challenges\nIncidents\nResearch Perspective\nTechnical Security Risk\nAffected Layers\nAttacks\nTime\nApplication\nLoss\nSolutions\nTechnology\nSociology\nEconomy\nEcology\nInfrastructural\nLayer\nNetwork\nCommunication\nDos (DDoS) [155] [156]\n2020/05\nYoubi\nN/A\n[156] [157]\n\u2713\nEclipse Attack [131] [158]\n-\n-\n-\n[159]\n\u2713\nSybil Attack [132]\nVarious\nArbitrum\n253M ARB\n[160]\n\u2713\n51% Attack [133] [161]\n2020/04\nPegNet\n0.6M USD\n[162]\n\u2713\nConsensus\nAlgorithm\nFork [163] [139] [27]\n-\n-\n-\n[163]\n\u2713\n\u2713\nMEV\nFront-running Attack [26] [142]\n2021/03\nDODO\n0.7M USD\n[143] [144]\n\u2713\n\u2713\nSandwich Attack [146] [27]\n2021/10\nAlpha Homora V2\n40.93 ETH\n[164] [165]\n\u2713\n\u2713\nArbitrage Attack [166]\n2021/01\nSaddle Finance\n8 BTC\n[167]\n\u2713\n\u2713\nProtocol\nLayer\nSmart Contract\nReentry [168] [151]\n2016/06\nThe DAO\n3.6M ETH\n[151]\n\u2713\nOverflow [169] [170]\n2018/07\nBancor\n1.2M USD\n[171] [172]\n\u2713\nMisuse of Random Number [152] [153]\n2021/07\nAnySwap\n8M USD\n[172]\n\u2713\nProtocol\nRug Pull [173]\n2021/03\nMeerkat Finance\n20M USD\n[174]\n\u2713\n\u2713\nApplication\nLayer\nBridge\nDouble Spend Attack [175]\n2020/02\nDForce\n2.5M USD\n[176]\n\u2713\nFalse Proof Attack [175] [177]\n2022/02\nWormhole\n1.2M ETH\n[177]\n\u2713\nReplay Attack [178]\n2022/09\nOmniBridge\n2M ETHW\n[179] [180]\n\u2713\nInter-Chain Route Hijacking [181]\n-\n-\n-\n[182] [180]\n\u2713\nWormhole Attack [183]\n-\n-\n-\n[184]\n\u2713\nCross-chain Price Manipulation [185]\n2023/08\nNeutra Finance\n23.5 ETH\n[185] [186]\n\u2713\n\u2713\nAuxiliary Tools\nOracle Manipulation [187] [1] [44]\n2023/06\nThemis Protocol\n0.37M USD\n[188]\n\u2713\n\u2713\nUsage Method\nPhishing Attack [183] [189]\n2022/12\nBitkeep\n8M USD\n[190] [191]\n\u2713\n\u2713\n\u2713\nEconomic Risk\nReal Collapse/Incidents\nInfrastructural\n+ Protocol\n+ Applicatoin\nLayers\nLiquidity Depletion\n2019/09\nCompound\n-\n[192] [193]\n\u2713\nGovernance Risk\n2022/04\nBeanstalk\n77M USD\n[194] [195]\n\u2713\n\u2713\n\u2713\n\u2713\nMarket Manipulation\n2022/10\nMango\n114M USD\n[196] [197]\n\u2713\n\u2713\n\u2713\n\u2713\nFlashloan\nvarious\nvarious\nvarious\n[139] [7]\n\u2713\n\u2713\nDeath Spiral\n2022/05\nLuna-UST Collapse\n60B USD\n[198] [71]\n\u2713\nPonzi and Fraud\n2022/11\nFTX Collapse\n32B USD\n[199]\n\u2713\n\u2713\n\u2713\nCeFi Impact\n2023/03\nSVB Collapse\n23B USD\n[200] [201]\n\u2713\nand depleted protocol liquidity. Attackers target data sources\nby attacking API interfaces or tampering with supply chains.\nThey provide false or inaccurate data, modify prices or offer\nincorrect market information. To prevent oracle manipulation,\ndevelopers must prioritize secure and tamper-resistant oracles,\nalong with incentivizing their usage. Ensuring the quality of\nconnected markets is also crucial.\nRisks of Ignorance. Users\u2019 limited understanding of smart\ncontracts and their associated security risks can lead to unfore-\nseen circumstances [202]. Moreover, the shortage of security\nawareness makes them susceptible to phishing attacks, re-\nsulting in personal information leaks and fund theft [203].\nPhishing attacks in DeFi involve impersonating legitimate\nentities or creating deceptive environments like fake DeFi\nplatforms or sending fraudulent notifications to trick users\ninto revealing sensitive information, private keys, or login cre-\ndentials. For example, in Dec. 2021, Badger DAO suffered a\n$120 million loss due to a phishing attack involving malicious\nwallet requests. Similarly, in 2021, attackers stole assets by\nsharing fraudulent links on social media, leading users to a\nfake Uniswap website.\n5\nEconomic Security Risks\nDeFi economic risks stem from rational players\u2019 actions\nwithin the ecosystem, rather than traditional vulnerabilities.\nLiquidity Depletion. DeFi liquidity depletion risk occurs\nwhen there is a shortage of market liquidity, causing transac-\ntion delays, price fluctuations, and market instability. Insuffi-\ncient liquidity can result from adverse market conditions, in-\ncreased risk sentiment, or rapid fund withdrawals. Factors like\nmarket fluctuations, falling collateral prices, or manipulation\ncan also contribute to liquidity depletion. The Black Thursday\nevent in Mar. 2020, involving MakerDAO, exemplifies the\nconsequences of liquidity depletion [204]. To mitigate this\nrisk, DeFi platforms should attract diverse liquidity providers\nand reduce dependency on specific sources. Incentives can be\nimplemented to attract and retain liquidity providers [84,205].\nAdditionally, DeFi applications should develop risk manage-\nment strategies and contingency plans to address liquidity\ndepletion scenarios.\nFlashloan Attack. Flash loan security risks involve vul-\nnerabilities, contracts, and attack risks associated with flash\nloans [7,139]. We observed that such attacks occur frequently\nand can be categorized into code vulnerabilities, bid arbi-\ntrage, and price manipulation. Attackers exploit flash loans to\nexecute sophisticated strategies that exploit smart contract vul-\nnerabilities. Bid arbitrage manipulates transaction sequences\nto capitalize on arbitrage opportunities using borrowed funds.\nPrice manipulation involves using flash loan funds for large-\nscale trading, influencing prices. Defending against flash loan\nattacks requires managing protocol security, auditing con-\ntracts, and implementing measures like transaction order re-\nstrictions, delays, or time windows.\nMarket Manipulation. Market manipulation artificially in-\nfluences asset prices to profit. Illiquid assets pose higher risks\nto underlying financial products. Manipulative strategies in-\nclude spoofing [206], ramping [207], bear raids, cross-market\n10\nmanipulation, and oracle manipulation [188], which can ma-\nnipulate segments or the entire market. Market manipulation\nhas resulted in various negative impacts on the DeFi ecosys-\ntem, such as bad debts due to failure of timely liquidation,\nlosses for liquidity providers due to false price-based payouts\nin synthetic assets, and depeg for algorithm stablecoins [71].\nDistinguishing normal fluctuations from manipulation in\nDeFi is challenging due to anonymity, trading freedom, and\nregulatory gaps. Anonymous transactions hinder accurate\ntracking of participant behavior. Trading freedom and liq-\nuidity provision enable price influence through large-scale\ntransactions or exploiting limited market depth. Regulatory\ngaps and the lack of mechanisms like KYC requirements\nhamper monitoring manipulative behavior. To reduce mar-\nket manipulation risks in the DeFi market, it is necessary to\nstrengthen regulatory compliance and enhance investor edu-\ncation. Monitoring tools and algorithms can detect abnormal\ntrading patterns and manipulative behavior in a timely manner.\nStrengthening investor education can increase awareness of\nmarket risks, encouraging cautious participation.\nGovernance Risk. Governance and incentives can drive\nchoices that benefit DeFi apps. However, inadequate incen-\ntives may lead token holders to prioritize external gains, poten-\ntially harming the system. Immediate governance updates can\nbe vulnerable if malicious contract code is executed using ac-\nquired governance tokens. The Beanstalk protocol faced gov-\nernance risks when an attacker accumulated tokens and pro-\nposed a malicious proposal to divert funds. In Ethereum 2.0\n(post-Merge), validators face censorship pressure due to The\nOffice of Foreign Assets Control of the US Department of the\nTreasury(US OFAC) sanctions on Tornado Cash [208,209].\nDeath Spiral and Instability. Stablecoins aim to maintain a\nconsistent value by being pegged to a fiat currency. A \"death\nspiral\" refers to a scenario where a stablecoin rapidly and\nuncontrollably loses its value. This decline can trigger a com-\npounding effect, intensifying the downward spiral and eroding\nconfidence in the stablecoin, ultimately culminating in a self-\nperpetuating cycle of value deterioration. The concept of a\ndeath spiral is particularly relevant in crypto stablecoins, es-\npecially algorithmic ones. An example is the deppeg of UST,\nwhich led to the collapse of Luna\u2019s value in 2022 [71,198].\nThis event marked the onset of a \"crypto winter,\" a period of\nprolonged market decline and reduced investor optimism.\nPonzi and Fraud. The Ponzi game is named after Charles\nPonzi, who deceived investors with a postage stamp specu-\nlation scheme. It involves funding preexisting liabilities by\nissuing new debt. Ponzi schemes have infiltrated the crypto\nmarkets, especially during ICOs, IEOs, IDOs, and similar\nevents. A recent example is the FTX collapse [199] in 2022,\nwhere SVB sold FTT tokens to Alameda, a high-frequency\ntrading company under the same ownership, in an attempt to\ninflate token prices. Ponzi\u2019s collapse extends beyond immedi-\nate losses of rug pull with far-reaching implications.\nCeFi Impact. The crypto market has become increasingly\ninfluenced by macroeconomics, exhibiting a trajectory that\nparallels traditional stock markets. It is susceptible to the\nimpacts of conventional financial crises. The SVB (Silicon\nValley Bank) collapse [200,201] in early 2023 is an illustrative\ncase. SVB, a Centralized Finance (CeFi) bank for high-tech\nand crypto startups, experienced a crisis that resulted in the\nloss of deposits. This event eroded confidence in secure crypto\nasset storage methods and raised concerns about asset safety.\n6\nOpen Research Challenges\nObservation. There exists a time lag between the industry\nand academia, as industry innovation often precedes academic\nresearch. However, the implementation of DeFi in the industry\ncurrently is primarily driven by commercial intuition, lacking\ncomprehensive academic research in problem definition, the-\noretical analysis, mechanism design, and economic models.\nThis gap hinders theoretical innovation and the timely resolu-\ntion of emerging issues, limiting efficiency and sustainability.\nGap. The relative lag in academic research, particularly with\nregard to information security concerns, can result in potential\ninadequacies in the security assessment of newly emerging\nDeFi protocols. Accidents and risks that arise during the use\nof new technologies (emerging financial products) cannot be\nanticipated, forewarned, or prevented in advance, posing risks\nto user assets and impeding comprehensive development.\nRevenue. Therefore, further research on DeFi requires in-\ndepth exploration of new technologies and models, encom-\npassing different perspectives such as information security,\nand game theory mechanisms, and conducting systematic\nevaluations that are aligned with industry practices. To bridge\nthe gap between industry and academia, it is necessary to ad-\ndress the lack of research and validation tools in the academic\ncommunity. Academic researchers require models, simulation\ntools, and data analysis capabilities to establish and validate\nDeFi solutions. Effective data and analysis tools are needed\nto collect, organize, and analyze transaction and contract data.\nComprehensive security audit tools are also necessary to eval-\nuate the security of smart contracts and protocols. Joint efforts\nbetween academia and the industry can promote the develop-\nment and improvement of these tools. Academic researchers\ncan focus on developing models and simulation tools, while\nthe industry can provide real-time data and practical experi-\nence to support data and analysis tool development. Collabo-\nration between the academic community and security audit\nteams can enhance the security of DeFi projects by jointly\nresearching and developing security audit tools.\nGap. Regarding economic security concerns, the relative\nlag in academia has resulted in a lack of in-depth analysis and\ntheoretical modeling of economic interactions and mechanism\ndesigns in DeFi. Firstly, the industry lacks a proper under-\nstanding of participant behavior and incentive mechanisms,\n11\nleading to product designs that heavily rely on experience\nand intuition. Secondly, information asymmetry and incom-\nplete information exacerbate the industry\u2019s limited awareness\nand application of existing academic research. DeFi appli-\ncations lack guidance from economic equilibrium theories,\nleading to potential risks, instability, manipulation, attacks,\nand systemic risks. Inappropriate incentive structures and mar-\nket imbalances undermine the achievement of economic and\nsocietal objectives, efficiency, fairness, and sustainability.\nRevenue. The academic community should utilize analyti-\ncal tools such as economic equilibrium and game theory to\nestablish technical and economic models for DeFi applica-\ntions and conduct research on game mechanism design and\nanalysis. Progress can be made from multiple perspectives\nof economic modeling, mechanism design, and technical im-\nplementation, and combining theoretical analysis, practical\nsolutions, and empirical research.\nGap. Regardless of the improvement in technology, secu-\nrity, or economics in the field of DeFi, the interdisciplinary\nnature of DeFi cannot be overlooked. Collaboration between\neconomists, computer scientists, legal experts, and other stake-\nholders is crucial. As mentioned earlier, the limitations of a\nsingle-disciplinary perspective have been highlighted, and it\nhas been pointed out that the core issue lies in the insufficient\ndepth of interdisciplinary collaboration and the shortage of\ntalent with interdisciplinary expertise.\nRevenue. To address this issue, on one hand, it is neces-\nsary to encourage and facilitate interdisciplinary collabora-\ntion among experts from different disciplines through cross-\ndisciplinary projects or platforms. On the other hand, it is\nimportant to cultivate talents with multidisciplinary skills re-\nquired in DeFi research. Specifically, these talents need to\npossess expertise in areas such as blockchain, network secu-\nrity, code analysis, financial markets, investment analysis, risk\nmanagement, and financial technology, spanning disciplines\nlike economics, computer science, and cryptography.\nIn addition to the overall observations in DeFi mentioned\nabove, there are also research gaps and challenges in specific\naspects such as technological construction, sociological con-\nstruction, economic construction, and ecosystem construction.\nWe will elaborate on each of these areas (cf. Table 3).\nTable 3: Open Research Challenges\nDirection\nOpen Research Challenge\nLiterature (paper count)\nGeneral Tools\nDefinition and Model\n283, e.g., [1]\nDeFi Technical\nConstruction\nPerformance\n137, [210] [211] [212]\nFunction Integration Platforms\nN/A\nContract Audition\n600, [213] [214] [215]\nIncident Detection\n308, [216] [217] [218]\nDeFi Economy\nConstruction\nSustainable Tokenomics\n193, [219] [220] [221]\nBalanced Incentive\n122, [222] [223] [224]\nDeFi Sociology\nConstruction\nPrivacy\n216, [225] [226]\nCompliance\n75, [227] [228] [229]\nDeFi Ecology\nUser Engagement and Education\n11, [230] [231] [232] [233]\n6.1\nDeFi Technology Construction\nFunctionality. There are numerous protocols and function-\nalities in DeFi. Function integration platforms can provide\nunified access, simplifying user operations and enhancing user\nexperience. Their goals include user-friendly interfaces, pro-\ntocol integration, security, and interoperability for seamless\nasset and data transfers. However, these aspects have not been\nextensively explored by both the industry and the academic.\nResearch challenges for function integration platforms en-\ncompass staying updated and incorporating the developments\nand innovations, implementing better risk management prac-\ntices to adapt to the dynamic nature of the DeFi market, con-\nducting comprehensive security audits and vulnerability fixes,\nand addressing challenges related to interoperability, stability,\nand availability that arise from integrating multiple protocols.\nSecurity. DeFi security involves analyzing attack and threat\nmodels at the network [134\u2013136], smart contract [234] (sin-\ngle contract, multiple contracts, and contract audit [8]), proto-\ncol [235], and application layers [236,237].\nWe found that in-depth research on DeFi network commu-\nnication security, standardized evaluation, audit methods, and\ndefense strategies is lacking. Researchers can enhance DeFi\nsecurity by analyzing network topology, node communica-\ntion, and protocols like authentication, access control, and\nsecure smart contracts. Existing smart contract audit tools\nhave limitations in detecting complex attack strategies and\nadvanced vulnerabilities. Research is needed on tracking con-\ntract changes, conducting timely audits, and establishing secu-\nrity standards and best practices. Moreover, there is limited re-\nsearch on secure DeFi application models and security issues\narising from the collaboration between different applications.\nIncident Detection and Emergency Response. DeFi acts as\nan amplifier for information security issues and risks, making\ndisaster recovery and emergency response more urgent. Cur-\nrently, this is a relatively unexplored research field. Timely\nincident detection and handling are essential for protecting\nuser assets and the health of DeFi. Detecting incidents based\non historical data is commonly done, but real-time monitoring\nremains understudied. Future research should focus on devel-\noping intelligent monitoring systems that analyze data and\ntraffic patterns, using machine learning to identify abnormal\nactivities and risks in advance. Establishing effective incident\nresponse mechanisms, as well as post-incident cooperation\nand asset recovery protocols, are important research gaps.\n6.2\nDeFi Sociology Construction\nPrivacy. DeFi privacy protection aims to safeguard users\u2019\npersonal information, transaction data, and financial flows\nfrom unauthorized tracking, monitoring, and access. As the\nuser base expands, privacy concerns in DeFi become more\napparent, as existing analysis techniques can de-anonymize\npseudonyms and infer user identities from external informa-\n12\ntion on the blockchain [238,239]. Existing research explores\nprivacy-enhancing technologies such as zero-knowledge\nproofs (ZKPs) [240], ring signatures [33], Trusted Execution\nEnvironments (TEEs) for anonymous computation, crypto-\ngraphic techniques, and mixing schemes for transaction pri-\nvacy protection, as well as confidential smart contracts for data\nprivacy protection [21,241]. Initially applied to privacy coins\nlike Zerocoin [242], zero-knowledge proofs (ZKPs) such as\nzk-SNARKs [243] and Bulletproofs [244] have been utilized\nto enhance transaction privacy on the blockchain. Simpler\nand more efficient privacy coin schemes, including mixing\nschemes, have also been proposed. These technologies of-\nfer improved privacy protection, data security, anonymous\ntransactions, and smart contract verification in DeFi. How-\never, how these technologies can adapt to the specific and\ncomplex application scenarios in DeFi, enhance performance,\nand achieve scalability, remains an unresolved research ques-\ntion. Additionally, striking a balance between anonymity and\ntraceability to meet regulatory requirements poses significant\nchallenges. Readers interested in exploring privacy-enhancing\ntechnologies in DeFi are recommended to refer to relevant\nSystematization of Knowledge (SoK) papers [245].\nCompliance. Compliance in DeFi is vital for protecting funds\nfor users, ensuring stability for the system, and preventing ille-\ngal activities such as money laundering and terrorist financing\nfor regulators. However, the decentralized and permissionless\nnature of DeFi conflicts with compliance and regulation. For\ninstance, Tornado Cash faced sanctions by the US OFAC for\nenabling anonymous transfers used in illicit activities. Bal-\nancing these conflicting aspects poses a challenge. Moreover,\nthe rapid growth of DeFi requires the development of an\nappropriate compliance framework, including cross-border\ncooperation and leveraging technology for efficient processes.\n6.3\nDeFi Economy Construction\nSustainable Tokenomics. Token issuers should prioritize\nthe design and implementation of a cryptocurrency or token\necosystem that promotes long-term viability, equilibrium, and\npositive impact. Rather than engaging in deceptive practices,\ntheir focus should be on crafting mechanisms that enhance\neconomic stability, while incentivizing productive and sustain-\nable behaviors among token holders, users, and participants.\nInitiatives should be geared towards creating enduring value\nfor the token, rather than relying on short-term speculative\ngains. By contributing to a resilient token ecosystem charac-\nterized by responsible practices and sustainable growth, token\nissuers can foster a positive and sustainable impact.\nBalanced Incentive. Incentives hold a crucial role for to-\nken investors and holders. An effective incentive mechanism\nshould extend benefits to all participants, encompassing both\nregular users (utilizing mobile clients, light clients, or web\nbrowsers) and network contributors (such as miners, valida-\nInfrastractural\nLayer\nProtocol\nLayer\nApplication\nLayer\nDeFi\nEcology\nEconomic Security\nTechnical Security\nPrivacy\nCompliance\nUser Education\nUser Engagement\nFuntionality\nPerformance Issue\n(Speed, Scalability)\nOpen Research Challenges\nSustainable Tokenomics\nBalanced Incentive\nFigure 6: Open Research Challenges\ntors, and operators). Within the PoW consensus model, the\nmajority of regular users often find it challenging to secure\nstable rewards, given their limited impact on the network.\nIn contrast, miners wield substantial power, affording them\nthe ability to generate MEV revenues. Meanwhile, in PoS\nsettings, stakeholders have the opportunity to earn a steady\nincome. However, the issuance of tokens without associated\ncosts can lead to potential token issuance abuse. Striking a\nbalance between incentivizing network contributors while pre-\nventing token issuance abuse is crucial. This will create a fair\necosystem where rewards align with contributions, promoting\nhealthier and equitable participation from all stakeholders.\n6.4\nDeFi Ecology Construction\nUser Engagement and Education. User engagement and\nuser education are crucial for the DeFi ecosystem\u2019s growth.\nLow user engagement can lead to reduced liquidity, increased\ntransaction costs, and insufficient market depth, while user\nignorance can elevate the risk of fraud and attacks. Enhancing\nusability is paramount in addressing these challenges. The\nindustry should prioritize creating user-friendly interfaces and\nstreamlining processes to attract a broader user base. Addi-\ntionally, effective incentive mechanisms can encourage user\nparticipation and contributions. Comprehensive and easily\nunderstandable educational resources, including textbooks,\nonline courses and guides, must be made available. Establish-\ning a supportive community can further bolster user education\nby promoting collaboration and knowledge sharing, enabling\nusers to assist and support each other on their DeFi journey.\nConclusion. This paper presents a comprehensive litera-\nture review and proposes a classification framework based\non the complexity of DeFi services. We evaluate DeFi ap-\nplications and discuss their security from both technical and\neconomic perspectives. Furthermore, we identify research\ngaps and future directions, exploring relevant research topics.\n13\nReferences\n[1] Sam Werner, Daniel Perez, Lewis Gudgeon, Ariah\nKlages-Mundt, Dominik Harz, and William Knotten-\nbelt. SoK: Decentralized finance (DeFi). In ACM\nConference on Advances in Financial Technologies\n(AFT), pages 30\u201346, 2022.\n[2] Kaihua Qin, Liyi Zhou, Yaroslav Afonin, Ludovico\nLazzaretti, and Arthur Gervais.\nCeFi vs. DeFi\u2013\ncomparing centralized to decentralized finance. arXiv\npreprint arXiv:2106.08157, 2021.\n[3] Patrick Schueffel. DeFi: Decentralized finance-an in-\ntroduction and overview. Journal of Innovation Man-\nagement, 9(3):I\u2013XI, 2021.\n[4] Rujia Li, Qin Wang, Qi Wang, and David Galindo. How\ndo smart contracts benefit security protocols? arXiv\npreprint arXiv:2202.08699, 2022.\n[5] Guangsheng Yu et al.\nLeveraging architectural\napproaches in Web3 applications-a DAO perspec-\ntive focused. In IEEE International Conference on\nBlockchain and Cryptocurrency (ICBC), pages 1\u20136.\nIEEE, 2023.\n[6] Dabao Wang, Siwei Wu, Ziling Lin, Lei Wu, Xingliang\nYuan, Yajin Zhou, Haoyu Wang, and Kui Ren. Towards\nunderstanding flash loan and its applications in DeFi\necosystem.\nInternational Workshop on Security in\nBlockchain and Cloud Computing (SBC@AsiaCCS),\n2021.\n[7] Kaihua Qin, Liyi Zhou, Benjamin Livshits, and Arthur\nGervais.\nAttacking the DeFi ecosystem with flash\nloans for fun and profit. In International Conference\non Financial Cryptography and Data Security (FC),\npages 3\u201332. Springer, 2021.\n[8] Liyi Zhou, Xihan Xiong, Jens Ernstberger, Stefanos\nChaliasos, Zhipeng Wang, Ye Wang, Kaihua Qin,\nRoger Wattenhofer, Dawn Song, and Arthur Gervais.\nSoK: Decentralized finance (DeFi) attacks. IEEE Sym-\nposium on Security and Privacy (SP), 2023.\n[9] Hayden Adams, Noah Zinsmeister, Moody Salem,\nRiver Keefer, and Dan Robinson. Uniswap v3 core.\nTech. rep., Uniswap, Tech. Rep., 2021.\n[10] Antonio Juliano. dydx: A standard for decentralized\nmargin trading and derivatives. Retrieved from http\ns://whitepaper.dydx.exchange, 2018.\n[11] Compound Labs. Compound finance. Retrieved from\nhttps://compound.finance/, 2019.\n[12] AAVE. Aave protocol whitepaper v1.0. Retrieved\nfrom\nhttps://github.com/aave/aave-protoco\nl/blob/master/docs/Aave_Protocol_Whitepape\nr_v1_0.pdf, 2020.\n[13] Convex Finance. Convex. Retrieved from\nhttps:\n//www.convexfinance.com/, 2023.\n[14] Harvest Finance. Harvest finance document. Retrieved\nfrom https://docs.harvest.finance/, 2023.\n[15] Lido. Lido docs. Retrieved from https://docs.l\nido.fi/, 2023.\n[16] Rocket Pool.\nRocket pool documentation.\nRe-\ntrieved from\nhttps://docs.rocketpool.net/gu\nides/, 2023.\n[17] Amani Moin, Kevin Sekniqi, and Emin Gun Sirer. SoK:\nA classification framework for stablecoin designs. In\nInternational Conference on Financial Cryptography\nand Data Security (FC), pages 174\u2013197. Springer,\n2020.\n[18] Wenqi Zhao, Hui Li, and Yuming Yuan. Understand\nvolatility of algorithmic stablecoin: Modeling, verifi-\ncation and empirical analysis. In International Con-\nference on Financial Cryptography and Data Secu-\nrity Workshop on Decentralized Finance (DeFi@FC),\npages 97\u2013108. Springer, 2021.\n[19] Massimo Bartoletti, James Hsin-yu Chiang, and Al-\nberto Lluch Lafuente. SoK: Lending pools in decen-\ntralized finance. In International Conference on Fi-\nnancial Cryptography and Data Security Workshop on\nDecentralized Finance (DeFi@FC), pages 553\u2013578.\nSpringer, 2021.\n[20] Teng Andrea Xu and Jiahua Xu. A short survey on busi-\nness models of decentralized finance (defi) protocols.\nInternational Conference on Financial Cryptography\nand Data Security Workshop on Decentralized Finance\n(DeFi@FC), 2022.\n[21] Rujia Li et al. SoK: TEE-assisted confidential smart\ncontract. Proceedings on Privacy Enhancing Technolo-\ngies (PETs), 3:1\u201321, 2022.\n[22] Jiahua Xu, Krzysztof Paruch, Simon Cousaert, and\nYebo Feng.\nSoK: Decentralized exchanges (DEX)\nwith automated market maker (AMM) protocols. ACM\nComputing Surveys (CSUR), 55(11):1\u201350, 2023.\n[23] Yimika Erinle, Yathin Kethepalli, Yebo Feng, and\nJiahua Xu.\nSoK: Design, vulnerabilities and de-\nfense of cryptocurrency wallets.\narXiv preprint\narXiv:2307.12874, 2023.\n14\n[24] Kaihua Qin, Liyi Zhou, and Arthur Gervais. Quanti-\nfying blockchain extractable value: How dark is the\nforest? In IEEE Symposium on Security and Privacy\n(SP), pages 198\u2013214. IEEE, 2022.\n[25] Sen Yang, Fan Zhang, Ken Huang, Xi Chen, Youwei\nYang, and Feng Zhu.\nSoK: Mev countermeasures:\nTheory and practice. arXiv preprint arXiv:2212.05111,\n2022.\n[26] Shayan\nEskandari, Seyedehmahsa\nMoosavi, and\nJeremy Clark. SoK: Transparent dishonesty: Front-\nrunning attacks on blockchain. In International Con-\nference on Financial Cryptography and Data Security\n(FC), pages 170\u2013189. Springer, 2020.\n[27] Liyi Zhou, Kaihua Qin, Antoine Cully, Benjamin\nLivshits, and Arthur Gervais. On the just-in-time dis-\ncovery of profit-generating transactions in DeFi pro-\ntocols. In IEEE Symposium on Security and Privacy\n(SP), pages 919\u2013936. IEEE, 2021.\n[28] Qin Wang, Rujia Li, Qi Wang, Shiping Chen, and Yang\nXiang. Exploring unfairness on proof of authority:\nOrder manipulation attacks and remedies. In ACM on\nAsia Conference on Computer and Communications\nSecurity (AsiaCCS), pages 123\u2013137, 2022.\n[29] Satoshi Nakamoto. Bitcoin: A peer-to-peer electronic\ncash system. Decentralized Business Review, 2008.\n[30] Vitalik Buterin et al. A next-generation smart contract\nand decentralized application platform. white paper,\n3(37):2\u20131, 2014.\n[31] Litecoin Wiki contributors. Main page \u2014 litecoin\nwiki. Retrieved from https://litecoin.info/in\ndex.php/Main_Page, 2019.\n[32] Kurt M Alonso et al. Zero to monero, 2020.\n[33] Shi-Feng Sun, Man Ho Au, Joseph K Liu, and Tsz Hon\nYuen.\nRingct 2.0: A compact accumulator-based\n(linkable ring signature) protocol for blockchain cryp-\ntocurrency monero. In European Symposium on Re-\nsearch in Computer Security (ESORICS), pages 456\u2013\n474. Springer, 2017.\n[34] Abraham Hinteregger and Bernhard Haslhofer. An\nempirical analysis of monero cross-chain traceability.\nInternational Conference on Financial Cryptography\nand Data Security (FC), 2019.\n[35] Daira Hopwood, Sean Bowe, Taylor Hornby, and\nNathan Wilcox. Zcash protocol specification. GitHub:\nSan Francisco, CA, USA, 4:220, 2016.\n[36] George Kappos, Haaroon Yousaf, Mary Maller, and\nSarah Meiklejohn. An empirical analysis of anonymity\nin Zcash. In USENIX security symposium (USENIX\nSec), pages 463\u2013477, 2018.\n[37] Nexus Mutual.\nThe nexus mutual protocol.\nRe-\ntrieved from\nhttps://docs.nexusmutual.io/pr\notocol/, 2020.\n[38] ConsenLabs. imtoken. Retrieved from https://gi\nthub.com/consenlabs, 2023.\n[39] Minter Team. Bip wallet. Retrieved from https://\ngithub.com/MinterTeam/bip-wallet-web, 2023.\n[40] Wetez. Wetez. Retrieved from https://docs.wet\nez.io/wetez/, 2023.\n[41] Trust Wallet. Trust wallet developer documentation.\nRetrieved from\nhttps://developer.trustwalle\nt.com/developer/, 2023.\n[42] Ledger. Ledger developer portal. Retrieved from\nhttps://developers.ledger.com/, 2023.\n[43] Trezor company.\nTrezor hardware wallet (official).\nRetrieved from https://trezor.io/, 2013.\n[44] Torgin Mackinga, Tejaswi Nadahalli, and Roger Wat-\ntenhofer. Twap oracle attacks: Easier done than said?\nIn IEEE International Conference on Blockchain and\nCryptocurrency (ICBC), pages 1\u20138. IEEE, 2022.\n[45] Mona Taghavi, Jamal Bentahar, Hadi Otrok, and Kaveh\nBakhtiyari. A reinforcement learning model for the\nreliability of blockchain oracles. Expert Systems with\nApplications, 214:119160, 2023.\n[46] Maker Foundation. The maker protocol: Makerdao\u2019s\nmulti-collateral dai (mcd) system. Retrieved from\nhttps://makerdao.com/en/whitepaper/, 2023.\n[47] Yuxi Cai, Nafis Irtija, Eirini Eleni Tsiropoulou, and\nAndreas Veneris. Truthful decentralized blockchain or-\nacles. International Journal of Network Management,\n32(2):e2179, 2022.\n[48] Naman Goel, Aris Filos-Ratsikas, and Boi Faltings. De-\ncentralized oracles via peer-prediction in the presence\nof lying incentives, 2019.\n[49] Lorenz Breidenbach, Christian Cachin, Benedict Chan,\nAlex Coventry, Steve Ellis, Ari Juels, Farinaz Koushan-\nfar, Andrew Miller, Brendan Magauran, Daniel Moroz,\net al. Chainlink 2.0: Next steps in the evolution of de-\ncentralized oracle networks. Chainlink Labs, 1, 2021.\n[50] nestprotocol.org. Nest: Decentralized martingale net-\nwork. Retrieved from https://www.nestprotocol\n.org/doc/ennestwhitepaper.pdf, 2023.\n15\n[51] nestprotocol.org. Nest: Decentralized martingale net-\nwork. Retrieved from https://www.nestprotocol\n.org/doc/ennestwhitepaper.pdf, 2023.\n[52] Gang Wang et al. Exploring blockchains interoper-\nability: A systematic survey. ACM Computing Surveys\n(CSUR), 2023.\n[53] Jae Kwon and Ethan Buchman. Cosmos whitepaper.\nA Netw. Distrib. Ledgers, 27, 2019.\n[54] Gavin Wood. Polkadot: Vision for a heterogeneous\nmulti-chain framework. White paper, 21(2327):4662,\n2016.\n[55] Ethereum and Consensys. Btc-relay. Retrieved from\nhttp://btcrelay.org/, 2016.\n[56] BTC Relay. Frequently asked questions\u2014btc relay 1.0\ndocumentation. retrieved april 7, 2019, 2016.\n[57] Vitalik Buterin. Chain interoperability. R3 research\npaper, 9:1\u201325, 2016.\n[58] Thorchain.\nThorchain whitepapers.\nRetrieved\nfrom\nhttps://github.com/thorchain/Resourc\nes/tree/master/Whitepapers, 2021.\n[59] Bin Wang, Xiaohan Yuan, Li Duan, Hongliang Ma,\nChunhua Su, and Wei Wang.\nDefiscanner: Spot-\nting DeFi attacks exploiting logic vulnerabilities on\nblockchain. IEEE Transactions on Computational So-\ncial Systems (TCSS), pages 1\u201312, 2022.\n[60] Christian Catalini, Alonso de Gortari, and Nihar Shah.\nSome simple economics of stablecoins. Annual Review\nof Financial Economics, 14, 2022.\n[61] Tether.\nTether:\nFiat currencies on\nthe Bit-\ncoin\nblockchain.\nRetrieved\nfrom\nhttps:\n//assets.ctfassets.net/vyse88cgwfbl/5U\nWgHMvz071t2Cq5yTw5vi/c9798ea8db99311bf90e\nbe0810938b01/TetherWhitePaper.pdf, 2023.\n[62] Coinbase.\nUsdc: The dollar for the digital age.\nRetrieved from\nhttps://www.coinbase.com/usd\nc, 2023.\n[63] Gemini Trust Company. Gemini. Retrieved from\nhttps://www.gemini.com/dollar, 2023.\n[64] Liquity. Official liquity documentation. Retrieved\nfrom https://docs.liquity.org/, 2023.\n[65] Evan Kuo, Brandon Iles, and Manny Rincon Cruz. Am-\npleforth: A new synthetic commodity.\nAmpleforth\nWhite Paper, 2019.\n[66] Nader Al-Naji, Josh Chen, and Lawrence Diao. Basis: a\nprice-stable cryptocurrency with an algorithmic central\nbank. Retrieved from https://basis.io/basis_w\nhitepaper_en.pdf, 2017.\n[67] Sam Kazemian, Jason Huan, Jonathan Shomroni, and\nKedar Iyer. Frax: A fractional-algorithmic stablecoin\nprotocol. In 2022 IEEE International Conference on\nBlockchain (Blockchain), pages 406\u2013411. IEEE, 2022.\n[68] Evan Kereiakes, Marco Di Maggio Do Kwon, and\nNicholas Platias. Terra money: Stability and adoption.\nWhite Paper, Apr, 2019.\n[69] Antonio Briola, David Vidal-Tom\u00e1s, Yuanrong Wang,\nand Tomaso Aste.\nAnatomy of a stablecoin\u2019s fail-\nure: The terra-luna case. Finance Research Letters,\n51:103358, 2023.\n[70] Ariah Klages-Mundt and Andreea Minca. (in) stability\nfor the blockchain: Deleveraging spirals and stablecoin\nattacks, 2021.\n[71] Shange Fu et al.\nRational ponzi game in algorith-\nmic stablecoin. In IEEE International Conference on\nBlockchain and Cryptocurrency (ICBC), pages 1\u20136.\nIEEE, 2023.\n[72] Matthew Black, Tingwei Liu, and Tony Cai. Atomic\nloans: Cryptocurrency debt instruments. arXiv preprint\narXiv:1901.05117, 2019.\n[73] Viet-Bang Pham and Tuan-Dat Trinh. Analysis model\nfor decentralized lending protocols. In International\nSymposium on Information and Communication Tech-\nnology (SOICT), pages 405\u2013412, 2022.\n[74] Kanis Saengchote.\nDecentralized lending and its\nusers: Insights from compound.\narXiv preprint\narXiv:2212.05734, 2022.\n[75] Zhipeng Wang, Kaihua Qin, Duc Vu Minh, and Arthur\nGervais. Speculative multipliers on DeFi: Quantifying\non-chain leverage risks. In International Conference\non Financial Cryptography and Data Security (FC),\npages 38\u201356. Springer, 2022.\n[76] Wisnu Uriawan, Omar Hasan, Youakim Badr, and Li-\nonel Brunie. Collateral-free trustworthiness-based per-\nsonal lending on a decentralized application (DApp).\nIn SECRYPT, pages 839\u2013844, 2021.\n[77] Yining Xie, Xin Kang, Tieyan Li, Cheng-Kang Chu,\nand Haiguang Wang. Towards secure and trustworthy\nflash loans: A blockchain-based trust management ap-\nproach. In International Conference on Network and\nSystem Security (NSS), pages 499\u2013513. Springer, 2022.\n16\n[78] Vikas Hassija, Gaurang Bansal, Vinay Chamola, Neeraj\nKumar, and Mohsen Guizani.\nSecure lending:\nBlockchain and prospect theory-based decentralized\ncredit scoring model. IEEE Transactions on Network\nScience and Engineering (TNSE), 7(4):2566\u20132575,\n2020.\n[79] TrueFi. Truefi docs. Retrieved from https://docs\n.truefi.io/faq/, 2023.\n[80] Michael Elisha. Introducing arcx sapphire (v3). Re-\ntrieved from\nhttps://arcx.substack.com/p/in\ntroducing-arcx-sapphire-v3, 2021.\n[81] CreDA.\nCreda whitepaper: Turn data into wealth.\nRetrieved from https://creda-app.gitbook.io/\ncreda-protocol/introduction/creda-protoco\nl-whitepaper, 2022.\n[82] Andrea Barbon and Angelo Ranaldo. On the quality\nof cryptocurrency markets: Centralized versus decen-\ntralized exchanges. arXiv preprint arXiv:2112.07386,\n2021.\n[83] Jan Arvid Berg, Robin Fritsch, Lioba Heimbach, and\nRoger Wattenhofer. An empirical study of market inef-\nficiencies in Uniswap and SushiSwap. arXiv preprint\narXiv:2203.07774, 2022.\n[84] Lioba Heimbach, Ye Wang, and Roger Wattenhofer.\nBehavior of liquidity providers in decentralized ex-\nchanges. arXiv preprint arXiv:2105.13822, 2021.\n[85] Will Warren and Amir Bandeali. 0x: An open pro-\ntocol for decentralized exchange on the Ethereum\nblockchain. Retrieved from\nhttps://github.com\n/0xProject/whitepaper, 2017.\n[86] Michael Oved and Don Mosites. Swap: A peer-to-\npeer protocol for trading Ethereum tokens. Whitepaper\nDatabase, 21, 2017.\n[87] Aurora Labs. Idex: A real-time and high-throughput\nEthereum smart contract exchange.\nRetrieved\nfrom\nhttps://static1.squarespace.com/st\natic/5d641c0fc8f92f0001cd9358/t/5d691f20e\nb666000012a45a7/1567170337906/IDEX-White\npaper-V0.7.6.pdf, 2019.\n[88] StarkEx.\nStarkex documentation.\nRetrieved\nfrom\nhttps://docs.starkware.co/starkex/in\ndex.html, 2023.\n[89] Yaron Velner Loi Luu and Y Velner. Kybernetwork: A\ntrustless decentralized exchange and payment service.\nRetrieved from\nhttps://home.kyber.network/a\nssets/KyberNetworkWhitepaper.pdf, 2017.\n[90] Fernando Martinelli and Nikolai Mushegian. A non-\ncustodial portfolio manager, liquidity provider, and\nprice sensor. Retrieved from https://balancer.f\ninance/whitepaper, 2019.\n[91] Eyal Hertzog, Guy Benartzi, and Galia Benartzi. Ban-\ncor protocol: Continuous liquidity for cryptographic\ntokens through their smart contracts. Available online:\nhttps://storage.googleapis.com/website-b\nancor/2018/04/01ba8253-bancor_protocol_w\nhitepaper_en.pdf, 2017.\n[92] Michael Egorov and Curve Finance. Automatic market-\nmaking with dynamic peg, 2021.\n[93] Vijay Mohan. Automated market makers and decentral-\nized exchanges: a DeFi primer. Financial Innovation,\n8(1):20, 2022.\n[94] Guillermo Angeris and Tarun Chitra. Improved price\noracles: Constant function market makers. In ACM\nConference on Advances in Financial Technologies\n(AFT), pages 80\u201391, 2020.\n[95] Michael Egorov. Stableswap-efficient mechanism for\nstablecoin liquidity. Retrieved Feb, 24:2021, 2019.\n[96] The Monero Project.\nMoneropedia.\nRetrived\nfrom\nhttps://www.getmonero.org/resources/\nmoneropedia/, 2014.\n[97] Electric Coin Company. Zcash. Retrieved from http\ns://z.cash/learn/, 2016.\n[98] Fabian Vogelsteller and Vitalik Buterin. Erc-20: Token\nstandard. Retrieved from https://eips.ethereum.\norg/EIPS/eip-20, 2015.\n[99] MetaMask. The crypto wallet for defi, Web3 dapps\nand nfts. Retrieved from\nhttps://metamask.io/,\n2016.\n[100] Ouriel Ohayon. Zengo: What is zengo recovery kit?\nRetrieved from\nhttps://help.zengo.com/en/ar\nticles/2603673-what-is-zengo-recovery-kit,\n2018.\n[101] argentlabs.\nArgent smart wallet specification.\nRe-\ntrieved from\nhttps://github.com/argentlabs/\nargent-contracts/blob/develop/specificat\nions/specifications.pdf, 2021.\n[102] Polygon Bridge.\nMatic whitepaper.\nRetrieved\nfrom\nhttps://github.com/maticnetwork/whit\nepaper/, 2020.\n[103] Maple Labs. Maple finance. Retrieved from https:\n//maplefinance.gitbook.io/maple/, 2023.\n17\n[104] Stellar. Liquidity on stellar: Sdex and liquidity pools.\nRetrieved from\nhttps://developers.stellar.o\nrg/docs/encyclopedia/liquidity-on-stellar\n-sdex-liquidity-pools#sdex, 2023.\n[105] Opium Team. Opium protocol whitepaper. Retrieved\nfrom\nhttps://github.com/OpiumProtocol/opi\num-contracts/blob/master/docs/opium_whit\nepaper.pdf, 2020.\n[106] Zubin Koticha. Building a generalized liquid options\nprotocol in DeFi. Opyn, 2019.\n[107] Molly Wintermute. Hegic: On-chain options trading\nprotocol on Ethereum powered by hedge contracts and\nliquidity pools. Technical report, Tech. Rep., 2020.[On-\nline]. Available: https://github.com/hegic/whi\ntepaper~\u00e2\u02d8A\u02dbe, 2020.\n[108] Enzyme Finance. Enzyme user docs(v4). Retrieved\nfrom https://docs.enzyme.finance/, 2023.\n[109] F Feng and B Weickmann. Set: A protocol for baskets\nof tokenized assets, 2019.\n[110] Insurepal. Vouvhforme(insurepal) whitepaper. Re-\ntrieved from http://vouchforme.co/VouchForMe\n_whitepaper_2018.pdf, 2018.\n[111] Jack Peterson, Joseph Krug, Micah Zoltu, Austin K\nWilliams, and Stephanie Alexander. Augur: a decen-\ntralized oracle and prediction market platform. arXiv\npreprint arXiv:1501.01042, 2015.\n[112] CDx.\nCdx whitepaper.\nRetrieved from\nhttps://cdxproject.com/assets/resource\ns/whitepaper.pdf, 2018.\n[113] Omen. Omen. Retrieved from https://omen.eth\n.link/, 2020.\n[114] Deribit Insights. The best information for crypto deriva-\ntives trading. Retrieved from https://insights.d\neribit.com/, 2021.\n[115] OKX Team. Okx exchange. Retrieved from https:\n//wp.whitepaper.io/okx/, 2022.\n[116] Matrixport Technologies.\nMatrixport: All-in-one\ncrypto financial services platform. Retrieved from\nhttps://matrixport.com/, 2021.\n[117] Babel Finance. Babel business and solutions. Retrieved\nfrom\nhttps://babel.finance/solutions.html,\n2021.\n[118] Babylon Finance.\nBabylon litepaper.\nRetrieved\nfrom\nhttps://docs.babylon.finance/protoco\nl/litepaper, 2022.\n[119] Index Coop. The definitive guide to earning yield on\ndigital assets. Retrieved from https://indexcoop.\ncom/whitepapers/the-definitive-guide-to-e\narning-yield-on-digital-assets, 2020.\n[120] Sunlabs. Sw dao. Retrieved from https://www.su\nninvest.com/, 2020.\n[121] Kava.\nDeFi for crypto: Leverage assets with\nkava\u2019s cross-chain cdp platform.\nRetrieved from\nhttps://api-new.whitepaper.io/documents/p\ndf?id=Sk_Ny2S9v, 2022.\n[122] Daoventures.\nDaoventures whitepaper.\nRetrieved\nfrom\nhttps://daoventures.gitbook.io/daove\nntures/, 2022.\n[123] Simon Cousaert, Nikhil Vadgama, and Jiahua Xu.\nToken-based insurance solutions on blockchain. In\nBlockchains and the Token Economy: Theory and Prac-\ntice, pages 237\u2013260. Springer, 2022.\n[124] Fabrizio Lamberti, Valentina Gatteschi, Claudio De-\nmartini, Matteo Pelissier, Alfonso Gomez, and Vic-\ntor Santamaria. Blockchains can work for car insur-\nance: Using smart contracts and sensors to provide\non-demand coverage.\nIEEE Consumer Electronics\nMagazine, 7(4):72\u201381, 2018.\n[125] Andrew W Singer. Can blockchain improve insurance?\nRisk Management, 66(1):20\u201325, 2019.\n[126] Mayank Raikwar, Subhra Mazumdar, Sushmita Ruj,\nSourav Sen Gupta, Anupam Chattopadhyay, and Kwok-\nYan Lam. A blockchain framework for insurance pro-\ncesses. In IFIP International Conference on New Tech-\nnologies, Mobility and Security (NTMS), pages 1\u20134.\nIEEE, 2018.\n[127] Tancrede Lepoint, Gabriela Ciocarlie, and Karim Elde-\nfrawy. Blockcis\u2014a blockchain-based cyber insurance\nsystem. In IEEE International Conference on Cloud\nEngineering (IC2E), pages 378\u2013384. IEEE, 2018.\n[128] K Sayegh and M Desoky.\nBlockchain application\nin insurance and reinsurance. france: Skema business\nschool. Work in Progress papers, 2019.\n[129] Guoming Zhang, Xuyun Zhang, Muhammad Bilal,\nWanchun Dou, Xiaolong Xu, and Joel JPC Rodrigues.\nIdentifying fraud in medical insurance based on\nblockchain and deep learning. Future Generation Com-\nputer Systems (FGCS), 130:140\u2013154, 2022.\n[130] Chin-Ling Chen, Yong-Yuan Deng, Woei-Jiunn Tsaur,\nChun-Ta Li, Cheng-Chi Lee, and Chih-Ming Wu. A\ntraceable online insurance claims system based on\nblockchain and smart contract technology. Sustain-\nability, 13(16):9386, 2021.\n18\n[131] Ethan Heilman, Alison Kendler, Aviv Zohar, and\nSharon Goldberg. Eclipse attacks on {Bitcoin\u2019s}{peer-\nto-peer} network. In 24th USENIX security symposium\n(USENIX Sec), pages 129\u2013144, 2015.\n[132] John R. Douceur.\nThe sybil attack.\nIn Peer-to-\nPeer Systems, pages 251\u2013260, Berlin, Heidelberg, 2002.\nSpringer Berlin Heidelberg.\n[133] Muhammad Saad, Jeffrey Spaulding, Laurent Njilla,\nCharles Kamhoua, Sachin Shetty, DaeHun Nyang, and\nDavid Mohaisen.\nExploring the attack surface of\nblockchain: A comprehensive survey. IEEE Commu-\nnications Surveys & Tutorials (COMST), 22(3):1977\u2013\n2008, 2020.\n[134] Oleg Sheyner, Joshua Haines, Somesh Jha, Richard\nLippmann, and Jeannette M Wing. Automated genera-\ntion and analysis of attack graphs. In IEEE Symposium\non Security and Privacy (SP), pages 273\u2013284. IEEE,\n2002.\n[135] Lingyu Wang, Anoop Singhal, and Sushil Jajodia.\nToward measuring network security using attack\ngraphs. In ACM workshop on Quality of Protection\n(QoP@CCS), pages 49\u201354, 2007.\n[136] M Asif Khan and Mureed Hussain. Cyber security\nquantification model. In International Conference on\nSecurity of Information and Networks (SIN), pages 142\u2013\n148, 2010.\n[137] Daniel Perez and Benjamin Livshits. Smart contract\nvulnerabilities: Vulnerable does not imply exploited.\nIn USENIX Security Symposium (USENIX Sec), pages\n1325\u20131341, 2021.\n[138] Xinrui Zhang, Rujia Li, et al. Time-manipulation at-\ntack: Breaking fairness against proof of authority aura.\nIn Proceedings of the ACM Web Conference (WWWW),\npages 2076\u20132086, 2023.\n[139] Philip Daian, Steven Goldfeder, Tyler Kell, Yunqi Li,\nXueyuan Zhao, Iddo Bentov, Lorenz Breidenbach, and\nAri Juels. Flash boys 2.0: Frontrunning in decentral-\nized exchanges, miner extractable value, and consensus\ninstability. In IEEE Symposium on Security and Pri-\nvacy (SP), pages 910\u2013927. IEEE, 2020.\n[140] Ye Wang, Yan\nChen, Haotian\nWu, Liyi\nZhou,\nShuiguang Deng, and Roger Wattenhofer. Cyclic ar-\nbitrage in decentralized exchanges. In Companion\nProceedings of the Web Conference (WWW), pages\n12\u201319, 2022.\n[141] Rujia Li, Xuanwei Hu, et al.\nTransaction fairness\nin blockchains, revisited. Cryptology ePrint Archive,\n2023.\n[142] Christof Ferreira Torres, Ramiro Camino, et al. Fron-\ntrunner jones and the raiders of the dark forest: An\nempirical study of frontrunning on the Ethereum\nblockchain. In USENIX Security Symposium (USENIX\nSec), pages 1343\u20131359, 2021.\n[143] Peyman Momeni, Sergey Gorbunov, and Bohan Zhang.\nFairblock: Preventing blockchain front-running with\nminimal overheads. In International Conference on\nSecurity and Privacy in Communication Systems (Se-\ncureComm), pages 250\u2013271. Springer, 2022.\n[144] Xinrui Zhang et al. Frontrunning block attack in PoA\nClique: A case study. In IEEE International Confer-\nence on Blockchain and Cryptocurrency (ICBC), pages\n1\u20133. IEEE, 2022.\n[145] Ben Weintraub, Christof Ferreira Torres, Cristina Nita-\nRotaru, and Radu State. A flash (bot) in the pan: mea-\nsuring maximal extractable value in private pools. In\nProceedings of the 22nd ACM Internet Measurement\nConference, pages 458\u2013471, 2022.\n[146] Ye Wang, Patrick Zuest, Yaxing Yao, Zhicong Lu, and\nRoger Wattenhofer. Impact and user perception of sand-\nwich attacks in the DeFi ecosystem. In Proceedings of\nthe CHI Conference on Human Factors in Computing\nSystems (CHI), pages 1\u201315, 2022.\n[147] Purathani Praitheeshan, Lei Pan, Jiangshan Yu, Joseph\nLiu, and Robin Doss.\nSecurity analysis methods\non Ethereum smart contract vulnerabilities: a survey.\narXiv preprint arXiv:1908.08605, 2019.\n[148] Zhiyuan Wan, Xin Xia, David Lo, Jiachi Chen, Xiapu\nLuo, and Xiaohu Yang. Smart contract security: A\npractitioners\u2019 perspective. In IEEE/ACM International\nConference on Software Engineering (ICSE), pages\n1410\u20131422. IEEE, 2021.\n[149] Huashan Chen, Marcus Pendleton, Laurent Njilla, and\nShouhuai Xu. A survey on Ethereum systems security:\nVulnerabilities, attacks, and defenses. ACM Computing\nSurveys (CSUR), 53(3):1\u201343, 2020.\n[150] Nicola Atzei, Massimo Bartoletti, and Tiziana Cimoli.\nA survey of attacks on Ethereum smart contracts (SoK).\nIn International Conference on Principles of Security\nand Trust (POST), pages 164\u2013186. Springer, 2017.\n[151] Zexu Wang, Bin Wen, Ziqiang Luo, and Shaojie Liu.\nMAR: A dynamic symbol execution detection method\nfor smart contract reentry vulnerability. In Interna-\ntional Conference on Blockchain and Trustworthy Sys-\ntems (BlockSys), pages 418\u2013429. Springer, 2021.\n19\n[152] Daojing He, Zhi Deng, Yuxing Zhang, Sammy Chan,\nYao Cheng, and Nadra Guizani. Smart contract vul-\nnerability analysis and security audit. IEEE Network,\n34(5):276\u2013282, 2020.\n[153] Sunbeom So, Seongjoon Hong, and Hakjoo Oh.\nSmartest: Effectively hunting vulnerable transaction\nsequences in smart contracts through language model-\nguided symbolic execution. In USENIX Security Sym-\nposium (USENIX Sec), pages 1361\u20131378, 2021.\n[154] Mengya Zhang, Xiaokuan Zhang, Yinqian Zhang, and\nZhiqiang Lin.\nTxspector: Uncovering attacks in\nEthereum from transactions. In USENIX Security Sym-\nposium (USENIX Sec), 2020.\n[155] Michael Mirkin, Yan Ji, Jonathan Pang, Ariah Klages-\nMundt, Ittay Eyal, and Ari Juels. Bdos: Blockchain\ndenial-of-service.\nIn ACM SIGSAC conference on\nComputer and Communications Security (CCS), pages\n601\u2013619, 2020.\n[156] Rajasekhar Chaganti, Rajendra V. Boppana, Vinayaku-\nmar Ravi, Kashif Munir, Mubarak Almutairi, Furqan\nRustam, Ernesto Lee, and Imran Ashraf.\nA com-\nprehensive review of denial of service attacks in\nblockchain ecosystem and open challenges. IEEE Ac-\ncess, 10:96538\u201396555, 2022.\n[157] Mayank Raikwar and Danilo Gligoroski. Dos attacks\non blockchain ecosystem. In Euro-Par 2021: Paral-\nlel Processing Workshops, pages 230\u2013242. Springer\nInternational Publishing, 2022.\n[158] Karl W\u00fcst and Arthur Gervais. Ethereum eclipse at-\ntacks. Technical report, ETH Zurich, 2016.\n[159] Yuval Marcus, Ethan Heilman, and Sharon Goldberg.\nLow-resource eclipse attacks on Ethereum\u2019s peer-to-\npeer network. Cryptology ePrint Archive, 2018.\n[160] Bulat Nasrulin, Georgy Ishmaev, and Johan Pouwelse.\nMeritrank: Sybil tolerant reputation for merit-based\ntokenomics. In Conference on Blockchain Research\n& Applications for Innovative Networks and Services\n(BRAINS), pages 95\u2013102. IEEE, 2022.\n[161] Daniel J Moroz, Daniel J Aronoff, Neha Narula, and\nDavid C Parkes. Double-spend counterattacks: Threat\nof retaliation in proof-of-work systems. arXiv preprint\narXiv:2002.10736, 2020.\n[162] Martijn Bastiaan. Preventing the 51%-attack: a stochas-\ntic analysis of two phase proof of work in Bitcoin. In\nAvailab le at\nhttps://fmt.ewi.utwente.nl\n/media/175.pdf, 2015.\n[163] Kaihua Qin, Liyi Zhou, and Arthur Gervais. Quanti-\nfying blockchain extractable value: How dark is the\nforest? In IEEE Symposium on Security and Privacy\n(SP), pages 198\u2013214, 2022.\n[164] Patrick Z\u00fcst, Tejaswi Nadahalli, and Ye Wang Roger\nWattenhofer. Analyzing and preventing sandwich at-\ntacks in Ethereum. ETH Z\u00fcrich, 2021.\n[165] Lioba Heimbach and Roger Wattenhofer. Eliminating\nsandwich attacks with the help of game theory. In ACM\non Asia Conference on Computer and Communications\nSecurity (AsiaCCS), pages 153\u2013167, 2022.\n[166] Yuheng Wang, Jiliang Li, Zhou Su, and Yuyi Wang.\nArbitrage attack: Miners of the world, unite! In Inter-\nnational Conference on Financial Cryptography and\nData Security (FC), pages 464\u2013487. Springer, 2022.\n[167] Kushal Babel, Philip Daian, Mahimna Kelkar, and Ari\nJuels. Clockwork finance: Automated analysis of eco-\nnomic security in smart contracts. In IEEE Symposium\non Security and Privacy (SP), pages 2499\u20132516. IEEE,\n2023.\n[168] Baptiste Pretre.\nAttacks on peer-to-peer networks.\nDept. of Computer Science Swiss Federal Institute of\nTechnology (ETH) Zurich Autumn, 2005.\n[169] Wenkai Li, Jiuyang Bu, Xiaoqi Li, Hongli Peng,\nYuanzheng Niu, and Yuqing Zhang. A survey of DeFi\nsecurity: Challenges and opportunities. arXiv preprint\narXiv:2206.11821, 2022.\n[170] Kris Oosthoek.\nFlash crash for cash:\nCyber\nthreats in decentralized finance.\narXiv preprint\narXiv:2106.10740, 2021.\n[171] Jianjun Huang, Songming Han, Wei You, Wenchang\nShi, Bin Liang, Jingzheng Wu, and Yanjun Wu. Hunt-\ning vulnerable smart contracts via graph embedding\nbased bytecode matching. IEEE Transactions on Infor-\nmation Forensics and Security (TIFS), 16:2144\u20132156,\n2021.\n[172] Zhipeng Gao, Vinoj Jayasundara, Lingxiao Jiang, Xin\nXia, David Lo, and John Grundy. Smartembed: A tool\nfor clone and bug detection in smart contracts through\nstructural code embedding.\nIn IEEE International\nConference on Software Maintenance and Evolution\n(ICSME), pages 394\u2013397. IEEE, 2019.\n[173] Saulo Dos Santos, Japjeet Singh, Ruppa K Thulasiram,\nShahin Kamali, Louis Sirico, and Lisa Loud. A new era\nof blockchain-powered decentralized finance (DeFi)-\na review. In IEEE Annual Computers, Software, and\nApplications Conference (COMPSAC), pages 1286\u2013\n1292. IEEE, 2022.\n20\n[174] Bruno Mazorra, Victor Adan, and Vanesa Daza. Do not\nrug on me: Leveraging machine learning techniques\nfor automated scam detection. Mathematics, 10(6):949,\n2022.\n[175] Sung-Shine Lee, Alexandr Murashkin, Martin Derka,\nand Jan Gorzny. SoK: Not quite water under the bridge:\nReview of cross-chain bridge hacks. In IEEE Interna-\ntional Conference on Blockchain and Cryptocurrency\n(ICBC), pages 1\u201314. IEEE, 2023.\n[176] Kuheli Sai and David Tipper. Disincentivizing double\nspend attacks across interoperable blockchains.\nIn\nFirst IEEE International Conference on Trust, Privacy\nand Security in Intelligent Systems and Applications\n(TPS-ISA), pages 36\u201345. IEEE, 2019.\n[177] Maurice Herlihy, Barbara Liskov, and Liuba Shrira.\nCross-chain deals and adversarial commerce. arXiv\npreprint arXiv:1905.09743, 2019.\n[178] Alberto Sonnino, Shehar Bano, Mustafa Al-Bassam,\nand George Danezis.\nReplay attacks and defenses\nagainst cross-shard consensus in sharded distributed\nledgers. In IEEE European Symposium on Security\nand Privacy (EuroSP), pages 294\u2013308. IEEE, 2020.\n[179] Panpan Han, Zheng Yan, Wenxiu Ding, Shufan Fei,\nand Zhiguo Wan. A survey on cross-chain technolo-\ngies. Distributed Ledger Technologies: Research and\nPractice, 2(2):1\u201330, 2023.\n[180] Li Duan, Yangyang Sun, Wei Ni, Weiping Ding,\nJiqiang Liu, and Wei Wang. Attacks against cross-\nchain systems and defense approaches: A contempo-\nrary survey. IEEE/CAA Journal of Automatica Sinica,\n10(8):1647\u20131667, 2023.\n[181] Maqsood Ahamed Abdul Careem and Aveek Dutta.\nReputation based routing in manet using blockchain. In\nInternational Conference on COMmunication Systems\n& NETworkS (COMSNETS), pages 1\u20136. IEEE, 2020.\n[182] Zhuo Lv, Di Wu, Wen Yang, and Li Duan. Attack and\nprotection schemes on fabric isomorphic crosschain\nsystems. International Journal of Distributed Sensor\nNetworks, 18(1):15501477211059945, 2022.\n[183] Giulio Malavolta, Pedro Moreno-Sanchez, Clara\nSchneidewind, Aniket Kate, and Matteo\nMaffei.\nAnonymous multi-hop locks for blockchain scalability\nand interoperability. Cryptology ePrint Archive, 2018.\n[184] Yangyang Sun, Longyang Yi, Li Duan, and Wei Wang.\nA decentralized cross-chain service protocol based on\nnotary schemes and hash-locking. In IEEE Interna-\ntional Conference on Services Computing (SCC), pages\n152\u2013157. IEEE, 2022.\n[185] Christopher G Harris. Cross-chain technologies: Chal-\nlenges and opportunities for blockchain interoperabil-\nity. In 2023 IEEE International Conference on Omni-\nlayer Intelligent Systems (COINS), pages 1\u20136. IEEE,\n2023.\n[186] Siwei Wu, Dabao Wang, Jianting He, Yajin Zhou, Lei\nWu, Xingliang Yuan, Qinming He, and Kui Ren. Defi-\nRanger: Detecting price manipulation attacks on DeFi\napplications. arXiv preprint arXiv:2104.15068, 2021.\n[187] Liya Su, Xinyue Shen, Xiangyu Du, Xiaojing Liao,\nXiaoFeng Wang, Luyi Xing, and Baoxu Liu.\nEvil\nunder the sun: Understanding and discovering attacks\non Ethereum decentralized applications. In USENIX\nSecurity Symposium (USENIX Sec), pages 1307\u20131324,\n2021.\n[188] Shayan Eskandari, Mehdi Salehi, Wanyun Catherine\nGu, and Jeremy Clark. SoK: Oracles from the ground\ntruth to market manipulation. In ACM Conference\non Advances in Financial Technologies (AFT), pages\n127\u2013141, 2021.\n[189] Philipp Winter, Anna Harbluk Lorimer, Peter Snyder,\nand Benjamin Livshits. What\u2019s in your wallet? pri-\nvacy and security issues in web 3.0. arXiv preprint\narXiv:2109.06836, 2021.\n[190] Shucheng Li, Fengyuan Xu, Runchuan Wang, and\nSheng Zhong. Self-supervised incremental deep graph\nlearning for Ethereum phishing scam detection. arXiv\npreprint arXiv:2106.10176, 2021.\n[191] Jinhuan Wang, Pengtao Chen, Xinyao Xu, Jiajing Wu,\nMeng Shen, Qi Xuan, and Xiaoniu Yang. Tsgn: Trans-\naction subgraph networks assisting phishing detection\nin Ethereum. arXiv preprint arXiv:2208.12938, 2022.\n[192] alethio. Illiquidity and bank run risk in defi. Retrieved\nfrom\nhttps://medium.com/alethio/overlooke\nd-risk-illiquidity-and-bank-runs-on-compo\nund-finance-5d6fc3922d0d, 2019.\n[193] Sirio\nAramonte, Wenqian\nHuang, and Andreas\nSchrimpf. Defi risks and the decentralisation illusion.\nBIS Quarterly Review, 2021.\n[194] Beanstalk Farms. Beanstalk governance exploit. Re-\ntrieved from\nhttps://bean.money/blog/beanst\nalk-governance-exploit, 2022.\n[195] Brian Sanya Mondoh, Sara M Johnson, Matthew Green,\nand Aris Georgopoulos. Decentralised autonomous\norganisations: The future of corporate governance or an\nillusion? Aris (Aristeidis), Decentralised Autonomous\nOrganisations: The Future of Corporate Governance\nor an Illusion, 2022.\n21\n[196] Nathan Reiff.\nCryptocurrency spoofing: How\nit works, protecting yourself.\nRetrieved from\nhttps://www.investopedia.com/tech/what-c\nryptocurrency-spoofing/, 2021.\n[197] Raphael Auer, Jon Frost, and Jose Mar\u00eda Vidal Pastor.\nMiners as intermediaries: extractable value and market\nmanipulation in crypto and defi. Technical report, Bank\nfor International Settlements, 2022.\n[198] David S Kerr, Karen A Loveland, Katherine Taken\nSmith, and Lawrence Murphy Smith. Cryptocurrency\nrisks, fraud cases, and financial performance. Risks,\n11(3):51, 2023.\n[199] Shange Fu, Qin Wang, Jiangshan Yu, and Shiping\nChen. FTX collapse: a Ponzi story. arXiv preprint\narXiv:2212.09436, 2022.\n[200] Imran Yousaf, Yasir Riaz, and John W Goodell. The\nimpact of the SVB collapse on global financial markets:\nSubstantial but narrow. Finance Research Letters, page\n103948, 2023.\n[201] Qin Wang, Guangsheng Yu, and Shiping Chen. Cryp-\ntocurrency in the aftermath: Unveiling the impact of\nthe SVB collapse. HAL-04216338, 2023.\n[202] CoinGeco. Coingecko yield farming survey 2020. Re-\ntrieved from\nhttps://www.coingecko.com/,\n2020.\n[203] Fabian Sch\u00e4r. Decentralized finance: On blockchain-\nand smart contract-based financial markets. FRB of St.\nLouis Review, 2021.\n[204] Qin Wang, Guangsheng Yu, Yilin Sai, Caijun Sun,\nLam Duc Nguyen, Sherry Xu, and Shiping Chen. An\nempirical study on Snapshot DAOs. arXiv preprint\narXiv:2211.15993, 2022.\n[205] Lioba Heimbach, Eric Schertenleib, and Roger Wat-\ntenhofer. Risks and returns of Uniswap v3 liquidity\nproviders. ACM Conference on Advances in Financial\nTechnologies (AFT), 2022.\n[206] Federico Cernera, Massimo La Morgia, Alessandro\nMei, and Francesco Sassi. Token spammers, rug pulls,\nand sniperbots: An analysis of the ecosystem of to-\nkens in Ethereum and the Binance smart chain (BNB).\nUSENIX Security Symposium (USENIX Sec), 2023.\n[207] Jiahua Xu and Benjamin Livshits. The anatomy of a\ncryptocurrency Pump-and-Dump scheme. In USENIX\nSecurity Symposium (USENIX Sec), pages 1609\u20131625,\n2019.\n[208] Zhipeng Wang, Xihan Xiong, and William J Knotten-\nbelt. Blockchain transaction censorship:(in) secure and\n(in) efficient? Cryptology ePrint Archive, 2023.\n[209] Anton Wahrst\u00e4tter, Jens Ernstberger, Aviv Yaish, Liyi\nZhou, Kaihua Qin, Taro Tsuchiya, Sebastian Steinhorst,\nDavor Svetinovic, Nicolas Christin, Mikolaj Barczen-\ntewicz, et al. Blockchain censorship. arXiv preprint\narXiv:2305.18545, 2023.\n[210] Bogdan Florin Cornea, Julien Bourgeois, The Tung\nNguyen, and Didier El-Baz. Scalable performance\npredictions of distributed peer-to-peer applications. In\nIEEE International Conference on High Performance\nComputing and Communication & IEEE International\nConference on Embedded Software and Systems, pages\n193\u2013201, 2012.\n[211] Shuai Yang and Wei Cui. An evaluation system for\ndefi lending protocols. In 2023 42nd Chinese Control\nConference (CCC), pages 8888\u20138893, 2023.\n[212] Mengqi Hao and Jingzhi Ding. Decision-making and\nimpact of blockchain on accounts receivable financ-\ning. In LISS 2021, pages 465\u2013477, Singapore, 2022.\nSpringer Nature Singapore.\n[213] Lohith J. J, Anusree Manoj K, Guru Nanma P, and\nPooja Srinivasan. Tp-detect: trigram-pixel based vul-\nnerability detection for ethereum smart contracts. Mul-\ntimedia Tools and Applications, 82(23):36379\u201336393,\n2023.\n[214] Lejun Zhang, Yuan Li, Ran Guo, Guopeng Wang, Jing\nQiu, Shen Su, Yuan Liu, Guangxia Xu, Huiling Chen,\nand Zhihong Tian. A novel smart contract reentrancy\nvulnerability detection model based on bigas. Journal\nof Signal Processing Systems, 2023.\n[215] Chuang Ma, Shuaiwu Liu, and Guangxia Xu. Hgat:\nsmart contract vulnerability detection method based on\nhierarchical graph attention network. Journal of Cloud\nComputing, 12(1):93, 2023.\n[216] Ke Ye, Meng Shen, Zhenbo Gao, and Liehuang Zhu.\nReal-time detection of cryptocurrency mining behavior.\nIn Blockchain and Trustworthy Systems, pages 278\u2013\n291, Singapore, 2022. Springer Nature Singapore.\n[217] P. Mercy Praise, S. Basil Xavier, Anoop Jose, G. Jas-\npher W. Kathrine, and J. Andrew. Variants of crypto-\njacking attacks and their detection techniques. In Appli-\ncations and Techniques in Information Security, pages\n71\u201387, Singapore, 2023. Springer Nature Singapore.\n[218] Xun Sun, Xi Xiao, Wentao Xiao, Bin Zhang, Guangwu\nHu, and Tian Wang. Short and distort manipulations\nin the cryptocurrency market: Case study, patterns and\n22\ndetection. In Algorithms and Architectures for Paral-\nlel Processing, pages 494\u2013508, Cham, 2022. Springer\nInternational Publishing.\n[219] Oleksandr Letychevskyi, Volodymyr Peschanenko,\nMaksym Poltoratskyi, and Yuliia Tarasich. Our ap-\nproach to formal verification of token economy mod-\nels. In Information and Communication Technologies\nin Education, Research, and Industrial Applications,\npages 348\u2013363, Cham, 2020. Springer International\nPublishing.\n[220] Li Zhihong and Zhang Jie. Online knowledge commu-\nnity governance based on blockchain token incentives.\nIn Knowledge and Systems Sciences, pages 64\u201372, Sin-\ngapore, 2019. Springer Singapore.\n[221] Philipp Lesche, Philipp Sandner, and Horst Treiblmaier.\nImplications of the Token Economy: A Taxonomy and\nResearch Agenda, pages 1\u201330. Springer International\nPublishing, Cham, 2022.\n[222] Liu B., Zhou J., and Z. Lim Y. Being accountable\nnever cheats: An incentive protocol for DeFi oracles.\nIn IEEE International Conference on Decentralized\nApplications and Infrastructures (DAPPS), pages 1\u201310,\n2022.\n[223] Chenquan Gan, Akanksha Saini, Qingyi Zhu, Yong\nXiang, and Zufan Zhang. Blockchain-based access\ncontrol scheme with incentive mechanism for ehealth\nsystems: patient as supervisor. Multimedia Tools and\nApplications, 80(20):30605\u201330621, 2021.\n[224] Aljosha Judmayer, Nicholas Stifter, Alexei Zamyatin,\nItay Tsabary, Ittay Eyal, Peter Ga\u017ei, Sarah Meiklejohn,\nand Edgar Weippl. Sok: Algorithmic incentive manip-\nulation attacks on permissionless PoW cryptocurren-\ncies. In Financial Cryptography and Data Security\nWorkshops, pages 507\u2013532, Berlin, Heidelberg, 2021.\nSpringer Berlin Heidelberg.\n[225] Zhiyu Xu, Minfeng Qi, Ziyuan Wang, Sheng Wen,\nShiping Chen, and Yang Xiang. Ib2p: An image-based\nprivacy-preserving blockchain model for financial ser-\nvices.\nIn 2021 IEEE International Conference on\nBlockchain (Blockchain), pages 552\u2013558, 2021.\n[226] Janka Hartmann and Omar Hasan. Privacy considera-\ntions for a decentralized finance (defi) loans platform.\nCluster Computing, 26(4):2147\u20132161, 2023.\n[227] St\u00e9phane Blemus. The compatibility of cbdcs with\n\u201cdefi\u201d protocols: A governance rather than a technolog-\nical issue to comply with financial crime regulations. In\nFinancial Cryptography and Data Security Workshops,\npages 97\u2013105, Cham, 2023. Springer International Pub-\nlishing.\n[228] Ryosuke Ushida and James Angel. Regulatory consid-\nerations on centralized aspects of defi managed by daos.\nIn Financial Cryptography and Data Security Work-\nshops, pages 21\u201336, Berlin, Heidelberg, 2021. Springer\nBerlin Heidelberg.\n[229] Jos\u00e9 Carlos Laguna De Paz. Some implications of the\nnew global digital economy for financial regulation and\nsupervision. Journal of Banking Regulation, 24(2):146\u2013\n155, 2023.\n[230] Dieter Reichert. How customer communications and\ninteractions become digital assets and critical resources\nin customer engagement \u2014 an interview with dieter\nreichert, co-founder of censhare ag. Journal of Digital\nAsset Management, 6(4):232\u2013242, 2010.\n[231] Chetan Saiya. Dam in marketing operations and the\nemergence of customer engagement objects \u2013 an inter-\nview with chetan saiya, ceo of assetlink. Journal of\nDigital Asset Management, 6(2):124\u2013129, 2010.\n[232] Paul Medeiros and Leonidas Deligiannidis. An ed-\nucational guide to creating your own cryptocurrency.\nIn Advances in Software Engineering, Education, and\ne-Learning, pages 163\u2013177, Cham, 2021. Springer In-\nternational Publishing.\n[233] Shi Y., Shahriar H., Lo D., and Chi H. Enhancing\nblockchain technology education with innovative ac-\ntive learning. In 2022 IEEE 2nd International Confer-\nence on Advanced Learning Technologies on Educa-\ntion & Research (ICALTER), pages 1\u20134, 2022.\n[234] Petar Tsankov, Andrei Dan, Dana Drachsler-Cohen,\nArthur Gervais, Florian Buenzli, and Martin Vechev.\nSecurify: Practical security analysis of smart contracts.\nIn Proceedings of the ACM SIGSAC conference on\nComputer and Communications Security (CCS), pages\n67\u201382, 2018.\n[235] Shehar Bano, Alberto Sonnino, Mustafa Al-Bassam,\nSarah Azouvi, Patrick McCorry, Sarah Meiklejohn,\nand George Danezis. SoK: Consensus in the age of\nblockchains. In Proceedings of the ACM Conference\non Advances in Financial Technologies (AFT), pages\n183\u2013198, 2019.\n[236] Zeinab Amin. A practical road map for assessing cyber\nrisk. Journal of Risk Research, 22(1):32\u201343, 2019.\n[237] Daniel W Woods and Rainer B\u00f6hme. SoK: Quantify-\ning cyber risk. In IEEE Symposium on Security and\nPrivacy (SP), pages 211\u2013228. IEEE, 2021.\n[238] Sarah Meiklejohn, Marjori Pomarole, Grant Jordan,\nKirill Levchenko, Damon McCoy, Geoffrey M Voelker,\nand Stefan Savage. A fistful of bitcoins: characterizing\n23\npayments among men with no names. In Proceed-\nings of the 2013 conference on Internet measurement\nconference, pages 127\u2013140, 2013.\n[239] Elli Androulaki, Ghassan O Karame, Marc Roeschlin,\nTobias Scherer, and Srdjan Capkun. Evaluating user\nprivacy in bitcoin. In International Conference on Fi-\nnancial Cryptography and Data Security, pages 34\u201351,\nBerlin, Heidelberg, 2013. Springer, Springer Science\n& Business Media.\n[240] Zhipeng Wang, Stefanos Chaliasos, Kaihua Qin, Liyi\nZhou, Lifeng Gao, Pascal Berrang, Benjamin Livshits,\nand Arthur Gervais. On how zero-knowledge proof\nblockchain mixers improve, and worsen user privacy.\nIn Proceedings of the ACM Web Conference (WWW),\npages 2022\u20132032, 2023.\n[241] Rujia Li et al. An accountable decryption system based\non privacy-preserving smart contracts. In International\nConference on Information Security (ISC), pages 372\u2013\n390. Springer, 2020.\n[242] Ian Miers, Christina Garman, Matthew Green, and\nAviel D Rubin. Zerocoin: Anonymous distributed e-\ncash from Bitcoin. In IEEE Symposium on Security\nand Privacy (SP), pages 397\u2013411. IEEE, 2013.\n[243] Jens Groth.\nOn the size of pairing-based non-\ninteractive arguments. In International Conference\non the Theory and Applications of Cryptographic Tech-\nniques, pages 305\u2013326. Springer, 2016.\n[244] Benedikt B\u00fcnz, Jonathan Bootle, Dan Boneh, Andrew\nPoelstra, Pieter Wuille, and Greg Maxwell. Bullet-\nproofs: Short proofs for confidential transactions and\nmore. In IEEE Symposium on Security and Privacy\n(SP), pages 315\u2013334. IEEE, 2018.\n[245] Carsten Baum, James Hsin-yu Chiang, Bernardo\nDavid, and Tore Kasper Frederiksen. SoK: Privacy-\nenhancing technologies in finance. Cryptology ePrint\nArchive, 2023.\n[246] Stuart Haber and W Scott Stornetta. How to time-stamp\na digital document. Springer, 1991.\n[247] Gavin Wood et al. Ethereum: A secure decentralised\ngeneralised transaction ledger. Ethereum project yel-\nlow paper, 151(2014):1\u201332, 2014.\n[248] Andrei-Drago\u00b8s Popescu. Decentralized finance (DeFi)\u2013\nthe lego of finance. Social Sciences and Education\nResearch Review, 7(1):321\u2013349, 2020.\n[249] Tam\u00e1s Katona. Decentralized finance: The possibilities\nof a blockchain \u201cmoney lego\u201d system. Financial and\nEconomic Review, 20(1):74\u2013102, 2021.\n[250] Reza Soltani, Uyen Trang Nguyen, and Aijun An. Prac-\ntical key recovery model for self-sovereign identity\nbased digital wallets. In IEEE Intl Conf on Depend-\nable, Autonomic and Secure Computing, Intl Conf on\nPervasive Intelligence and Computing, Intl Conf on\nCloud and Big Data Computing, Intl Conf on Cyber\nScience and Technology Congress (DASC/PiCom/CB-\nDCom/CyberSciTech), pages 320\u2013325. IEEE, 2019.\n[251] Gyeong-Jin Ra, Chang-Hyun Roh, and Im-Yeong Lee.\nA key recovery system based on password-protected se-\ncret sharing in a permissioned blockchain. Computers,\nMaterials & Continua, 65(1):153\u2013170, 2020.\n[252] Ali Bagherzandi, Stanislaw Jarecki, Nitesh Saxena, and\nYanbin Lu. Password-protected secret sharing. In ACM\nconference on Computer and Communications Security\n(CCS), pages 433\u2013444, 2011.\n[253] Jan Camenisch, Anja Lehmann, Anna Lysyanskaya,\nand Gregory Neven. Memento: How to reconstruct\nyour secrets from a single password in a hostile envi-\nronment. In Annual Cryptology Conference (CRYPTO),\npages 256\u2013275. Springer, 2014.\n[254] Shuangyu He, Qianhong Wu, Xizhao Luo, Zhi Liang,\nDawei Li, Hanwen Feng, Haibin Zheng, and Yanan\nLi.\nA social-network-based cryptocurrency wallet-\nmanagement scheme.\nIEEE Access, 6:7654\u20137663,\n2018.\n[255] Niko Lehto, Kimmo Halunen, Outi-Marja Latvala,\nAnni Karinsalo, and Jarno Salonen.\nCryptovault-a\nsecure hardware wallet for decentralized key manage-\nment.\nIn 2021 IEEE International Conference on\nOmni-Layer Intelligent Systems (COINS), pages 1\u20134.\nIEEE, 2021.\n[256] Weiqi Dai, Yan Lv, Kim-Kwang Raymond Choo,\nZhongze Liu, Deqing Zou, and Hai Jin. Crsa: A cryp-\ntocurrency recovery scheme based on hidden assis-\ntance relationships. IEEE Transactions on Information\nForensics and Security (TIFS), 16:4291\u20134305, 2021.\n[257] Sercan \u00b8Sahan, Adil Furkan Ekici, and \u00b8Serif Bahtiyar.\nA multi-factor authentication framework for secure\naccess to blockchain. In International Conference on\nComputer and Technology Applications (CCAT), pages\n160\u2013164, 2019.\n[258] E Benli, I Engin, C Giousouf, MA Ulak, and \u00b8S Bahtiyar.\nBiowallet: a biometric digital wallet. ICONS 2017,\npage 45, 2017.\n[259] Mehmet Aydar, Salih Cemil Cetin, Serkan Ayvaz, and\nBetul Aygun. Private key encryption and recovery in\nblockchain. arXiv preprint arXiv:1907.04156, 2019.\n24\n[260] A Jagadeesan and K Duraiswamy. Secured crypto-\ngraphic key generation from multimodal biometrics:\nfeature level fusion of fingerprint and iris.\narXiv\npreprint arXiv:1003.1458, 2010.\n[261] Teng Hu, Xiaolei Liu, Weina Niu, Kangyi Ding, Yan-\nping Wang, and Xiaosong Zhang. Securing the private\nkey in your blockchain wallet: a continuous authen-\ntication approach based on behavioral biometric. In\nJournal of Physics: Conference Series, volume 1631,\npage 012104. IOP Publishing, 2020.\nA\nFoundations of DeFi\nA.1\nOperational Supports\nTransactions. A transaction is the smallest unit in the\nblockchain ledger. It includes sender and receiver addresses,\nthe number of coins involved, a unique hash value, a times-\ntamp, transaction/gas fee, block information (block ID of the\nfirst recording block), and data payloads for execution (cf.\nFigure 1). Interactions with the blockchain are categorized as\ntransfer or contract transactions. Transfer transactions involve\nsimple coin transfers, while contract transactions interact with\nsmart contracts. A transaction sender must be an Externally\nOwned Account (EOA), while the receiver can be a smart\ncontract address or an EOA, and the transaction data field\ncontains the required parameters for the contract function.\nBlock. The block is a fundamental unit of data, consisting of\nheader and body. The header contains the previous block\u2019s\nhash, current block\u2019s ID, and Merkel root of its content, en-\nsuring a tamper-proof chain. The block body contains trans-\nactions. Creating a new block involves propagation and val-\nidation across different nodes via consensus algorithms. A\nnewly added block is linked in the current chain.\nChain. The chain is a series of blocks linked together using\ncryptographic hashes (cf. Figure 1). Each block contains a\nunique identifier (hash) derived from its data and the previous\nblock\u2019s hash. This creates a continuous and tamper-resistant\nchain of data known as the blockchain (conceptual milestones\nin 1991 [246], 2008 [29], and 2014 [247]).\n...\nBlock 0\nBlock i-1\n...\nBlock i\nMerkle\nRoot\nTime-\nstamp\nParent \nBlock \nHash\nTransaction Counter\nTx1\n...\nHeader\nBody\nTx2\nTxn\n...\nhash(Tx1)\nhash(Tx2)\nhash(Txn)\nhash(Tx1,Tx2)\nhash(Txn-1,Txn)\n...\nMerkle Root\nHash\nPrivate \nKey\nDigital Signature\nSign\nTx\nHash\nTimestamp\nFrom\nTo\nAmount\nGas\nData\nTransaction\nBlockchain \nNetwork\nBlock j\n...\nvalidate\npackage\nAgreements\nSmart Contract\nSign\nTx\nBlockchain Network\ndeploy\nNode\nVirtual Machine\nPreset Conditions\nValue\nStatus\nPreset Rules\nSmart ContractA\ntrigger\nSign\nTx\nexecute\nBlock n\nBlock n-1\nFigure 1: DeFi Foundations\nSmart contracts. Smart contract constitutes a crucial element\nsupporting DeFi protocols. Deployed on-chain, it acts as a\ncomputerized transaction protocol that transforms traditional\ncontract terms into executable programs, maintaining logical\nconnections between terms as a flow (see Figure 1). Smart\ncontracts feature automatic execution, instant response, and\nstrict enforcement, and the contracts deployed on them are\ntamper-proof, minimizing the chance of human intervention.\nDApp. Short for decentralized applications, DApps are con-\nstructed on blockchain using smart contracts [248]. Smart\ncontracts can be likened to code-based Lego blocks with auto-\nmatic execution functions [249]. Multiple smart contracts can\ncollaborate to achieve the intricate functionalities required\nby applications. DApps usually offer user interfaces, stream-\nlining users\u2019 interactions with the blockchain. User actions\nvia DApps are recorded on the blockchain as transactions,\nexecuted according to pre-written smart contract rules, and\nverified by blockchain nodes.\nA.2\nDeFi Composition\nWallet. A user can manage multiple accounts from a single\nwallet in DeFi. Each account has three components: public\nkey, private key, and address, as shown in Figure 2. A crypto-\ngraphic algorithm generates a pair of one-to-one keys when\nan account is created. The private key generates the digital\nsignature necessary for proving ownership of assets, which\ncan be verified by the corresponding public key. An address,\ngenerated from the public key by a one-way hash function, is\nto DeFi what an account is to traditional finance, symboliz-\ning a user\u2019s on-chain identity. Since private keys are difficult\nto remember, the wallet developers have set up mnemonics\nas double insurance policy to help users memorize complex\nprivate keys. A mnemonic can be understood as a simplified\nversion of the private key, which is generated by an algorithm\nthat selects words from a fixed vocabulary. When the user\nforgets the private key, the mnemonic is used to recover it.\nPassword\nRandom\nSECP256K1\nSHA256\nRIPEMD160\nDOUBLESHA256\nhash(Public Key)\n0x00\nFirst 4 Bytes\n            hash(Public Key)\ncheck code\n0x00\nBASE58\nRandom\nSHA256\n        Entropy\nChecksum(4 bits)\nWord List\n\u2462split\n\u2460\n\u2461\n\u2463\nPrivate Key\nPublic Key\nAddress\nPrivate Key\nPublic Key\nAddress\nPrivate Key\nPublic Key\nAddress\nMnemonic Phrase\nword1 word2 word3\n... word11\nword12\nSalt\n(multiple rounds)\n\u2464\n\u2467\n\u2466\n\u2465\nChain A\nChain B\nChain C\nFigure 2: Components of Wallets\nThe security of wallets focus on three essential links: the\ncreation, storage, and use of private keys. The storage security\nof private keys can be strengthened through local storage. The\nsecurity recovery of private keys can be enhanced through se-\ncret sharing and TTP. The secure usage of private keys can be\n25\nachieved through multi-factor authentication. Non-custodial\nwallets, such as MetaMask [99], locally store private keys,\nprotecting them from server owners and attackers. Through\nacademic research, the conditions for implementing secret\nsharing to protect private keys have evolved from relying on\nTTP authentication [250] or permissioned blockchains [251]\nto utilizing single-password systems [252] and trustless en-\nvironments [253]. The industry has also developed security-\nenhanced wallets based on secret sharing, such as Zengo [100].\nAcademic research has covered different types of TTP-based\nwallets, e.g., [254]\u2019s identity-based key encryption for soft-\nware wallets and [255]\u2019s recovery for hardware wallets, and\nconsidered factors like privacy, e.g., [256]\u2019s recovery scheme\nwith privacy protection using ZKPs. Argent [101] is one\nof the industry examples that utilizes TTP. Multi-factor au-\nthentication, including biometric features [257] like finger-\nprint [258,259], iris, pulse [260], and behavioral features like\nmouse behavior [261], can help to verify the identity of user.\nOracle. Oracle provides external data sources for smart con-\ntracts on the blockchain, supplying them with data infor-\nmation. The oracle retrieves the data from off chain data\nproviders, typically nodes within the blockchain network,\nwho fetch data from various public sources. The data is then\nsent to smart contracts of the oracle, which tasks such as pack-\naging, verification, and cleansing of the received data. Finally,\nthe oracle submits the updated data, allowing the user or smart\ncontract that initiated the request to obtain.\nStablecoin. Stablecoins can be formed through various meth-\nods, including off-chain reserves or on-chain collateralization.\nStablecoins circulate similarly to traditional finance systems,\ninvolving reserve, issuance, and other essential links. Off-\nchain reserved stablecoins are backed by fiat or assets like\ngold. Maintaining transparency and integrity of reserve as-\nsets ensures a 1:1 collateralization ratio between stablecoins\nand backing assets. However, these stablecoins carry risks\ndue to centralized reserves and third-party audits. In contrast,\non-chain reserve stablecoins and algorithmic stablecoins use\ndigital assets as collateral or eliminate collateralization al-\ntogether. They are created through a transparent on-chain\nprocess with different price stabilization mechanisms. De-\nspite their advantages, some on-chain stablecoins are prone\nto downfall caused by a death spiral during crises.\nLending. Decentralized lending protocols typically involve\ncollateralization, lending, and liquidation. Users provide digi-\ntal assets as collateral, which are aggregated into a pool that\nforms a reserve used for redemption. The smart contracts\nissue credential tokens to users, which can be used for re-\ndemption. Users\u2019 credit for borrowing is based on the liquid-\nity they provide, and the floating or fixed borrowing rate is\ndetermined by an interest rate contract that adjusts based on\nsupply-borrowing dynamics according to specific interest rate\nmodels. Liquidation is triggered when a user\u2019s debts exceed\nthe borrowing capacity, and any participant can compete to\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\nBorrower\nFlash Loan \nManagement Contract\nLending Pool\n\u2460 request for flash loan\n (token type, loan amount)\n\u2461 check reserve of lending pool\n    (loan amount\u2264total reserve)\n\u2462calculate fees\n\u2463 optimistic transfer (token type, loan amount)\n\u2464 execute \nself-defined \nbusiness\n\u2465 allowance\n    (repay amount, fee)\n\u2466 check\n   (token type, \n    repay amount+fee)\n\u2467 transfer\n  (token type, repay amount+fee)\nRequest\nBorrow\nRepay\nUse\n(Arbitrage, \nLiquidation, etc.)\nFigure 3: Flash Loan Workflow\nliquidate debts and earn rewards. Some protocols distribute\ngovernance tokens to users to incentivize participation.\nFlash Loan. The workflow of flash loans or flash swaps is\nillustrated in Figure 3.\nSmart Contract\nsubmit order\nsettle\nmatch\nOrder Book\nrecord\nSmart Contract\nsubmit order\nsettle\nBlockchain Network\nmatch\nOrder Book\nSmart Contract\nsubmit order\nsettle\nExchange Rate\nManagement\n   Token\ufffd\n   Token\ufffd\nPrice\nPool Token\ufffdPool Token\ufffd\nOff-chain Order Book\nOn-chain Order Book\nNon Order Book(AMM)\noff-chain\non-chain\nFigure 4: DEX Implementation Models\nExchange. DEX can be divided into different models based\non the implementation of trading pair discovery and order\nmatching (cf. Figure 4). Some DEXs use order book, where\norders are recorded in an order book, and transactions are\naggregated using principles of high and low bids and time\norder. DEXs using on-chain order books maintain order books\nat each node, with orders submitted to smart contracts and\nbroadcasted to the network. When receiving the order, the\nnode records and matches the prices and automatically exe-\ncutes the trade. The discovery of transactions in this model\nis limited by network performance. The off-chain order book\nmodel is similar to traditional exchanges, where the exchange\nmaintains an order book and matches them off-chain. Several\nDEXs innovate the non-order book model. Two methods are\n(i) the establishment of a reserve pool, and (ii) the use of the\nAMM mode, which calculates the exchange rate between two\nor more assets according to specific algorithms, providing the\nquotation between assets at any time. Both sides of AMM\ntrades interact with on-chain liquidity pools that allow users\nto seamlessly switch between tokens. Liquidity providers earn\nincome based on the percentage of their contribution to the\npool. The core of AMM lies in various exchange rate algo-\nrithms, including constant mean, constant product, dynamic\nweighting, and constant sum.\n26\n",
    "2106.08157": "CeFi vs. DeFi \u2014\nComparing Centralized to Decentralized Finance\nKaihua Qin\u2217\nkaihua.qin@imperial.ac.uk\nImperial College London\nLiyi Zhou\u2217\nliyi.zhou@imperial.ac.uk\nImperial College London\nYaroslav Afonin\nyaroslav.afonin20@imperial.ac.uk\nImperial College London\nLudovico Lazzaretti\nludovicolazzaretti@gmail.com\nIndependent\nArthur Gervais\na.gervais@imperial.ac.uk\nImperial College London\nAbstract\nTo non-experts, the traditional Centralized Finance (CeFi) ecosys-\ntem may seem obscure, because users are typically not aware of\nthe underlying rules or agreements of financial assets and products.\nDecentralized Finance (DeFi), however, is making its debut as an\necosystem claiming to offer transparency and control, which are par-\ntially attributable to the underlying integrity-protected blockchain,\nas well as currently higher financial asset yields than CeFi. Yet, the\nboundaries between CeFi and DeFi may not be always so clear cut.\nIn this work, we systematically analyze the differences between\nCeFi and DeFi, covering legal, economic, security, privacy and mar-\nket manipulation. We provide a structured methodology to differ-\nentiate between a CeFi and a DeFi service. Our findings show that\ncertain DeFi assets (such as USDC or USDT stablecoins) do not\nnecessarily classify as DeFi assets, and may endanger the economic\nsecurity of intertwined DeFi protocols. We conclude this work with\nthe exploration of possible synergies between CeFi and DeFi.\n1\nIntroduction\nCentralized finance was originally invented in ancient Mesopotamia,\nseveral thousand years ago. Since then, humans have used a wide\nrange of goods and assets as currency (such as cattle, land, or cowrie\nshells), precious metals (such as gold, which have enjoyed near-\nuniversal global cultural acceptance as a store of value), and, more\nrecently, fiat currencies. As such, it has been shown that a currency\ncan either carry intrinsic value (e.g., land) or be given an imputed\nvalue (fiat currency). All these known attempts to create an everlast-\ning, stable currency and finance system were based on the premise\nof a centralized entity, where e.g., a government is backing the\nfinancial value of a currency, with a military force at its command.\nHistory, however, has shown that currencies can also be valued\nusing an imputed value, that is an assumed value assigned to a\ncurrency, which can be unrelated to its intrinsic value, and, e.g.,\nmay even be zero.\nWith the advent of blockchains, and their decentralized, permis-\nsionless nature, novel imputed currencies have emerged. One of\nthe blockchain\u2019s strongest innovations is the transfer and trade of\nfinancial assets without trusted intermediaries [185]. In addition\nto this, Decentralized Finance (DeFi), a new sub-field of blockchain,\nspecializes in advancing financial technologies and services on top\nof smart contract enabled ledgers [168]. DeFi supports most of\nthe products available in CeFi: asset exchanges, loans, leveraged\n\u2217Both authors contributed equally to the paper.\ntrading, decentralized governance voting, stablecoins. The range\nof products is rapidly expanding, and some of the more complex\nproducts, such as options, and derivatives, are rapidly developing\nas well.\nContrary to the traditional centralized finance1, DeFi offers three\ndistinctive features: 1. Transparency. In DeFi, a user can inspect\nthe precise rules by which financial assets and products operate.\nDeFi attempts to avoid private agreements, back-deals and central-\nization, which are significant limiting factors of CeFi transparency.\n2. Control. DeFi offers control to its users by enabling the user to\nremain the custodian of its assets, i.e., no-one should be able to\ncensor, move or destroy the users\u2019 assets, without the users\u2019 con-\nsent. 3. Accessibility. Anyone with a moderate computer, internet\nconnection and know-how can create and deploy DeFi products,\nwhile the blockchain and its distributed network of miners then\nproceed to effectively operate the DeFi application. Moreover, the\nfinancial gain in DeFi also presents a significant contrast to CeFi.\nIn the years 2020 and 2021, DeFi offered higher annual percentage\nyields (APY) than CeFi: the typical yield of USD in a CeFi bank is\nabout 0.01% [53], while at the time of writing, DeFi offers consis-\ntent rates beyond 8% [12]. On the one hand, DeFi enables mirroring\ntraditional financial products, on the other hand, it enables novel fi-\nnancial primitives, such as flash loans and highly-leveraged trading\nproducts, that yield exciting new security properties.\nIn this paper, we aim to compare and contrast systematically the\ntraditional Centralized Finance and Decentralized Finance ecosys-\ntems. Firstly, we compare both domains in their technological differ-\nences, such as transaction execution order, throughput, privacy, etc.\nSecondly, we dive into their economic disparities, such as the differ-\nences from an interest rate perspective, transaction costs, inflation\nand possible monetary policies. Finally, we contrast the legal pecu-\nliarities, such as regulations around consumer protections, know\nyour customer (KYC) and anti-money laundering (AML) techniques.\nIn summary, our contributions are the following:\nCeFi \u2014 DeFi Decision Tree We devise a decision tree which en-\nables the classification of a financial service as CeFi, DeFi, or\na hybrid model. We highlight that commonly perceived DeFi\n1We prefer to refer to the (currently) traditional finance as CeFi, as centralization is one\nof the most distinguishing properties, and the term \u201ctraditional\u201d might not withstand\nthe test of time.\n1\narXiv:2106.08157v2  [q-fin.GN]  16 Jun 2021\nFigure 1: Decision tree to differentiate among DeFi and CeFi.\nassets (such as USDC or USDT stablecoins), are in fact cen-\ntrally governed, allowing a single entity to censor or even de-\nstroy cryptocurrency assets. We find that nearly 44M black-\nlisted USDT were destroyed by Tether Operations Limited.\nWe show how this power may lead to significant financial\ndanger for DeFi protocols incorporating these assets.\nDeFi Systematization We provide a comprehensive systematiza-\ntion of DeFi, its underlying blockchain architecture and fi-\nnancial services, while highlighting DeFi\u2019s ability to perform\natomic composability. We also exposit the various market\nmechanisms that can be targeted from traditional CeFi as\nwell as novel DeFi market manipulations.\nCase Studies We separately provide a case-by-case comparison\nbetween CeFi and DeFi focussing on legal, financial services,\neconomics and market manipulations. We conclude the case\nstudies by distilling possible synergies among CeFi and DeFi.\nCeFi \u2014 DeFi Decision Tree Due to a lack of definition when\nit comes to DeFi, we have prepared in Figure 1 a possible decision\ntree that may help classify a financial product or service as CeFi or\nDeFi. In this tree, the first decisive question is whether the financial\nassets are held by the user, i.e., whether the user retains control\nover its own assets. If the user is not in control, does not retain\ncustody nor the ability to transact the assets without a financial\nintermediary, the service is an instance of CeFi. Otherwise, we\nask the question whether someone has the capacity to unilaterally\ncensor a transaction execution. Such powerful intermediary points\nto the existence of a CeFi intermediary, while the asset settlement\nmay still occur in a decentralized, DeFi-compliant manner. Finally,\nwe question whether an entity bears the power to single-handedly\nstop, or censor the protocol\u2019s execution. If this is the case, we\nwould argue that the DeFi protocol is centrally governed. If this last\nquestion can be answered to the negative, the protocol in question\nwould then qualify as a pure DeFi protocol. To the best of our\nknowledge we are the first to differentiate with three simple and\nobjective questions whether a service is an instance of CeFi or DeFi.\nOur methodology also highlights that the boundary between CeFi\nand DeFi is not always as clear-cut as from the first glance.\nThe paper is organized as follows. Section 2 provides a system-\natization of DeFi as well as a background on CeFi and applicable\nproperties for the remainder of the paper. Diving into specific case-\nby-case comparisons, Section 3 focusses on the legal similarities,\nSection 4 exposes the differences in the financial CeFi and DeFi ser-\nvices, while Section 5 exposes economic and market manipulation\nanalogies. We positively derive possible synergies between DeFi\nand CeFi in Section 6 and conclude the paper in Section 7.\n2\nBackground\nIn this section we provide a primer on finance, blockchains, DeFi\nand its distinguishing properties when considering CeFi.\n2.1\nWhat is Finance?\nFinance is the process that involves the creation, management, and\ninvestment of money [100]. A financial system links those in need\nof finance for investment (borrowers) with those who have idle\nfunds (depositors). Financial systems play an essential role in the\neconomy since it boosts the economy\u2019s productivity by regulating\nthe supply of money, by ensuring high utilization of existing money\nsupply. Without a financial system, each entity would have to fi-\nnance themselves, rather than rely on a capital market, and goods\nwould be bartered on spot markets. Such a system would only be\nable to service a very primitive economy. An effective financial sys-\ntem provides legally compliant, safe, sound, and efficient services\nto market participants. Financial systems typically consist of the\nfollowing three components, namely the institution, instrument\nand market [182]. On a high level, financial institutions issue, buy,\nand sell financial instruments on financial markets according to the\npractices and procedures established by laws.\nFinancial Institutions refer to financial intermediaries, which\nprovide financial services. Traditional financial services in-\nclude banking, securities, insurance, trusts, funds, etc. Corre-\nspondingly, traditional financial institutions include banks,\nsecurities companies, insurance companies, trust investment\ncompanies, fund management companies, etc. A comprehen-\nsive definition of financial institutions is contained in title\n31 of the United States Code, including financial auxiliary\nservice providers such as travel agencies, postal services, etc.\nFinancial Instruments refer to monetary assets. A financial in-\nstrument can be a paper document or virtual contract that\nrepresents legal agreements involving monetary value. All\nsecurities and financial assets (including cryptocurrencies)\nfall under the broad category of financial instruments.\nFinancial Markets refer broadly to any marketplace where the\ntrading of financial instruments occurs. Financial markets\ncreate liquidity by bringing together sellers and buyers, which\nhelps market participants to agree on a price.\n2.2\nBlockchains and DeFi\nThe inception of Bitcoin [148] in 2009 solved the fundamental\ndouble-spending problem in a decentralized, electronic setting. For\nthe first time in history, users are able to send and receive online\nfinancial assets, without passing through third parties, such as bro-\nkers. This very permissionless property of Bitcoin enables users\nto join and leave the system at their will, without the danger of\n2\nFigure 2: High-level systematization of Decentralized Finance. DeFi builds upon a distributed blockchain database, enabling\natomic transaction settlement. Communication with external databases, such as other blockchains, centralized exchanges etc\nis possible through non-atomic interactions.\nassets being frozen by a controlling instance. Crucially, Bitcoin\nintroduced the concept of a time-stamping blockchain, which al-\nlows to pin-point the precise time and order at which a transaction\nshould execute. This time-stamping service is critical to the exe-\ncution of financial assets and allows to unmistakably derive how\nmany financial assets which account holds at which point in time.\nBitcoin\u2019s blockchain therefore allows its users to act as the custo-\ndian of their own assets, effectively retaining control over their\nassets. This empowering property creates new opportunities for\ncitizens that are being threatened by malicious governments and\nirresponsible monetary inflation policies. While Bitcoin supports\nmore complex transactions, fully featured smart contract enabled\nblockchains truly allow to construct flexible financial products on\ntop of blockchains. With the broader adoption of smart contracts,\nthe concept of Decentralized Finance truly came to fruition, to the\npoint of hosting an economy exceeding 100 Billion USD.\nDeFi builds upon the permissionless foundations provided by\nblockchains. Anyone is free to code and propose a novel financial\ncontract, which anyone is free to interact with, transfer assets to,\nas well as remove assets from, as long as remaining compliant\nwith the immutable smart contract rules. To provide a higher level\nintuition of what DeFi is, and can do, we provide the high-level\nsystematization of DeFi in Figure 2.\nAt its core, a DeFi state transition must be necessarily reflected\non its underlying blockchain. For this to happen, a user has to create\na transaction, and broadcast this transaction in the public peer-to-\npeer (P2P) blockchain network. Blockchain miners subsequently\npick up the transaction, and depending on the amounts of fees paid\nby the transaction, the miners may choose to include the transaction\nin the blockchain consensus layer. Once a transaction is included in\nthe blockchain, the transaction can be considered to be confirmed,\nand may be final after a certain time period passed. A confirmed\ntransaction modifies the blockchain and its corresponding DeFi\nstate, by e.g., altering the liquidity provided in an exchange. DeFi\nbuilds upon the blockchain\u2019s state machine, whereby various fi-\nnancial services are currently being offered. Those services include\nlending/borrowing, market-making, stablecoins, pegged tokens,\nprice oracles, privacy services, flash loans, decentralized portfolio\nmanagers, insurance and many other [50, 61, 102, 147, 158, 173].\n2.3\nProperties\nIn this section we outline the most prevalent DeFi properties.\nPublic Verifiability: While the DeFi application code may not\nalways be open source, to classify as non-custodial DeFi,\nits execution and bytecode must be publicly verifiable on\na blockchain. Hence, contrary to CeFi, any DeFi user can\ninspect the DeFi state transitions and verify their orderly\nexecution. Such transparency provides the unprecedented\nability to convey trust in the emerging DeFi system.\nCustody: Contrary to CeFi, DeFi allows its users to control their\nassets directly and at any time of the day (there is no need to\nwait for the bank to open). With such great power, however,\nalso comes great responsibility. Technical risks are mostly\nabsorbed by the users, unless an insurance is underwritten [8,\n147]. Therefore, centralized exchanges are very popular for\nstoring cryptocurrency assets [82], which in turn are largely\nequivalent to traditional custodians.\n3\nPrivacy: To the best of our knowledge, DeFi is exclusively present\non non-privacy preserving smart contract enabled blockchains.\nAs such, these blockchains offer pseudoanonymity, but no\nreal anonymity [160, 165]. A rich literature corpus has al-\nready shown how blockchain addresses can be clustered and\ntransaction data can be traced [114, 115, 140, 145, 150, 160,\n180]. Given that centralized exchanges with KYC/AML prac-\ntices are often the only viable route to convert between fiat\nand cryptocurrency assets, these centralized exchanges have\nthe ability to disclose address ownership to law enforcement.\nAtomicity: A blockchain transaction supports sequential actions,\nwhich can combine multiple financial operations. This com-\nbination can be enforced to be atomic \u2014 which means that\neither the transaction executes in its entirety with all its\nactions, or fails collectively. While this programmable atom-\nicity property is to our knowledge mostly absent from CeFi,\n(likely costly and slow) legal agreements could enforce atom-\nicity in CeFi as well.\nExecution Order Malleability: Through a P2P network, users\non permissionless blockchains typically share publicly the\ntransactions that are aimed to be executed. Because of the\nlack of a persistent centralized entity ordering transaction\nexecution, peers can perform transaction fee bidding con-\ntests to steer the transaction execution order. Such order\nmalleability was shown to result in various market manipu-\nlation strategies [96, 158, 189, 191], which are widely used\non blockchains nowadays [157]. In CeFi, regulatory bodies\nimpose strict rules on financial institutions and services as\nin how transaction ordering must be enforced [60]. In CeFi\nthis is possible due to the centralized nature of the financial\nintermediaries.\nTransaction Costs: Transaction fees in DeFi and blockchains in\ngeneral are essential for the prevention of spam. In CeFi,\nhowever, financial institutions can opt to offer transaction\nservices at no cost (or are mandated by governments to offer\ncertain services for free [177]) because of the ability to rely\non KYC/AML verifications of their clients.\nNon-stop Market Hours: It is rare for CeFi markets to operate\nwithout downtime. For example, the New York Stock Ex-\nchange and the Nasdaq Stock Exchange are the two major\ntrading venues in the United States, and their business hours\nare Monday to Friday from 9:30 a.m. to 4 p.m. Eastern Time.\nDue to the non-stop nature of blockchains, most if not all\nDeFi markets are open 24/7. As a result, DeFi does not have\npre- or post-market trading compared to CeFi whereby liq-\nuidity on a range of products is typically thin during these pe-\nriods. Furthermore, system outages at CeFi stock exchanges\nand CeFi cryptocurrency exchanges have been known to\noccur due to numbers of users attempting to access the ex-\nchanges during times of volatility such as the GameStop\nshort squeeze event, not to mention the intervention by bro-\nkerage firms to restrict their respective customer\u2019s purchase\nand sale of certain equity products due to liquidity and sol-\nvency concerns [41, 44].\nAnonymous Development and Deployment: Many DeFi projects\nare developed and maintained by anonymous teams2, even\nthe Bitcoin creator remains to date anonymous. Once de-\nployed, the miners implicitly operate the DeFi smart con-\ntracts. Anonymous DeFi projects can function without a\nfront-end, requiring users to interact with the smart contract\ndirectly. Alternatively, the front-end website can be served\nthrough a distributed storage service, such as IPFS.\n3\nCase by Case \u2014 Legal\nIn the following we focus on the legal aspects of CeFi and DeFi.\n3.1\nOn-boarding and Continuous Compliance\nWhen opening an account with a financial institution in CeFi, in\nmost countries, it means that the user needs to visit a nearby branch,\nor online portal and follow the on-boarding steps. CeFi heavily re-\nlies on KYC verifications, which are required by regulations [159].\nKYC typically involves the verification of the identity, through an\nID, passport or a driver\u2019s license. Moreover, the user is usually re-\nquired to provide a proof of address or residency. Depending on\nlocal regulations, and the user\u2019s intent, the user may also be re-\nquired to answer questionnaires to clarify its financial background\n(i.e., whether the user is knowledgeable about the financial risks\nof different asset classes). Finally, depending on the user\u2019s intent,\nthe financial institution may also require a proof of accredited in-\nvestor, for example showing that the user\u2019s net worth exceed the\nrespective jurisdiction\u2019s threshold to admit them for accessing cer-\ntain sophisticated services, or requesting formal classification as a\nnon-retail participant which entails losing their rights to complain\nto the Financial Ombudsman (e.g. in the UK) or other financial\nregulator [36]. Depending on the user\u2019s background, intentions and\nthe financial institution, this KYC process may take from a few\nhours to several weeks. As such, compliance checks are especially\nchallenging in a worldwide setting, with many different passport\nformats and qualities. Therefore, dedicated companies are nowa-\ndays offering on-boarding services [25]. While KYC is certainly\nvery helpful in combating illegal activities, compliance checks sig-\nnificantly increase the bureaucratic overhead and associated costs\nwhen offering financial services in CeFi.\nBesides KYC, AML verifications in CeFi are typically an ongoing\neffort to verify the source, destination and purpose of asset trans-\nmissions by financial institutions [146, 170]. AML\u2019s purpose is to\ncombat money laundering, as in to differentiate between benign\nand malicious sources of funds and, in most jurisdictions, a senior\nofficial at the financial institution is required to act as the Money\nLaundering Reporting Officer or similar nominated role [36]. With\nthe advent of DeFi, and blockchain transactions in general, CeFi\nfinancial institutions are known to thoroughly investigate funds\nwith a DeFi provenance [14]. Yet, it is technically much simpler to\ntrace DeFi funds than CeFi assets due to the open and transparent\nnature of blockchains. Therefore, we expect CeFi institutions to\nfurther accept DeFi assets, for which a user is able to justify the\nsource of funds. Note that some CeFi institutions simply avoid ac-\ncepting DeFi or blockchains assets due to the increased compliance\n2Such as Harvest Finance on Ethereum and Pancakeswap on Binance Smart Chain.\n4\noverhead and costs which are at times (depending on jurisdictions)\nonerous and costly for traditional CeFi participants.\nBecause DeFi assets and transactions are typically traceable\nthrough investigating the publicly accessible blockchain, KYC/AML-\nenabled CeFi exchanges, which provide fiat and cryptocurrency\nassets trading pairs, can offer law enforcement helpful identity in-\nformation in combating money laundering [2]. However, if a user\nsolely operates within DeFi, without ever crossing the boundary\ninto CeFi, it is technically possible to entirely avoid KYC. Moving\nnon-KYC\u2019d assets to CeFi, may however prove to be challenging\nfrom a compliance perspective.\nInsight 1: Linking DeFi assets from CeFi\nThe on-boarding process in DeFi typically requires a CeFi\nintermediary, and hence discloses the blockchain addresses\nof the respective users. DeFi\u2019s transparency would then\nallow to trace the coins provenance.\n3.2\nAsset Fungibility in CeFi and DeFi\nThe Financial Action Task Force (FATF) is an intergovernmental\norganization with the aim to develop policies to combat money\nlaundering and the financing of terrorism (CFT) [23]. The FATF\nrecommendations are increasingly being accepted by major juris-\ndictions, also affecting DeFi. For instance, the FATF introduced\nterms such as virtual asset service provider (VASP), and the travel\nrule. VASPs are e.g., entities which hold assets on behalf of users,\nsuch as custodians. However, as of now, it is unclear whether an\nindividual who deploys a DeFi protocol would be classified as a\nVASP [55]. The FATF rules may render a software engineer liable\nfor developing a DeFi application, even if this developer does not\nretain any control over the deployed application, nor is involved in\nthe launch or post-launch activities [24]. The travel rule requires\nfinancial institutions (in particular VASPs) to notify the receiving\nfinancial institutions about a cryptocurrency transactions along\nwith its identifying information [1, 19, 39].\nCensoring (Temporarily) Transactions In Figure 1 we pro-\nvide a decision tree on how to differentiate between CeFi and DeFi\nservices, whereas this tree is substantially influenced by the legal\npeculiarities at stake. One critical differentiation therein is whether\nsomeone has the option to censor a transaction, or an entire proto-\ncol execution. Regulators, e.g., in Switzerland, are known to impose\nAML rules on non-custodial providers which have the ability to in-\ntervene, i.e., censor, a transaction [48]. In practice, there may appear\nmany services capable of first temporarily censoring transactions,\nas well as services that may indefinitely block the execution of a\nparticular transaction.\nMiners in Bitcoin for instance, are certainly empowered to not\ninclude a transaction in the blockchain, and hence have the ability\nto temporarily censor a transaction execution. In Lightning [156]\nfor instance, nodes may simply refuse to provide service for a\nparticular transaction, forcing the user to either chose another\noff-chain payment path, or return to the on-chain layer through a\nregular Bitcoin transaction. Alternative off-chain technologies, such\nas commit-chains, which are possibly operating a single centralized,\n1\nfunction transfer(address _to , uint _value) public\nwhenNotPaused {\n2\nrequire (! isBlackListed[msg.sender ]);\n3\nif (deprecated) {\n4\nreturn UpgradedStandardToken(upgradedAddress).\ntransferByLegacy(msg.sender , _to , _value);\n5\n} else {\n6\nreturn super.transfer(_to , _value);\n7\n}\n8\n}\n9\nfunction addBlackList (address _evilUser) public\nonlyOwner {\n10\nisBlackListed[_evilUser] = true;\n11\nAddedBlackList(_evilUser);\n12\n}\n13\nfunction destroyBlackFunds (address _blackListedUser)\npublic onlyOwner {\n14\nrequire(isBlackListed[_blackListedUser ]);\n15\nuint dirtyFunds = balanceOf(_blackListedUser);\n16\nbalances[_blackListedUser] = 0;\n17\n_totalSupply -= dirtyFunds;\n18\nDestroyedBlackFunds(_blackListedUser , dirtyFunds);\n19\n}\nListing 1: USDT code blacklist functionality.\nbut non-custodial server, may have the ability to censor transactions,\nand may hence also require to meet KYC/AML requirements.\nInsight 2: Censoring transactions and KYC/AML requirements\nIf an entity is able to single-handedly censor or intervene\nin a financial transaction, this entity may become liable to\nKYC/AML/CFT requirements, even if the entity is not an\nasset custodian.\nBlacklists, Fungibility and the Destruction Assets Once a\nfinancial service provider is subject to KYC/AML requirements, the\nfinancial enforcement authorities of the respective legislation may\nrequest and require the ability to freeze and confiscate financial\nassets. This requirement, however, fundamentally contradicts with\nthe non-custodial property and vision, on which Bitcoin and its\nmany permissionless follow-up variants are built upon.\nFor instance, the stablecoins USDT and USDC have a built-in\nsmart contract functionality to add specific blockchain addresses\non a blacklist (cf. Listing 1). Once a blockchain address is added\nto this blacklist, this address cannot send USDT or USDC coins or\ntokens any longer (while USDT can still be received). Moreover, the\ncompany behind USDT retains the capability to entirely zero the\nbalance of a blacklisted address. While we have not found a public\nstatement, we believe that the blacklist functionality was imple-\nmented due to a regulatory requirement. By collecting the entirety\nof the Ethereum blockchain events since USDT\u2019s and USDC\u2019s in-\nception, we observe that 449 accounts are blacklisted by the USDT\nsmart contract (8 of these accounts were removed from the black-\nlist) at the time of writing. Alarmingly, a total of over 43.97M USDT\nwere destroyed. The USDC contract features 8 blacklisted accounts.\nWe find no overlap between the USDT and USDC blacklist.\nDeFi \u201cBank Run\u201d The ability to blacklist, or even destroy cryp-\ntocurrency assets by a central body certainly contradicts DeFi\u2019s\nnon-custodial vision. Technically, such feature moreover endan-\ngers the intertwined DeFi ecosystem as we show in the following.\n5\nDeFi is heavily reliant on liquidity pools which are governed by\nsmart contracts accepting a variety of different tokens. A user that\ndeposits tokens in a liquidity pool, receives in return a liquidity\nprovider (LP) token, which accounts for the user\u2019s share in the pool.\nExchanges as well as lending platforms, such as Aave [61] and\nCurve [13], advertise various pools that contain USDT tokens. If\nthe company behind USDT would choose to block the address of\nthe smart contract liquidity pool containing USDT, all users of such\npools are affected, irrespective of whether their USDT are benign\nor illicit assets. An adversary with illicit USDT would moreover\nbe incentivised to deposit its illegally acquired USDT within such\nliquidity pools, as blacklisting the adversary\u2019s blockchain addresses\nwouldn\u2019t yield any effects thereafter.\nIf a Curve liquidity pool containing USDT is blacklisted by the\nUSDT emitter, all users of this pool would exit the pools through\nthe other (fungible) pool assets. To that end, the user will return to\nthe smart contract its LP tokens, and demand the non-blacklisted\nassets. Contrary to a bank run in CeFi, the smart contract will\nnot seize operation, but provide the user a possibly significantly\nworse exchange rate for the LP tokens. That is, because the pricing\nformula of liquidity pools typically penalizes users that move the\npool away from its assets equilibrium. Worryingly, such a DeFi\n\u201cbank run\u201d would cause in particular losses to those that act last.\nInsight 3: \u201cBank Run\u201d in DeFi\nIf an entity can single-handedly blacklist, censor, or destroy\nspecific cryptocurrency assets, this asset poses a danger to\nsmart contracts relying on its fungible property, and can\ntrigger a DeFi \u201cbank run\u201d. Contrary to a CeFi bank run,\na DeFi bank run will return assets to the user, however,\nat a much worse exchange rate. Smart contract liquidity\npools are currently not adept to fine-grained AML that\nCeFi relies upon.\n4\nCase by Case \u2014 Services\nIn the following we compare objectively various financial services\nand highlight how DeFi and CeFi differ respectively. We outline the\nservice architecture of CeFi and DeFi in Figure 3. Notably, oracles\nand stablecoins (specifically, stablecoins with the reserve of pegged\nasset mechanism) interconnect CeFi and DeFi.\nDeFi protocols frequently rely on CeFi data to function. Stable-\ncoins, for example, typically require the USD-to-cryptocurrency\nconversion rate to maintain the peg. However, blockchains do not\nnatively support access to off-chain data. Oracles are a third-party\nintermediary service that aims to address this issue by feeding ex-\nternal data (including CeFi data) into DeFi [62, 70, 79, 83, 139, 161,\n173, 187, 188]. Due to the high cost of writing data to the chain,\nthe frequency of an oracle\u2019s updates is typically several orders of\nmagnitude lower than the frequency of CeFi price changes.\n4.1\nCeFi vs. DeFi Exchanges\nAn exchange is a marketplace where financial instruments are\ntraded. Historically, this can occur on a physical location where\ntraders meet to conduct business, such as NYSE. In the last decades,\ntrading has transitioned to centralized electronic exchanges. A\nCeFi\nBroker\nExchange\nCentral Bank\nRegulator\nDeFi\nOracle\nAutomated Market Maker\nLending/Borrowing\nAlgorithmic\nLeveraged Loan\nReserve of Pegged Asset\nStablecoin\nWallet\nBank\nFigure 3: High-level service architecture of CeFi and DeFi.\nmodern electronic exchange typically consists of three components:\n(i) a price discovery mechanism, (ii) an algorithmic trade match-\ning engine, and (iii) a trade clearing system. The degree of decen-\ntralization of an electronic exchange depends on whether each of\nthese three components is decentralized. The literature and prac-\ntitioners community features various exchange designs based on\nblockchain architectures (DEX) [117, 178, 184], trusted execution\nenvironments (TEE) [80, 91, 93, 137, 138] and multi-party computa-\ntion (MPC) [126, 127] (cf. Table 1).\nExchanges can also be categorized based on the traded asset\npairs. Decentralized, blockchain-based clearing systems, typically\nonly support cryptocurrency assets, or tokens, and stablecoins rep-\nresenting fiat currencies. Contrary to DeFi, in centralized CeFi\nexchanges (CEX), there exists standalone custodians, and the ex-\nchange is segregated from the custodian for safety reasons, with\ncustodians typically being large banks [107, 131]. CEX can support\nthe flexible trading of both fiat and cryptocurrencies.\nFinancial Instrument Listing A CEX usually has specific as-\nset listing requirements [149, 155], including the provision of fi-\nnancial auditing and earning reports, minimum working capital\nstatements, etc. However, for centralized cryptocurrency exchanges,\nto our knowledge, there exists no binding legal requirement for as-\nset listings. Therefore, centralized cryptocurrency exchanges may\naccept, or refuse the listing of financial instruments due to sub-\njective or political reasons. One advantage of a DEX is that the\nexchange governance may be achieved in a decentralized manner,\nsuch that the listing of assets may be transparent. For instance,\nthe only requirement for a listing on Uniswap is that the financial\ninstrument meets the ERC20 standard [20].\nHigh-frequency Trading (HFT) HFT refers to automated trad-\ning strategies that aim to profit from short-term market fluctuations.\nPrevious research has revealed a variety of CEX HFT strategies and\ntheir economic impact, including arbitrage, news-based trading,\nalgorithmic market making, etc. [63, 69, 84, 141]. Although DEX\nare fundamentally different from CEX in terms of their technical\ndesign, traditional HFT strategies remain similar in DEX [96, 157].\nIn the following, we focus on one of the most basic HFT strategies,\nnamely two-point arbitrage, in which a trader purchases a financial\ninstrument in one market and then sells the same instrument at a\nhigher price in a different market. Two-point arbitrage eliminates\nshort-term price discrepancies between two markets, resulting in\nan increased market efficiency. Other types of HFT strategies are\n6\nTable 1: Comparison of different types of CeFi and DeFi exchanges.\nCentralized (CEX)\nHybrid\nDecentralized (DEX)\nExchange Name\nNASDAQ [38]\nCoinbase [5]\nIDEX [129]\n0x [184]\nTesseract [81]\nUniswap [178]\nCurrencies\nUSD\nFiat + Crypto\nCrypto\nCrypto\n-\nCrypto\nGovernance\nCentralized\nCentralized\nCentralized\nDAO\nCentralized\nDAO + smart contract\nPrice discovery mechanism\nCentralized\nCentralized\nCentralized\nDecentralized\nTEE\nSmart contract\nTrade matching engine\nCentralized\nCentralized\nCentralized\nDecentralized\nTEE\nSmart contract\nClearing system\nCentralized\nCentralized\nBlockchain\nBlockchain\nBlockchain\nBlockchain\nCan manipulate transaction order?\nRegulated\nRegulated\nYes\nYes\nNo\nYes (Miners)\nCan reject valid transaction?\nRegulated\nRegulated\nYes\nYes\nNo\nYes (Miners)\nsimilar to two-point arbitrage in terms of execution, despite being\ndifferent in their execution methodologies.\nArbitrage Execution HFT strategies are known to be fiercely\ncompetitive [63, 72, 76, 85, 116]. In the case of a two-point arbitrage\nopportunity, the arbitrageur with the fastest execution speed on\nboth exchanges remains profitable in expectation.\nIn CEX and hybrid exchanges, arbitrageurs typically interact di-\nrectly with a centralized service provider (e.g., the exchange itself)\nto obtain the most recent market state to execute their transactions.\nArbitrageurs invest in high performance computing resources and\noptimize their source code and hardware to achieve lower laten-\ncies [92]. Arbitrageurs are known to even physically relocate servers\ncloser to the corresponding exchange to further reduce network\nlayer latency. The recent advent of low-orbit satellite internet ser-\nvice [17], was shown to further reduce the global internet latency\nby as much as 50% [111], which we therefore expect to be a prime\ncommunication medium for HFT.\nMessages in blockchain-based DEX by design propagate on the\npublic peer-to-peer (P2P) network. Therefore, at the transaction\ncreation time, it is not known which node, or miner, will execute\nthe transaction. To gain a competitive advantage, an arbitrageur\nmust aim to reduce its latency to all major miners and mining pools.\nTo that end, arbitrageurs can run multiple blockchain nodes in\ndifferent physical locations around the world, as well as maximize\nthe number of connections for each node to decrease transaction\nreception latency [106] and transaction broadcast speeds [191].\nArbitrage Risks An arbitrage should ideally execute atomically\nto reduce the risks of price fluctuations. In practice, arbitrage on\ncentralized and hybrid exchanges is unavoidably subject to market\nprice fluctuations, unless the arbitrageurs are colluding with the\nexchanges to guarantee execution atomicity.\nArbitrage between two decentralized exchanges on the same\nblockchain can be considered risk-free, when ignoring transaction\nfees. This is because traders can use the blockchain atomicity feature\nto create a smart contract that executes the arbitrage, and reverts\nif the arbitrage does not yield a profit. If, however, an arbitrage\nattempt reverts, the trader is still liable to pay the transaction fees.\nIt should be noted that the atomicity property is only preserved\nfor arbitrage among different DEX on the same blockchain. If the\narbitrage involves two DEX on different blockchains, the arbitrage\nrisk can be considered similar to that of a CEX and hybrid exchange.\n4.2\nDeFi vs. CeFi Lending/Borrowing\nLending and borrowing are ubiquitous services in CeFi. Credit, of-\nfered by a lender to a borrower, is one of the most common forms\nof lending [9]. Credit fundamentally enables a borrower to pur-\nchase goods or services while effectively paying later. Once a loan\nis granted, the borrower starts to accrue interest at the borrowing\nrate that both parties agree on in advance. When the loan is due, the\nborrower is required to repay the loan plus the accrued interests.\nThe lender bears the risk that a borrower may fail to repay a loan on\ntime (i.e., the borrower defaults on the debt). To mitigate such risk,\na lender, for example, a bank, typically decides whether to grant a\nloan to a borrower based on the creditworthiness of this borrower,\nor mitigates this risk through taking collateral - shares, assets, or\nother forms of recourse to assets with tangible value. Creditwor-\nthiness is a measurement or estimate of the repaying capability\nof a borrower [10]. It is generally calculated from, for example,\nthe repayment history and earning income, if it is a personal loan.\nIn CeFi, both lenders and borrowers can be individuals, public or\nprivate groups, or financial institutions.\nOn the contrary, in DeFi, the lack of a creditworthiness system\nand enforcement tools on defaults leads to the necessity of over-\ncollateralization in most lending and borrowing protocols (e.g.,\nAave [61], Compound [102]). Over-collateralization means that a\nborrower is required to provide collateral that is superior to the\noutstanding debts in value. Such systems are also widespread in\nCeFi and are known as margin lending or repo-lending [128]. The\nmost prevalent form of lending and borrowing in DeFi happens in\nthe so-called lending pools. A lending pool is in essence a smart\ncontract that orchestrates lender and borrower assets, as well as\nother essential actors (e.g., liquidators and price oracles). Typically,\na lender makes cryptocurrencies available for borrowing by de-\npositing them into a lending pool. A borrower hence collateralizes\ninto and borrows from the lending pool. Note that borrowers also\nautomatically act as lenders when the lending pool lends out the\ncollateral from borrowers. Assets deposited by users in lending\npools are not protected by traditional CeFi regulations such as bank\ndeposit protection which protects a banking institution\u2019s customer\ndeposit account up to a certain threshold of fiat currency.\nTo maintain the over-collateralization status of all the borrowing\npositions, lending pools need to fetch the prices of cryptocurrencies\nfrom price oracles. Once a borrowing position has insufficient col-\nlateral to secure its debts, liquidators are allowed to secure this posi-\ntion through liquidations. Liquidation is the process of a liquidator\nrepaying outstanding debts of a position and, in return, receiving\n7\nthe collateral of the position at a discounted price. At the time\nof writing, there are two dominant DeFi liquidation mechanisms.\nOne is the fixed spread liquidation, which can be completed in one\nblockchain transaction [61], while the other one is based on auc-\ntions that require interactions within multiple transactions [103].\nUnder-collateralized borrowing still exists in DeFi (e.g., Alpha\nHomora [27]), while being implemented in a restricted manner. A\nborrower is allowed to borrow assets exceeding the collateral in\nvalue, however, the loan remains in control of the lending pool\nand can only be put in restricted usages (normally through the\nsmart contracts deployed upfront by the lending pool). For example,\nthe lending pool can deposit the borrowed funds into a profit-\ngenerating platform (e.g., Curve [13]) on behalf of the borrower.\nFlash Loans A novel lending mechanism, which only exists\nin DeFi, are flash loans [158]. A flash loan is initiated and repaid\nwithin a single, atomic blockchain transaction, in which a borrower\n\ud835\udc35performs the following three actions:\n(1) \ud835\udc35requests assets from a flash loan lending pool.\n(2) \ud835\udc35is free to use the borrowed assets arbitrarily.\n(3) \ud835\udc35repays the flash loan plus interests to the lending pool.\nThe transaction atomicity property (cf. Section 2.3) ensures that, if\nthe borrower cannot repay the flash loan by the end of the trans-\naction, the on-chain state remains unmodified (i.e., as if no flash\nloan was granted) [65, 158]. Therefore, although the borrowers do\nnot provide collateral for the loan, the lenders can be sure, that the\nborrowers cannot default on their debt.\nFlash loans are widely applied in DeFi arbitrages and liquidations,\nas they allow to eliminate the monetary risks of holding upfront\nassets [158, 183]. Flash loans, however, also facilitate DeFi attacks\nthat have caused a total loss of over 100M USD to victims in the\nyear 2020 alone [15, 28, 33, 158]. Despite the fact that flash loans\nare not the root vulnerability of these DeFi attacks, they do give\nadversaries instant access to billions of USD, costing only a minor\nupfront cost (i.e., the blockchain transaction fees). To our knowledge\nsuch instantaneous loans have no counterpart in CeFi.\nInsight 4: Flash loans facilitate DeFi attacks\nFlash loans are typically not the cause, but facilitate DeFi\nattacks by granting adversaries instant access to billions\nof USD of capital. In essence these loans therefore democ-\nratize access to capital, lowering the barriers of entry to a\nmarket which traditionally is exclusive to few in CeFi.\nRisk Free Rate of Return The risk-free rate of return is a cru-\ncial concept in CeFi, referring to the theoretical rate of return that\nan investor expects to earn from a risk-free investment [43]. The\nnotion is critical to a functioning financial system and underpins\nvaluation of almost every major financial product, bank deposit,\nloans, government/corporate bond, and the valuation of stocks. Al-\nthough there exists no absolutely risk-free investment opportunity\nin practice, the interest rate of some investments with a negligible\nrisk is commonly considered as the risk-free rate. For instance, U.S.\ngovernment bonds are generally used as risk-free rates because it\nis unlikely that the U.S. government will default on its debt [58].\nIt is unclear whether a risk-free investment opportunity exists in\nDeFi, especially when we consider the various risks imposed by\nthe underlying smart contracts and blockchain consensus (e.g., po-\ntential smart contract program bugs). We, however, observe that\nseveral DeFi protocols may yield revenue in a risk-free manner, if\nwe only consider the high-level economic designs while ignoring\nthe risks from the underlying layers3. For example, MakerDAO,\nthe organization behind the stablecoin DAI (cf. Section 4.3), offers\ninterests to the investors who deposit DAI into a smart contract at\nthe so-called DAI saving rate (DSR). DSR is a fixed non-negative\ninterest rate, which is convertible through a governance process.\nSimilarly, the interests generated from the aforementioned lending\nplatforms (e.g., Aave, Compound) are generally considered low-risk.\nThe lending interest rate is typically determined algorithmically\nthrough the supply and demand of the lending pool, which is hence\nmore variable than the DAI saving rate. At the time of writing,\nMakerDAO offers a DAI saving rate of 0.01%. The estimated an-\nnual percentage yield (APY) of DAI on Compound and Aave is\n3.18% and 5.65%, respectively. As a comparison, the U.S. 10-year\ngovernment bond has a 1.623% yield [51].\n4.3\nCeFi vs. DeFi Stablecoins\nCryptocurrencies are notoriously known for their price volatility\nwhich appeals to speculators. However, conservative traders may\nprefer holding assets that are less volatile. Stablecoins are hence\ndesigned to satisfy such demand and offer better price stability.\nThe price of a stablecoin is typically pegged to a fiat currency (e.g.,\nUSD), which is less volatile than most cryptocurrencies. Following\nrelated work [144], we proceed to summarize the dominating DeFi\nstablecoin mechanisms.\nReserve of Pegged Asset One method to create a stablecoin is to\ncollateralize the asset that the stablecoin should be pegged to (e.g.,\nUSD) in a reserve to back the value of the minted stablecoin. Such\nmechanism commonly requires a centralized and trusted authority\nto manage the collateralized assets. This authority is permitted\nto mint the stablecoin, while any entity is allowed to burn the\nstablecoin in exchange for the collateral at the pegged price (e.g.,\nburning one unit of USD stablecoin allows to redeem $1). When\nthe stablecoin price declines below the pegged price, arbitrageurs\nare incentivized to purchase the stablecoin to redeem the collateral,\nwhich in return supports the stablecoin price. Conversely, when\nthe price rises above the peg, more stablecoins are minted and\nhence the expanded supply may depreciate its price. In this way,\nsuch mechanism aims to stabilize the minted stablecoin value to\nthe pegged asset. With an accumulated volume of over 49B USD,\nUSDT and USDC are the most circulated stablecoins following the\nabove mechanism. According to our CeFi-DeFi decision tree (cf.\nFigure 1), the stablecoins adopting the asset reserve mechanism are\nnon-custodial. Second, a stablecoin transaction cannot be censored\nby a third party. However, given the blacklist functionality (cf.\nSection 3), the stablecoin issuing authority can censor the protocol\n3In CeFi, the risk free rate of return is typically defined regionally. Local currency\ninvestors use the central bank bond yields of their respective countries to estimate their\nindividual risk-free rate. For example, an investor based in Brazil whose P&L currency\nis BRL will rely on the interest rate of Brazilian government bonds for estimating\npremium of their investments over their BRL-denominated risk-free rate. In such\ncontext, we deem a DeFi investment opportunity risk-free, when it is programmatically\nguaranteed to offer a positive return in the same invested cryptocurrency.\n8\n$0.99\n$1.00\n$1.01\nUSDT\n$0.99\n$1.00\nUSDC\n$1.00\n$1.05\nPrice (USD)\nDAI\n$1.00\n$2.00\n$3.00\nAMPL\n2020-01\n2020-03\n2020-05\n2020-07\n2020-09\n2020-11\n2021-01\n2021-03\n2021-05\nYYYY-MM\n$1.00\n$5.00\n$9.00\n$13.00\nESD\nFigure 4: Prices of USD stablecoins, USDT, USDC, DAI, AMPL, and ESD from January, 2020 to May, 2021. We crawl the price\ndata from https://www.coingecko.com/.\nexecution. Therefore, such stablecoins are instances of centrally\ngoverned DeFi. Moreover, the main drawback of this stablecoin\nmechanism is the necessity of a trusted authority. The authority\u2019s\nability to blacklist addresses may help with regulatory compliance\n(cf. Section 3) but harms the decentralization of DeFi.\nLeveraged Loans The mechanism of leveraged loans also relies\non collateral to secure the value of a stablecoin. Instead of collat-\neralizing fiat assets, which demands a centralized authority, the\nleveraged loan mechanism accepts cryptocurrencies (e.g., ETH) as\ncollateral. DAI is the most prominent stablecoin that follows this\nmechanism. To mint DAI, a user creates a Collateralized Debt Posi-\ntion (CDP) by locking cryptocurrencies into a smart contract. In the\nfollowing, we refer to this user as the CDP owner. The CDP owner is\nallowed to mint DAI from the CDP, where the minted DAI becomes\nthe owner\u2019s debt. A CDP is required to be 1.5\u00d7 over-collateralized,\ni.e., the value of the collateral represents at least 150% of the debt.\nOtherwise, the CDP would become available for liquidations (cf.\nSection 4.2). When compared to the asset reserve mechanism, the\nover-collateralization design makes the leveraged loan mechanism\nless capital efficient. For instance, a collateral of 150B USD can mint\nat most 100B USD of leveraged loan stablecoins.\nAlgorithmic Supply Adjustments Instead of collateralizing fiat\nor other cryptocurrencies, an algorithmic stablecoin attempts to\nmaintain the stablecoin price autonomously. Specifically, the algo-\nrithmic supply adjustment mechanism adjusts the supply of the\nstablecoin in response to price fluctuations. The main idea of an\nalgorithmic stablecoin is that the adjustment of the supply can\neffectively drive the price of the stablecoin towards the desired\ntarget. Typically, the adjustment algorithm is encoded within a\nsmart contract. Therefore, the supply adjustment can be processed\nautonomously without a central entity.\nIn Figure 4, we present the prices of five stablecoins. USDC\nand USDT are reserve-based, while DAI relies on leveraged loans.\nAMPL and ESD, are algorithmic stablecoins. We find that the re-\nserve mechanism appears the most stable among the dominating\nstablecoin solutions, with a price fluctuation range between $0.99\nand $1.01 since January 2020. DAI is less stable than USDC and\nUSDT, but shows increasing stability since January 2021. To our\nsurprise, the mechanisms of algorithmic supply adjustments appear\nineffective in stabilizing the price. AMPL fluctuates between $0.50\nand $3.83. ESD presents a downtrend deviating from the $1 target\nprice, closing at $0.1 at the time of writing.\nAlthough the term stablecoin emerged in DeFi, CeFi aims for\ndecades to stabilize currency prices [37]. The Hong Kong dollar\n(HKD), for example, is pegged to the US dollar [57], permitted to be\ntraded at a tight interval between 7.75 and 7.85 USD [59]. Within\nthis price range, the Hong Kong Monetary Authority intervenes\nthrough buying or selling the currency.\nInsight 5: Algorithmic stablecoins are less stable in practice\nGiven empirical data, we observe that stablecoins based on\nthe mechanism of algorithmic supply adjustments offer less\nstability than reserve and loan based stablecoin models.\n5\nCase by Case \u2014 Economics & Manipulation\nNext we dive into the economic and market manipulation aspects\nof CeFi and DeFi.\n9\n5.1\nCeFi vs. DeFi Inflation\nInflation is defined as the devaluation of an existing currency supply,\nthrough the addition of more supply [120]. While inflation is the loss\nof purchasing power of a currency, the relationship between supply\nand inflation may not always manifest itself directly \u2014 sometimes\nmoney supply increases, but does not cause inflation [86].\nIn CeFi, central banks retain the authority to create their re-\nspective fiat currency, and inflation is typically measured against\nthe value of \u201crepresentative basket of consumer goods\u201d, or a con-\nsumer price index (CPI) [119]. The official policy goal of central\nbanks in developed markets is to keep the inflation at or around\n2.0% [75, 152]. Inflation in developed countries in recent decades\nhas rarely diverged from central bank official targets. While there\nhave been several notable instances of high inflation or hyperinfla-\ntion historically (Germany 1923, USA in 1970s, certain emerging\nmarket countries like Argentina, Venezuela, Zimbabwe), in recent\ndecades official inflation figures in the USA, Europe, and other\nmajor economies have rarely been above 3.0%.\nHowever, despite the positive picture painted by central banks,\nmany market participants doubt whether the basket of consumer\ngoods is representative. Various social group baskets can vary dra-\nmatically, making the 2.0% headline inflation rate irrelevant in their\ncontext. In the USA, in recent decades the richest 1% of the popu-\nlation have seen their incomes rise at a much faster pace than the\nbottom 50%, who have seen little inflation-adjusted increase. For\nexample, as of mid-April 2021, the year-to-date increase in price\nof Lumber is circa 40% [176], the main cost component in house\nconstruction, while the CPI in the USA is at 2.6% [154]. This, and\nsimilar increases in prices of many goods, have cast doubts whether\nthe official inflation figures really measure inflation accurately.\nCentral banks have learned to print money without causing\nbroad CPI-inflation - rather than giving money directly to con-\nsumers like in 1920s Germany, money is now effectively distributed\nto asset holders \u2014 so they can purchase more risky assets, driving\ntheir prices up. This, in turn, supports the economy by ensuring peo-\nple with capital continue investing and creating jobs. The flipside\nis that people who do not own assets, see the value of their savings\ninflated away. Bitcoin\u2019s fixed supply protects from the risk of the\ncurrency being printed into zero (like Venezuela or Zimbabwe did),\nhowever, whether having a fixed supply is advantageous is not yet\nclear. Fiat currencies also used to have a fixed supply system similar\nto that of Bitcoin - until 1974 when the gold standard was scrapped,\nand each dollar no longer had to be backed by a specific quantity\nof gold [97]. The standard was scrapped because it constrained\ncountries\u2019 ability to support economic activity.\nSome cryptocurrencies have variable asset supply. Bitcoin even-\ntually is likely to run into the issue where supply has a hard cap\n\u2014 while the economic activity it has to support does not have a\ncap \u2014 leading to a shortage of currency. Related work suggests\nthat Bitcoin, or blockchains in general, without a block reward, and\nhence without inflation, might be prone to security instabilities [87].\nWhether Bitcoin and other cryptocurrencies end up suffering from\nhigh income inequality from the inflation built into the fiat system\nis yet to be seen \u2014 there is no conclusive track record as of yet to\nsuggest cryptocurrencies solve this problem. Many people have\ncome to see cryptocurrencies as a way to liberate themselves from\nCeFi\nDeFi\nFinancial Institution\nwithdraw\nwithdraw\nCryptocurrency Mixer\npro\ufb01t\nDeFi Protocols\nattack\ndeposit\nTainted Wallet\ntransfer\nBenign Wallet\ndeposit\ntransfer\ndeposit\nwithdraw\nFigure 5: Example of money laundering with a DeFi attack.\nthe influence of central banks [169]. Ethereum, however, bears an\ninflation rate of about 4%. This metric is most directly comparable\nto measures of monetary mass, such as M1 [101], which, by contrast,\nincreased by circa 250 percent in 2020, due to money printing by\nthe Federal Reserve.\n5.2\nMixer and DeFi Money Laundering\nTo our knowledge, for blockchains without native privacy preserv-\ning functionality, address linkability (i.e., the process of linking \ud835\udc5b\nblockchain addresses to the same entity) can only be broken with\na mixing service. A mixer allows users to shuffle their coins with\nthe coins of other users [68, 104, 118, 142, 166]. This may appear\nsimilar to CeFi\u2019s traditional money laundering techniques, in which\nthe money launderer mixes tainted, or \u201cdirty\u201d, and \u201cclean\u201d money.\nThe literature contains a number of proposals for mixer services\nthat can be either centralized or governed by smart contracts. Be-\ncause of DeFi\u2019s traceability, the source and amounts of both benign\nand illicit assets, as well as the anonymity set sizes, the source\ncode and the mixing cost, are all public. Ironically, from a technical\nstandpoint, this transparency greatly reduces the risk of the money\nlaunderer. Worryingly, mixer services have begun to reward their\nusers for participation, providing an economic reason for DeFi users\nto provide untainted assets to help money laundering [49, 132].\n5.3\nCeFi vs. DeFi Security and Privacy\nDeFi attacks can be broadly classified into five attack types: (i) net-\nwork layer; (ii) consensus layer; (iii) financial institution; (iv) smart\ncontract code; and (v) DeFi protocol and composability attacks. At-\ntacks of type (iii) and (iv) use a mixer to perform money laundering\n(cf. Figure 5). In the following sections, we outline each attack type.\nNetwork Layer Attacks Previous research has revealed how\nan adversary can partition the blockchain P2P network without\nmonopolizing the victim\u2019s connections. This allows an adversary\nto control the victim node\u2019s view of the blockchain activity. Eclipse\nattacks can occur at the infrastructure layer (such as BGP hijack-\ning [73, 167]) or during blockchain message propagation [106].\nOther types of common network attacks, such as DDoS [163],\nMitM[98], and wireless network attacks [151], are also possible in\nDeFi. An attacker could, for example, use the evil twin attack [130]\nto impersonate a wireless access point to trick users into connecting\nto bogus DeFi smart contracts. For further information, we refer\nthe interested reader to previous literature [162].\nConsensus Layer Attacks Consensus attacks such as double\nspending [124, 125] and selfish mining [99, 108, 164] endanger the\nstability and integrity of the DeFi settlement layer. For more details,\nwe refer the reader to extensive previous studies [105, 134, 135].\n10\nFinancial Institution Attacks Ideally and to maintain its de-\ncentralized vision (cf. Figure 1), DeFi should solely rely on smart\ncontracts ignoring third party intermediaries. However, in practice,\nDeFi is still heavily reliant on centralized intermediaries such as wal-\nlet providers (MetaMask [34], Coinbase wallet [7], etc.), blockchain\nAPI providers (Infura [30]), mining pools (SparkPool [47], Ether-\nmine [22], etc.) and oracles [173]. Aside the risks of downtime and\ncode vulnerabilities, it is important to note that these intermediaries\nare typically run by physical businesses that may be forced to close\ndue to local laws and regulations [3].\nSmart Contract Code Attacks Smart contract vulnerabilities\nin DeFi have already caused at least 128M USD of losses to users (cf.\nTable 3) [16, 29, 40, 42, 52]. Common vulnerability patterns include\ninteger overflow, reentrancy, timestamp dependencies, etc [74]. For\nexample, in April 2020, the lending platform \u201cLendf.Me\" suffered a\nre-entry attack, resulting in the loss of 25M USD in funds [29]. To\nour knowledge, the most significant smart contract code vulnera-\nbility resulted in an adversarial profit of 57M USD on the \u201cUranium\nFinance\" platform in April 2021 [52].\nDeFi Protocol and Composability Attacks DeFi\u2019s atomic com-\nposability can result in creative economic attacks (cf. Table 3). To\nour knowledge, \u201cValue DeFi\u201d is the target of the most severe compos-\nability attack on Ethereum, in which the adversary manipulated the\nprice oracle in November 2020 to extract 740M USD in profit [54].\n\u201cPancakeBunny\u201d suffered the to date most severe composability\nattack on the Binance Smart Chain in May 2020, resulting in a total\nloss of 45M USD [46].\nDeFi Privacy While CeFi institutions are professionals at pre-\nserving their customer\u2019s privacy, DeFi\u2019s transparency discloses ex-\ntensive information about the users\u2019 assets and transactions. There-\nfore, multiple corporations offer services to governmental bodies,\nand law enforcement to trace and analyze blockchain-related finan-\ncial transactions [21, 88]. Achieving privacy in DeFi hence appears\nas one of the most challenging future research directions. Related\nwork goes as far as claiming an impossibility result on automated\nmarket makers [71].\n5.4\nCeFi vs. DeFi Market Manipulation\nMarket manipulation describes the act of intentional or willful con-\nduct to deceive or defraud investors by controlling the price of\nfinancial instruments [45]. Market manipulation harms market fair-\nness and honest traders\u2019 rights and interests, regardless of whether\nthe maleficent actor is the exchange or an internal/external trader.\nMarket \nManipulation \nTechniques\n(a) External \nManipulation\n(b) Exchange Based \nManipulation\n(i) Action Based\n(ii) Information Based\n(iii) Trade Based\n(iv) Order Based\nFigure 6: Classification of market manipulation techniques.\nMarket manipulations can be broadly classified into two cat-\negories based on whether they involve an exchange, namely (a)\nexternal manipulation and (b) exchange-based manipulation (cf.\nFigure 6). Previous research has further classified market manipu-\nlations into four sub-categories [64, 171]: (i) Action-based, where\nthe manipulator alters the actual or perceived value of the finan-\ncial instrument without trading activities; (ii) Information-based\nmanipulation, through the dissemination of false information or\nrumors. (iii) Trade-based manipulation, where a manipulator buys\nor sells financial instruments in a predetermined manner; and (iv)\nOrder-based manipulation, where a manipulator cancels the placed\norders before their execution.\nIt appears that action- and information-based manipulations are\nless reliant on the technical details of the underlying financial sys-\ntem. Therefore, external manipulation techniques for CeFi and DeFi\nare similar. However, exchange-based market manipulations, espe-\ncially order-based HFT manipulations, rely heavily on the technical\narchitecture. In Table 2, we present a taxonomy for DeFi related ma-\nnipulation techniques. We omitted CeFi manipulation techniques\nthat are not viable in DeFi4.\nMEV and Market Manipulation as a Service Miner Extractable\nValue (MEV) can be captured by miners [96], as well as non-mining\ntraders. When miners create a block, they have the unilateral power\nto momentarily decide what transactions to include, in what order.\nAs a result, MEV extraction is frequently associated with trade-\nbased market manipulation techniques like front-running [96],\nback-running [157], and sandwich attacks [191]. Worryingly, re-\nlated work found that miners collaborate with centralized interme-\ndiaries to sell market manipulation as a service (MMaas) [35, 157].\nAlthough MMaas lacks underlying principles or concepts of fair-\nness and social benefits in general [122], at the time of writing this\npaper, there is no regulation prohibiting MEV extraction or market\nmanipulations in DeFi.\nInsight 6: DeFi Market Manipulations and the Wild Wild West\nAt the time of writing, world-wide regulations mostly do\nnot account for the possible market manipulations feasible\nin DeFi, such as front-, back-running and sandwich attacks.\nAs such, it appears that DeFi regulations remain at a state\nwhere CeFi was before the securities act of the year 1933.\n6\nSynergies between CeFi and DeFi\nDeFi is still in its infancy. Due to the blockchain settlement layer,\nDeFi maintains unique properties to CeFi, such as non-custody,\ntransparency, and decentralization. However, the blockchain also\nlimits DeFi\u2019s transaction throughput, transaction confirmation la-\ntency, and privacy. Ultimately, DeFi and CeFi share the same goal:\nto provide customers with high-quality financial products and ser-\nvices, and to power the entire economy. Summarizing, DeFi and\nCeFi each have their own set of advantages and disadvantages, and\nwe cannot find a trivial way to combine the best of both systems.\nTherefore, we believe that these two distinct but intertwined finan-\ncial systems will coexist and improve each other. In the following\nwe present selected synergy opportunities.\n4benchmark manipulation, wash sales, scalping, layering etc. [112, 113, 121, 136, 171]\n11\nTable 2: Taxonomy of market manipulation techniques. CeFi manipulation techniques that are not viable in DeFi are omitted.\nCategory\nTechnique\nDifferences compared with CeFi\nReferences\nAction-\nPonzi scheme\nPayout rules are clearly written in smart contracts, which cannot be changed once deployed.\n[77, 78, 89, 90, 143]\nHoneypot\nA new type of market manipulation in DeFi that combine security issues with scams.\n[175]\nInfo-\nFraudulent financial statements\nOn-chain data is transparent, but intermediaries may reveal fraudulent financial statements.\n[109]\nPump and dump/Short and distort\n-\n[110, 123, 133, 186]\nTrade-\nWash trade/Matched orders/Painting the tape\nCeFi exchanges can fabricate volume, while DeFi wash traders must pay transaction fees.\n[66, 95, 158, 181]\nInsider trading\n-\n[67, 179]\nCornering\n-\n-\nCapping\n-\n-\nMarking the close\nDeFi does not have market opening or closing times.\n-\nFront-/back-running, sandwich\nBlockchain transaction orders are enforced by miners, which can be bribed.\n[96, 157, 189, 191]\nClogging/ Jamming\nClogging on the blockchain was used to win gambling applications.\n[157]\nChurning\nA centrally governed DeFi application may misuse users\u2019 assets to generate excessive fees.\n-\nOrder-\nRamping/Advancing the bid/ Reducing the ask\nIn DeFi, transaction fees may deter an adversary from these practices.\n-\nSpoofing/Pinging\nThese attacks are nearly free of cost on the DeFi network layer.\n[172]\nQuote stuffing\nRelated works observed quote stuffing through back-run flooding.\n[190]\n6.1\nBridges\nFinancial institutions are bridging DeFi and CeFi to improve their ef-\nficiency. Oracles such as Chainlink transfer CeFi data to DeFi [173];\nSynthetix allows users to trade CeFi financial instrument as deriva-\ntives on DeFi [174]; and the Grayscale Bitcoin Trust enables users\nto trade Bitcoin on CeFi over-the-counter market (OTCQX) [26].\n6.2\nDeFi: An Innovative Addition to CeFi\nWe observe that DeFi protocols not only copy fundamental CeFi\nservices, but optimize them to the unique blockchain properties.\nFor example, a new exchange mechanism called Automated Mar-\nket Maker (AMM) [191] replaces in DeFi the prevalent order-book\nmodel of CeFi. An AMM is a smart contract that takes assets from\nliquidity providers. Traders hence trade against the AMM smart\ncontract instead of interacting with liquidity providers directly. The\nAMM design requires fewer interactions from the market makers\nthan a CeFi order book, which reduces transaction costs. We no-\ntice that CeFi is absorbing such innovations in turn. Centralized\nexchanges (e.g., Binance) start to provide market making services\nfollowing an AMM model [56]. Certain CeFi markets, such as FX\nhave employed a blend of the AMM model with human interven-\ntion, are well-positioned to enter the market-making business in\nDeFi, while incumbent DeFi AMM providers may adopt some of\nthe CeFi techniques to reduce their customers\u2019 exposure to arbi-\ntrageurs [153]. We anticipate more innovative DeFi protocols, e.g.,\nliquidity mining and lending pools with algorithmic interest rates,\nwill be ported over to CeFi in the near future.\n6.3\nDeFi Collapse: A Lesson for CeFi?\nOn the 12th of March, 2020, the cryptocurrency market collapsed,\nwith the ETH price declining over 30% within 24 hours [18]. On\nthe 19th of May, 2021, the ETH price again dropped by more than\n40% [11]. CeFi markets experienced a similar degree of distress\n(although with less extreme daily movements), with the Dow Jones\nIndustrial Average declining by 9.99%, with the day earning the\nname of \u201cBlack Thursday\u201d.\nBoth CeFi and DeFi experienced severe stress throughout these\ncrashes. Centralized exchange services were interrupted due to an\nunprecedented number of trading activities (e.g., Coinbase halted\ntrading for over one hour [6]) and exchanges were temporarily\nclosed down after hitting pre-determined daily movement lim-\nits [94]. Similarly, on Ethereum, the gas price increased sharply,\nto the point that a regular ETH transfer costed over one hundred\nUSD. The resulting network congestion delayed the confirmation of\nusers\u2019 transactions and caused the failure of MakerDAO liquidation\nbots [32] in February 2020. Unlike CeFi, DeFi services are technically\nalways available because of the distributive nature of blockchains.\nHowever, in the aforementioned extreme cases, the DeFi systems\nbecome prohibitively expensive for most users. Since then, more\nattention was given to the robustness of DeFi protocols [31].\nAlthough CeFi and DeFi have different settlement mechanisms\nand user behaviors, DeFi\u2019s stress tests may be invaluable lessons for\nCeFi. While CeFi relies on circuit-breakers to ease excessive asset\nvolatility [4] (markets halt trading upon volatility beyond custom\nthresholds), DeFi has to date apparently well coped without such\ninterruptions and may help CeFi to better understand its limits.\nWho\u2019s responsible? The presence of a centralized counter-\nparty in CeFi, puts an implicit degree of responsibility on the central\ncounterparty to maintain an orderly marketplace. Although not\nspecifically codified, there is an implicit market expectation, built\nover the recent years, that the central bank will step at in times of\nsevere crashes, either through verbal support, or through increasing\nthe supply of money (lowering the central bank interest rates or\nprinting more money through repurchases of government debt)\nto support asset prices. For example, in March 2020, the Federal\nReserve drastically expanded money supply, slashed interest rates\nto near-zero, prompting a rapid recovery in equity prices. By con-\ntrast, in DeFi, there is no such central counterparty responsible for\nsupporting asset prices in times of crises, and the closest equivalent\nto the CeFi mechanism are \u201cshow of confidence\u201d measured by cryp-\ntocurrency influencers \u2014 founders of major cryptocurrencies, social\nmedia influencers, exchanges, and well-regarded adopters. Market\ncrashes can be extremely destructive to the economic well-being\nof a society, and through history of CeFi market participants have\nsought to reduce the incidence of crashes. DeFi, so far, has gone\nthrough fewer crashes, and is likely to need to adopt some of the\nCeFi crash-prevention features as it gains mainstream adoption.\n12\nInsight 7: CeFi and DeFi\nWe expect CeFi and DeFi to co-exist, to complement, to\nstrengthen and to learn from each others\u2019 experiences,\nmistakes and innovations. CeFi and DeFi are already today\ntightly intertwined (e.g., through centrally controllable\nstablecoins) and have jointly allowed the onboarding of a\nwider (e.g., technical) user demographic.\n7\nConclusion\nUnder the above scrutiny, CeFi and DeFi may not appear as different\nas one might expect. The most prevalent distinguishing features are\n(i) who controls the assets, (ii) how transparent and accountable\nis the system, and (iii) what privacy protections exist for the end\nuser? In this work, we provide a first taxonomy to objectively differ-\nentiate among CeFi and DeFi systems, its services, and ultimately\nfind that DeFi already deeply incorporates CeFi assets (e.g., USD-\nC/USDT stablecoins) and practices (such as market manipulations).\nWe ultimately hope that this work provides a bridge for both the\nCeFi and the DeFi audiences, to work together, learn from each\nothers\u2019 mistakes towards constructing resilient, user friendly and\nefficient financial ecosystems.\nAcknowledgments\nThe authors would like to thank Philipp Jovanovic for providing\nhelpful comments on an earlier version as well as Xihan Xiong for\ncollecting DeFi attacks in Table 3.\nReferences\n[1] Analysis: Proposed fatf guidance for virtual assets and vasps - ciphertrace.\nhttps://ciphertrace.com/analysis-proposed-fatf-guidance-for-virtual-assets-\nand-vasps/.\n[2] Anti-money laundering regulation for all crypto exchanges on austrac\u2019s wish\nlist | zdnet. https://www.zdnet.com/article/anit-money-laundering-regulation-\nfor-all-crypto-exchanges-on-austracs-wish-list/.\n[3] China crypto mining business hit by beijing crackdown, bitcoin tumbles. https:\n//www.reuters.com/world/china/crypto-miners-halt-china-business-after-\nbeijings-crackdown-bitcoin-dives-2021-05-24/.\n[4] Circuit breaker definition. https://www.investopedia.com/terms/c/circuitbrea\nker.asp.\n[5] Coinbase. https://www.coinbase.com.\n[6] Coinbase, binance outage: exchanges go offline during crypto sell-off | fortune.\nhttps://fortune.com/2021/05/19/coinbase-binance-outage-crypto-bitcoin-\ncrash/.\n[7] Coinbase wallet. https://wallet.coinbase.com.\n[8] Cover protocol. https://www.coverprotocol.com/.\n[9] Credit definition. https://www.investopedia.com/terms/c/credit.asp.\n[10] Creditworthiness definition. https://www.investopedia.com/terms/c/credit-\nworthiness.asp.\n[11] The crypto collapse: Here\u2019s what\u2019s behind bitcoin\u2019s sudden drop. https://ww\nw.cnbc.com/2021/05/19/the-crypto-collapse-heres-whats-behind-bitcoins-\nsudden-drop.html.\n[12] Crypto lending rates - earn crypto interest by defi lending. https://defirate.co\nm/lend/.\n[13] Curve.fi. https://curve.fi/.\n[14] Decentralized finance needs regulatory clarity and smarter compliance. https:\n//www.withersworldwide.com/en-gb/insight/decentralized-finance-needs-\nregulatory-clarity-and-smarter-compliance.\n[15] Defi deep dive \u2013 what is the bzx protocol? https://academy.ivanontech.com/blo\ng/defi-deep-dive-what-is-the-bzx-protocol.\n[16] Defi project akropolis drained of $2m in dai. https://www.coindesk.com/defi-\nproject-akropolis-token-pool-drained.\n[17] Defi status report post-black thursday - defi pulse. https://www.starlink.com.\n[18] Defi status report post-black thursday - defi pulse. https://defipulse.com/blog/\ndefi-status-report-black-thursday/#:~:text=On%20Thursday%20March%2012%\n2C%202020,%2C%20bolstering%20collateral%20ratio%2C%20etc.\n[19] Documents - financial action task force (fatf). https://www.fatf-gafi.org/pu\nblications/fatfrecommendations/documents/public-consultation-guidance-\nvasp.html.\n[20] Eip-20: Erc-20 token standard. https://eips.ethereum.org/EIPS/eip-20.\n[21] Elliptic. https://www.elliptic.co.\n[22] Ethermine. https://ethermine.org.\n[23] Fatf-gafi.org - financial action task force (fatf). https://www.fatf-gafi.org/.\n[24] Fatf\u2019s new guidance takes aim at defi - coindesk. https://www.coindesk.com/f\natfs-new-guidance.\n[25] The future of client onboarding - fintech futures. https://www.fintechfutures.co\nm/2018/09/the-future-of-client-onboarding/.\n[26] Grayscale bitcoint trust. https://grayscale.com/products/grayscale-bitcoin-\ntrust/.\n[27] Home - alpha finance lab. https://alphafinance.io.\n[28] Home | prevent flash loan attacks. https://preventflashloanattacks.com/.\n[29] How did lendf.me lose $25 million to a reentrancy attack? [an analysis]. https:\n//hackernoon.com/how-did-lendfme-lose-dollar25-million-to-a-reentrancy-\nattack-an-analysis-091iy32s7.\n[30] Infura. https://infura.io.\n[31] Liquidations 2.0: Technical summary - governance / proposal ideas - the maker\nforum. https://forum.makerdao.com/t/liquidations-2-0-technical-summary/46\n32.\n[32] The market collapse of march 12-13, 2020: How it impacted makerdao. https:\n//blog.makerdao.com/the-market-collapse-of-march-12-2020-how-it-\nimpacted-makerdao/.\n[33] Market dynamics of the 1st bzx hack: Flash loans and the insolvent loan. https:\n//quantstamp.com/blog/market-dynamics-of-the-1st-bzx-hack-part-1.\n[34] Metamask. https://metamask.io/.\n[35] Mev monster. https://mev.monster.\n[36] Ml 7.1 the money laundering reporting officer - fca handbook. https://www.ha\nndbook.fca.org.uk/handbook/ML/7/1.html?date=2005-04-02.\n[37] Monetary policy: Stabilizing prices and output - back to basics: Finance &\ndevelopment. https://www.imf.org/external/pubs/ft/fandd/basics/monpol.htm.\n[38] Nasdaq. https://www.nasdaq.com.\n[39] New fatf draft guidance to regulate p2p transfers, defi, dexs, nft and stablecoins\n- sygna. https://www.sygna.io/blog/fatf-draft-guidance-on-rba-to-virtual-\nassets-and-vasps-public-consultation-march-2021/.\n[40] Origin dollar incident: Root cause analysis. https://peckshield.medium.com/or\nigin-dollar-incident-root-cause-analysis-f27e11988c90.\n[41] Outages continue to plague online brokerages - wsj. https://www.wsj.com/arti\ncles/outages-continue-to-plague-online-brokerages-11611768827.\n[42] Paid network exploit mints attacker 60m tokens: Report. https://www.coindesk\n.com/paid-network-exploit-mints-attacker-60m-tokens-report.\n[43] Risk-free rate of return definition. https://www.investopedia.com/terms/r/risk-\nfreerate.asp.\n[44] Robinhood restricts trading in gamestop, other names involved in frenzy. https:\n//www.cnbc.com/2021/01/28/robinhood-interactive-brokers-restrict-trading-\nin-gamestop-s.html.\n[45] Sec market manipulation and case studies. https://www.sec.gov/files/Market%\n20Manipulations%20and%20Case%20Studies.pdf.\n[46] Slowmist: Pancakebunny hack analysis. https://slowmist.medium.com/slowmi\nst-pancakebunny-hack-analysis-4a708e284693.\n[47] Sparkpool. https://www.sparkpool.com.\n[48] Sr 955.0 - federal act of 10 october 1997 on combating money laundering and\nterrorist financing in the financial sector (anti-money laundering act, amla).\nhttps://www.fedlex.admin.ch/eli/cc/1998/892_892_892/en.\n[49] Tornado anonymity mining. https://app.tornado.cash/mining/.\n[50] Tornado.cash. https://tornado.cash/.\n[51] United states government bonds - yields curve. http://www.worldgovernmentb\nonds.com/country/united-states/.\n[52] Uranium finance - rekt. https://www.rekt.news/uranium-rekt/.\n[53] U.s. bank savings account rates | bankrate. https://www.bankrate.com/banking\n/savings/us-bank-savings-rates/.\n[54] Value defi incident: Root cause analysis. https://blog.peckshield.com/2020/11/\n15/valuedefi/.\n[55] What exactly is a virtual asset service provider (vasp)? - ciphertrace. https:\n//ciphertrace.com/what-exactly-is-a-virtual-asset-service-provider-vasp/#:~:\ntext=When%20a%20digital%20asset%20entity,role%20as%20a%20money%20tr\nansmitter.\n[56] What is liquid swap? | binance support. https://www.binance.com/en/support/f\naq/85d614205d334128b76c0275aba61ea6.\n[57] What is the hong kong-us dollar peg and how does it work? - yp | south china\nmorning post. https://www.scmp.com/yp/discover/advice/article/3093224/what-\nhong-kong-us-dollar-peg-and-how-does-it-work.\n13\n[58] What is the risk-free rate of return? https://www.thebalance.com/what-is-risk-\nfree-rate-of-return-5097109.\n[59] Why trump administration threat to hurt hong kong\u2019s dollar peg won\u2019t work.\nhttps://www.cnbc.com/2020/07/13/why-trump-administration-threat-to-\nhurt-hong-kongs-dollar-peg-wont-work.html#:~:text=The%20Hong%20Kong\n%20dollar%20has,selling%20or%20buying%20the%20currency.\n[60] Foreign exchange manipulation: FINMA issues six industry bans, 2019.\n[61] Aave. Aave Protocol. https://github.com/aave/aave-protocol, 2020.\n[62] Hamda Al-Breiki, Muhammad Habib Ur Rehman, Khaled Salah, and Davor\nSvetinovic. Trustworthy blockchain oracles: review, comparison, and open\nresearch challenges. IEEE Access, 8:85675\u201385685, 2020.\n[63] Irene Aldridge. High-frequency trading: a practical guide to algorithmic strategies\nand trading systems, volume 604. John Wiley & Sons, 2013.\n[64] Franklin Allen and Douglas Gale. Stock-price manipulation. The Review of\nFinancial Studies, 5(3):503\u2013529, 1992.\n[65] Sarah Allen, Sr\u0111jan \u010capkun, Ittay Eyal, Giulia Fanti, Bryan A Ford, James\nGrimmelmann, Ari Juels, Kari Kostiainen, Sarah Meiklejohn, Andrew Miller,\net al. Design choices for central bank digital currency: Policy and technical\nconsiderations. Technical report, National Bureau of Economic Research, 2020.\n[66] Arash Aloosh and Jiasun Li. Direct evidence of bitcoin wash trading. Available\nat SSRN 3362153, 2019.\n[67] John P Anderson. Insider trading and cryptoassets: The waters just got muddier.\nIowa L. Rev. Bull., 104:120, 2019.\n[68] Elli Androulaki, Ghassan O Karame, Marc Roeschlin, Tobias Scherer, and Srdjan\nCapkun. Evaluating user privacy in bitcoin. In International Conference on\nFinancial Cryptography and Data Security, pages 34\u201351. Springer, 2013.\n[69] James J Angel and Douglas McCabe. Fairness in financial markets: The case of\nhigh frequency trading. Journal of Business Ethics, 112(4):585\u2013595, 2013.\n[70] Guillermo Angeris and Tarun Chitra. Improved price oracles: Constant function\nmarket makers. arXiv preprint arXiv:2003.10001, 2020.\n[71] Guillermo Angeris, Alex Evans, and Tarun Chitra. A note on privacy in constant\nfunction market makers. arXiv preprint arXiv:2103.01193, 2021.\n[72] Jun Aoyagi. Strategic Speed Choice by High-Frequency Traders under Speed\nBumps. ISER DP, (1050), 2019.\n[73] Maria Apostolaki, Aviv Zohar, and Laurent Vanbever. Hijacking bitcoin: Routing\nattacks on cryptocurrencies. In 2017 IEEE Symposium on Security and Privacy\n(SP), pages 375\u2013392. IEEE, 2017.\n[74] Nicola Atzei, Massimo Bartoletti, and Tiziana Cimoli. A survey of attacks on\nethereum smart contracts (sok). In International conference on principles of\nsecurity and trust, pages 164\u2013186. Springer, 2017.\n[75] European Central Bank. Monetary Policy. https://www.ecb.europa.eu/mopo/h\ntml/index.en.html, 2021.\n[76] Matthew Baron, Jonathan Brogaard, Bj\u00f6rn Hagstr\u00f6mer, and Andrei Kirilenko.\nRisk and return in high-frequency trading. Journal of Financial and Quantitative\nAnalysis, 54(3):993\u20131024, 2019.\n[77] Massimo Bartoletti, Salvatore Carta, Tiziana Cimoli, and Roberto Saia. Dissect-\ning ponzi schemes on ethereum: identification, analysis, and impact. Future\nGeneration Computer Systems, 102:259\u2013277, 2020.\n[78] Massimo Bartoletti, Barbara Pes, and Sergio Serusi. Data mining for detecting\nbitcoin ponzi schemes. In 2018 Crypto Valley Conference on Blockchain Technology\n(CVCBT), pages 75\u201384. IEEE, 2018.\n[79] Abdeljalil Beniiche.\nA study of blockchain oracles.\narXiv preprint\narXiv:2004.07140, 2020.\n[80] Iddo Bentov, Yan Ji, Fan Zhang, Lorenz Breidenbach, Philip Daian, and Ari Juels.\nTesseract: Real-time cryptocurrency exchange using trusted hardware. In Pro-\nceedings of the 2019 ACM SIGSAC Conference on Computer and Communications\nSecurity, pages 1521\u20131538, 2019.\n[81] Iddo Bentov, Yan Ji, Fan Zhang, Yunqi Li, Xueyuan Zhao, Lorenz Breidenbach,\nPhilip Daian, and Ari Juels. Tesseract: Real-Time Cryptocurrency Exchange\nusing Trusted Hardware. Conference on Computer and Communications Security,\n2019.\n[82] Daniele Bianchi and Alexander Dickerson. Trading volume in cryptocurrency\nmarkets. Available at SSRN 3239670, 2019.\n[83] Lorenz Breidenbach, Christian Cachin, Benedict Chan, Alex Coventry, Steve\nEllis, Ari Juels, Farinaz Koushanfar, Andrew Miller, Brendan Magauran, Daniel\nMoroz, et al. Chainlink 2.0: Next steps in the evolution of decentralized oracle\nnetworks. 2021.\n[84] Jonathan Brogaard et al. High frequency trading and its impact on market\nquality. Northwestern University Kellogg School of Management Working Paper,\n66, 2010.\n[85] Eric Budish, Peter Cramton, and John Shim. The high-frequency trading arms\nrace: Frequent batch auctions as a market design response. The Quarterly Journal\nof Economics, 130(4):1547\u20131621, 2015.\n[86] Tong Cao. Paradox of Inflation: The Study on Correlation between Money\nSupply and Inflation in New Era. https://core.ac.uk/download/pdf/79576314.pdf,\n2015.\n[87] Miles Carlsten, Harry Kalodner, S Matthew Weinberg, and Arvind Narayanan.\nOn the instability of bitcoin without the block reward. In Proceedings of the\n2016 ACM SIGSAC Conference on Computer and Communications Security, pages\n154\u2013167, 2016.\n[88] Chainanalysis. Decoding increasingly sophisticated hacks, darknet markets,\nand scams. Technical report, 2019.\n[89] Weili Chen, Zibin Zheng, Jiahui Cui, Edith Ngai, Peilin Zheng, and Yuren Zhou.\nDetecting ponzi schemes on ethereum: Towards healthier blockchain technology.\nIn Proceedings of the 2018 World Wide Web Conference, pages 1409\u20131418, 2018.\n[90] Weili Chen, Zibin Zheng, Edith C-H Ngai, Peilin Zheng, and Yuren Zhou. Ex-\nploiting blockchain data to detect smart ponzi schemes on ethereum. IEEE\nAccess, 7:37575\u201337586, 2019.\n[91] Raymond Cheng, Fan Zhang, Jernej Kos, Warren He, Nicholas Hynes, Noah\nJohnson, Ari Juels, Andrew Miller, and Dawn Song. Ekiden: A platform for\nconfidentiality-preserving, trustworthy, and performant smart contracts. In 2019\nIEEE European Symposium on Security and Privacy (EuroS&P), pages 185\u2013200.\nIEEE, 2019.\n[92] Michael Chlistalla, Bernhard Speyer, Sabine Kaiser, and Thomas Mayer. High-\nfrequency trading. Deutsche Bank Research, 7:3\u20134, 2011.\n[93] Arka Rai Choudhuri, Matthew Green, Abhishek Jain, Gabriel Kaptchuk, and Ian\nMiers. Fairness in an unfair world: Fair multiparty computation from public\nbulletin boards. In Proceedings of the 2017 ACM SIGSAC Conference on Computer\nand Communications Security, pages 719\u2013728, 2017.\n[94] CNBC, Bloom Michael, Cox Jeff, and Franck Thomas. \u2018Circuit breaker\u2019 triggered\nagain to keep stocks from falling through floor. https://www.cnbc.com/2020/\n03/12/stock-futures-hit-a-limit-down-trading-halt-for-a-second-time-this-\nweek-heres-what-that-means.html, 2020.\n[95] Lin William Cong, Xi Li, Ke Tang, and Yang Yang. Crypto wash trading. Available\nat SSRN 3530220, 2020.\n[96] Philip Daian, Steven Goldfeder, Tyler Kell, Yunqi Li, Xueyuan Zhao, Iddo Bentov,\nLorenz Breidenbach, and Ari Juels. Flash Boys 2.0: Frontrunning, Transaction Re-\nordering, and Consensus Instability in Decentralized Exchanges. arXiv preprint\narXiv:1904.05234, 2019.\n[97] Barry J Eichengreen, Barry Eichengreen, and Marc Flandreau. The gold standard\nin theory and history. Psychology press, 1997.\n[98] Parinya Ekparinya, Vincent Gramoli, and Guillaume Jourjon. Impact of man-\nin-the-middle attacks on ethereum. In 2018 IEEE 37th Symposium on Reliable\nDistributed Systems (SRDS), pages 11\u201320. IEEE, 2018.\n[99] Ittay Eyal and Emin G\u00fcn Sirer. Majority is not enough: Bitcoin mining is vul-\nnerable. In Financial Cryptography and Data Security, pages 436\u2013454. Springer,\n2014.\n[100] Frank J Fabozzi and Pamela Peterson Drake. What is finance. FRANK J. FABOZZI\nPAMELA PETERSON DRAKE, 3, 2009.\n[101] St Louis Fed. M1 Money Stock. https://fred.stlouisfed.org/series/M1, 2021.\n[102] Compound Finance. Compound finance. https://compound.finance/, 2019.\n[103] The Maker Foundation. Makerdao. https://makerdao.com/en/, 2019.\n[104] Arthur Gervais, Srdjan Capkun, Ghassan O Karame, and Damian Gruber. On the\nprivacy provisions of bloom filters in lightweight bitcoin clients. In Computer\nSecurity Applications Conference, pages 326\u2013335, 2014.\n[105] Arthur Gervais, Ghassan O Karame, Karl W\u00fcst, Vasileios Glykantzis, Hubert\nRitzdorf, and Srdjan Capkun. On the security and performance of proof of work\nblockchains. In Proceedings of the 2016 ACM SIGSAC Conference on Computer\nand Communications Security, pages 3\u201316. ACM, 2016.\n[106] Arthur Gervais, Hubert Ritzdorf, Ghassan O Karame, and Srdjan Capkun. Tam-\npering with the delivery of blocks and transactions in bitcoin. In Conference on\nComputer and Communications Security, pages 692\u2013705. ACM, 2015.\n[107] Globalcustodian.com. Global Custodians. https://www.globalcustodian.com/di\nrectory-type/global-custodians/, 2021.\n[108] Johannes G\u00f6bel, Holger Paul Keeler, Anthony E Krzesinski, and Peter G Taylor.\nBitcoin blockchain dynamics: The selfish-mine strategy in the presence of\npropagation delay. Performance Evaluation, 104:23\u201341, 2016.\n[109] John M Griffin and Amin Shams. Is bitcoin really untethered? The Journal of\nFinance, 75(4):1913\u20131964, 2020.\n[110] JT Hamrick, Farhang Rouhi, Arghya Mukherjee, Amir Feder, Neil Gandal, Tyler\nMoore, and Marie Vasek. The economics of cryptocurrency pump and dump\nschemes. 2018.\n[111] Mark Handley. Delay is not an option: Low latency routing in space. In\nProceedings of the 17th ACM Workshop on Hot Topics in Networks, pages 85\u201391,\n2018.\n[112] Jon D Hanson and Douglas A Kysar. Taking behavioralism seriously: Some\nevidence of market manipulation. Harvard law review, pages 1420\u20131572, 1999.\n[113] Jon D Hanson and Douglas A Kysar. Taking behavioralism seriously: The\nproblem of market manipulation. NYUL Rev., 74:630, 1999.\n[114] Martin Harrigan and Christoph Fretter. The unreasonable effectiveness of\naddress clustering. In 2016 Intl IEEE Conferences on Ubiquitous Intelligence &\nComputing, Advanced and Trusted Computing, Scalable Computing and Commu-\nnications, Cloud and Big Data Computing, Internet of People, and Smart World\nCongress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld), pages 368\u2013373. IEEE,\n14\n2016.\n[115] Martin Harrigan, Lei Shi, and Jacob Illum. Airdrops and privacy: a case study in\ncross-blockchain analysis. In 2018 IEEE International Conference on Data Mining\nWorkshops (ICDMW), pages 63\u201370. IEEE, 2018.\n[116] Larry Harris. What to do about high-frequency trading, 2013.\n[117] Eyal Hertzog, Guy Benartzi, and Galia Benartzi. Bancor protocol. 2017.\n[118] Abraham Hinteregger and Bernhard Haslhofer. An Empirical Analysis of Mon-\nero Cross-Chain Traceability. CoRR, abs/1812.02808, 2018.\n[119] Investopedia. Basket of Goods. https://www.investopedia.com/terms/b/baske\nt_of_goods.asp, 2021.\n[120] Investopedia. Inflation. https://www.investopedia.com/terms/i/inflation.asp,\n2021.\n[121] Robert A Jarrow. Market manipulation, bubbles, corners, and short squeezes.\nJournal of financial and Quantitative Analysis, 27(3):311\u2013336, 1992.\n[122] Ari Juels, Ittay Eyal, and Mahimna Kelkar. Op-ed: Miners, front-running-as-a-\nservice is theft. https://mev.monster.\n[123] Josh Kamps and Bennett Kleinberg. To the moon: defining and detecting cryp-\ntocurrency pump-and-dumps. Crime Science, 7(1):1\u201318, 2018.\n[124] Ghassan O Karame, Elli Androulaki, and Srdjan Capkun. Double-spending fast\npayments in bitcoin. In Proceedings of the 2012 ACM conference on Computer\nand communications security, pages 906\u2013917. ACM, 2012.\n[125] Ghassan O Karame, Elli Androulaki, Marc Roeschlin, Arthur Gervais, and Srdjan\n\u010capkun. Misbehavior in bitcoin: A study of double-spending and accountability.\nACM Transactions on Information and System Security (TISSEC), 18(1):2, 2015.\n[126] Aggelos Kiayias, Hong-Sheng Zhou, and Vassilis Zikas. Fair and robust multi-\nparty computation using a global transaction ledger. In Annual International\nConference on the Theory and Applications of Cryptographic Techniques, pages\n705\u2013734. Springer, 2016.\n[127] Ahmed Kosba, Andrew Miller, Elaine Shi, Zikai Wen, and Charalampos Papa-\nmanthou. Hawk: The blockchain model of cryptography and privacy-preserving\nsmart contracts. In 2016 IEEE symposium on security and privacy (SP), pages\n839\u2013858. IEEE, 2016.\n[128] Peter Koudijs and Hans-Joachim Voth. Leverage and beliefs: personal experience\nand risk-taking in margin lending. American Economic Review, 106(11):3367\u2013\n3400, 2016.\n[129] Aurora Labs. Idex: A real-time and high-throughput ethereum smart contract\nexchange. Technical report, January 2019.\n[130] Fabian Lanze, Andriy Panchenko, Ignacio Ponce-Alcaide, and Thomas Engel.\nUndesired relatives: protection mechanisms against the evil twin attack in ieee\n802.11. In Proceedings of the 10th ACM symposium on QoS and security for wireless\nand mobile networks, pages 87\u201394, 2014.\n[131] CFA Larry Harris, PhD. STRUCTURE OF THE INVESTMENT INDUSTRY.\nhttps://www.cfainstitute.org/-/media/documents/support/programs/investme\nnt-foundations/13-structure-of-the-investment-industry.ashx, 2021.\n[132] Duc V Le and Arthur Gervais. Amr: Autonomous coin mixer with privacy\npreserving reward distribution. arXiv preprint arXiv:2010.01056, 2020.\n[133] Tao Li, Donghwa Shin, and Baolian Wang. Cryptocurrency pump-and-dump\nschemes. Available at SSRN 3267041, 2020.\n[134] Xiaoqi Li, Peng Jiang, Ting Chen, Xiapu Luo, and Qiaoyan Wen. A survey\non the security of blockchain systems. Future Generation Computer Systems,\n107:841\u2013853, 2020.\n[135] Iuon-Chang Lin and Tzu-Chun Liao. A survey of blockchain security issues and\nchallenges. IJ Network Security, 19(5):653\u2013659, 2017.\n[136] Tom CW Lin. The new market manipulation. Emory LJ, 66:1253, 2016.\n[137] Joshua Lind, Ittay Eyal, Peter Pietzuch, and Emin G\u00fcn Sirer. Teechan: Payment\nchannels using trusted execution environments. arXiv preprint arXiv:1612.07766,\n2016.\n[138] Joshua Lind, Oded Naor, Ittay Eyal, Florian Kelbert, Peter R Pietzuch, and\nEmin G\u00fcn Sirer. Teechain: Reducing Storage Costs on the Blockchain With\nOffline Payment Channels. In Proceedings of the 11th {ACM} International Systems\nand Storage Conference, {SYSTOR} 2018, HAIFA, Israel, June 04-07, 2018, 2018.\n[139] Bowen Liu, Pawel Szalachowski, and Jianying Zhou. A first look into defi oracles.\narXiv preprint arXiv:2005.04377, 2020.\n[140] Sarah Meiklejohn, Marjori Pomarole, Grant Jordan, Kirill Levchenko, Damon\nMcCoy, Geoffrey M Voelker, and Stefan Savage. A fistful of bitcoins: characteriz-\ning payments among men with no names. In Proceedings of the 2013 conference\non Internet measurement conference, pages 127\u2013140. ACM, 2013.\n[141] Albert J Menkveld. The economics of high-frequency trading: Taking stock.\nAnnual Review of Financial Economics, 8:1\u201324, 2016.\n[142] Ian Miers, Christina Garman, Matthew Green, and Aviel D Rubin. Zerocoin:\nAnonymous distributed e-cash from bitcoin. In Symposium on Security and\nPrivacy, pages 397\u2013411, 2013.\n[143] Tian Min, Hanyi Wang, Yaoze Guo, and Wei Cai. Blockchain games: A survey.\nIn 2019 IEEE Conference on Games (CoG), pages 1\u20138. IEEE, 2019.\n[144] Amani Moin, Kevin Sekniqi, and Emin Gun Sirer. Sok: A classification framework\nfor stablecoin designs. In International Conference on Financial Cryptography\nand Data Security, pages 174\u2013197. Springer, 2020.\n[145] John V Monaco. Identifying bitcoin users by transaction behavior. In Biometric\nand Surveillance Technology for Human and Activity Identification XII, volume\n9457, page 945704. International Society for Optics and Photonics, 2015.\n[146] Wouter H Muller, Christian H Kalin, and John G Goldsworth. Anti-Money\nLaundering: international law and practice. John Wiley & Sons, 2007.\n[147] Nexus Mutual. Nexus Mutual. https://nexusmutual.io/, 2020.\n[148] Satoshi Nakamoto and A Bitcoin. A peer-to-peer electronic cash system. Bitcoin.\u2013\nURL: https://bitcoin. org/bitcoin. pdf, 4, 2008.\n[149] Nasdaq. Initial Listing Guide. https://listingcenter.nasdaq.com/assets/initialgui\nde.pdf, 2021.\n[150] Till Neudecker and Hannes Hartenstein. Could network information facilitate\naddress clustering in bitcoin? In International conference on financial cryptogra-\nphy and data security, pages 155\u2013169. Springer, 2017.\n[151] Mardiana Mohamad Noor and Wan Haslina Hassan. Wireless networks: develop-\nments, threats and countermeasures. International Journal of Digital Information\nand Wireless Communications (IJDIWC), 3(1):125\u2013140, 2013.\n[152] Bank of England. Inflation and the 2 percent target. https://www.bankofenglan\nd.co.uk/monetary-policy/inflation, 2021.\n[153] Bank of International Settlements. FX execution algorithms and market func-\ntioning. https://www.bis.org/publ/mktc13.pdf, 2020.\n[154] US Bureau of Labor Statistics. Consumer prices increase 2.6 percent for the 12\nmonths ending March 2021. https://www.bls.gov/opub/ted/2021/consumer-\nprices-increase-2-6-percent-for-the-12-months-ending-march-2021.htm,\n2021.\n[155] Financial Conduct Authority of the UK. Primary Markets. https://www.fca.org.\nuk/markets/primary-markets, 2021.\n[156] Joseph Poon and Thaddeus Dryja. The bitcoin lightning network: scalable\noff-chain instant payments, 2016.\n[157] Kaihua Qin, Liyi Zhou, and Arthur Gervais. Quantifying blockchain extractable\nvalue: How dark is the forest? arXiv preprint arXiv:2101.05511, 2021.\n[158] Kaihua Qin, Liyi Zhou, Benjamin Livshits, and Arthur Gervais. Attacking the\ndefi ecosystem with flash loans for fun and profit. Financial Cryptography and\nData Security: 25th International Conference (FC 2021), 2021.\n[159] Venkatesh U Rajput. Research on know your customer (kyc). International\nJournal of Scientific and Research Publications, 3(7):541\u2013546, 2013.\n[160] Fergal Reid and Martin Harrigan. An analysis of anonymity in the bitcoin\nsystem. In Security and privacy in social networks, pages 197\u2013223. Springer, 2013.\n[161] Hubert Ritzdorf, Karl W\u00fcst, Arthur Gervais, Guillaume Felley, and Srdjan Cap-\nkun. TLS-N: Non-repudiation over TLS Enabling Ubiquitous Content Signing.\nIn NDSS, 2018.\n[162] Muhammad Saad, Jeffrey Spaulding, Laurent Njilla, Charles Kamhoua, Sachin\nShetty, DaeHun Nyang, and Aziz Mohaisen. Exploring the attack surface of\nblockchain: A systematic overview. arXiv preprint arXiv:1904.03487, 2019.\n[163] Muhammad Saad, My T Thai, and Aziz Mohaisen. Poster: deterring ddos\nattacks on blockchain-based cryptocurrencies through mempool optimization.\nIn Proceedings of the 2018 on Asia Conference on Computer and Communications\nSecurity, pages 809\u2013811, 2018.\n[164] Ayelet Sapirshtein, Yonatan Sompolinsky, and Aviv Zohar. Optimal selfish min-\ning strategies in bitcoin. In International Conference on Financial Cryptography\nand Data Security, pages 515\u2013532. Springer, 2016.\n[165] Corina Sas and Irni Eliana Khairuddin. Design for trust: An exploration of the\nchallenges and opportunities of bitcoin users. In Proceedings of the 2017 CHI\nConference on Human Factors in Computing Systems, pages 6499\u20136510, 2017.\n[166] Eli Ben Sasson, Alessandro Chiesa, Christina Garman, Matthew Green, Ian\nMiers, Eran Tromer, and Madars Virza. Zerocash: Decentralized anonymous\npayments from bitcoin. In Security and Privacy (SP), 2014 IEEE Symposium on,\npages 459\u2013474. IEEE, 2014.\n[167] Sarwar Sayeed and Hector Marco-Gisbert. Assessing blockchain consensus and\nsecurity mechanisms against the 51% attack. Applied Sciences, 9(9):1788, 2019.\n[168] Fabian Sch\u00e4r. Decentralized finance: On blockchain-and smart contract-based\nfinancial markets. Available at SSRN 3571335, 2020.\n[169] Linda Schilling and Harald Uhlig. Some simple bitcoin economics. Journal of\nMonetary Economics, 106:16\u201326, 2019.\n[170] Paul Allan Schott. Reference guide to anti-money laundering and combating the\nfinancing of terrorism. World Bank Publications, 2006.\n[171] Michael Siering, Benjamin Clapham, Oliver Engel, and Peter Gomber. A taxon-\nomy of financial market manipulations: establishing trust and market integrity\nin the financialized economy through automated fraud detection. Journal of\nInformation Technology, 32(3):251\u2013269, 2017.\n[172] Antoon Spithoven. Theory and reality of cryptocurrency governance. Journal\nof Economic Issues, 53(2):385\u2013393, 2019.\n[173] Sergey Nazarov Steve Ellis, Ari Juels. Chainlink: A decentralized oracle network,\n2017.\n[174] Synthetix. Synthetix: Decentralized synthetic assets. https://www.synthetix.io/,\n2020.\n[175] Christof Ferreira Torres, Mathis Steichen, et al. The art of the scam: Demystifying\nhoneypots in ethereum smart contracts. In 28th {USENIX} Security Symposium\n({USENIX} Security 19), pages 1591\u20131607, 2019.\n15\n[176] Tradingview. Random length lumber futures. https://www.tradingview.com/ch\nart/?symbol=CME%3ALBS1!, 2021.\n[177] European Union. Payments, Transfers, and Cheques. https://europa.eu/yo\nureurope/citizens/consumers/financial-products-and-services/payments-\ntransfers-cheques/index_en.htm, 2021.\n[178] Uniswap.io, 2018. https://docs.uniswap.io/.\n[179] Andrew Verstein. Crypto assets and insider trading law\u2019s domain. Iowa L. Rev.,\n105:1, 2019.\n[180] Friedhelm Victor. Address clustering heuristics for ethereum. In International\nConference on Financial Cryptography and Data Security, pages 617\u2013633. Springer,\n2020.\n[181] Friedhelm Victor and Andrea Marie Weintraud. Detecting and quantifying\nwash trading on decentralized cryptocurrency exchanges.\narXiv preprint\narXiv:2102.07001, 2021.\n[182] Christopher Viney and Peter Phillips. Financial institutions, instruments &\nmarkets. McGraw-Hill Australia, 2012.\n[183] Dabao Wang, Siwei Wu, Ziling Lin, Lei Wu, Xingliang Yuan, Yajin Zhou, Haoyu\nWang, and Kui Ren. Towards understanding flash loan and its applications in\ndefi ecosystem. arXiv preprint arXiv:2010.12252, 2020.\n[184] Will Warren and Amir Bandeali.\n0x: An open protocol for decen-\ntralized exchange on the ethereum blockchain.\nURl: https://github.\ncom/0xProject/whitepaper, pages 04\u201318, 2017.\n[185] Karl W\u00fcst and Arthur Gervais. Do you need a blockchain? In 2018 Crypto Valley\nConference on Blockchain Technology (CVCBT), pages 45\u201354. IEEE, 2018.\n[186] Jiahua Xu and Benjamin Livshits. The anatomy of a cryptocurrency pump-and-\ndump scheme. In 28th USENIX Security Symposium (USENIX Security 19), pages\n1609\u20131625, 2019.\n[187] Fan Zhang, Ethan Cecchetti, Kyle Croman, Ari Juels, and Elaine Shi. Town crier:\nAn authenticated data feed for smart contracts. In Proceedings of the 2016 aCM\nsIGSAC conference on computer and communications security, pages 270\u2013282.\nACM, 2016.\n[188] Fan Zhang, Deepak Maram, Harjasleen Malvai, Steven Goldfeder, and Ari Juels.\nDeco: Liberating web data using decentralized oracles for tls. In Proceedings of\nthe 2020 ACM SIGSAC Conference on Computer and Communications Security,\npages 1919\u20131938, 2020.\n[189] Liyi Zhou, Kaihua Qin, Antoine Cully, Benjamin Livshits, and Arthur Gervais.\nOn the just-in-time discovery of profit-generating transactions in defi protocols.\n2021 IEEE Symposium on Security and Privacy (SP), 2021.\n[190] Liyi Zhou, Kaihua Qin, and Arthur Gervais. A2mm: Mitigating frontrunning,\ntransaction reordering and consnsus instability in decentralized exchanges.\n2021.\n[191] Liyi Zhou, Kaihua Qin, Christof Ferreira Torres, Duc V Le, and Arthur Ger-\nvais. High-frequency trading on decentralized on-chain exchanges. 2021 IEEE\nSymposium on Security and Privacy (SP), 2020.\n16\nTable 3: Smart contract code and DeFi protocol/composability attacks on Ethereum as well as the Binance Smart Chain.\nVictim\nAmount (USD)\nPlatform\nSource\nThe DAO\n60,000,000\nETH\nhttps://hackingdistributed.com/2016/06/18/analysis-of-the-dao-exploit/\nParity\n30,000,000\nETH\nhttps://medium.com/solidified/parity-hack-how-it-happened-and-its-aftermath-9bffb2105c0\nBancor\n23,500,000\nETH\nhttps://medium.com/@theoceantrade/hack-attack-volume-3-bancor-55abfa9aefe2\nSpankchain\n38,000\nETH\nhttps://medium.com/swlh/how-spankchain-got-hacked-af65b933393c\nbZx\n355,880\nETH\nhttps://blog.peckshield.com/2020/02/17/bZx/\nbZx\n665,840\nETH\nhttps://blog.peckshield.com/2020/02/18/bZx/\nLendf.Me\n25,236,849\nETH\nhttps://blog.peckshield.com/2020/04/19/erc777/\nBancor\n135,229\nETH\nhttps://blog.bancor.network/bancors-response-to-today-s-smart-contract-vulnerability-dc888c589fe4\nBalancer\n523,617\nETH\nhttps://blog.peckshield.com/2020/06/28/balancer/\nBalancer\n2,408\nETH\nhttps://cointelegraph.com/news/hacker-steals-balancers-comp-allowance-in-second-attack-within-24-hours\nVETH\n900,000\nETH\nhttps://hacked.slowmist.io/en/?c=ETH%20DApp\nOpyn\n371,000\nETH\nhttps://blog.peckshield.com/2020/08/05/opyn/\nYFValue\n170,000,000\nETH\nhttps://valuedefi.medium.com/yfv-update-staking-pool-exploit-713cb353ff7d\nSoftFinance\n250,000\nETH\nhttps://cointelegraph.com/news/jackpot-user-turns-200-into-250k-thanks-to-a-buggy-defi-protocol\nUniswap\n220,000\nETH\nhttps://medium.com/consensys-diligence/uniswap-audit-b90335ac007\nSoda.Finance\n160,000\nETH\nhttps://anchainai.medium.com/soda-finance-hack-could-formal-verification-have-prevented-it-code-included-\n71b6e9f94ea5\nEminence\n15,000,000\nETH\nhttps://www.rekt.news/eminence-rekt-in-prod/\nDeFi Saver\n30,000\nETH\nhttps://slowmist.medium.com/slowmist-how-was-the-310-000-dai-of-defi-saver-users-stolen-91de37a4ade2\nHarvest Finance\n33,800,000\nETH\nhttps://www.rekt.news/harvest-finance-rekt/\nAxion Network\n500,000\nETH\nhttps://cointelegraph.com/news/certik-dissects-the-axion-network-incident-and-subsequent-price-crash\nCheese Bank\n3,300,000\nETH\nhttps://blog.peckshield.com/2020/11/16/cheesebank/\nAkropolis\n2,030,000\nETH\nhttps://blog.peckshield.com/2020/11/13/akropolis/\nValueDeFi\n740,000,000\nETH\nhttps://blog.peckshield.com/2020/11/15/valuedefi/\nOUSD\n7,700,000\nETH\nhttps://blog.peckshield.com/2020/11/17/ousd/\n88mph\n100,000\nETH\nhttps://peckshield.medium.com/88mph-incident-root-cause-analysis-ce477e00a74d\nPickle.Finance\n20,000,000\nETH\nhttps://www.rekt.news/pickle-finance-rekt/\nSushiSwap\n15,000\nETH\nhttps://slowmist.medium.com/slowmist-a-brief-analysis-of-the-story-of-the-sushi-swap-attack-c7bc6709adea\nWarp.Finance\n7,800,000\nETH\nhttps://blog.peckshield.com/2020/12/18/warpfinance/\nNexus Mutual\n8,000,000\nETH\nhttps://www.certik.io/blog/technology/nexus-mutual-attack-8-million-lost\nCover Protocol\n3,000,000\nETH\nhttps://blog.peckshield.com/2020/12/28/cover/\nSushiSwap\n103,842\nETH\nhttps://www.rekt.news/badgers-digg-sushi/\nBT.Finance\n1,500,000\nETH\nhttps://www.rekt.news/the-big-combo/\nYearn.Finance\n11,000,000\nETH\nhttps://www.rekt.news/yearn-rekt/\nCream.Finance\n37,500,000\nETH\nhttps://www.rekt.news/alpha-finance-rekt/\nMeerkat Finance\n31,000,000\nBSC\nhttps://www.rekt.news/meerkat-finance-bsc-rekt/\nPaid Network\n27,418,034\nETH\nhttps://www.rekt.news/paid-rekt/\nFurucombo\n15,000,000\nETH\nhttps://www.rekt.news/furucombo-rekt/\nIron.Finance\n170,000\nBSC\nhttps://ironfinance.medium.com/iron-finance-vfarms-incident-post-mortem-16-march-2021-114e58d1eaac\nUranium.Finance\n13,000,000\nBSC,ETH\nhttps://www.certik.org/blog/uranium-finance-exploit-technical-analysis\nPancakeSwap\n1,800,000\nBSC\nhttps://cryptopwnage.medium.com/1-800-000-was-stolen-from-binance-smart-chain-pancakeswap-lottery-pool-\nca2afb415f9\nUranium.Finance\n57,200,000\nBSC,ETH\nhttps://www.rekt.news/uranium-rekt/\nSpartan\n30,500,000\nBSC\nhttps://blog.peckshield.com/2021/05/02/Spartan/\nValueDeFi\n10,000,000\nBSC\nhttps://www.rekt.news/value-rekt2/\nEasyFi\n59,000,000\nLayer 2\nhttps://www.rekt.news/easyfi-rekt/\nValueDeFi\n11,000,000\nBSC\nhttps://blog.peckshield.com/2021/05/08/ValueDeFi/\nRari Capital\n14,000,000\nETH\nhttps://nipunp.medium.com/5-8-21-rari-capital-exploit-timeline-analysis-8beda31cbc1a\nxToken\n24,000,000\nETH\nhttps://medium.com/xtoken/initial-report-on-xbnta-xsnxa-exploit-d6e784387f8e\nFinNexus\n7,000,000\nETH,BSC\nhttps://news.yahoo.com/latest-defi-hack-drains-7-050841516.html\nPancakeBunny\n45,000,000\nBSC,ETH\nhttps://slowmist.medium.com/slowmist-pancakebunny-hack-analysis-4a708e284693\nBogged Finance\n3,600,000\nBSC\nhttps://blog.peckshield.com/2021/05/22/boggedfinance/\nAutoShark Finance\n822,800\nBSC\nhttps://authorshark.medium.com/\nDeFi100\n32,000,000\nETH\nhttps://www.coindesk.com/people-behind-crypto-protocol-defi100-may-have-absconded-with-32m-in-investor-funds\nWLEO\n42,000\nETH\nhttps://leofinance.io/@leofinance/wrapped-leo-white-paper-investigative-report-lp-refunds-and-wleo-relaunch\nUniCats\n200,000\nETH\nhttps://hacked.slowmist.io/en/?c=ETH%20DApp\nWeb3 DeFi\n100,000\nETH\nhttps://medium.com/mycrypto/phishing-campaigns-take-aim-at-web3-defi-applications-19e224d9f207\nbZx\n8,000,000\nETH\nhttps://bzx.network/blog/incident\nMakerDAO\n8,320,000\nETH\nhttps://www.coindesk.com/mempool-manipulation-enabled-theft-of-8m-in-makerdao-collateral-on-black-thursday-\nreport\nFomo 3D\n18,000,000\nETH\nhttps://blog.peckshield.com/2018/07/24/fomo3d/\n17\nTable 4: Definitions of DeFi market manipulation techniques.\nCategory\nTechnique\nDefinition\nAction-\nPonzi scheme\nAn adversary raises funds from investors while paying to previous investors, creating the illusion of high returns.\nHoney pot\nAn adversary feigns a financial instrument, luring market participants into making erroneous trades.\nInfo-\nFraudulent financial statements\nIntentional misrepresentation of a company\u2019s financial health via disclosure violations and improper accounting.\nPump and dump/Short and distort\nAdversary buying positions to increase the price, disseminating positive information, and then selling.\nTrade-\nWash trade/Matched orders/Painting the tape\nCreating fictitious transactions to imply market activity.\nInsider trading\nTrading based on non-public information.\nCornering\nObtaining a large quantity of a specific financial instrument to manipulate the market price.\nCapping\nPreventing the rise/decrease in the financial instrument\u2019s price.\nMarking the close\nPumps or dumps the opening or closing price of an instrument.\nFront-/back-running, sandwich\nUsing pending information about incoming transaction to perform a financial action.\nClogging/Jamming\nClogging the network to prevent other market participants from issuing transactions.\nChurning\nPurchasing and selling of financial instruments on behalf of a client for profit.\nOrder-\nRamping/Advancing the bid/ Reducing the ask\nIn/decreasing the bid for an asset to artificially in/decrease its price, or to simulate an active asset interest.\nSpoofing/Pinging\nPlaces trading orders that are not intended to be executed, to observe or mislead other participants\u2019.\nQuote stuffing\nPlacing and canceling a many orders to overload a financial system, similar to a DoS attack.\n18\n",
    "2311.01433": "A Comprehensive Study of Governance Issues in\nDecentralized Finance Applications\nWEI MA, Nanyang Technology University, Singapore\nCHENGUANG ZHU, The University of Texas at Austin, USA\nYE LIU, Nanyang Technology University, Singapore\nXIAOFEI XIE, Singapore Management University, Singapore\nYI LI, Nanyang Technology University, Singapore\nDecentralized Finance (DeFi) is a prominent application of smart contracts, representing a novel financial\nparadigm in contrast to centralized finance. While DeFi applications are rapidly emerging on mainstream\nblockchain platforms, their quality varies greatly, presenting numerous challenges, particularly in terms of\ntheir governance mechanisms. In this paper, we present a comprehensive study of governance issues in DeFi\napplications. Drawing upon insights from industry reports and academic research articles, we develop a\ntaxonomy to categorize these governance issues. We collect and build a dataset of 4,446 audit reports from\n17 Web3 security companies, categorizing their governance issues according to our constructed taxonomy.\nWe conducted a thorough analysis of governance issues and identified vulnerabilities in governance design\nand implementation, e.g., voting sybil attack and proposal front-running. Our findings highlight a significant\nobservation: the disparity between smart contract code and DeFi whitepapers plays a central role in these\ngovernance issues. As an initial step to address the challenges of code-whitepaper consistency checks for DeFi\napplications, we built a machine-learning-based prototype, and validated its performance on eight widely\nused DeFi projects, achieving a 56.14% F1 score and a 80% recall. The process of developing and evolving DeFi\napplications presents distinct traits that set it apart from conventional software systems. These include aspects\nlike decentralization, transparency, and modification through governance mechanisms. Therefore, it\u2019s essential\nto explore whether adapting existing software development paradigms or creating a new methodology is\nmore effective in constructing trustworthy DeFi applications. Our study culminates in providing several key\npractical implications for various DeFi stakeholders, including developers, users, researchers, and regulators,\naiming to deepen the understanding of DeFi governance issues and contribute to the robust growth of DeFi\nsystems.\n1\nINTRODUCTION\nDecentralized Finance (DeFi) [117] has rapidly emerged as a transformative force in the financial\nworld, challenging traditional parad-igms with its blockchain-based, intermediary-free model. The\nappeal of DeFi lies in its foundational principles: transparency, immutability, and openness, coupled\nwith the anonymity it offers to users. At its core, DeFi contrasts starkly with centralized finance\nby empowering users with direct control over their transactions. This autonomy, facilitated by\nblockchain technology and smart contracts, marks a significant shift towards a more accessible\nand inclusive financial ecosystem. DeFi has also fueled a surge in innovation. This innovation is\nevident in the rapidly expanding DeFi landscape, encompassing varied financial services such as\nlending, trading, and asset management. A testament to its growing influence is the substantial\ncapital influx, with billions of dollars currently locked in various DeFi protocols. A notable example\nis Uniswap, a decentralized cryptocurrency exchange boasting over 30 million active users and a\ntotal value locked (TVL) of approximately $48.65 billion [103].\nHowever, in addition to its immense opportunities, DeFi also faces a myriad of challenges [68, 75,\n113]. One of the crucial aspects that require attention is governance [18, 25, 29, 47, 66]. Governance\nplays a central role in DeFi applications and serves as the foundation of the DeFi ecosystem. Effective\nAuthors\u2019 addresses: Wei Ma, Nanyang Technology University, Singapore; Chenguang Zhu, The University of Texas at\nAustin, USA; Ye Liu, Nanyang Technology University, Singapore; Xiaofei Xie, Singapore Management University, Singapore;\nYi Li, Nanyang Technology University, Singapore.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\narXiv:2311.01433v3  [cs.SE]  11 Jan 2024\n2\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\ngovernance in DeFi is vital for collective decision making, management of business models, and\nthe distribution of rewards within the ecosystem. On the other hand, bad governance mechanisms\nmay leave opportunities for unauthorized manipulation of the DeFi protocol configurations and\nimplementations, which may affect a large number of DeFi users.\nIn practice, DeFi governance faces many challenges. First, some DeFi applications, such as\nUniswap V1 [109], operate without specific governance mechanisms, resulting in difficulties in\nmaintaining and updating these applications. This issue was rectified in its later versions, namely\nV2 and V3 [110]. Second, vulnerable governance mechanisms expose an entire DeFi system to\nmalicious attacks which could result in massive financial losses. Examples include the Beanstalk\ngovernance attack [94] and the Build Finance DAO incident [45], which demonstrate vulnerabilities\nnot just in code, but also in governance designs. Third, another serious issue that may harm DeFi\nusers and investors is opaque or fraudulent governance strategies. It is a common practice for DeFi\ndevelopment teams to publish whitepapers about their projects in advance, which documents the\nparticular governance mechanisms to be adopted. However, there are instances where the actual\nimplementations deviate from these plans, sometimes for the developers\u2019 own personal gains. For\nexample, CodeInc developers can issue tokens in excess of their declared amount and also have\nthe ability to destroy them to gain additional benefits, all without making any payment [102].\nThese discrepancies, while often subtle, can have a profound impact on the healthy growth of DeFi\nsystems. They raise questions regarding transparency and ethical practices in DeFi governance,\npotentially resulting in diminished public trust. A notable instance of such is the phenomenon of\n\u201crug pulls\u201d [100], where certain DeFi teams (e.g., ARBIX FINANCE [92]) exploit hidden governance\nloopholes to rapidly deplete funds from the pool.\nRobust and transparent governance mechanisms are crucial in the DeFi landscape. They play\na vital role in establishing trust among users and investors, which is key to encouraging long-\nterm investment and ensuring the sustainable development of the ecosystem. However, there is\na noticeable research gap in this area, particularly regarding the standardization of governance\npractices. To address this, our paper embarks on a thorough examination of governance issues in\nDeFi applications, mainly by analyzing audit reports of influential DeFi applications. Specifically,\nwe delve into both academic research papers and high-quality industry reports to develop a\ncomprehensive understanding of the DeFi governance taxonomy. This taxonomy categorizes\ngovernance issues as well as assesses the issues based on their nature and severity, offering a\ndetailed perspective on the present challenges in DeFi governance. We observe that 38% of the\nhigh-severity issues identified pertain to governance, which is substantial.\nGuided by the taxonomy we developed, an in-depth analysis of audit reports of various DeFi\napplications revealed that the main governance issues center around the ownership structures and\nincentive schemes. For example, a recurring concern is the degree of centralization, especially in\nareas such as token distribution and protocol management, where a high-degree of centralization\nmay endanger the application\u2019s credibility. For example, critical privileges such as changing fee\nrates or transferring ownership are usually not expected to be centrally controlled. In addition,\nour analysis also revealed that some serious governance issues in DeFi are rooted at the mismatch\nbetween the proposed governance structures in whitepapers and their actual implementations. For\ninstance, there are cases [42] where DeFi owners reserve the right to mint any number of tokens by\nhiddening mint functions, which is never specified in the published governance structure. These\ndiscrepancies indicate potential loopholes which may be exploited to bypass intended governance\nmechanisms. As a first step towards automating the detection of these inconsistencies, we created a\nprototype tool based on large language model. This tool is designed to identify these misalignments,\naiming to improve the governance integrity in DeFi applications.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n3\nA crucial point to highlight from our study is that our findings offer several significant insights\nfor multiple DeFi stakeholders. For researchers in software engineering, there is a need to study\nand develop governance frameworks and theories for DeFi, as well as methods for validating\nthese governance systems. As an important application of blockchain, DeFi applications have a\nstandardized governance system development process that is crucial. Unlike centralized software\nsystems, the lifecycle management of DeFi diverges from traditional software approaches. In\nconventional software development, user needs and feedback drive continuous modifications.\nHowever, DeFi projects deviate from this model; their evolution is governed by their distinct\ngovernance systems. Stakeholders in DeFi should possess the authority to guide its evolution.\nHence, it\u2019s imperative for software engineers to address challenges within DeFi governance and\ncontribute towards establishing a comprehensive framework for its governance. For developers,\nit is essential to be cognizant of governance issues and to design transparent, ethical, and robust\ngovernance systems. For users and investors, they should investigate the governance structure of\nDeFi projects, such as the contract ownership, user privileges, and token power distribution. For\nregulators, it is crucial to both oversee governance structures and examine whitepapers of DeFi\nprojects, as they are key to identify fradulent activities.\nThese insights are instrumental in understanding and addressing the governance challenges\nwithin the DeFi sector. We aim to contribute to the development of robust and secure DeFi gover-\nnance frameworks and foster a better understanding of governance issues, promote best practices,\nand facilitate sustainable growth of the DeFi ecosystem. In summary, we make the following\ncontributions:\n\u2022 A Taxonomy of DeFi Governance: We created a detailed taxonomy for DeFi governance based\non an extensive review of academic literature and industry reports. This taxonomy offers a\nstructured approach to understanding and categorizing governance challenges in DeFi.\n\u2022 A Comprehensive Analysis of DeFi Governance Issues: Our paper provides a thorough examination\nof governance in DeFi applications. Through our analysis of audit reports by our governance\ntaxonomy, we shed light on the present conditions, challenges, and unaddressed needs in DeFi\ngovernance. Our research highlights important issues that urgently need to be addressed in DeFi\ngovernance-related research.\n\u2022 An Inconsistency Checking Tool between DeFi Whitepapers and Implementations: We have developed\na new prototype tool employing large language model (LLM). We use the text understanding\nability and code ability of LLM to guess what possible variable names are possible to be used.\nThen, we use the symbolic expression matching the code and the expression from the whitepaper\nto verify if the financial model is correctly implemented. This tool represents a pioneering effort\nto automatically identify and address inconsistencies between the governance described in DeFi\napplications\u2019 whitepapers and their actual implementations, paving the way for more aligned\nand transparent governance practices.\nThe paper is organized as follows. Section 2 introduces the three research questions under\ninvestigation, delineates our methodology, and details our data sources. Section 3 presents the\nresults corresponding to each research question and discusses the implications of our study. Related\nstudies to our work are reviewed in Section 4. Finally, Section 5 identifies potential threats and the\ncorresponding mitigation strategies used. Our concluding remarks and a summary of the work are\nencapsulated in Section 6.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n4\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\nSect. 2.1: Understanding\nGovernance Concepts\nSect. 2.2: Analyzing\nGovenance Issue\nAcademic and\nIndustry Articles\nReal-World\nAudit Reports\nSect 3.1: Governance\nTaxonomy (RQ1)\nSect 3.2: Common\nGovernance Issues (RQ2)\nSect 3.3: Governance\nInconsistency (RQ3)\nFig. 1. Overview of our study methodology.\n2\nMETHODOLOGY\nFigure 1 depicts the process that illustrates our analytical methodology and our three research\nquestions in the different stages:\n\u2022 RQ1: What governance taxonomy can we use to analyze the governance issue?\n\u2022 RQ2: What are the common governance issues in DeFi applications?\n\u2022 RQ3: How closely do DeFi application developers follow the guidelines specified in whitepa-\npers during application development?\nIn our initial phase, we delve into the concept of DeFi governance as it is elucidated in aca-\ndemic literature and industry blogs. Our aim here is to develop a comprehensive governance\ntaxonomy, a crucial framework that will underpin our entire analysis that guides us review the\ngovernance issues (RQ1). Moving forward, we collect and scrutinize audit reports, employing our\nnewly established governance taxonomy to dissect and understand governance issues in DeFi\napplications (RQ2). A significant aspect of our study revolves around the role of DeFi development\nteams in designing and implementing governance mechanisms. Here, we examine the commitments\noutlined in whitepapers, recognizing these documents as not only informative tools but also as\nmediums through which trust is established with investors and users. Consequently, we also focus\non assessing the extent to which development teams adhere to their designs and promises as\narticulated in their whitepapers (RQ3).\n2.1\nUnderstanding DeFi Governance Concepts\nGovernance, a pivotal concept in DeFi, lacks a universally accepted definition that encompasses\nits principles, scope, and role. This ambiguity poses a significant challenge in understanding and\nanalyzing governance within DeFi. To address this crucial gap, we adopt the mapping study [87].\nWe aimed at establishing a comprehensive taxonomy of DeFi governance. This taxonomy is a\nclassification system and a tool to dissect and categorize the multifaceted governance issues\nprevalent in DeFi applications. Through this endeavor, we aim to paint a clear picture of the current\ngovernance landscape in DeFi, highlighting key concerns and areas demanding further research\nattention.\nWe commenced our literature search with a systematic exploration of prominent databases,\nnamely IEEE Xplore [14], ACM Digital Library [9], and Scopus [15]. We first defined the keywords\nthat are directly related to the domain we were going to study, \u201cblockchain governance\u201d, \u201csmart\ncontract governance\u201d, and \u201cDeFi governance\u201d. These predefined keywords were used to search the\nrelated articles. This initial phase yielded a substantial corpus of articles: 458 from IEEE Xplore,\n498 from ACM Digital Library, and 1898 from Scopus, all published between 2017 and 2023 as\nshown in Figure 2. It is evident that there is a growing emphasis on governance. It is important\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n5\n2017\n2018\n2019\n2020\n2021\n2022\n2023\nYear\n0\n100\n200\n300\n400\nNumber of Papers\nSources\nACM\nIEEE\nScopus\nFig. 2. Conference Paper Count by Year (2017-2023).\nto acknowledge that the data for 2023 does not represent the entire year. Recently, researchers\nhave studied how GPT4 can be used to analyze documents [79, 101]. To distill this vast collection,\nwe also employed GPT4 as a query assistant,focusing specifically on the titles and abstracts to\nidentify the 100 most pertinent articles from each database, with an emphasis on governance in\ndecentralized finance applications. We upload the files that contain the title and abstracts to GPT4.\nThen, we instruct GPT4 to return the most related items with the prompt, \"according to the \u2019title\u2019\nand \u2019abstract\u2019, please use the topic model to extract the top 100 items from the file that related\nto the topic \u2019Decentralization Finance Application Governance\u2019 in a concise way.\" Expanding our\nsearch horizon, we also utilized Google Scholar and Connected Papers [11], reviewing the first five\npages of the search results to identify articles closely aligned with our research theme. We checked\ntheir titles and abstracts to see if they are related to decentralized finance and governance. In the\nend, this comprehensive approach led to the selection of 34 academic articles.\nIn our quest for a holistic understanding of DeFi governance, we extended our exploration\nbeyond academic literature to include industry perspectives. Recognizing the critical insights that\nWeb3 entities offer, we expanded our dataset to encompass 11 blog articles about DeFi governance\nfrom leading firms [20] in this field, like OpenZeppelin. This inclusion of diverse, industry-specific\nperspectives ensures a more comprehensive understanding of DeFi governance. Notably, during\nsearching articles, we discovered that several esteemed international organizations have published\nreports on decentralization finance from EUROFI [52], WIFPR [115],OECD [82],BIS [33] and Dutch\nBlockchain Coalition [48].We use Google engine and the aforementioned keywords to search for\nthese reports. We consider only the internal organization or the national institute. This led us to\nincorporate five such reports into our dataset, enriching our analysis with practical viewpoints.\nWe used Google to collect industry blogs and organization reports, employing DeFi governance\nas a keyword search, and checked the first 10 pages. We have published the list of search results\nonline [20].\nIn our quest to understand the specific aspects of governance emphasized in the literature,\nwe recognize that a universally accepted definition of DeFi governance is still evolving [25, 26,\n28, 46, 62, 66, 77, 95, 115]. Key components identified in these studies include decision-making\nprocesses [22, 25, 46, 47, 77, 97, 104], incentives for participation [25, 29, 62, 66], and issues related to\nownership and decentralization [29, 96, 104]. A central aspect of governance in DeFi systems is the\nuse of governance tokens, which often determine voting power in decision-making processes [25,\n29, 62, 69, 104]. The distribution of these tokens and the mechanism by which they are used in\ngovernance, including both off-chain and on-chain methods [38, 46, 50, 77, 116], are crucial aspects\nthat shape the governance structure. Furthermore, participants in the governance process are often\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n6\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\ninfluenced by incentive models, which can include utility tokens, incentive models, and revenue\nmodels [25, 29, 29, 40, 62, 66, 86] that are collectively called tokenomics.\nAn examination of governance from an industry perspective reveals notable congruences with\nacademic viewpoints, especially in conceptualizing it as a rule-based framework for decision-making.\nWhile academic literature often delves into broad topics, such as the governance of foundational\nplatforms like Ethereum, industry blogs [30\u201332, 37, 38, 49, 50, 80] tend to diverge, placing a greater\nemphasis on the practical aspects of DeFi governance at the application layer. This includes a\nfocus on the technical details, design strategies, and monitoring mechanisms of smart contract\ngovernance. These industry discussions typically revolve around several key themes, such as\ndetermining the scope of governance, identifying stakeholders, exploring different governance\nmodels, and conducting comparative analyses of their pros and cons. For instance, the intustries\noften discuss how governance mechanisms are integrated into the codebase, offering insights\ninto real-world implementation challenges and successes. This practical orientation provides a\ncomplementary perspective to the theoretical frameworks discussed in academic circles. As a\nsummary, the academy focuses on the nature of DeFi and its governace sysgtems with these aspects\ndecision-making processes, incentive for participation, ownership and decentralization; while the\nindustry emphasizes the mechanisms of implementation and the scenarios of real-world applications\nwith the following views, design strategies, monitoring mechanisms and implementation choice.\n2.2\nAnalyzing DeFi Governance in Audit Reports\nAudit reports, as products of expert scrutiny, are invaluable for studying the complex issues and\nchallenges in DeFi governance. These reports, rich in high-quality data, provide detailed insights\ninto smart contract issues that are critical to understanding DeFi governance. To harness this\nwealth of information, we gathered audit reports from a diverse range of reputable online sources,\navailable in formats such as PDF and HTML. This varied collection ensured a comprehensive data\npool. Our analysis of these reports involved extracting and categorizing governance-related issues,\nthereby creating a detailed picture of the challenges and intricacies involved in DeFi governance.\n2.2.1\nData Resource. In our pursuit of high-quality audit reports, we prioritized security companies\nknown for their expertise and reliability, particularly focusing on Certik and OpenZeppelin, whose\ncomprehensive reports are readily accessible on their websites. Recognizing that many security\nfirms also publish their findings on GitHub, we employed a targeted search using the following\nkeywords \u201caudit\u201d, \u201caudit report\u201d, and \u201csmart contract audit\u201d to gather more reports. To ensure the\ncredibility of these sources, we established a set of criteria: we examine an audit report only if the\nauditing company has over 1,000 Twitter followers\u2014a threshold verified for authenticity using the\ntool FollowerAudit [12]\u2014or is recognized on the Etherscan directory of smart contract auditors [16].\nThe website [16] includes recognizable security companies, and audit reports from these companies\nhave a higher chance of being good. Table 1 lists 17 security companies, collectively contributing\nto a dataset of 4,446 audit reports.\n2.2.2\nData Processing. An audit report contains the issues found by experts in one project, and we\nneed to extract each issue. We implemented a PDF parser and an HTML parser to convert raw audit\nreports into text format. Furthermore, we remove invalid text characters and then parse these texts\ninto JSON format according to the different audit sections, title, severity, recommendation, status,\nand description of each issue. The extraction leads to a total of 26,037 issues, as shown in the last\ncolumn of Table 1. Figure 3a illustrates the severity distribution of all issues. 35% of the issues are\nlabeled high and medium in terms of severity, which means the development team heavily depends\non the audit to find the serious problems. Figure 3b shows the resolution status distribution of all\nissues. We can conclude that most of the issues have been fixed (34.89%) or acknowledged (27%)\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n7\nTable 1. Commercial Security Company List as the Resource of Audit Reports.\nCompany\nOfficial Website\n#Twitter Followers\nEtherscan\n#Reports\n#Issues\nCertik\nhttps://www.certik.com\n288,957\n\u2713\n1,133\n12,461\nOpenzeppelin\nhttps://www.openzeppelin.com\n53,327\n\u2713\n92\n1,133\nImmune Bytes\nhttps://www.immunebytes.com\n738\n\u2713\n83\n673\nOak Security\nhttps://www.oaksecurity.io\n1544\n92\n950\nCyberscope\nhttps://www.cyberscope.io\n12,703\n336\n2,364\nCoinscope\nhttps://www.coinscope.co\n15,851\n184\n1,124\nSolidified\nhttps://www.solidified.io\n2546\n\u2713\n142\n289\nHASHEX\nhttps://hashex.org\n10,472\n\u2713\n30\n280\nZellic\nhttps://www.zellic.io\n6676\n28\n143\nQuillAudits\nhttps://www.quillaudits.com\n12,563\n\u2713\n85\n512\nCyStack\nhttps://cystack.net\n4643\n\u2713\n11\n48\nTechRate\nhttps://techrate.org\n12,466\n\u2713\n1,745\n3,049\nDecentraland\nhttps://decentraland.org\n631,806\n1\n3\nChainsulting\nhttps://chainsulting.de\n39,894\n\u2713\n74\n329\nSomish\nhttps://www.somish.com\n349\n\u2713\n9\n113\nPeckShield\nhttps://peckshield.com\n76,204\n\u2713\n277\n1,227\nQuantstamp\nhttps://quantstamp.com\n79,148\n\u2713\n124\n1,339\nTotal\n-\n-\n-\n4,446\n26,037\n6838\n2350\n7406\n7206\n1764\n237\n(a) Distribution of Severity about all issues\n738\n9086\n7032\n105\n8574\n150\n176\n(b) Distribution of Status about all issues.\nFig. 3. Severity and Status of the Issues in our dataset.\nby the developers. However, acknowledgment does not mean that the development team will\nfix these issues. If we compare the Fixed and Ack bars in Figure 3b, many serious issues are\nacknowledged (Ack) but not fixed. The reason behind it may be interesting but is beyond the scope\nof this work.\nWe filter out non-governance issues and then group the remaining governance issues based on\nthe built governance taxonomy. To categorize the governance issues, we extracted keywords for\neach category in the governance taxonomy according to the collected articles, as shown in Table 2.\nWe also collect statistics on governance issues in terms of the status and severity of the issue. This\ncan reflect what impact governance issues have and how developers handle them. Owing to the\nsubstantial amount of data acquired, manual analysis poses a significant workload. Consequently,\nwe leverage Natural Language Processing (NLP) techniques for initial data processing. We employ\nBERTopic [59] as an assistant to group the data and help us find common topics. We examine the\nclusters generated by BERTopic and determine the three most significant topics (Top-3) by the\nfrequency for each governance category.\n2.3\nInvestigating Consistency between DeFi Whitepapers and Implementations\nDuring we analyze the governance issues, we find that some governance issues are related to\nthe inconsistency between DeFi whitepapers and implementations. These inconsistencies were\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n8\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\nignored in previous studies. Inconsistencies between the whitepapers and the actual code can have\na profound impact on investor trust and interest. Such discrepancies, even if they do not lead to\nvulnerabilities, can profoundly affect the credibility and success of a DeFi project. For users and\ninvestors alike, it is both interesting and vital to assess how faithfully developers adhere to their\nclaims made in the whitepapers. This adherence is not just a matter of technical accuracy but also\none of maintaining trust and transparency in the burgeoning world of decentralized finance.\nTo address the challenge of identifying governance issues related to whitepapers in DeFi projects,\nwe employed an AI-based approach. Initially, we extracted relevant information by matching the\ntwo keywords \u2019whitepaper\u2019 and \u2019document\u2019 in audit reports. Recognizing the lack of existing tools\nfor this specific purpose, we also developed a prototype tool that integrates the capabilities of\nChatGPT [78]. This tool is designed to facilitate semi-automated detection of discrepancies between\nwhitepapers and source code. Figure 8 illustrates our detector. We first ask ChatGPT to find the\npossible variable names that can appear in the code from the whitepaper. An expert will read the\nwhitepaper and construct the financial expressions. Then, we build a tool to automatically extract\nthe mathematical expression from the smart contract. Then, we use the symbolic expression to\ncheck if they are equal.\nTo validate our prototype tool, we collected the whitepapers and source codes from eight DeFi\nprojects on the decentralization finance platform. The selected DeFi projects have to satisfy two\ncriteria: 1). The whitepaper should contain the financial model and can be downloaded from\nthe Internet; 2). The source code is public. Our collection process revealed the often-overlooked\nchallenge of accessing reliable sources; many projects, despite claims of openness, had invalid links\ndue to various reasons, such as project discontinuation or poor maintenance. We explore the ICO\nwebsites1 and the collected audit reports, and, in the end, we find eight projects whose source code\nand whitepaper are available. A smart contract auditor that works on this field more than 1 years\nextracted the claims about tokenomics from these whitepapers, and then employed our tool to\nverify them in the code.\n3\nFINDINGS AND IMPLICATIONS\nIn this section, we delve into a detailed analysis of our three research questions based on our data\nand the analysis framework. We demonstrate our findings for each research question. In the end,\nwe illustrate the implications.\n3.1\nTaxonomy of DeFi Governance (RQ1)\nWe identified their governance definitions and what aspect they focus on DeFi governance. After\ncarefully reviewing these resources, we formulate a governance taxonomy specifically tailored to\nthe domain of Decentralized Finance (DeFi). This taxonomy served as an analytical lens for our\nsubsequent scrutiny of governance issues.\n3.1.1\nDeveloping a Taxonomy for DeFi Governance. The governance of one DeFi project should\nfollow the typical software development pattern and is usually developed in a top-down manner, pro-\nceeding through three stages: governance design, governance content and governance implementation\nas shown in Figure 4.\nGovernance Design First, the DeFi team must establish a clear vision and principles guiding\ntheir governance approach to navigate the complexities of Decentralized Finance (DeFi) effectively.\nThis fundamental step is crucial, as it shapes the subsequent decisions and strategies.\n1https://icodrops.com/, https://icomarks.com/icos/defi\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n9\nGovernance Design\nGovernance Content\nGovernance Implementation\nVision and Principles?\nSpecific Mechanisms\nand Objects?\nSmart Contracts?\nFig. 4. Three-Stage Development Process of DeFi Governance.\nGovernance Content Next, the DeFi team should delve into the specifics of the governance\nstructure. This involves selecting a suitable governance mechanism and justifying its appropriate-\nness for their unique context. This step details the governance process\u2019s \u2018what\u2019 and \u2018why\u2019 , ensuring\nall stakeholders understand the rationale behind the choices.\nGovernance Implementation As the last step, the DeFi team implements the governance\ndesign. For a DeFi project to be deemed reliable, it should, at a minimum, detail its governance\ndesign in its whitepaper. An exemplary DeFi project not only makes claims in its whitepaper but\nalso shows how these claims are realized in practical applications.\nFigure 4 illustrates the three steps to develop governance in practice. A good whitepaper should\nrecord the three steps and make sure that the governance is transparent to users and investors from\nthe design to the end. Based on our understanding of the extracted information of the collected\narticles as described in Section 2.1 we developed our taxonomy to study governance issues. We\napproach DeFi governance as shown in Figure 5 from two perspectives: how governance should\nbe performed, and what should be governed. According to the common content that we find from\nthe collected articles, blogs, and reports, we used the six labels of governance issues with several\nrelated keywords that were highlighted in orange as shown in Figure 5. The leaf nodes list the\ncommon content of each category. How governance is decided by the vision and objective of DeFi\napplications.\nDifferent types of DeFi applications have different usages and goals, so their governance design\nand the corresponding implementation are also different. For example, Uniswap 3 is a decentralized\nexchange platform and assigns voting power to users through liquidity mining2. Aave3 is a lending\nplatform and claims to be a decentralized non-custodial liquidity market protocol, so it use Decen-\ntralized Autonomous Organization (DAO) to govern. Both are based on the on-chain governance\nbut the later also need to communicate in the forum. What should be governed describes the scope\nof DeFi governance. It consists of two parts, namely system mechanisms and underlying code.\nThe DeFi project constructs an economic system that includes financial models, and all on-chain\ngovernance is conducted through code.\nHow to govern There are two types of governance mechanisms [38, 50, 77]: off-chain and on-\nchain governance. Off-chain governance typically employs social approaches to reach a consensus\nfor governance. On the other hand, on-chain governance utilizes coded mechanisms within the\nplatform to achieve consensus. First, since our focus is on governance issues related to DeFi\nprojects implemented in smart contracts, our taxonomy is based primarily on on-chain governance\n(specifically, governance tokens) [23, 30, 37, 38, 80]. The governance token is used for decision\n2https://uniswap.org/governance\n3https://aave.com/#governance\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n10\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\nmaking and is regarded as the power to propose and vote [28, 46, 66]. Usually, the governance token\nshould be decentralized. Second, since the owner of a DeFi project often has certain privileges\nto govern smart contracts, ownership [38, 55] significantly influences the governance of DeFi\nprojects and plays an important role in the governance mechanism. The right of belonging is a\ncontroversial topic and centralization does not comply with the Web3 manifesto, decentralization,\nbut the actual situation may be more complicated. In the initial phase of the DeFi app, the team\nusually maintains ownership for convenience of updating. Although excessive rights are considered\nrisky, when analyzing data, we have observed that the presence of an ower role is needed in\nemergency situations, e.g., stopping an attacking transaction. The developer team should justify\nwhy they keep ownership, what power the owner role has, and how they manage the owner role.\nWhat should be governed We identified two key areas: tokenomics [25, 29, 29, 31, 32, 40, 55,\n62, 66, 86, 112] and codebase [112]. Tokenomics refers to the ecosystem defined by DeFi projects and\ncomprises three essential components: 1) Utility tokens [31], which serve as proof of access to DeFi\nservices such as payments, staking, and lending. The supply of Utilit token usually has the maximum\nlimitation. The initial distribution of tokens greatly affects the interest allocation, the security and\nreliability of the project. 2) Revenue streams [32, 55], which outlines how DeFi projects generate\nprofits. The revenue mechanism directly affects the survival time of the project and is a key issue\nto focus on in the DeFi governance. Revenue streams involve charging fees from users, increasing\ntoken prices, insurance, and the profits from other projects. 3) Incentive mechanisms [31, 55], which\ndetail how participants are incentivized to ensure long-term sustainability of the DeFi project.\nDepending on the target of DeFi applications, there are various incentive mechanisms that reward\nparticipants. Yield farming is to earn the rewards by locking the token. Liquidity mining rewards\nthe liquidity providers. Other incentive mechanisms include staking, airdrops, token burning, and\nreferral programs.\nCodebase pertains to the implementation of DeFi applications. Governance of the codebase\ninvolves determining how to update the implementation and rectify code-related issues, e.g., fixing\nvulnerabilites or code optimization. These modifications directly influence the DeFi project\u2019s\nfunctionality, impacting every user. Hence, regulating changes in the code is a crucial aspect of\ncontract governance. In this study, we focus on the issues of code updating, that is, how DeFi\napplications maintain their code.\n3.2\nCommon Governance Issues (RQ2)\n3.2.1\nDistribution of Governance Issues. Initially, we must filter out non-government issues. Table 2\npresents the raw keywords we originally used for issue classification, aimed at extracting governance\nissues based on our established governance taxonomy. Our taxonomy contains six class labels, as\ndepicted in the subcategory column. These labels are grouped into three categories: governance\nmechanism, tokenomics, and codebase. These keywords were derived from the papers and blogs\nwe collected. We eliminated the issues that did not include these keywords, yielding a total of\n7,346 governance issues. The status and severity of the governance issues for each category are\ndemonstrated, respectively, in Table 3 and Table 4. The final columns in Table 3 and Table 4 reveal\nthat most of the governance issues relate to ownership and incentive mechanisms. Discounting the\nstatus-unknown issues, it is evident that almost all status-known governance issues are addressed\nby the development team, as seen in Table 3. Table 4 indicates that most governance issues are\nlabeled with high or medium severity. Compared to Figure 3a, it is clear that a significant number\nof high-severity issues are governance related (about 38%). Figure 6 illustrates the extent of overlap\namong different categories of governance issues. It is evident from Figure 6 that the majority of\nthese issues are unique to their respective categories and do not overlap.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n11\nDeFi Governance\nMechanism\nOwnership\nGovernance Token\nVoting\nDecentralization\nDecision Making\nSubjects\nCodebase\nUpgrade\nIncentive\nYield Farming\nLiquidity Minting\nStaking\nAirdrops\nToken Burning\nReferral Programs\nRevenue Stream\nFee Calculation\nPrice Increase\nPenalty\nInsurance\nProfit form Others\nUtility Token\nSupply\nDistribution\nUsage\nFig. 5. The Overview of DeFi Governance Taxonomy.\nTable 2. Raw Keywords for Issue Classification.\nCategory\nSubcategory\nKeywords\nCitations\nGovernance\nMechanism\nGovernance Token\ngovernance\ntoken,\nvote,\nproposal,\ndeceision-making,\ntally,\nabstation,\nquorum, veto\n[25, 46, 47, 77, 97, 104]\n[22, 29, 61, 96, 104]\nOwnership\nowner, ownership, privilege\nTokenomics\nUtility Token\nsupply, token distribution, token name,\ntoken usage, asset token, token utility\n[25, 29, 40, 62, 66, 86]\n[21, 25, 54, 60, 65]\nRevenue Stream\ntransaction fee, trading fee, market-\nplace fee, borrow rate, protocol fee,\npremium fee, performance fee, token\nissuance, generic fee, interest rate,\ncharge a fee\nIncentive Mechanism\nlock up, total value locked, yield, bor-\nrow, airdrop, burn, stake, liquidity, lend,\nloan, referral, mint, incentive\nCodebase\nCode\nupdate contract, upgradable\n[1, 13, 48, 51, 58, 88]\nWe conclude the following points: 1) ownership and incentive mechanisms are two of the most\ncommon governance issues; 2) apart from governance issues with unknown status, most governance\nproblems have been resolved or acknowledged; 3) the number of high-severity issues is the highest\namong all severity levels of governance problems; 4) a significant number of high-severity issues\nare governance related (about 38%); 5) there is a small overlap among these governance categories.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n12\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\n(1)\nGovernance Mechanism,\nTokenomics and \nCodebase\n2212\n3150\n36\n6\n2\n12\n1928\nT\nGM\nC\n293\n4736\n67\n(2)  \nGovernance Token and \nOwnership\nGT\nO\n(3)\nUtility Token, \nRevenue Stream and    \nIncentive Mechanism\n129\n3382\n420\n4\n2\n85\n126\nRS\nUT\nIM\nFig. 6. Overlapping of Different Categories about Governance Issues.\nTable 3. Status of Governance Issues. The number in the last row are counted by excluding the overlapping.\nCategory\nFixed\nAck\nMitigated\nPending\nUnfixed\nDeclined\nUnknown\nAll\nGov Token\n175\n118\n19\n1\n3\n1\n43\n360\nOwnership\n688\n1372\n214\n23\n9\n8\n2,489\n4803\nUtility Token\n115\n273\n40\n6\n3\n2\n113\n552\nRevenue\n88\n80\n8\n1\n2\n3\n38\n220\nIncentive\n879\n986\n130\n16\n12\n9\n1,565\n3,597\nCodebase\n20\n14\n7\n0\n1\n0\n14\n56\nTotal\n1,689\n2,303\n325\n41\n26\n17\n2,945\n7,346\nTable 4. Severity of Governance Issues. The number in the last row are counted by excluding the overlapping.\nCategory\nHigh\nMedium\nLow\nInformation\nOptim\nUndet\nAll\nGov Token\n101\n77\n130\n44\n0\n8\n360\nOwnership\n1,814\n447\n637\n327\n3\n1575\n4,803\nUtility Token\n279\n98\n118\n48\n0\n9\n552\nRevenue\n46\n43\n82\n41\n0\n8\n220\nIncentive\n972\n421\n832\n356\n3\n1013\n3,597\nCodebase\n21\n14\n14\n5\n1\n1\n56\nTotal\n2606\n866\n1,554\n713\n7\n1600\n7,346\n3.2.2\nHierarchy of Governance Vulnerability. To delve deeper into governance issues and their\nrelated vulnerability, we have categorized these issues based on the design and implementation\nprocess of governance, as depicted in Figure 7. The first column in the figure outlines the gover-\nnance issues at each developmental stage, while the second column identifies the corresponding\nvulnerabilities. For each stage, we summarized vulnerabilities by identifying key security-related\nterms, such as \"attack\", and then conducted a manual review of the filtered issues. Initially, in the\ngovernance design stage, ownership is determined based on the vision and principles of the DeFi\nproject. Ownership is the core of DeFi governance. It decides which governance mechanism will\nbe applied. For example, if ownership is decided to belong to all participants, it should use the\nDAO (decentralized autonomous organization) governance model. During this stage, the owner\nrights should be carefully designed. Flaws in ownership design can lead to risks like \u2019rug-pulling\u2019.\nOwners, typically vested with extensive rights to manipulate contracts and maintain privileged\nfunctions, can easily misappropriate funds from users. The special rights associated with governance\nroles can, if compromised, pose a threat to the entire DeFi application.\nIn the subsequent stage, issues concerning governance tokens, revenue streams, incentive mech-\nanisms, and utility tokens emerge, all of which contribute to the formation of governance content.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n13\nGovernance Design\n\u2022 Ownership\nGovernance Content\n\u2022 Governance Token\n\u2022 Incentive Mechanism\n\u2022 Revenue Stream\n\u2022 Utility Token\nGovernance Implementation\n\u2022 Coding practice\n\u2022 Implementation Issues of Tokenomics\nand Governance Mechanism\n\u2022 Rug Pull\n\u2022 Key Compromise\n\u2022 Proposal Front-Running\n\u2022 Voting Sybil Attack\n\u2022 Denial Voting\n\u2022 Governance Logical Flaws \n\u2022 Centralization of Contract \nUpgrading  \nHierarchy of Governance Issues\nVulnerability\nFig. 7. Hierarchy of Governance Issue.\nThis stage often brings to light governance functionality issues, such as proposal front-running,\nSybil attacks in voting, denial voting, and inconsistencies in the governance process relative to its\ndesign. For instance, in proposal front-running, attackers can prematurely reach a consensus on a\nmalicious proposal [84]. In voting Sybil attacks [85], an attacker might rapidly acquire substantial\nvoting weight through flash loans. Denial voting often results from the depletion of gas fees [89].\nGovernance process flaws can significantly increase the susceptibility to attacks. For example,\nDerivaDEX\u2019s governance structure and its use of the Diamond proxy pattern are vulnerable to\nexploitation by malicious actors [89]. The implementation of governance may be different from the\ndesigned documents, introducing some risks such as phishing attacks [98] or causing the fairness\nproblem [35] to the DeFi projects.\nLastly, the governance implementation stage involves addressing issues related to coding practices\nand the implementation of tokenomics and governance mechanisms. The way governance roles\nmanage and update the DeFi system is crucial. Incorrect initialization [39] or inappropriate upgrades\ncan precipitate the failure of a DeFi project [36].\n3.2.3\nCommon Topics on Governance Issues. We use BERTopic [59] to cluster governance issues\nfor each category. Table 5 demonstrates the top-3 frequent topic words, respectively. Based on the\nclusters in Table 5, we make the following summary:\nGovernance Token. The first is related to the management of the proposal. It includes the\nexpiration of the proposal, unexpected cancellations, and non-unique keys to identify voting topics.\nThe second one is about the voting process, especially the management of voting power, i.e., how\nit is transferred, burned, or minted. The third is about the decision-making processes and the\ngovernance vulnerabilities, e.g., the delay of executing decisions and malicious proposals.\nOwnership. The first is about the centralization risk that the owners are authorized too much or\nless, e.g., stopping any transaction or lacking the handling-emergency right. The second is about\nthe administration key management; the admin roles are assigned with some privileged functions\nand the leak of admin keys must result in huge loss. The third is about the management of the\nblacklist.\nUtility Token. The first concerns the initial token distribution. For example, deployers distribute\ntokens without obtaining consensus from the community, and few whale accounts can hold almost\nall tokens. The second is about the token total supply. For example, the total token supply is not\nconsistent with the whitepaper, and the total supply can be increased or decreased without any\nrestriction. The third is about the usage problems of the utility token, e.g., price settings, liquidity,\nand reward calculation.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n14\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\nTable 5. Top-3 Topic Words in all governance issues.\nCategory\nTop 1\nTop 2\nTop 3\nGov Token\nproposal, contract, token\nvoting power, power moved\ngovernance,\nmacilious,\nlack\nevent\nOwnership\ncentralization risk\ntrust issue admin, keys\nblacklisted contract\nUtility Token\ntoken distribution initial\ntotal supply, wrong total, supply\nrestriction\nrewards, price, users, duplicate,\nliquidity\nIncentive\nowner privileges, centralization\nrisk\nmint token\ntrust issue admin, keys\nRevenue\nprotocol fee, transaction\ninterest rate, borrow, manipu-\nlate\nincompatibility deationary to-\nkens\nCodebase\nupgradeable contracts, storage\ncentralized\ncontrol\ncontract,\ncontract upgrade\n-\nIncentive Mechanism. The first is the centralization risks and the privilege function, where\nowners have the authority to manipulate functions related to the incentive mechanism, such as\nmodifying the fee rate. The second is about the minting function, including the minting restriction\nand limitation, minting authority, and access control. The third is about the administration key\nmanagement; the improper key management can resulting in the incentive mechanism can be\nmanipulated by the third party.\nRevenue Stream. The first concerns fee configuration issues, e.g., fee calculation, transaction\nfee manipulation, and inconsistent fee setting. The second is about borrowing and loaning issues,\ne.g., the design of borrowing and loaning processes or the interest rate configurations. The third is\nabout the incompatibility between the non-deflationary token and the deflationary tokens.\nCodebase. The first major concern is the technical aspect, such as improper initialization or\nincorrect implementation during upgrades. These issues can lead to catastrophic update failures or\nexpose vulnerabilities in the contract. The second concern is the risk of centralization in contract\nupgradeability. If an attacker gains control of the \u2019owner\u2019 role, they could update the contract with\nmalicious intent, potentially leading to substantial losses.\n3.3\nDeFi Whitepaper-Implementation Inconsistency (RQ3)\n3.3.1\nGovernance Inconsistency Issue. We used two keywords, \u201cwhitepaper\u201d and \u201cdocument\u201d to\nfilter the governance issues and find 136 issues related to the governance design. We use the\nBERTopic [59] model to analyze the main topics in these 136 issues and find that the inconsistency\nbetween the document and implementation is the main concern (top 1). These inconsistencies\nusually have three cases; a) the code does not implement the features in the whitepaper; b) the\ncode implements features that are not described in the whitepaper; c) the code implementation\nmismatches the design in the whitepaper, e.g., the tokenomics configurations like fee and interest\nrate.\n3.3.2\nDetection of Inconsistency. There are many difficulties in detecting the inconsistency between\nthe whitepaper and the implementation. Whitepapers from different developers have different\nformats and contain a variety of information. The source codes from the different developers also\nhave different styles. These factors make matching between the whitepaper and the code difficult.\nTo study whether it is possible to detect these inconsistencies automatically or semi-automatically,\nwe make a prototype tool as the first attempt. This tool checks if the fee setting is consistent between\nthe whiepaper and the implementation. Figure 8 demonstrates the overview of our prototype tool.\nWe use the programming ability [34] of ChatGPT to obtain possible variable names of the DeFi\nconfigurations in the code. We extract the tokenomics configuration settings from the whitepaper\nand then check if they match the code. Table 6 shows the results with the F1 score of 56.14% and\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n15\nPrompt\nPossible \nvariable names\nReports\nMatcher and \nChecker\nExpression \nextractor\nAdd values\nSmart Contract\nWhitepaper\nFig. 8. Inconsistency Detection of Parameters about Tokenomics.\nTable 6. DeFi Tokenomics Configuration Inconsistency Checking, and F1 = 56.14%.\nNo. of Params\nPredicted P/N\nFP\nFN\nMoonGame [2]\n5\n0/5\n0\n0\nPanther-Farm [4]\n6\n4/2\n2\n1\nHFTToken [7]\n6\n5/1\n3\n0\nShivaToken [8]\n8\n3/5\n3\n2\nASENIX [5]\n6\n4/2\n3\n0\nBiokript [10]\n7\n7/0\n1\n0\nBitchmdefi [3]\n7\n6/1\n1\n1\nEteru [6]\n9\n8/1\n8\n0\nTotal\n54\n37/17\n21\n4\nrecall of 80% on our collected DeFi projects. The second column shows the number of tokenomics\nconfiguration settings in the whitepaper. The predicted P/N in the third column means the predicted\npositive/negative by our tool, where we label the inconsistency as 1 and the consistency as 0. FP\nand FN mean false positive and false negative. Our tool is available online.4\n3.4\nImplications\nOur findings from this study derive multiple implications for various stakeholders in the DeFi\necosystem, including researchers, DeFi developers, investors, users, policymakers, and regulatory\nbodies. Specifically, we provide insights on developing and improving governance frameworks in\nDeFi projects, highlight the challenges and vulnerabilities in DeFi governance, and facilitate the\nformulation of guidelines and best practices in this domain.\nFor Researchers. First, in the realm of software engineering (SE) research, there is a pressing\nneed to delve into DeFi governance frameworks. Governance challenges form a substantial part of\nthe hurdles DeFi applications face, necessitating thorough research and solutions. Our taxonomy\nserves as a foundation for this exploration. Yet, numerous challenges remain unaddressed. For\ninstance, the absence of a governance development model akin to software development frameworks\nhampers the design and implementation of effective governance strategies. Furthermore, the\nfairness in tokenomics and the balancing act in centralization demand in-depth study. For example,\ndetermining the extent of control for \u2019owners\u2019 and establishing ownership criteria are critical.\nIn certain scenarios, centralization can safeguard a DeFi project, such as halting a malicious,\nunvalidated transaction. A deeper understanding and resolution of these issues could significantly\nenhance investor confidence and the success of DeFi applications. Second, a robust verification\nmethodology is vital for scrutinizing the governance system design prior to implementation. Given\n4https://anonymous.4open.science/r/consistency_checker-CD88\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n16\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\nthat smart contracts are immutable post-deployment, rectifying defects is not as straightforward as\nin traditional software systems. From proposal initiation to final execution, each state transition\nwithin the governance process warrants careful verification. Overlooking flaws in governance design\ncan have dire consequences, such as losing control to hackers. Addressing potential flaws proactively\nis crucial, as fixing high-level issues post-deployment in DeFi systems can be exceedingly costly.\nThird, ensuring consistency between DeFi whitepapers and their implementation is paramount.\nThis alignment is crucial for transparent and accurate communication with investors and users.\nDeveloping semi- or fully automatic approaches to verify this consistency is an essential step\nforward. The prototype tool developed in our research could pave the way for more advanced\nsystems capable of automating the verification process, thereby upholding the integrity of DeFi\nprojects.\nFor DeFi Developers. First, Designing a robust governance system is paramount. It is essential to\nalign with our proposed governance taxonomy and clearly articulate the rationale behind chosen\ndesigns, especially in managing privileged functions. Implementing these designs with transparency\nand communicating the details to users is crucial for trust-building. Second, developers must stay\nabreast of common governance issues and vulnerabilities. By enhancing governance mechanisms\nand refining implementation processes, they can address critical concerns related to ownership and\ntokenomics, thereby bolstering the security and reliability of their applications. Particular attention\nshould be paid to ownership protection mechanisms, such as safeguards against unauthorized\naccess to owner keys by team members or external threats. Third, developers should commit\nto transparent and accurate communication with investors and users. Maintaining consistency\nbetween the project\u2019s whitepaper and actual code is essential to reduce misinformation and mitigate\nrisks. This approach not only builds trust but also solidifies the project\u2019s credibility in the DeFi\necosystem.\nFor Investors and Users. The insights from this study equip investors and users with the knowl-\nedge to make informed decisions in the DeFi arena. Understanding the governance issues, as\ncategorized in our taxonomy, is key. Investors should scrutinize the governance frameworks, own-\nership structures, and tokenomics of DeFi projects for indicators of robustness and fairness. Crucial\nsteps include:\n\u2022 Evaluating how a DeFi program manages ownership and the rationale behind these strategies.\n\u2022 Investigating the rights granted by governance tokens within the project\u2019s structure.\n\u2022 Assessing token distribution and privileged functions for potential unfair practices or incon-\nsistencies with the whitepaper.\n\u2022 Understanding who holds the power to alter the DeFi code.\nBy comprehensively analyzing these elements, investors and users can discern the value and\nlegitimacy of a DeFi application, thereby steering clear of scams. For example, the ability of a DeFi\nprogram to mint unlimited tokens or withdraw liquidity unrestrainedly may signal fraudulent\nintent. While there are inherent risks, a well-governed DeFi project can also present significant\nopportunities. Thus, a balanced approach in evaluation is crucial.\nFor Regulators and Policymakers. Regulators and policymakers stand to gain significant insights\nfrom this research, particularly in understanding the nuanced governance challenges in DeFi.\nThis study underscores the necessity for regulatory frameworks that go beyond assessing code\nvulnerabilities to encompass the entire governance structure of DeFi projects. A key area for\nfuture policy development is the role of the whitepaper; it is time to engage in discussions about\nits legal significance within the DeFi ecosystem. For instance, considering whether whitepapers\nshould be subjected to regulatory oversight, given their role in outlining project fundamentals, is\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n17\ncrucial. Additionally, governance issues often center around ownership and incentive mechanisms.\nTherefore, regulatory bodies should closely monitor privileged functions that have a substantial\nimpact on DeFi tokenomics, ensuring they align with both investor protection and market integrity.\nWhile doing so, it is important to strike a balance between effective regulation and fostering an\nenvironment that encourages innovation in the DeFi space.\n4\nRELATED WORK\nStudies on Blockchain and Decentralized Finance. Blockchain employs a decentralization\nmethodology, securely storing data in a specifically structured entity known as a block. In particular,\ndata incorporated into the system becomes impervious to tampering. Blockchain technology has\ncaused profound changes and impacts on traditional Web 2.0 and is becoming a fundamental service\nof the Web, leading to the emergence of Web 3.0. Blockchain has been widely used in many fields,\nsuch as cryptocurrency, financial services, games, trading systems, and IoT [44, 56, 120]. Zheng et al.\n[120] and Gao et al. [56] reviewed the fundamental techniques in Blockchain such as architecture\nand consensus algorithms, and also discuss several blockchain applications. Di Francesco Maesa and\nMori [44] study non-cryptocurrency blockchain applications and practical problems they solved,\nindicating that blockchain is a valuable technique for the real world. Decentralized finance (DeFi)\nis one main application scenario for blockchain. Meyer et al. [81] conduct the systematic literature\nreview about DeFi at three different levels, i.e., micro, meso and macro. Shah et al. [99] reviews the\nvarious types of DeFi protocol in DeFi products. Bartoletti et al. [24] reviews the formal methods\nfor DeFi to ensure its correct behavior. Jiang et al. [64] investigates the DeFi running mechanisms\nand systemically reviews the DeFi risks. Werner et al. [114] reviews the features and security of\nDeFi.\nBlockchain and DeFi Governance. In the realm of blockchain and DeFi governance, several\nstudies stand out. Allen et al. [18, 19] propose a descriptive framework to understand blockchain\ngovernance, and later develop an exchange theory for Web3 governance. Ekal et al. [47] bridged\ntraditional finance governance models with blockchain-based mechanisms. Kiayias et al.[66] con-\nducted a comprehensive examination of the characteristics of blockchain governance. Marc et\nal. [108] and Gogel et al. [57] discussed its main forms, offering insights into this emerging field. Liu\net al.[77] performed a systematic review analysis, summarizing the concept of blockchain gover-\nnance as the system and procedures established to ensure that the development and implementation\nof blockchain technology complies with legal, regulatory and ethical obligations. Furthermore,\nLiu et al.[76] proposed a governance framework specifically for blockchain technology. Other\nfoundational works [70, 86, 112] have also explored the realm of blockchain governance, offering\nhighly abstract and conceptual insights. Another relevant study [55] looks at the DeFi revenue\nmodels and governance systems based on the analysis of real DeFi applications. Some works study\ngovernance risks and code update. Bekemeier et al. [27] systematically analyzes risks in DeFi, in-\ncluding DeFi governance. Bhambhwani et al. [29] analyzed the top 50 DeFi protocols and indicated\npotential governance risks. Erik et al. [48] discuss smart contract governance on smart contract\nupgrade in permissionless and permissioned blockchains. Reports from international organizations\nlike the OECD and BIS [33, 52, 82, 115] discuss the current state and potential impacts of DeFi,\nproviding a broader policy perspective. All of these works do not study the governance issues in\nDeFi applications. We benefit from the previous studies and build a governance taxonomy to study\nthe governance issues in DeFi.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n18\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\nDeFi Security. Since its inception, blockchain technology has held a strong affinity with finance,\nand as such, its security issues often precipitate substantial financial losses. For example, RONIN5\nlost $624M because the attacker found a way to access the additional validator. The increased\nfocus on blockchain security has led to the emergence of numerous tools to identify and rectify\nvulnerabilities, such as Slither [53] and ContractFuzzer [63]. Zhou et al. [121] study the 13 common\nvulnerabilities and compare different security tools. Nevertheless, these resources are predominantly\ncode-centric, overlooking design-level vulnerabilities, like those that pertain to flash loan attacks.\nThese security gaps depend mainly on human auditing for detection and correction. Li et al. [72]\ncomprehensively analyze the security issues of DeFi at each blockchain layer. Since DeFi defines\nan economy system and interacts with the real world, its vulnerability is not only limited in its\nself weakness but also includes some more complex risk issues. Liu et al. [75] studies the fairness\nproblem in DeFi. Trozze et al. [107] study the financial fraud in DeFi. Torres et al. [106] study\nhoneypot smart contracts and develop a tool to detect this scam. Liang et al. [73] study Ponzi scam\nin DeFi.\nCode-Document Inconsistency. Inconsistency between code and documents is the common issue\nin software evolution. Wen et al. [111] systematically investigate the inconsistency between code and\ndocuments in a large dataset. Tan et al. [105] study the outdated documents and analyze the reason\nwhy the document is not synchronized with the latest code. Recent research works use machine\nlearning approaches to detect inconsistencies between code and documents. Rabbi and Siddik\n[90] use the siamese recurrent network to detect inconsistency based on word tokens in code and\ndocuments. Kim and Kim [67] employ natural language processing to detect inconsistent identifiers.\nPanthaplackel et al. [83] utilize the graph neural networks to detect code-doc inconsistencies based\non AST. Rani et al. [91] conducted a literature review on code-document quality and found that\nmost works focus on Java programs, resulting in poor generation performance. All of the works\nfocus on the code function and descriptions. Our work employs the foundational model to solve the\ninconsistency of financial models between code and whitepapers on a fine-grained level (expression\nlevel).\nNLP Topic Model and Foundation Model. The topic model [41] is a useful text analysis tool\nand can identify the topic words in the documents without the training phase. A. Abdelrazek,\nY. Eid et al. [17] group topic molds into four categories, algebraic, fuzzy, bayesian probabilistic,\nand neural topic models. Since the appearance of BERT [43], a large number of deep learning-\nbased topic models have emerged [119], like Sentence-BERT [93] and BERTopic [59]. Recently, the\nfoundation models like ChatGPT and StarCoder [71] have demonstrated outstanding performance\non a multitude of tasks related to documents and code. C. Zhang et al. [118] illustrate that ChatGPT\nis at the initial level of general intelligence. Prompt [74] technique is critical for these foundation\nmodels. P. Liu et al. [74] systemically investigate prompt engineering in NLP and indicate that\nresearch on prompt theory should be enhanced.\n5\nTHREATS TO VALIDITY\nIn this study, there are some threats-to-validity factors that need to be considered. These threats\ninclude data bias, the subjectivity of topic models due to the limited training dataset, as well as\nlimitations of the inconsistency detector about the code and the whitepaper.\nFirst, this study primarily focuses on existing DeFi application projects and is limited to the\nanalysis of governance issues. There may be selection bias in the sample. The DeFi ecosystem\nconsists of a variety of DeFi applications, and it also is an evolving and changing field, with the\n5https://rekt.news/ronin-rekt/\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n19\npossibility of new application projects and governance issues emerging. An incomplete sample set\nmay result in biases in the analysis. It is possible that the research findings may not fully cover\nfuture trends in DeFi development without enough data. In order to address this problem, we\nselected up to 17 reputable Web3 security companies and collected over 4000 audit reports, aiming\nto include a diverse range of DeFi application projects.\nSecond, we filtered the data using keywords, and further analysis and summaries were conducted\nusing the topic model, BERTopic[59]. While this approach provides a strong analytical framework,\nthere is still some level of subjective judgment when it comes to extracting and interpreting\nkey themes because of the possible bias knowledge of AI models. AI models are limited by their\ntraining data. To reduce its impact, researchers conducted multiple independent analysis, and\nengaged in careful discussions and negotiations to reach a consensus. Additionally, the feasibility\nof the verification tool about the consistency between the code and the whitepaper also has some\nlimitations. Due to variations in the formatting of different whitepapers and source code styles, the\ntool may encounter challenges in practical applications. The large language model training corpus\nincludes a wide range of codebases and document styles. We chose to utilize the large language\nmodel (ChatGPT) to reduce the impact of this diversity in styles of code and whitepapers.\n6\nCONCLUSION\nThis paper presents a comprehensive study of governance issues in decentralized finance (DeFi)\napplications. Drawing on the existing research literature and industry blogs, we propose a novel\nDeFi governance taxonomy for governance issues, categorizing and analyzing them through the\nlenses of governance design and implementation. To analyze governance issues, we collected\n4,446 audit reports from 17 reputable Web3 security companies, amounting to a total of 26,037\nissues. To grasp the attributes of the collected data, we examined the severity levels and resolution\nstatuses of these issues. Then, we identified in the audit reports that 7,346 issues were related to\ngovernance according to the governance taxonomy. We discovered that most of the problems are\nassociated with ownership and incentive mechanisms. To study deeply, we employed the BERTopic\ntool to conduct an extensive analysis of governance issues within each category, revealing main\nproblematic topics (top 3). The discovery of these topics provides clearer directions and foundations\nto solve these governance issues. In addition, we explore the challenges posed by maintaining\nconsistency between the code and the whitepaper in DeFi applications. Whitepapers serve as\nthe development-team commitment to users. In our analysis of governance issues, we identified\nsome inconsistency issues between implemented code and the whitepapers. These discrepancies\ncan significantly impact users. To tackle this problem, we developed a governance inconsistency\ndetector powered by AIGC (ChatGPT) to check semantic artifacts between whitepapers and the\ncode, and demonstrated its effectiveness by the evaluation of eight DeFi projects, providing valuable\ninsights for the future resolution of this inconsistency issue.\nIn summary, our research systematically investigates the governance issues present in DeFi\napplications and reveals the main concerns of DeFi governance. We propose a novel framework to\nunderstand them. Our work highlight the potential research directions about DeFi applications for\nsoftware engineering researchers. As a decentralized application, DeFi emphasizes decentralization\nand transparency. We should study how to standardize the DeFi governance design, development\nand change process to make DeFi projects credible. Through this study, we hope to help development\nteams of DeFi applications, DeFi users, regulatory bodies, and researchers interested in DeFi to\ngain a better understanding of and address governance challenges, thereby promoting the healthy\ndevelopment of decentralized finance.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n20\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\nREFERENCES\n[1] 2019. How we Safeguard our Smart Contracts (and Governance).\nhttps://blog.oceanprotocol.com/making-ocean-\nprotocols-smart-contracts-and-it-s-governance-unstoppable-45cf99dc1b65\n[2] 2020. MOONGAME. https://www.coincarp.com/currencies/moongame/\n[3] 2021. Bitchemicaldefi. https://github.com/Bitchemicaldefi\n[4] 2021. PantherSwap. https://www.passiveincomewithdefi.com/yieldfarming-with-pantherswap-f0e4068f71b0\n[5] 2022. ASENIXToken. https://asenix.org/\n[6] 2022. Eternumland. https://eternumland.io/\n[7] 2022. Hashflow. https://www.hashflow.com/\n[8] 2022. SHIVA Token. https://coinmooner.com/coin/shiva-token-shiva\n[9] 2023. ACM Digital Library. https://dl.acm.org/\n[10] 2023. Biokript. https://biokript.com/\n[11] 2023. Connected Papers. https://www.connectedpapers.com/\n[12] 2023. Followeraudit. https://www.followeraudit.com/\n[13] 2023. How to set up on-chain governance. https://docs.openzeppelin.com/contracts/4.x/governance\n[14] 2023. IEEE Xplore. https://ieeexplore.ieee.org/Xplore/home.jsp\n[15] 2023. Scopus. https://www.scopus.com/\n[16] 2023. Smart Contracts Audit And Security. https://etherscan.io/directory/Smart_Contracts/Smart_Contracts_Audit_\nAnd_Security,timestamp19/07/2023\n[17] Aly Abdelrazek, Yomna Eid, Eman Gawish, Walaa Medhat, and Ahmed Hassan. 2022. Topic modeling algorithms and\napplications: A survey. Information Systems (2022), 102131.\n[18] Darcy WE Allen and Chris Berg. 2020. Blockchain governance: what we can learn from the economics of corporate\ngovernance. Allen, DWE and Berg, C (Forthcoming)\u2018Blockchain Governance: What can we Learn from the Economics of\nCorporate Governance (2020).\n[19] Darcy WE Allen, Chris Berg, Aaron M Lane, Trent MacDonald, and Jason Potts. 2023. The exchange theory of web3\ngovernance. Kyklos (2023).\n[20] anonymous. 2023.\nThe List of Searched Articles.\nhttps://docs.google.com/spreadsheets/d/1CzTdtF-4ufHBh9_\njs9U01PgLL4eus1LO/edit?usp=drive_link&ouid=111813213768125351842&rtpof=true&sd=true\n[21] Adam P Balcerzak, Elvira Nica, El\u017cbieta Rogalska, Milo\u0161 Poliak, Tom\u00e1\u0161 Klie\u0161tik, and Oana-Matilda Sabie. 2022.\nBlockchain technology and smart contracts in decentralized governance systems. Administrative Sciences 12, 3 (2022),\n96.\n[22] E. Baninemeh, S. Farshidi, and S. Jansen. 2023. A decision model for decentralized autonomous organization\nplatform selection: Three industry case studies. Blockchain: Research and Applications 4, 2 (2023), 100127.\nhttps:\n//doi.org/10.1016/j.bcra.2023.100127\n[23] Tom Barbereau, Reilly Smethurst, Orestis Papageorgiou, Johannes Sedlmeir, and Gilbert Fridgen. 2023. Decentralised\nFinance\u2019s timocratic governance: The distribution and exercise of tokenised voting rights. Technology in Society 73\n(2023), 102251. https://doi.org/10.1016/j.techsoc.2023.102251\n[24] Massimo Bartoletti, James Hsin-yu Chiang, and Alberto Lluch Lafuente. 2021. Towards a Theory of Decentralized\nFinance. In Financial Cryptography and Data Security. FC 2021 International Workshops, Matthew Bernhard, Andrea\nBracciali, Lewis Gudgeon, Thomas Haines, Ariah Klages-Mundt, Shin\u2019ichiro Matsuo, Daniel Perez, Massimiliano Sala,\nand Sam Werner (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 227\u2013232.\n[25] Roman Beck, Christoph M\u00fcller-Bloch, and John Leslie King. 2018. Governance in the blockchain economy: A\nframework and research agenda. Journal of the association for information systems 19, 10 (2018), 1.\n[26] Felix Bekemeier. 2021. Deceptive Assurance? A Conceptual View on Systemic Risk in Decentralized Finance (DeFi).\nIn Proceedings of the 2021 4th International Conference on Blockchain Technology and Applications. 76\u201387.\n[27] Felix Bekemeier. 2022. Deceptive Assurance? A Conceptual View on Systemic Risk in Decentralized Finance (DeFi). In\nProceedings of the 2021 4th International Conference on Blockchain Technology and Applications (Xi\u2019an, China) (ICBTA\n\u201921). Association for Computing Machinery, New York, NY, USA, 76\u201387. https://doi.org/10.1145/3510487.3510499\n[28] Siddharth Bhambhwani. 2023. Governing decentralized finance (DeFi). Available at SSRN 4513325 (2023).\n[29] Siddharth M Bhambhwani. 2022. Governing Decentralized Finance (Defi). Available at SSRN 4225775 (2022).\n[30] Binance. 2022. What Are Governance Tokens? https://www.binance.com/bg/feed/post/42812\n[31] Binance. 2022. What Is Tokenomics and Why Does It Matter?\nhttps://academy.binance.com/en/articles/what-is-\ntokenomics-and-why-does-it-matter\n[32] Binance. 2023. How DeFi Protocols Generate Revenue and Why It\u2019s Important. https://academy.binance.com/en/articles/\nhow-defi-protocols-generate-revenue-and-why-it-s-important\n[33] BIS. [n. d.]. DeFi risks and the decentralisation illusion1. https://www.bis.org/publ/qtrpdf/r_qt2112b.pdf\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n21\n[34] Som Biswas. 2023. Role of ChatGPT in Computer Programming.: ChatGPT in Computer Programming. Mesopotamian\nJournal of Computer Science 2023 (2023), 8\u201316.\n[35] Certik. 2022. NFN-02, Security Assessment Notable. https://certik-public-assets.s3.amazonaws.com/CertiK-Audit-for-\nNotable-v5.pdf\n[36] Certik. 2022. TFF-01, Tokensfarm. https://certik-public-assets.s3.amazonaws.com/CertiK-Audit-for-Tokensfarm-v5-\nv9.pdf\n[37] Certik. 2023.\nSecurity Considerations When Designing Blockchain Governance Systems.\nhttps://www.certik.\ncom/resources/blog/1oil2sf9hiNQL4ucVxqsrM-security-considerations-when-designing-blockchain-governance-\nsystems\n[38] CertikGovernance. 2021.\nSkynet Security Primitive 3: Governance.\nhttps://www.certik.com/resources/blog/\nSkynetGovernance\n[39] Chainsulting. 2022. 6.6.1 Initialze Not Protected, CrowdSwap Staking. https://github.com/CrowdSwap/audits/blob/\nmain/02_Smart_Contract_Audit_CrowdSwap_Staking.pdf\n[40] Amit Chaudhary, Roman Kozhan, and Ganesh Viswanath-Natraj. 2023. Interest Rate Rules in Decentralized Finance:\nEvidence from Compound. In 4th International Conference on Blockchain Economics, Security and Protocols (Tokenomics\n2022). Schloss Dagstuhl-Leibniz-Zentrum f\u00fcr Informatik.\n[41] Rob Churchill and Lisa Singh. 2022. The evolution of topic modeling. Comput. Surveys 54, 10s (2022), 1\u201335.\n[42] DeFisec. 2023. How to spot hidden mint functions. https://defisec.info/how_to_spot_hidden_mint_functions\n[43] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional\ntransformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).\n[44] Damiano Di Francesco Maesa and Paolo Mori. 2020. Blockchain 3.0 applications survey. J. Parallel and Distrib.\nComput. 138 (2020), 99\u2013114. https://doi.org/10.1016/j.jpdc.2019.12.019\n[45] Laszlo Dobos. 2020. Build Finance DAO hostile takeover, treasury drained. https://cryptoslate.com/build-finance-dao-\nhostile-takeover-treasury-drained/\n[46] Taner Dursun and Burak Berk \u00dcst\u00fcnda\u011f. 2021. A novel framework for policy based on-chain governance of blockchain\nnetworks. Information Processing & Management 58, 4 (2021), 102556. https://doi.org/10.1016/j.ipm.2021.102556\n[47] Hassan Hamid Ekal and Shams N Abdul-wahab. 2022. DeFi Governance and Decision-Making on Blockchain.\nMesopotamian Journal of Computer Science 2022 (2022), 9\u201316.\n[48] Maarten Everts (TNO) Erik Weitenberg (TNO). [n. d.].\nSmart Governance for Smart Contracts.\nhttps://\ndutchblockchaincoalition.org/assets/images/default/DBC-Rapport-Smart-governance-for-smart-contracts.pdf\n[49] esatya. 2018. All you want to know about DeFi Governance? https://esatya.io/blogs/all-you-want-to-know-about-\ndefi-governance\n[50] ethereum. 2023. Introduction to Ethereum governance. https://ethereum.org/en/governance/\n[51] Ethereum. 2023. UPGRADING SMART CONTRACTS.\nhttps://ethereum.org/gl/developers/docs/smart-contracts/\nupgrading/\n[52] Eurofi. 2022.\nDECENTRALIZED FINANCE (DeFi): OPPORTUNITIES, CHALLENGES AND POLICY IMPLICA-\nTIONS. https://www3.weforum.org/docs/WEF_DeFi_Policy_Maker_Toolkit_2021.pdf.https://www.eurofi.net/wp-\ncontent/uploads/2022/05/eurofi_decentralized-finance-defi_opportunities-challenges-and-policy-implications_\nparis_february-2022.pdf\n[53] Josselin Feist, Gustavo Grieco, and Alex Groce. 2019. Slither: a static analysis framework for smart contracts. In 2019\nIEEE/ACM 2nd International Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB). IEEE,\n8\u201315.\n[54] Stefania Fiorentino and Silvia Bartolucci. 2021. Blockchain-based smart contracts as new governance tools for the\nsharing economy. Cities 117 (2021), 103325.\n[55] Alessandro Fusco. 2021. Decentralized applications: an empirical analysis of their revenue models and governance\nsystems. (2021).\n[56] Weichao Gao, William G. Hatcher, and Wei Yu. 2018. A Survey of Blockchain: Techniques, Applications, and\nChallenges. In 2018 27th International Conference on Computer Communication and Networks (ICCCN). 1\u201311. https:\n//doi.org/10.1109/ICCCN.2018.8487348\n[57] David Gogel. 2021. DeFi Beyond the Hype: The Emerging World of Decentralized Finance. In collab. with Wharton\nBlockchain and Digital Asset Project and World Economic Forum. Wharton. url: https://wifpr. wharton. upenn. edu/wp-\ncontent/uploads/2021/05/DeFi-Beyond-the-Hype. pdf.\n[58] Upgrades governance. 2023. Upgrades governance. https://docs.zeppelinos.org/docs/2.4.0/upgrades_governance\n[59] Maarten Grootendorst. 2022. BERTopic: Neural topic modeling with a class-based TF-IDF procedure. arXiv preprint\narXiv:2203.05794 (2022).\n[60] Jens J Hunhevicz, Pierre-Antoine Brasey, Marcella MM Bonanomi, Daniel M Hall, and Martin Fischer. 2022. Applica-\ntions of blockchain for the governance of integrated project delivery: A crypto commons approach. arXiv preprint\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n22\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\narXiv:2207.07002 (2022).\n[61] Johannes Rude Jensen, Victor von Wachter, and Omri Ross. 2021. How decentralized is the governance of blockchain-\nbased finance: Empirical evidence from four governance token distributions. arXiv preprint arXiv:2102.10096 (2021).\n[62] Johannes Rude Jensen, Victor von Wachter, and Omri Ross. 2021. An Introduction to Decentralized Finance (DeFi).\nComplex Syst. Informatics Model. Q. 26 (2021), 46\u201354. https://api.semanticscholar.org/CorpusID:234500185\n[63] Bo Jiang, Ye Liu, and Wing Kwong Chan. 2018. Contractfuzzer: Fuzzing smart contracts for vulnerability detection. In\nProceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. 259\u2013269.\n[64] Erya Jiang, Bo Qin, Qin Wang, Zhipeng Wang, Qianhong Wu, Jian Weng, Xinyu Li, Chenyang Wang, Yuhang Ding,\nand Yanran Zhang. 2023. Decentralized finance (DeFi): A survey. arXiv preprint arXiv:2308.05282 (2023).\n[65] Wulf A Kaal. 2020. Blockchain-Based Corporate Governance. Stan. J. Blockchain L. & Pol\u2019y 4 (2020), 3.\n[66] Aggelos Kiayias and Philip Lazos. 2022. SoK: blockchain governance. arXiv preprint arXiv:2201.07188 (2022).\n[67] Suntae Kim and Dongsun Kim. 2016. Automatic identifier inconsistency detection using code dictionary. Empirical\nSoftware Engineering 21 (2016), 565\u2013604.\n[68] Destan Kirimhan. 2023. Importance of anti-money laundering regulations among prosumers for a cybersecure\ndecentralized finance. Journal of Business Research 157 (2023), 113558. https://doi.org/10.1016/j.jbusres.2022.113558\n[69] Roman Kozhan and Ganesh Viswanath-Natraj. 2022. Fundamentals of the MakerDAO Governance Token. In 3rd\nInternational Conference on Blockchain Economics, Security and Protocols (Tokenomics 2021) (Open Access Series in\nInformatics (OASIcs), Vol. 97), Vincent Gramoli, Hanna Halaburda, and Rafael Pass (Eds.). Schloss Dagstuhl \u2013 Leibniz-\nZentrum f\u00fcr Informatik, Dagstuhl, Germany, 11:1\u201311:5. https://doi.org/10.4230/OASIcs.Tokenomics.2021.11\n[70] Gabriella Laatikainen, Mengcheng Li, and Pekka Abrahamsson. 2021. Blockchain Governance: A Dynamic View. In\nSoftware Business, Xiaofeng Wang, Antonio Martini, Anh Nguyen-Duc, and Viktoria Stray (Eds.). Springer International\nPublishing, Cham, 66\u201380.\n[71] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone,\nChristopher Akiki, Jia Li, Jenny Chim, et al. 2023.\nStarCoder: may the source be with you!\narXiv preprint\narXiv:2305.06161 (2023).\n[72] Wenkai Li, Jiuyang Bu, Xiaoqi Li, Hongli Peng, Yuanzheng Niu, and Yuqing Zhang. 2022. A survey of DeFi security:\nChallenges and opportunities. Journal of King Saud University - Computer and Information Sciences 34, 10, Part B\n(2022), 10378\u201310404. https://doi.org/10.1016/j.jksuci.2022.10.028\n[73] R. Liang, J. Chen, K. He, Y. Wu, G. Deng, R. Du, and C. Wu. 2024. PonziGuard: Detecting Ponzi Schemes on\nEthereum with Contract Runtime Behavior Graph (CRBG). In 2024 IEEE/ACM 46th International Conference on Software\nEngineering (ICSE). IEEE Computer Society, Los Alamitos, CA, USA, 755\u2013766. https://doi.ieeecomputersociety.org/\n[74] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023. Pre-Train, Prompt,\nand Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. ACM Comput. Surv. 55, 9,\nArticle 195 (jan 2023), 35 pages. https://doi.org/10.1145/3560815\n[75] Ye Liu, Yi Li, Shang-Wei Lin, and Rong Zhao. 2020. Towards Automated Verification of Smart Contract Fairness.\nIn Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the\nFoundations of Software Engineering (Virtual Event, USA) (ESEC/FSE 2020). Association for Computing Machinery,\nNew York, NY, USA, 666\u2013677. https://doi.org/10.1145/3368089.3409740\n[76] Yue Liu, Qinghua Lu, Guangsheng Yu, Hye-Young Paik, and Liming Zhu. 2022. Defining blockchain governance\nprinciples: A comprehensive framework. Information Systems 109 (2022), 102090. https://doi.org/10.1016/j.is.2022.\n102090\n[77] Yue Liu, Qinghua Lu, Liming Zhu, Hye-Young Paik, and Mark Staples. 2023. A systematic literature review on\nblockchain governance. Journal of Systems and Software 197 (2023), 111576. https://doi.org/10.1016/j.jss.2022.111576\n[78] Wei Ma, Shangqing Liu, Wenhan Wang, Qiang Hu, Ye Liu, Cen Zhang, Liming Nie, and Yang Liu. 2023. The Scope of\nChatGPT in Software Engineering: A Thorough Investigation. arXiv preprint arXiv:2305.12138 (2023).\n[79] Jonathan Mellon, Jack Bailey, Ralph Scott, James Breckwoldt, and Marta Miori. 2022. Does GPT-3 know what the\nMost Important Issue is? Using Large Language Models to Code Open-Text Social Survey Responses At Scale. Using\nLarge Language Models to Code Open-Text Social Survey Responses At Scale (December 22, 2022) (2022).\n[80] messari. 2023. Governor Note: Evolving On-Chain Governance With Element Council. https://messari.io/report/governor-\nnote-evolving-on-chain-governance-with-element-council\n[81] Eva Meyer, Isabell M Welpe, and Philipp G Sandner. 2022. Decentralized finance\u2014A systematic literature review and\nresearch directions. ECIS.\n[82] OECD. [n. d.]. Why Decentralised Finance (DeFi) Matters and the Policy Implications. https://www.oecd.org/daf/fin/\nfinancial-markets/Why-Decentralised-Finance-DeFi-Matters-and-the-Policy-Implications.pdf\n[83] Sheena Panthaplackel, Junyi Jessy Li, Milos Gligoric, and Raymond J Mooney. 2021. Deep just-in-time inconsistency\ndetection between comments and source code. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35.\n427\u2013435.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\nA Comprehensive Study of Governance Issues in Decentralized Finance Applications\n23\n[84] PeckShield. 2020. 3.2 Front-Running of Proposal Tally, SMART CONTRACT AUDIT REPORT for NODEEX HOLD-\nINGS LIMITED. https://github.com/peckshield/publications/blob/master/audit_reports/PeckShield-Audit-Report-\nOneSwap-v1.0.pdf\n[85] PeckShield. 2020.\nVoting Amplification With Sybil Attack, SMART CONTRACT AUDIT REPORT for LuckyChip\nToken.\nhttps://github.com/peckshield/publications/blob/master/audit_reports/PeckShield-Audit-Report-ERC20-\nLuckyChip-v1.0.pdf\n[86] Rowan van Pelt, Slinger Jansen, Djuri Baars, and Sietse Overbeek. 2021. Defining blockchain governance: A framework\nfor analysis and comparison. Information Systems Management 38, 1 (2021), 21\u201341.\n[87] Kai Petersen, Sairam Vakkalanka, and Ludwik Kuzniarz. 2015. Guidelines for conducting systematic mapping studies\nin software engineering: An update. Information and Software Technology 64 (2015), 1\u201318. https://doi.org/10.1016/j.\ninfsof.2015.03.007\n[88] Polygon. 2023.\nPolygon Introduces Governance 2.0 With Proposed Protocol Council For Smart Contract Up-\ngrades.\nhttps://www.bitcoininsider.org/article/230047/polygon-introduces-governance-20-proposed-protocol-\ncouncil-smart-contract-upgrades\n[89] Quantstamp. 2020. QSP-3, DerivaDEX. https://certificate.quantstamp.com/full/deriva-dex.pdf\n[90] Fazle Rabbi and Md Saeed Siddik. 2020. Detecting code comment inconsistency using siamese recurrent network. In\nProceedings of the 28th International Conference on Program Comprehension. 371\u2013375.\n[91] Pooja Rani, Arianna Blasi, Nataliia Stulova, Sebastiano Panichella, Alessandra Gorla, and Oscar Nierstrasz. 2023. A\ndecade of code comment quality assessment: A systematic literature review. Journal of Systems and Software 195\n(2023), 111515. https://doi.org/10.1016/j.jss.2022.111515\n[92] EZRA REGUERRA. 2022. CertiK identifies Arbix Finance as a rug pull, warns users to steer clear. https://cointelegraph.\ncom/news/certik-identifies-arbix-finance-as-a-rug-pull-warns-users-to-steer-clear\n[93] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In\nProceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational\nLinguistics. http://arxiv.org/abs/1908.10084\n[94] Pranav GarimidiScott Duke KominersTim Roughgarden. 2020. DAO governance attacks, and how to avoid them.\nhttps://a16zcrypto.com/posts/article/dao-governance-attacks-and-how-to-avoid-them/\n[95] Djuri Baars Rowan van Pelt, Slinger Jansen and Sietse Overbeek. 2021. Defining Blockchain Governance: A Framework\nfor Analysis and Comparison. Information Systems Management 38, 1 (2021), 21\u201341. https://doi.org/10.1080/10580530.\n2020.1720046 arXiv:https://doi.org/10.1080/10580530.2020.1720046\n[96] Carlos Santana and Laura Albareda. 2022. Blockchain and the emergence of Decentralized Autonomous Organizations\n(DAOs): An integrative model and research agenda. Technological Forecasting and Social Change 182 (2022), 121806.\nhttps://doi.org/10.1016/j.techfore.2022.121806\n[97] Bettina Schneider, Ruben Ballesteros, Pascal Moriggl, and Petra M Asprion. 2020. Decentralized Autonomous\nOrganizations\u2013Evolution, Challenges, and Opportunities. (2020).\n[98] OPENZEPPELIN SECURITY. 2022. Everyone can deploy new Comet instances, Compound III Audit.\nhttps://blog.\nopenzeppelin.com/compound-iii-audit#everyone-can-deploy-new-comet-instances\n[99] Kaushal Shah, Dhruvil Lathiya, Naimish Lukhi, Keyur Parmar, and Harshal Sanghvi. 2023. A systematic review of\ndecentralized finance protocols. International Journal of Intelligent Networks 4 (2023), 171\u2013181. https://doi.org/10.\n1016/j.ijin.2023.07.002\n[100] Trishie Sharma, Rachit Agarwal, and Sandeep Kumar Shukla. 2023. Understanding Rug Pulls: An In-Depth Behavioral\nAnalysis of Fraudulent NFT Creators. ACM Trans. Web 18, 1, Article 8 (oct 2023), 39 pages. https://doi.org/10.1145/\n3623376\n[101] Kabir Manandhar Shrestha, Katie Wood, D Goodman, and M Mistica. 2023. Do We Need Subject Matter Experts? A\nCase Study of Measuring Up GPT-4 Against Scholars in Topic Evaluation. In Proceedings of the Seventh Workshop on\nNatural Language for Artificial Intelligence (NL4AI 2023) co-located with 22th International Conference of the Italian\nAssociation for Artificial Intelligence (AI* IA 2023).\n[102] SOLIDIFIED. 2018. Audit Report for Coder Inc. https://drive.google.com/file/d/1EcY6rE5gVgfDa_XeI6_c7ud_0DLfifUT/\nview?usp=sharing\n[103] Statista. 2022. Decentralized Finance (DeFi) - statistics & facts. https://www.statista.com/topics/8444/decentralized-\nfinance-defi/#topicOverview\n[104] Xiaotong Sun, Charalampos Stasinakis, and Georigios Sermpinis. 2022. Decentralization illusion in Decentralized\nFinance: Evidence from tokenized voting in MakerDAO polls. https://api.semanticscholar.org/CorpusID:257687911\n[105] Wen Siang Tan, Markus Wagner, and Christoph Treude. 2024. Detecting outdated code element references in software\nrepository documentation. Empirical Software Engineering 29, 1 (2024), 5.\n[106] Christof Ferreira Torres, Mathis Steichen, et al. 2019. The art of the scam: Demystifying honeypots in ethereum smart\ncontracts. In 28th USENIX Security Symposium (USENIX Security 19). 1591\u20131607.\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n24\nWei Ma, Chenguang Zhu, Ye Liu, Xiaofei Xie, and Yi Li\n[107] Arianna Trozze, Toby Davies, and Bennett Kleinberg. 2023. Of degens and defrauders: Using open-source investigative\ntools to investigate decentralized finance frauds and money laundering. Forensic Science International: Digital\nInvestigation 46 (2023), 301575.\n[108] Marc Truchet. 2022.\nDecentralized Finance (DeFi): opportunities, challenges and policy implications.\nhttps://www.eurofi.net/wp-content/uploads/2022/05/eurofi_decentralized-finance-defi_opportunities-challenges-\nand-policy-implications_paris_february-2022.pdf\n[109] Uniswap V1. 2018. The Uniswap V1 Smart Contracts. https://docs.uniswap.org/contracts/v1/overview\n[110] Uniswap V2. 2020. Governance Reference. https://docs.uniswap.org/contracts/v2/reference/Governance/governance-\nreference\n[111] Fengcai Wen, Csaba Nagy, Gabriele Bavota, and Michele Lanza. 2019. A Large-Scale Empirical Study on Code-\nComment Inconsistencies. In 2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC). 53\u201364.\nhttps://doi.org/10.1109/ICPC.2019.00019\n[112] Johannes Werner, Sebastian Frost, and R\u00fcdiger Zarnekow. 2020. Towards a taxonomy for governance mechanisms of\nblockchain-based platforms. (2020).\n[113] Sam Werner, Daniel Perez, Lewis Gudgeon, Ariah Klages-Mundt, Dominik Harz, and William Knottenbelt. 2022. Sok:\nDecentralized finance (defi). In Proceedings of the 4th ACM Conference on Advances in Financial Technologies. 30\u201346.\n[114] Sam Werner, Daniel Perez, Lewis Gudgeon, Ariah Klages-Mundt, Dominik Harz, and William Knottenbelt. 2023.\nSoK: Decentralized Finance (DeFi). In Proceedings of the 4th ACM Conference on Advances in Financial Technologies\n(Cambridge, MA, USA) (AFT \u201922). Association for Computing Machinery, New York, NY, USA, 30\u201346. https://doi.org/\n10.1145/3558535.3559780\n[115] WIFPR. 2021. DeFi Beyond the Hype The Emerging World of Decentralized Finance. https://wifpr.wharton.upenn.edu/wp-\ncontent/uploads/2021/05/DeFi-Beyond-the-Hype.pdf\n[116] Jiahua Xu, Daniel Perez, Yebo Feng, and Benjamin Livshits. 2023. Auto. gov: Learning-based on-chain governance for\ndecentralized finance (defi). arXiv preprint arXiv:2302.09551 (2023).\n[117] Dirk A Zetzsche, Douglas W Arner, and Ross P Buckley. 2020. Decentralized finance (defi). Journal of Financial\nRegulation 6 (2020), 172\u2013203.\n[118] Chaoning Zhang, Chenshuang Zhang, Chenghao Li, Yu Qiao, Sheng Zheng, Sumit Kumar Dam, Mengchun Zhang,\nJung Uk Kim, Seong Tae Kim, Jinwoo Choi, et al. 2023. One small step for generative ai, one giant leap for agi: A\ncomplete survey on chatgpt in aigc era. arXiv preprint arXiv:2304.06488 (2023).\n[119] He Zhao, Dinh Phung, Viet Huynh, Yuan Jin, Lan Du, and Wray Buntine. 2021. Topic modelling meets deep neural\nnetworks: A survey. arXiv preprint arXiv:2103.00498 (2021).\n[120] Zibin Zheng, Shaoan Xie, Hong-Ning Dai, Xiangping Chen, and Huaimin Wang. 2018. Blockchain challenges and\nopportunities: A survey. International journal of web and grid services 14, 4 (2018), 352\u2013375.\n[121] Haozhe Zhou, Amin Milani Fard, and Adetokunbo Makanju. 2022. The State of Ethereum Smart Contracts Security:\nVulnerabilities, Countermeasures, and Tool Support. Journal of Cybersecurity and Privacy 2, 2 (2022), 358\u2013378.\nhttps://doi.org/10.3390/jcp2020019\n, Vol. 1, No. 1, Article . Publication date: January 2018.\n",
    "2310.19201": "arXiv:2310.19201v2  [cs.CY]  12 Jun 2024\nOpen Problems in DAOs\nJoshua Tan1,2, Tara Merk3,1, Sarah Hubbard4, Eliza R. Oak5,\nHelena Rong6, Joni Pirovich1, Ellie Rennie7,1, Rolf Hoefer8,\nMichael Zargham9,10,1, Jason Potts7, Chris Berg7, Reuben\nYoungblom11, Primavera De Filippi3,4, Seth Frey12,13,1, Je\ufb00\nStrnad10, Morshed Mannan14, Kelsie Nabben7,14, Silke Noa\nElrifai15,11, Jake Hartnell16, Benjamin Mako Hill17, Tobin South18,\nRyan L. Thomas19, Jonathan Dotan20, 11, Ariana Spring20, Alexia\nMaddox21, Woojin Lim4, Kevin Owocki22, Ari Juels23,24, and Dan\nBoneh10\n1Metagov\n2University of Oxford\n3CNRS\n4Harvard University\n5Yale University\n6Columbia University\n7RMIT University\n8Cultur3\n9BlockScience\n10WU Vienna\n11Stanford University\n12University of California, Davis\n13The Ostrom Workshop at Indiana University\n14European University Institute\n15Paris II (Panth\u00e9on-Assas)\n16DAODAO\n17University of Washington\n18MIT\n19Wentworth Institute of Technology\n20EQTY Lab\n21La Trobe University\n22Gitcoin\n23Cornell Tech\n24IC3\n1\nJune 17, 2024\nAbstract\nDecentralized autonomous organizations (DAOs) are a new, rapidly-\ngrowing class of organizations governed by smart contracts. Here we de-\nscribe how researchers can contribute to the emerging science of DAOs and\nother digitally-constituted organizations.\nFrom granular privacy primi-\ntives to mechanism designs to model laws, we identify high-impact prob-\nlems in the DAO ecosystem where existing gaps might be tackled through\na new data set or by applying tools and ideas from existing research \ufb01elds\nsuch as political science, computer science, economics, law, and organiza-\ntional science. Our recommendations encompass exciting research ques-\ntions as well as promising business opportunities. We call on the wider\nresearch community to join the global e\ufb00ort to invent the next generation\nof organizations.\nContents\n1\nIntroduction\n4\n1.1\nWho is this article written for? . . . . . . . . . . . . . . . . . . .\n4\n1.2\nCall for collaboration . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.3\nThe bigger picture . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2\nComputer science\n6\n2.1\nGranular privacy . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.2\nPrivate execution . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.3\nNew computational substrates . . . . . . . . . . . . . . . . . . . .\n10\n2.4\nSecure voting . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.5\nModeling and formal veri\ufb01cation for governance . . . . . . . . . .\n12\n2.6\nHuman-computer interaction for DAO interfaces\n. . . . . . . . .\n14\n2.7\nDAOs as social computing systems . . . . . . . . . . . . . . . . .\n15\n2.8\nMeasures of decentralization . . . . . . . . . . . . . . . . . . . . .\n16\n2.9\nDemocratic infrastructures for governing technology\n. . . . . . .\n17\n2.10 Data sets and data standards . . . . . . . . . . . . . . . . . . . .\n17\n2.11 Automated testing and automated experimentation . . . . . . . .\n18\n3\nEconomics\n20\n3.1\nInstitutional economics . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3.2\nCase studies within institutional economics\n. . . . . . . . . . . .\n23\n3.3\nCorporate governance and principal agent problems\n. . . . . . .\n24\n3.4\nDynamics and strategy . . . . . . . . . . . . . . . . . . . . . . . .\n25\n3.5\nTokenomics and platform economics\n. . . . . . . . . . . . . . . .\n26\n3.6\nLabor economics . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n3.7\nSocial choice\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n2\n4\nEthics\n31\n4.1\nCan DAOs be unethical? . . . . . . . . . . . . . . . . . . . . . . .\n32\n4.2\nAre DAOs moral agents? . . . . . . . . . . . . . . . . . . . . . . .\n33\n4.3\nRunning an ethical DAO . . . . . . . . . . . . . . . . . . . . . . .\n34\n5\nLaw\n35\n5.1\nLegal de\ufb01nition . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n5.2\nLegal liability . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n5.3\nFinancial regulation\n. . . . . . . . . . . . . . . . . . . . . . . . .\n37\n5.4\nIncorporation and legal recognition . . . . . . . . . . . . . . . . .\n38\n5.5\nDispute resolution systems . . . . . . . . . . . . . . . . . . . . . .\n39\n6\nOrganizational science\n40\n6.1\nOrganizational imprinting . . . . . . . . . . . . . . . . . . . . . .\n40\n6.2\nEvolutionary social science . . . . . . . . . . . . . . . . . . . . . .\n41\n6.3\nNeo-institutional theory . . . . . . . . . . . . . . . . . . . . . . .\n43\n6.4\nOrganizations as complex adaptive systems . . . . . . . . . . . .\n44\n6.5\nOrganizational methodology in the era of complete data . . . . .\n46\n6.6\nOrganizational ethnography . . . . . . . . . . . . . . . . . . . . .\n47\n7\nPolitical science and philosophy\n48\n7.1\nInstitutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\n7.2\nTurnout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n50\n7.3\nReal-time experimentation . . . . . . . . . . . . . . . . . . . . . .\n51\n7.4\nSelf-governance . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n51\n7.5\nGlobal governance\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n7.6\nPolitical philosophy . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n8\nMajor coordination problems\n57\n8.1\nSustaining open-source software . . . . . . . . . . . . . . . . . . .\n58\n8.1.1\nThe problem\n. . . . . . . . . . . . . . . . . . . . . . . . .\n58\n8.1.2\nCurrent progress . . . . . . . . . . . . . . . . . . . . . . .\n58\n8.1.3\nSuccess criteria . . . . . . . . . . . . . . . . . . . . . . . .\n60\n8.1.4\nRationale . . . . . . . . . . . . . . . . . . . . . . . . . . .\n62\n8.2\nDemocratic governance of arti\ufb01cial intelligence\n. . . . . . . . . .\n62\n8.2.1\nThe problem\n. . . . . . . . . . . . . . . . . . . . . . . . .\n62\n8.2.2\nCurrent progress . . . . . . . . . . . . . . . . . . . . . . .\n63\n8.2.3\nSuccess criteria . . . . . . . . . . . . . . . . . . . . . . . .\n65\n8.3\nRegenerative \ufb01nance: Toward a sustainable and equitable plane-\ntary economy . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n67\n8.3.1\nThe problem\n. . . . . . . . . . . . . . . . . . . . . . . . .\n67\n8.3.2\nCurrent progress . . . . . . . . . . . . . . . . . . . . . . .\n69\n8.3.3\nSuccess criteria . . . . . . . . . . . . . . . . . . . . . . . .\n71\n3\n1\nIntroduction\nDecentralized autonomous organizations (DAOs) \ufb01rst began to surface in dis-\ncussions of the blockchain community around 2013, where people imagined them\nas digital substitutes for traditional organizations. Technologists argued that\nDAOs could automate many organizational processes and allow for more broad-\nbased ownership and governance of the digital economy, all on the basis of a\ncryptographically-secured blockchain [54, 176]. While such DAOs existed mostly\nin the realm of speculation, with the noteworthy exception of The DAO [103],\nthe reality of DAOs has drastically changed over the past few years. Driven\nby the surge of interest in crypto, real world deployment of DAOs surged by\nas much as 660% from 2019 to late 2020 [135], rising to 1.6 million partici-\npants collectively managing 16 billion USD across over 13,000 DAOs in 2022\n[199, 151, 293].\nWhile there is no single comprehensive de\ufb01nition of DAOs, their core char-\nacteristics can be synthesized from various academic uses of the term: DAOs are\norganizations governed by a smart contract, typically deployed on a blockchain\nthat autonomously enforces rules for interaction among the members [141].\nDAOs also belong to a larger class of digitally-constituted organizations: orga-\nnizations governed through computational artifacts such as software, hardware,\nand/or protocols. For example, the Bitcoin, Ethereum, and Tor networks, even\nthough they are not DAOs, can be classi\ufb01ed as digitally-constituted organiza-\ntions.\nThis article provides an overview of the open problems and research questions\nrelevant to DAOs and related organizations, as well as a number of discrete\nresearch and engineering projects across many disciplines. We cover not only\nproblems important to DAO practitioners but also opportunities to address\nlarger research questions through the lens of DAOs.\nMany of the problems\ndescribed here will also be relevant to anyone looking at governance issues within\nonline communities.\n1.1\nWho is this article written for?\nThis article is intended to (1) establish key problems and research opportunities\nin DAOs, (2) communicate and motivate those problems and opportunities to\nresearchers not already familiar with DAOs, and (3) survey existing research\nworks and projects relevant to DAOs. We hope that our recommendations will\nprove valuable to several di\ufb00erent audiences.\nAcademics and researchers: Throughout this paper we identify many\nproblems that require conceptual and practical innovations, either within DAOs\nor within an academic discipline.\nDAO practitioners: Many of the problems identi\ufb01ed in this paper were\nsourced directly from our engagement with DAO practitioners, including work-\nshops at Stanford, Harvard, Devcon, and Devconnect. We hope that in reading\nthis paper practitioners can identify areas of research relevant to their problems\nand begin to think through the implications that existing research has for their\n4\npractice today.\nEntrepreneurs: Many of the problems and questions highlighted through-\nout this document require the development of various services, tools, and so-\nlutions in order to be solved in the long run. Consequently, we believe that\nthis paper presents an interesting starting point for entrepreneurs looking to\ncontribute to the wider DAO ecosystem.\nInvestors: Given its growth and potential, the DAO ecosystem presents an\ninteresting area for investors. We believe that highlighting some of the most\npressing problems for DAOs today can serve as a useful indicator for allocating\nimpactful investments, be it to research or to support the concrete development\nof tools and solutions in the space.\n1.2\nCall for collaboration\nWhile this article is divided into disciplinary sections, many of the problems de-\nscribed require collaboration across multiple \ufb01elds. For example, economic ques-\ntions around the potential use of DAOs by unions will require input from lawyers\nin employment law; analysis of DAOs as social computing systems should invoke\nexisting research within organizational science; a study of the cultural evolution\nof DAOs likely requires signi\ufb01cantly more development of o\ufb00-chain data sets by\nengineers; and so on. More generally, collaboration across \ufb01elds is more likely to\nproduce impactful solutions that can handle the complexities of actual DAOs.\nWe particularly encourage empirical collaborations between academics and\nbuilders in the DAO ecosystem. DAOs are not only organizations but constitute\na toolbox that one can work with\u2014an empirical advantage that we encourage\nresearchers to take advantage of. And because so much of the DAO ecosystem\nis being developed on the \ufb02y, it is often useful to work with someone aware of\ncurrent trends in the ecosystem.\nTo aid readers in \ufb01nding collaborators, data sets, and other resources, we\nhave built a website to accompany this article at www.daoscience.org.\n1.3\nThe bigger picture\nAs an organizational form, DAOs are closely related to earlier forms of online\ncommunity, especially open-source communities; many of the most successful\nDAOs are also communities organized around an open-source product.\nBut\nDAOs also have antecedents in digital cooperatives and platform cooperatives\n[253, 195], multi-organizational networks such as keiretsus [240, 171], crowdfund-\ning platforms such as Patreon, the economies of virtual worlds such as World\nof Warcraft and Second Life [180], and networked projects for peer production\nsuch as Wikipedia that question the role of the traditional \ufb01rm [31].\nAs a research subject, DAOs occupy an interesting and important intersec-\ntion between the social sciences and the computer and engineering sciences. As\nresearch subjects, DAOs are interesting because of the unique opportunities for\nintervention a\ufb00orded by smart contracts, the native availability of \ufb01ne-grained\n5\ndata, the vibrancy of the ecosystem, and a fast-moving do-ocratic culture in-\nherited from tech and open-source. Compared to related \ufb01elds such as platform\ngovernance or civic tech, DAO science is more \ufb01nancially sophisticated, more\nentrepreneurial, and less permissioned by existing institutions. Compared to\nblockchain governance (with which it substantially overlaps), DAO science is\nmore experimental and human-centered. Compared to older studies of online\ncommunities and virtual (game) worlds, DAO science requires signi\ufb01cantly more\nlegal, economic, and organizational sophistication; in DAOs, the scope of activ-\nities is broader, and the stakes higher.\nAnd compared to the many studies\nof information technology within management science, DAO science is more\nkeyed into questions of governance rather than operations: a digital organi-\nzation may operate through tools like Slack, Salesforce, or Zendesk without\nadjudicating rights and power through a digital mechanism; vice versa, a DAO\nor digitally-constituted organization may govern incentives and roles within a\nco-op or restaurant that uses very few digital technologies in its day-to-day\noperations.1\nPerhaps most importantly, the smart contracts and Ricardian contracts upon\nwhich DAOs are based are truly general-purpose instruments. That means that\nDAOs can express the full range of existing organizational forms\u2014so the choice\nis not between a corporation and a DAO per se but between a traditional,\nlegally-constituted corporation and a corporation that is digitally-constituted\nthrough a smart contract. DAOs are not just curious instances of a certain\nkind of online community; they have the expressive potential to transport a\ntremendous amount of institutional infrastructure from the stonebound halls of\npower onto the open internet; from law and economics into computer science.\nDAOs in their current form may or may not become the future of orga-\nnizations. However, it is already clear that online forms of organization are\nbecoming more and more important in the politics and economies of the world.\nDAO science is one of the most promising paths forward for tackling and making\nprogress on hard questions of organization, coordination, and governance.\n2\nComputer science\nEditor: Joshua Tan. Contributors: Joshua Tan, Michael Zargham,\nJake Hartnell, Benjamin Mako Hill, Dan Boneh, Tobin South, Ari\nJuels, Eliza R. Oak.\nComputer science historically grew out of applied mathematics, but over\nthe past few decades the \ufb01eld has also found remarkable success applying the\ntheory and practice of computation to the challenges of other disciplines such\nas physics, biology, and economics. DAOs can be understood as a facet of this\n\u201ccomputational lens\" [161, 301]: they allow us to convert many long-standing\n1This is not to say that governance and operations are not linked or correlated\u2014DAOs are\nstill most likely to be used to govern digital artifacts like smart contracts or AI, not hamburger\njoints\u2014simply that they are not necessarily so.\n6\nsocial, organizational, and legal problems into computational ones, opening up\ninteresting new challenges for computer scientists, mathematicians, and engi-\nneers.\nIn this section, we will explore a number of di\ufb00erent open problems and re-\nsearch opportunities in DAOs from the perspective of computer science, touch-\ning on subjects in cryptography and networking, which have traditionally been\nthe most salient aspects of computer science to blockchains, as well subjects\nmotivated from social computing, online governance, and human-computer in-\nteraction (HCI). Perhaps the most important cluster of research opportunities\nrevolves around building up the scienti\ufb01c foundations of research into DAOs,\nincluding better benchmarks, data sets, validation criteria, smart contract tax-\nonomies, and research-friendly DAO frameworks that, taken together, would\nenable faster experimentation, more rigorous statistics, easier formal veri\ufb01ca-\ntion, and even the training of better AI models for organizations.\n2.1\nGranular privacy\nSummary: Full transparency is often disadvantageous in strategic settings and\ncan be counterproductive in social settings when it reduces the incentives for par-\nticipation. Cryptography can help de\ufb01ne new, composable primitives for privacy\nthat allow DAOs and DAO participants to act strategically even while operating\non a public ledger.\nMost current DAOs are public and transparent by default, built on pseudony-\nmous and public blockchain protocols.\nHowever, there are various use-cases\nwhere DAOs require some form of privacy.\nFor example, ConstitutionDAO,\nwhich participated in a widely-reported auction for the U.S. Constitution, was\na\ufb00ected by the fact that their treasury size was publicly-known, marking a dis-\ntinct disadvantage for the DAO [223]. In general, revealing sensitive information\nabout a DAO or DAO participant\u2019s strategies, preferences, or \ufb01nancial positions\ncan lead to manipulation, collusion, and other negative outcomes. Further, full\ntransparency can be socially problematic for many reasons [211], e.g. exposing\nidentifying information (even wallet addresses) may deter users from participat-\ning in DAOs due to concerns about privacy, security, and liability. On the other\nhand, too much privacy can lead to co-optation by problematic actors\u2014consider\nthe use of Tornado Cash by North Korean hackers, which provoked governmen-\ntal responses and the eventual sanctioning of Tornado Cash [215]. More granular\nprivacy primitives enabled by advances in zero-knowledge (ZK) proofs, homo-\nmorphic encryption, and secure multiparty computation can solve many of these\nproblems:\n\u2022 Private donations to a public treasury allows large, crowdfunded experi-\nments like ConstitutionDAO to participate in auctions while retaining the\ntransparency of a public ledger. Properly executed, the donations would\nbe private before the auction and then become public at a later date.\n\u2022 Private voting on public proposals allows the members of DAOs to par-\nticipate in public governance without sharing public identi\ufb01ers like wallet\n7\naddresses or the vote that they cast. This is especially useful for sensi-\ntive decisions like member compensation. Several platforms have already\nbegun implementing these features, though scalability and usability ques-\ntions remain. Depending on its implementation though, private voting\nmay also destabilize the social fabric of a DAO or undermine the legiti-\nmacy of an organization\u2019s decisions.\n\u2022 Private proposals would allow DAOs to vote securely on proposals whose\ncontent is private. These may be useful for sensitive decisions like a merger\nor acquisition deal that the DAO does not want to make public.\n\u2022 Private membership allows DAOs to operate like traditional private mem-\nber organizations. This is useful for a variety of use-cases, for example in\nsensitive security situations or for blinded peer review in scienti\ufb01c research.\n\u2022 Private treasuries enable DAOs to hide the contents of their treasuries\nas well as payments to and from those treasuries. Providing for privacy\naround payments allows for a return to the norms that many businesses\nand organizations expect. For example, many traditional companies shy\naway from using DAO tooling as they do not want to allow competitors\nto see their \ufb01nances or their employees to see their compensation with\nrespect to their peers.\n\u2022 Zero-knowledge compliance allows for DAOs to prove things about them-\nselves without revealing con\ufb01dential information. For example, proving\nthat no members or payments received are on an OFAC registry or prov-\ning the amount of taxable DAO income for a DAO registered as an LLC.\nMore granular privacy primitives could be especially helpful in squaring the\ncircle between the anonymity germane to public peer-to-peer networks and the\ndisclosure requirements of governments and regulators.\n2.2\nPrivate execution\nSummary: Privacy concerns extend beyond DAO management into the realm\nof DAO execution, where the actions of the DAO itself (usually through smart-\ncontract execution) are public by default. This could be disadvantageous to some\norganizations. While some tools for private execution of operations exist, more\nwork in computer science is needed to bridge between the status quo of public\nDAO execution and the ability of organizations to selectively act discretely for\nstrategic reasons.\nBeyond the scope of integrating privacy primitives into various aspects of\nDAO management (treasuries, voting, membership), there is a broader issue\nconcerning the privacy of DAO execution.\nMost existing traditional organi-\nzations rely on the privacy of their internal operations to function e\ufb00ectively.\nBroad operational privacy is crucial for defending against corporate espionage,\n8\nprotecting the con\ufb01dentiality of individuals and communities served by the or-\nganization, enabling surprise product releases, and defending against other vul-\nnerabilities\u2014issues that have been witnessed in DAOs as they have become\nmore sophisticated [208].\nTo fully realize their potential, DAOs must o\ufb00er greater choice in execution\nprivacy while retaining their \u2018autonomous\u2019 character.\nIn general, this relies upon executing smart contracts privately, of which\nthere has been extensive work. In particular, private contract execution via new\nchains has spawned both academic work (including theoretical analysis in [163]\nand in-production public chains. These approaches draw on a wide variety of\ntechnology primitives for privacy including secure multi-party computation (e.g.,\nEnigma by Zyskind et al. [320], Eagle by Baum et al. [24], hardware enclaves\n[73, 158, 304], and zero-knowledge SNARKS (e.g., Hawk by Kosba et al. [169],\n[62], Bulletproofs by [52], zkay by [274], Zexe by [42], or via other schemes\nsuch as including UTXO-based systems [42, 292] and incentivized agreement\nof o\ufb00-chain smart contract execution (e.g. Arbitrum, [157], if all parties are\nhonest). Other approaches using permissioned blockchains to add privacy to\nsmart contract execution [21, 46].\nMany of these systems operate via a fully private on-chain environment,\nespecially those with the strongest privacy guarantees, and necessitate a shift\nin DAO operations onto a secure chain. Some approaches piggyback and in-\nteroperate with existing popular chains, however these privacy solutions are\nincomplete. For example, zkay and Zether go some way towards addressing this\ninteroperability challenge with Ethereum, but their privacy guarantees are lim-\nited to payments (Zether) or speci\ufb01c private values (zkay). At the very least,\nmost interoperable solutions with public chains always leak activity metadata\non what contracts are executing.\nHybrid models, which exchange metadata been private and public execution\nat a minimum, are possible but need to be integrated with existing DAO tooling\nand undergo more battle testing and security analysis.\nWhile these technical goals are worth striving for, it exists in tension with\nthe principles of openness set forward by the DAO community.\nThe public\nnature of DAO execution drives transparency and accountability, a key feature\nin building competitive advantages based on trust, and considered to many a\ncore ethical advantage. Further, the existence of privately executing DAOs can\nlead to malicious phenomena such as Dark DAOs [90] where a decentralized\ncartel buys on-chain votes opaquely. Are the bene\ufb01ts of normalizing private\nDAO usage worth the risks of coordinated large-scale bribery?\nWhile the use of privacy over transparency is not always an ethical cost (such\nas if privacy enables the protection of vulnerable people), the tension between\nthe existing bias of the traditional business world toward public secrecy and the\nvalues of open communities should be examined further, perhaps facilitating the\nbuilding new models of hybrid transparency enabled through DAOs.\nBy combining inherently private o\ufb04ine activities with secure DAO opera-\ntions, the future of DAOs could o\ufb00er valuable granular privacy choices. This\nwould enable a variety of strategic options that would be unfeasible or disadvan-\n9\ntageous in a fully public setting. Ongoing development, testing, and deployment\nof these tools are necessary as the DAO ecosystem continues to grow.\n2.3\nNew computational substrates\nSummary: DAOs and digitally-constituted organizations are built on top of com-\nputational substrates such as blockchains. Computer networking, cryptography,\nand distributed computing can help improve the properties of these substrates,\nhelp them interoperate with each other, and even de\ufb01ne entirely new substrates.\nComputer science is the material science of digital space. Just as new materi-\nals allow us to build taller buildings and longer bridges, new computational prim-\nitives allow us to build more accessible spaces, more scalable platforms, and more\ne\ufb00ective digital organizations. For example, scaling challenges in blockchains\nhave led to new technological developments such as optimistic rollups and zero-\nknowledge rollups that enable blockchains to securely delegate computation to\no\ufb00-chain substrates, typically a \u201clayer 2\" blockchain. This idea of delegating\ncomputation across di\ufb00erent computational substrates highlights several open\nresearch questions for DAOs:\n1. How do we build secure and e\ufb00ective multichain DAOs? Substantial work\non cross-chain communication protocols [172, 305], cryptographically-secure\nbridges [29, 308], and atomic swaps [201] highlights the way in which there\nis a growing universe of \u201cledgers of record\". DAOs increasingly operate\nand manage assets across multiple chains, and they need a secure way of\nowning and governing themselves across multiple chains.\n2. How do we build secure and e\ufb00ective multi-substrate DAOs, i.e. DAOs\nwhose organizational logic is executed across multiple di\ufb00erent compu-\ntational substrates, e.g.\nwithin two blockchains with substantially dif-\nferent properties, within a blockchain and a distributed network such as\nHolochain [138]?\n3. How do we securely and e\ufb03ciently interoperate between DAOs and the rest\nof the internet? While DAOs are commonly associated with the smart con-\ntract infrastructure of certain blockchains,2 many DAOs already delegate\nsubstantial parts of their organizational logic and compute to traditional,\no\ufb00-chain services such as Discord and Discourse as well as decentralized\nstorage services such as IPFS. Substantial research and development has\nbeen done on o\ufb00-chain oracles [5] as well as various ways of presenting\nblock transactions through subgraphs, but many open questions remain\nabout the architecture (client-server, peer-to-peer, n-tier, etc.) and gov-\nernance of these o\ufb00-chain services\u2014which relates to the design of general\ninternet services and applications.\n2The \u201cdecentralized\" and \u201cautonomous\" in \u201cDAO\" are typically predicated on the guaran-\ntees of cryptographic consensus within a widely-distributed peer-to-peer network.\n10\n4. What kind of computational substrate is su\ufb03cient for DAOs? For ex-\nample, is it possible to build minimally-viable DAOs on other sorts of\npeer-to-peer networks beyond the blockchain, or within the internet pro-\ntocol stack itself? Such a project seems possible: after all, the \ufb01rst usage\nof the term \u201cDAO\" was part of a proposal for a wireless home network\n[141].\n5. What kind of computational substrate is optimal for DAOs? If a blockchain\nwith a smart contract architecture is optimal, what kind of blockchain and\nwhat kind of architecture best supports the use-cases of DAOs?\nIn general, any research that increases the speed, reduces the cost of on-\nchain storage and compute, or makes smart contract architectures more robust\nto attack will expand the practical design space of DAOs.\n2.4\nSecure voting\nSummary: Many forms of DAO governance depend on secure and trustworthy\nvoting mechanisms. New research in computer science, especially cryptography,\ncan help DAOs implement voting mechanisms that is more secure along sev-\neral di\ufb00erent dimensions, including integrity, public veri\ufb01ability, privacy, and\ncoercion-resistance.\nThe process of voting on proposals is central to the governance of DAOs.\nVoting raises many design decisions, such as how to allocate voting power and\nhow voting choices should translate into outcomes. These decisions relate to\nquestions of social choice and tokenomics discussed in this paper. Once a DAO\nchooses to adopt a desired mechanism for voting, the question arises of how to\nimplement it, and in particular how to do so securely.\nDAO voting di\ufb00ers from conventional voting in political elections in several\nkey ways. First, it is entirely digital. Users do not need to visit polling stations\nor interact physically with ballots. Second, it is typically pseudonymous: Voters\nidentify themselves by on-chain addresses, rather than real-world identities, as\nin conventional elections.\nFinally, while most political elections permit only\none vote per eligible voter, DAO voting often weights votes according to token\nholdings. DAO voting bears some similarity in this sense to corporate proxy\nvoting.\nThere is a well-established literature on what is often called veri\ufb01able voting\n(see, e.g., [30, 72, 247]). While this literature is often concerned with conven-\ntional voting, it nonetheless outlines a number of cryptographic concepts and\ntools relevant to DAO voting. Especially important is an articulation of the de-\nsirable security properties for voting systems. These properties vary somewhat\nacross the literature. Informally, though, they typically include:\n\u2022 Integrity: Each voter should be able to cast only a single ballot and the\nchoice(s) made by a voter on that ballot should be re\ufb02ected correctly in\nthe outcome of a vote.\n11\n\u2022 Public veri\ufb01ability: Anyone should be able to verify (cryptographically)\nthe integrity of a vote.\n\u2022 Privacy: No entity, including those tasked with tallying election results,\nshould learn anything about an election other than the outcome. (Privacy\nin this sense is a special case of private execution, discussed above.)\n\u2022 Coercion-resistance: Voters should be unable to prove to anyone how they\nvoted. As a result, coercion\u2014which encompasses voter bribery, i.e., vote-\nbuying, as well as voter intimidation\u2014should be infeasible [79, 156].\nToday, the main focus of DAO voting systems has been on integrity\u2014the\nonly one of these properties that is truly indispensable for trustworthy gover-\nnance\u2014and to some extent on public veri\ufb01ability. Privacy has been a growing\nconcern, however. For instance, Snapshot, the most popular voting system for\nDAOs, recently incorporated support for ballot privacy\u2014although it lasts only\nfor the duration of the ballot-casting period [173]. The properties of privacy and\nintegrity are in fact in fundamental tension. For example, one way to achieve\npublic veri\ufb01ability is to publish all ballots and their tally on chain, but this ap-\nproach would undermine ballot privacy. Simultaneously achieving integrity and\nprivacy is one of the main focuses of the veri\ufb01able-voting literature. Translat-\ning results from that literature to the setting of DAOs is an open problem\u2014as\nis, more generally, a practical realization of the full set of four voting security\nproperties.\nCoercion-resistance is an especially tricky property to enforce. Recognizing\nthe risk it poses in blockchain systems to DAOs and even to staking systems, re-\nsearchers have considered a range of various countermeasures, such as Buterin\u2019s\nMinimum Anti-Collusion Infrastructure (MACI) [55].\nUnfortunately, blockchains aren\u2019t just an attractive platform for implement-\ning voting schemes, but also for attacking them through orchestrated coercion\nor vote-buying.\nThis is the idea behind what is called a Dark DAO [90], a\ndecentralized vote-buying system that uses a secure enclave to conceal the iden-\ntities of its participants. While not yet deployed in the wild, Dark DAOs are\nnonetheless a practical threat, realizable today using enclave-based blockchains\nsuch as Oasis and capable of attacking DAOs on other chains such as Ethereum\n[16]. Dark DAOs break MACI and other vote-buying prevention schemes.\nE\ufb00ective countermeasures to Dark DAOs\u2014and, in general, practical ways\nof achieving coercion-resistance in DAO voting\u2014are a critical open subproblem\nwithin the larger challenge of realizing secure voting systems for DAOs [162].\n2.5\nModeling and formal veri\ufb01cation for governance\nSummary: There are many modes of failure within DAOs and many ways in\nwhich they might achieve undesirable outcomes. It is hard\u2014but not impossible,\ngiven the computational nature of DAOs\u2014to de\ufb01ne conditions that provably or\nstatistically constrain such failures. Computer science can help de\ufb01ne conditions\n12\nand build mathematical models for DAOs that produce formal and statistical\nguarantees about DAOs\u2019 behavior.\nExisting research within social choice theory and computational social choice\ngives conditions and limitations on the performance of voting and preference ag-\ngregation systems, most famously Arrow\u2019s impossibility theorem. While results\nfrom social choice and its variants are certainly relevant to DAOs, the organi-\nzational logic embedded within a DAO usually extends far beyond the exact\nvoting mechanism. This broadness makes them susceptible to a wide range of\nother attacks, exploits, and failures beyond those salient in social choice (e.g.\n51% attacks, sybil attacks, free-riding on governance, lack of engagement), but\nit also sits them downstream of a number of potential improvements.\nFormal veri\ufb01cation involves the use of mathematical methods to prove the\ncorrectness of the implementations of algorithms. Since the hack of The DAO,\nsubstantial work has been done to verify the functional correctness and security\nof smart contracts using formal methods [36, 206], complementing a strong\ntradition of industry-driven security audits for smart contracts.\nThere are existing e\ufb00orts in game theory and computer science to build\ncomputer-aided design (CAD) tools for governance [118, 126], i.e. a modeling\nlanguage that captures the basic primitives and incentives necessary to design\nand analyze governance systems. These languages already have applications to\ncontract theory (the economic analysis of legal contracts) and to smart contracts,\nand could be directly extended to the smart contracts that constitute DAOs.\nWhile agent-based models do not typically produce formal guarantees, they\nare often quite valuable for exploring and drawing insights into a complex sys-\ntem [2].\nAgent-based models can provide a useful framework for simulating\nand understanding the dynamics of DAOs, allowing researchers to test various\ncon\ufb01gurations and observe their impact on system behavior [296].\nReachability analysis, a concept borrowed from robotics [9, 312], can be ap-\nplied to DAOs to determine the feasibility of achieving certain states through\nunknown sequences of actions. This approach involves de\ufb01ning a \"governance\nsurface\" analogous to a control surface, which can be used to identify possible\noutcomes and transitions within the DAO\u2019s governance process. By understand-\ning the reachability of di\ufb00erent states, we can better evaluate the robustness and\nadaptability of a DAO\u2019s governance structure [310].\nAdditionally, computer-aided design methodologies, particularly model-based\nsystems engineering (MBSE) for complex systems [101], can provide valuable\ninsights into the design and management of DAOs. MBSE focuses on creating,\nanalyzing, and managing complex systems using models, which can help in ad-\ndressing the unique challenges posed by DAOs. In the context of DAOs, it is\ncrucial to distinguish between veri\ufb01cation and validation, as they determine the\ne\ufb00ectiveness of a software system deployed to administrate a governance process\nwithin the DAO. Veri\ufb01cation ensures that the system meets its speci\ufb01cations,\nwhile validation ensures that it ful\ufb01lls its intended purpose in the real-world\ncontext [68].\nThe extent to which a particular set of governance algorithms\nentrenched as smart contract logic is suitable for the context in which they\ndeployed is a question of validation, rather than veri\ufb01cation [193].\n13\nIn conclusion, the interdisciplinary nature of DAOs opens up opportunities\nfor integrating various computer science concepts and methodologies to ana-\nlyze and improve their governance structures. By leveraging formal veri\ufb01cation,\nreachability analysis, agent-based models, and computer-aided design method-\nologies, we can build a more robust understanding of DAOs and develop more\nsecure, e\ufb03cient, and resilient governance systems.\n2.6\nHuman-computer interaction for DAO interfaces\nSummary: DAOs have a usability problem. Human-computer interaction can\nhelp design better interfaces and systems through which members and stakehold-\ners organize their decentralized communities.\nHuman-computer interaction (HCI) is a sub\ufb01eld of computer science that\nfocuses on the design, implementation, and evaluation of interactive computing\nsystems.\nIn particular, HCI tends to focus on the interfaces and processes\nthrough which humans interact with computers and digital systems, as opposed\nto the internal workings of those systems. Many innovative features of online\nplatforms are \ufb01rst incubated as research projects within the \ufb01eld of HCI [99],\ne.g. within content moderation [111]. While HCI researchers have contemplated\nand sometimes approached the design questions of blockchain applications [105],\nthey have rarely worked on topics speci\ufb01c to DAOs. There are a number of\ndimensions within which HCI can contribute to DAOs:\n\u2022 Promoting usability. Right now, the learning curve to enter a DAO is ex-\ntremely steep, ruling out use by users with more diverse backgrounds and\nabilities. Further, the rigid, irreversible nature of smart contracts makes\nmany interactions prohibitively risky for users without a signi\ufb01cant \ufb01nan-\ncial cushion. HCI can inform the design of inclusive systems that cater\nto varying levels of expertise, language, and accessibility needs, ensuring\nthat DAOs are available to a wider audience.\n\u2022 Bring rigorous methodology into the design process for DAOs. There is a\nneed for more consistent design methodology in this space. For example,\nwhile many projects have built dashboards and visualizations for DAOs, a\nrigorous, HCI-driven evaluation process can help iterate and re\ufb01ne these\nsystems.\n\u2022 Testing speci\ufb01c design interventions.\nA key component of DAOs is to\nengage participants in governance. While the industry has so far been\ndrawn to cryptoeconomic systems that incentivize participation such as\nPaladin, design interventions that focus on better interfaces for eliciting\nand aggregating preferences may be less costly and more e\ufb00ective. HCI is\nparticularly well-suited for evaluating the cognitive and social factors that\nin\ufb02uence group decision-making in DAOs.\n\u2022 Exploring bots and technical interventions within DAOs.\nMany DAOs\nmake use of bots and automated tools within their communication plat-\nforms. These bots facilitate not only blockchain-enabled features such as\n14\ntoken-gating but also various forms of governance decision-making. Vari-\nous studies could explore this dynamic, for example calculating a DAO\u2019s\n\u201csense of virtual community\" [165] and then measuring how bots a\ufb00ect\nthat metric.\n2.7\nDAOs as social computing systems\nSummary: DAOs, as novel forms of digital organization, are germane to many\ncore questions in social computing, an interdisciplinary sub\ufb01eld of computer sci-\nence. Social computing can help provide a design framework for DAOs and con-\ntextualize them within a wide range of digital institutions including open-source\nsoftware, reputation systems, online auctions, and crowdfunding platforms.\nSocial computing is a sub\ufb01eld of computer science that studies the interplay\nbetween people, technology, and society.\nAs a highly interdisciplinary \ufb01eld,\nmany research questions motivated by social computing overlap with those mo-\ntivated from political science, sociology, and economics\u2014e.g. how do we un-\nderstand, model, and visualize the behavior of DAOs, what is novel and not\nnovel about them, how does this particular digital infrastructure change the\nway that people behave? Unlike social science, social computing research tends\nto center computing technology as the primary object of study. Although social\ncomputing is closely related to HCI, it seeks to understand or design comput-\ning systems for social groups and social behavior while HCI research typically\nfocuses on individual users. In this sense, DAOs are classic examples of social\ncomputing systems.\nDespite clear a\ufb03nities, there has been relatively little work in social comput-\ning on DAOs. DAOs have been discussed as promising sites for future research\nin social computing work on governance [119] and some early work has treated\nDAOs as objects of study [13, 189]. Social computing can potentially o\ufb00er a\nunique and important perspective on DAOs, one that situates DAOs within the\nlarger context of socio-technical systems and emphasizes the role of technology\nin shaping social processes. Social computing is also often more experimental\nand interventionist than traditional social science, which matches well with the\nopen and permissionless character of DAOs. Some potential research questions\ninclude:\n\u2022 How do speci\ufb01c technological design choices in the context or a\ufb00ordances\nshape social behavior or social interaction within a DAO? How will speci\ufb01c\ntechnological choices made by the creators of DAOs allow, encourage,\ndiscourage, or foreclose certain types of behaviors and outcomes?\n\u2022 How does social structure (e.g., roles, power structure, norms, expecta-\ntions about technology, and so on) shape the way that a particular tech-\nnology is understood or used? For example, how might technically-similar\nsmart contracts ground di\ufb00erent communities in very di\ufb00erent ways?\n\u2022 How can we design DAO technology to support certain types of social\nbehaviors or outcomes and to prevent others?\n15\n2.8\nMeasures of decentralization\nSummary: Research on standardized metrics and de\ufb01nitions of decentralization\nis ongoing, with approaches ranging from entropy-based indices, SoKs, or em-\npirical analyses of voting concentration. Broader questions about the current\nstate, value, and structures of decentralized systems continue to be explored.\nResearch on how to measure DAO decentralization is still emerging, but\nvarious works have explored this topic. [115] examine the Gini and Nakamoto\nindices, participation rates, and the monetary aspects of governance.\n[263]\ndelve into di\ufb00erent entropy concepts and introduce graph-centric decentraliza-\ntion measures. Wright presents a classi\ufb01cation system comparing DAOs with\nother autonomous entities [307]. [281] analyze voting blocs in MakerDAO, us-\ning clustering to identify them. Additionally, [16] introduce a new, DAO-speci\ufb01c\nmetric called voting-bloc entropy (VBE), merging traditional entropy measures\nwith voting-bloc identi\ufb01cation. Another noteworthy concept is \"credible neu-\ntrality,\" a community benchmark mentioned in sources like [56, 59].\nMoreover, various systematizations of knowledge (SoKs) have sought to as-\nsess the landscape as well as propose new measures. [314] note the need for the\nblockchain community to converge on a standardized de\ufb01nition or metric for de-\ncentralization. In their SoK, they \ufb01rst create a taxonomy based on consensus,\nnetwork, governance, wealth, and transactions. Building on this taxonomy, they\napply Shannon entropy to propose a decentralization index for blockchain trans-\nactions which they then apply empirically in the context of DeFi token transfers\nto document that DEXs and DeFi lending protocols appear slightly more de-\ncentralized than payment and derivative apps. They also \ufb01nd that EIP-1559\n[60], which modi\ufb01ed Ethereum\u2019s transaction fees, increases decentralization.\n[160] also present an SoK on the topic of blockchain decentralization, this\ntime taking a strati\ufb01ed approach by \ufb01rst dissecting blockchain systems into\nmultiple strata (hardware; software; network; consensus; economics; API; gov-\nernance; and geography). They also introduce the \u201cMinimum Decentralization\nTest\u201d as an approach to assessing decentralization.\nFinally, another approach to measuring decentralization might focus specif-\nically on governance participation, which [198] do by examining decentralized\nvoting to amend DeFi smart contracts. Focusing on decentralized lending pro-\ntocol Compound, they \ufb01nd a striking concentration of power, with ten voters\nholding nearly 60% of voting power.\nIn addition to these e\ufb00orts to develop a systematic measure of decentral-\nization, de\ufb01ning decentralization touches on other fruitful research questions,\nincluding:\n\u2022 What is the current landscape of decentralization?\n\u2022 Why/ when is decentralization valuable?\n\u2022 To what extent do the unique aspects of web3/ decentralization help or\nhurt with the challenges of online interactions?\n16\n\u2022 How do we incorporate the role of foundations and other groups of actors\ninto our measure of decentralization?\nOne possible angle for mapping the motivations for decentralization could\ndi\ufb00erentiate between the economic; regulatory; technical engineering; and ideo-\nlogical motivations.\n2.9\nDemocratic infrastructures for governing technology\nSummary: DAOs are practical examples of an approach to governing technology\nthat foregrounds the role of technology and local communities instead of tradi-\ntional modalities of regulation. Computer science can help us understand and\nimprove these approaches to the governance of technology.\nThe governance of technology and algorithms is more often approached\nthrough an institutional or legal lens than a computational one.\nStudies of\npast examples tend to foreground regulatory mechanisms such as the law and\ninstitutions; for example, research on the governance of internet protocols tends\nto focus on technical standards bodies such as the IETF or elite forums such as\nthe IGF, assuming that control over the internet protocol was out of the reach\nof ordinary users [97]. More recent work has highlighted ways to involve ordi-\nnary users in the design and governance of digital technologies such as machine\nlearning algorithms [270], but these e\ufb00orts have not scaled to more widespread\nuse. DAOs are on the forefront of these more community-oriented approaches\nto the governance of technology. However, DAOs are also quite limited insofar\nas the technologies they govern are usually protocols and contracts deployed on\na blockchain. How can DAOs or related social technologies govern technologies\nsuch as websites and domain names, server infrastructure, telecommunications\nprotocols, and even pre-trained AI models\u2014none of which are not implemented\nin a Web3 context?\nPerhaps sensitive algorithms in content moderation or\npolicing could be content-addressed, creating the means through which a\ufb00ected\nparties could participate in algorithmic oversight.\n2.10\nData sets and data standards\nSummary: DAOs, despite their public nature, are still di\ufb03cult to study due to\nlack of standardization, reliance on o\ufb00-chain services and APIs, and other chal-\nlenges with data indexing and integration. Computer science can help de\ufb01ne\ndata sets, schemas, and taxonomies that would enable easier data collection,\nfaster experimentation, more consistent statistical tests, easier formal veri\ufb01ca-\ntion, and even the training of better AI models.\nDAOs are nominally fully public and transparent, but there are many ques-\ntions that researchers might like to ask which cannot be readily answered given\nthe current data infrastructure of DAOs. For example:\n\u2022 How many DAOs exist on a given blockchain at any moment?\n\u2022 Who are the actual members of a DAO?\n17\n\u2022 What is the contract space of a DAO, i.e. all the on-chain contracts and\nmultisigs controlled by or associated with a DAO?\n\u2022 What is the level of engagement of members over time?\n\u2022 What is the legal status of a DAO, if any?\n\u2022 What is the organizational structure of a DAO, e.g. in terms of subDAOs?\n\u2022 What is the spread of di\ufb00erent voting schemes across all DAOs?\n\u2022 What kinds of activities does a DAO engage in?\n\u2022 What rights are a\ufb00orded to the members of a DAO? Which rights are\ncode- versus rule-enforced?\nAgain, the issue in these cases is not that the information is private and must\nbe negotiated for (as with typical Web2 platforms) or that the precise de\ufb01nition\nof a metric is being contested (e.g. of decentralization). Most data relevant\nto DAOs is publicly-accessible, but interpreting, integrating, and organizing\nthat data is hard. Some of these issues arise from lack of on- and o\ufb00-chain\nstandardization across DAOs and DAO frameworks, which is being addressed\nby nascent e\ufb00orts in the ecosystem to develop standard schemas and taxonomies\n[91, 285]. Others arise because engaging with a DAO involves interacting with\nmany o\ufb00-chain platforms, and these platforms either do not report data or do\nnot integrate with early standards e\ufb00orts. And while some data sets have been\nbuilt for DAO smart contracts [167], DAO constitutions [284], and political\nsentiment [168], other data sets simply still need to be built.\nDespite the present lack of data infrastructure, DAOs present a unique op-\nportunity to build \u201clive\" data sets, whether through public subgraphs and other\nautomated mechanisms, through technical standards implemented by DAO frame-\nworks and other service providers, or through institutional designs that incen-\ntivize reporting on a DAO-to-DAO basis. Having access to such live data is\nnot only a boon to scienti\ufb01c analysis; it is also an important basis for providing\nreal-time feedback to DAOs, drastically reducing the timeline for research to\nimpact the real world. DAOs themselves could substantially bene\ufb01t from access\nto such data, whether for operational, reporting, or governance purposes.\n2.11\nAutomated testing and automated experimentation\nSummary: DAOs do not have a rigorous testing framework or any infrastructure\nfor experimentation such as which exists in psychology, medicine, or AI. Com-\nputer science can help supply the protocols and libraries for automated testing\nand automated experimentation.\nWhile most experimentation with DAOs currently takes place outside of aca-\ndemic settings, various quality-of-life improvements to tooling and infrastruc-\nture could make it much easier for researchers (and ordinary users) to develop,\ndeploy, and test DAOs.\n18\nAutomated testing of DAOs could be especially helpful. While there ex-\nist platforms for smart contract testing such as Tenderly, none are currently\nspecialized to DAOs. Automated tests or benchmarks could be constructed to\nquery a given DAO\u2019s:\n\u2022 susceptibility to the loss or inattention of key participants or administra-\ntors [224],\n\u2022 resilience to 51% attacks,\n\u2022 speed and responsiveness to crises,\n\u2022 ability to handle disagreements,\n\u2022 susceptibility to forking,\n\u2022 and likely responses to various adverse \ufb01nancial or technical events.\nSuch tests and benchmarks follow a rich tradition of testing and quality\nassurance within software engineering and could be used to validate a DAO\u2019s\n\ufb01tness for purpose. Further tests could be devised that could be structured as\nchallenges or games that a living DAO could run through, akin to \ufb01re drills,\nwar games, and other tests of capacity.\nAnother approach to automated experimentation involves working directly\nwith the many already-extant DAO frameworks. A governance framework for\nDAOs, or just DAO framework, is a smart contract template or set of such\ntemplates that can be used to deploy a DAO on a blockchain, typically with\nan associated management interface.\nMany of these frameworks are moving\ntoward specialized use-cases, e.g. Safe\u2019s focus on multisig management com-\npared to Aragon\u2019s focus on permissions infrastructure. A modular, open-ended\nplugin or library that can abstract over these DAO frameworks and connect\nthem to rigorous testing tools\u2014comparable to how libraries like scikit-learn or\nTensorFlow drastically reduce the hassle of building and testing new learning\nalgorithms in AI\u2014could be extremely useful.\nUltimately, the elements above could be synthesized into an experimen-\ntal platform for DAOs and DAO frameworks. For example, software such as\nDallinger [279], Pushkin [139], and Experiment Factory [271] automate sig-\nni\ufb01cant parts of the process for producing classes of psychology experiments\nvia automated statistical design, a domain-speci\ufb01c language for experimental\nsetup, and simple Mechanical Turk and TaskRabbit integrations.\nThey al-\nlow a researcher to build and run a psychology experiment in a matter of\nhours\u2014something that would have taken them months to plan and run pre-\nviously\u2014and to run \u201cmassive\" versions of traditional experiments that were\npreviously impossible. A similar platform for testing governance experiments,\nincluding distinct modules for voting, reputation, and privacy as well as in-\ntegrations for on-chain deployment and data tracking, could vastly accelerate\nexperimentation as well as data collection and synthesis.\n19\n3\nEconomics\nEditors: Jason Potts, Chris Berg, Sarah Hubbard. Contributors:\nJe\ufb00Strnad, Sarah Hubbard, Jason Potts, Chris Berg, Divya Sid-\ndarth, Sarah Horowitz, Michael Zargham.\nEconomists who have sought to study blockchains have developed a num-\nber of distinct approaches. These include: (1) cryptoeconomics (game theory\nand mechanism design applied to incentive problems in protocol design, also\nknown as tokenomics); (2) microeconomics, including \ufb01nance, industrial orga-\nnization, and public goods, typically using some formulation of Chicago price\ntheory, Berkeley competition theory, and Harvard/MIT welfare economics (e.g.\nAbadi and Brunnermeier 2018 [1], Cong and He 2019 [84], Buterin et al 2019\n[61], Catilini and Gans 2020 [67]), and (3) institutional cryptoeconomics, which\ndraws on new institutional economics, public choice theory and Austrian eco-\nnomics (e.g. Davidson et al 2018 [92], Berg et al 2019 [33]. There is also a\ndistinct school of crypto monetary economics (e.g. George Selgin [260], Larry\nWhite [300], William Luther, et al [190]). There is overlap between these mostly\ncomplementary approaches, and it is useful to understand these as examining\nbroadly di\ufb00erent parts of the crypto-economy at di\ufb00erent levels of focus and\nwith somewhat di\ufb00erent tools. Nevertheless, the common core is analysis of\nthe crypto-economy through the lens of rational behavior subject to incentives,\nwhich are designed mechanisms in which blockchain technologies (including\nsmart contracts) are new technologies that lower speci\ufb01c costs. The purpose of\nanalysis is to trace these changes in costs, through changes in markets, through\nto new equilibrium outcomes.\nThe economic approach to DAOs is a new \ufb01eld that sits within the standard\neconomic approach to the theory of the \ufb01rm as developed by leading economists\nsuch as Ronald Coase, Oliver Williamson, Armen Alchian and Harold Dem-\nsetz, Jensen and Meckling, and Oliver Hart. In 1939, Ronald Coase asked \u2018why\ndo \ufb01rms exist?\" and then answered that they were an organizational technol-\nogy that economized on the transaction costs of using the market [80]. This\n\u2018transaction cost\u2019 perspective is the foundation of New Institutional Economics.\nWilliam and Hart developed this approach further by examining issues of trust\nand opportunism, and the economic logic of contracting. Jensen and Meckling\ndeveloped a theory of the \ufb01rm as a \u2018nexus of contracts\u2019 and Alchian and Dem-\nsetz developed a model of a \ufb01rm as a \u2018private market\u2019. These approaches sought\nto understand the existence of \ufb01rms, as well as their comparative advantages\nas technologies for coordinating people and capital, through the lens of e\ufb03cient\ncontracting over situations that involved missing information and uncertainty\n(i.e. asymmetric information, hazards of opportunism and problems of trust).\nA small but growing literature seeks to develop economic analyses of DAOs.\nLumineau et al. [188] and Santana and Albareda [249] o\ufb00er useful recent sur-\nveys. This literature largely overlaps with the theory of the \ufb01rm and therefore\nincludes topics such as: agency, contracting, entrepreneurship, investment under\nuncertainty, team production, asset speci\ufb01city, boundaries of the \ufb01rm, and cor-\n20\nporate governance. However, the economics of DAOs also sits within a broader\nliterature on voluntary or private organizations, integrating the economic the-\nory of clubs and the economic theory of commons [244]. Clubs and commons\ntheory is also focused on governance and collective decision-making, as well as\nthe creation and use of common pool resources or local public goods.\n3.1\nInstitutional economics\nSummary: Part of the rationale for DAOs is that they are a technology, much\nlike \ufb01rms, for minimizing transaction costs and \u2018costs of trust\u2019. Institutional\neconomics can help explain present DAO structures and suggest new designs for\nDAOs based on a rigorous analysis of the DAO\u2019s cost functions.\nWhy do DAOs exist? This is the same question that Ronald Coase asked in\n1939 that established the concept of transaction cost and the \ufb01eld of New In-\nstitutional Economics as a comparative analysis of institutions. Coase\u2019s answer\nwas that \ufb01rms exist to minimize the \u2018transaction cost\u2019 of using a market. These\ntransaction costs are the costs of searching for counterparties, writing contracts,\nmonitoring actions, haggling and bargaining and so on. They include search and\ninformation costs, agency and monitoring costs, contracting and decision costs;\nto a considerable extent they are \u2018costs of trust\u2019 that would not exist in a world\nof perfect costless information with total transparency in a world of counter-\nparties who only ever told the truth and always did what they promised. Such\na world would lack uncertainty and opportunism. Firms are a technology for\norganizing people and resources into coordinated actions. Firms exist when it\nis cheaper to use that technology than an alternative institutional technology,\nnamely the market. Firms exist because they economize on the costs of using\nthe market. The particular boundaries of \ufb01rms (e.g. vertically integrated, mul-\ntidivisional, cooperative, etc) are competitive consequences of those cost-speci\ufb01c\ncost advantages over a range of margins. The same logic applies to the economic\nanalysis of DAOs.\nA DAO is an organization made in part using a new technology: smart con-\ntracts. These give DAOs di\ufb00erent competitive advantages in relation to trans-\nparency, monitoring and auditing, as well assurance and expectation. As such,\nDAOs have di\ufb00erent cost functions with respect to a range of key operational\nand competitive functions within economic coordination, e.g. some have argued\nthat DAOs exist to economize on the costs of trust compared to \ufb01rms and mar-\nkets [33]. Note that not all costs are signi\ufb01cantly lower. On some dimensions\nsuch as regulatory uncertainty and integration with legal and other external\nsystems, DAOs are often more costly than traditional industrial corporations.\nIn other words, DAOs are institutional competitors to other forms of economic\norganization (also including clubs, coops, trusts, governments, as well as \ufb01rms\nand markets).\nThe problem, then, is to develop a general economic theory of DAOs that\n(1) explains their existence in terms of speci\ufb01c costs and the way in which those\ncosts are internalized, (2) grounds those costs in the logic and design of (smart)\ncontracts and other resources within the DAO, and (3) links those resources to\n21\na theory of DAO strategy (see \u201cDynamics and strategy\", below). Within this\ngeneral framing, we can then organize a range of open questions:\n\u2022 Structure of a DAO. Analogous to the theory of the organizational\nstructure of a \ufb01rm (pioneered by Alfred Chandler [71], and the U-form and\nM-form corporation), what is the governing economic logic determining\nthe structure of DAOs and subDAOs?\n\u2022 Information economics of DAO coordination. The economic e\ufb03-\nciency of \ufb01rms and markets (and governments) is in part based on their\ncomparative e\ufb03ciency in di\ufb00erent types of information processing, e.g.\nin price signals in markets or entrepreneurial coordination (in the work\nof F.A. Hayek [143], Mark Casson [66, 65], Israel Kirzner [164], George\nStigler. An open question is to empirically and theoretically analyze the\neconomic mechanisms and economic e\ufb03ciency of information \ufb02ow and pro-\ncessing in a DAO, including through new data sets not present in a typical\n\ufb01rm.\n\u2022 Entrepreneurship versus management. Firms are both e\ufb00ective or-\nganizational mechanisms for starting and building new projects and engag-\ning in entrepreneurship (e.g. entrepreneurial capitalism, viz. Schumpueter\n[254], Kirzner [164]), as well as e\ufb03cient mechanisms for operating large\ngoing concerns e.g. managerial capitalism, viz. Porter, Bloom and van\nReenan). Do DAOs share this joint comparative e\ufb03ciency, or are they bet-\nter for starting new projects due to low costs of organizing (entrepreneur-\nship) or for operating existing projects due to low costs of participation\nin cooperative joint ownership (management)? This is both an empirical\nand theoretical research question.\n\u2022 Management and incentives in DAOs.\nWhat incentive structures\n(tokenized or otherwise) are evident across DAOs that can be designed\nand used for e\ufb00ective DAO management?\n\u2013 How can tendencies towards speculation be identi\ufb01ed and minimized\nmechanistically? What are the impacts of \ufb01nancialized governance\non e\ufb03cacy, ability to fundraise, and internal execution processes?\nHow should token distributions be structured?\n\u2013 How should incentives be created to get work done from contributors?\nWhat is an e\ufb00ective compensation structure for aligning delegate\nincentives?\n\u2013 How to de\ufb01ne and create e\ufb00ective bounties? (Note this issue relates\nbroadly to incentivising community production of local public goods)\n\u2022 DAO constitutions. Public choice theory and constitutional economics\nmakes speci\ufb01c predictions about the economic e\ufb03ciency of di\ufb00erent types\nof constitutions [38, 49](Black 1948, Buchanan and Tullock 1962 [50],\nBuchanan 1990 [49]). Early data on DAO constitutions suggest a very\n22\ndi\ufb00erent form for DAO constitutions, which are designed to complement\nexisting smart contracts [284]. What are the economic principles of DAO\nconstitutions? Does the e\ufb03ciency principle of supermajority or unanimity\nhold in internalizing externalities?\n\u2022 Mapping rules for DAOs.\nWhere corporate \ufb01rms use hierarchical\ndecision-making, DAOs tend to be \ufb02atter and egalitarian, like a commons\n[219]. A large-scale empirical and theoretical research question is to map\nthe governance rules of all DAOs, e.g. through some form of institutional\ngrammar [87, 117] or building earlier work on capturing data sets of DAO\nsmart contracts [167].\n\u2022 Cultural and institutional economics of DAOs. A signi\ufb01cant liter-\nature in development economics focuses on the role of culture in shaping\ninstitutional evolution and economic outcomes (e.g. Grube and Storr [133]\n2015, Storr [277], Chamlee-Wright 2002, 2008 [69, 70]). This literature can\nbe usefully re-applied to the study of DAO communities and ecologies.\n\u2022 Externalities and social welfare. What are \u2018market failure\u2019 equiva-\nlents for DAOs, and what types of goods can be provided by di\ufb00erent\nactors within a given DAO\u2019s ecosystem? How can public goods funding\nmechanisms piloted in DAOs (e.g. see Gitcoin\u2019s quadratic funding rounds)\nextend existing economic theory, particularly in maximizing positive-sum\nreturns to semi-private, anti-rival goods? How do DAOs bound their club\ngoods? What digital property rights should be enforceable? What public\n\u201cbads\" can be reduced by DAOs?\n\u2022 Infrastructure and public goods. Due to the relatively low cost of dis-\ntributed ownership and participation, DAOs have characteristics of clubs,\nand are therefore e\ufb00ective institutional mechanisms for the private provi-\nsion of local public goods or quasi-public infrastructure, applying to both\nthe private individual and private collections. Such goods can be provi-\nsioned by sub-committees within a DAO or by a trust or foundation under\nDAO oversight [231]. A major open question in this arena concerns the\ndesign and analysis of incentive mechanisms to provide di\ufb00erent types of\nlocal public goods, e.g. taxes, bounties, grants, prizes, retroactive funding,\nand so on [61].\n3.2\nCase studies within institutional economics\nSummary: Economists do not currently have a good way of measuring and quan-\ntifying the transaction and governance costs of DAOs. To make progress on this\nproblem, we can build on top of particular case studies that compare DAOs with\ncomparable \ufb01rm or market forms of coordination.\nThe overarching research project in the institutional economics of DAOs is\nto map, quantify, and analyze the transaction costs and governance costs within\nDAOs versus comparable \ufb01rm or market forms of coordination. In particular,\n23\nquantifying these costs forms the basis for comparative static institutional anal-\nysis. From an empirical perspective, such an examination must begin with case\nstudies of particular application domains before building to sectoral data sets.\nFor example:\n\u2022 Exchanges.\nWhat are the costs within centralized exchanges such as\nCoinbase versus those in decentralized (and DAO-governed) exchanges\nsuch as Uniswap? How do costs compare between even di\ufb00erent decen-\ntralized exchanges?\n\u2022 Unions.\nWhat are the collective action costs within traditional labor\nunions versus in those in (theorized) DAO-based unions [8]?\n\u2022 Courts.\nWhat are the governance costs within traditional governance\ninstitutions such as courts as compared with those in blockchain-based\ndispute resolution systems such as Kleros, Celeste, and Aragon Court?\n\u2022 Open source. Open-source software is a good example of a public good\nthat is easier to build than to maintain [104], and DAOs have previously\nbeen theorized as an evolution of open-source communities [168]. In a\nDAO, what is the balance between costs associated with developing such\ngoods and costs associated with maintenance and operations; how do these\ncosts compare with costs in typical open source communities?\nNote: while institutional comparative statics is an empirical research exer-\ncise, it is also a market test [6], as we expect that DAOs with lower relative costs\nwill survive and grow, whereas DAOs with higher costs will be outcompeted by\nalternative forms of organization. Of course, that claim only holds in the long\nrun and under the selection pressure of fair and robust market competition,\nso there are many reasons that short or medium run results may depart from\neconomic optimal conditions and predictions.\n3.3\nCorporate governance and principal agent problems\nSummary: Research and best-practices in corporate governance can help inform\nexisting DAO practices, especially with respect to principal agent problems be-\ntween managers and owners. On the other hand, there are many open questions\nabout whether and how DAOs can imitate various aspects of corporate structure.\nSeparation of ownership and control is an important source of value in the\nmodern corporation, but it is costly and requires governance. The \ufb01eld of cor-\nporate governance studies this trade-o\ufb00and its economic consequences, though\nits results apply far beyond traditional corporations, e.g. principal agent prob-\nlems between labor unions and union bosses. For example, Davidson and Potts\n2022 [93] argue that corporate governance, not democratic voting, is the correct\nmodel for understanding decision-making in DAOs. DAOs o\ufb00er the prospect of\nsigni\ufb01cantly reducing agency problems in organizations through lowered costs\nof governance and collective-decision making, e.g. through new forms of liquid\n24\ndemocracy. But aside from the typical social choice critiques of mechanisms\nsuch as liquid democracy, many of these mechanisms expose agents to higher\ninformation and attention costs. Some of these costs may be o\ufb00set with greater\npotential for automation.\nA central line of open questions relates to what we can learn from from\nmodels and structures explored in the corporate governance literature, cover-\ning decision-making hierarchy, accountability (to boards or other entities), and\nmeasures of success. What best practices should DAOs learn from traditional\ncorporate governance, and what best practices should they reject? If a DAO\nchooses to, how can it appoint board(s) of directors, advisors, and C-suite exec-\nutives with roles and powers as expected in modern corporations? Is there room\nfor an on-chain CEO? More generally, can DAOs and smart contracts change\nthe parameters of principal agent problems? On the economics of corporate\ngovernance, see Jensen and Meckling [153], Fama and Jensen [110], Shleifer and\nVishny [265]. On applications to blockchains see Yermack [309].\n3.4\nDynamics and strategy\nSummary: Like traditional \ufb01rms, DAOs need to make strategic decisions based\non an evaluation of their internal constraints as well as of the external, macroe-\nconomic environment.\nMicroeconomic and macroeconomic theories can help\nprovide the analytic foundations for DAO strategy, especially for competition\nand cooperation within an ecology of other DAOs, L1s, and traditional institu-\ntions such as governments.\nA range of questions also concern the dynamics of DAOs. There are the in-\nternal dynamics i.e. how we expect a particular DAO to evolve and change over\ntime; these dynamics can be measured through a range of variables including or-\nganizational structure, code, revenue, activities, and culture. There are external\ndynamics, which relate to the behavior and evolution of populations of DAOs\nwithin an ecology of other types of economic organization. Between the internal\nand external dynamics is the emerging \ufb01eld of DAO strategy (and DAO policy),\nwhich is e\ufb00ectively how to navigate the microdynamics and macrodynamics in\na world of both other DAOs, other competing organizations and institutions,\nand other complementary organizations and institutions in the network ecology.\nDAO strategy will thus include study of phenomena including DAO-to-DAO\npartnerships [88], mergers and acquisitions (ref. Fei and Rari [226], Gnosis and\nxDAI, Hermes and Polygon), and DAO-to-government relations. These phe-\nnomena give rise to a range of speci\ufb01c questions, including:\n\u2022 What are the conditions and best-practices for strategic cooperation be-\ntween DAOs? How do smart contracts, token swaps, and other technical\ninterfaces change the costs and incentives for such relationships?\n\u2022 How can token swaps between DAOs support coalitional dynamics within\nDAO markets?\n25\n\u2022 What determines coalition formation within DAO ecosystems? What are\nthe dynamics between economic and political coalitions?\n\u2022 What is the role of inter-DAO governance in structuring the markets that\nDAOs participate in? E.g. the role of competition governance, antitrust\nauthority, and industry associations or consortia.\n\u2022 What are the costs and bene\ufb01ts of governmental lobbying by DAOs? Em-\npirically, which DAOs are already contributing to such lobbying, and for\nwhat reasons?\nMany problems that arise in the arena of DAO strategy are speci\ufb01c to\nthe layer 1 (L1) blockchain that hosts the DAOs.\nFor example, the Inter-\nBlockchain Communication (IBC) protocol in Cosmos allows communication\nbetween chains; each chain in Cosmos e\ufb00ectively functions as a little DAO con-\nnected to other DAOs by bridges.3 There is competition between bridges, and\nthe bridges are not fungible with each other, which is a problem.\n\u2022 How does bridge competition or strategic partnerships interact with L1\nchain competition?\n\u2022 What is the role of L1 foundations and protocols with ecosystems? How\ndo we balance the power of these foundations and ecosystems with the\nDAOs that operate within them?\n\u2022 How should L1s fund di\ufb00erent DAOs and organizations? What\u2019s the right\ndistribution?\n\u2022 How can and should L1 foundations support (and possibly regulate) DAOs\nand other initiatives working on top of their infrastructure?\n\u2022 When the costs of bargaining are too high, public regulation is more e\ufb03-\ncient; this is the basis of the institutional possibility frontier analysis, see\nDjankov et al. [100]. Insofar as L1s represent a form of public regulation\non DAOs and other players in the ecosystem, in what circumstances does\npublic provision or standardization at an infrastructural level make more\nsense than having it be organized at the level of governance, through a\nDAO?\n3.5\nTokenomics and platform economics\nSummary: Many DAOs are governed through tradeable tokens.\n\u2018Token eco-\nnomics\u2019 or \u2018tokenomics\u2019 is a term given to the economic incentives entrenched\n3Note that IBC-style communication requires \u201cfast \ufb01nality\" but the current architecture\nof Ethereum makes this hard. Figuring out how to extend additional bridge functionality to\nEVM-based architectures is a problem for computer scientists.\n26\nwithin a token\u2019s smart contract or protocol, and the particular \ufb01scal and mon-\netary policies DAOs may implement for these tokens through governance. Ad-\nditional research on tokenomics can help expose the limitations and tradeo\ufb00s of\ntokens and coin-voting as a mechanism for governance.\nTokenomics relies on the same \ufb01rst principles as platform economics, as de-\nsigners aim to imbue their tokens with \u2018utility\u2019 to satisfy regulatory constraints.\nUtility most commonly takes the form of facilitating transactions within a plat-\nform economy; the supply side provides a service, the demand side provides the\nservice, and the token is incorporated as a tool to facilitate transactions between\nactors who are not assumed to trust each other [107, 282].\nAnother common consideration is how to initialize token supply across ac-\ntors contributing labor and capital prior to token release; the initial coin o\ufb00ering\n(ICO) craze led to large distributions of tokens to founders and investors. A sec-\nond wave of projects followed the Fair Launch principle [246] which emphasized\nall stakeholders starting on an equal playing \ufb01eld. When considering systems\nwhere tokens are used for voting, it is especially important to consider the initial\ntoken distribution.\nOne of the most exciting but also most challenging intersections between\nDAOs and tokens is the concept of a dynamic supply token: tokens which do\nnot have a \ufb01xed total supply but rather have rule systems and parameterized\nsmart contracts which determine how they are created and destroyed.\nThe\nterm \u201cgovernance surface\" was \ufb01rst used to describe the set of rules governing\nthe parameters of the RAI token [310]. Other large DAOs, such as MakerDAO,\nactually govern parameters which directly and indirectly determine the supply\nof tokens and the risk borne by token holders.\nTokens are commonly traded on secondary markets such as decentralized\nexchanges (DEXes), and the prices on these exchanges impact those tokens\ne\ufb00ectiveness both in their roles as platform economy enablers and as skin-in-\nthe-game for governance. Mechanisms such as constant function market makers,\nDEX aggregators and bonding curves are used to provide liquidity, and in ideal\nsettings reduce volatility [311, 313].\nAdditional economic incentives associated with tokens are subsidies and\ngrants. Subsidies generally target increased adoption and involve distributing\ntokens to server providers and/service consumers. The concept of yield farming\ninvolves users jumping from token to token engaging precisely to capture these\nsubsidies. Curve pioneered the concept of gauge weights where their DAO votes\non how to allocate their subsidies across various pools. This kicked o\ufb00a pro-\ncess wherein a DAO emerged to capture controlling interest in another DAO\n[289]. In the Balancer DAO, users faced down and eventually came to a com-\npromise with a whale who insisted on placing high gauge weights on a pool they\ncontrolled in order to capture subsidies [40]. While grants are notably less com-\nplex than programmatic subsidies, they most directly surface the relationship\nbetween DAOs and traditional challenges in treasury management and public\n\ufb01nance [142]. Unsurprisingly, a class of \u2018protocol politicians\u2019 has emerged to at-\ntempt to steer decision-making, especially \ufb01nancially impactful decision making\nin DAOs.\n27\nDue to the prevalence of DAOs with a tradeable governance token, token\ndesign cannot be cleanly separated from governance. Indeed, governance tokens\nare often used (perhaps more often used) for speculation rather than for their\nintended governance functions. Many authors have raised various critiques of\ntoken-based governance [252, 58]. Thus, a key question of tokenomics as ap-\nplied to DAOs is how to prevent governance tokens from becoming an end in\nthemselves. How can DAOs distinguish between voting rights and other consid-\nerations?\nBut for the foreseeable future, many DAOs will still be funded and governed\nby a form of token-based governance; DAOs with tokens have proven to be\nan e\ufb00ective mechanism to raise capital for enterprise operations. Given this, a\nnumber of questions arise:\n\u2022 What\u2019s the right way to do token distributions, both the initial distribution\nas well as ongoing distributions? Tokens tend to be heavily concentrated\nin the hands of initial founders, which leads to centralization and gives\ncontributors less buy-in.\n\u2022 What is the right way to distribute / manage tokens in a given treasury?\na lot of DAOs seem to have just one token, so one sees huge \ufb02uctuations\nin the value of these treasuries, which is problematic. Can hybrid mod-\nels, which use a mix of transferrable and soul-bound tokens, provide the\nbene\ufb01ts of marketable tokens while minimizing the downsides?\n\u2022 DAOs hold \ufb01nancial assets (digital or real) in collective ownership for\nfuture use and disbursement. How can principles of optimal capital man-\nagement and portfolio diversi\ufb01cation developed from principles of modern\n\ufb01nance (e.g. Markowitz\u2019s modern porto\ufb02io theory, Miller\u2019s work on cor-\nporate \ufb01nance, Fama and French on risk factors [109]) apply to DAOs?\nNote that this question is tightly coupled with legal questions of liability,\nownership, and legal / \ufb01duciary responsibilities that vary depending on\nthe DAO\u2019s particular legal structure [306].\n3.6\nLabor economics\nSummary: Many DAOs, especially protocol DAOs, constitute a new way of or-\nganizing production and labor that has evolved from the open source movement\nand various modes of peer production. Research in labor economics can help us\nunderstand this \u201cfuture of work\" and identify more productive and equitable ar-\nrangements. Further, organized labor has many structures and institutions that\ncould bene\ufb01t from DAO-based infrastructure, but there are many practical and\ntheoretical di\ufb03culties standing in the way of adoption that additional research\ncould help us bridge.\nA large range of standard analysis in labor economics that has previously\nfocused on \ufb01rms and markets carries over to the analysis of employment and\nwork in DAOs. See Ilyushina and Macdonald [148] for a review of this emerging\n\ufb01eld with a focus on new types of employment. Open questions include:\n28\n\u2022 How many people work for DAOs, and what do they do? Some preliminary\nstatistics exist in industry aggregators such as DeepDAO, Messari, and\nDune, but a rigorous global survey would be extremely relevant here.\n\u2022 What labor and employment relationships are being set up in the DAO\ncontext, and how do they interact with existing labor and employment\nrights, gig work paradigms, and ownership structures? Do DAOs form\na structurally new mode of joint employee ownership? How does labor\ncontract automation interact with labor rights and current practices?\n\u2022 How might DAOs be used by unions? For example, unions run elections\nthat could bene\ufb01t from some of the privacy and security properties DAOs.\n\u2022 How does DAO infrastructure shift the operation of labor markets? What\nnew types of organizations are possible?\n\u2022 How do bounties incentivise, and what particular tasks are best done\nthrough bounties? Note that bounty-based compensation is often inap-\npropriate for ongoing software contributors, who heavily front-load learn-\ning.\n\u2022 What are the leading/main DAO compensation/reward primitives?\n3.7\nSocial choice\nSummary: Use of newly-theorized mechanisms in social choice such as quadratic\nvoting and variants of liquid democracy by DAOs have been the subject of con-\nsiderable discussion as well as actual implementation in some cases. As such,\nDAOs represent an interesting testbed for experimentation within social choice\nand an exciting new source of data; social choice can also suggest improvements\nto existing governance within DAOs.\nSocial choice theory is an important body of work that is relevant to DAO\nmechanism design. At the same time, DAOs provide a testing ground for how\nsocial choice mechanisms perform in a real-world setting. Some of the social\nchoice and DAO design questions are:\n1. Applicability and e\ufb00ectiveness of quadratic voting. Quadratic vot-\ning has clear applicability to the allocation of public goods, but its creators\nthemselves have stated that \u201capplications to politics . . . or corporate gov-\nernance . . . remain far more speculative and are not advisable without\nfurther experimentation at smaller scales,\" despite citing their own work\nsuggesting possible application in both domains [174]. Although there has\nbeen a great deal of theoretical interest, quadratic voting has not found\nmany applications in DAO governance to date. It has been \u201cmuch dis-\ncussed but rarely implemented\" [205]. What are possible ways in which\nquadratic voting can contribute to DAO governance? What are the prac-\ntical limitations such as evasion through creating multiple identities akin\nto a Sybil attack? How would quadratic voting (and quadratic funding)\n29\nin DAOs a\ufb00ect minority rights and the in\ufb02uence of majority stakehold-\ners? What would be the real-world implications of quadratic voting for\nthe e\ufb03cient allocation of resources and decision-making within DAOs?\n2. Long-term vs. short-term decision-making. What are the observ-\nable e\ufb00ects of short-term incentives on DAO decision-making? How can\nDAOs be structured to prioritize long-term sustainability over short-term\ngains?\n3. Iterative decision-making. How can DAOs implement iterative decision-\nmaking processes that adapt to real-time feedback? What are the advan-\ntages and potential pitfalls of rapid iteration in DAO governance? How\ncan existing ideas from cybernetics and control theory provide a lens for\nthinking about these questions?\n4. Hybrid voting systems. Some DAOs implement parallel or hierarchical\nvoting systems that may employ di\ufb00erent voting methods in stages of a\nsingle proposal process or within parallel tracks and grant programs. How\ncan diverse voting methods (like ranked-choice voting, quadratic voting,\nand liquid democracy) be cohesively integrated within a DAO? What are\nthe emergent properties of DAOs that adopt hybrid voting systems?\n5. Vote buying. Systems such as Paladin and Bribe Protocol facilitate vote\nbuying of governance tokens. Can vote buying enhance DAO governance?\nVote buying can capture intensity of preferences, but it can also be a\nvehicle for malicious actors to secure control.\nWhat is the balance of\npositive and negative on that front, and how can that balance be addressed\nby structuring the vote buying system with appropriate incentives and\nlimitations?\n6. Applicability and e\ufb00ectiveness of liquid democracy. Blockchain\ngovernance includes multiple instances of the use of liquid democracy,\nand scholars have examined the performance and characteristics of some\nprominent cases. [182] provides an excellent example of one such study.\nThe study captures the actual behavioral patterns of participating vot-\ners, raising questions such as what to make of the apparent tendency of\nthe studied instances of liquid democracy to concentrate voting among\na few delegatees.\nThere also is a substantial theoretical literature on\nthe strengths and limitations of various liquid democracy implementa-\ntions both from the vantage point of the possibility or impossibility of\nembodying an e\ufb00ective decision process and from the vantage point of\ncomputational feasibility. A prominent example is [27]. These theoretical\nstudies are of obvious relevance to DAOs. A combination of theoretical\nand observational work can provide answers to the question of whether\nliquid democracy has a role to play in DAO governance, and, if so, which\nimplementations are likely to be most e\ufb00ective and desirable both with\nrespect to decision outcomes and power dynamics.\n30\nMany of these methods have potential in the context of DAO governance,\nbut, at present, their e\ufb00ectiveness and desirability is unclear. We are only in\nthe early stages of gaining understanding on that front. That makes studying\nthe methods both theoretically and observationally all the more important.\n4\nEthics\nEditor: Reuben Youngblom.\nContributors: Reuben Youngblom,\nJoshua Tan, Tara Merk.\nDAOs are a powerful tool for organizing and governing digitally-constituted\nentities, but little attention has been paid to the potential ethical implications\nof housing jurisdictionless, corporate-like structures on an immutable substrate.\nDespite this, or perhaps because of it, ethical questions abound, ranging from\nthe practical (e.g. are there moral obligations when architecting a DAO?) to the\nmeta (e.g. what kind of ethics are embodied within the DAO structure?) to the\nontological (e.g. who is morally culpable if a DAO performs an unethical action?\nAre DAOs moral agents?). Finding universally-accepted answers to all of these\nquestions may prove to be an intractable problem, but hopefully just being\naware of some of the open questions will give us an edge as we think through\nthe answers or, more pessimistically, arm us with the requisite knowledge to\nmake good decisions as unforeseen ethical issues inevitably crop up. Early work\non DAO ethics has focused largely on DAOs as tools for ethical enforcement\n[280], or blockchain ethics within organizations [262], or, even more generally, on\n\ufb01nancial ethics, but this space can be signi\ufb01cantly expanded. Useful \ufb01elds that\nmay o\ufb00er insights could be moral theory [102], tech ethics [43], or organizational\nethics [159], among others.\nIn exploring DAO ethics, it is critical to keep in mind that if DAOs are, for\nexample, capable of being leveraged for unethical ends, this does not automati-\ncally equate to \u201cbad.\" The crux of this exercise is, in part, to examine the extent\nto which DAOs might be used unethically (but also explore other questions like\ntheir moral agency, etc.), primarily so that this line of thinking simply gets sur-\nfaced\u2014it\u2019s very possible that, once the potential negative externalities of DAOs\nare collected and analyzed, the community still sees DAOs as representing a\nsigni\ufb01cant net positive. Further complicating the issue is the idea that the very\nde\ufb01nition of DAOs can be a bit squishy, and as a\ufb00ordances change, so too does\nthe ethical landscape. For instance, a true smart-contract-based DAO, running\non a decentralized virtual machine, that is entirely governed by on-chain code,\nshould perhaps be considered di\ufb00erently than a \u201cDAO In Name Only\" (DINO),\nsuch as a loosely-organized Discord group or similar. To take this a step fur-\nther, many of the issues raised below won\u2019t apply to most DAOs, and this is by\ndesign. The important question is not whether most DAOs are reasonable, but\nrather, what is possible at the edges?\nAs an important note, it is also good to keep in mind that, while devolving\ninto full ethical relativism is likely to be unhelpful, ethics tend to be (or, at\n31\nleast, are arguably) subjective or relative. When statements about ethics are\nmade in relation to DAOs, it\u2019s useful to understand any claims about \u201cethical\"\nor \u201cunethical\" as \u201cwhatever an individual understands to be ethical or unethical\nin this context.\"\n4.1\nCan DAOs be unethical?\nSummary: What capacities do DAOs have to cause harm in the world? Un-\nderstanding the ways in which DAOs can be leveraged to create positive change\nis important, but so is understanding how they might be used to further im-\nmoral ends. What kind of undesirable (unethical, net negative, etc.) actions are\nenabled by DAOs?\nAs noted elsewhere in this document, there are over 4000 active DAOs that\ncollectively manage over $20 billion USD. By any metric, this is a non-negligible\nindustry that can a\ufb00ect similarly non-negligible change on the world. Given\nthis potential, it\u2019s important to consider the full scope of possible positive im-\npacts that DAOs may have on organizations [41], labor [129], coordination [147],\ncomputation, and the like, but equally as important to explicitly illuminate any\npotential negative externalities. This is particularly dangerous if we believe that\nDAOs have the potential to be a tool (or, hopefully, one of many tools) that\ncan be used to reshape society. Then, if DAOs are able to have an unknown\nbut signi\ufb01cant impact on the world, it seems shortsighted to assume that the\nonly outcome(s) are likely to be positive. Given this, it is worth questioning the\nextent to which DAOs are capable of evil. This is a two-part question or, at\nleast, a question that can be interpreted in one of two ways. One interpretation\nasks whether or not DAOs, as a structure, are able to cause negative conse-\nquences that we might consider to be unethical (above and beyond what might\nbe possible as individuals, or under existing coordination architectures). The\nsecond is whether DAOs, as a structure, ought to be held morally responsible\nfor these negative consequences\u2014in other words, whether or not they are true\nmoral agents (see below).\nOf course, the answer to whether or not DAOs are able to cause negative\nconsequences is almost certainly \u201cyes,\" in the same way most things have \u201cthe\npotential\" to make the world worse if they are bent into service in such a way\nby the wrong individuals. Still outstanding, however, are targeted conversations\naround scenarios that are among the most likely to occur, and what these sce-\nnarios mean in practice. This requires community input, as no one small group\nof academics has the perspective or the collective intelligence to do this well. To\nthat end, it is a worthwhile exercise to think through the ways in which DAOs\ncould be leveraged as a tool for evil. For example:\n\u2022 DAOs could be leveraged to defraud retail investors\n\u2022 DAOs can encode business ethics, but then can also encode rules/outputs\nthat we would consider unethical, e.g. price gouging\n32\n\u2022 DAOs can enable markets for coordination around goods and services that\nserve antisocial ends, e.g. organ markets or assassination markets\n\u2022 DAOs might replace traditional corporate structures with something that\nis ultimately worse and less equitable, either from a \ufb01nancial perspective\nor beyond\nFurther exercises might include (a) placing these within the larger context\nalong a spectrum of good vs. evil; and (b) considering mitigating solutions.\n4.2\nAre DAOs moral agents?\nSummary: It\u2019s not clear whether or not DAOs, as \u201cautonomous\" organizations,\nought to be considered full (or part) moral agents, and thus whether or not they\nshould be held ethically liable for their actions. Or, if DAOs themselves are not\nheld ethically responsible, who\u2014if anyone\u2014should be?\nA \u201cmoral agent\" is an entity capable of being held ethically accountable for\ntheir actions, as they have the ability to do things like conceptualize distinctions\nbetween right and wrong, to formulate plans of action that can be against one\u2019s\nbetter judgment or interests, and to put these plans of action into motion [222].\nWhether or not DAOs (or, indeed, any organization) rises to this level is a sticky\nquestion.\nAs an imperfect starting point, it may be helpful to think about organiza-\ntional structures we are more familiar with: say, a U.S. corporation. On some\nlevel, we believe that the actual entity that is a corporation can be held respon-\nsible for the unethical actions performed by said entity\u2014not only are corpora-\ntions recognized as \u201clegal people\" in a number of jurisdictions [299], but most\njurisdictions also levy punishments for misdeeds committed by the corporation\nprimarily at the \u201ccorporate entity\" level [81], and they (as an entity) can ar-\nguably even engage in moral interactions [179]. In other ways, this does not fully\ntrack with our intuition of a corporation, which is, realistically, an inanimate\nshell that is incapable of acting without human intervention. To reconcile this,\nphilosophers have proposed the idea of \u201cgroup agency,\" underpinned by the idea\nthat groups can often \u201cintend\" to act (in the same way even a humanless cor-\nporation \u201cintends\" to act by virtue of its existence), and can even intentionally\nact in ways that none of the decision-making, input-providing humans expect or\nwant the group to act [37]. Interestingly, this is also often formulated In terms\nof corporate culture as an emergent property that is unable to be reduced to\nany individual beyond macro intentions and coincidence [242].\nThe overarching ethical question here is whether DAOs, speci\ufb01cally, have\nthis group agency and/or can \u201cintend\" to act. This is, in part, a question about\nthe implications of autonomy as de\ufb01ned within a DAO context. Shepherd [264]\nhas likened corporations to \u201cextremely dangerous psychopaths [...] capable of\nmanipulating their own responses to achieve the ends they truly value\"\u2014a sen-\ntiment worth exploring further by extending the thought process to DAOs. The\npsychopathic tendencies of corporations is due less to the individuals existing\n33\nwithin/around the corporate sphere, and more to the environmental factors (up\nto and including collective culture) that enable a corporation to act in certain\nways. Is this notion of group agency, possibly catalyzed by environmental fac-\ntors, a reasonable framework to apply to DAOs, given that they are a similar\ntype of organization, but without many of the controls found in traditional cor-\nporations (size, scope, jurisdictional pressures, permissions, centralized control,\netc.)?\nOther open questions include:\n\u2022 Do DAOs have moral agency?\n\u2022 What might be determinative of moral agency for a DAO?\n\u2022 Who is responsible if a DAO does something anti-social (or evil, etc.)?\n\u2022 What exactly do we mean when we say DAOs are \u201cautonomous\"?\n\u2022 What external factors, if any, can in\ufb02uence the behavior of a DAO?\n4.3\nRunning an ethical DAO\nSummary: Are there ethical obligations to consider when constructing a DAO,\nand if so, how ought a DAO be architected such that it follows ethical best prac-\ntices?\nHow do we run a DAO ethically; alternately, how do we code an ethical\nDAO?This, too, is a multi-part question. DAOs are capable of being used as a\ntool for evil.However, most nouns can be used for evil, though we don\u2019t consider\nmost things inherently immoral. The more interesting question is the extent\nto which we (as a community) have an obligation to ensure that DAOs are not\nused unethically and the steps we ought to take to achieve this. How does one\nrun a DAO ethically? Is there a framework or a set of best practices that can be\nfollowed such that we strike a balance between ethical norms that vary between\ncultures?\nPerhaps a good reference can be found in the \ufb01eld of bioethics. Likely as a\nway of recognizing that overly-prescriptive rules don\u2019t allow for the \ufb02exibility\nto make nuanced ethical decisions in real time, the best-practices framework in\n(western) bioethics is composed of four guiding principles: Justice, Bene\ufb01cence,\nNon-malevolence, and Respect for Autonomy [26]. One open question is whether\nconstructing a similar framework would be helpful for DAOs, as well as what\nshould be included in this framework. Future work will include \ufb02eshing out\nand de\ufb01ning the components that the community \ufb01nds most relevant, but a\npotential framework can be found below.\nPotential framework components:\n\u2022 Transparency\n\u2022 Equity\n\u2022 Immutability\n34\n\u2022 Prosocial purpose\n\u2022 Respect for autonomy\n5\nLaw\nEditors: Joni Pirovich, Primavera De Filippi. Contributors: Joni\nPirovich, Chris Wray, Morshed Mannan, Primavera de Filippi, Silke\nNoa Elrifai, Tara Merk.\nAs novel mechanisms for organizing and governing, DAOs raise a host of\nlegal issues and risks. Given the scope of existing legal rules, DAO practitioners\nhave repeatedly highlighted the need for greater legal certainty [127], partic-\nularly concerning the sharing of ownership or rights to govern in DAOs with\ntokens [302]. This includes legal certainty on liability issues for DAO members\nand contributors [113], as well as potential liability for the organization itself,\nincluding when the DAO has been incorporated or formed as a legal entity dis-\ntinct from its members [152]. More legal certainty has also been demanded for\nstructuring the interaction between DAOs and traditional entities, particularly\nnon-Web3 native organizations, including in relation to the ownership of tra-\nditional physical assets (e.g. real estate or land) [245] and the engagement of\ncontributors [148]. Furthermore, DAO practitioners are curious to better under-\nstand the regulatory landscape and where the application of existing law should\nbe clari\ufb01ed versus reformed in order to formulate clearer policy demands. Lastly,\nmany practitioners are interested in exploring whether and how legal tools can\nimprove governance structures and accountability within DAOs [207].\n5.1\nLegal de\ufb01nition\nSummary: Legal jurisdictions have a hard time classifying DAOs using existing\nentity types. Legal research can contribute insights as to where existing legal\nframeworks can be applied to DAOs and when new regulatory approaches are\nrequired.\nDAOs currently face many open problems that could bene\ufb01t from increased\nattention from the legal community. On the one hand, some legal scholars ques-\ntion the feasibility of DAOs being alternatives to the traditional corporation\n[187]. On the other hand, other scholars observe that while existing laws are\nwell-equipped to address certain challenges presented by DAOs, there are socio-\ntechnical features of DAOs (e.g., \ufb02uid transnational membership, pseudonymous\ncontributions) and the open-source protocols they govern (e.g. what smart con-\ntract parameters are subject to governance) that \u2018test\u2019 the boundaries of legal\norders\u2014requiring amendment of the law, a reassertion of existing laws, or a\ncomplete reappraisal of how the law perceives certain activities and transac-\ntions [96]. These unique features present a challenge to adequately classifying\nDAOs as existing default entity types (e.g., general partnerships, unincorpo-\nrated associations) across jurisdictions [146, 200, 249, 250, 297] or \u2018wrapping\u2019\n35\nDAOs (or parts of DAOs) into existing legal entity forms, such as corporations,\ncooperatives or other for-pro\ufb01t and nonpro\ufb01t entities [47].\n5.2\nLegal liability\nSummary: Lack of limited liability is a major concern for DAO participants, as\nis the potential liability arising from governance participation. Legal researchers\ncan analyze and create frameworks to help address core concerns both for the\ncommunity DAO practitioners and regulators.\nOne major overarching issue that legal scholarship can contribute to is help-\ning us better understand the speci\ufb01c liability risks for members and contributors\nwhen operating through a DAO that is not wrapped in a legal entity (whether\nregistered or unregistered, noting that general partnerships and unincorporated\nassociations can exist as legal entities without registration), thereby not bene-\n\ufb01ting from separate legal personality or limited liability [75]. While the risk of\njoint and several liability has often been \ufb02agged, certain issues can be explored\nfurther:\n\u2022 What are the grounds on which a claim could be brought against a DAO,\nits members and/or contributors?\n\u2022 What are the duties of members or contributors (including core developers,\nadministrators or delegates), the ful\ufb01llment of which would help avoid such\nliability?\n\u2022 How will claims be brought against DAOs, contributors, or its members,\nindividually or collectively? Who will bring such claims?\n\u2022 When are DAOs most vulnerable to such claims (e.g., at times of \ufb01nancial\ndistress, or following a hack, or strategic forks in the road)?\n\u2022 What do theories on corporate attribution and rules on attribution tell\nus about the attribution and allocation of responsibilities and liabilities in\nthe context of DAOs?\n\u2022 What legal protections and tools are available to DAOs and their members\nto avoid liability?\n\u2022 How will such liability be imposed if a judgment is delivered against a\nDAO or its members? If a judgment is delivered against a DAO or its\nmembers, how would the remedy be e\ufb00ective and timely if it must be\nformally recognised in each jurisdiction that the remedy is to be enforced?\n\u2022 What civil and criminal remedies are available against DAOs and their\nmembers?\nOngoing legal proceedings (e.g., Ooki, bZx, Tulip Trading) continue to shed\nlight on how courts view such issues.\n36\nThere are also foreseeable liability risks that have yet to materialize in prac-\ntice, such as the insolvency of a DAO. While a \u2018wrapped\u2019 DAO may be subject\nto the insolvency procedures of a traditional entity in the jurisdiction of regis-\ntration or seat, it remains to be seen how creditors and bankruptcy courts treat\nunwrapped DAOs that are unable to pay their debts and how the technical\nand governance features of such DAOs \ufb01gure in procedural arrangements and\nsubstantive considerations. For example, Oasis.app was ordered by the High\nCourt of England and Wales to use their accidental multisignature signing per-\nmissions to return stolen tokens from a vault to the rightful owner [128], which\no\ufb00ers insights into how the legacy justice system relies on such permissions ex-\nisting whereas DAO practitioners are designing systems to optimize for security\nthrough decentralization so that such permissions do not exist. Research on\nthe insolvency of general partnerships and unincorporated associations, among\nother things, may shed light on this issue.\n5.3\nFinancial regulation\nSummary: As DAOs often issue and rely on cryptographic tokens in their gov-\nernance and operations, the relation of these \ufb01nancial technologies to existing\n\ufb01nancial regulation such as securities laws, \ufb01nancial services, and anti-money\nlaundering regulation and taxation. Legal research can help to discern when and\nwhere existing regulation can apply, inform new regulatory frameworks and in-\nnovate by proposing Web3 enabled mechanisms to achieve regulatory equivalence\nin these areas.\nOther important open issues for research include the relationship of DAOs\nwith securities, \ufb01nancial services, and anti-money laundering and counter-terrorism\n\ufb01nancing (AML/CTF) frameworks designed to prevent, detect and prosecute \ufb01-\nnancial crime, which were developed with legacy system entities with centralized\nmanagement and more static membership in mind.\nWithin securities law, the key question is: should a DAO\u2019s governance to-\nkens be treated as securities? Inherently related to the processes around legal\nrecognition of DAOs is the question of whether the crypto-tokens required for\ngovernance interactions (i.e. governance tokens) are or should be securities or\notherwise regulated as \ufb01nancial products. A number of governance tokens have\nbeen alleged by the U.S. Securities Exchange Commission (SEC) as securities,\nin legal actions by the SEC against Coinbase, Binance, and others. These law-\nsuits will proceed over the course of 2022 and 2023, alongside policy e\ufb00orts in\nthe US and worldwide to establish the regulatory purview over crypto-tokens as\ncommodities, securities, or new things for which new regulation is inspired by\n\ufb01nancial regulation but not constrained by it.\nThere are a range of legal questions within AML/CTF. For example, how can\nDAOs comply with the objectives and spirit of laws and regulations intended\nto combat illicit activities, while still retaining their distinctive features (e.g.\npseudonymous or anonymous contributors)?\nMore fundamentally, given the\nshortcomings of existing AML/CTF frameworks [230], can DAOs achieve these\nobjectives more e\ufb00ectively and in a more privacy-preserving manner than these\n37\nframeworks? Even more broadly, how can DAOs contribute to the regulatory\ndiscourse on the activities and transactions that are deemed to be (prohibited)\nmoney laundering? DAOs after all provide a fertile ground for experimentation,\nenabling novel approaches for structuring the interplay between the technical\nand legal codi\ufb01cation of rules [94].\nFinally, another major open issue for research is taxation: whether and how\nshould DAOs, their members, and contributors be taxed? How are they already\nbeing taxed? How may double-taxation and penalties be avoided?\n5.4\nIncorporation and legal recognition\nSummary: Various jurisdictions have attempted to better regulate DAOs by cre-\nating bespoke legal entity forms for them. More comparative legal research, es-\npecially from the law and society perspective, can identify the bene\ufb01ts and trade-\no\ufb00s of di\ufb00erent approaches, contrast how each behaves in the face of exogenous\nshocks or changes, and analyze potential convergence of high-level approaches.\nA number of jurisdictions have begun introducing legislation that creates\nbespoke entity forms for DAOs, starting with the US state of Vermont with its\nBlockchain-Based Limited Liability Company in 2018 [307], and followed soon\nby the US state of Wyoming amending its corporate law statutes to enable the\nregistration of DAO LLCs in 2021 [22] and the Marshall Islands also allowing for\nsuch registration (with di\ufb00erent conditions) in 2022 [22]. While each of the DAO\nlegislations are di\ufb00erent, the recognition of legal personality and limited liability\nof DAOs in all of these jurisdictions are predicated on the DAO registering\nwith a registrar in their jurisdiction. Most recently, however, in March 2023\nthe US state of Utah adopted a DAO Act that will come into force in 2024,\nwhich amends the Utah Revised Uniform Limited Liability Company Act to\n\u2018recognize\u2019 a DAO as a limited liability DAO (an LLD) as equivalent to a Utah\nLLC so long as it meets certain requirements, such as appointing a registered\nagent in the state of Utah [112]. The Zone Authority of the Catawba Digital\nEconomic Zone also passed in February 2023 speci\ufb01c legislation to recognise a\nDAO as a limited liability company or unincorporated not-for-pro\ufb01t association\n[197]. There are several jurisdictions across the globe that are exploring DAO\nlegislation, including Australia [214], New Hampshire [112], Malta [122], the\nUnited Kingdom [83], and St.\nHelena [45], while there are others in which\nacademics have called for their introduction (e.g., North Carolina) [85].\nIn\naddition, there have been jurisdictions like Malta that provide certain legal\nassurances to DAOs without recognizing their legal personality yet [75, 194].\nLegal recognition of DAOs, and the ensuing questions around regulation of\nDAOs as another form of distinct legal person or if that is not appropriate then\nthe responsibility and liability attribution frameworks that should apply, is still\nin its infancy, but there is a proliferation of views on whether and how each\nshould be best achieved. The LAO had a strong in\ufb02uence on the Wyoming\nDAO LLC legislation [216], while MIDAO has championed the incorporation-\nbased approach of registering DAOs by the Marshall Islands [202]. The Utah\nDAO Act mirrors many provisions of the COALA Model Law on DAOs, while\n38\ndeparting from its text in important respects [112]. And the ongoing discussion\non DAO legislation in Malta reveals that their approach to create a DAITO\n(Decentralized and Autonomous Innovative Technology Organizations) will also\ndepart from the approaches mentioned above [122]. Future research could com-\npare these di\ufb00erent legislative approaches to regulating DAOs, particularly from\na law & society scholarship perspective, as well as assess their resilience in the\nface of changes brought on by market developments, lawsuits, and other reg-\nulatory actions.\nIt remains to be seen whether there will be a convergence\nof approaches on how DAOs are regulated, particularly as the questions out-\nlined above are addressed, and if one \u2018model\u2019 ultimately prevails. Research on\nprivate international, stateless, marine law, space law, and transnational law\napproaches as applied to DAOs is also of great interest and may inform new\ninnovative mechanisms to place DAOs within regulatory frameworks.\n5.5\nDispute resolution systems\nSummary: Smart contracts cannot cover disputes that have not or cannot be\ncodi\ufb01ed in software, forcing DAOs and DAO members to settle disputes and\nseek recourse through the legacy legal system. Legal research can contribute to\nstudies of and solutions for on-chain versions of dispute resolution.\nPlain language laws have a number of use-cases that deterministic code can-\nnot cover, and vice versa, meaning that DAO members often have to resort to\ninteracting with the legacy legal system in order to seek redress for grievances,\nto a\ufb00ect assets not governed by a smart contract, or to go around the contract\nlogic by compelling o\ufb00-chain enforcement. This suggests a number of di\ufb00erent\nresearch questions:\n\u2022 What has been the result of experiments with existing on-chain dispute\nresolution systems such as Kleros, Aragon Court, and Celeste [14]?\n\u2022 How do such on-chain dispute resolution systems compare with other forms\nof alternative dispute resolution? How have they fared? Are there funda-\nmental limits to code-is-law-style dispute resolution systems?\n\u2022 How do we incentivize more e\ufb03cient participation and fairer judgments in\nthese dispute resolution systems?\n\u2022 Are there ways of integrating smart contract enforcement with other forms\nof alternative dispute resolution?\nWhile DAOs may want to interact with legacy legal systems for many reasons\n(and their ability to interoperate with the existing legal system may even be a\ncompetitive advantage relative to other forms of online organization), more re-\nsearch is needed to understand how to allow DAOs to become more autonomous\nfrom legacy legal systems.\n39\n6\nOrganizational science\nEditors:\nRolf Hoefer, Ellie Rennie.\nContributors:\nRolf Hoefer,\nSeth Frey, Sarah Hubbard, Tony Douglas, Scott Moore, Michael\nMuthukrishna, Mason Youngblood, Michael Price, Ellie Rennie, Alexia\nMaddox, Anna Weichselbraun, Kelsie Nabben, Primavera de Filippi,\nTara Merk.\nDAOs constitute a fascinating, rapidly emerging organizational form in the\nwild.\nIn a prototypical DAO, on-chain software is central to the organizing\nprocess and every member is able to directly in\ufb02uence the execution of key\norganizational decisions.\nBlockchain infrastructure also o\ufb00ers systematically\nrich, granular, and longitudinal data.\nDAOs represent one of the most exciting empirical phenomena in organiza-\ntional science. As of 2022, DAO participants in over 4000 active DAOs collec-\ntively managed over $20 billion USD worth of assets in their treasuries. DAOs\nare organizations operating in all kinds of industries, organizing around com-\nmon goals ranging from everything in \ufb01nance to gaming, politics, culture, arts,\nand civil society. One illustration of the potential of DAOs and other Web3\ndevelopments comes from re\ufb02ecting on Web2\u2019s impact on organizational schol-\narship. The Internet\u2019s second wave made new, unprecedented organizational\nforms possible. For example, Wikipedia demonstrated the scalability of \ufb02at or-\nganizations and the ability of well-designed technological mediation to organize\nthe incremental contributions of millions of people [233]. Poorly explained by\nexisting organizational thought, Wikipedia and other examples motivated the\ndevelopment of Benkler\u2019s theory of peer production, which provided an intellec-\ntual foundation for a new generation of organizational scholars [31].\nWhat new organizational forms will DAOs permit, and what \ufb02aws will they\nreveal in how we conceptualize organizational possibilities? New mechanistic\ncorrections for the shortcomings of decentralized organization will further ad-\nvance the frontier that was opened by Web2. New forms of collective ownership\nwill blur the line between ownership and management regardless of whether they\nembrace decentralization. Instantaneous algorithmic design and incorporation\nof ephemeral businesses will blur the lines of Williamson\u2019s transaction cost ra-\ntionale for \ufb01rm versus market exchange [303]. For their potential to both build\non and extend a century of organizational thought, DAOs merit close attention\nfrom organizational scholars.\nIn the following we neither claim nor attempt to depict the breadth and\ndepth of overlap between organizational science and DAOs. Instead, we pick a\nfew topics we believe are interesting and fruitful explorations for those interested\nin DAOs and organizational science.\n6.1\nOrganizational imprinting\nSummary: We still do not fully understand why and how emerging organizations\ncome to adopt their particular social structures and strategies. DAOs, which\n40\ngenerate a signi\ufb01cant amount of granular, longitudinal data through on-chain\nprocesses, can provide valuable insights into the evolution of social structures\nand practices within organizations, o\ufb00ering opportunities to explore dynamics,\nhistories, and the impact of elements like smart contracts, incentive schemes,\nand forks.\nA seminal piece in organizational theory is Stinchcombe\u2019s 1965 chapter on\n[276]. Over time, this chapter has come to be known for highlighting an ob-\nservation unique to organizational theory: the phenomenon of organizational\nimprinting. Organizational imprinting describes the observation that organiza-\ntions founded at one time tend to have a di\ufb00erent social structure from those\nfounded at another time. Once an organization forms its social structure, its\nsocial structure tends to persist for an extended period.\nWhile Stinchcombe\u2019s observation is widely taken-for-granted, why and how\nemerging organizations come to adopt their social structures and strategies has\nbeen underexplored [137, 154, 155]. In this context, DAOs are interesting be-\ncause they represent a new, \ufb02edgling organizational form.\nAs a novel type\nof organization, DAOs are in the process of forming and adopting the social\nstructures and strategies that will, according to past organizational imprinting\nresearch, persist for a long period of time. This suggests that DAOs represent\na fertile ground for researchers to understand the formation phase of organiza-\ntional imprinting, including when, why, and how an organization does or does\nnot become imprinted.\n6.2\nEvolutionary social science\nSummary: Evolutionary social science applies ideas from biology and evolution\nto questions in the social domain. DAOs represent a fertile new domain for\ndeveloping and testing some of these ideas due to the availability of data, their\nuse of technical infrastructure that can be precisely characterized, and the speed\nat which they evolve.\nHistorically, much research on organizational imprinting has drawn inspira-\ntion from biology and evolution [185] with concepts such as an organization\u2019s\n\u201cDNA\"; organizations evolving through adaptation and selection pressures [316];\nand complex patterns of mutualism [286]. More broadly, the \ufb01eld of evolution-\nary social science has a long history of applying evolutionary ideas to questions\nof social evolution, cultural evolution, and organizational evolution. DAOs rep-\nresent a fertile new domain for developing and testing some of these ideas.\nA research program applying evolutionary ideas to DAOs would need to\ninclude at least three components: conceptual mapping, data and tooling de-\nvelopment, and comparative case studies.\n1. Conceptual mapping. To apply evolutionary methods to a \ufb01eld, we\nneed to de\ufb01ne a set of evolutionary primitives, in particular mechanisms for\nvariation, transmission, and variation reductive (which, if adaptive, should\nbe selective). What is the mechanism by which variation is created within\nDAOs? Variation is produced sometimes in the act of transmission\u2014is\n41\nthat true for DAOs? For any evolutionary system you want high \ufb01delity\nin transmission, but how much actual transmission is there? Finally, what\nare the mechanisms for selection? Are there informal mechanisms, ways\nthat communities can change, or fork to change? Note: having \u201cgenes\" or\n\u201cbuilding blocks\"\u2014e.g. granular privacy primitives\u2014can be useful but it\nis not essential for this modeling.\n2. Data and tooling development.\nHow does the infrastructure of a\nDAO allow a working evolutionary social scientist to engage with either\nindividual DAOs or the broader ecosystem? Given the issues with o\ufb00-chain\ndata, what a\ufb00ordances and tooling exist to allow researchers to understand\nand parse what is going on within DAOs? What particular aspects of DAO\ndata are evolutionary social scientists particularly interested in?\n3. Comparative case studies. We want to compare DAO evolution to\nexisting examples within social evolution, for example the evolution of\nchurches [116], of constitutions [239], within coding competitions [203],\nand of other online communities such as subreddits [283].\nWithin the scope of such a research program, there are a number of di\ufb00erent\nopen questions:\n\u2022 Forks. Forks are phenomena where an organization splits from another\norganization yet retains the exact same history as the previous organiza-\ntion [32]. Due to its public nature, the data and contracts that de\ufb01ne a\nDAO can be easily forked as a technical matter. Indeed forks have hap-\npened, e.g. SushiSwap from Uniswap or during the attempted takeover of\nSteemit, and the threat of forks represent a signi\ufb01cant check on bad be-\nhaviors by founders and other powerful members of a DAO or blockchain.\n\u2022 Infrastructure for merging. The US federal government is a way for\nstates to merge. The EU is another model for merging. Australia is a\nvery di\ufb00erent model. In the infrastructure of a DAO (or a blockchain),\nwhat are the mechanisms that would allow you to explore new possible\ncon\ufb01gurations and to possibly incentivize merging of communities?\n\u2022 Cultural evolution. How does the new technical infrastructure of a DAO\nenable and constrain the variation, transmission, and variation reduction\nof cultural practices within the DAO? How can these infrastructures trans-\nlate into non-Web3 contexts?\n\u2022 Simulating cultural evolution.\nIdeas from cultural evolution could\nbe particularly useful in simulating DAO behavior. There is a suite of\nmethods in cultural evolution for simulating how conformity bias, prestige\nbias, and payo\ufb00bias interact with one another in extremely complex ways,\nwith norms co-evolving with these biases. Considerable time and expense\nhas been applied to collect data from social networks that can then be\napplied to these models, whereas these methods could be applied directly\n42\nto DAOs based on already-extant data. Such simulations could eventually\nbe incorporated into DAO design.\n\u2022 Theory of cultural evolution.\nInsofar as they represent interesting\nexamples of self-governing communities, DAOs could inspire new math-\nematical treatments of agents\u2019 ability to self-determine and create their\nown games, as opposed to traditional treatments that operate within a\ntight framework of phenotypes and behavior.\n\u2022 Cultural traditions as cognitive tools. Cognitive tools are artifacts\nor processes that facilitate cognition. These are not just physical things\nbut also \u201cways of seeing the world\", i.e. cultural traditions. For exam-\nple, \u201cmountain calendars\" from Mexico [108] or \u201cknuckle mnemonics\" for\nmonths of the year. What kinds of cultural traditions operate as cognitive\ntools within DAO governance and DAO operations? How can existing\ninfrastructure support such cultural traditions?\n6.3\nNeo-institutional theory\nSummary: Building and maintaining legitimacy is a key concern for traditional\ninstitutions but especially in DAOs, which often govern through \ufb02at hierarchies\nand informal cultural norms.\nNeo-institutional theory shifts the focus of re-\nsearch on legitimacy to its communicative aspects and allows for a deeper un-\nderstanding of how organizations, including DAOs, achieve legitimacy through\nlanguage and communication rather than mere di\ufb00usion of practices.\nThus,\nneo-institutional theory can help practitioners and DAO managers navigate the\nemergence, intercultural participation, chaos, and complexity that characterize\nDAO environments.\nFor decades, institutional theory and its variances have been a dominant\nresearch stream within organizational science. A core concept in institutional\ntheory is the concept of legitimacy [34, 98, 121, 258, 278, 318]. While much\nwork has measured legitimacy as a function of the successful di\ufb00usion of orga-\nnizational practices, the process by which organizations such as DAOs achieve\nlegitimacy is fundamentally communicative. Consistent with the phenomeno-\nlogical tradition in institutional theory [257], legitimacy is \u201cbuilt upon language\nand uses language as its principal instrumentality\" [34].\nA focus on legitimacy as a communicative phenomenon is interesting for two\nreasons. First, from a theoretical perspective, adopting the view of legitimacy as\na communicative concept avoids the suggestion that the di\ufb00usion and adoption\nof organizational structures, practices, and strategies is evidence of legitimacy.\nOrganizational structures, practices, and strategies can be sparsely adopted\nyet legitimate, and they can be widely adopted yet not legitimate [317, 132].\nFocusing on language also resonates with the linguistic turn in institutional\nand organizational science [10]. Recent research e\ufb00orts at the intersection of\nentrepreneurship and institutional theory, such as the work on cultural en-\ntrepreneurship [154, 186], have started to examine the ways that the legitimacy\nof organizations is a function of language, suggesting an emerging body of work\n43\nthat scholars can build on and extend. Second, a focus on legitimation as rooted\nin communication is interesting from practitioners\u2019 perspectives [57, 95]. DAOs\nare internet-native organizations. Coordination is managed digitally in a fast-\npaced world. When environmental change is high, organizational systems need\nto adapt quickly, and this work is typically facilitated by people who focus al-\nmost exclusively on coordination as opposed to execution \u2014and that is the role\nof management, or, put into the language of DAOs, that is the role of community\nmanagers and delegates [53].\nPersuasion in DAOs often happens more with stories rather than tables,\nwords rather than numbers, beliefs rather than facts. Managers must become\nskilled at persuasion with stories, words, and beliefs. Persuasion increases social\nstickiness, and social stickiness is what keeps organizations as communities and\nsocial networks together in the absence of tight, hierarchical structures and\nvague incentive structures. The current mintage of DAOs is characterized by\nemergence, intercultural participation, chaos, and complexity. Managing these\nDAOs requires managers to become skilled communicators. Those who lean on\nthe knowledge gained from research e\ufb00orts in institutional theory such as those\non cultural entrepreneurship may bene\ufb01t tremendously.\n6.4\nOrganizations as complex adaptive systems\nSummary: Understanding DAOs as complex adaptive systems (CAS) presents\nopportunities to study properties such as path-dependency, sensitivity to ini-\ntial conditions, emergent changes, and episodic shifts. Researchers can employ\ngrounded theory and comparative case study approaches to advance empirical\nunderstanding and generate theories around organizational evolution. Addition-\nally, the unique data properties of DAOs o\ufb00er avenues for fascinating studies\non social networks, dynamic tie evolution, and the use of agent-based models\nto project and understand organizational dynamics over time. This stream of\norganizational research can further help to address questions of how and why\nproductive self-organization emerges in organizations and DAOs.\nMany DAO participants believe DAOs o\ufb00er new opportunities for organiza-\ntional systems to self-organize. There is a real opportunity for academic work\nthat may help practitioners understand how, when, and why productive self-\norganization emerges. Much existing work is rooted in views of organizations as\ncomplex adaptive systems evolving at the edge of chaos. Indeed, the contribu-\ntions of scholars such as Herbert Simon and James March were as fundamental\nfor the development of complex systems as organization science [268], while Eli-\nnor Ostrom explicitly bases her foundational concept of institutional diversity\non the proto-CAS thought of cybernetics [220]. Interestingly, empirical research\nin this domain has been slowed down by the lack of appropriate empirically-\ngrounded data and methods to test researchers\u2019 theoretical hypotheses. DAOs\npresent an opportunity to not only test these hypotheses but also to inform and\ngenerate new ones.\nComplexity, in brief, views systems such as organizations as wholes that\nare more than the sum of their parts and even as archetypes for the multi-\n44\nscale structure that characterizes emergent complexity [220]. The literature on\ncomplexity highlights properties such as path-dependency, sensitivity to initial\nconditions, emergent (uncertain but not random), and episodic changes [28]. Of\nparticular interest to practitioners in the DAO space might be how to manage\ncomplex organizations while staying true to emergent self-organization [221].\nDAOs are a fertile ground with plenty of exceptional data to study self-\norganization. On-chain data does not su\ufb00er from left-censoring; however note\nthe learnings from the Curve wars regarding manipulation of the governance\nthat occurs on-chain. Certain datasets have perfect data, obviating the need for\nsophisticated statistics to address gaps. The recent explosion of DAOs also of-\nfers su\ufb03cient freedoms of observation. This presents rich opportunities. On one\nhand, grounded theory and comparative case study approaches would advance\nour empirical understanding of DAOs. It may also generate theory around orga-\nnizational evolution. Models of organizational change as punctuated equilibrium\ntraditionally invoke change as developing from a growing discrepancy between\nan organization and its environment. The causal mechanism typically invoked\nis organizational inertia. Yet considering organizations as complex adaptive sys-\ntems suggests alternative mechanisms. For example, organizations may change\nvia punctuated equilibrium because patterns of both small and large changes\nover time can often naturally lead to a pattern of change in the form of a punc-\ntuated equilibrium.\nMoreover, a unique research opportunity rests in the data properties around\nDAOs. Empirically inclined researchers may create fascinating new studies that\nleverage this data:\n\u2022 Researchers may analyze social networks of agents not only at a given\npoint in time, but dynamically as these social networks evolve over time,\nand agents and their organizations begin to co-create each other [315].\nMuch research in social networks is based on the presence or absence\nof connections between some or the other actor. Data related to DAOs\nallows researchers to see how ties dynamically evolve. This can be similarly\nstudied at the dyadic, triadic, cluster, or network levels.\n\u2022 Researchers viewing organizations as complex adaptive systems can easily\nmeasure, more easily than ever, how a focal actor\u2019s behavior in the current\ntime period a\ufb00ects the behavior of other actors in the next time period.\n\u2022 An even more fascinating approach would be to train or condition agent-\nbased models on real-life data points. DAOs may permit faithful imple-\nmentations and rigorous tests of classic computational models of organiza-\ntions, from the anarchic garbage can model [82] to Carley\u2019s ORGAHEAD\nof organizational adaptation [64]. For example, an agent-based model\u2019s\n\ufb01rst iterations modeled using real data and the revealed dynamics could\ncontinue projecting an organization\u2019s evolution in the next few iterations.\nSuch models would approach scienti\ufb01c work with practitioner work, both\ntremendously bene\ufb01ting from each other via superior, shared understand-\ning and greater empirical and theoretical groundedness.\n45\n6.5\nOrganizational methodology in the era of complete\ndata\nSummary: The questions scholars ask about organizations tend to be a function\nof the limited data they have access to. As DAOs provide complete data from the\nlevel of individuals to the level of populations of organizations, the completeness\nand transparency of this data promises to advance organizational scholarship,\nparticularly as organizational scholars increasingly work to reconcile and inte-\ngrate disparate research frameworks.\nOrganizations are di\ufb03cult to study. They are typically too big, dynamic, and\nunobservable to provide the elements necessary for controlled scienti\ufb01c inquiry.\nDAOs correct for this by being highly instrumented, entirely transparent orga-\nnizations that o\ufb00er systematically rich, granular, and longitudinal data. The\ncomprehensiveness of DAO data is atypical of what academics have encountered\nto date. As a result, DAOs represent not just a novel empirical setting but an\nopportunity to develop and test novel empirical methods that were previously\nimpossible to apply.\nAs DAOs rely on on-chain processes for membership, governance, and opera-\ntions, they generate a wealth of granular, longitudinal data about the evolution\nof their social structures and practices. Often this on-chain data does not suf-\nfer from typical left-censoring or sampling issues, and, apart from community\nmoderation, other public data from governance and operational interactions is\nuncensored. We have already discussed the longitudinal tracing of how social\nstructures evolve via on-chain elements, dynamics, and histories such as smart\ncontracts, incentive schemes, and forks, but many other opportunities remain.\nLooking ahead, this data could be used to power multiscale studies that\nbridge (or challenge) Hannan and Freeman\u2019s \ufb01ve levels of organizational analy-\nsis: members, subunits, individual organizations, populations of organizations,\nand communities of populations of organizations [137]. This is important be-\ncause the major paradigmatic di\ufb00erences driving contemporary organizational\nscholarship are more a function of data availability than any epistemological\ndi\ufb00erences. An ideal example lies in \ufb01rm- versus population-level theories of\norganizational survival. Frameworks like the \ufb01rm-level \u201cresource-based view\"\nrely on behavioral data of members of organizations to discover internal deter-\nminants of organizational success. By contrast, frameworks like the population-\nlevel organizational ecology view rely on data about populations of interacting\norganizations to reveal environmental determinants of success. While scholars\nacknowledge that both must be true [130, 181, 295], the di\ufb03culty of collect-\ning large, complete, multi-scale datasets has made it impossible to understand\nhow internal and environmental theories of organizational performance inter-\nact and complement each other. From this perspective, DAOs promise to be\nthe substrate upon which organizational scholars develop a uni\ufb01ed multi-scale\nconception of \ufb01rm success and even emergent social order.\nLooking even further ahead, it is important to recognize that the people who\nstart and operate organizations are themselves organizational scholars engaged\nin the challenge of building a social system capable of learning and adapting\n46\n[261]. Classic work by March emphasizes the spotty and imperfect nature of try-\ning to theorize about a single organization while situated within it [196]. With\ntheir automation, instrumentation, standardization, and transparency, DAOs\npromise to transform organizational learning by making it easier for members\nto automatically register and learn from each others\u2019 mistakes both within orga-\nnizations and across many organizations. Although it has long been recognized\nthat organizational learning can happen at the level of communities of popula-\ntions of organizations [25], even lessons at that scale tend to be anecdotal, and\nlack the automatic, systematic comprehensiveness of potential future DAO-to-\nDAO organizational learning systems.\n6.6\nOrganizational ethnography\nBeyond analyzing DAOs through their on-chain and quantitative data, quali-\ntative research methods are widely employed throughout organization studies.\nIn this section, we make a case for ethnography, a speci\ufb01c type of qualitative\nresearch method, as a means to surface DAO-based social phenomena and prac-\ntices that may push the boundaries of existing disciplines.\nEthnography is a qualitative approach in which the researcher is immersed\nin the phenomena and community they are studying. It is typically used to\nmake visible the invisible, surface new and recurring questions and themes, and\nchallenge normative assumptions with an eye to identifying discrepancies that\nexist between what communities say they do versus what they actually do. The\nprocess involves producing \u201cthick description\" [125], meaning an interpretative\naccount not just of actions, but the meanings, symbols and structures that in-\nform behaviors. As ethnography looks to \u201c\ufb01rst-hand\" knowledge rather than\nrelying exclusively on second-hand accounts [145], researchers will spend sig-\nni\ufb01cant time with the people, communities, and contexts they are researching\nto understand their language, design, rules, and customs. In addition to ob-\nservation \ufb01eld notes, ethnographic data may include interviews, focus groups,\ncollecting data across multiple media sites [15] or even computational data [191].\nIn the case of DAO research, the ethnographer\u2019s task lies in documenting\nand understanding the social dynamics underpinning a particular context and\nthe interactions among both human and non-human actors constituting a \ufb01eld\nsite. A DAO community is not always the thing being studied; the ethnographer\nmay be tracing various phenomena such as values, standards, infrastructures,\nand automated policies by observing how they occur in and through DAOs.\nThe ethnographer may choose to extend upon traditional ethnographic re-\nsearch methods by including the study of computer mediated social interactions,\nthe study of online communities and the use of digital technologies in data col-\nlection and analysis [3, 228]. For instance, ethnographers studying in DAOs\nmay need to follow both human and non-human actors [259], and make sense of\ntheir interaction with each other and the community\u2019s wider social and material\ncontext [177]. Speci\ufb01c techniques such as situational mapping, arena mapping,\nand positional mapping [77, 78] may be used to synthesize empirical observa-\ntion without excluding technical actors, infrastructural components, discursive\n47\ndynamics or the broader context.\nConducting ethnographic research in DAOs and Web3 comes with speci\ufb01c\nchallenges. Firstly, ethnographers are required to de\ufb01ne, access and make sense\nof the deluge of data gathered through their \ufb01eld site, including online forums\nsuch as Discord servers. In the context at hand, this requires us to ask questions\nsuch as: Where is the DAO? Where, when and how can we see it, and where\nnot? Secondly, while ethnographers are relatively free to choose the speci\ufb01c\ntechniques most appropriate to making sense of their data, it is not always\neasy to get informed consent from all actors being observed in a DAO. One\nexample of an attempt to overcome this challenge is the Telescope consent bot,\ndeveloped by Rennie et al. [237] to automate parts of the consent process for\ndata collection within Discord chats.\nTo date, researchers have used ethnographic methods to explore the informal\naspects DAO governance [103, 266], cultural dynamics and beliefs in cryptocur-\nrency communities [44, 114], activism in darknet marketplaces [192] and the use\nof Web3 technologies as a form of \u2018self-infrastructuring\u2019 [209]. Researchers em-\nploying ethnographic methods have made valuable contributions to DAO science\nby revealing unformalized and somewhat messy o\ufb00-chain governance dynamics,\nanchor on-chain components within speci\ufb01c context and meaning to understand\ntheir mediating capabilities, and by developing new participatory methods to\ninvolve DAO practitioners in the research process. Ethnography is therefore a\npromising approach for identifying emergent \u2018open problems\u2019 in DAO science.\n7\nPolitical science and philosophy\nEditor: Eliza R. Oak. Contributors: Eliza R. Oak, Woojin Lim,\nH\u00e9l\u00e8ne Landemore, Danielle Allen.\nPolitical science is the systematic study of governance (Goodin and Klinge-\nmann, 1998; Roskin, 2005). At the heart of political science is the study of\nthe transfer and allocation of power in decision-making processes, and of the\nemergence and consequences of di\ufb00erent governance systems. Studying the gov-\nernance of DAOs and other digitally-constituted organizations is interesting for\npolitical scientists because (1) DAOs o\ufb00er a new platform to empirically test\ntheories from the political science canon; (2) DAOs are actively seeking expert\nknowledge to consult their governance design decisions so there is real-world\ndemand for scholarship on this topic; and (3) as all aspects of society become\nincreasingly digitized, understanding best-practices for DAO governance paves\nthe way for re-imagining and potentially re-designing current political processes\n[35].\nSocieties and organizations have puzzled over governance questions for mil-\nlennia, and the contested idea of democracy\u2014a system of governing which de-\npends on the will of the people\u2014is central to these debates (e.g. [229, 12, 184,\n243, 89, 232, 175]). In theory, DAOs present innovative opportunities for collec-\ntive decision-making, though in practice there are many possibilities for the anti-\n48\ndemocratic seizure of DAOs. Insofar as DAOs rely on blockchain-based auto-\nmated data storage mechanisms and smart contracts, how can challenges related\nto technocracy be avoided [61]\u2014and are such automated decision-execution pro-\ntocols even desirable? How can plutocracy or sybil attacks be avoided, when\ncommon \u201cone-token-one-vote\" mechanisms mean that wealthy users can buy a\ndisproportionate number of tokens and subsequently gain a disproportionate\namount of voting power? Because of these and other problems in practice, more\nthought should be dedicated to questions of whether \ufb01nancializing governance\nactually make sense\u2014and to formalizing the conditions under which certain\nvoting models are appropriate.\n7.1\nInstitutions\nSummary: As DAOs create political institutions, they confront classic coordi-\nnation puzzles such as preference aggregation, credible commitments and audi-\nence costs, information asymmetry, or representation and accountability. As a\nunique empirical setting, DAOs can help political scientists (1) study founda-\ntional theories about political institutions and (2) generate novel theories to be\ntested in digital governance settings.\nThe potential problems of tokenized governance raise interesting questions\nconcerning the design of durable and representative political institutions. Polit-\nical institutions tend to refer to \u201cthe formal and informal rules, procedures, and\norganizations that govern the behavior of individuals and groups in a political\nsystem\" [136]\u2014that is, the \u201crules of the game in a society, or more formally,\nthe humanly devised constraints that shape human interaction\" [213]. Scholars\nhave debated the implications of di\ufb00erent types of institutional design, includ-\ning separation of powers, federalism, the strategic design of non-democratic\ninstitutions, or institutional change. How might these theories map onto the\ndesign of digitally-native governance institutions? For example, does separation\nof powers in DAOs prevent any one entity from becoming too powerful [204],\nincreasing transparency and accountability [183], or does this instead result in\ngridlock and indecisive government action [291]? Does dividing power between\ncentral and \u201cregional\" entities in DAOs lead to greater democratic participa-\ntion, as the threat of regional secession (forking?) can create incentives for the\ncentral government to compromise and increase responsiveness [238]? In order\nfor institutional change to occur in DAOs\u2014where change can occur much more\nrapidly\u2014must there still be signi\ufb01cant buy-in from political elites and a credible\ncommitment by political actors to respect the new institutional rules [298]?\nHow can DAOs avoid elite interest capture? For example, non-democratic\nregimes will sometimes create electoral institutions in order to gain information\nabout who to trust among the ruling elites, meaning these institutions are little\nmore than performative \u201cwindow-dressings\" of democracy designed to promote\nnon-democratic regime survival [123].\nOther research has examined how despite the same institutional composi-\ntion, variation in the levels of \u201ccivicness\" explains why some regional govern-\nments are more e\ufb03cient and more responsive [234]. Recent scholarship has also\n49\nargued that the disruptive Schumpeterian consequences of blockchains make it\nan institutional technology rather than a general purpose technology, and that\nblockchains themselves are an instance of institutional evolution [92].\n7.2\nTurnout\nSummary: The coordination challenge in collective choice, which involves aggre-\ngating individual preferences, also applies to DAOs, prompting questions about\nvoter turnout, representation, and accountability.\nPolitical science can help\nDAOs strike a balance between more participatory decision-making and the inef-\n\ufb01ciencies caused by uninformed voting, e.g. through new (and old) incentiviza-\ntion methods to address issues of accessibility and quality of participation. The\nformal voting mechanisms and informal mobilization strategies that in\ufb02uence\nonline, token-incentivized civic participation in DAOs remain open questions in\nthis context.\nThe coordination puzzle of aggregating individual preferences by some method\nsuch as voting to produce a social outcome (i.e., collective choice) underpins\nquestions about governance and institutions. Collective choice is shown to in-\nvolve \u201csurprisingly intransigent paradoxes that seem to challenge the possibility\nof fair democratic decision-making\u201d [255]. DAOs similarly confront classic ques-\ntions of turnout, representation, and accountability as they design their gover-\nnance institutions. DAOs su\ufb00er from similarly low levels of voter turnout to\nthose documented in the real world and therefore aim to balance the desire for\nmore participatory and inclusive decision-making processes, without inducing\nlow levels of participation and ine\ufb03ciencies from uninformed decision-making\n[51]. As DAOs experiment with di\ufb00erent voting mechanisms, important ques-\ntions related to participation arise, for example:\n\u2022 What are the most compelling ways to incentivize voting participation \u2014\nwithout building-in perverse incentives?\n\u2022 Is participation due more to lack of interest or lack of accessibility?\n\u2022 How should we think about the quality of participation? Quality of partic-\nipation is especially relevant in DAOs where users can earn tokens based\non participation, as this opens up subjective questions about who gets to\ndecide what type of participation is considered deserving of more tokens.\n\u2022 How do informal concepts like \u201cdo-ocracy\" and \u201clazy consensus\" become\nrelevant and operationalized in these digital contexts?\nOpen questions remain regarding which individual-level characteristics, insti-\ntutional factors, and mobilization strategies in\ufb02uence online, token-incentivized\ncivic participation in DAOs. Do DAO voters, for example, also tend to be in-\ndividuals with higher levels of income, education, and social status are more\nlikely to have access to political information and feel a sense of political e\ufb03-\ncacy [294, 144]? Or do the individual-level characteristics of DAO voters re\ufb02ect\n50\nthose of early crypto adopters more generally\u2014do they tend to be younger,\nmale, more dissatis\ufb01ed with existing institutions and tech-savvy, for example?\nMoreover, do DAOs with compulsory voting laws [183], unicameralism [149], or\nproportional representation rather than plurality systems [39] also tend to have\nhigher levels of voter turnout? What mobilization strategies are most e\ufb00ective in\nDAOs\u2014for example invoking social pressure by publicizing individuals\u2019 voting\nbehavior [48], or online variations of get-out-the-vote e\ufb00orts [131]?\n7.3\nReal-time experimentation\nSummary: DAOs are experimenting rapidly with both traditional and novel gov-\nernance strategies, with online programmability widening the design space for\nwhat is possible. The rapid experimentation of DAOs provide political scien-\ntists a unique and, to date, mostly unexploited opportunity to study the e\ufb00ect of\ninstitutions on political behavior and collective outcomes.\nUnlike political governing bodies which historically take decades or even cen-\nturies to change, DAOs are experimenting with the design of governing bodies\nat exponentially quicker scales (Hall and Smith, 2022). Optimism4, for exam-\nple, has designed a bicameral governance structure where governance matters\nare divided between the Token House and the Citizens\u2019 House. In the Token\nHouse, an individual with more tokens has more votes. In the Citizen House,\nevery individual \u201ccitizen\u201d is granted one non-transferable citizen token which\nyields precisely one vote per individual citizen. Optimism has also created a\nsystem of delegation that allows users to select a trusted third party to make\ngovernance decisions on their behalf, though said user retains full ownership of\ntheir tokens and can choose at any time whether to vote directly instead of via\nthe delegate. Other DAOs are experimenting with new voting mechanisms in-\ncluding: quadratic voting which allows individuals to express how strongly they\ncare about a given issue, quorum voting which requires a certain threshold of\nvotes in order for a proposal to pass, conviction voting in which proposals ac-\ncumulate enough votes to pass over time, or versions of liquid democracy which\nemploy elements of both direct and representative democracy.\nThese and other real-time applications provide political scientists with a\nunique opportunity to analyze large amounts of time-stamped, individual-level\ndata on governance participation. This opens up new opportunities for scholars\nto empirically test centuries of political thought as well as test new bold ideas for\nvoting and governance. This could o\ufb00er scholars and practitioners the oppor-\ntunity to apply lessons from DAO governance to potentially improve political\nprocesses and coordination in our ever-digitizing society.\n7.4\nSelf-governance\nSummary: Previous scholarship has explored decentralized forms of governance\nin non-state realms, shedding light on factors that contribute to successful self-\n4Optimism is a Layer 2 network and can be thought of as a sort of blockchain built on top\nof another \u201cLayer 1\u201d blockchain to reduce fees and transaction speed.\n51\ngovernance and coordination which are relevant for understanding the gover-\nnance of decentralized digital governance.\nPolitical science can help address\nquestions about power allocation, participant vetting, community norm enforce-\nment, and the ideal level of gatekeeping in self-governing communities, while\nconsidering the coexistence with external regulatory jurisdictions and the impor-\ntance of informal authority and community building in decentralized organiza-\ntions.\nContemporary political science increasingly includes the study of non-state\nrealms of governance, including the governance of \ufb01rms and other government-\nrecognized legal entities; tribes and other socio-political groups; or gangs, protest\nmovements, and other non-state networks. Scholars have documented how and\nwhen decentralized governance and coordination is successful in the absence\nof strong formal governing institutions, which is relevant for understanding the\ngovernance of distributed online networks. 13th-century Mediterranean traders,\nfor example, created a unique institutional system based on norms and prac-\ntices that promoted trust, cooperation, and reputation-building among traders,\nenabling traders to overcome the risks associated with long-distance trade and\nresolve disputes without violence [17]. Other scholarship has examined the role\nof social capital, villager associations, and informal monitoring networks in facil-\nitating the provision of public goods in the absence of democratic or bureaucratic\nmechanisms of accountability [290].\nSelf-governance can exist in the absence of formal rules. In examining the\nconditions in which criminal groups exert state-like functions in their spheres of\nin\ufb02uence, scholars have documented how the internal organization of a Mexican\nma\ufb01a gang functions much like a traditional cooperative with a written consti-\ntution [170], whereas a prison gang lacks clearly de\ufb01ned control rights and is\nworker-owned, with each member having a vote and relying on an internal rule\nstructure [269]. To gain membership into either a prison or ma\ufb01a gang, recruits\nmust make costly sacri\ufb01ces to improve member quality, limit free riding, and re-\nveal information about the recruit\u2019s abilities and dedication. DAOs face similar\nquestions regarding power allocation, participant vetting to improve quality of\ndeliberation, and community norm enforcement in self-governing organizations.\nOther explanations for self-governance look beyond state solutions or market-\noriented approaches to explain how societies and groups regularly devise rules\nand enforcement mechanisms to govern the commons [219]. This scholarship re-\nveals that these types of self-governing cooperatives tend to work because they\u2019re\nrather homogeneous and have \u201cclearly de\ufb01ned community boundaries\u201d [244]; ex-\ntensions of commons scholarship to online communities have demonstrated the\nframework\u2019s power for understanding virtual and computational resource gov-\nernance as well [120, 166]. As DAOs aspire to be \ufb02atter and more egalitarian\nwith power distributed across tokenholders who cast votes, this open, participa-\ntory, and heterogeneous structure raises questions about how best to scale. In\nterms of clearly de\ufb01ning community boundaries, DAOs face questions regard-\ning the ideal level of gatekeeping\u2014how open, and how participatory should a\nvalues-aligned, mission-driven DAO be, and who should decide this?\nOf course, DAOs do not operate in a vacuum and are exploring ways to\n52\nself-govern while co-existing with evolving external, formal regulatory jurisdic-\ntions. Similarly, existing research examines the relationships that arise through\ninteractions between state and informal actors at the local level (e.g., hostility,\nacquiescence, collusion) and seeks to understand what factors make this type of\ngovernance stable over time. Baldwin [20], for example, argues that unelected\ntraditional leaders (chiefs) in Africa improve the responsiveness of democratic\ngovernments by helping to hold political leaders accountable, depending on how\nwell local politicians work with chiefs. Just as political scientists focus on many\naspects of governance beyond the formal constitutions, there are many aspects\nof DAO governance beyond questions about hard-coded governance rules, for\nexample online community building and informal authority delegation.\n7.5\nGlobal governance\nSummary: Similar to nation-states regulating themselves without a central gov-\nerning body and designing their own mechanisms for enforcement, DAOs oper-\nate without a central governing DAO and alongside territorial nation-state laws.\nThe scholarship on non-state actors and international institutions is relevant for\nunderstanding inter-DAO operations both between DAOs, and in the context of\nnational regulatory landscapes.\nStudying DAOs is also useful for theorizing about how technological inno-\nvations might transform transnational interactions between nation states and\nnon-state actors.\nWithin political science, the sub\ufb01eld of international rela-\ntions (IR) examines why, and how, states and non-state actors interact. This\ninvolves interactions between sovereign states, as well as interactions between\nnon-state actors across international borders. Between states, these interactions\ninclude war, trade, and diplomacy. Non-state actors include intergovernmen-\ntal organizations, multinational corporations, multilateral \ufb01nancial institutions,\ninternational non-governmental and humanitarian organizations, transnational\ndiaspora communities, drug cartels, and armed resistance groups. A core as-\nsumption of IR is the anarchic nature of the international system - states regu-\nlate themselves without a central governing body, or without a \u201cworld police.\"\nDAOs similarly face questions about governing in the absence of a pre-existing\ncentral governing body.\nWith cross-chain interoperability protocols such as Layer Zero or IBC en-\nabling interactions between chains, can we think of chains functioning as self-\ngoverning, decentralized platforms themselves, connected by bridges?\nWhat\ndetermines coalition formation in these ecosystems, and what is the role of\ninter-chain, or inter-DAO governance? Could lessons from global governance be\napplied here? Just as the League of Nations was formed to hold nation-states ac-\ncountable,and for example regional trade commissions, global health bodies, or\nthe international criminal court were designed to pool expert knowledge and en-\nforce common norms, DAOs also grapple with balancing expert knowledge and\ncentralized accountability with individual autonomy and representation. An in-\nteresting framework might connect parallels between interactions of states and\nnon-state actors in the international system, with interactions between DAOs\n53\nand L1 and L2 protocols, forming alliances and coalitions, and facing similar\nquestions about balancing the desire for expert knowledge and centralized ac-\ncountability with the desire for autonomy and representation.\nMoreover, scholars have argued that globalization and the proliferation of\nnon-state actors in recent decades has led to the erosion of power and sovereignty\nof the traditional Westphalian nation state (Keck and Sikkink, 1998). While\nsome early IR scholarship focuses on the use-case of cross-border payments via\ncryptocurrencies [210, 74], many open questions remain about how DAOs - and\nthe underlying blockchain tech more broadly - might reshape how we think\nabout cooperation, governance, and power in the international system.\nThe above paragraphs highlight fruitful avenues for connecting research on\nDAO governance to existing scholarship on formal, informal, or global gover-\nnance. In addition to both theoretical and empirical advances scholarship on\ngovernance, political institutions, and civic behavior, studying DAOs o\ufb00ers an\nadditional important output: Understanding DAO governance could also poten-\ntially inform the design of new digital processes for online civic engagement and\nassembly. While other aspects of society have rapidly digitized, political institu-\ntions continue to employ processes designed for pre-digital times. The reason for\nholding national political leaders accountable only every 2-4 years, for example,\nis essentially a technology problem and there is arguably little reason to believe\nexisting systems for representation, accountability, civic participation, or even\nthe organization of nation states under the current Westphalian system will be\nimmune to digital disruption [35, 272]. Studying DAO governance o\ufb00ers the\nopportunity for scholars to combine centuries of political thought with lessons\nfrom the trial and error of early web3 collectives to build democratic political\ninstitutions for the future.\n7.6\nPolitical philosophy\nSummary: DAOs present far-reaching questions related to deliberation, justice,\naccess, fairness, representation, and self-determination in digital governance,\nnecessitating productive dialogue between political philosophers and DAO mem-\nbers to bridge the gap between traditional and techno-normative concepts. Ap-\nplying lessons from political philosophy will o\ufb00er insights into the complexities\nof the digital public sphere, civic foundations of discourse, and legitimacy in\ngroup action.\nConcepts, methodologies, and frameworks from political philosophy also\nspeak to contemporary issues raised by the presence of DAOs in digital gov-\nernance infrastructures. Though to date political theorists have shown little\ninterest in DAO-based governance, DAOs clearly raise questions on the nature\nof deliberation in the digital public sphere, justice, access to information, fairness\nand political equality, representation and participation, and self-determination.\nThe most important immediate work will need to be translational, such\nthat political philosophers and DAO members can speak to each other produc-\ntively. Currently, political theorists speak in highly technical terminology inher-\nited from a long tradition of normative and analytical thinking, whereas DAO\n54\nbuilders and members may describe their work using inventive lexicons native to\nthe blockchain space. A signi\ufb01cant contribution to the literature on DAOs would\ntranslate between traditional concepts in political philosophy (such as equality,\nliberty, non-domination, and reciprocity), and what some have called \u201ctechno-\nnormative concepts,\" cited as desirable by builders and community members\n[7]. This parallels early work on AI ethics and on bioethics.\nAs an operative medium for social organization and coordination, DAOs\nraise questions around the emerging role of the digital public sphere. Research\nin this area might examine recent experiments in e\ufb00orts in more healthy, demo-\ncratic digital conversations and decision making, such as Polis. Importantly,\nit\u2019s worth considering whether this \u201cdemocratization\" of digital conversations\nis having a collectivizing e\ufb00ect rather than simply empowering atomized indi-\nviduals. Research here might also turn to J\u00fcrgen Habermas\u2019s formulation of\nthe public sphere [134] and recent work looking at Habermasian approaches to\ndigital technologies and the digital possibilities (and perils) of healthy, delib-\nerative democracy. Further research in political thought on DAOs might ask\nwhether traditional models of deliberative democracy su\ufb03ce in capturing the\ncomplexities of the digital public sphere and whether DAOs o\ufb00er new techno-\nlogical means to empower individuals to collaborate as political, economic, and\nsocial equals as members of collective decision-making bodies.\nAmong the key concerns of contemporary and 20th century political philos-\nophy, riding on the coattails of the Rawlsian tradition in A Theory of Justice\n[236], are questions of distributive justice. These concern the fair distribution\nof bene\ufb01ts and burdens of social cooperation and mutual reciprocity in a so-\nciety of individuals with competing needs and claims. Building on Ciepley\u2019s\nwork on political theorizing about corporations [76], DAOs cannot be satisfac-\ntorily assimilated to the dichotomous categories that form the basis for liberal\npolitical theorizing, such as public/private, government/market, state/society,\nprivilege/equality, and status/contract. DAOs may require political theorists to\ncarve out a new set of rules and norms of regulation that address \u201cmeso-level\"\ninstitutions. First o\ufb00, can we even apply existing theories of distributive justice\nto questions of DAO governance? If so, what counts as a distributive good in\nDAOs (e.g. tokens as \ufb01nancial compensation or reputational markers, social\nbases for self-respect) and according to what criterion of justice should these\ngoods be distributed (e.g. equality, desert, market forces)? There also arises\nthe question of global territorial scope [63, 212, 275] and of justice in produc-\ntion or \u201cproductive justice\" [273]. Can DAO members be compelled to work to\nproduce primary goods whose principles of distributive justice, if any, governs\nto be produced? What principles should govern the production of such goods in\nDAOs and to what degree ought such principles incur obligations (of work) on\nDAO members? What are the conditions of DAO membership as an analogue\nof citizenship?\nProvided that members of a DAO span various cross-cultural identities that\ninclude a plurality of geographies, citizenships, and political a\ufb03liations, ques-\ntions arise on the civic foundations of discourse across boundaries of di\ufb00erence.\nSome scholars cite the importance of egalitarian pluralism as a starting ground\n55\n[7, 150]. We must ask questions about how DAOs raise both opportunities for\nindividuals to act as decision-making equals in political and economic forums.\nPerhaps, we must challenge the presumption that token-based participation in\nDAOs, even in theory, can o\ufb00er robust conditions of political equality such as\nthose demanded by Danielle Allen\u2019s recent interpretation and critique of Rawls\n(Allen, 2023).\nAnother potentially fruitful area for research in political philosophy centers\naround questions of legitimacy and group action. DAOs provide a unique cross-\nnational medium for the technological constitution of groups. Recent work in\npolitical philosophy has suggested that democratic legitimacy is not simply a\ndescriptive, positivistic notion, but is deeply normative [11, 178]. Much of this\nwork centers around questions about the possibility and de\ufb01nition of group\nactors and group agency. Philosophers might seek to de\ufb01ne more formally the\nconditions under which decision-making in and by DAOs can be legitimate.\nEven further, philosophers might study DAOs as potentially novel structures\nfor collective decision-making which shed light on traditional work on group\nagents.\n56\n8\nMajor coordination problems\nEditors: Helena Rong and Joshua Tan. Contributors: Helena Rong,\nJoshua Tan, Jonathan Dotan, Ryan L. Thomas, Kevin Owocki, Ar-\niana Fowler, Scott Moore, Benedict Lau.\nDAOs and digitally constituted organizations have been the subject of ex-\ntraordinary hype; various boosters have advertised them as \u201cchanging the way\nwe work\u201d or as \u201cthe next generation of organizations\u201d\u2014including this essay\u2019s own\nabstract. This is a problem not only for colleagues outside the \ufb01eld trying to sift\nfact from hyperbole but also for researchers and builders whose contributions\nare held up against unrealistic expectations.\nIn lieu of hopes and hype, we de\ufb01ne a set of clear coordination, collective\naction, and social problems that DAOs and other social technologies may be\nable to solve. These problems are well-understood to be hard and without good\nsolutions. Solving them would help not only mark a signi\ufb01cant contribution to\nsociety but help validate some of the claims of the technologists to those not\nalready convinced. Failing to solve these problems would also mark a signi\ufb01-\ncant contribution to knowledge insofar as the failures clearly demonstrate the\nlimitations and relative \ufb01t of di\ufb00erent types of solutions for di\ufb00erent types of\nproblems.\nThe problems, in short, are:\n1. Sustaining open-source software\n2. Democratic governance of arti\ufb01cial intelligence\n3. Regenerative \ufb01nance\nEach problem, organized into subsections below, highlights a major coor-\ndination, collective action, or social problem and a survey of recent work to\naddress them, including but not limited to work in the DAO space. Each prob-\nlem is accompanied by a set of clear success criteria modeled on the XPRIZE5\nstructure, with the broad caveat that complete success is hard to de\ufb01ne in these\ncomplex problem domains.\nIn evaluating success, we have sought to choose\nmetrics and indicators that are concrete, persuasive, and sustainable.6\nWhile we have curated problems where some form of social coordination or\ncollective action failure is the sticking point\u2014and where technological solutions\nseem promising\u2014many of these problems admit solutions that have nothing to\ndo with DAOs and even nothing to do with coordination per se (e.g. by sharply\n5XPRIZE is a non-pro\ufb01t organization that hosts public competitions aimed at encouraging\ntechnological development to bene\ufb01t humanity. See https://www.xprize.org/.\n6By concrete, we mean that a metric has a de\ufb01nite and measurable answer that is not\ndependent on subjective judgment.\nA concrete metric is often but not always numeric or\ncategorical. By persuasive, we mean that the metric should be able to communicate success\nto the general public; genuine success along a metric should \u201cpop\u201d to the public. Finally, by\nsustainable we mean that a metric (or a slate of metrics, considered holistically) should be\nnot too expensive to collect and, ideally, collectible through automated means.\n57\nreducing the cost of a key process or increasing the availability of a scarce re-\nsource). We have tried to write evaluation criteria with this in mind. Sometimes,\nthe best way to solve a coordination problem is to sidestep it altogether.\n8.1\nSustaining open-source software\n8.1.1\nThe problem\nOpen-source software (OSS) is a multi-billion dollar industry and the backbone\nof major enterprise-level software products and services [256]. Values inherent\nto open-source, including peer review, open code contribution, and community\nfeedback, are now widely recognized as key catalysts for fostering innovation\nand ensuring software quality.\nDespite its role as critical infrastructure for\nmany devices and applications that form an integral part of our daily lives, OSS\nsu\ufb00ers from chronic underfunding and resource shortages; this has led to a crisis\nin its maintenance and sustainability [104].\nOpen-source software projects are largely volunteer-driven initiatives in which\ndevelopers join, cooperate, or cease contributing of their own volition. They face\nchallenges typical of public goods maintenance, notably the \u201cfree rider\u201d problem\nand the \u201ctragedy of the commons\u201d, where individuals bene\ufb01t from OSS without\ncontributing to its maintenance, placing an undue burden on those who do [248].\nThis volunteer-driven model often leads to the problem of contributor burnout,\nespecially among key maintainers, resulting in a disproportionate distribution\nof resources and e\ufb00ort. For instance, although the top 1000 projects on the\npopular OSS hosting site GitHub show an average of around 80 contributors\n[23], many other projects\u2014including critical digital infrastructure [319]\u2014are\nmaintained by just one person, often the overstretched founder of that project.\nAs OSS becomes increasingly global, its coordination challenges further grow\nexponentially. These complexities can become particularly pronounced when\nlarge companies and states, losing either interest or capacity, fail to continu-\nously support OSS projects. This situation is exacerbated when these entities\nthemselves adopt free rider behavior at an institutional level, similar to individ-\nuals. As a result, these public goods face severe coordination failures, despite\ntheir ability to generate substantial positive externalities for increasingly large\npopulations. This dichotomy between the immense impact of OSS and the lack\nof adequate support and coordination mechanisms underscores the urgency of\nthis crisis. The question becomes: what can we do to help sustain this unique\nclass of public goods given the value they continue to create?\n8.1.2\nCurrent progress\nFOSS foundations such as the Linux Foundation, Apache, NumFOCUS, and\nPython o\ufb00er critical support and guidance by leveraging their extensive expe-\nrience and understanding of common challenges faced by OSS projects. They\nprovide a range of services including mentorship, formal incubation processes\nfor new projects, project operations, tooling, training, and even legal and IP\n58\nmanagement. These services help OSS projects navigate complex issues like\ngovernance, asset management, and community growth.\nIn terms of management tooling, Open Collective provides crucial support\nfor open-source projects by managing the administrative burdens associated\nwith grant-funded work. This includes handling the complexities of grant re-\nporting, tracking success, and maintaining or \ufb01nding suitable charitable enti-\nties to support projects, thereby allowing developers to focus more on their\ncore project activities without the overhead of administrative tasks. An often\nunder-appreciated fact about Open Collective is that the \ufb01scal sponsorship path\ne\ufb00ectively gives open source projects access to a bank account\u2014similar to the\nuse-case for a multisig or certain DAOs.\nOther e\ufb00orts, from new OSS licenses to new donation systems, o\ufb00er ways\nto protect and shape the incentives of OSS contributors.\nFor example, the\nCryptographic Autonomy License (CAL) protects user autonomy by ensuring\nusers have control over their data and the software they use, while the Server\nSide Public License (SSPL) introduced by MongoDB is designed to ensure that\nif a service provider leverages the software to deliver services, they must also\nshare the service\u2019s entire source code under the same license, thus promoting\ntransparency and fairness in the use of OSS. With respect to funding, GitHub\nSponsors is an example of a platform that facilitates community-driven \ufb01nan-\ncial support, allowing individual developers and organizations to receive direct\ncontributions from those who value their open-source work.\nIn the DAO ecosystem, a key focus has been developing e\ufb00ective ways to re-\nward contributors fairly and promoting more equitable ownership. Many DAOs\nare experimenting with community currencies [4] to deter free-riding and ensure\nbalanced opportunities for voice and exit [32]. These currencies enable contrib-\nutors\u2014whether they are coding, supporting, or adding value in other ways\u2014to\nengage in the governance of these organizations. Some may even gain from\nthe broader adoption and application of the projects they contribute to, thus\nnurturing a more sustainable and participatory ecosystem.\nDAOs like Gitcoin and Optimism have made signi\ufb01cant progress towards\n\ufb01nding new models that allow any group to curate, evaluate, and consequently\nallocate capital to developers that do not necessarily have any immediate \ufb01-\nnancial return but have a signi\ufb01cant impact on the ecosystems they exist in.\nDevelopers are funded based on their impact either as judged by community\nsentiment through quadratic funding (as in the case of Gitcoin) or by expert\ndecision-makers curated via a web of trust (as in the case of Optimism). Both\nmodels have their trade-o\ufb00s but fundamentally deviate from prior grants-making\nprocesses typically led by closed-ended and opaque committees rather than open\ncommunities. In the case of Gitcoin, the platform has conducted tests across\nover one hundred distinct grant pools, collectively distributing over 50M USD.\nThis signi\ufb01cant funding milestone was achieved in partnership with prominent\norganizations, including the Ethereum Foundation and UNICEF. Among the\nfunded projects are notable entities like the Electronic Frontier Foundation,\nInternet Archive, Uniswap, and WalletConnect.\n59\n8.1.3\nSuccess criteria\nThe criteria de\ufb01ned below are intended to capture results over a one-year pe-\nriod for a particular cohort of open-source projects. We expect all open-source\nprojects included in the evaluation to:\n\u2022 Have a working code.\n\u2022 Have published code under a widely accepted open-source license, e.g., the\nMIT License or a Creative Commons license.\n\u2022 Have at least 50 stars on GitHub, GitLab, or an equivalent metric as a\nmeasure of user adoption.\n\u2022 Have at least one active maintainer who has created or resolved an issue.\nProposal criteria\nThe following criteria are intended to help teams de\ufb01ne\nand plan their solution. It may also be used by funders considering proposals\nthat promise to address open-source sustainability.\nCriteria\nDescription\nEvaluation Metric\nContributor\nsustain-\nability\nQuality\nand\nparticipation\nrate\n(over time) of contributors\nThe planned solution must create a path for contributors to take part\nin the decision-making and direction of the project.\nMaintainer\nsustain-\nability\nQuality\nand\nparticipation\nrate\n(over time) of maintainers\nThe planned solution must account for the maintainer\u2019s participation\nover time, productivity, satisfaction with the solution, and burnout.\nGovernance\nsustain-\nability\nContribution of non-code contri-\nbutions\nThe planned solution must allow all participants to contribute to the\ngovernance of the software.\nFinancial sustainabil-\nity\nMonetary incentives and \ufb01nancial\nsupport of the project\nThe planned solution must include a way to reward contributors and\nmaintainers for continued motivation to build value for the project.\nTable 1: Proposal criteria\nImplementation criteria\nThe following implementation criteria cover met-\nrics that need to be evaluated on any implementation of the solution or inter-\nvention. Note, we expect proposals to evolve over the course of implementation.\n60\nCriteria\nDescription\nEvaluation Metric\nUser adoption\nGrowing number of users\nThe user base of the OSS project (across all forks) does not decline over the\ncourse of implementing the solution.7\nContributor\nsustain-\nability\nParticipation rate over time\nof contributors\nFor 75% of projects in the cohort, the average participation rate (measured\nin submitted PRs, comments, contributions, and all other interactions with\nthe repository) of all active contributors increases by at least 25%.\nNew contributors\nFor 75% of projects in the cohort, the number of active contributors does\nnot decline. An active contributor is a person who actively submits PRs,\ncomments on issues, or contributes to discussions within a 3-month window.8\nQuality of commits by new\ncontributors\nNew contributor pull requests must be of high quality, meaning (1) more\nthan 75% of PRs of new contributors are eventually merged, and (2) less\nthan 5% of code in the PR needs to be revised before merging.\nOnboarding speed\nThe average time between a new contributor\u2019s \ufb01rst interaction with the\nproject (de\ufb01ned as starring, forking, or posting an issue), and their \ufb01rst\nPR, is less than 30 days.\nMaintainer\nsustain-\nability\nParticipation over time\nFree the maintainer: Aim for 75% of the maintainers to report increased\n\ufb02exibility in their engagement with contributors and projects within a 3-\nmonth period.\nCommit to the commit: Within 6 months, 75% of maintainers should have\nestablished and communicated clear guidelines for contributor engagement\nand responsibility acceptance.\nProductivity\nThe ratio of issues being opened to issues being closed over a 3-month time\nspan is no greater than 2:1.\nSatisfaction with solution\nAfter 10 months, at least 70% of maintainers should respond neutrally to\npositively about their experience with the solution.\nBurnout\nAfter 10 months, at least 70% of maintainers should rate \u201cgood\" or \u201cexcellent\"\non the survey question about their work-life balance.\nGovernance\nsustain-\nability\nIncentive structures\nRaise the value of non-code contributions: Recognizing and elevating\nthe contributions of all project participants will legitimize their concerns,\nraise their pro\ufb01le, leverage the same motivations that lead developers to\ncontribute, and create stronger software that is the product of a more diverse\nrange of perspectives and skills.\nFinancial sustainabil-\nity\nFinancial\nsupport\nand\n\ufb01-\nnance management\nUse money as an incentive for open source: Provide a stable foundation\nof support while enabling contributors and maintainers to continue to build\nvalue within projects.\nRecognize, value, and invest in OSS: After 10 months, at least a 50%\nincrease in project funding will be conditional on the project\u2019s value.\nLower barriers for open source projects to manage \ufb01nances: Pro-\nvide mechanisms to simplify \ufb01nancial management processes for open source\nprojects to enhance accessibility and e\ufb03ciency.\nTable 2: Implementation criteria\nScale criteria\nIn addition to the implementation criteria above, a successful\nsolution must be scalable.\nCriteria\nDescription\nEvaluation Metric\nScale\nTeams must scale their so-\nlutions\nto\nas\nmany\nOSS\nprojects as possible within\n10 months.\nThe target population size will be at least 1000 contributors across at least\n20 OSS projects.9\nTeams will be evaluated based on the criteria from Round 2.\nTable 3: Scale criteria\n61\n8.1.4\nRationale\nIn de\ufb01ning the cohort, we expect that by selecting projects that already demon-\nstrate a foundational level of engagement and quality\u2014evidenced by working\ncode, recognized licensing, a minimum user adoption rate, and active mainte-\nnance\u2014we can establish a fertile ground for testing and enhancing sustainability\nsolutions for OSS. The rationale behind these criteria is to focus on projects that,\nwhile already valuable and impactful, are at a crucial juncture where strategic\ninterventions can signi\ufb01cantly bolster their long-term viability and e\ufb00ectiveness.\nUser adoption is a critical indicator of a project\u2019s relevance and potential for\nbroader impact, guiding our e\ufb00orts toward those initiatives most likely to bene\ufb01t\nfrom and contribute to the overarching goals of open-source sustainability.\n8.2\nDemocratic governance of arti\ufb01cial intelligence\n8.2.1\nThe problem\nArti\ufb01cial intelligence (AI) is quickly becoming an integral part of the modern\nworld. By 2030, it is estimated that AI could contribute up to $15.7 trillion to\nthe global economy [235], impacting all industries and societies with new forms\nof automation and e\ufb03ciency.\nHowever, as AI\u2019s impact and importance grow, so do the coordination prob-\nlems related to its creation and governance. Training e\ufb00ective AI algorithms\u2014including\nbut not limited to large language models (LLMs) and other foundation mod-\nels\u2014requires a collaborative e\ufb00ort among various stakeholders, including re-\nsearchers, engineers, and entrepreneurs. Ensuring AI is responsible and equi-\ntable requires these same experts to work together with end-users and society\nat large to provide the feedback needed to set guardrails that render AI safe\nand inclusive.\nThe problem of governing AI, as we de\ufb01ne it here, is thus the problem of\nspecifying and implementing a multi-party, federated, and iterative endeavor.\nThis endeavor is multi-party insofar as it spans many entities, roles, and domains\nof expertise. It is federated insofar as it integrates intelligence across ecosystems\nof di\ufb00erent vendors and entities that provide data, code, and infrastructure. And\nit is iterative insofar as it is constantly evolving as it adapts to the ever-changing\nrequirements of creators and end-users.\nAdditional considerations for democratic AI\nThe unprecedented adop-\ntion of generative AI has been led by transformative LLMs that consume un-\nprecedented amounts of computing and data. In this opening stage of main-\nstream AI, the most performant foundational models are being released by ei-\nther the most valuable corporations in the world, their a\ufb03liates and investees,\nor nation-states. Together they have formed a powerful monopsony over AI\ninfrastructure. The concentration of power in just a handful of entities has cre-\nated critical vulnerabilities in the safety and e\ufb00ectiveness of the most dominant\nAI models. Even open-source AI projects released by these companies have not\nsolved the problem, as nearly all do not open-source their training data.\n62\nLike prior technology eras, the fear is that a lack of competition can lead\nto market distortions, more brittle products, and slower innovation. As Tim\nO\u2019Reilly put it, this \u201cdark pattern\u201d ensures that the market no longer picks\nthe winners, but instead delivers \u201cunequal returns to entrepreneurs, investors,\nand society\u201d [218]. A new concern, driven by geopolitics, is that these same\nlarge companies could be pushed and subsidized by governments to prioritize\ncompetition over greater societal norms, such as protecting privacy and mini-\nmizing bias. While AI accountability is taking shape with national-state-level\nregulations, many new laws are vague and do not prescribe speci\ufb01c actions for\ncompliance or enforcement. Further, it is not clear, even with more precision in\nregulation, that practically responsible AI can be enforced from the top down.\nFurther, this logic leaves unquestioned a prevailing myth that only large AI\nmodels can and will be e\ufb00ective. We see, instead, smarter AI can follow the\nlogic of \u201csubsidiarity\u201d that scholars such as Amy Hasino\ufb00and Nathan Schneider\npersuasively argue allows local social units to have meaningful autonomy to\npromote local social goals and push out the gains of AI to its members [140].\nThe responsibility of preventing and addressing harm is therefore accountable\nto the people who are most directly a\ufb00ected. Context-sensitive AI governance\ncan then scale across larger networks through federalist or polycentric forms of\ncommunity [287]. Instead of one distorted market, decentralized AI markets can\nsyndicate and amplify di\ufb00erent norms, rules, and objectives. Self-sovereign AI,\ncreated in a community is best positioned to represent the perspectives of its\nconstituents and participants.\nThese considerations motivate us to focus on a speci\ufb01c class of decentral-\nized, democratic, and bottom-up approaches to AI governance in this problem\nspeci\ufb01cation. We believe DAOs and other coordination technologies can sustain\na new, bottom-up form of AI governance that is more responsive and repre-\nsentative of the stakeholders impacted by AI. Indeed, supporters of bottom-up\nAI governance have argued that DAOs could easily pool capital and resources\nto scale and compete with AI giants with more purchasing power [227]. This\nshort-term win might inject new competitive vigor into AI markets to make\ntraining and inference more a\ufb00ordable and democratic.\n8.2.2\nCurrent progress\nSocial coordination research, as applied to AI governance, shapes how demo-\ncratic AI might work in practice. For example, constitutional AI approaches,\npioneered by Anthropic, align AI algorithms to a set of pre-determined prin-\nciples that they are benchmarked against [19].\nThese pre-de\ufb01ned rules give\nauditors, regulators, and end-users a clear view of which choices were made\nduring model training. Alignment assemblies go one step further in bringing\na democratic process to forming constitutions for AI through collective input\nthrough conversations about user needs and goals for AI [124].\nDAOs o\ufb00er a powerful structure to coordinate these activities to create re-\nsponsible AI by using cryptographic primitives to underwrite a new layer of ver-\ni\ufb01ability across the entire AI lifecycle. By knowing what each party contributed\n63\nto AI development and tracing that impact from training to inference, new forms\nof incentives, coalition building, and value creation are unlocked. DAOs can also\naction business logic on veri\ufb01able credentials, zero-knowledge proofs, and other\ncryptographic artifacts that can bind and audit AI governance frameworks. Fi-\nnally, by establishing veri\ufb01able custody and attribution for contributions to AI\nmodels, DAOs could be the most e\ufb03cient corporate structure to reward the\ncontributors to AI algorithms, thereby arriving at the most accurate value of\nself-sovereign AI assets in the next generation of AI-focused marketplaces.\nPutting some of these ideas into practice, the \ufb01rst AI DAO legally registered\nis the Endowment of Climate Intelligence (ECI). Formed in March 2024, the ECI\ngoverns ClimateGPT: an ensemble of the \ufb01rst task-speci\ufb01c open-source LLMs\nand benchmarks on the impact of climate change [288]. The DAO is registered\nas a DLT Foundation in the Abu Dhabi Global Market free trade zone and\nuses new cryptographic methods to create new binding and legally enforceable\nsmart contracts. Through successive steps of progressive decentralization [106],\nthe ECI brings together AI engineers, climate change experts, civil society, and\nenterprises in working groups to re\ufb01ne and govern the model. As a cryptographic\ncoordination layer, the DAO serves three purposes: \ufb01rst, it bootstraps and\noperates a private ledger that registers machine and human attestations across\nthe AI development lifecycle; second, it coordinates the policies and rules of the\nEndowment; and third, it enables collective ownership, custody and governance\nof the Endowment as it seeks to reinvest royalties from paid access to the models.\nThe ECI\u2019s design as a distributed governance organization is intuitive be-\ncause of its mission. Climate change is a global problem that will only be solved\nwith cooperation from stakeholders from across the world. As a pioneering AI\nDAO, the ECI is primed to set the pace for collective AI governance. It does this\nby \ufb01rst organizing an array of motivated parties to pool the capital to procure\ncompute powered by renewable energy and recruit the engineering talent needed\nto train the foundational model best. The ECI then seeks to facilitate binding\nguidance from expert and local stakeholders impacted by climate change to cu-\nrate training, instruction \ufb01ne-tuning, and RAG datasets that help ensure the\nquality and inclusivity of the model. Examples include expert aggregation of\nhigh-quality open science research alongside Creative Commons to both meet\nquality levels and respect fair-use copyright terms. Of equal importance is the\ninclusivity of the model to build into the inference the views of climate change\nactivists that may have been underrepresented in traditional model training. For\ninstance, the DAO is making a careful e\ufb00ort to include indigenous or inner-city\nyouth\u2019s perspectives in the model that are often overlooked.\nFinally, the ECI uses DAOs to manage revenue in a treasury. A percentage\nof \ufb01at proceeds from paid commercial revenue will then \ufb02ow back to the ECI to\n\ufb01nance subsidies of inference to quali\ufb01ed researchers and further model train-\ning. Similarly, cryptographic block rewards from cryptographic utilities, such as\nFilecoin and forthcoming systems like Gensyn and Fluence, that are used by the\nsystem are also brought back into the treasury. These royalties and rewards are\nreinvested to create new and more valuable versions of the model, which in turn\nproduce more royalties and block rewards. As a new kind of public utility, the\n64\nmodels can become a new class of AI regenerative endowments and/or bonds\n\u2014 sustainable in every sense of the term.\nThe ECI\u2019s regenerative non-pro\ufb01t approach points to possibilities for nascent\ncommercial AI marketplaces. In a community where the users and stakeholders\nown an AI algorithm, value is determined holistically. Growth gives way to more\nregenerative priorities such as loyalty, quality, safety, and specialization that\ncome with reinvestment in AI algorithms rather than solely extracting pro\ufb01ts.\nThis push towards a more pluralistic notion of AI governance will re\ufb02ect smarter,\nagile, safer, and more valuable forms of AI that can serve as commercial and\npublic goods.\nDAOs are, therefore, inspiring discussions on how to reimagine valuation\nmethods that can determine contributions to AI and syndicate them in a mar-\nketplace. For instance, beyond the canonical Shapley valuation method, Sim et\nal. propose three incentive conditions for revenue allocation: individual ratio-\nnality, stability of the grand coalition, and group welfare [267]. This opens up\nthe possibility for more metrics for value, such as loyalty and longevity of coor-\ndination. At best DAOs should spur many decentralized markets with di\ufb00erent\nnorms, rules, and objectives.\nThis is the true endgame for compliance: the\nformation of collective governance of AI that can simultaneously be syndicated\nacross various groups and be re\ufb01ned by di\ufb00erent stakeholders with di\ufb00erent\npriorities and incentives.\n8.2.3\nSuccess criteria\nThe criteria de\ufb01ned below are intended to capture results over a one-year period\nfor a particular cohort of responsible AI projects that intend to be governed as\na DAO.\nWe expect all responsible AI projects included in the evaluation to:\n\u2022 Set up a DAO-type governing infrastructure that allows for transparent\ncoordination of the creation, evaluation, and maintenance of an AI system.\n\u2022 Have at least 5 active members in the DAO.\n\u2022 Have trained, published and deployed a model that can be accessed on an\nopen source platform such as HuggingFace.\n\u2022 Have responsible AI technical documentation for the AI by system, includ-\ning model card and evidence of a responsible AI framework implementa-\ntion.\n\u2022 Use cryptographic methods to generate veri\ufb01able attestations across the\nentire AI lifecycle, including all data and source code, governance, and,\nwhere possible, compute.\nProposal criteria\nThe following criteria are intended to help teams de\ufb01ne\nand plan their solution. It may also be used by funders considering proposals\nthat promise to address responsible AI.\n65\nCriteria\nDescription\nEvaluation Metric\nResponsible\nAI\nsus-\ntainability\nQuality of responsible AI imple-\nmentation\nThe planned solution must implement responsible AI standards.\nAI system sustainabil-\nity\nQuality and usability of AI system\nThe planned solution must include a functioning AI model and appli-\ncation.\nDecentralized\ngover-\nnance sustainability\nQuality of governance infrastruc-\nture\nThe planned solution must implement a decentralized governance\nstructure, enabling the transparent coordination of the creation, eval-\nuation, and maintenance of an AI system\nAI\nlifecycle\ntrans-\nparency sustainability\nQuality and usability of documen-\ntation\nThe planned solution must provide thorough documentation and cryp-\ntographic attestations of the AI lifecycle, enabling third-party audits.\nContributor\nsustain-\nability\nQuality and participation rate of\ncontributors\nThe planned solution must encourage active participation from experts\nand impacted stakeholders.\nRepresentative gover-\nnance\nGovernance should be representa-\ntive of end-user concerns,\nespe-\ncially stakeholders who are most\nvulnerable to the model\u2019s impact\nThe planned solution should include special working groups for rep-\nresentatives of end-users and create mechanisms for feedback and\ngrievances to be registered and addressed.\nTable 4: Proposal criteria\nImplementation criteria\nThe following implementation criteria cover met-\nrics that need to be evaluated on any implementation of the solution or inter-\nvention. We expect proposals to evolve over the course of implementation.\nCriteria\nDescription\nEvaluation Metric\nResponsible\nAI\ncon-\nsideration\nResponsible AI framework\nFor 75% of projects in the cohort, clear implementation of an industry-\nstandard responsible AI framework must be provided.\nFunctional AI system\nModel\nFor 75% of projects in the cohort, an AI model repository must be published\non Github and Hugging Face, along with an open-source license.\nApplication\nFor 75% of projects in the cohort, an AI application using the published\nmodel must be deployed and made available to users.\nDecentralized\ngover-\nnance infrastructure\nGovernance\nstructure\nfor\ntransparent coordination\nFor 75% of projects in the cohort, a DAO-type governing infrastructure must\nbe established and documented. The governance structure must allow for\ntransparent coordination of the creation, evaluation, and maintenance of the\nproposed AI system.\nAI\nlifecycle\ntrans-\nparency\nDocumentation\nFor 75% of projects in the cohort, documentation regarding the AI lifecycle\nmust be provided. This includes, but is not limited to, a model card with\nsubstantial evaluation results.\nCryptographic methods are encouraged to\ngenerate veri\ufb01able attestations across the entire lifecycle, including all data\nand source code, governance, and, where possible, compute.\nUser adoption\nGrowing number of users\nThe user base of the AI model does not decline over the course of implement-\ning the solution.\nContributor\nsustain-\nability\nParticipation of experts\nFor 75% of projects in the cohort, clear working groups are established for\nexpert contributions to the model, and the average participation rate of both\ntechnical and domain experts (measured in active membership and active\nvotes on governance proposals) increases by at least 25%.\nStakeholder feedback\nFor 75% of projects in the cohort, clear working groups are established for\nstakeholders to help \ufb01ne-tune the model and set automated and human\nbenchmarking (such as reinforcement learning from human feedback). Stake-\nholder groups should have proper representation for end-user viewpoints and\nunderstanding of trust and safety concerns and have active contributions to\nworking groups (measured in active membership and votes) increased by at\nleast 25%.\nTable 5: Implementation criteria\n66\n8.3\nRegenerative \ufb01nance: Toward a sustainable and equi-\ntable planetary economy\n8.3.1\nThe problem\nTraditional \ufb01nance and investment models are primarily concerned with, and\ngenerally legally obligated to ensure maximizing shareholder returns, often at\nthe expense of the environment and marginalized communities. The \ufb01nancial\nsystem frequently overlooks the need to invest in realizable activities that regen-\nerate natural capital, such as reforestation and carbon removal, or social capital,\nsuch as community development and equitable access to credit. This has resulted\nin substantial inequalities, environmental degradation, and economic instabil-\nity. Regenerative Finance (ReFi) is a relatively new concept-turned-movement\nthat seeks to address these inherent \ufb02aws in the existing \ufb01nancial system.10 A\nkey distinction between extractive economic systems and regenerative economic\nsystems is that while the former assigns value to the consumption of CPRs, such\nas natural assets and increases pro\ufb01ts for a few individuals, the latter seeks to\nassign value to the protection and regeneration of these assets where the pro\ufb01t\nof their exchange is distributed fairly.\nReFi can be thought of in terms of \u201cbig problems\" and \u201csmall primitives.\"\nThe \u201cbig problem\" ReFi intends to address is to build a more ecologically and\nsocially sustainable alternative in governing global CPRs. In essence, the ReFi\nmovement seeks to encourage ecological restoration, social justice, and economic\nresilience by aligning \ufb01nancial incentives with the principles of sustainability, eq-\nuity, and plurality; thus promoting a symbiotic catallaxy between nature and\npeople, galvanized by primitives that support a viable planetarity. ReFi poses\nitself to address these multifaceted, planetary scale issues through the microeco-\nnomic use of fundamental cryptoeconomics tools and coordination mechanisms,\nwhich are colloquially called \u201cprimitives.\" In what ways can we build tools for\nmore positive-sum games that increase resource capacity? This refers to not\nonly \ufb01nancial resource capacity, but across the eight types of capital, includ-\ning\u2013natural, \ufb01nancial, material, intellectual, experiential, social, cultural, and\nspiritual [225]. Using small primitives that agglomerate to resolve big problems,\nReFi aims to challenge a speculative, extractive, and ultimately harmful status\nquo at the macroeconomic level. This is to say that to be \u201cregenerative,\" proto-\ncols, mechanisms, and organizations must themselves address harms generated\nby traditional \ufb01nance and investment models in the capitalist system. This con-\ncept intentionally works to restore faith in operations of many enterprises that\n10The underlying concept of this approach traces its roots to \"Regenerative Capitalism,\" a\nterm \ufb01rst coined by economist John Fullerton in 2015 [CITE fullerton_regenerative_2015].\nThough Fullerton did not originally link his concept to decentralized technologies, his eight\nprinciples of a regenerative economy\u2013(1) in right relationship; (2) views wealth holistically;\n(3) innovative, adaptive, responsive; (4) empowered participation; (5) honors community and\nplace; (6) edge e\ufb00ect abundance; (7) robust circulatory \ufb02ow; and (8) seeks balance# have since\nbeen adopted by impact-oriented professionals within the Web3 space. These practitioners\nhave used Fullerton\u2019s principles to construct systems that promote behaviors that enhance\noverall systemic health and discourage actions that cause its deterioration.\n67\ncan fundamentally provide technical utility while resolving these externalized\nharms through systemically positive-sum dynamics.\nIn a recent analysis and report by Carbon Copy on The State of ReFi in Q1\n2024, written in coordination with ReFi DAO, the authors state, \u201cAt a more\npractical level, ReFi can be described as Web3-powered ecological and social\nimpact.\nIn other words, taking the available Web3 solutions \u2014 blockchain,\ncryptocurrency, smart contracts, and decentralized autonomous organizations\n(DAOs) \u2014 and combining them with other modern technologies to build solu-\ntions that address our systemic issues\" [86]. The key assertion in this consensus\namong many varied de\ufb01nitions of this concept is the addressing of systemic\nissues, not just providing novel utilities atop of their faults.\nFor some within the broader collective of ReFi organizations, developers,\nand evangelists, the de\ufb01nitions presented are still narrow, albeit broad in their\nscope. This is because there is a signi\ufb01cant bottom-up, grassroots, and often\nsubaltern base from which ReFi can be viewed. Bottom-up in the sense that\nthe primitives being developed are reinventing basic fundamentals of traditional\n\ufb01nance that are taken as given. Some may include crowdfunding protocols for\nallocating capital based on community ampli\ufb01cation, or mechanisms for disburs-\ning funds for those who do provable virtuous actions, or providing transparent\nretroactive certi\ufb01cations of promissory actions to come, among many other novel\nprimitives. Through ReFi as a movement, extractivist goods and transactional\nservices become public goods and services to the planet. The grassroots and\nsubaltern state of many of these e\ufb00orts is given that several signi\ufb01cant projects\nin this vein are being developed in the Global South, by people whose actions\nhave been usually beyond the tunnel vision of Silicon Valley startup funders\nand multinational corporate investment \ufb01rms. ReFi has become a platform for\ntypically unsung innovations in the traditional \ufb01nancial system. This said, there\nare still areas of concern regarding coordination in the current state of ReFi,\nbeyond those addressed in the aforementioned report. These include succumb-\ning to what we are calling the \u201caccelerationist trap,\" the risk of virtue signaling\nturning into virtue noise, and a lack of cohesive standard setting between TradFi\nand ReFi.\n\u2022 Sustainability bolstering the accelerationist trap11: As the ReFi\nmovement gains momentum, there\u2019s a risk of falling into the \"accelera-\ntionist trap\" where rapid scale and \ufb01nancial pro\ufb01t motives overshadow\nthe core principles of regeneration, and sustainability becomes a basis for\nattracting venture capital without proof of impact. This could lead to\n11\u201cSustainability\" itself has been a tenuous term for traditional \ufb01nance, as its most agreed\nupon de\ufb01nition was established in the 1987 Report of the United Nations World Commission\non Environment and Development, titled Our Common Future, but more commonly known\nas the Brundtland Report [217].\nThe report has de\ufb01ned sustainable development as, \u201cde-\nvelopment that meets the needs of the present without compromising the ability of future\ngenerations to meet their own needs\" (ibid). This basis established the terms used by the UN\nwhich transcended their Millenium Development Goals toward their more current Sustainable\nDevelopment Goals (SDGs) and yet the fundamental practices of sustainable development\nused by global governance has not changed in nearly 40 years.\n68\nprioritizing short-term gains over long-term ecological and social values,\npotentially replicating the same dynamics criticized in traditional \ufb01nance\nby the ReFi movement.\n\u2022 Virtue signaling becoming virtue noise:\nIn the ReFi space, the\nprevalence of virtue signaling\u2014where entities proclaim their sustainabil-\nity e\ufb00orts more for marketing than impact\u2014can degrade into \"virtue\nnoise,\" where the abundance of unsubstantiated claims drowns out genuine\nprogress.\nEnsuring accountability and transparency through veri\ufb01able\nmetrics, such as \u201cProof-of-Virtue,\" and \u201cProof-of-Useful-Work (PoUW)\"\nis essential to prevent this drift [18].\n\u2022 Standard setting between TradFi and ReFi: The ReFi movement\nfaces challenges establishing cohesive standards that align with traditional\n\ufb01nance (TradFi) systems. For example, in the realm of the carbon mar-\nket, the challenges of price discovery, accounting, and the quality of carbon\ncredits are re\ufb02ective of the broader issue of inconsistent standards [241].\nWithout uni\ufb01ed frameworks, ReFi initiatives struggle with interoperabil-\nity and recognition in broader \ufb01nancial markets, hampering their e\ufb00ec-\ntiveness and scalability. There is a signi\ufb01cant need to develop common\nstandards that could bridge the gap between innovative ReFi mechanisms\nand established \ufb01nancial protocols.\nDespite these challenges, however, the ongoing exploration of ReFi re\ufb02ects\nits potential to bring about a signi\ufb01cant transformation in our economic sys-\ntems, aligning them more closely with environmental and social sustainability\nobjectives. Given the current development of ReFI, we ask: How can we ef-\nfectively leverage the innovative tools and approaches of ReFi to ensure they\ntruly contribute regeneratively to sustainable development, rather than merely\nreplicating traditional \ufb01nancial systems\u2019 shortcomings under a new greenwashed\nguise?\n8.3.2\nCurrent progress\nCurrently, the ReFi movement seeks to achieve sustainable governance of CPRs\nthrough digital monitoring, reporting and veri\ufb01cation, asset tokenization, and\ndecentralized governance practices [251]. We identify two levels of interrelated\nprogress in the space: (1) coordinated \ufb01nancing and governance of CPRs; and\n(2) regeneration of CPRs through impact-oriented real-world projects.12\nSeveral Web3 innovations have emerged in recent years to address the chal-\nlenge of sustainably \ufb01nancing and governing CPRs. For example, Optimism\nhas played a crucial role in \ufb01nancing public goods through mechanisms like\n12Currently, there is a notable absence of Fortune 500 examples within the ReFi sector.\nThis is not necessarily indicative of the movement\u2019s e\ufb00ectiveness or ambitions. Rather, the\nfocus is on a collective of smaller, cohesive projects working synergistically toward common\nregenerative goals, which suggests that the strength of ReFi may lie in the aggregate impact\nof numerous smaller initiatives rather than the involvement of large corporate entities.\n69\nRetroactive Public Goods Funding (RetroPGF). This initiative demonstrates a\npioneering approach by distributing tokens to contributors based on the impact\nand value they bring to the ecosystem, rather than traditional upfront funding\nmodels. By doing so, Optimism incentivizes ongoing contributions to the de-\nvelopment and maintenance of public goods, aligning \ufb01nancial incentives with\nlong-term ecological and social bene\ufb01ts. Optimism is notable because of the size\nof the funding it allocates to public goods, but there are other, smaller players,\nwho are also innovating on creating \ufb01nancing for ReFi projects, such as Giveth,\nCLRfund, Gitcoin, and Artizen.\nSimilarly, HyperCerts o\ufb00ers a novel solution for the certi\ufb01cation of sustain-\nable impacts. These digital certi\ufb01cates are blockchain-based records that pro-\nvide veri\ufb01able proof of ecological outcomes, such as carbon sequestration or re-\nforestation e\ufb00orts. By making these certi\ufb01cations transparent and immutable,\nHyperCerts provides a \u201cproof-of-virtue\" mechanism and ensures that the envi-\nronmental bene\ufb01ts claimed by projects are indeed credible and traceable. This\ntransparency is crucial for building trust among investors and stakeholders, fa-\ncilitating more informed decisions in the \ufb01nancing of regeneration projects.\nThe new \ufb02ows of \ufb01nance into ReFi have helped sustain a new generation of\ninnovators who are using Web3 for regenerative ends. Many projects endeavor\nto bridge the gap between the tangible world and the \ufb01nancial sphere through\nthe creation, veri\ufb01cation, and valuation of token-based representations of real-\nworld assets (RWAs). By facilitating the creation and utilization of novel asset\ntypes (like natural resources), these projects propel economies toward progres-\nsion based on environmental guardianship and conscientious resource admin-\nistration. Projects like Open Forest Protocol (OFP) and Regen Network use\nblockchain to provide the infrastructure for transparent monitoring and report-\ning of environmental data in the carbon credit creation process, enhancing the\nmanagement of CPRs such as forestry projects. For instance, OFP enables var-\nious stakeholders, including environmental groups, corporations, and govern-\nments, to generate transparent, immutable, and veri\ufb01ed proof-of-impact data in\nreal-time. The project has partnered with organizations like Solid World, whose\noperations are on risk assessment and scoring carbon credit futures, to scale its\ne\ufb00orts in network expansion, market access, broadening the technological base,\nand diversifying funding sources with robust \ufb01nancial support mechanisms.\nAsset tokenization projects like Toucan, Flowcarbon, and KlimaDAO focus\non the tokenization of carbon credits, aiming to create a transparent, e\ufb03cient\nmarketplace for carbon trading, thus increasing market liquidity and providing\nveri\ufb01able tracking of carbon credit transactions. Expanding beyond the tra-\nditional carbon credits market, Kolektivo, a pilot initiative in Cura\u00e7ao, aims\nto tokenize natural assets such as food forests and coral reefs to promote lo-\ncal self-reliance and economic resilience in marginalized communities.\nUsing\nthe ReFi-focused Celo blockchain and the Astral Protocol, Kolektivo creates a\nDecentralized Exchange Trading System (DETS) that bolsters environmental\nresilience and addresses interdependent \ufb01nancial and biospheric risks. This ap-\nproach incentivizes the preservation of natural resources and broadens access to\ncarbon markets.\n70\nDespite these e\ufb00orts, most ReFi projects are limited to tokenizing carbon\nand nature credits to broaden the \ufb01nancialization of commodi\ufb01ed assets that\nare traded on markets to incentivize companies and individuals to lower and/or\no\ufb00set their carbon emissions. Although it is true that tokenization holds the\npromise of allowing companies to support public goods while capturing pri-\nvate value, potentially improving their reputation and customer relationships\nby integrating these tokens into stakeholder interactions, the sole focus on nat-\nural asset tokenization risks the perpetuation of an extractive economic model\nby commodifying nature, encouraging short-term transactions of carbon cred-\nits rather than fostering long-term sustainable investments. While tokenization\ncould alter corporate interactions positively, it might also maintain the status\nquo without truly regenerating the environment. Further research and deeper\nintegration with regenerative economics are necessary to ensure that ReFi con-\ntributes e\ufb00ectively to sustainable and equitable economic practices.\nAs such, we believe that future projects should engage more proactively and\nthoroughly with the \u201cregeneration\" aspect of regenerative \ufb01nance and provide\nsolutions that would genuinely promote long-term environmental sustainability\nand societal well-being.\n8.3.3\nSuccess criteria\nThe criteria de\ufb01ned below are intended to capture results over a one-year period\nfor a cohort of ReFi projects.\nWe expect all ReFi projects included in the evaluation to:\n\u2022 Have a clear de\ufb01nition of a common pool resource (CPR) that is to be gov-\nerned (whether it is tokenized carbon removal, renewable energy, nature-\nbased solutions, etc.)\n\u2022 Address early problems laid out in the primitives to be designed or utilized.\nProposal criteria\nThe following proposal criteria are intended to help teams\nde\ufb01ne and plan their solution.\nIt may also be used by funders considering\nproposals that promise to address the sustainable governance and regeneration\nof common resources.\n71\nCriteria\nDescription\nEvaluation Metric\nRegenerative\nIn-\ntentionality\nand\nRelevance\nExplicit impact-driven goals and\nwhat stakeholders deem this im-\npact of capital relevance to them.\nThe planned solution must demonstrate regenerative intentionality in\nits goals and objectives, ensuring alignment with relevant issues and\nchallenges to generate a positive impact.\nThis includes sustainable\nfunding, \ufb01nancial management, and a net positive increase in resource\navailability, with a focus on impact signi\ufb01cance.\nBeyond economic\nrelevance - Consider 8 Forms of Capital (natural, \ufb01nancial, material,\nintellectual, experiential, social, cultural, and spiritual).\nDecentralized\nGover-\nnance\nand\nTechnical\nSustainability\nBuilding institutional capacity and\nincentive structures, and enhanc-\ning\ninteroperability\nof\nsystems.\nPositive-sum participation.\nThe planned solution must provide tools for relevant stakeholders to\nparticipate and engage in governance without technical or institutional\nbarriers. It must also ensure data traceability, transparency, authen-\nticity, and interoperability. E\ufb03ciency of the system must not come at\na detriment to its baseline performance or those stakeholders partici-\npating in it. Ensuring the systems are not more intensive to operate\nthan the impact they provide. (e.g. power consumption at scale)\nInternalized\nImpact\nand Materiality\nRegeneration of resources without\nexternalizing harms.\nTranslation of nominal units of ac-\ncount into CPRs with traceable\nimpact via novel primitives which\ngenerate material change to the\nfundamental problems.\nThe planned solution should address the internalization of externalities\nin speci\ufb01c industries or anthropogenic practices, particularly utilizing\nthe creation of regenerative primitives. This involves translating trace-\nable impact into CPRs and ensuring that the creation of these leads\nto material changes in operational decisions initially addressed, rather\nthan solely circulating through super\ufb01cial \ufb01nancial transactions. The\nplanned solution must track and ensure the net positive increase in\nresource availability, without externalizing harm. The net bene\ufb01t to\ncommunities must outweigh the net harm.\nTable 6: Proposal criteria\nImplementation criteria\nThe following implementation criteria cover met-\nrics that need to be evaluated on any implementation of the solution or inter-\nvention. We expect proposals to evolve over the course of implementation.\nCriteria\nDescription\nEvaluation Metric\nRegenerative\nIn-\ntentionality\nand\nRelevance\nExplicit impact-driven goals\nAt least 75% of project goals aligned with regenerative impact objectives.\nProject funding\nThe planned solution must include a way to sustainably fund the project\nand reward contributors without resorting to accelerationist pressures. High\nratio (e.g., more than 50%) of sustainable funding sources to total project\nfunding.\nDecentralized\nGover-\nnance and Technical\nSustainability\nInstitutional capacity\nBuilding institutional capacity for decentralized stakeholders and providing\nincentive structures for participation.\nInteroperability\nSolution standards are recognized and adopted by a sizable number of in-\ndustry stakeholders. Data should be interoperable across multiple platforms\nand ledgers. The solution should e\ufb00ectively integrate related on-chain and\no\ufb00-chain systems.\nQuality of data\nData provenance and transparency should be accounted for. Transparency\nscore based on quanti\ufb01able metrics (e.g., percentage of data publicly avail-\nable).\nProof-of-Virtue\nProof-of-Useful Work\nVerify the actual realization of claimed project bene\ufb01ts. Percentage of ben-\ne\ufb01ts audited and validated after 10 months of project implementation.\nInternalized\nImpact\nand Materiality\nRegeneration of resources\nResource availability must see a net positive increase while avoiding ex-\nternalizing harms. These can be measured in quantitative indicators such\nas hectares of forest restored and kilowatts of renewable energy generated.\nThere should be a percentage increase in carbon credits or other regenerative\nassets generated compared to the baseline, yielded by tangible results.\nUser adoption\nGrowing number of stake-\nholders that recognize the so-\nlution as a valid standard\nThere should be a reasonable growth of relevant stakeholders who either\nadopt or recognize the project\u2019s legitimacy.\nTable 7: Implementation criteria\n72\nScale criteria\nTraditionally, CPRs are associated with small local systems\nsuch as irrigation systems and \ufb01sheries [219]. However, ReFi has the potential\nto address much larger-scale problems requiring coordination at a global level.\nAs such, a successful solution must be scalable.\nCriteria\nDescription\nEvaluation Metric\nMulti-level Scale\nCross-scale linkages\nThe solution must consider interactions between actors of di\ufb00erent levels of\npolitical or social organizations.\nMacroscopic\nShift\nfrom Exchange Value\nto Use Value\nReFi assets and primitives\nthat deploy CPRs can be\nmeasured by the extent to\nwhich their value transitions\nfrom being primarily derived\nfrom \ufb01nancial exchange to\nbeing derived from their in-\ntrinsic\nutility\nin\ngenerat-\ning positive environmental\nor social outcomes.\nThe solution must yield a greater percentage of total value derived from the\nuse value of the underlying regenerative asset compared to the exchange value\nit was initially assigned upon instantiation.\nQualitative assessments of stakeholders\u2019 perception of the assets\u2019 utility and\nintrinsic value.\nAnalysis of market trends indicating increasing demand for CPRs based on\ntheir regenerative use value rather than speculative trading.\nRegenerative\nMarket\nInsights\nand\nAnalysis\nInvestment\nportfolios\nand\nratings\nagencies\ndevelop\ncompetitive\nindices\nto\nTradFi\nstock\nindices\nto\nassess\nviability\nof\ntransi-\ntioning\ntheir asset\nclasses\nfrom\nspeculative\nones\nto\nregenerative ones.\nMajor investment \ufb01rms declare signi\ufb01cant investment into CPRs via invest-\nment vehicles traceable not by price speculation but by regenerative impact\nperformance. Investments would go beyond economic corollary and become\ncausal in promoting direct impact.\nSovereign wealth funds begin to publish their utilization of CPRs as stable\nasset classes and support infrastructure that promote positive-sum dynamics\nfor their respective citizens and allies.\nReFi assets are utilized in parity with, or in lieu of, sovereign currency, gov-\nernment bonds, or debt (in debt-for-nature or debt-for-social impact swaps).\nThis parity promotes units of account that maintain sovereign economic sol-\nvency while promoting positive-sum impact beyond economic forecasts in\nTradFi market cycles.\nAt-scale, CPRs may reliably o\ufb00set the unforeseen\nsocioeconomic consequences of these typical market cycles.\nTable 8: Scale criteria\n73\nAcknowledgements\nWe are deeply grateful for suggestions, comments, and feedback from Divya Sid-\ndarth, Anna Weichselbraun, Eugene Leventhal, H\u00e9l\u00e8ne Landemore, Tony Dou-\nglas, Connor Spelliscy, Sara Horowitz, Dawn Song, Nathan Schneider, Daniel\nKronovet, Marina Markezic, Scott Moore, Benedict Lau, Dennison Bertram,\nCent Hosten, and Hazel Devjani.\nReferences\n[1] J. Abadi and M. Brunnermeier. Blockchain Economics, Dec. 2018.\n[2] S. Abar, G. K. Theodoropoulos, P. Lemarinier, and G. M. P. O\u2019Hare.\nAgent Based Modelling and Simulation tools: A review of the state-of-art\nsoftware. Computer Science Review, 24:13\u201333, May 2017.\n[3] C. Abidin and G. de Seta. Private messages from the \ufb01eld: Confessions\non digital ethnography and its discomforts. Journal of Digital Social Re-\nsearch, 2020.\n[4] A. Adriano. Technological innovation is fueling the resurgence of com-\nmunity currencies. Technical report, International Monetary Fund, Mar.\n2021.\n[5] H. Al-Breiki, M. H. U. Rehman, K. Salah, and D. Svetinovic. Trustworthy\nBlockchain Oracles: Review, Comparison, and Open Research Challenges.\nIEEE Access, 8:85675\u201385685, 2020. Conference Name: IEEE Access.\n[6] A. A. Alchian. Uncertainty, Evolution, and Economic Theory. Journal of\nPolitical Economy, 58(3):211\u2013221, June 1950. Publisher: The University\nof Chicago Press.\n[7] D. Allen, G. Weyl, D. Siddarth, J. Simons, and W. Lim. Ethics of De-\ncentralized Social Technologies: Lessons from Web3, the Fediverse, and\nBeyond. Technical report, Harvard University or the Justice, Health &\nDemocracy Impact Initiative, Mar. 2023.\n[8] D. W. Allen, C. Berg, and A. Lane. Cryptodemocracy: How Blockchain\nCan Radically Expand Democratic Choice. 2019.\n[9] M. Altho\ufb00. Reachability analysis and its application to the safety assess-\nment of autonomous cars. Doctoral Dissertation, Technische Universit\u00e4t\nM\u00fcnchen, 2010.\n[10] M. Alvesson and D. K\u00e4rreman. Taking the Linguistic Turn in Organiza-\ntional Research: Challenges, Responses, Consequences. The Journal of\nApplied Behavioral Science, 36(2):136\u2013158, June 2000. Publisher: SAGE\nPublications Inc.\n74\n[11] A. I. Applbaum. Legitimacy without the Duty to Obey. Philosophy &\nPublic A\ufb00airs, 38(3):215\u2013239, 2010.\n[12] Aristotle. Nicomachean Ethics. 353 BCE.\n[13] J. Arroyo, D. Dav\u00f3, E. Mart\u00ednez-Vicente, Y. Faqir-Rhazoui, and S. Has-\nsan. DAO-Analyzer: Exploring Activity and Participation in Blockchain\nOrganizations. In Companion Publication of the 2022 Conference on Com-\nputer Supported Cooperative Work and Social Computing, CSCW\u201922 Com-\npanion, pages 193\u2013196, New York, NY, USA, Nov. 2022. Association for\nComputing Machinery.\n[14] F. Ast and B. De\ufb00ains.\nWhen Online Dispute Resolution Meets\nBlockchain:\nThe Birth of Decentralized Justice.\nStanford Journal of\nBlockchain Law & Policy, June 2021.\n[15] P. Atkinson and M. Hammersley. Ethnography and participant observa-\ntion. In Strategies of Qualitative Inquiry, pages 248\u2013261. Thousand Oaks:\nSage., 1998.\n[16] J. Austgen, A. F\u00e1brega, S. Allen, K. Babel, M. Kelkar, and A. Juels. DAO\nDecentralization: Voting-Bloc Entropy, Bribery, and Dark DAOs. ArXiv,\nNov. 2023.\n[17] G. Avner. Institutions and the Path to the Modern Economy: Lessons\nfrom Medieval Trade. Cambridge University Press, 2006.\n[18] J. Bachman, S. Chakravorti, S. Rane, and K. Thyagarajan.\nIncen-\ntivizing Gigaton-Scale Carbon Dioxide Removal via a Climate-Positive\nBlockchain, Aug. 2023. arXiv:2308.02653 [cs].\n[19] Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen,\nA. Goldie, A. Mirhoseini, C. McKinnon, C. Chen, C. Olsson, C. Olah,\nD. Hernandez, D. Drain, D. Ganguli, D. Li, E. Tran-Johnson, E. Perez,\nJ. Kerr, J. Mueller, J. Ladish, J. Landau, K. Ndousse, K. Lukosuite,\nL. Lovitt, M. Sellitto, N. Elhage, N. Schiefer, N. Mercado, N. Das-\nSarma, R. Lasenby, R. Larson, S. Ringer, S. Johnston, S. Kravec, S. E.\nShowk, S. Fort, T. Lanham, T. Telleen-Lawton, T. Conerly, T. Henighan,\nT. Hume, S. R. Bowman, Z. Hat\ufb01eld-Dodds, B. Mann, D. Amodei,\nN. Joseph, S. McCandlish, T. Brown, and J. Kaplan. Constitutional AI:\nHarmlessness from AI Feedback, Dec. 2022. arXiv:2212.08073 [cs].\n[20] K. Baldwin.\nThe Paradox of Traditional Chiefs in Democratic Africa.\nCambridge University Press, 1 edition, Nov. 2015.\n[21] A. Baliga, I. Subhod, P. Kamat, and S. Chatterjee. Performance Evalua-\ntion of the Quorum Blockchain Platform. ArXiv, July 2018.\n[22] J. Bannermanquist. Marshall Islands legally recognizes DAOs as domestic\nlimited liability companies, Dec. 2022.\n75\n[23] L. Bao, X. Xia, D. Lo, and G. C. Murphy. A Large Scale Study of Long-\nTime Contributor Prediction for GitHub Projects. IEEE Transactions on\nSoftware Engineering, 47(6):1277\u20131298, June 2021.\n[24] C. Baum, J. Chiang, B. David, and T. Frederiksen. Eagle: E\ufb03cient Pri-\nvacy Preserving Smart Contracts. 2022.\n[25] J. A. C. Baum and P. Ingram. Survival-Enhancing Learning in the Man-\nhattan Hotel Industry, 1898\u20131980. Management Science, 44(7):996\u20131016,\nJuly 1998.\n[26] T. Beauchamp and J. F. Childress. Principles of biomedical ethics (6th\ned.). New York: Oxford University Press., 2009.\n[27] R. Becker, G. D\u2019Angelo, E. Delfaraz, and H. Gilbert.\nUnveiling the\nTruth in Liquid Democracy with Misinformed Voters. In D. Fotakis and\nD. R\u00edos Insua, editors, Algorithmic Decision Theory, Lecture Notes in\nComputer Science, pages 132\u2013146, Cham, 2021. Springer International\nPublishing.\n[28] E. D. Beinhocker. The Origin of Wealth: The Radical Remaking of Eco-\nnomics and What it Means for Business and Society. Harvard Business\nPress, Sept. 2007. Google-Books-ID: GtRBDwAAQBAJ.\n[29] R. Belchior, A. Vasconcelos, S. Guerreiro, and M. Correia.\nA Survey\non Blockchain Interoperability: Past, Present, and Future Trends. ACM\nComputing Surveys, 54(8):168:1\u2013168:41, Oct. 2021.\n[30] J. Benaloh, R. Rivest, P. Y. A. Ryan, P. Stark, V. Teague, and P. Vora.\nEnd-to-end veri\ufb01ability, Apr. 2015. arXiv:1504.03778 [cs].\n[31] Y. Benkler, A. Shaw, and M. Benjamin.\nPeer production: A form of\ncollective intelligence. Handbook for Collective Intelligence, 175, 2015.\n[32] A. Berg and C. Berg. Exit, Voice, and Forking, Dec. 2017.\n[33] C. Berg, S. Davidson, and J. Potts. Understanding the Blockchain Econ-\nomy, 2019.\n[34] P. L. Berger and T. Luckmann. The Social Construction of Reality: A\nTreatise in the Sociology of Knowledge. Open Road Media, Apr. 2011.\nGoogle-Books-ID: Jcma84waN3AC.\n[35] L. Bernholz, Helene Landemore, and R. Reich, editors. Digital Technology\nand Democratic Theory. The University of Chicago Press, 2021.\n[36] K.\nBhargavan,\nA.\nDelignat-Lavaud,\nC.\nFournet,\nA.\nGollamudi,\nG. Gonthier, N. Kobeissi, N. Kulatova, A. Rastogi, T. Sibut-Pinote,\nN. Swamy, and S. Zanella-B\u00e9guelin. Formal Veri\ufb01cation of Smart Con-\ntracts: Short Paper. In Proceedings of the 2016 ACM Workshop on Pro-\ngramming Languages and Analysis for Security, PLAS \u201916, pages 91\u201396,\nNew York, NY, USA, Oct. 2016. Association for Computing Machinery.\n76\n[37] G. Bj\u00f6rnsson and K. Hess. Corporate Crocodile Tears? On the Reac-\ntive Attitudes of Corporate Agents.\nPhilosophy and Phenomenological\nResearch, 94(2):273\u2013298, Mar. 2017.\n[38] D. Black. On the Rationale of Group Decision-making. Journal of Political\nEconomy, 56(1):23\u201334, 1948. Publisher: University of Chicago Press.\n[39] A. Blais and A. Dobrzynska. Turnout in electoral democracies. European\nJournal of Political Research, 33(2):239\u2013262, Mar. 1998.\n[40] BlockScience. Applying Lessons from Constitutional Public Finance to\nToken System Design, Nov. 2022.\n[41] R. Boder. How DAOs Can Transform the Business World, July 2022.\n[42] S. Bowe, A. Chiesa, M. Green, I. Miers, P. Mishra, and H. Wu. ZEXE:\nEnabling Decentralized Private Computation. 2020 IEEE Symposium on\nSecurity and Privacy (SP), pages 947\u2013964, May 2020.\n[43] P. Brey. Ethics of Emerging Technology. In S. Hassan, editor, Methods\nfor the Ethics of Technology. Rowman and Little\ufb01eld International, 2017.\n[44] A. Brody and S. Couture. Ideologies and Imaginaries in Blockchain Com-\nmunities: The Case of Ethereum. Canadian Journal of Communication,\n46(3):19\u2013pp, 2021.\n[45] M. Brooks. St Helena Government Budget Speech 2022. May 2022.\n[46] R. Brown. The Corda Platform : An Introduction. 2018.\n[47] C. Brummer and R. Seira. Legal Wrappers and DAOs, May 2022.\n[48] C. J. Bryan, G. M. Walton, T. Rogers, and C. S. Dweck. Motivating\nvoter turnout by invoking the self. Proceedings of the National Academy\nof Sciences of the United States of America, 108(31):12653\u201312656, Aug.\n2011.\n[49] J. M. Buchanan. The domain of constitutional economics. Constitutional\nPolitical Economy, 1(1):1\u201318, Dec. 1990.\n[50] J. M. Buchanan and G. Tullock. The Calculus of Consent: Logical Foun-\ndations of Constitutional Democracy. 1962.\n[51] E. Bueno de Mesquita and A. Hall. Paying People to Participate in Gov-\nernance. a16z Crypto, 2022.\n[52] B. Bunz, J. Bootle, D. Boneh, A. Poelstra, P. Wuille, and G. Maxwell.\nBulletproofs: Short Proofs for Con\ufb01dential Transactions and More. 2018\nIEEE Symposium on Security and Privacy (SP), pages 315\u2013334, May\n2018.\n77\n[53] R.\nM.\nBurton,\nD.\nD.\nH\u00e5konsson,\nJ.\nNickerson,\nP.\nPuranam,\nM. Workiewicz, and T. Zenger.\nGitHub: exploring the space between\nboss-less and hierarchical forms of organizing. Journal of Organization\nDesign, 6(1):10, Dec. 2017.\n[54] V. Buterin. DAOs, DACs, DAs and More: An Incomplete Terminology\nGuide, June 2014.\n[55] V. Buterin. Minimal anti-collusion infrastructure, May 2019.\n[56] V. Buterin. Credible Neutrality As A Guiding Principle, Jan. 2020.\n[57] V. Buterin. The Most Important Scarce Resource is Legitimacy, Mar.\n2021.\n[58] V. Buterin. On Nathan Schneider on the limits of cryptoeconomics, Sept.\n2021.\n[59] V. Buterin. What do I think about Community Notes?, Aug. 2023.\n[60] V. Buterin, E. Conner, R. Dudley, M. Slipper, I. Norden, and A. Bakhta.\nEIP-1559: Fee market change for ETH 1.0 chain, Apr. 2019.\n[61] V. Buterin, Z. Hitzig, and E. G. Weyl.\nA Flexible Design for Fund-\ning Public Goods. Management Science, 65(11):5171\u20135187, Nov. 2019.\narXiv:1809.06421 [econ, q-\ufb01n].\n[62] B. B\u00fcnz, S. Agrawal, M. Zamani, and D. Boneh. Zether: Towards Privacy\nin a Smart Contract World. volume 12059, pages 423\u2013443, Cham, 2020.\nSpringer International Publishing.\n[63] S. Caney.\nCosmopolitan Justice, Responsibility, and Global Climate\nChange. Leiden Journal of International Law, 18(4):747\u2013775, Dec. 2005.\n[64] K. M. Carley.\nOrganizational adaptation in volatile environments.\nIn\nD. R. Ilgen and C. L. Hulin, editors, Computational modeling of behavior\nin organizations: The third scienti\ufb01c discipline., pages 241\u2013273. American\nPsychological Association, Washington, 2000.\n[65] M. Casson. The Nature of the Firm Reconsidered: Information Synthe-\nsis and Entrepreneurial Organisation. MIR: Management International\nReview, 36:55\u201394, 1996.\n[66] M. Casson.\nInformation and Organization: A New Perspective on the\nTheory of the Firm. Clarendon Press., 1997.\n[67] C. Catalini and J. S. Gans. Some simple economics of the blockchain.\nCommunications of the ACM, 63(7):80\u201390, June 2020.\n[68] O. Cetinkaya and D. Cetinkaya.\nVeri\ufb01cation and Validation Issues in\nElectronic Voting. Electronic Journal of e-Government, 5(2):pp117-126\u2013\npp117-126, Dec. 2007. Number: 2.\n78\n[69] E. Chamlee-Wright. The Cultural Foundations of Economic Development:\nUrban Female Entrepreneurship in Ghana, 2002.\n[70] E. Chamlee-Wright. The Structure of Social Capital: An Austrian Per-\nspective on its Nature and Development. Review of Political Economy,\n20:41\u201358, Feb. 2008.\n[71] A. D. Chandler. Strategy and Structure. The MIT Press, Aug. 1969.\n[72] D. Chaum, A. Essex, R. Carback, J. Clark, S. Popoveniuc, A. Sherman,\nand P. Vora. Scantegrity: End-to-End Voter-Veri\ufb01able Optical- Scan Vot-\ning. IEEE Security & Privacy, 6(3):40\u201346, May 2008.\n[73] R. Cheng, F. Zhang, J. Kos, W. He, N. Hynes, N. Johnson, A. Juels,\nA. Miller, and D. Song.\nEkiden:\nA Platform for Con\ufb01dentiality-\nPreserving, Trustworthy, and Performant Smart Contracts. 2019 IEEE\nEuropean Symposium on Security and Privacy (EuroS&P), pages 185\u2013\n200, June 2019.\n[74] H.-k.\nChey.\nCryptocurrencies\nand\nthe\nIPE\nof\nmoney:\nan\nagenda\nfor\nresearch.\nReview\nof\nInternational\nPolitical\nEcon-\nomy,\n30(4):1605\u20131620, July 2023.\nPublisher:\nRoutledge _eprint:\nhttps://doi.org/10.1080/09692290.2022.2109188.\n[75] I. H.-Y. Chiu and J. Linarelli. Regulating the Crypto Economy: Business\nTransformations and Financialisation.\nHart Publishing, Oxford ; New\nYork, Nov. 2021.\n[76] D. A. Ciepley. Beyond Public and Private: Toward a Political Theory of\nthe Corporation, Feb. 2013.\n[77] A. E. Clarke. Situational Analyses: Grounded Theory Mapping After the\nPostmodern Turn. Symbolic Interaction, 26(4):553\u2013576, Nov. 2003.\n[78] A. E. Clarke, R. Washburn, C. Friese, A. E. Clarke, and R. Washburn,\neditors.\n: Mapping Research with Grounded Theory.\nRoutledge, New\nYork, June 2016.\n[79] M. R. Clarkson, S. Chong, and A. C. Myers. Civitas: Toward a Secure\nVoting System. In 2008 IEEE Symposium on Security and Privacy (sp\n2008), pages 354\u2013368, May 2008. ISSN: 2375-1207.\n[80] R. H. Coase. The Nature of the Firm. Economica, 4(16):386\u2013405, Nov.\n1937.\n[81] M. A. Cohen. Punishing Corporations. In M. L. Rorie, editor, The Hand-\nbook of White-Collar Crime, pages 314\u2013333. Wiley, 1 edition, Oct. 2019.\n[82] M. D. Cohen, J. G. March, and J. P. Olsen.\nA Garbage Can Model\nof Organizational Choice. Administrative Science Quarterly, 17(1):1\u201325,\n1972.\n79\n[83] U. L. Commission. Decentralised Autonomous Organisations (DAOs) -\nCall for Evidence, Nov. 2022.\n[84] L. W. Cong and Z. He. Blockchain Disruption and Smart Contracts. The\nReview of Financial Studies, 32(5):1754\u20131797, May 2019.\n[85] K. Conway. Blockchain Technology: Limited Liability Companies and the\nNeed for North Carolina Legislation. Campbell Law Review, 45(1):127,\nJan. 2022.\n[86] C. Copy. The State of ReFi: A Closer Look at Web3 Regenerative Finance.\nTechnical report, 2024.\n[87] S. E. S. Crawford and E. Ostrom. A Grammar of Institutions. American\nPolitical Science Review, 89(3):582\u2013600, Sept. 1995.\n[88] C. F. Dagdelen, J. Emmett, M. Hampshire, S. Voshmgir, and M. Zargham.\nExploring DAO2DAO Collaboration Mechanisms, Mar. 2021.\n[89] R. A. Dahl.\nDemocracy and Its Critics.\nYale University Press, 1989.\nGoogle-Books-ID: l1RQngEACAAJ.\n[90] P. Daian, T. Kell, I. Miers, and A. Juels. On-Chain Vote Buying and the\nRise of Dark DAOs, July 2018.\n[91] DAOstar. www.daostar.org, Mar. 2023. Accessed March 31, 2023.\n[92] S. Davidson, P. D. Filippi, and J. Potts. Blockchains and the economic\ninstitutions of capitalism. Journal of Institutional Economics, 14(4):639\u2013\n658, Aug. 2018. Publisher: Cambridge University Press.\n[93] S. Davidson and J. Potts. Corporate Governance in a Crypto-World, May\n2022.\n[94] P. De Filippi and S. Hassan. Blockchain Technology as a Regulatory Tech-\nnology: From Code is Law to Law is Code, Jan. 2018. arXiv:1801.02507\n[cs].\n[95] P. De Filippi, M. Mannan, J. Henderson, T. Merk, S. Cossar, and\nK. Nabben. Report on Blockchain Technology & Legitimacy, Dec. 2022.\n[96] P. De Filippi, M. Mannan, and W. Reijers. The alegality of blockchain\ntechnology. Policy and Society, 41(3):358\u2013372, 2022.\n[97] L. DeNardis. Protocol Politics: The Globalization of Internet Governance.\nThe MIT Press, Cambridge, Mass, \ufb01rst edition, 1st printing edition, July\n2009.\n[98] P. J. DiMaggio and W. W. Powell. The Iron Cage Revisited: Institu-\ntional Isomorphism and Collective Rationality in Organizational Fields.\nAmerican Sociological Review, 48(2):147\u2013160, 1983. Publisher: [American\nSociological Association, Sage Publications, Inc.].\n80\n[99] A. Dix, J. E. Finlay, G. D. Abowd, and R. Beale.\nHuman-Computer\nInteraction. Pearson, Harlow, England ; New York, 3rd edition edition,\nSept. 2003.\n[100] S. Djankov, E. Glaeser, R. LaPorta, F. Lopez-de Silanes, and A. Shleifer.\nThe New Comparative Economics. Journal of Comparative Economics,\n31(4):595\u2013619, 2003.\n[101] B. P. Douglass. Chapter 1 - What Is Model-Based Systems Engineering?\nIn B. P. Douglass, editor, Agile Systems Engineering, pages 1\u201339. Morgan\nKaufmann, Boston, Jan. 2016.\n[102] J. Driver. Moral Theory. June 2022.\n[103] Q. DuPont.\nExperiments in algorithmic governance:\nA history and\nethnography of \u201cThe DAO,\u201d a failed decentralized autonomous organi-\nzation. In Bitcoin and Beyond. Routledge, 2017. Num Pages: 21.\n[104] N. Eghbal. Working in public: the making and maintenance of open source\nsoftware. Stripe Press, San Francisco, \ufb01rst edition edition, 2020.\n[105] C. Elsden, A. Manohar, J. Briggs, M. Harding, C. Speed, and J. Vines.\nMaking Sense of Blockchain Applications: A Typology for HCI. In Pro-\nceedings of the 2018 CHI Conference on Human Factors in Computing\nSystems, CHI \u201918, pages 1\u201314, New York, NY, USA, Apr. 2018. Associa-\ntion for Computing Machinery.\n[106] J. Esber and S. D. Kominers. Progressive Decentralization: A High-level\nFramework, Jan. 2023.\n[107] P. C. Evans and A. Gawer. The Rise of the platform Enterprise: A Global\nSurvey. Technical report, The Center for Global Enterprise, 2016.\n[108] E. Ezcurra, P. Ezcurra, and B. Meissner. Ancient inhabitants of the Basin\nof Mexico kept an accurate agricultural calendar using sunrise observato-\nries and mountain alignments. Proceedings of the National Academy of\nSciences, 119(51):e2215615119, Dec. 2022. Publisher: Proceedings of the\nNational Academy of Sciences.\n[109] E. F. Fama and K. R. French. Common risk factors in the returns on stocks\nand bonds. Journal of Financial Economics, 33(1):3\u201356, Feb. 1993.\n[110] E. F. Fama and M. C. Jensen. Separation of Ownership and Control. The\nJournal of Law & Economics, 26(2):301\u2013325, 1983. Publisher: [Univer-\nsity of Chicago Press, Booth School of Business, University of Chicago,\nUniversity of Chicago Law School].\n[111] J. Fan and A. X. Zhang.\nDigital Juries: A Civics-Oriented Approach\nto Platform Governance. In Proceedings of the 2020 CHI Conference on\nHuman Factors in Computing Systems, CHI \u201920, pages 1\u201314, New York,\nNY, USA, Apr. 2020. Association for Computing Machinery.\n81\n[112] F. Fannizadeh. Lawmakers In New Hampshire And Utah Recognize DAOs\nAs Legal Persons, July 2023.\n[113] J. S. Farmer, J. Cahill, J. S. Farmer, and J. Cahill. DAOs: A game changer\nin need of new rules. Reuters, Oct. 2022.\n[114] S. Faustino, I. Faria, and R. Marques. The myths and legends of king\nSatoshi and the knights of blockchain.\nJournal of Cultural Economy,\n15(1):67\u201380, Jan. 2022.\n[115] R. Feichtinger, R. Fritsch, Y. Vonlanthen, and R. Wattenhofer. The Hid-\nden Shortcomings of (D)AOs \u2013 An Empirical Study of On-Chain Gover-\nnance, Feb. 2023. arXiv:2302.12125 [cs].\n[116] R. Finke and R. Stark. The Churching of America, 1776-2005: Winners\nand Losers in Our Religious Economy. Rutgers University Press, New\nBrunswick, N.J, revised edition edition, Mar. 2005.\n[117] C.\nK.\nFrantz\nand\nS.\nSiddiki.\nInstitutional\nGrammar\n2.0:\nA\nspeci\ufb01cation\nfor\nencoding\nand\nanalyzing\ninstitutional\nde-\nsign.\nPublic\nAdministration,\n99(2):222\u2013247,\n2021.\n_eprint:\nhttps://onlinelibrary.wiley.com/doi/pdf/10.1111/padm.12719.\n[118] S. Frey, J. Hedges, J. Tan, and P. Zahn. Composing games into complex\ninstitutions. PLOS ONE, 18(3):e0283361, Mar. 2023. Publisher: Public\nLibrary of Science.\n[119] S. Frey, P. M. Kra\ufb00t, and B. C. Keegan.\n\"This Place Does What It\nWas Built For\": Designing Digital Institutions for Participatory Change.\nProceedings of the ACM on Human-Computer Interaction, 3(CSCW):1\u2013\n31, Nov. 2019.\n[120] S. Frey and R. W. Sumner. Emergence of integrated institutions in a large\npopulation of self-governing communities. PLOS ONE, 14(7):e0216335,\nJuly 2019.\n[121] R. Friedland and R. Alford. Bringing Society Back In: Symbols, Practices,\nand Institutional Contradictions. Jan. 1991.\n[122] M. Ganado, J. Ellul, G. Pace, S. Tendon, and B. Wilson. Mapping the\nFuture of Legal Personality. MIT Computational Law Report, Nov. 2020.\n[123] J. Gandhi. Political Institutions under Dictatorship. Cambridge Univer-\nsity Press, 2008.\n[124] D. Ganguli, S. Huang, L. Lovitt, and D. Siddarth. Collective Constitu-\ntional AI: Aligning a Language Model with Public Input, Oct. 2023.\n[125] C. Geertz. The Interpretation Of Cultures. Basic Books, 1973. Google-\nBooks-ID: m3Y4DgAAQBAJ.\n82\n[126] N. Ghani, J. Hedges, V. Winschel, and P. Zahn. Compositional Game\nTheory. In Proceedings of the 33rd Annual ACM/IEEE Symposium on\nLogic in Computer Science, LICS \u201918, pages 472\u2013481, New York, NY,\nUSA, July 2018. Association for Computing Machinery.\n[127] A. Ghavi, A. Qureshi, G. Weinstein, J. Schwartz, and S. Lofchie. A Primer\non DAOs, Sept. 2022.\n[128] A. Gilbert and S. Haig.\n\u2019Counter-Exploit\u2019 Claws Back $202M From\nHacker, Feb. 2023.\n[129] S. Glaveski.\nHow DAOs Could Change the Way We Work.\nHarvard\nBusiness Review, Apr. 2022.\n[130] I. Goll and A. A. Rasheed. The Relationships between Top Management\nDemographic Characteristics, Rational Decision Making, Environmental\nMuni\ufb01cence, and Firm Performance.\nOrganization Studies, 26(7):999\u2013\n1023, July 2005.\n[131] D. P. Green and A. S. Gerber. Get Out the Vote: How to Increase Voter\nTurnout. Brookings Institution Press, 3 edition, 2015.\n[132] S. E. Green. A Rhetorical Theory of Di\ufb00usion. The Academy of Manage-\nment Review, 29(4):653\u2013669, 2004. Publisher: Academy of Management.\n[133] L. E. Grube and Storr. Culture and Economic Action, 2015.\n[134] J. Habermas. The Public Sphere.\nIn Media Studies: A Reader. NYU\nPress, Mar. 2000. Google-Books-ID: 86kZKhuAjlAC.\n[135] S. Haig. The number of active DAOs is up 660% since 2019. Cointelegraph,\nSept. 2020.\n[136] P. A. Hall and R. C. R. Taylor. Political Science and the Three New\nInstitutionalisms. Political Studies, 1996.\n[137] M. T. Hannan, M. D. Burton, and J. N. Baron. Inertia and Change in the\nEarly Years: Employment Relations in Young, High Technology Firms.\nJan. 1996. Accepted: 2020-11-17T17:23:32Z.\n[138] E. Harris-Braun, N. Luck, and A. Brock. Holochain: scalable agent-centric\ndistributed computing. Oct. 2017.\n[139] J. K. Hartshorne, J. R. de Leeuw, N. D. Goodman, M. Jennings, and T. J.\nO\u2019Donnell. A thousand studies for the price of one: Accelerating psycho-\nlogical science with Pushkin.\nBehavior Research Methods, 51(4):1782\u2013\n1803, Aug. 2019.\n[140] A. A. Hasino\ufb00and N. Schneider.\nFrom Scalability to Subsidiarity in\nAddressing Online Harm. Social Media + Society, 8(3):205630512211260,\nJuly 2022.\n83\n[141] S. Hassan and P. De Filippi. Decentralized Autonomous Organization.\nInternet Policy Review, 10(2), Apr. 2021.\n[142] Hasu and monetsupply. A New Mental Model for De\ufb01Treasuries, Oct.\n2021.\n[143] F. Hayek. Kinds of Order in Society. New Individualist Review, Vol. 1(No.\n3):457\u2013466, 1964.\n[144] B. Highton and R. E. Wol\ufb01nger.\nThe Political Implications of Higher\nTurnout. British Journal of Political Science, 31(1):179\u2013223, 2001.\n[145] C. Hine. Ethnography for the Internet: embedded, embodied and everyday.\nBloomsbury Academic, An imprint of Bloomsbury Publishing Plc, London\n; New York, 2015.\n[146] B. Hitchens and O. Roberts. Decentralised Autonomous Organisations\n(DAOs): What are they? And can they be parties to a claim?, Jan. 2023.\n[147] S. Hubbard. Beyond the Buzzwords: Web3, DAOs, and the Future of\nHuman Coordination, Apr. 2022.\n[148] N. Ilyushina and T. Macdonald.\nDecentralised Autonomous Organisa-\ntions: A New Research Agenda for Labour Economics. The Journal of\nThe British Blockchain Association, Apr. 2022. Publisher: The British\nBlockchain Association.\n[149] R. W. Jackman. Political Institutions and Voter Turnout in the Industrial\nDemocracies. American Political Science Review, 81(2):405\u2013423, 1987.\n[150] S. Jain, V. Suriyakumar, K. Creel, and A. Wilson. Algorithmic Pluralism:\nA Structural Approach To Equal Opportunity. 2023.\n[151] G. Jenkinson. Remote work triggers move to DAOs in the post-pandemic\nworld: Survey. Cointelegraph, Dec. 2022.\n[152] M. Jennings and D. Kerr. How to pick a DAO legal entity, June 2022.\n[153] M. C. Jensen and W. H. Meckling. Theory of the \ufb01rm: Managerial be-\nhavior, agency costs and ownership structure. Journal of Financial Eco-\nnomics, 3(4):305\u2013360, Oct. 1976.\n[154] V. Johnson. What Is Organizational Imprinting? Cultural Entrepreneur-\nship in the Founding of the Paris Opera. American Journal of Sociology,\n113(1):97\u2013127, 2007. Publisher: The University of Chicago Press.\n[155] V. Johnson. Backstage at the Revolution: How the Royal Paris Opera\nSurvived the End of the Old Regime. University of Chicago Press, Chicago,\nIL, Feb. 2009.\n84\n[156] A. Juels, D. Catalano, and M. Jakobsson. Coercion-resistant electronic\nelections. In Proceedings of the 2005 ACM workshop on Privacy in the\nelectronic society, WPES \u201905, pages 61\u201370, New York, NY, USA, Nov.\n2005. Association for Computing Machinery.\n[157] H. Kalodner, S. Goldfeder, X. Chen, S. M. Weinberg, and E. W. Felten.\nArbitrum: Scalable, private smart contracts. pages 1353\u20131370, 2018.\n[158] G. Kaptchuk, M. Green, and I. Miers.\nGiving State to the Stateless:\nAugmenting Trustworthy Computation with Ledgers. Proceedings 2019\nNetwork and Distributed System Security Symposium, 2019.\n[159] M. Kaptein and M. Constantinescu. Corporations as Moral Entities. In\nD. C. Po\ufb00and A. C. Michalos, editors, Encyclopedia of Business and\nProfessional Ethics, pages 1\u20134. Springer International Publishing, Cham,\n2017.\n[160] Karakostas, Dimitris, Kiayias, Aggelos, and Ovezik, Christina. SoK: A\nStrati\ufb01ed Approach to Blockchain Decentralization. ArXiv, 2022.\n[161] R. M. Karp. Understanding Science Through the Computational Lens.\nJournal of Computer Science and Technology, 26(4):569\u2013577, July 2011.\n[162] M. Kelkar, K. Babel, P. Daian, J. Austgen, V. Buterin, and A. Juels.\nComplete Knowledge: Preventing Encumbrance of Cryptographic Secrets,\n2023. Publication info: Preprint.\n[163] T. Kerber, A. Kiayias, and M. Kohlweiss. Kachina - Foundations of Pri-\nvate Smart Contracts. 2021 IEEE 34th Computer Security Foundations\nSymposium (CSF), pages 1\u201316, June 2021.\n[164] I. M. Kirzner. Competition and Entrepreneurship. University of Chicago\nPress, Chicago, IL, 1973.\n[165] J. Koh and Y.-G. Kim.\nSense of Virtual Community: A Conceptual\nFramework and Empirical Validation. International Journal of Electronic\nCommerce, 8(2):75\u201393, 2003. Publisher: Taylor & Francis, Ltd.\n[166] P. Kollock and M. Smith. Managing the Virtual Commons: Cooperation\nand con\ufb02ict in computer communities. Computer-Mediated Communica-\ntion: Linguistic, Social, and Cross-Cultural Perspectives, edited bySusan\nHerring. Amsterdam: John Benjamins., pages Pp. 109\u2013128, Jan. 1996.\n[167] L. Korpas and J. Z. Tan. Governance Surfaces of DAOs, 2023.\n[168] L. M. Korpas, S. Frey, and J. Tan. Political, economic, and governance\nattitudes of blockchain users. Frontiers in Blockchain, 6, 2023.\n85\n[169] A. Kosba, A. Miller, E. Shi, Z. Wen, and C. Papamanthou. Hawk: The\nBlockchain Model of Cryptography and Privacy-Preserving Smart Con-\ntracts. 2016 IEEE Symposium on Security and Privacy (SP), pages 839\u2013\n858, May 2016.\n[170] J. Kostelnik and D. Skarbek. The governance institutions of a drug traf-\n\ufb01cking organization. Public Choice, 156(1/2):95\u2013103, 2013. Publisher:\nSpringer.\n[171] K. Kreutler. A Prehistory of DAOs, 2021.\n[172] J. Kwon and E. Buchman. Cosmos Whitepaper: A Network of Distributed\nLedgers. 2019.\n[173] S. Labs. www.snapshot.org. Accessed October 27, 2023.\n[174] S. P. Lalley and E. G. Weyl. Quadratic Voting: How Mechanism Design\nCan Radicalize Democracy. AEA Papers and Proceedings, 108:33\u201337, May\n2018.\n[175] H. Landemore. Democratic Reason: Politics, Collective Intelligence, and\nthe Rule of the Many. Princeton University Press, 2017.\n[176] S. Larimer. Bitcoin and the Three Laws of Robotics, Sept. 2013.\n[177] B. Latour. Reassembling the social: An introduction to actor-network-\ntheory. Oup Oxford, 2007.\n[178] S. Lazar. Legitimacy, Authority, and Democratic Duties of Explanation.\n2022.\n[179] M. LeBar. Corporations, Moral Agency, and Reactive Attitudes. George-\ntown Journal of Law & Public Policy, 17:811, 2019.\n[180] V. Lehdonvirta and E. Castronova. Virtual Economies: Design and Anal-\nysis. The MIT Press, 2014.\n[181] M. J. Leiblein and D. J. Miller. An empirical examination of transaction-\nand \ufb01rm-level in\ufb02uences on the vertical boundaries of the \ufb01rm. Strategic\nManagement Journal, 24(9):839\u2013859, Sept. 2003.\n[182] C. Li, R. Xu, and L. Duan. Liquid Democracy in DPoS Blockchains, Sept.\n2023. arXiv:2309.01090 [cs].\n[183] A. Lijphart. Patterns of Democracy: Government Forms and Performance\nin Thirty-Six Countries. Yale University Press, 2012.\n[184] J. Locke. Two Treatises of Government. 1690.\n[185] K. Lorenz. Der Kumpan in der Umwelt des Vogels. Journal f\u00fcr Ornitholo-\ngie, 83(2):137\u2013213, Apr. 1935.\n86\n[186] M.\nLounsbury\nand\nM.\nA.\nGlynn.\nCultural\nentrepreneurship:\nstories,\nlegitimacy,\nand\nthe\nacquisition\nof\nresources.\nStrate-\ngic\nManagement\nJournal,\n22(6-7):545\u2013564,\n2001.\n_eprint:\nhttps://onlinelibrary.wiley.com/doi/pdf/10.1002/smj.188.\n[187] K. F. K. Low, E. Schuster, and W. Y. Wan. The Company and Blockchain\nTechnology, Oct. 2022.\n[188] F. Lumineau, W. Wang, and O. Schilke. Blockchain Governance\u2014A New\nWay of Organizing Collaborations? Organization Science, 32(2):500\u2013521,\nMar. 2021. Publisher: INFORMS.\n[189] C. Lustig. Intersecting Imaginaries: Visions of Decentralized Autonomous\nSystems.\nProceedings of the ACM on Human-Computer Interaction,\n3(CSCW):210:1\u2013210:27, Nov. 2019.\n[190] W. J. Luther. CRYPTOCURRENCIES, NETWORK EFFECTS, AND\nSWITCHING COSTS. Contemporary Economic Policy, 34(3):553\u2013571,\nJuly 2016.\n[191] A. Maddox. Netnography to Uncover Cryptomarkets. In Netnography\nUnlimited. Routledge, 2020.\n[192] A. Maddox, M. J. Barratt, M. Allen, and S. Lenton. Constructive ac-\ntivism in the dark web: cryptomarkets and illicit drugs in the digital\n\u2018demimonde\u2019.\nInformation, Communication & Society, 19(1):111\u2013126,\nJan. 2016.\n[193] D. Magazzeni, P. McBurney, and W. Nash. Validation and Veri\ufb01cation\nof Smart Contracts: A Research Agenda. Computer, 50(9):50\u201357, 2017.\nConference Name: Computer.\n[194] W. Magnuson. Blockchain Democracy: Technology, Law and the Rule of\nthe Crowd. Cambridge University Press, Cambridge, 2020.\n[195] M. Mannan. Fostering Worker Cooperatives with Blockchain Technology:\nLessons from the Colony Project, Dec. 2018.\n[196] J. G. March, L. S. Sproull, and M. Tamuz. Learning from Samples of One\nor Fewer. Organization Science, 2(1):1\u201313, Feb. 1991.\n[197] J. McKinney. PR008 \u2013 DAO Regulation., Mar. 2023.\n[198] Messias, Johnnatan, Pahari, Vabuk, Chandrasekaran, Balakrishnan, Gu-\nummadi, Krishna P., and Loiseau, Patrick.\nUnderstanding Blockchain\nGovernance: Analyzing Decentralized Voting to Amend DeFi Smart Con-\ntracts. ArXiv, 2023.\n[199] MetisDAO. New Survey Indicates The Rapid Growth of Decentralized\nOrganizations is Coming, Dec. 2022.\n87\n[200] L. Metjahic. Deconstructing the DAO: The need for legal recognition and\nthe application of securities laws to decentralized organizations. Cardozo\nL. Rev., 39:1533, 2017.\n[201] R. v. d. Meyden. On the speci\ufb01cation and veri\ufb01cation of atomic swap\nsmart contracts (extended abstract). In 2019 IEEE International Con-\nference on Blockchain and Cryptocurrency (ICBC), pages 176\u2013179, May\n2019.\n[202] MIDAO. MIDAO awarded Facilitation of DAO Registry Process by gov-\nernment of Marshall Islands, Dec. 2022.\n[203] E. Miu, N. Gulley, K. N. Laland, and L. Rendell. Innovation and cumu-\nlative culture through tweaks and leaps in online programming contests.\nNature Communications, 9(1):2321, June 2018.\nNumber: 1 Publisher:\nNature Publishing Group.\n[204] Montesquieu. The Spirit of the Laws. Hafner Publishing Company, 1748.\n[205] G. Moore. What Is Quadratic Voting and Why Don\u2019t More Projects Use\nIt?, Jan. 2023.\n[206] A. Murray, S. Kuban, M. Josefy, and J. Anderson.\nContracting in\nthe Smart Era: The Implications of Blockchain and Decentralized Au-\ntonomous Organizations for Contracting and Corporate Governance. Apr.\n2019.\n[207] A. Murray, S. Kuban, M. Josefy, and J. Anderson.\nContracting in\nthe Smart Era: The Implications of Blockchain and Decentralized Au-\ntonomous Organizations for Contracting and Corporate Governance.\nAcademy of Management Perspectives, 35(4):622\u2013641, Nov. 2021.\n[208] K. Nabben. Is a \"Decentralized Autonomous Organization\" a Panopti-\ncon?: Algorithmic governance as creating and mitigating vulnerabilities in\nDAOs. In Proceedings of the Interdisciplinary Workshop on (de) Central-\nization in the Internet, pages 18\u201325, Virtual Event Germany, Dec. 2021.\nACM.\n[209] K. Nabben. Web3 as \u2018self-infrastructuring\u2019: The challenge is how. Big\nData & Society, 10(1):205395172311590, Jan. 2023.\n[210] K. Nershi. How Strong are International Standards in Practice? Evidence\nfrom Cryptocurrency Transactions. Under Review, 2020.\n[211] C.\nT.\nNguyen.\nTransparency\nis\nSurveillance.\nPhilosophy\nand\nPhenomenological\nResearch,\n105(2):331\u2013361,\n2022.\n_eprint:\nhttps://onlinelibrary.wiley.com/doi/pdf/10.1111/phpr.12823.\n[212] C. Nine. Global Justice and Territory. OUP Oxford, May 2012. Google-\nBooks-ID: VCvFb85XvlsC.\n88\n[213] D. North. Institutions, Institutional Change and Economic Performance.\nCambridge University Press, 1990.\n[214] S. of the Parliament of Australia. Select Committee on Australia as a\nTechnology and Financial Centre, Oct. 2021.\n[215] U. D. of the Treasury. U.S. Treasury Sanctions Notorious Virtual Currency\nMixer Tornado Cash, Aug. 2022.\n[216] S. of Wyoming Legislature. Wyoming Decentralized Autonomous Organi-\nzation Supplement, Apr. 2021.\n[217] W. C. on Environment and Development. Our Common Future. Oxford\nPaper Backs. Oxford University Press., Oxford; New York, 1987.\n[218] T. O\u2019Reilly.\nAI Has an Uber Problem: How Silicon Valley\u2019s Race for\nMonopoly Inhibits Product-Market Fit, Apr. 2024.\n[219] E. Ostrom. Governing the Commons. Cambridge University Press, 1990.\n[220] E. Ostrom. Designing complexity to govern complexity. In Property Rights\nand the Environment: Social and Ecological Issues, pages 33\u201345. World\nBank Publications, 1995. Google-Books-ID: O9iBJ_f7RZ8C.\n[221] E. Ostrom. Beyond Markets and States: Polycentric Governance of Com-\nplex Economic Systems. Nobel Prize in Economics documents, Dec. 2009.\n[222] J. Parthemore and B. Whitby.\nWHAT MAKES ANY AGENT A\nMORAL AGENT? REFLECTIONS ON MACHINE CONSCIOUSNESS\nAND MORAL AGENCY. International Journal of Machine Conscious-\nness, 05(02):105\u2013129, Dec. 2013.\n[223] N. Patel. From a meme to $47 million: ConstitutionDAO, crypto, and\nthe future of crowdfunding, Dec. 2021.\n[224] I. Patka. Exploiting Inattention & Optimism in DAOs, Oct. 2022.\n[225] N. Pecone. The Eight Forms of Capital, 2023.\n[226] M. Peterson.\nA Match Made in DeFi: Rari Capital and Fei Protocol\nMerge to \u2018FeiRari\u2019, Dec. 2021.\n[227] B. Pham. Why DAOs Should Govern AI, Jan. 2024.\n[228] S. Pink, H. Horst, J. Postill, L. Hjorth, T. Lewis, and J. Tacchi. Digital\nethnography: Principles and practice. sage, 2015.\n[229] Plato. \"The Republic\" in The Dialogues of Plato translated into English\nwith Analyses and Introductions by B. Jowett, M.A. in Five Volumes.\nOxford University Press, 3rd edition revised and corrected edition, 1892.\n89\n[230] R. F. Pol. Anti-money laundering: The world\u2019s least e\ufb00ective policy ex-\nperiment? Together, we can \ufb01x it. Policy Design and Practice, 3(1):73\u201394,\nJan. 2020.\n[231] J. Potts, D. W. E. Allen, C. Berg, S. Davidson, and T. MacDonald. An\neconomic theory of blockchain foundations, May 2021.\n[232] A. Przeworski. Democracy and Development: Political Institutions and\nWell-Being in the World, 1950-1990. Cambridge University Press, 2012.\n[233] P. Puranam, O. Alexy, and M. Reitzig. What\u2019s \u201cNew\u201d About New Forms\nof Organizing?\nAcademy of Management Review, 39(2):162\u2013180, Apr.\n2014.\n[234] R. Putnam. Making Democracy Work. Princeton University Press, 1993.\n[235] PWC.\nGenerative AI: Transform the future of business and lead with\ntrust. Technical report, 2024.\n[236] J. Rawls.\nA Theory of Justice: Original Edition.\nHarvard University\nPress, 1971.\n[237] E. Rennie, M. Zargham, J. Tan, L. Miller, J. Abbott, K. Nabben, and\nP. De Filippi. Toward a Participatory Digital Ethnography of Blockchain\nGovernance. Qualitative Inquiry, 28(7):837\u2013847, Sept. 2022.\n[238] W. Riker. Federalism: Origin, Operation, Signi\ufb01cance. Little, Brown, and\nCompany, 1964.\n[239] D. N. Rockmore, C. Fang, N. J. Foti, T. Ginsburg, and D. C. Krakauer.\nThe cultural evolution of national constitutions.\nJournal of the Asso-\nciation for Information Science and Technology, 69(3):483\u2013494, 2018.\n_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.23971.\n[240] D. Ronfeldt.\nTribes, Institutions, Markets, Networks:\nA Framework\nAbout Societal Evolution.\nTechnical report, RAND Corporation, Jan.\n1996.\n[241] H. Rong, E. Peris, and E. Jin. Blockchain for Impact Workshop: Per-\nspectives on International Development, Public Goods, and Regenerative\nEconomy, May 2023.\n[242] A. S. Roth. Shared Agency. In E. N. Zalta, editor, The Stanford En-\ncyclopedia of Philosophy. Metaphysics Research Lab, Stanford University,\nsummer 2017 edition, 2017.\n[243] J.-J. Rousseau. The Social Contract. 1762.\n[244] D. Rozas, A. Tenorio-Forn\u00e9s, S. D\u00edaz-Molina, and S. Hassan. When Os-\ntrom Meets Blockchain: Exploring the Potentials of Blockchain for Com-\nmons Governance.\nSAGE Open, 11(1):21582440211002526, Jan. 2021.\nPublisher: SAGE Publications.\n90\n[245] J. Ruane and A. McAfee. What a DAO Can \u2014 and Can\u2019t \u2014 Do. Harvard\nBusiness Review, May 2022.\n[246] C. Russo. \"Fair Launch is a New Way for Founders to Express Them-\nselves:\" Gavin McDermott of IDEO CoLab - The De\ufb01ant, Oct. 2020.\n[247] P. Ryan, D. Bismark, J. Heather, S. Schneider, and Zhe Xia. Pr\u00cat \u00c0\nVoter: a Voter-Veri\ufb01able Voting System. IEEE Transactions on Informa-\ntion Forensics and Security, 4(4):662\u2013673, Dec. 2009.\n[248] P. A. Samuelson. Diagrammatic Exposition of a Theory of Public Expen-\nditure. The Review of Economics and Statistics, 37(4):350, Nov. 1955.\n[249] C. Santana and L. Albareda. Blockchain and the emergence of Decentral-\nized Autonomous Organizations (DAOs): An integrative model and re-\nsearch agenda. Technological Forecasting and Social Change, 182:121806,\nSept. 2022.\n[250] M. Schillig. Decentralized Autonomous Organizations (DAOs) under En-\nglish Law, Sept. 2022.\n[251] M. Schletz, A. Constant, A. Hsu, S. Schillebeeckx, R. Beck, and M. Wain-\nstein. Blockchain and regenerative \ufb01nance: charting a path toward regen-\neration. Frontiers in Blockchain, 6:1165133, July 2023.\n[252] N. Schneider. Cryptoeconomics as a Limitation on Governance. 2021.\n[253] T. Scholz and N. Schneider, editors. Ours to Hack and to Own: The Rise\nof Platform Cooperativism, A New Vision for the Future of Work and a\nFairer Internet. OR Books, 2016.\n[254] J. A. Schumpeter.\nCapitalism, Socialism, and Democracy.\nHarper &\nBrothers, \ufb01rst edition edition, 1942.\n[255] J. Schwartz. Collective Choice, 2011.\n[256] C. M. Schweik and R. C. English. Internet Success: A Study of Open-\nSource Software Commons. The MIT Press, June 2012.\n[257] R. W. Scott. Institutions and Organizations. Ideas, Interests and Iden-\ntities.Paperback: 360 pages Publisher: Sage (1995) Language: English\nISBN: 978-142242224. M@n@gement, 17(2):136\u2013140, 2014.\n[258] W. R. Scott and J. W. Meyer. Institutional Environments and Organiza-\ntions: Structural Complexity and Individualism. SAGE Publications, Inc,\nThousand Oaks, Calif, 1st edition edition, Apr. 1994.\n[259] N. Seaver. Algorithms as Culture: Some Tactics for the Ethnography of\nAlgorithmic Systems. Big Data and Society, 4(2), 2017.\n91\n[260] G. Selgin. Bitcoin: Problems and Prospects. Apr. 2022. Publisher: Cato\nInstitute.\n[261] P. M. Senge.\nThe \ufb01fth discipline: the art and practice of the learning\norganization. Doubleday/Currency, New York, rev. and updated edition,\n2006. OCLC: ocm65166960.\n[262] M. M. Sharif and F. Ghodoosi. The Ethics of Blockchain in Organizations.\nJournal of Business Ethics, 178(4):1009\u20131025, July 2022.\n[263] T. Sharma, Y. Kwon, K. Pongmala, H. Wang, A. Miller, D. Song, and\nY. Wang.\nUnpacking How Decentralized Autonomous Organizations\n(DAOs) Work in Practice, Apr. 2023. arXiv:2304.09822 [cs].\n[264] J. Shepherd. Are Corporations Moral Agents? | Practical Ethics, Dec.\n2015.\n[265] A. Shleifer and R. Vishny. A Survey of Corporate Governance. Journal\nof Finance, 52(2):737\u2013783, 1997.\n[266] T. Shorin, J. Pope, L. Lotti, A. Z. Lewis, and M. Gomez. Uniswap Re-\nsearch Report: Discord, Governance, Community, Aug. 2021.\n[267] R. H. L. Sim, Y. Zhang, M. C. Chan, and B. K. H. Low. Collaborative\nMachine Learning with Incentive-Aware Model Rewards. 2020. Publisher:\n[object Object] Version Number: 1.\n[268] H. A. Simon. The sciences of the arti\ufb01cial. The MIT Press, Cambridge,\nMassachusetts, third edition [2019 edition] edition, 2019.\n[269] D. Skarbek. Governance and Prison Gangs. American Political Science\nReview, 2011.\n[270] C. E. Smith, B. Yu, A. Srivastava, A. Halfaker, L. Terveen, and H. Zhu.\nKeeping Community in the Loop: Understanding Wikipedia Stakeholder\nValues for Machine Learning-Based Systems. In Proceedings of the 2020\nCHI Conference on Human Factors in Computing Systems, pages 1\u201314,\nHonolulu HI USA, Apr. 2020. ACM.\n[271] V. V. Sochat, I. W. Eisenberg, A. Z. Enkavi, J. Li, P. G. Bissett, and\nR. A. Poldrack. The Experiment Factory: Standardizing Behavioral Ex-\nperiments. Frontiers in Psychology, 7, 2016.\n[272] B. Srinivasan. The Network State: How to Start a New Country. 2022.\n[273] L. Stanczyk.\nProductive Justice.\nPhilosophy and Public A\ufb00airs,\n40(2):144\u2013164, 2012.\n[274] S. Ste\ufb00en, B. Bichsel, M. Gersbach, N. Melchior, P. Tsankov, and\nM. Vechev. zkay: Specifying and Enforcing Data Privacy in Smart Con-\ntracts. Proceedings of the 2019 ACM SIGSAC Conference on Computer\nand Communications Security, pages 1759\u20131776, Nov. 2019.\n92\n[275] A. Stilz. Territorial boundaries and history. Politics, Philosophy & Eco-\nnomics, 18(4):374\u2013385, Nov. 2019.\n[276] A. L. Stinchcombe. Social structure and organizations. In J. A.C. Baum\nand F. Dobbin, editors, Economics Meets Sociology in Strategic Manage-\nment, volume 17 of Advances in Strategic Management, pages 229\u2013259.\nEmerald Group Publishing Limited, Jan. 2000.\n[277] V. Storr. Understanding the Culture of Markets, 2013.\n[278] M. C. Suchman. Managing legitimacy: Strategic and institutional ap-\nproaches. The Academy of Management Review, 20:571\u2013610, 1995. Place:\nUS Publisher: Academy of Management.\n[279] J. Suchow, T. Morgan, and T. Gri\ufb03ths. Dallinger, Aug. 2023.\n[280] A. J. Sulkowski.\nThe Tao of Dao:\nHardcoding Business Ethics on\nBlockchain. Business & Finance Law Review, 3:146, 2019.\n[281] X. Sun, X. Chen, C. Stasinakis, and G. Sermpinis. Voter Coalitions and\ndemocracy in Decentralized Finance: Evidence from MakerDAO, June\n2023. arXiv:2210.11203 [cs, q-\ufb01n].\n[282] L. Swartz. Theorizing the 2017 blockchain ICO bubble as a network scam.\nNew Media & Society, 24(7):1695\u20131713, July 2022.\n[283] C. Tan. Tracing Community Genealogy: How New Communities Emerge\nfrom the Old. Proceedings of the International AAAI Conference on Web\nand Social Media, 12(1), June 2018. Number: 1.\n[284] J. Z. Tan, M. Langenkamp, A. Weichselbraun, A. Brody, and L. Korpas.\nThe Constitutions of Web3. 2022.\n[285] J. Z. Tan, I. Patka, I. Gershtein, E. Eithcowich, M. Zargham, and\nS. Furter. ERC-4824: Common Interfaces for DAOs [DRAFT]. Ethereum\nImprovement Proposals, (4824), Feb. 2022.\n[286] N. TeBlunthuis and B. M. Hill. Identifying Competition and Mutualism\nbetween Online Groups. Proceedings of the International AAAI Confer-\nence on Web and Social Media, 16:993\u20131004, May 2022.\n[287] A. Thiel.\nPolycentric Governing and Polycentric Governance.\nIn\nF. Gadinger and J. A. Scholte, editors, Polycentrism: How Governing\nWorks Today, page 0. Oxford University Press, May 2023.\n[288] D. Thulke, Y. Gao, P. Pelser, R. Brune, R. Jalota, F. Fok, M. Ramos,\nI. van Wyk, A. Nasir, H. Goldstein, T. Tragemann, K. Nguyen, A. Fowler,\nA. Stanco, J. Gabriel, J. Taylor, D. Moro, E. Tsymbalov, J. de Waal,\nE. Matusov, M. Yaghi, M. Shihadah, H. Ney, C. Dugast, J. Dotan, and\nD. Erasmus. ClimateGPT: Towards AI Synthesizing Interdisciplinary Re-\nsearch on Climate Change.\n2024.\nPublisher: [object Object] Version\nNumber: 1.\n93\n[289] A. Thurman.\n\u2018Curve Wars\u2019 Heat Up: Emergency DAO Invoked After\n\u2018Clear Governance Attack\u2019. CoinDesk, Nov. 2021. Section: Finance.\n[290] L. L. Tsai. Accountability without Democracy: Solidary Groups and Public\nGoods Provision in Rural China. Cambridge University Press, 2007.\n[291] G. Tsebelis. Veto Players: How Political Institutions Work. Princeton\nUniversity Press, 2002.\n[292] T. Vaitiekunas. Dialektos: Privacy-preserving Smart Contracts. IACR\nCryptol. ePrint Arch., 2022.\n[293] D. Ventures. www.deepdao.io. Accessed October 26, 2022.\n[294] S. Verba and N. H. Nie. Participation in America: Political Democracy\nand Social Equality. University of Chicago Press, 1987.\n[295] H. W. Volberda, N. Van Der Weerdt, E. Verwaal, M. Stienstra, and A. J.\nVerdu.\nContingency Fit, Institutional Fit, and Firm Performance: A\nMeta\ufb01t Approach to Organization\u2013Environment Relationships. Organi-\nzation Science, 23(4):1040\u20131054, Aug. 2012.\n[296] S. Voshmgir and M. Zargham. Foundations of Cryptoeconomic Systems.\nTechnical report, Research Institute for Cryptoeconomics, Vienna, 2019.\n[297] S. Wang, W. Ding, J. Li, Y. Yuan, L. Ouyang, and F.-Y. Wang. Decen-\ntralized Autonomous Organizations: Concept, Model, and Applications.\nIEEE Transactions on Computational Social Systems, 6(5):870\u2013878, Oct.\n2019.\n[298] B. R. Weingast. The Economic Role of Political Institutions: Market-\nPreserving Federalism and Economic Development. Journal of Law, Eco-\nnomics, & Organization, 1995.\n[299] P. H. Werhane. Corporate Moral Agency and the Responsibility to Re-\nspect Human Rights in the UN Guiding Principles: Do Corporations Have\nMoral Rights? Business and Human Rights Journal, 1(1):5\u201320, Jan. 2016.\n[300] L. White. The Market for Cryptocurrencies. Cato Journal, 35(2):383\u2013402,\n2015. Publisher: Cato Journal, Cato Institute.\n[301] A. Wigderson. Mathematics and Computation: A Theory Revolutionizing\nTechnology and Science. Princeton University Press, Princeton, NJ, Oct.\n2019.\n[302] J. Wigginton, M. Jano\ufb00, J. Perkins, T. Morrey, S. Burton, J. Volz,\nA. Truths, D. Antoni, and S. Heiser. Cooperatives: An Ownership Model\nfor Digital Networks. Technical report, National Society of Accountants\nfor Cooperatives, Jan. 2023.\n94\n[303] O. E. Williamson. Markets and Hierarchies: Analysis and Antitrust Im-\nplications: A Study in the Economics of Internal Organization, 1975.\n[304] C. Woetzel.\nSecret Network: A Privacy-Preserving Secret Contract &\nDecentralized Application Platform. 2022.\n[305] G. Wood. Polkadot: Vision for a heterogenous multi-chain framework.\nNov. 2016.\n[306] A. Wright and C. P. o. L. a. B. N. C. S. o. Law. The Rise of Decentral-\nized Autonomous Organizations: Opportunities and Challenges. Stanford\nJournal of Blockchain Law & Policy, June 2021.\n[307] S. A. Wright.\nMeasuring DAO Autonomy: Lessons From Other Au-\ntonomous Systems.\nIEEE Transactions on Technology and Society,\n2(1):43\u201353, Mar. 2021.\n[308] T. Xie, J. Zhang, Z. Cheng, F. Zhang, Y. Zhang, Y. Jia, D. Boneh, and\nD. Song. zkBridge: Trustless Cross-chain Bridges Made Practical. In Pro-\nceedings of the 2022 ACM SIGSAC Conference on Computer and Com-\nmunications Security, CCS \u201922, pages 3003\u20133017, New York, NY, USA,\nNov. 2022. Association for Computing Machinery.\n[309] D. Yermack. Corporate Governance and Blockchains*. Review of Finance,\n21(1):7\u201331, Mar. 2017.\n[310] M. Zargham and K. Nabben. Aligning \u2018Decentralized Autonomous Orga-\nnization\u2019 to Precedents in Cybernetics, Apr. 2022.\n[311] M. Zargham, K. Paruch, and J. Shorish. Economic Games as Estima-\ntors. In P. Pardalos, I. Kotsireas, Y. Guo, and W. Knottenbelt, editors,\nMathematical Research for Blockchain Economy, Springer Proceedings in\nBusiness and Economics, pages 125\u2013142, Cham, 2020. Springer Interna-\ntional Publishing.\n[312] M. Zargham and J. Shorish. Generalized Dynamical Systems Part I: Foun-\ndations. Technical report, Institute for Cryptoeconomics, Interdisciplinary\nResearch, WU Vienna University of Economics and Business, Vienna,\n2022.\n[313] M. Zargham, J. Shorish, and K. Paruch. From Curved Bonding to Con-\n\ufb01guration Spaces. In 2020 IEEE International Conference on Blockchain\nand Cryptocurrency (ICBC), pages 1\u20133, May 2020.\n[314] Zhang, Luyao, Ma, Xinshi, and Liu, Yulin. SoK: Blockchain Decentral-\nization. ArXiv, 2023.\n[315] Q. Zhong and S. Frey. Institutional similarity drives cultural similarity\namong online communities. Scienti\ufb01c Reports, 12(1):18982, Nov. 2022.\n95\n[316] Q. Zhong, S. Frey, and M. Hilbert. Quantifying the Selective, Stochastic,\nand Complementary Drivers of Institutional Evolution in Online Commu-\nnities. Entropy, 24(9):1185, Sept. 2022.\n[317] T. B. Zilber. Institutionalization as an Interplay between Actions, Mean-\nings, and Actors: The Case of a Rape Crisis Center in Israel. The Academy\nof Management Journal, 45(1):234\u2013254, 2002.\nPublisher: Academy of\nManagement.\n[318] L. G. Zucker. The Role of Institutionalization in Cultural Persistence.\nAmerican Sociological Review, 42(5):726\u2013743, 1977. Publisher: [American\nSociological Association, Sage Publications, Inc.].\n[319] E. Zuckerman. What is Digital Public Infrastructure? Technical report,\nCenter for Journalism & Liberty, 2020.\n[320] G. Zyskind, O. Nathan, and A. Pentland. Enigma: Decentralized Compu-\ntation Platform with Guaranteed Privacy, June 2015. arXiv:1506.03471\n[cs].\n96\n",
    "2209.02446": "1\nWeb3 Challenges and Opportunities for the\nMarket\nDan Sheridan\u2020, James Harris\u2020, Frank Wear\u2020,Jerry Cowell Jr\u2020, Easton Wong\u2020, Abbas Yazdinejad\u2021\n\u2020College of Computing and Software Engineering, Kennesaw State University, GA, USA\nhsherid2@students.kennesaw.edu; Ewong6@students.kennesaw.edu ; jharr651@students.kennesaw.edu;\nfwear@students.kennesaw.edu; jcowellj@students.kennesaw.edu\n\u2021Cyber Science Lab, School of Computer Science, University of Guelph, Ontario, Canada\nayazdine@uoguelph.ca\nAbstract\u2014The inability of a computer to think has been a limiter in its usefulness and a point of reassurance for humanity since the\n\ufb01rst computers were created. The semantic web is the \ufb01rst step toward removing that barrier, enabling computers to operate based on\nconceptual understanding, and AI and ML are the second. Both semantic knowledge and the ability to learn are fundamental to web3,\nas are blockchain, decentralization, transactional transparency, and ownership. Web3 is the next generational step in the information\nage, where the web evolves into a more digestible medium for users and machines to browse knowledge. The slow introduction of\nWeb3 across the global software ecosystem will impact the people who enable the current iteration. This evolution of the internet space\nwill expand the way knowledge is shared, consumed, and owned, which will lessen the requirement for a global standard and allow\ndata to interact ef\ufb01ciently, no matter the construction of the knowledge. The heart of this paper understands the: 1) Enablement of\nWeb3 across the digital ecosystem. 2) What a Web3 developer will look like. 3) How this alteration will evolve the market around\nsoftware and knowledge in general.\nIndex Terms\u2014Blockchain, Web3, Web3 Developers, Web3 Market, Semantic Web, Web3 Risks.\n!\n1\nINTRODUCTION\nDecentralization, blockchain technology, and token-based\neconomics are all concepts incorporated into Web3, a new\niteration of the World Wide Web [1]. The origin of Web3\ncan be traced to Tim Berners-Lee [2], the founder of the\nWorld Wide Web and the \ufb01rst person to summarize and\ndiscuss the idea of Web3, which he originally referred to\nas the \u201dSemantic Web\u201d. However, Web3 is currently de-\n\ufb01ned by a set of principles focused on decentralization,\nuser ownership of data, and cryptocurrency [3]. Berners-\nLee identi\ufb01es the initial challenge of creating a system that\nallows knowledge sharing with no central governance or\nforced commonalities that make sharing inherently tricky.\nThis idea was partially delivered by introducing search\nengines and globally accepted guidelines on structuring\ndata so that it can be indexed [4], which helped organize\ndata and make it more accessible. This combination of \u201ddo-\ngooding\u201d developers and growing search engines led to\nenormous amounts of shared data which is now accessible\nto a wide audience [4].\nWeb3, or the semantic web, has evolved from the idea of\ngrowing the Internet out of this inherent paradox of an ency-\nclopedia without a set organization to creator or user owner-\nship of the knowledge and assets that collectively comprise\nthe Internet. The solution, as identi\ufb01ed by Berners-Lee, is\nthe ability to pass data along with the rules and logic that\ngovern it from source to source while attempting to lose as\nlittle information as possible [4]. The implementation of this\nsolution is now contained in the public blockchains that are\nthe foundation of cryptocurrencies and smart contracts [5].\nThis in theory, resolves the limitation of needing developers\nto create knowledge in good faith to be able to be shared\nand indexed because of the ability to pass logic across the\nInternet. Berners-Lee also highlights that the bene\ufb01ts of this\nidea are not waiting for an astronomical breakthrough in\ntechnology where \u201dfuture software agents. . . can navigate\nthe wealth of its rich representations.\u201d Instead, it can be\ngradually realized as systems provide more detailed infor-\nmation [4], and the community makes a conscious effort\nto adopt those core principles of knowledge sharing enable-\nment and user ownership. With the connection between sys-\ntems through smart contracts, the bene\ufb01ts of a Web3 world\ncan begin to be realized as greater change comes over time.\nThis fundamental move to Web3 is not synonymous with\na technology upgrade but rather aligned with a growing\nInternet culture focused on data sharing and ownership\nthat can enable computers to process this data better for\nthe bene\ufb01t of the wider community. As Berners-Lee puts it,\n\u201dthink of the web today as turning all the documents in the\nworld into one big book, then think [Web3] as turning all the\ndata into one big database, or one big mathematical formula.\nWeb3 is not a separate web; it is a new form of information\nadding one more dimension to the diversity of the one web\nwe have today\u201d [4]. Simply put, Web1 was read-only. Web2\nwas read-write. Web3 is read-write-own [6].\narXiv:2209.02446v1  [cs.CY]  6 Sep 2022\n2\n2\nFOUNDATION OF WEB3 AND ENABLEMENT\nWeb3, as mentioned by Berners-Lee, is not going to hinge\non a technological breakthrough, although there is evidence\nalready of creative libraries that enable Web3 ideas. Web3 is\nan ideological shift in how the Internet of data is constructed\nthat can be enabled with existing technology to produce\nbene\ufb01ts today. The enablement of Web3 will depend on\nthe transition to Web3 libraries and concepts by knowledge\nand data creators. The foundational items that currently\ncomprise the Web3 framework are blockchain networks\n(decentralized [7] but connected nodes), Web3 libraries,\nemerging specialized languages (Solidity), identity stores\n(wallets), smart contracts, and specialized service providers\n[8].\n2.1\nBlockchains (Bitcoin, Ethereum, etc.)\nThe public blockchains are the core pipelines for all trans-\nactions and interactions that occur within Web3 applica-\ntions. They are the public ledgers of record, decentralized\nand immutable [9]. A global permissionless database that\nprovides the ability to track the ownership chain of any\nasset or piece of data that exists on the blockchain at any\ntime by anyone. While made popular by cryptocurrencies,\ntheir utility extends to any form of data. This is about\nFacebook or any other social network moving your pro\ufb01le\nto a blockchain where you have complete control to grant,\nrevoke, or even sell your data rather than giving it away\nfor the utility of using the social network. In Web2, the\nnetwork controlled and held all the value. The principles\nof Web3 dictate that the data holds all the value, not the\nnetwork. Web3 is an ideological shift for the Internet, just as\nWeb2 was for Web1. As users interact across Web3 and its\nassociated frameworks, there is a functional need to house\nthe necessary transactions and interactions. The Web3 com-\nponents which provide this service and enable blockchains\nto function are known as nodes. Without nodes, the appli-\ncations cannot communicate; thus, the decentralization of\napplications becomes voided. Nodes facilitate the tracking\nof data and are the multiple storehouses that exist to \ufb01ght\nagainst data loss threats [8] and have additional copies of\nthe interaction. This also makes transactions veri\ufb01able and\nimmutable because this would be the corroborating source\nfor other Web3 applications.\n2.2\nWeb3 Libraries\nThe Web3 libraries provide a set of application program-\nming interfaces to bridge blockchains and smart con-\ntracts, enabling the creation of a new class of applica-\ntions, commonly known as Decentralized Applications (aka\nDApps). By their very de\ufb01nition, Web3 applications utilize a\nblockchain. Ethereum is the most common blockchain used\nby DApps as Ethereum was created to support applica-\ntion development and has a governance model speci\ufb01cally\ncrafted to be developer friendly. Web3.js, Next.js, Ether.js,\nand Truf\ufb02e Suite [8] are commonly used Web3 applica-\ntion development libraries, which are all JavaScript based.\nCloud\ufb02are provides an example of this interaction here,\nwhich hosts an open-source NFT project to explain Web3\nand blockchain [10].\nFig. 1. System targets from a user-centric explainable AI framework [8]\n2.3\nIdentity Stores (Wallets)\nWith ownership being at the heart of the Web3 principles,\nimmutable identities are a requirement. Wallets are applica-\ntions that store and protect the identity used for interacting\nwith blockchain and facilitate the literal transaction. This\nwallet is the \u201c\ufb01nal authority of your data\u201d and can be\nany entity [10]. Transactions are totaled here, and all the\ninteractions with knowledge will also be tracked here.\n2.4\nSmart Contracts\nA smart contract [11] is akin to what Berners-Lee was talking\nabout when passing the rules along with the knowledge.\nSmart contracts act as a conditional mechanism to make\nsomething happen that is fully transparent and separate\nfrom any intermediary to ful\ufb01ll a transaction. Smart con-\ntracts rely on nodes to validate the data of a wallet account\nand pass in the parameters to provide the output of a\nsmart contract condition. Essentially, smart contracts are\ncodes that re\ufb02ect the logic of the transaction two parties are\nexecuting. Every interaction with a smart contract is then\nrecorded in a \u2018block\u2019 on the \u2018chain\u2019 by the node executing\nthe contract [12]. These would act as the access points of\nknowledge sharing permission or a point of passing the\nuniversal logic. These concepts have contributed to the early\nlandscape of Web3 and are critical cogs to a functioning\nnetwork of decentralized data points, knowledge sharing,\nand registered owners.\n2.5\nVirtual Reality Systems\nVirtual reality has evolved beyond games today, and peo-\nple use it for art, tourism, and industrial purposes [13].\nTicketing or fees must be paid for this purpose, and a\nblockchain is an excellent solution for completely secure\npayments [13], [14]. Blockchains provide a distributed cryp-\ntographic ledger that cannot be trusted. There is no need\nfor a trusted authority to verify a party\u2019s interaction [15],\n[16]. Depending on how users log in and their access rights,\nthere are different types of blockchain, including private,\npublic, and consortium. Generally, blockchain-based virtual\nreality platforms use a blockchain for supporting Web3 so\nthat anyone can easily participate. Virtual reality in the\nblockchain process involves hashing all the information the\n3\nuser provides, then encrypting the private key on the user\u2019s\ndevice and generating a digital signature. On a peer-to-peer\n(P2P) network, transaction data is sent to peers along with\na digital signature. Using the public key, network members\ndecrypt the device by comparing its hash against the hash\nof the transaction data. Due to the widespread use of Web3\ntechnology, concerns have been raised about information\ntheft, hacking, dissemination, and copying. Consequently,\nmany companies are using virtual reality, because they\nare unable to limit supply. To support virtual reality in\nthe middle of Web3, a blockchain is an ideal solution for\ncreating decentralization, security, and transparency [17],\n[18]. The data recorded in the virtual reality system cannot\nbe altered, and its use can be easily traced. As a result of\nutilizing blockchain technology, security is increased, and\nthe user experience is improved. Virtual reality security and\ntrust can be improved by utilizing blockchain.\n3\nA WEB3 DEVELOPER\nWeb3 as a concept has created a market for developers with\nskillsets that can enable and manage the core functions of\nknowledge and data-sharing-centric network. With Web3\nbeing tied heavily to the current cryptocurrency infrastruc-\nture that is aligned with the core principles of Web3, there\nhas been a large move of users contributing to the most\nsigni\ufb01cant public GitHub repositories involving the Web3\ndevelopment stack, according to Richard MacManus at the\nNew Stack [19] due to the interest stirred by the recent\npopularity of cryptocurrency. This population of around\n18,000 developers is likely an underestimate of the active\nbase, as there is no information on the true amount of pri-\nvate proprietary Web3 developers. Consensys, the makers\nof popular Web3 development tools and services, reported\n350,000 active developers using its Infura blockchain devel-\nopment platform in November 2021 [20]. By April 2022 \u2013 the\ntime of the creation of this paper \u2013 this number had grown to\n430,000 active developers [21]. According to the New Stack,\nthis \ufb01gure is a \u201cdrop in the bucket,\u201d with the likelihood of\nthis population growing more in the coming years as this\nmarket has the potential to rapidly expand if the market\nfor decentralized and interconnected applications becomes\na wider norm for software and technology companies. In\nthis market, a Web3 developer does not look vastly different\nfrom other developers, with the difference being experi-\nenced in the core concepts of blockchain, digital wallets,\nsmart contracts, and the Web3 libraries mostly written in\nJavaScript and Web3 service providers. Familiarity with the\ncore libraries is important in creating the core functions\nof a Web3 app which is no different from other \ufb01elds of\nsoftware development and relies on knowledge of some\nof the most popular languages to create this interaction,\nnamely JavaScript [8]. The one exception to this assertion\nis in the area of smart contracts, which are usually written\nin a specialized language in order to optimize performance.\nSome of these languages are Solidity, Rust, Yul, Vyper, and\nJavaScript. This area is also not restricted in any sense,\nwith open-source libraries available to whoever wants to\ninteract and use them. Web3 development looks to involve\nmore of a fundamental mindset shift in how applications\nand functions need to interact and the creation of readable\nscripts that other applications can tap into as portable\nnodes rather than querying a central server, very similar\nto querying cloud services. The ability to communicate with\nthe recording system is essential in being part of this Web3\nenvironment because all interactions across the environment\nrely on an audit log with speci\ufb01c conditions that need\nto be passed, sometimes referred to as a ledger \u2013 the\nblockchain. Experience with data security is also a key trait\nfor Web3 developers based on the general infrastructure\nthat Web3 is founded on, passing data around transactions\nthrough ledgers and conditional function codes known as\nsmart contracts. This interaction is different from most other\ncentral-based systems, where logging is always a reference\npoint back to internal systems through various inputs rather\nthan a wider network of checks that are highly portable\nand accessible via a blockchain network. Security on a\nblockchain is enforced at every entry and execution point on\nthe chain. If you do not meet the security requirements of\nthe blockchain, your application will not be able to execute\nsmart contracts or write to the blockchain. The governing\nbody of the blockchain sets the security standards, or the\nDAO \u2013 Decentralized Autonomous Organization \u2013 their\npublished bylaws. Fundamentally, Web3 developers look\nvery much like other software developers today but work\nwith specialized concepts and tools speci\ufb01c to blockchain\ntechnologies. Demand will continue to grow for Web3 de-\nvelopers. The population of around 430,000 will also enable\nthese \ufb01rst-comers to make potentially ground-breaking con-\ntributions to the space and push Web3 forward. The market\nwill continue to grow for some time, and the developers\nlooking for new challenges and the likes of the \u2019do-gooding\u2019\ndevelopers that helped push Web2 are most likely going\nto join in the coming years. The continual fascination with\nblockchain as a technology and its applications will also be\na part of this growing market with estimates as high 34.1%\nCAGR (compounded annual growth rates) over the next 10\nyears [22]. With blockchain being closely tied to Web3 as an\nenabler, this will create more developers capable of pushing\nthe Web3 principles in other areas outside the core areas\nright now of banking, cybersecurity, and cryptocurrency.\nDevelopers wishing to explore a shift in their careers can\n\ufb01nd many helpful free resources, from job boards [23] to\nguides to learning Web3 technologies [24], [25].\n4\nWEB3 IMPACT\nIn order to understand Web3, we must \ufb01rst understand the\nplace of the web in the network architecture, as shown in\nFig 2 In this way, real-world applications can help us better\nunderstand web functionality.\nWeb3 aims to be an evolution into an open, permission-\nless, decentralized environment for the Internet that will\nhave widened the scope of knowledge and data accessibility\nand fundamentally shifted the economics upon adoption\n[26]. Whether this adoption is contingent on technology\nor ideology, these principles will hold true on the overall\nimpact in both the market and the internet ecosystem. The\ncore impact will be on how computers will interact with\nother computers for the bene\ufb01t of users and who owns\nthe outcome. This will create smarter searches and better\napplication of smart technology to put the ownership of\n4\nFig. 2. The place of web in the network architecture\nthe outcomes in the hands of the users and creators rather\nthan the intermediaries of Web2. Web3 will be structured\nas open-source code, not reliant on the big middlemen\nthat enable accessing of content today, such as Google,\nMicrosoft, and Facebook as examples [26]. That is until\nBig Tech creates their own blockchains, makes them public,\nand incentivizes developers with airdrops backed by the\ncompany\u2019s stock to use their tools and services, making\nthe developers owners of the company. The development of\nWeb3 has become transparent to allow software developers\nto utilize the growing library of publicly accessible Web3\npackages and libraries to build the ecosystem as soon as\ninformation becomes available, accelerating the velocity of\nevolution. This availability of the infrastructure will enable\nusers to create this Web3 ecosystem. A core piece of this\nidea is around permissionless technology where interactions\nare not reliant on trusted third parties to connect users,\nwhether through a search engine or transaction machine\n[26]. The goal will be to make this feasible by \u201dblockchain-\nlike\u201d infrastructure, if not the same libraries that blockchains\nuse today. The structure acts as its intermediaries, so peer\ncomputers can cut out the requirement of an intermediary\nby using universal logic and conditions to have transferable\ndata ledgers to track transactions and share knowledge\nbased on rules within the node through smart contracts.\nThis helps to protect against the concern of data theft by the\ncurrent infrastructure of Web2 that enables intermediaries to\ncapture your data and use it for their purposes, often mon-\netizing it in ways the creators of the data might not agree\nwith. Allowing the rules and conditions to be transferable\nand available without going through an intermediary can\nalso increase execution speed, transparency, and equitable\nownership. The reliance on large sole sources in the form\nof data warehouses that maintain knowledge is most likely\nto be disrupted by the principles of knowledge within\nWeb3. Adopting Web3 as the infrastructure creates more\nareas where data is stored, which mitigate major data-loss\nthreats, keeps data behind rules not maintained by one\nguardian, and keeps data from being hidden and controlled\nby middlemen that disperse the data not necessarily to the\nbene\ufb01t of the user base [26]. Decentralization of data storage\nis a core feature of Web3 that will allow users to create more\ncontent and follow a universal logic to share information\nrather than conforming to an intermediary that acts as a\ngatekeeper that pushes a framework requirement to best\nshare out the work [26]. Lessening the effort required to\ncreate new content accessible can make the whole process\nof knowledge sharing and value creation a lot faster than it\nis today through the use of Web3 principles and technology.\n5\nWEB3 RISKS\nWith the emergence of this new Web3 ecosystem which is\nprojected to have a large swath of in\ufb02uence, there are some\ninherent risks based on the core infrastructure of Web3 and\nblockchain technology as a whole [27].\n5.1\nLack of Regulation and Oversight\nToday, blockchain technology interfaces within the Web3\nlandscape are essentially unregulated, with a general lack\nof understanding by most regulators. There are no written\nlaws or advisory boards overseeing how this ecosystem\noperates, which poses a risk of bad actors and bad faith\ninteractions occurring. This open space of operation has\nregulatory boards struggling to de\ufb01ne even the structure of\nwhat are \u2019entities\u2019 within this operation, such as how even\nto de\ufb01ne what a \u201cblockchain-enabled organization\u201d is in\ncomparison to other companies [28]. Blockchains are oper-\nated by Decentralized Autonomous Organizations (DAO\u2019s)\nwith varying and non-standard governance models by\ncommon business standards [29]. DAOs are organizations\nrepresented by rules encoded as a transparent computer\nprogram, controlled by the organization members, and not\nin\ufb02uenced by a central government [30]. Transactions pose\nanother risk based purely on the global scope of how Web3\ncan interact, with a central point not existing in any of these\necosystems. For knowledge sharing of particular materials,\nthe jurisdiction of regulation is unclear because it can exist\nin many different environments and tracking a geographic\norigin might be impossible. Countries, regions, and govern-\ning bodies have different regulations for more traditional\nknowledge sharing that would be disrupted by how Web3\nand blockchain operate without a framework to govern this.\nWith services being provided through a Web3 environment,\nthere are also \ufb01nancial implications in how those are served\nand to what body. It is unreasonable to believe that because\nthere is not one singular regional source that governing bod-\nies will allow transactions to be monitored/taxed without\noversight for a long period of time. This would include\nhow bad faith transactions would work because currently,\nthere is no clear operating system to govern and ensure\npeople are behaving appropriately beyond the bylaws of\nthe DAOs. Traditional \u2018scams\u2019, insider trading, and various\nschemes can be adjudicated through justice systems that\nare not connected to or cover the framework of Web3\u2019s\nblockchains. This new business model of promoting peer-\nto-peer transactions now puts the risks with users instead of\nwhat used to be managed by central intermediaries, which is\n5\nan inherent risk of working with blockchain technology [31].\nFor example, a current blockchain/cryptocurrency scheme\nthat exists (which does not directly tie into Web3 and the\nsemantic web but provides an overview of potential risks) is\nreferred to as a crypto pump and dump, which is parallel to\ninsider trading on big events. An organization will promote\na cryptocurrency they may have a large stake in to push\nthe value up considerably before cashing out and typically\ncrashing a currency with new entrants bearing the brunt of\nthe losses. Because most governing bodies do not consider\ncryptocurrency as a security, let alone a commodity or actual\ncurrency, there is no legal precedent for doing anything\nabout this practice that is parallel to an illegal activity [32].\nAs Web3 is adopted and operates for a wider audience,\nregulation boards should move closer to providing guide-\nlines and direction to ensure the safety of consumers and\nbusinesses from bad actors [?]. This will also be a big pillar\nof credibility to this area of what exists now as the gray area\nwith few legal de\ufb01nitions.\n5.2\nPortability of Illegal Items\nWeb3, as professed in the previous material, is focused on\nallowing knowledge to be shared without a required frame-\nwork where information can be easily queried and passed\nalong with the rules that de\ufb01ne it. The ecosystem now exists\nwithin a connected framework where each node houses the\nsame universal information that makes traceability hard.\nThis means bad actors can use these properties to create\nmaterial that is easily accessible by the people who want to\nview it and hidden from users who do not want to view it\nthrough a major component of Web3 as the smart contract.\nIllegal media could more easily exist in a Web3 framework\ndue to this decentralization that allows creators to be more\ninclined to release more of this knowledge and data due\nto the inherent security provided by a decentralized and\nconditionally accessed piece of knowledge. As a concept,\nthe portability of illegal items might make other internet\ncontent creators and providers hesitant to begin the full-\non shift based on the services they plan to make available,\nespecially with no plan/guideline in place to protect against\nthese questionable practices that, in parallel mediums are\nconsidered illegal [33]. This gap has a market in waiting, so\npotentially by the time Web3 is truly ready to be embraced,\ncompanies and services could be available to help combat\nthis issue with their own version of a secure smart contract\nand ledger. This could also be in combination with wider\nefforts of regulators to put in place guidelines on the opera-\ntion and have a better understanding of this space operates.\n5.3\nAccuracy of Information\nNow that, in the context of Web3, content is easily trans-\nmissible and not contained to a central source, there lies\na risk with the rapid movement of disinformation [34],\n[35]. The ability to send and receive information fast via\na Web3 framework has issues in highlighting good or bad\ninformation. Current state, content creators and providers\nhave the opportunity to monitor this information and cor-\nrect items because it is sourced in their own central area.\nWithin a Web3 framework, information can pass way faster\nwith no restrictions and no oversight. This issue is prevalent\ntoday through other semi-decentralized applications such\nas WhatsApp, which has had rampant issues in combating\ndisinformation in its own encrypted messaging platform\n[34].\n5.4\nPrivacy\nWith security at the forefront as a bene\ufb01t for the Web3\nframework, there is still a vague gap regarding data privacy\nand how interactions will be saved not only for a user\u2019s\nwallet but also within the network [32]. If an interaction is\nlogged within a ledger and that ledger exists everywhere,\nwhat sort of information does the wallet provide to get\nin, and will users be able to understand those implica-\ntions? This could mean now intermediaries do not control\npersonal data but potentially their peers. With data being\nfree \ufb02owing in this environment, there seems to be larger\nhurdles to surpass for data privacy, primarily when sources\nare not centered in regions but exist across networks. A\nuser-focused approach for Web3 empowers users and the\ninternet to be focused on them, but that does not provide\nthem the education on how their information is going to\nbe processed by each unique system, and this especially\nmeans regulators will not understand this either [32], [36].\nWeb2 policies around data privacy do not account for this\nframework and will need to be updated to account for the\nnew capabilities of the framework to process information\nand store it universally. This alone will put the full onus\non service providers to ensure they store this information\ncorrectly, which is not suf\ufb01cient without regulatory over-\nsight to provide clear direction on what that means. There is\ndanger in allowing companies to govern themselves because\nensuring that you are constantly doing the right thing does\nnot always \ufb01t with the plan, as we can review countless \ufb01rm\npractices that have put consumers and users in harm\u2019s way.\n5.5\nFuture Roadmap\nOur digital world faces new technologies ( e.g., Software De-\n\ufb01ned Network (SDN) [37], Network functions virtualization\n(NFV) [38], Arti\ufb01cial intelligence (AI) [39], Internet of things\n(IoT) [40], and Blockchain [41]) that directly and indirectly\naffect human life in education, business, industry, and the\nmilitary. Combined technologies have also improved con-\nstruction, energy, and resource ef\ufb01ciency [38], [40]. Web3\n[42] is one of today\u2019s hottest, most attractive, and most\nexciting technologies.\nWe anticipate that research on Web3 will move towards\nquantum, IoT, AI, and secure cloud-assisted areas. The\nreason behind this anticipation is the existence of trends\ntoward the application of security, Quantum, AI, IoT, and\nsecure cloud-assisted environments are interesting areas for\nacademic and industry sections [43]. Many companies are\ninvesting in Web3 applications and building their prod-\nucts to support them. Moreover, Fig. 3 summarizes the\nwidespread involvement of AI and IoT, Quantum with\nWeb3, for the future. Indeed, it shows that inspired AI\nsupported Web3 and the ability to Combination of Web3\nwith other technologies. It can prove these areas will move\ntoward Web3 quickly.\n6\nFig. 3. Combination of Web3 with other technologies\n5.6\nConclusion\nFast forward 10 years \u2013 all developers are Web3 developers\nof some form. The de\ufb01nition of \u201dfull stack\u201d will evolve.\nFront-end developers will remain focused on the user ex-\nperience but may have to deal with additional complexi-\nties of data coming from blockchains or sending data for\nsmart contract execution. Back-end developers will still deal\nwith server or cloud application-based logic, but the new\ncomplexities of blockchain and smart contract dependencies\nwill require new skill development. Blockchain and smart\ncontract layers will be added to the de\ufb01nition of \u201dfull stack\u201d,\ncreating new areas of specialization and opportunities. With\neach blockchain transaction being assigned a very speci\ufb01c\nvalue in terms of the transaction itself and the value of the\ndata contained in the blocks, security will become a very\nacute focus and a specialization unto itself. Web3 security\nwill be focused on the security of the blockchain and the\nsmart contracts, the points where the value is created and\nstored. Security practices will become ever more integrated\ninto the code of the applications, increasing the requirement\nof developers to obtain new skills and demonstrate secure\ncoding and development practices. The inherent risks posed\nby the current state of Web3 technologies create opportuni-\nties for growth and value creation. Likely, the jobs boom\nthat occurred as the industry began to understand what\nWeb2 meant in the context of Web1 will be dwarfed by the\njobs boom Web3 will generate. The fundamental economic\nshifts in the ideology of Web3 alone will trigger a tectonic\nshift we have never seen before. This, coupled with the\nscarcity of resources the industry expects over the next\ndecade, even without considering the impact of Web3, will\nprovide developers and other roles in software engineering\na tremendous opportunity to generate value and wealth\n[44], [45], [46].\nREFERENCES\n[1]\nM. Kovacova, J. Horak, and M. Higgins, \u201cBehavioral analytics,\nimmersive technologies, and machine vision algorithms in the\nweb3-powered metaverse world,\u201d Linguistic and Philosophical In-\nvestigations, vol. 21, pp. 57\u201372, 2022.\n[2]\nG. Kuck, \u201cTim berners-lee\u2019s semantic web,\u201d SA Journal of Informa-\ntion Management, vol. 6, no. 1, 2004.\n[3]\nJ. Beck, \u201c What is Web3? Here Are Some Way To Explain It To\nA\nFriend,\u201d\nhttps://consensys.net/blog/blockchain-explained/\nwhat-is-web3-here-are-some-ways-to-explain-it-to-a-friend/,\n2022.\n[4]\nT. Berners-Lee, \u201cThe Semantic Web. Tim Berners-Lee - Seman-\ntic\nWeb,\u201d\nhttps://www.w3.org/2000/Talks/0906-xmlweb-tbl/\ntext.html.\n[5]\nA. Yazdinejad, H. HaddadPajouh, A. Dehghantanha, R. M. Parizi,\nG. Srivastava, and M.-Y. Chen, \u201cCryptocurrency malware hunting:\nA deep recurrent neural network approach,\u201d Applied Soft Comput-\ning, vol. 96, p. 106630, 2020.\n[6]\nC.\nDempsey,\n\u201cWang,\nAngie;\nMart,\nJustin.\n\u201cA\nsimple\nguide\nto\nthe\nWeb3\nstack,\u201d\nhttps://blog.coinbase.com/\na-simple-guide-to-the-web3-stack-785240e557f0, 2022.\n[7]\nA. Yazdinejad, G. Srivastava, R. M. Parizi, A. Dehghantanha, K.-\nK. R. Choo, and M. Aledhari, \u201cDecentralized authentication of\ndistributed patients in hospital networks using blockchain,\u201d IEEE\njournal of biomedical and health informatics, vol. 24, no. 8, pp. 2146\u2013\n2156, 2020.\n[8]\nR. Huford, \u201cHire web3 Developers: Everything You Need\nto Know.\u201d Hire Web3 Developers: Everything You Need to\nKnow,\u201d https://blog.cloud\ufb02are.com/get-started-web3/,https://\ngithub.com/cloud\ufb02are/cfweb3, 2022.\n[9]\nA. Yazdinejad, A. Dehghantanha, R. M. Parizi, M. Hammoudeh,\nH. Karimipour, and G. Srivastava, \u201cBlock hunter: Federated learn-\ning for cyber threat hunting in blockchain-based iiot networks,\u201d\nIEEE Transactions on Industrial Informatics, pp. 1\u20131, 2022.\n[10] K. Freeman, \u201cGet Started Building web3 Apps with Cloud-\n\ufb02are,\u201d\nhttps://blog.cloud\ufb02are.com/get-started-web3/,https:\n//github.com/cloud\ufb02are/cfweb3, 2021.\n7\n[11] A. Singh, R. M. Parizi, Q. Zhang, K.-K. R. Choo, and A. Dehghan-\ntanha, \u201cBlockchain smart contracts formalization: Approaches\nand challenges to address vulnerabilities,\u201d Computers & Security,\nvol. 88, p. 101654, 2020.\n[12] M. Hussey, \u201cDaniel Phillips. \u201cWhat Are Smart Contracts and How\nDo They Work?\u201d https://decrypt.co/resources/smart-contracts,\n2022.\n[13] K. Viswanathan and A. Yazdinejad, \u201cSecurity considerations for\nvirtual reality systems,\u201d arXiv preprint arXiv:2201.02563, 2022.\n[14] G. Srivastava, R. M. Parizi, and A. Dehghantanha, \u201cThe future of\nblockchain technology in healthcare internet of things security,\u201d\nBlockchain cybersecurity, trust and privacy, pp. 161\u2013184, 2020.\n[15] A. Yazdinejad, A. Dehghantanha, H. Karimipour, G. Srivastava,\nand R. M. Parizi, \u201cAn ef\ufb01cient packet parser architecture for\nsoftware-de\ufb01ned 5g networks,\u201d Physical Communication, vol. 53,\np. 101677, 2022.\n[16] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, and H. Karimipour,\n\u201cFederated learning for drone authentication,\u201d Ad Hoc Networks,\nvol. 120, p. 102574, 2021.\n[17] A. Yazdinejad, G. Srivastava, R. M. Parizi, A. Dehghantanha,\nH. Karimipour, and S. R. Karizno, \u201cSlpow: Secure and low latency\nproof of work protocol for blockchain in green iot networks,\u201d in\n2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring).\nIEEE, 2020, pp. 1\u20135.\n[18] A. Yazdinejad, R. M. Parizi, G. Srivastava, A. Dehghantanha, and\nK.-K. R. Choo, \u201cEnergy ef\ufb01cient decentralized authentication in\ninternet of underwater things using blockchain,\u201d in 2019 IEEE\nGlobecom Workshops (GC Wkshps).\nIEEE, 2019, pp. 1\u20136.\n[19] R.\nMacManus,\n\u201cWeb3\nDeveloper\nEcosystem\nIs\nTiny,\nbut\nSteep\nUptake\nin\n2021,\u201d\nhttps://thenewstack.io/\nweb3-developer-ecosystem/, 2021.\n[20] C. Blog, \u201cOver 350K Web3 Developers Now Use Blockchain De-\nvelopment Platform Infura,\u201d 2021.\n[21] ConsenSys, \u201c Homepage with \ufb01gure,\u201d https://consensys.net/,\n2021.\n[22] B.\nMarket,\n\u201cFuture\nMarket\nInsights,\u201d\nhttps://www.\nfuturemarketinsights.com/reports/blockchain-market, 2022.\n[23] Web3.career., \u201cHomepage with job listing,\u201d https://web3.career/.\n[24] \u2014\u2014, \u201cLearn Web2 With These Free Resources (Updated 2022),\u201d\nhttps://web3.career/learn-web3, 2022.\n[25] M.\nNystrom,\n\u201cWeb3\nJobs:\nHow\nto\nGet\na\nJob\nin\nCrypto\n(Updated\n2022),\u201d\nhttps://messari.io/article/\nweb3-jobs-how-to-get-a-job-in-crypto-updated-2022, 2022.\n[26] GeeksforGeeks,\n\u201cHow\nWeb\n3.0\nIs\nGoing\nto\nImpact\nthe\nDigital\nWorld?\u201d,\u201d\nhttps://www.geeksforgeeks.org/\nhow-web-3-0-is-going-to-impact-the-digital-world/., 2021.\n[27] L. Steinberg.\n[28] M. Berberich and M. Steiner, \u201cBlockchain technology and the\ngdpr-how to reconcile privacy and distributed ledgers,\u201d Eur. Data\nProt. L. Rev., vol. 2, p. 422, 2016.\n[29] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, and K.-K. R. Choo,\n\u201cP4-to-blockchain: A secure blockchain-enabled packet parser for\nsoftware de\ufb01ned networking,\u201d Computers & Security, vol. 88, p.\n101629, 2020.\n[30] C. Hackl, \u201cWhat are daos and why you should pay attention,\u201d\nRetrieved June, vol. 1, p. 2021, 2021.\n[31] E. Zamani, Y. He, and M. Phillips, \u201cOn the security risks of the\nblockchain,\u201d Journal of Computer Information Systems, vol. 60, no. 6,\npp. 495\u2013506, 2020.\n[32] L. Y. Gely-Rojas, \u201cCryptocurrencies and the uniform commercial\ncode: The curious case of bitcoin,\u201d UPR Bus. LJ, vol. 8, p. 129, 2016.\n[33] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, G. Srivastava,\nS. Mohan, and A. M. Rababah, \u201cCost optimization of secure\nrouting with untrusted devices in software de\ufb01ned networking,\u201d\nJournal of Parallel and distributed Computing, vol. 143, pp. 36\u201346,\n2020.\n[34] A. D. Soto-V\u00b4asquez and M. S\u00b4anchez-Santos, \u201cEl cabal, vacunas,\ny donald trump: An analysis of spanish-language disinformation\nleading up to the us capitol insurrection,\u201d Cultural Studies Critical\nMethodologies, p. 15327086221093949, 2022.\n[35] A. Yazdinejadna, R. M. Parizi, A. Dehghantanha, and M. S.\nKhan, \u201cA kangaroo-based intrusion detection system on software-\nde\ufb01ned networks,\u201d Computer Networks, vol. 184, p. 107688, 2021.\n[36] R. M. Parizi, S. Homayoun, A. Yazdinejad, A. Dehghantanha, and\nK.-K. R. Choo, \u201cIntegrating privacy enhancing techniques into\nblockchains using sidechains,\u201d in 2019 IEEE Canadian Conference\nof Electrical and Computer Engineering (CCECE).\nIEEE, 2019, pp.\n1\u20134.\n[37] A. Yazdinejad, A. Bohlooli, and K. Jamshidi, \u201cEf\ufb01cient design and\nhardware implementation of the open\ufb02ow v1. 3 switch on the\nvirtex-6 fpga ml605,\u201d The Journal of Supercomputing, vol. 74, no. 3,\npp. 1299\u20131320, 2018.\n[38] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, Q. Zhang, and K.-\nK. R. Choo, \u201cAn energy-ef\ufb01cient sdn controller architecture for\niot networks with blockchain-based security,\u201d IEEE Transactions on\nServices Computing, vol. 13, no. 4, pp. 625\u2013638, 2020.\n[39] A. Ekramifard, H. Amintoosi, A. H. Seno, A. Dehghantanha,\nand R. M. Parizi, A Systematic Literature Review of Integration of\nBlockchain and Arti\ufb01cial Intelligence.\nCham: Springer International\nPublishing, 2020, pp. 147\u2013160.\n[40] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, H. Karimipour,\nG. Srivastava, and M. Aledhari, \u201cEnabling drones in the internet\nof things with decentralized blockchain-based security,\u201d IEEE\nInternet of Things Journal, vol. 8, no. 8, pp. 6406\u20136415, 2020.\n[41] A. Yazdinejad, R. M. Parizi, A. Dehghantanha, and K.-K. R. Choo,\n\u201cBlockchain-enabled authentication handover with ef\ufb01cient pri-\nvacy protection in sdn-based 5g networks,\u201d IEEE Transactions on\nNetwork Science and Engineering, vol. 8, no. 2, pp. 1120\u20131132, 2019.\n[42] L. Cao, \u201cDecentralized ai: Edge intelligence and smart blockchain,\nmetaverse, web3, and desci,\u201d IEEE Intelligent Systems, vol. 37, no. 3,\npp. 6\u201319, 2022.\n[43] B. Zolfaghari, E. Rabieinejad, A. Yazdinejad, R. M. Parizi, and\nA. Dehghantanha, \u201cCrypto makes ai evolve,\u201d arXiv preprint\narXiv:2206.12669, 2022.\n[44] A. D. Carleton, E. Harper, J. E. Robert, M. H. Klein, D. De Niz,\nE. Desautels, J. B. Goodenough, C. Holland, I. Ozkaya, D. Schmidt\net al., \u201cArchitecting the future of software engineering: A national\nagenda for software engineering research and development,\u201d\nCARNEGIE-MELLON UNIV PITTSBURGH PA, Tech. Rep., 2021.\n[45] Y. Hailemariam, A. Yazdinejad, R. M. Parizi, G. Srivastava, and\nA. Dehghantanha, \u201cAn empirical evaluation of ai deep explainable\ntools,\u201d in 2020 IEEE Globecom Workshops (GC Wkshps.\nIEEE, 2020,\npp. 1\u20136.\n[46] C. M. Kayanan, \u201cA critique of innovation districts: Entrepreneurial\nliving and the burden of shouldering urban development,\u201d Envi-\nronment and Planning A: Economy and Space, vol. 54, no. 1, pp. 50\u201366,\n2022.\n",
    "2306.03351": "The current opportunities and challenges of Web 3.0\nYuqing Fan1,2,Tianyi Huang1,2,Yiran Meng1,2,Shenghui Cheng1,2\n1 Research Center for the Industries of the Future, Westlake University,Hangzhou,China\n2 School of Engineering,Westlake University,Hangzhou,China\nAbstract\nWith recent advancements in AI and 5G technologies,as well as the nascent concepts of blockchain and\nmetaverse,a new revolution of the Internet,known as Web 3.0,is emerging. Given its significant potential\nimpact on the internet landscape and various professional sectors,Web 3.0 has captured considerable\nattention from both academic and industry circles. This article presents an exploratory analysis of the\nopportunities and challenges associated with Web 3.0. Firstly, the study evaluates the technical differences\nbetween Web 1.0, Web 2.0, and Web 3.0, while also delving into the unique technical architecture of Web\n3.0. Secondly, by reviewing current literature, the article highlights the current state of development\nsurrounding Web 3.0 from both economic and technological perspective. Thirdly, the study identifies\nnumerous research and regulatory obstacles that presently confront Web 3.0 initiatives. Finally, the article\nconcludes by providing a forward-looking perspective on the potential future growth and progress of Web\n3.0 technology.\n1\nIntroduction\nThe Internet began in 1969 in the United States with the AppaNet, initially limited to research departments,\nschools, and government departments. In 1980, independent business networks began to develop. In 1989,\nTim Berners Lee formally proposed the idea of the World Wide Web, and in 1990, he developed the world\u2019s\nfirst web browser in the European particle physics laboratory in Geneva. In today\u2019s world, the Internet has\nbecome an indispensable part of production and life, and its development is related to the overall progress of\nan era. Since its inception, the Internet has gone through three stages: 1) Web 1.0 is an information-connected\nweb, where web pages are static and do not provide interaction; 2) Web 2.0 is the connection between people,\nwhere people can communicate on web pages; 3) Web 3.0 is a semantic network. In addition to interaction,\nWeb 3.0 also covers a large amount of data. Due to its decentralized characteristics, it can freely access data\nresource [19].\nWeb 3.0 was proposed by John Markoff in the New York Times in 2006. Research has pointed out\nthat Web 3.0 is a symbiotic entity of web technology and knowledge representation, a subfield of artificial\nintelligence [18]. Some studies also suggest that Web 3.0 is the next-generation network that integrates\ntechnology, law, and payment systems[6]. With the continuous development of Web 3.0, it has integrated\nmany emerging concepts, such as the metaverse, digital economy, and 5G. This integration is constantly\nchanging people\u2019s lives. For example, people can immerse themselves in the places they want to go home\nthrough virtual reality (VR) technology and the internet and interact with their peers\u2019 virtual digital human\nimages. These changes have made people\u2019s expectations for the internet increasingly strong. Table 1 compares\nthe differences between Web 1.0, Web 2.0, and Web 3.0. From Web 1.0 to Web 3.0, interaction has improved,\nand the amount of information available has also significantly increased. This continuously improves the user\nexperience[8].\nThe emergence of Web 3.0 represents a significant evolution in the realm of Internet technologies, marked\nby four key characteristics distinguishing it from its predecessors. Firstly, Web 3.0 is characterized by openness,\nwhich enables users to access various platforms utilizing only one account. Secondly, data privacy is ensured\nvia the decentralized structure of blockchain technology that protects user data ownership and eliminates\nreliance on third-party management platforms. The third key feature of Web 3.0 relates to cooperation,\nwhich is facilitated through token incentives designed to reward content creators for their contributions and\nfoster a more equitable platform. Lastly, interoperability refers to the degree to which third parties no longer\n1\narXiv:2306.03351v1  [cs.CY]  6 Jun 2023\nTable 1: Comparison among Web 1.0,Web 2.0 and Web 3.0\nWeb 1.0\nWeb 2.0\nWeb 3.0\nTime\n1996\n2006\n2016\nAttribute\nHypertext\nSocial media\nSemantic web\nMedium\nStatic texts\nInteractive contents\nVirtual contents\nInfrastructure\nPC\nCloud and mobile device\nBlockchain\nInteraction\nCompany publishes,\nusers can only read\nCompany establish platforms\nfor users to interact\nAnyone can\nestablish platforms\nSearching\nWidely search,\nresults are very vague\nSearch with keywords\nbring with accurate results\nMore accurate results\nusing big data\nconstrain user behaviors, thereby offering greater latitude in managing personal activities and engagements\nacross varying digital environments. See figure 1 for details.\nFigure 1: 4 characteristics of Web 3.0\nWeb 3.0 has garnered significant attention, with numerous high-tech companies rapidly positioning\nthemselves within this emerging landscape. For instance, Twitter has begun integrating various Web 3.0\napplications into its products, while Google established a dedicated Web 3.0 team in May 2022. Moreover,\nmany notable celebrities, including Stephen Chow, Jay Chou, and Junjie Lin, have prominently featured\nNFTs among their holdings. Importantly, at the national level, Web 3.0 represents a novel field of competitive\nengagement between countries. This competition extends beyond technological prowess, entailing a contest\nfor influence in the unfolding Internet ecosystem. The implications of these developments for the future of\ndigital society are profound and warrant further examination and exploration by scholars and practitioners\nalike.\nIn conclusion, Web 3.0 constitutes a profound transformation that will significantly impact various\naspects of our social, technological and economic lives. This comprehensive article aims to provide a detailed\nintroduction to the concept of Web 3.0. The contributions of this paper are multi-fold, including: 1. a\nthorough exposition of the connotations and applications of Web 3.0, and a comprehensive analysis of its\ncurrent development status from the perspectives of policy, market, and scientific research; 2. an exploration\nof the changes and opportunities that Web 3.0 presents, identifying its developmental requirements based\non these changes and opportunities; 3. an overview of the future prospects for the evolution of Web 3.0,\naddressing the potential risks emanating from this new technological paradigm.\n2\n2\nConnotation and application\nThis section first introduces the technology stack of Web 3.0, then provides six common functions of technology\nstack and provides use cases.\n2.1\nWeb 3.0 technology stack\nAs of January 2023, many papers have listed the technology stacks of Web 3.0. Guan [14] cited the five-layer\ntechnology stack proposed by the Web3 Foundation in 2017. The zero layer includes node communication\nand low-level programming. The first layer is responsible for providing interaction and transferring data. The\nsecond layer is used to extend the functions of the first layer. The third layer provides a readable language\nfor development. Ordinary users interact in the fourth layer. Jacksi [22] proposed a four-layer technology\nstack for Web 3.0. The first layer is the unified resource identifier, the second layer is the hypertext transfer\nprotocol(HTTP), the third layer is the file transfer protocol, and the last layer is the IP security protocol.\nSwati [38] gave a Web 3.0 technology stack composed of the application layer, blockchain framework layer,\nand blockchain network layer. In addition, Petcu [32] also proposed different Web 3.0 technology stack\narchitectures. Rasekh [33], Sarchandraa [36] and Zheng [51] proposed the technology stacks of Semantic Web,\nEthereum, and DApp respectively.\nThe Web 3.0 technology stack proposed by this paper is shown in 2, which is divided into six layers:\nFigure 2: Web 3.0 technology stack\nAt the bottom of the stack is the infrastructure layer. It provides a faster network environment for Web\n3.0. 5G technology adds the file form that can be transferred [42]; Chips expand the overall computing power\nof the device; The distributed architecture of edge computing alleviates traffic congestion [44]; Cloud native\nis used to help software development; Privacy computing can effectively prevent information disclosure[45].\nInfrastructure development can drive the development of the network layer and the protocol layer. For\nexample, P2P protocol can enable efficient file transmission and greatly relieve the pressure on the server.\nPlasma protocol improves the throughput of blockchain in the form of \"The chain in the chain\"[41]. In\n3\nTable 2: Classification of Web 3.0 applications\nClassification\nDescription\nExamples\nFinance\nIssue,trade and manage financial products\nand other traditional services\nUniswap,MetaMask\nInfrastructure\nProvide infrastructure services\nsuch as blockchain or on-chain storage\nEthereum,Antgroup\nSocial\nDigital community composed of enthusiasts\nalso contain media functions\nSapien,Steemit,Meta\nMultimedia\nProvide a variety of creative methods,\nand ensure creators can obtain\ncorresponding benefits\nBanklessDAO, Forefront\nGame\nA new form of game\nCrypto Dynasty,Splinterlands\nService\nOther services provide to users\nincluding telecommuting and digital medicine Horizon Workrooms,Ethlance\naddition, there are consensus mechanisms that allow nodes to vote, cryptography technologies that enhance\nsecurity on the chain, smart contracts that allow no third-party transactions, and chained storage.\nThrough various expansion devices, the equipment layer of Web 3.0 can provide users with multi-\ndimensional experiences, such as touch and hearing. For example, AR/VR/MR and other devices that bring\n3D experience provide tactile changes in body sense devices and mobile devices that make applications more\nconvenient.\nAbove the equipment layer is the software layer. Robotic Process Automation (RPA) can realize the\nautomation of massive repetitive processes and reduce labor costs. AI has added a learning function to RPA\nfor intelligent operation[25]. As the core of the development program, the engine can help developers quickly\nlay the program. The operating system provides management capabilities for terminal devices and software.\nAPI can help software interact well with other software.\nThis is how DApps are built on the technology stack. Compared with traditional software, DApps have\nmade great progress in a distributed architecture, body-sensing devices, software collaboration, and other\naspects. As a result, they can bring users a cross-era experience.\n2.2\nWeb 3.0 applications\nIn recent years, the applications of Web 3.0 has been in a blowout state. According to a survey, 57% of\nrespondents experienced at least one Web 3.0 application in 2022. By January 2023, the number of DAPPs\nin the global market has reached 6370, and the number of smart contracts has reached 16140 [28]. Table 2\nshows the classification of typical Web 3.0 applications on the market at present:\nThe financial industry is the field where many Web 3.0 applications are based. Web 3.0 can be combined\nwith existing financial instruments to create a new business model[5]. Ozili [30] et al. divided the existing\nWeb 3.0 financial applications into nine types: stable currency levy, loan, NFT issuance, non-intermediary\ntransaction, secondary market transaction, liquidity, e-wallet, and asset management. The digital banking\nsoftware released by banks automates traditional banking services through intelligent devices, bringing great\nconvenience to customers.\nSome enterprises choose to rent or sell infrastructure services and platforms related to Web 3.0. Taking\nblockchain as an example, many enterprises in China, such as Ant, Tencent, and Baidu, have provided alliance\nchain solutions; Onchain.storage chooses to provide on-chain storage services to help other DApp developers\nprovide data storage space.\nSocial media has been very hot in the era of Web 2.0, and the arrival of Web 3.0 will further upgrade\ncommunication between people. Meta has brought the metauniverse technology into social interaction and\nbrought participants an immersive experience through virtual imaging. Applying VR and somatosensory\ndevices will also bring further innovation to the social model.\nThe multimedia of Web 3.0 includes two specific functions. The first is providing creators with as\nmany creative methods as possible, and the second is establishing a platform to ensure that creators can\n4\nobtain corresponding benefits. Some digital design platforms even allow customers to customize their large-\nscale functions[26]. The application of this function includes RaidGuild, which provides consulting, design,\ndevelopment, and marketing services\u2014Flickr, which creates and shares diversified photos.\nThe virtual nature of the game makes it the first to embrace the ecosystem of Web 3.0. As a combination\nof game and decentralized finance, chain game allows assets in the game to circulate in the real world as\ncommodities. Decentraland is a 3D digital game platform. Players can exchange collectibles, purchase and\nsell digital assets in the game, and also interact through wearable devices [15].\nIn addition to the above five functions, there are some scattered functions. This article integrates it into\nother services that can provide users with an experience. It includes remote office service software such as\nHorizon Workrooms and Ethlance, Web 3.0 browsers with built-in encrypted wallets such as Brave and Osiris,\nand digital medical services for managing hospital files and assisting with medical examinations.\nOf course, most Web 3.0 applications have multiple functions simultaneously. For example, financial\nservices and social tools are a common combination. Take MakerDAO as an example, and its participants\ncan modify the Maker agreement by holding MKR tokens to vote. The MakerDAO community also has a\nstable currency Dai for storage, exchange, payment, and bookkeeping. The community also provides blogs\nand forums for participants to conduct social activities [11].\n3\nDevelopment status\nThe development of theory is a prerequisite for the development of Web 3.0 applications. Web 3.0 as a\nresearch area has a history that dates back to 2006. Although still in its nascent stage, significant strides have\nbeen made towards its advancement. For example, blockchain technology has found widespread application\nin the financial sector, whereas intelligent contracts and distributed applications are continuously being\ndeveloped and promoted. Other fundamental components of Web 3.0 such as semantic Web, distributed file\nsystems, metadata application, and the Internet of Things (IoT) are in the process of implementation or are\ndeveloping towards implementation, arousing extensive industry interest. Enterprises recognize that Web\n3.0 technology will significantly transform future business landscapes. Based on diverse perspectives from\nhome and abroad, and buttressed by empirical data, this paper examines the status of Web 3.0 from three\ndimensions of market, policy, and scientific research, analyzing its developmental trajectory and charting\npossible future directions.\n3.1\nMarket status\nIn 2014, the founder of Ethereum described the ideal operation mode of Web 3.0. By 2020, with the rapid\nspread of the concept of the metauniverse, Web 3.0 will arouse public discussion for another time. In recent\nyears, the market size of Web 3.0 has been increasing. This paper uses Messari 1 of Web 3.0-related industries\nto preliminary analyze the current market size. Figure 3 shows the market size of various fields under the\ncurrent Web 3.0 ecosystem. By January 29, 2023, the market size of Web 3.0 had reached US $102.14 billion,\nof which the largest market size was in the field of payments, reaching US $63.45 billion. On the other hand,\nthe market size of Media and Entertainment is the smallest, with only US $940 million.\n1Messari is the most prominent Web 3.0 research institute at present. The institute provides real-time data and research\nreports\n5\nFigure 3: Web 3.0 market scale. Unit: billion dollars\nFigure 4 uses the thermal diagram to analyze the contribution of different businesses in various fields\nof the Web 3.0 ecosystem. It can be seen from the figure that the Currency business in the Payment field\nis the largest, about 46.47%. This number shows that the number of companies in the payment field is\nsignificant. Then is the Smart Contract Platform business in the infrastructure field, the Stablecoins business\nin the payment field, and the Smart Contract Platform business in the financial field. Through the analysis\nof market scale contribution, we can see that the major development of the Web 3.0 market comes from\nelectronic payment. The digital financial industry based on blockchain technology has begun to take shape.\nHowever, other fields are still in the early stage of development with significant room for growth.\n6\nFigure 4: Web 3.0 market size contribution of each category: the horizontal axis is domain classification, and\nthe vertical axis is business classification. White indicates that there is no corresponding business under the\nfield\nUnlike the international market, China\u2019s development has adopted the path of alliance chain as the\nprimary way and adopted the separation strategy of chain and currency to reduce the Internet financial credit\nrisk under blockchain technology as much as possible. According to the statistics of China Information and\nCommunication Academy, the revenue scale of China\u2019s alliance chain business in the first half of 2022 will\nreach about 2 billion yuan. The development of the alliance chain has also promoted the growth of domestic\nblockchain as a service (BaaS) business. In 2021, China\u2019s BaaS business market will reach 188 million US\ndollars, with a growth rate of 92.6%. Domestic Internet companies, blockchain technology service providers,\nuniversities and research institutes, and other joint research and development alliance chains are gradually\nbeing established [52]. At present, leading domestic technology enterprises, such as Tencent, Alibaba, and\nHuawei, have invested a large amount of research and development funds in the technical fields related to\nWeb 3.0, actively promoting enterprises to use the Web 3.0 ecosystem to realize digital transformation, which\n7\nTable 3: Some Chinese national regulatory policies on Web 3.0 related fields\nField\nRegulatory policies\nVirtual currency\nNotice on protection against Bitcoin risks\nAnnouncement on preventing the risk\nof token issuance financing\nNotice on Further Preventing and Dealing with\nthe Risks of Fictitious Currency Trading\nBlockchain\nBlockchain information service management regulations\nMeta-universe\nRisk tips on preventing illegal fund-raising\nin the name of \"meta-universe\"\nNFT\nInitiatives on preventing NFT-related financial risks\nhas laid a technical foundation for the development of Web 3.0 in China.\n3.2\nPolicy status\nCurrently, the most important national laws and regulations on Web 3.0 are mainly focused on virtual\ncurrency. The government has issued several laws and regulations on virtual currency and its derivatives\nrelated to Web 3.0. Table 3 shows some of the current regulatory policies of the country. It can be seen that\nthe focus of China\u2019s current regulation is how to regulate the malignant transfer of legal currency to virtual\ncurrency, how to regulate the malicious injection or withdrawal of foreign capital into the domestic market\nthrough virtual currency, and how to prevent speculators from using Web 3.0, blockchain, NFT and other\nemerging concepts to make malicious speculation and create economic foam[6].\nIn addition to regulating virtual currencies, state authorities are required to oversee a wide range of\naspects concerning the development and utilization of Web 3.0 technology. While strict regulations may\nmitigate potential financial risks, they also have the potential to impede domestic technological innovation.\nConsequently, it is necessary to consider alternative means of preventing and reversing any trend towards a\nshift from reality to virtual brought about by Web 3.0. Equally important is the prevention of malicious\nforms of competition amongst internet enterprises stemming from changes to business models brought on\nby Web 3.0 technology. Hence, governments need to adopt more forward-looking and innovative regulatory\nstrategies to promote sustainable long-term growth in this area.\n3.3\nResearch status\nThis study offers empirical evidence to facilitate a comprehensive analysis of the current state of international\nresearch on Web 3.0 technology by surveying relevant documents indexed in the Web of Science database.\nFurthermore, the Chinese knowledge infrastructure (CNKI) is employed to examine the corresponding status\nof domestic research. By conducting a comparative analysis of the relevant scholarship on Web 3.0 in China\nand abroad, this paper enables an investigation of any notable differences between these two research contexts.\n8\nFigure 5: Web 3.0 related literature publication, 2003-2023\nFigure 6: Distribution of subjects of Web 3.0 related literature in CNKI database. From most to least: Com-\nputer software and applications;News and Media;Internet technology;Information and Post economy;Education\ntheory and management; Entrepreneur economy;Trade economy\n9\nFigure 7: Distribution of subjects of Web 3.0 related literature in WOS database\nAs of January 29, 2023, 125 documents with high relevance to Web 3.0 have been retrieved in the WOS\ndatabase, while 794 documents related to Web 3.0 have been found in the CKNI database. Figure 5 shows\nthe changing trend of the number of documents related to Web 3.0 published at home and abroad. In 2006,\nresearch related to Web 3.0 began to appear in China. After reaching the first peak in 2014, the number of\ndocuments gradually decreased, and until 2020, the number of related documents increased sharply. Although\nthe overall number of foreign documents related to Web 3.0 is less than that in China, its change trend is\nsimilar to that in China. Figures 6 and 7 show the disciplinary distribution of relevant literature, respectively.\nDomestic research mainly focuses on computer software and computer applications, news and media, and\nInternet technology, while foreign research focuses on security systems and telecommunications.\nIn addition, this paper extracts keywords from Web 3.0-related literature to analyze the research hot spots\nin this field. The hot topics in the past literature represent the research focus of this field in a certain period,\nand the frequency of keyword occurrence is the specific manifestation of the research focus. This paper\ncarries out keyword clustering analysis and emergent keyword analysis, providing references for researchers to\nexplore the iterative development and frontier trends of Web 3.0 hot topics.\n3.3.1\nKeyword trending among Chinese literature\nFigure 8 shows the results of keyword clustering analysis for published web 3.0 related papers in China.\nBased on the clustering analysis results, it can be seen that since 2006, the Web 3.0 literature published in\nChina can be roughly divided into three categories.\nThe first category is theoretical research, which mainly studies the fundamental theories behind the\ndevelopment of Web 3.0. For example, some researchers discussed the current development trend of Web 3.0\nfrom four aspects: network and computing technology, security and trustworthiness technology, virtual real\nfusion technology, and intelligent interaction technology; Li Jie [24] believes that the core of Web 3.0 is the\nSemantic Web, and discusses the relationship between Web 3.0, social 5.0 and the metauniverse; Wu Tong\net al. [43] proposed that the core concept of Web 3.0 is that users have access to data, which enables it to\nincorporate data into the framework of production factors; Chen Yongwei [5] discussed four possible challenges\nthat Web 3.0 may bring from the perspective of policy designation, and proposed some corresponding\nmeasures. In addition, the relevant literature in this category mainly focuses on the market opportunities\nand value that Web 3.0 may bring. For example, the \"Business Opportunities\" cluster includes \"Business\n10\nOpportunities\", the \"Media Integration\" cluster includes theme words such as \"Model Innovation\", and the\n\"Web 3.0 Era\" cluster also includes theme keywords related to macro development such as \"Collaborative\nDevelopment\" and \"Regional Development.\" However, Web 3.0 is not accurately defined in the theoretical\nliterature. Therefore, from a research perspective, there is currently no unified definition for it.\nThe second category is technical research, which mainly focuses on the technologies required for the\ndevelopment of Web 3.0, including high-frequency keywords in \"resource sharing\" clustering that include\n\"mashup technology\", and \"metaverse\" clustering that includes topics such as \"blockchain\", \"smart contracts\",\n\"IPFS\", and \"Truffle framework\". In addition, the \"Web3D technology\" clustering includes keywords such\nas \"3D annotation\" and \"VRML\". These topics are hot topics in the research of Web 3.0 technology. For\nexample, Yun Jian et al. [47] designed a digital archive storage platform based on alliance chain and IPFS\ntechnology, which can expand storage capacity while also taking into account data security; Sun Yushan\net al. [37] proposed a data structure suitable for efficient authentication of streaming data on the chain,\nwhich solves the problem of server untrustworthiness when data is outsourced for storage; Lu Jiawei et al.\n[27] discussed a mashup service clustering method based on non-negative matrix factorization combining\ntags and word embedding (TWE-NMF) topic model, which is more efficient than traditional methods in\nclustering accuracy. Tianyi Huang et al. [20] introduced a new data analysis and visulization method based\non high-dimensional data, which can be implemented under multiple categories.However, the literature in\nthis category currently only focuses on the technology itself, with almost no specific application of technology\nin Web 3.0.\nThe third category is application research, which mainly explores specific applications in the Web 3.0\necosystem. For example, high-frequency topics such as \"online teaching platforms\", \"electronic libraries\", and\n\"NFTs\" are included in the \"resource sharing\" cluster. Tian Linan et al. [40] analyzed the application of\nspatiotemporal encoding technology in Web 3.0 digital finance using Qingdao City as a model and concluded\nthat spatiotemporal encoding technology could play an essential role in platform traffic distribution, financial\nrisk control, financial supervision, and other scenarios; Zhai Xuesong et al. [48] analyzed the possible\napplications of Web 3.0 in education and believed that Web 3.0 could seize the opportunities of major\neducational strategies such as high-quality personalized teaching, educational equity, and the simultaneous\ndevelopment of \"five educations\"; Zhao Yichen et al. [50] proposed using blockchain technology to solve the\nproblem of strenuous tax activities in the digital economy and reduce the phenomenon of tax evasion. From\nthe current literature, research on Web 3.0 application scenarios mainly focuses on online teaching, metaverse,\nand online marketing. Moreover, more involvement in applied research in other fields must be needed.\n11\nFigure 8: CNKI keyword cluster map. Category from 0 to 9:Web 3.0;Metaverse;Business opportunities;\nResource sharing;Web 2.0;Internet marketing;Media fusion;Digital collections;The era of Web 3.0;Web 3D\ntechnology;\nOther researchers have integrated the three types of research mentioned above to study the future\ndevelopment of Web 3.0. For example, the book \"Web 3.0: A Disruptive and Significant Third Generation\nInternet\" provides a detailed introduction to the basic theoretical knowledge and applications of Web 3.0, and\nprovides suggestions on how to formulate network behavior guidelines in the Web 3.0 era based on literature\nreview[6].\nFigure 9 shows the top 20 keywords. The first emergent keyword was \"browser\", which emerged from\n2006 to 2009, followed by \"business application\", \"personal portal\", and \"online marketing\". This shows that\nin the early research of Web 3.0 in China, the main direction is to explore new Internet marketing methods.\nThe key word with the most significant strength is \"blockchain\", and its strength reaches 17.73. In addition,\ndomestic research has gradually shifted from the initial \"commercial application\" and \"online marketing\" to\nthe technical topics of \"platform construction\", \"consensus mechanism\", and \"blockchain\". It is worth noting\nthat \"digital assets\", \"decentralization\", \"artificial intelligence,\" and \"data sharing\" have been new research hot\nspots in the past three years.\n12\nFigure 9: CNKI emergent keywords Top20: light green is the basic time axis, dark green is the time interval from\nthe emergence of keywords to the present, and red is the time interval of the duration of keyword emergent. The\nkeywords in the figure are sorted by the starting time of emergent.Keywords from top to below:Browser;Business\napp;Personal portal;Web marketing;Data aggregation;Semantic Web;IoT;Personalization;Cloud Comput-\ning;Transformation;Web 3.0;Internet;Platform construction;IT;Consensus mechanism;Blockchain;Smart con-\ntract ;Ethereum;Digital assets;Decentralization;AI;Data sharing\n3.3.2\nKeyword trending in foreign countries\nFigure 10 shows the keyword clustering analysis graph of web 3.0-related literature published abroad. Unlike\ndomestic research, the hot topics related to Web 3.0 research abroad can be divided into four categories:\ntheoretical research, technical research, industrial research, and application research.\nThe first category is theoretical research. In addition to outlining the overall development, there are\nalso studies abroad that jointly analyze Web 3.0 and social sciences. For example, Rudman and Bruwer [35]\nsummarized the overall development and current challenges of Web 3.0; Kreps and Kimppa [23] discussed\nthe specific definition of Web 3.0 from the perspective of post-structuralism, and demonstrated the social\ndevelopment brought by Web 3.0 through five papers; Ferraro et al. [13] starting from the development of\npsychology and technology, discussed how to establish trust mechanisms in Web 3.0 and concluded that there\nare loopholes in the current trust mechanisms.\nThe second category is technical research, which is similar to domestic research and explores supporting\nWeb 3.0 technology development. For example, in the \"Machine Learning\" cluster, topics such as \"ICA\nAlgorithm\" appear, while in the \"Data Storage\" cluster, keywords such as \"Storage Systems\" and \"IPFS\"\nare included. In addition, Clarke et al. [12] proposed that the decentralized communication layer in the\nmainframe can be used as a supplementary protocol to strengthen the network security of the Internet; Vega\n13\net al. [10] designed a new cryptographic primitive, Nil Message Compute (NMC). Because nodes under the\nNMC structure do not run immutable ledgers that store transaction data, nor are they interconnected, it will\nbe more secure than blockchain structures. However, unlike domestic research, there is only a little research\non Web3D technology in foreign literature related to Web 3.0.\nThe third category is industrial research, which mainly focuses on how Web 3.0 integrates with existing\nindustries to build a new industrial ecosystem. Among them, the \"Industry 4.0\" cluster contains keywords\nsuch as \"IoT\" and \"industrial internet of things\", and the \"Parallelism\" cluster contains keywords such as\n\"Supply Chain\". Anwar [1] explored the connection between Web 3.0 and the Internet of Things (IoT),\nbelieving that the collaboration between Web 3.0 and the Internet of Things will benefit society in multiple\ndirections such as smart cities and soil observation; Castro et al. [3] delved into the connection between\nWeb 3.0 and the manufacturing industry and introduced a virtual enterprise framework specifically designed\nfor small and medium-sized enterprises using the Web 3.0 platform. This framework will help small and\nmedium-sized enterprises adapt faster to changes in industrial structure and achieve sustainable development\ngoals. Compared to domestic research, foreign research has already discussed building a Web 3.0 industry\necosystem.\nThe fourth category is applied research. Foreign Web 3.0 application research covers many fields, including\noffice, healthcare, education, commerce, economics, and other scenarios. For example, Gupta et al. [16]\ndeveloped a 3D conferencing application in the metaverse and VR devices. This program ensures meeting\nefficiency and reduces the impact of delays; Ayoade et al. [2] proposed a decentralized data management\nsystem suitable for IoT devices. As it does not require central system management, it can better protect\ndata; Thrul et al. [39] believe that DAO can provide remote mental health services and solve the problem of\nscarce mental health resources.\nFigure 10: WOS keyword cluster map\nFigure 11 shows the top 10 prominent keywords in foreign Web 3.0-related literature. The first emergent\nkeyword is \"Semantic Web\", which emerged from 2009 to 2012. This represents the initial stage of research.\nForeign literature focuses on discussing the concept and meaning of Web 3.0. Like Chinese research, the\n14\nTable 4: Connections between Web 3.0 and digital economy\nBlockchain\nDecentralization\nMetaverse\nDigital industrialization\nDigital currency and NFT\nDefi and storage technology\nMetaverse software\nIndustry digitization\nIoT\nE2E Mechanism\nVR/AR/MR\nDigital management\nSmart cities\nDecentralized management\n-\nData value\nFederated learning\nData storage\nMetaverse and AI\nkeyword with the most considerable emergent strength in foreign countries is \"blockchain\", whose strength\nis 3.66. Unlike Chinese research, in recent years, foreign research focuses on the field of Web 3.0 are still\nconcentrated on the technical topics of \"blockchain\", \"smart contract,\" and \"big data\". At the same time,\n\"artificial intelligence\" is the common research trend in Web 3.0 in China and abroad.\nFigure 11: WOS emergent keywords Top10: light green is the basic time axis, light green is the basic time\naxis, dark green is the time interval from the emergence of keywords to the present, and red is the time\ninterval of the duration of keyword emergence. The keywords in the figure are sorted by the starting time of\nemergence\n4\nTransformation and Opportunities\nThis section examines the mutualistic interplay between the construction of the Web 3.0 ecosystem and the\nadvancement and transformation of the digital economy. Specifically, we explore how the digital economy\nprovides fertile ground for emerging technological development, thereby promoting scientific progress and\ntechnological innovation in Web 3.0. Furthermore, this section provides a comprehensive analysis of the\nchanging landscape and opportunities brought about by the ongoing development of Web 3.0 technology\nfrom both technological and economic perspectives.\n4.1\nTransformation and Opportunities in Economy\nThe concept of the digital economy can be divided into four parts [4]: digital industrialization, industry\ndigitization, digital management, and data value. The connections between Web 3.0 in these four aspects are\nshown in Table 4. These connections have brought about significant changes in the digital economy, creating\nmany opportunities in this transformation.\nFrom the perspective of digital industrialization, the transformation of the economic landscape by Web 3.0\nis mainly reflected in value creation centered around users by delegating digital assets that initially belonged\nto the platform to users. Digital currency, NFT, decentralized finance and storage, and metaverse software are\nall specific applications. These applications have effectively promoted the development of the digital economy.\nFor example, Web 3.0 protects digital art works and artists\u2019 rights and interests through payment, intellectual\n15\nproperty management, digital storage, etc., which significantly promotes the creation and transaction of\ndigital works of art in Web 3.0 [9].\nWeb 3.0 has promoted intelligence development and effective management in traditional industries\nregarding industry digitization. The industrial Internet of Things (IIoT) formed by Web 3.0 has been\nused in various industries. For example, the blockchain based on the industrial internet of things has\nbeen used in the food supply chain to ensure food quality and safety by providing a more traceable food\nproduction chain [31]. End-to-end technology can be described as the exchange of information between\nsystems performing autonomous tasks, which is the foundation for the operation of future IoT devices. For\nthe metaverse, combining Web 3.0 and VR or AR technology can make our interactions more immersive,\neffectively promoting the development of teaching software and electronic games.\nIn terms of digital management, intelligent cities utilize technology and data to improve the quality of\nlife of their residents, enhance sustainability, and simplify urban services. The concept involves integrating\ninformation and communication technology and IoT devices into urban infrastructure to collect and analyze\nreal-time data. Then use this data to manage urban assets and resources, provide better services to its\nresidents, and make wise decisions about the city\u2019s future development. Decentralized management is an\nessential component of innovative city governance, enabling people to coordinate and govern themselves\nthrough automated execution rules deployed on the blockchain [17].\nIn mining data value, it is necessary to ensure both the security of the data and sufficient storage\nspace. Among them, ensuring secure privacy computing can prevent data leakage and ensure that sensitive\ninformation is not accessed or manipulated by unauthorized persons while ensuring that organizations or\nindividuals can process and use this data. It includes many privacy protection technologies, such as secure\nmulti-party computing, homomorphic encryption, differential privacy, and zero-knowledge proof [46]. In\naddition, decentralized data storage effectively increases data transmission flexibility and scattered storage\nresources. AI can also drive these data to enhance participants\u2019 immersive interaction experience in the\nmetaverse.\n4.2\nTransformation and Opportunities in technology\nWeb 3.0 requires the support of many emerging technologies, mainly AI, blockchain, and VR/AR. They all have\nvery high requirements for computing power, requiring fundamental network technologies such as computing,\ntransmission, storage, and related equipment to undergo leapfrog improvements. The transformation and\nbenefits of Web 3.0 on the economy will further promote the development of related technologies. The\nrelationships between Web 3.0, digital economy, and science and technology are shown in 12\nFigure 12: The Relationship between Web 3.0, Digital Economy, and Science and Technology\nIn recent years, investors have invested in the development of science and technology related to Web 3.0,\nand major companies have also formed new technology projects related to Web 3.0, ushering in new changes\n16\nand opportunities for technological development. From the perspective of technology projects that have\nalready been implemented, Google Cloud has launched a fully hosted cloud service that maintains blockchain\nnodes, known as the Blockchain Node Engine. It is mainly responsible for managing and maintaining the\nintegrity of the blockchain ledger and promoting the consensus process among network participants. This\nengine can significantly reduce the cost of data management and maintenance and improve the efficiency of\nWeb 3.0 development. In addition, WIMI.US has developed a human-machine interaction system based on\nXR technology, and its VR human-machine interaction terminal and other human-machine interaction-related\ntechnologies have also obtained corresponding patents.\nFigure 13 shows the Gartner hype cycle which include five stages of new technology would go through\nfrom inception to maturity. In the early stages of new technology, the market will have high expectations\nfor the benefits it can bring. However, the market will eliminate unrealistic and hyped technology after the\ntechnology has gone through the foam period. Afterward, emerging technologies will gradually transition to a\nmature stage. At this stage, the market\u2019s expectations for new technologies will become more stable and\ncloser to reality.\nThe concept of Web 3.0 first appeared in 2006, but before that, there had been a long period of decentralized\nand distributed system technology. As a result, most Web 3.0 applications are experimental and have yet to\nbe widely adopted.\nBlockchain technologies, such as Ethereum, have developed into mature platforms in the past few years,\nand many Web 3.0 applications have emerged. These applications include decentralized exchanges, digital\nidentity verification systems, digital asset management platforms, etc. At this stage, Web 3.0 applications are\nbeing promoted to many users, and some larger companies and organizations are exploring the potential of\nthese technologies.\nHowever, Web 3.0-related technologies are still in the stage of innovation foam, and the current expectations\nfor the market value are too high. False and exaggerated propaganda and hype concepts also appeared at\nthe same time. The current market situation is relatively complex. Therefore, we need to view Web 3.0\ntechnology more rationally, recognizing its limitations and shortcomings while facing enormous development\nopportunities.\nFigure 13: Gartner\n17\n5\nNeeds and Challenges\nThe Web 3.0 ecosystem can solve data security, platform monopoly, and trust problems in the Web 2.0 era. At\nthe same time, Web 3.0 provides a technical base for the metaverse, representing the direction of application\nscenarios and lifestyle innovation and enabling the economy to carry out digital transformation.\nThe\ndevelopment of Web 3.0 is expected to shape a new system of Internet technology, optimize the development\nmode and industrial pattern of the Internet, and build a new paradigm of the Internet economy. The\nsubsequent section of this manuscript will focus on identifying the key components for building a sustainable\nWeb 3.0 ecosystem, outlining potential challenges and proposing strategies for overcoming them.\n5.1\nEcological construction\nThe ecosystem of Web 3.0 is defined as a distributed open technology system that supports information\nand data sharing, connectivity, discovery, governance, and value aggregation. We assert that the new\norganizational collaboration mode, combined with advancements in financial technology and digital identity\nmanagement, represents the foundational building blocks of the Web 3.0 ecology.\n5.1.1\nThe Management Model of Web 3.0 Ecology - Decentralized Autonomous Organizations\n(DAO)\nThe internet ecosystem in the era of Web 2.0 is closed, as internet giants monopolize user data resources.\nTherefore, the public\u2019s demand for establishing a decentralized organizational collaborative approach is\nincreasing, and DAO has also emerged. Decentralized Autonomous Organization (DAO) is a new type of\norganizational collaboration based on blockchain technology, which is seen as a spark that subverts traditional\nInternet organizational structures.\nUnlike traditional organizations, DAO operates on the blockchain and is controlled by stakeholders rather\nthan specific institutions. This allows all members to achieve co-governance within the DAO through smart\ncontracts, eliminating subordinate relationships and improving the efficiency of organizational collaboration.\nAlthough the concept of DAO is developing in various forms, security and legal risks, remain a concern.\nAdditionally, further research is needed to establish a DAO ecosystem that aligns with China\u2019s national\nconditions.\n5.1.2\nThe driving force of the Web 3.0 ecosystem - Decentralized Finance (DeFi)\nDecentralized Finance (DeFi) is a new type of digital finance based on blockchain technology. DeFi aims to\nachieve secure financial services without the intervention of traditional financial institutions through smart\ncontracts and decentralized networks.\nThis new financial ecosystem is built on public chains such as Ethereum, supporting various financial\napplications and services, including decentralized exchanges (DEX), lending platforms, stable currencies,\nand unmanaged wallets. In addition, smart contracts on the blockchain can automatically execute DeFi\ntransactions, and each transaction data is auditable. The main financial applications implemented by DeFi\ninclude asset trading, available lending, and aggregated income wealth management.\nTable 5 compares the differences between decentralized finance, centralized finance, and traditional financial\nsystems in different financial services categories. The asset trading of the crypto financial system on the chain\nis done through crypto exchanges, but the difference is that DeFi\u2019s exchange is decentralized. Decentralized\nexchanges (DEXs), as alternative payment ecosystems with new financial trading protocols, appear within\nthe framework of available finance and are part of blockchain technology and financial technology. Unlike\ncentralized cryptocurrency exchanges (CEX) such as Coinbase, Huobi, or Binance, they used to order books\nto match buyers and sellers in the open market and store encrypted assets in exchange-based wallets. In\naddition, DEX is unmanaged and utilizes automated intelligent contracts for peer-to-peer trading, while users\nretain control over their private keys and funds[6].\nFrom the table above, DeFi is also the digitized form of the traditional financial system. It cannot operate\nindependently from the traditional financial system or avoid the hidden risks in traditional finance. However,\nDeFi has the advantage of having high transparency and coverage that traditional finance cannot possess.\n18\nTable 5: DeFi,CeFi and traditional finance\nCrypto financial system\nCategory\nService\nDecentralized Finance\n(DeFi)\nCentralized Finance\n(CeFi)\nTraditional Finance\nFund transfer\nDeFi Stable coin\n(DAI)\nCeFi Stable coin\n(USDT,USDC)\nPayment platforms\nAsset transactions\nCrypto assets DEX\nUniswap\nTrading\nDerivative trading\nCrypto derivative DEX\nSynthetic,dYdX\nCrypto CEX\n(Binance,Coinbase)\nBourse\nAgent\nMortgage\nDecentralized lending platform\n(Aave,Compound)\nCentralized lending platform\n(BlockFi,Celsius)\nLoan Trading agents\nDebit\nUnsecured Loan\nCredit commission agency\n(Aave)\nDigital banking\n(Silvergate)\nCommercial bank\nInvestment Financial Products Decentralized investment portfolio\n(yearn,Convex)\nCrypto Fund\n(Grayscale,Galaxy)\nFund\n5.1.3\nDistributed digital identity (DID): an ecological identity authentication method for Web\n3.0\nThe emergence of distributed digital identity (DID) has solved the problem of self-sovereignty of digital\nidentity in networking and enhanced the individual\u2019s control over identification information. Specifically,\nDID aims to form a self-sovereignty identity where users can exercise autonomous control over their data\ninformation without needing permission from any platform or organization. DID is a critical component of the\nconstantly evolving Web 3.0 ecosystem, which can verify identity without relying on centralized institutions\nand third-party services, providing a method that does not require trust and guarantees privacy.\n5.1.4\nIndustrial ecological value\nThe Web 3.0 ecosystem is linked by token incentives, which can significantly achieve co-construction and\nsharing within organizations, break boundaries, and promote value circulation. First, underpinning the Web\n3.0 ecosystem is a protocol that somewhat reduces the cost of obtaining trust guarantees from third-party\nsources, offering individuals more opportunities to exchange their innovations for monetary gains directly.\nWithin the decentralized autonomous organization (DAO), participants can obtain benefits transparently and\nwith greater trust through the interconnected distributed digital identity.\nSecondly, the Web 3.0 ecosystem can transcend industry boundaries to create new forms of collaboration.\nThe enhanced digital system integrated with advanced technologies in Web 3.0 can efficiently document,\nmonitor, and adjust every aspect of the interaction between connected devices. In this more open internet\nenvironment, blockchain-based digital trust systems expand the coverage of digital services and accelerate\ndata integration into reality, ultimately nurturing low-cost, efficient, and healthier socio-economic ecosystems.\nAs such, token incentives are crucial for establishing and maintaining value circulation within the Web 3.0\necosystem, creating a highly interoperable and trusted environment that enhances industrial cooperation\nacross sectors. Nonetheless, there is still much work required to align the adoption and development of Web\n3.0 with China\u2019s national policies while positively contributing to global digital innovation initiatives.\n5.2\nCurrent challenges\nAlthough the construction of the Web 3.0 ecosystem has become a vision for the development of the Internet,\nit still faces many challenges.\nPrimarily, there is a lack of a systematic theoretical and technological research layout for Web 3.0 in\nChina. Research into Web 3.0 theory and technology, such as architecture and protocol stacks, alliance chains,\nopen alliance chains, public chains, digital identities, and distributed storage, requires significant backing\nfrom artificial intelligence, cloud computing, 5G, virtual reality, and other emerging technologies.However,\nwhile there has been more research focus on the alliance chain in China, robust research initiatives are still\nlacking on these other critical components. Another critical challenge associated with Web 3.0\u2019s development\nis the severe shortage of high-level, composite talents in this field. The complexity and diversity involved in\nWeb 3.0\u2019s technology and application demand proficiency and cross-disciplinary knowledge in cryptography,\n19\ncomputer science, network security, visualization and economics[7, 49].Despite this, there is still no specialized\ncourse or major to cultivate Web 3.0 talents in China specifically. That, coupled with the lack of related\ntextbooks, training platforms, and other supportive resources, indicates an urgent need to establish a more\ncomprehensive talent cultivation system that can stay abreast of the rapidly evolving field of Web 3.0.\nSecondly,The decentralized characteristics of Web 3.0 may pose significant challenges to existing legal\nand regulatory systems. For instance, some questions need to be addressed on how to enhance ownership\nrelationships associated with NFTs and develop a property management system to govern the legal aspects of\nNFT ownership.Additionally, the emergence of new business models facilitated by Web 3.0 may introduce\nillegal and criminal activities, such as illegal fundraising and money laundering, which could disrupt the\nfinancial market. Legal frameworks must be put in place to regulate these activities effectively.Another\nsignificant challenge pertains to identifying DAOs\u2019 nature from a legal perspective, assigning appropriate\nrights and obligations, and establishing regulations that guide their operations. It is noteworthy that public\nchains and cryptocurrencies play an integral role in the development and success of Web 3.0. However, due\nto limited development by domestic regulatory policies, scholars are keen to explore ways to circumvent these\nlimitations.As such, it is essential to address these legal challenges comprehensively to ensure the successful\ndevelopment and deployment of Web 3.0 while safeguarding the public interest.\n6\nConclusion\nWeb 3.0 is still in its early stages of development and has enormous potential for development. With the\ndevelopment of science and technology such as 5G, AI, and metaverse, as well as the further improvement of\nmanagement concepts such as decentralization, Web 3.0 will make breakthroughs in the following two areas\nin the future, allowing users to receive better services [34]. 1) With the further improvement of decentralized\ndata management and the 5G, the workload of data on a single server will be effectively reduced, and the\nexisting data transmission efficiency will be further improved to more efficiently search or analyze data for\nusers. 2) With the further optimization of AI technology, they will be better integrated with Web 3.0 and\nprovide intuitive web services to promote economic housing exhibitions. For example, AI can summarize\nmany consumer habits collected, leading to better online marketing and promoting consumption. Combining\nefficient data management and AI will bring users more valuable and personalized data services. In the\nfuture, more AI platforms similar to ChatGPT will provide users with accurate and efficient data search and\ngeneration services [29, 21].\nIt is for sure that potential risks would appear along with the development of Web 3.0, specifically regarding\nlegal and technical factors. Concerning decentralized data management, challenges may emerge in regulating\nthe proliferation of illicit data on the network, as well as enhancing cybersecurity to managing network\nattacks like SQL injection and malware, which are more likely in the Web 3.0 environment. Personalizing\nnetwork content may also raise concerns regarding personal data privacy and the associated risks of identity\ntheft or social phishing.\nGiven these prospects and challenges, China must examine its governance policies and regulatory frame-\nworks surrounding Web 3.0 while simultaneously focusing on cultivating requisite technology capabilities and\nsupporting infrastructural improvements to ensure effective management of the decentralized networks.\nThrough this approach, China can shape a distinctive model for Web 3.0 development with reinforced\ncentral governance mechanisms and robust legislation that better safeguards user safety and privacy and\nmaintains national security. As such, it is arguable that China possesses relative strategic advantages\ngiven its unique geopolitical position, significant technological capacity, and ambitions toward technological\nleadership. Overall, exploring avenues for effective governance frameworks that balance innovation and\nbusiness opportunities with sustainable risk management will be critical to successfully realizing Web 3.0\u2019s\npromise and potential.\n20\nReferences\n[1] Adeem Ali Anwar. A survey of semantic web (web 3.0), its applications, challenges, future and its\nrelation with internet of things (iot). Web Intell., 20:173\u2013202, 2022.\n[2] Gbadebo Ayoade, Vishal Karande, Latifur Khan, and Kevin Hamlen. Decentralized iot data management\nusing blockchain and trusted execution environment.\nIn 2018 IEEE International Conference on\nInformation Reuse and Integration (IRI), pages 15\u201322, 2018.\n[3] H. Castro, G. Putnik, M.M. Cruz-Cunha, L. Ferreira, V. Shah, and C. Alves. Meta-organization and\nmanufacturing web 3.0 for ubiquitous virtual enterprise of manufacturing smes: A framework. Procedia\nCIRP, 12:396\u2013401, 2013.\n[4] Chuan Chen, Lei Zhang, Yihao Li, Tianchi Liao, Siran Zhao, Zibin Zheng, Huawei Huang, and Jiajing\nWu. When digital economy meets web 3.0: Applications and challenges. IEEE Open Journal of the\nComputer Society, 2022.\n[5] Yong wei Chen. Web 3.0: Evolution and response(in chinese). Journal of Dongbei University of Finance\nand Economics, 6:27\u201339, 2022.\n[6] Shenghui Cheng. Web 3.0 Era. Tsinghua University Press, 2023.\n[7] Shenghui Cheng and Klaus Mueller. The data context map: Fusing data and attributes into a unified\ndisplay. IEEE Transactions on Visualization and Computer Graphics, 22(1):121\u2013130, 2016.\n[8] Shenghui Cheng, Yue Zhang, Xiaofei Li, Lin Yang, Xin Yuan, and Stan Z Li. Roadmap toward the\nmetaverse: An ai perspective. The Innovation, 3(5):100293, 2022.\n[9] Stuart Cunningham and Terry Flew. A research agenda for creative industries. 2019.\n[10] Miguel de Vega, Andrew Masanto, Rob Leslie, Andrew Yeoh, Alex Page, and Tristan Litre. Nillion: A\nsecure processing layer for web3, 2022.\n[11] Yu Du and Ziming Zhang. Web3.0 empowers the digital economy with New Era(in Chinese). China\nTranslation and Publishing Corporation, 2022.\n[12] A. Clarke et al. Mainframe: The web3 communications layer, 2018.\n[13] Carla Ferraro, Melissa A. Wheeler, Jason I. Pallant, Samuel G. Wilson, and Julian Oldmeadow. Not so\n\u2018trustless\u2019 after all: Trust in web3 technology and opportunities for brands. Business Horizons, 2023.\n[14] Chong Guan, Ding Ding, and Jiancang Guo. Web3.0: A review and research agenda. 2022 RIVF\nInternational Conference on Computing and Communication Technologies (RIVF), pages 653\u2013658, 2022.\n[15] Barbara Guidi and Andrea Michienzi.\nSocial games and blockchain: exploring the metaverse of\ndecentraland. In 2022 IEEE 42nd International Conference on Distributed Computing Systems Workshops,\npages 199\u2013204. IEEE, 2022.\n[16] Yash Gupta, Amit Chawla, Tanuja Pal, Myakala Phanindra Reddy, and Dharmendra Singh Yadav. 3d\nnetworking and collaborative environment for online education. 2022 10th International Conference on\nEmerging Trends in Engineering and Technology - Signal and Information Processing (ICETET-SIP-22),\npages 1\u20135, 2022.\n[17] Samer Hassan and Primavera De Filippi. Decentralized autonomous organization. Internet Policy Review,\n10(2):1\u201310, 2021.\n[18] Jim Hendler. Web 3.0 emerging. Computer, 42(1):111\u2013113, 2009.\n[19] BK Hiremath and Anand Y Kenchakkanavar. An alteration of the web 1.0, web 2.0 and web 3.0: a\ncomparative study. Imperial Journal of Interdisciplinary Research, 2(4):705\u2013710, 2016.\n21\n[20] Tianyi Huang, Shenghui Cheng, Stan Z Li, and Zhengjun Zhang. High-dimensional clustering onto\nhamiltonian cycle. arXiv preprint arXiv:2304.14531, 2023.\n[21] Tianyi Huang, Stan Z Li, Xin Yuan, and Shenghui Cheng. Roadmap towards meta-being. arXiv preprint\narXiv:2303.06795, 2023.\n[22] Karwan Jacksi and Shakir M Abass. Development history of the world wide web. Int. J. Sci. Technol.\nRes, 8(9):75\u201379, 2019.\n[23] David Kreps and Kai Kimppa. Theorising web 3.0: Icts in a changing society. Information Technology\n& People, 28:726\u2013741, 11 2015.\n[24] Jie Li. Hot topics and intellectual base of web 3.0, society 5.0 and metaverse(in chinese). Science Focus,\n18(13-23), 2023.\n[25] Yang Li and Jian Li. Introduction to Data science(in Chinese). China Renmin University Press, 2021.\n[26] Jingqi Ling. Whether fashion should be redefined in web 3.0 age?(in chinese). 2022.\n[27] Jiawei Lu, Wei Zhao, Yuanming Zhang, et al. Twe-nmf topic model-based approach for mashup service\nclustering(in chinese). Journal of Software, 2022.\n[28] Tian Min and Wei Cai. Portrait of decentralized application users: an overview based on large-scale\nethereum data. Transactions on Pervasive Computing and Interaction, 4(2):124\u2013141, 2022.\n[29] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions\nwith human feedback. arXiv preprint arXiv:2203.02155, 2022.\n[30] Peterson K Ozili. Decentralized finance research and developments around the world. Journal of Banking\nand Financial Technology, pages 1\u201317, 2022.\n[31] Mario Pe\u00f1a, Juan Llivisaca, and Lorena Siguenza-Guzman. Blockchain and its potential applications\nin food supply chain management in ecuador. In Miguel Botto-Tobar, Joffre Le\u00f3n-Acurio, Angela\nD\u00edaz Cadena, and Pr\u00e1xedes Montiel D\u00edaz, editors, Advances in Emerging Trends and Technologies, pages\n101\u2013112, Cham, 2020. Springer International Publishing.\n[32] Adrian Petcu, Bogdan Pahontu, Madalin Frunzete, and Dan Alexandru Stoichescu. A secure and\ndecentralized authentication mechanism based on web 3.0 and ethereum blockchain technology. Applied\nSciences, 13(4):2231, 2023.\n[33] Iman Rasekh. Dynamic search optimization for semantic webs using imperialistic competitive algorithm.\nIn 2012 International Conference on Information Science and Applications, pages 1\u20135. IEEE, 2012.\n[34] Riaan Rudman and Rikus Bruwer. Defining web 3.0: opportunities and challenges. The electronic library,\n2016.\n[35] Riaan J. Rudman and Rikus. Hendrik. Jacobus Bruwer. Defining web 3.0: opportunities and challenges.\nElectron. Libr., 34:132\u2013154, 2016.\n[36] Tharuka Sarathchandra and Damith Jayawikrama. A decentralized social network architecture. In 2021\nInternational Research Conference on Smart Computing and Systems Engineering (SCSE), volume 4,\npages 251\u2013257. IEEE, 2021.\n[37] Yushan Sun, Jingcong Yang, Qi Xia, and Jianbin Gao. Smt: Efficient authenticated data structure for\nstreaming data on blockchain(in chinese). Journal of Software, 2023.\n[38] Jadhav Swati, Pise Nitin, Parate Saurabh, Deshmukh Parikshit, Patil Gitesh, and Sharma Rahul.\nBlockchain based trusted secure philanthropy platform: Crypto-gocharity. In 2022 6th International\nConference On Computing, Communication, Control And Automation (ICCUBEA, pages 1\u20138. IEEE,\n2022.\n22\n[39] Johannes Thrul, Luther G. Kalb, Patrick H. Finan, Zachary Prager, and John A. Naslund. Web3 and\ndigital mental health: Opportunities to scale sustainable mental health promotion and peer support.\nFrontiers in Psychiatry, 13, 2022.\n[40] Linan Tian, Qi Sun, Erbao Nie, and Jiang Zhu. Research on the application of spatiotemporal coding\ntechnology in web3.0 digital finance(in chinese). Cyber Security and Data governance, 41(84-89), 2022.\n[41] Anurag Choubey Vanita Jain, Arun Kumar Dubey. Implementing and Leveraging Blockchain Program-\nming. Springer, 2022.\n[42] Zhengshi Wang. Understanding 5G technology in a book(in Chinese). China Machine Press, 2021.\n[43] Tong Wu and Jianguang Shang. Web 3.0: The underlying network structure of the metaverse(in chinese).\nJournal of Dongbei University of Finance and Economics, No.146(40-48), 2023.\n[44] Renchao Xie, tao Huang, fan Yang, and yunjie Liu. Principle and Practice of edge computing(in Chinese).\nThe People\u2019s Posts and Telecommunications Press, 2019.\n[45] Shu Yan and Ailin Lv.\nOverview of the development of privacy preseving computing(in chinese).\nInformation and Communications Technology and Policy, 47:1\u201311, 2021.\n[46] Qiang Yang, Yang Liu, Yong Cheng, Yan Kang, Tianjian Chen, and Han Yu. Federated learning.\nSynthesis Lectures on Artificial Intelligence and Machine Learning, 13(3):1\u2013207, 2019.\n[47] Jian Yun, Zhen Wang, and Chunxia Wang. Research on the construction of digital archives distributed\napplication platform based on consortium blockchain and ipfs technology(in chinese). Cyber Security\nand Data governance, 41(90-101), 2022.\n[48] Xuesong Zhai, Longzhu Yi, Huijun Wang, Xin Zhang, et al. Opportunities and challenges for the\ndevelopment of \"internet + education\" in the era of web3.0(in chinese). Open Education Research,\n28(4-11), 2022.\n[49] Xinyu Zhang, Shenghui Cheng, and Klaus Mueller. Graphical enhancements for effective exemplar\nidentification in contextual data visualizations. IEEE Transactions on Visualization and Computer\nGraphics, pages 1\u20131, 2022.\n[50] Yichen Zhao, yang Lu, and Mingxue Zhai. Blockchain technology:a possibility of web3.0+taxation.\nModern business, No.601(104-108), 2021.\n[51] Gavin Zheng, Longxiang Gao, Liqun Huang, and Jian Guan. Ethereum smart contract development in\nsolidity. Springer Nature, 2020.\n[52] Huimin Zheng. Who says web3 has nothing to do with china?(in chinese), 2022.\n23\n",
    "2206.07164": "Edge Security: Challenges and Issues\nXin Jin, Charalampos Katsis, Fan Sang, Jiahao Sun, Ashish Kundu, Ramana Kompella\nCisco Research\n{xijin3, ckatsis, fsang, jiahasun, ashkundu, rkompell}@cisco.com\nAbstract\u2014Edge computing is a paradigm that shifts data\nprocessing services to the network edge, where data are gener-\nated. While such an architecture provides faster processing and\nresponse, among other bene\ufb01ts, it also raises critical security\nissues and challenges that must be addressed.\nThis paper discusses the security threats and vulnerabilities\nemerging from the edge network architecture spanning from the\nhardware layer to the system layer. We further discuss privacy\nand regulatory compliance challenges in such networks. Finally,\nwe argue the need for a holistic approach to analyze edge network\nsecurity posture, which must consider knowledge from each layer.\nI. INTRODUCTION\nAn edge computing infrastructure is being adopted widely in\nthe industry for better performance, lower latency, better data\ngovernance, privacy, and compliance. With the exponential\ngrowth in the usage of Internet-of-Things (IoT) devices and\nsensors1, sending petabytes of data to a centralized cloud or an\nenterprise data center has several challenges. The processing of\nIoT data incurs huge delays and costs, and technical challenges\nto data movement, management, processing, storage, privacy,\nsecurity, and compliance. As an extension to the cloud and data\ncenter perimeter, the edge computing infrastructure deploys\nedge devices, servers, and edge-network capabilities near\n(within 1-hop of) data sources.\nThe increase in the size of edge computing infrastructure\nand its deployment in a geo-distributed manner provides\nbetter performance and data governance. However, at the\nsame time, it offers new security, privacy, and regulatory\ncompliance challenges. Security of edge computing involves\nvarious \ufb01elds, such as networks, systems, cryptography, and\nmachine learning. Hindered by the diversity of domain-speci\ufb01c\nknowledge, security researchers specialized in each \ufb01eld are\ninvestigating the challenges without a holistic view of the edge\ncomputing system. Such an isolated research methodology\noverlooks security challenges that emerge from the interaction\nboundaries between domains. Worse, naively \ufb01tting a domain-\nspeci\ufb01c security measurement to the overall edge computing\npipeline brings incompatibility and redundancy issues.\nIn this paper, we explore the emerging security vulner-\nabilities and threats speci\ufb01c to edge computing spanning\nacross different domains. Our goal is to stress the security\nissues arising from the different layers and spark initiatives to\nestablish a uniform system that holistically analyzes them.\n1IoTs are being used in manufacturing industry (Industry 4.0 [135]),\nhealthcare, personal health management, agriculture, transportation, and across\nother sectors [236].\nII. BACKGROUND AND OVERVIEW\nA. Edge Computing Framework\nIoT 1\nMobile 2\nIoT m\nEdge \nNetwork\nEdge \nDevice n\nEdge \nDevice 1\nEdge \nServer i\nCloud 1\nCloud k\nEDL\nESL\nCSL\nMobile n\nFig. 1. The general architecture of edge computing\nAn edge computing infrastructure has edge devices as well\nas edge servers as primary entities to carry out computation\nand data processing. A general architecture of edge computing\nmainly consists of three layers: an edge device layer (EDL), an\nedge server layer (ESL), and a cloud server layer (CSL) [264].\nSystems on the CSL have the most powerful computational\npower, the ones on the ESL follow, and the devices on the\nEDL usually have the least computational power.\nEdge Device Layer (EDL).\nDevices deployed to the EDL\nare called edge devices, which usually conduct \ufb01eld tasks\nsuch as sensing, actuating, and controlling, in the physical\nworld. Common edge devices are controlled by microcon-\ntrollers (MCUs), which implements the \ufb01rmware that provides\nlow-level software interfaces to control the device\u2019s hard-\nware [233]. Edge devices can be further grouped into IoT\ndevices and mobile devices. IoT devices usually consist of\nlightweight electronic devices that are interconnected or con-\nnected to the ESL through wireless protocols such as 4G/5G,\nWiFi, and Bluetooth. Examples include smart home devices,\nhealth monitoring devices, and smart warehouse carts in in-\ndustrialized IoT (IIoT). Most IoT devices use Cortex-M series\nMCUs produced by STMicroelectronics [161]. Once a real-\ntime operating systems (RTOS) [33], [147], [234] is burned\ninto the IoT devices, no additional programming interfaces\nare provided under normal circumstances. Meanwhile, mobile\ndevices usually have more advanced operating systems, such\nas Android and iOS, which provide programmable interfaces\nfor programmers to develop applications compatible with the\nOS. Common mobile devices include smartphones, tablets,\nand central controllers of smart vehicles, and usually adopt\nCortex-A series MCUs produced by high-performance chip\nmanufacturers such as Qualcomm [94].\n1\narXiv:2206.07164v1  [cs.CR]  14 Jun 2022\nEdge Server Layer (ESL). Edge servers handle the core com-\nputing functions in edge computing, including authentication,\nauthorization, computation, data analytics, task of\ufb02oading, and\ndata storage. ESL usually consists of multiple hierarchical sub-\nlayers of edge servers with increasing computational power.\nDevices such as wireless base stations and access points\n(APs) sit at the lowest sub-layer. They are mainly responsible\nfor receiving data from the edge devices and transmitting\ncontrol \ufb02ows back to them. Base stations/APs forward the data\nreceived from edge devices to the edge servers in the higher\nlayer to perform individual computation tasks. When a task is\ntoo complicated to be handled on the current edge server, the\ntask will be delegated to the servers with more computational\npower at a even higher sub-layer. After the task is handled\nproperly, a sequence of control \ufb02ows will be passed back to\nthe base stations/APs, and eventually transmitted to the edge\ndevices. Popular state-of-the-art edge servers include NVIDIA\nJetson Nano [50], Raspberry Pi [279], Marvell OCTEON 10\nDPU [82], and Mac Mini [68].\nCloud Service Layer (CSL).\nCSL hosts cloud servers\nand data centers. The cloud servers are responsible for the\nhighest level of operations and integration of tasks of\ufb02oaded\nfrom EDL and ESL, while the data centers storing the vast\namount of data generated in the edge computing infrastructure.\nUsually, CSL consists of clusters of powerful machines. In this\npaper, we mainly focus on EDL and ESL, as they are unique\ninfrastructures in edge computing.\nB. Security Characteristics of Edge Computing\nEven though edge computing and cloud computing are\nsimilar with respect to the offered services and functionalities,\nthe scopes of security measures are largely different, posing\nnew challenges due to the unique characteristics of edge\ncomputing platforms.\nWeaker computation power. Compared to a cloud server, the\ncomputation power of an edge server is relatively weaker. As\na result, an edge server might be more vulnerable to existing\nattacks that are less effective towards a cloud server. Similarly,\ncompared to general-purpose computers, edge devices have\nless robust defense systems. Attacks that have been mitigated\nfor desktop computers can still pose serious threats.\nLarge volume of interconnected devices. Client devices in\ncloud computing are usually not interconnected, limiting the\nin\ufb02uential impact when a few are compromised. Nevertheless,\nedge devices are typically interconnected, so a small intrusion\ncan have a more signi\ufb01cant impact if the attack is spread and\npropagated among devices (e.g,. Mirai botnet [26]).\nHeterogeneous device form factors. As we can see, devices\nof various form factors can co-exist in edge computing,\nespecially in EDL, where depending on the purpose of the\ndevice and the physical location being deployed, two devices\nmight have totally different hardware and software stacks.\nSuch a heterogeneity of devices poses extreme challenges\nwhen designing general solutions to potential threats and\nissues. The number of different scenarios of devices interacting\nwith each other increases exponentially when the number of\ndevices increases. Handling all those scenarios either sacri\ufb01ces\ngenerality if target a speci\ufb01c subgroup of edge devices, or loses\naccuracy when searching for a panacea.\nUnavailability of security features.\nVarious hardware se-\ncurity features have landed on modern platforms (e.g., [101],\n[123], [158], [163]) to mitigate existing and unforeseen threats.\nMeanwhile, architectural improvements are being introduced\nto the CPU, as well as its chipset [86], [105], [179], [185],\n[195], [207]. Not to mention the collection of software mitiga-\ntion techniques built on top of those platform-speci\ufb01c features.\nUnfortunately, due to different form factors and diverse of\nplatforms, desired security features are not always available\non speci\ufb01c edge computing platforms, and a tough decision\nof security versus cost-effectiveness has to be made.\nMaintaining quality of service.\nLast but not least, any\nadditional security measurements should try to maintain the\noriginal quality of service (QoC) (e.g., availability and real-\ntimeness) at best effort, as it is the initial purpose of edge\ncomputing.\nC. Multi-dimensional Security Analysis of Edge Computing\nThe logical components of an edge computing stack are:\ndevice hardware, \ufb01rmware and system, network and communi-\ncation, cloud stack (such as Kubedge [267]), machine learning\nas workload infrastructure and compute apps, data protection,\nprivacy, cryptography, users, identity and access management,\nand regulatory compliance.\nIn this paper we amplify an edge device and dissect in\norder to study its security issues. This study can be extended\nto an edge server or any other cyberphysical edge entity.\nIn the following sections, we will systematically study the\nvulnerabilities speci\ufb01c to edge computing for each of these\nlogical components.\nIII. DEVICE AND SYSTEM\nAs the backbone of edge computing, the edge device itself\nand the system on top serve as the shield of the edge\ncomputing system at the lowest level. System software such\nas the OS often runs at the highest privilege and mediates\nthe management tasks across process domains. At the same\ntime, the hardware provides the resources for the OS to\ncorrectly ful\ufb01ll tasks as intended by the user. As a result, the\nhardware and system software de\ufb01ne the trustworthiness of\na standalone edge device, which is a fundamental building\nblock to achieving a secure edge computing service and fully\nunleashing its power.\nWe de\ufb01ne the hardware and the system software of an\nedge device as an edge platform. To support the desired\nsecurity requirements of edge computing services, an ideal\nedge platform should consist secure 1) physical protection\n(III-A) 2) hardware components (III-B), 3) \ufb01rmware (III-C),\nand 4) system software (e.g., OS) (III-D).\nRe-imagining existing threats under edge computing. As\ncomputing devices themselves of different form factors, edge\n2\nplatforms are susceptible to existing security threats if they\npossess the targeted attack surface. Worse, the unique charac-\nteristics of edge computing may exacerbate the impact of such\nattacks. Together with privileged attackers that possess and\nprovision the edge devices of diverse form factors, there are\nvarious challenges to guarantee a trustworthy edge platform.\nA. Insecure Physical Protection\nPhysical access is commonly assumed as the last layer to\ndefend against attackers. Generally speaking, physical access\nis always excluded from threat models of cloud computing.\nHowever, this is one of the initial weapons granted in the\nattacker\u2019s arsenal under edge computing.\n1) Intrusive attacks require physical connections to the\ndevice, such as accesses to the communication ports and\nchannels (e.g., USB, PCIe [77], [121], [205], [248]),\nor direct tempering the motherboard (e.g., via solder-\ning) [206], [261].\n2) Physical side-channel attacks focus on leaking secrets\nbased on physical behaviors of the components during\nsecurity sensitive workloads, including power analy-\nsis [196], [208], electromagnetic analysis [45], [155],\nand so on. Launching such attacks requires an attacker to\naccess the target device physically or through malicious\napps, which is highly feasible under edge computing,\nwhere the attack can be conducted in an isolated and\nstable environment.\nPhysical protection boundary at edge. The cloud servers\u2019\nphysical access control models do not apply to edge devices\ndue to the high volume and diversity. Not to mention the\nprocedure of access control needs to be audited by the cloud\nserver from remote. Hence, an adequate physical access con-\ntrol model tailored for edge computing is under urgent call.\nB. Insecure Hardware Components\n1) A common source of insecure hardware components\nstems from the broken chain of trust of the hard-\nware components, such as due to an untrusted supply\nchain [74], [103] or lack of unforgeable Hardware Se-\ncurity Modules (TPMs) [16], [55], [98] and Hardware\nSecurity Modules (HSMs) [97], [115]. Such vulnerabil-\nities might hide in the original hardware package and\nare dif\ufb01cult to mitigate thoroughly without replacing the\nwhole \ufb02awed component.\n2) Other hardware attacks exploit the inherent design of\nthe components that are critical to its correct function-\nalities and thus are even more challenging to mitigate\nholistically.\n\u2022 Energy attack [134] aims to render the device in-\noperable by draining the equipped batteries through\nexcessive legitimate operations. Such an attack can\nbe launched across different layers of a device stack,\nincluding hardware resources (e.g., GPS, sensors,\nand related operations), software resources (e.g.,\nsystem calls, API, memory allocation, locking),\nnetwork operations (e.g., data transfer, handshaking\nprotocols, the bandwidth, and antenna).\n\u2022 Rowhammer attack [122], [247], tries to trigger ran-\ndom bit \ufb02ips in the RAM/DRAM via the electronic\ninterference of neighboring memory cells to tamper\nwith security-sensitive states (e.g., access control\nbit, root bit, etc.).\n\u2022 Covert channels [52] have drawn increasing atten-\ntion as they exploit the unintended communication\nchannels stemming from the normal operations of\nthe shared components such as DRAM and Last\nLevel Caches (LLC). They can break the data\nprotection mechanisms enforced by the system to\nrestrict unintended communications and provide the\nmalicious applications a stealthy way to transfer\n(security-sensitive) data between each other.\n\u2022 Mircoarchitectural side-channel attacks exploit se-\ncret related micro-architectural events, including\nthose inside CPU caches (e.g., Prime+Probe [151],\nFlush+Reload [274]), and Translation Lookaside\nBuffers [88], branch predictors with speculative ex-\necutions (e.g., Spectre and Meltdown [126], [150]).\nEdge hardware.\nAttackers under edge computing environ-\nments are even more advantageous in hardware attacks. Such\nattackers directly possess the devices and can perform physical\nattacks within an isolated and stable environment tailored for\ntheir needs, making traditional hardware attacks more feasible.\nC. Insecure Firmware\nA computing platform delegates the complexity of hardware\ninitialization tasks to the earlier boot stage using \ufb01rmware in\norder to simplify the operation system code. Under edge com-\nputing, hardware and \ufb01rmware\u2019s diverse and proprietary nature\nproliferates the fear of effective widespread exploitation.\n1) Firmware modi\ufb01cation attacks [54], [64] aim to inject\nmalicious logic into the target device \ufb01rmware. Usually,\nsuch attacks are achieved via \ufb01rmware update features\ninstead of directly exploiting \ufb02aws in the software.\nFirmware update is a common feature in most modern\nsystems, while not ubiquitously protected by suf\ufb01cient\nsecurity measurements. Lack of security checks (e.g.,\nsignature veri\ufb01cation) prior to \ufb01rmware updates directly\nfacilitates successful \ufb01rmware modi\ufb01cation attacks. A\nsecondary payload following the successful exploitation\nof the device via traditional attack vectors, such as mem-\nory modi\ufb01cation attacks [226], [227], can be used to\nbypass checks if they exist. The malicious code running\nat the \ufb01rmware level could be used to compromise any\ncomponents that are loaded later in the boot process,\nsuch as the boot loader and the OS (or hypervisor).\n2) Hard-coded and weak passwords in \ufb01rmware [194]\nis another major concern, especially in devices that\nembed default passwords while lacking administrative\nmanagement. Although the use of hard-coded or weak\npasswords can save the maintenance overhead, it leaves\n3\nthe devices vulnerable to naive password-based attacks\nsuch as dictionary attacks. Such attacks are extremely\neasy to conduct using existing tools (e.g., John the\nRipper [160], HashCat [252]) without domain-speci\ufb01c\nknowledge.\nFirmware in edge hardware.\nBesides the threats to the\nintegrity of the \ufb01rmware, edge devices with legitimate but\noutdated \ufb01rmware are also in the attackers\u2019 interest [37],\n[159], [191]. On the one hand, because of the different form\nfactors of devices, the diversity of environment for devices in\nthe \ufb01eld, and the speci\ufb01c management requirements, legacy\ndevices cannot be updated in time and therefore expose known\nvulnerabilities to attackers. On the other hand, as the attacker\nunder edge computing has more authority over the operation\nenvironment (e.g., by directly possessing the device or by\nless strict physical access control) , the \ufb01rmware updating\nprocess could be spoofed (e.g., via MITM) to preserve a stale\nversion. As a result, edge computing may magnify the impact\nof legacy \ufb01rmware attacks due to the attacker\u2019s overseeing of\nthe \ufb01rmware management process and a much larger amount\nof stale devices.\nD. Insecure System Software\nWhen the OS and the system software are trusted, i.e., the\nrequests from users are faithfully ful\ufb01lled, traditional software\nvulnerabilities can still exist.\n1) Memory corruptions [59], [85], [268] (e.g., memory\nover\ufb02ow, improper boundary check, lack of sanitization,\ndouble-free, use after free) can lead to control \ufb02ow\nhijacking (e.g., ROP [47]), and result in violations of\nthe integrity and con\ufb01dentiality of system data, or even\ngrant complete access to the system (e.g., root-access).\n2) Race conditions in the system can lead to TOCTOU\nattacks [271] and lead to similar consequences.\n3) Even with a formally veri\ufb01ed OS [124], [125] that are\nfree of such vulnerabilities, \ufb02aws in the device drivers\nand third-party libraries can still completely break the\nestablished security guarantees [61], [69], [106], [280].\n4) Besides traditional software vulnerabilities, improper\naccess control implementation allows the attacker to gain\naccess to sensitive data without launching an end-to-\nend exploit [21], [73] and generate data \ufb02ows that are\notherwise disallowed.\n5) The system software cannot always be trusted, as the de-\nvices are directly possessed and provisioned by untrusted\nadministrative parties. When facing privileged attackers\nsuch as malicious OS and hypervisors, Trusted Exe-\ncution Environments (TEEs) always come into play to\nisolate the security-sensitive content [62], [138], [188],\n[213]. However, privileged attackers can still use side-\nchannel attacks to study the program runtime behaviors,\nsuch as the through control \ufb02ow [223], [270] or the\nmemory access patterns [43], [171], and leak the secret,\nas the OS is still responsible for management tasks such\nas handling page faults.\nSELinux and Security Monitors. Edge devices and servers\nthat enable defensive features SELinux [228] and security\nmonitors [63] may temporarily turn off these features for\npower and performance considerations, leaving chances for\nattacks. Not to mention that the features are not free of\nvulnerabilities [112]. An untrusted OS can maliciously manage\nthe edge devices, and temper with the overall infrastructure of\nan edge computing entity.\nIV. NETWORK AND COMMUNICATION\nLooking into the network-level security concerns of edge\ncomputing, one must deal with various threats and vulnerabil-\nities pertaining to the communication among network nodes.\nWe \ufb01rst discuss network security issues that emerge from\nnetwork-related vulnerabilities found in devices connected in\nthe edge network (IV-A) and edge services (IV-B). We then\ndiscuss issues with the protocol (IV-C) when establishing\ntrust (IV-D) and proving that an edge node is delegated to\nperform computation tasks (IV-E). Finally, we discuss side\nchannel (IV-F) and Denial of Service attacks (IV-G), and\noutline research challenges (IV-H).\nA. Device Vulnerabilities\nThe physical layout of the edge network introduces new\nthreats. One such threat is the physical access to the machine\nitself. Edge nodes are physically located close to where data\nare generated or need to be processed. Thus, it is beyond the\nvendor\u2019s or service provider\u2019s physical control. A threat actor\nmay leverage physical access to the device to perform various\nactivities. For example, they could cause Denial of Service\n(DoS) by damaging or unplugging the device or attempting\nto penetrate the system by connecting to an open port, or\nreplacing the device with a rogue one. Wiretapping is also\npossible, allowing packet snif\ufb01ng or even injection.\nIn real-world deployments, devices are highly heteroge-\nneous and may be developed by different vendors. This is an\nundebatable fact, especially in the context of IoT. Such devices\nare often found running vulnerable code (or \ufb01rmware) that\nhas not received proper security assessments. Some devices\nmay have common vulnerabilities, such as out-of-bounds-\nwrite, which adversaries can leverage. For instance, Philips\nHue Bridge (model 2.X) contains a heap-based buffer over-\n\ufb02ow which allows remote code execution. Often, the device\nmay utilize buggy libraries even though they could be well-\nknown. OpenSSL library is a widely used cryptographic li-\nbrary that implements secure communication protocols such as\nSSL/TLS. According to CVE-2014-0160 [113], the heartbleed\nbug in OpenSSL\u2019s heartbeat implementation leads to memory\nleakage from the server to the client and from the client to the\nserver. Such leakage could reveal secret keys or other protected\nmaterial.\nNetwork nodes such as Network Address Translators (NAT)\ncarry vulnerabilities of their own. A NAT \u201chides\u201d the IP ad-\ndresses of internal network devices from the outside network.\nAll internal devices share one public IP address. Thus a threat\nactor from the outside cannot know which devices exist in\n4\nthe internal network. However, the slipstreaming vulnerability\nfound in NAT [209] actually allows outsiders to learn which\ndevices are in the internal network and probe them. The\nadversary only needs to convince one of the devices in the\ninternal network to connect to a malicious domain.\nB. Vulnerabilities in the Edge Services\nAn adversary may be able to inject a malicious payload\nusing several underlying techniques such as SQL injection\n[96], XSS [259], and CSRF [34]. The main root cause of all\nthose techniques is the lack of proper input sanitization, where\nthe edge server needs to check the validity of the input request.\nOften, servers merely check only for correct syntax, which is\ntrivial. However, they do not reason about the contents of the\nrequest, e.g., code is found where there should be data or vice\nversa. For instance, a vulnerability was found in the Cisco Fog\nDirector that allowed an unauthenticated attacker to conduct an\nXSS attack against a user of the web interface of the affected\nsoftware [58].\nC. Protocol Vulnerabilities\nThe Edge network usually uses lightweight communication\nprotocols such as LTE [212], Wi-Fi, Bluetooth, MQTT [232],\nCoAP [218], AMQP [253], LoRa [22], and Zigbee [23]. Cloud\ncomputing employs heavyweight protocols such as TLS [71],\nHTTPS [198], and FTP [190]. The protocol itself becomes\npart of the attack surface. Soft spots in the communication\nprotocols may provide an attacker the grounds to launch an\nattack.\nThe Zigbee (before version 3.0) required communicating\ndevices to share a pre-master secret key. This key was installed\non devices by vendors. However, considering the millions of\nIoT devices, an adversary can inevitably \ufb01gure out the pre-\nmaster secret [257]. Another possibility is that an adversary\nmay force the endpoints to downgrade the security of the com-\nmunication [172]. Such an attack is possible if the endpoints\nhave no way of verifying that the security properties agreed are\nthe ones that were truly intended. M\u00a8oller et al. , demonstrated\nthe POODLE attack (Padding Oracle On Downgraded Legacy\nEncryption) on SSL 3.0, which allows stealing secret material,\nsuch as HTTP cookies. HTTP is used in the edge-cloud\ncommunication.\nMessage Queuing Telemetry Transport (MQTT) is an\napplication-layer communication protocol widely used for\nIoT to edge communication. While MQTT protocol supports\nencrypted communication, it is optional. This con\ufb01guration\ncould result in critical privacy violations while allowing a man-\nin-the-middle to inject messages. For instance, data generated\nfrom wearable devices could include highly sensitive medical\ndata, personal information, and even people\u2019s movements.\nLike MQTT, CoAP is another application layer for edge\ndevices and applications that works on top of UDP. It has\nbeen reported that CoAP is susceptible to attacks such as\naddress spoo\ufb01ng and ampli\ufb01cation attacks [28], [57], [111].\nIn CoAP the response packet is much larger than the request\npacket, and thus an attacker can use small UPD requests to\ngenerate large-size responses from CoAP nodes, thus causing\ndenial-of-service to the victim devices (see section 11.3 in\nRFC 7252 [218]).\nD. Establishing Trust\nAuthentication poses another challenge. Low-end devices\nmay be authenticated to the edge servers using weak cre-\ndentials. Thus, an adversary may even be able to perform a\ndictionary attack to break into the system [167]. However,\nvulnerabilities may be introduced due to the usage of weak\ncryptographic authentication protocols (e.g., WEP [239]) or\nunpatched versions of them (e.g., WPA2-PSK dictionary at-\ntack [174]). Authentication code-level implementation poses\nadditional threats to entity authentication. Code that has not\nbeen tested or peer-reviewed may implement authentication in\na wrong way, granting access to unauthorized entities. A good\nexample of that is Apple\u2019s \u201cgoto fail\u201d bug, which allowed a\nMITM adversary to compromise the end-to-end secure TLS\nconnection. The bug was essentially bypassing the certi\ufb01cate\nveri\ufb01cation of the server, thus compromising the authenticity\nof the connection [231].\nE. Compute Authorization\nOne crucial contribution of edge computing is the dele-\ngation of complex computing tasks to the network\u2019s edge.\nWhile authentication aims to solve the problem of verifying\nidentities, authorization deals with the problem of verifying\nwhether a particular node is authorized to perform a particular\ncomputing task. A similar problem is encountered in Content\nDelivery Networks (CDNs), where media stream providers\n(e.g., Net\ufb02ix) authorize servers to deliver content on its behalf\nin several regions. The same physical spread applies in edge\ncomputing as well. Similar to how end-users need to verify\nthe content received from a CDN server, an edge device needs\nto be able to prove that it is authorized to perform such\ncomputation from the core network (e.g., corporate network,\nservice provider).\nF. Side-channel Attacks\nWhen the attacker can gain knowledge about the occurring\ncommunication and the endpoints communicating, they may\nbe able to use this information to attack the infrastructure\nitself. Information leaked through side channels often reveal\ninformation about the secret keys. Ronen et al. [204] demon-\nstrated a novel side-channel attack on Philips Hue smart lamps,\nwhich revealed the initialization vector and the secret key\nthat the lamps use to authenticate and encrypt the \ufb01rmware.\nThus, information gained from the side channel could lead to\ncatastrophic results. In addition, side channels raise privacy\nissues, especially in environments where privacy preservation\nis of high importance (e.g., smart home).\nG. Denial of Service Attacks\nEdge computing is a complex infrastructure that includes\nthe interconnection of edge devices, edge servers, and the\ncloud. As discussed earlier, edge device vulnerabilities or\n5\nvulnerabilities in the protocol itself may allow an attacker to\ncause disruptions. The edge network is more susceptible to\ndistributed denial of service (DDoS) attacks since it contains\ncomputationally less powerful resources than the cloud. For\nthe same reason, often, services deployed at the edge are\nerror-prone in their security settings [265]. For instance, if\nan attacker can take control of a cluster of edge devices,\nthey essentially create a botnet. A very famous attack is the\nMirai botnet [128] where attackers were able to compromise\nIoT devices and use them to cause a DDoS to the edge\nserver network providers such as Krebs and OVH [27]. Then,\nthe botnet \ufb02oods the core network (i.e., the edge servers)\nwith enormous requests. Such an attack causes a DoS due to\nresource exhaustion. Techniques to cause a denial of service\ninclude message \ufb02ooding at the internet layer (e.g., ICMP),\nthe transport layer (e.g., TCP, UDP), or even the application\nlayer (e.g., HTTP).\nWhile DDoS attacks are more practical in the edge network,\ncloud DDoS is still feasible from the attacker\u2019s perspective.\nSuccessful DDoS attacks on the cloud can cause signi\ufb01cant\ndisruptions in the edge network. CVEdetails report the top 50\nvulnerable products [70], many of which run on cloud servers\n(e.g., Windows 10 and Linux Debian).\nH. Research Challenges\nFrom the network security point of view, many challenges\nneed to be addressed in the future research.\n1) Network security con\ufb01gurations and management: Edge\ncomputing is designed to support a range of devices\nspanning different vendors with different security capa-\nbilities. Different vendors provide different application\nprogramming interfaces to con\ufb01gure the device. Ad-\nministrators must make signi\ufb01cant efforts to adequately\ncon\ufb01gure the devices, making it a costly and error-prone\ntask.\n2) Adoption of Zero Trust Architecture (ZTA): As argued\nearlier in the section, access control is critical when\nmanaging large distributed infrastructures like edge\ncomputing. Frameworks are needed to support \ufb01ne-\ngrained access control policy speci\ufb01cations; in other\nwords, which communications should be allowed and\nwhy. De\ufb01ning such access control policies needs to be\ndone in a way that keeps errors minimal. For example, an\nadministrator may specify at a high level which entities\nneed to communicate and have an automated process to\ntranslate this to network-level details (e.g., using \ufb01rewall\nrules, etc.). Often, organizations adopt threat models\nwith weak adversarial assumptions. For instance, they\nmay assume that the adversary may not be able to\ncompromise end devices. Therefore, access control is\nvery loosely de\ufb01ned within the network while enforcing\nmore access control on network perimeters (i.e., \ufb01re-\nwalls). However, this becomes a major issue once the\npresumably trusted devices misbehave. For example, a\ncompromised IoT device may start probing resources on\nthe network or try to spread the infection further in the\nnetwork. Such an attack is feasible since access control\nis non-existent or very loosely de\ufb01ned [204]. In other\nwords, one needs to precisely de\ufb01ne who can access\nwhat on the network and for what reason [117], [118].\n3) Secure access service edge (SASE): SASE extends the\nZTA by granting access to network resources based on\nthe entity\u2019s identity (e.g., IoT, device, user application),\nwhile it also requires real-time context and continuous\nassessment of risk and trust throughout the sessions.\nReal-time contexts can vary across edge computing\ndeployments and must be standardized for compatibility\nacross SASE services. Assessment of risk and trust\nmust be a continuous monitoring process as long as\nan entity lives in the network. However, as we discuss\nin the paper, risk and trust must account for threats\nand vulnerabilities emerging from different architectural\nstacks (e.g., network, hardware, system).\nV. CLOUD STACK\nThe cloud composes the central processing and maintenance\nof the data collected in the edge network. The edge network\ntransmits data to the cloud for further processing or permanent\nstorage, among other purposes. The cloud is a distributed\nsystem composed of several interconnected machines similar\nto the edge network. However, cloud resources are shared\namong many parties. In public clouds, those parties can be\ndifferent users or organizations. Therefore, security issues\nemerging in the cloud impact edge network as well. Despite\nits architectural incentives and bene\ufb01ts, the cloud brings its\nsecurity issues to the edge network.\nA. Cloud Vulnerabilities\n1) Miscon\ufb01gurations:.\nData can be exposed simply by\nmiscon\ufb01guration of the cloud machine instances (see\nFigure 1). For example, extremely sensitive user data\nwere leaked by a cloud leader due to a miscon\ufb01guration\nof Amazon Web Services S3 [67], [84]. The miscon-\n\ufb01guration allowed public access to the cloud server\nhosting the data while also having no access control\nenforcement.\n2) Insecure APIs:.\nCloud services expose their func-\ntionality through Application Programming Interface\nparadigms (e.g., REST). Gartner predicts that by 2022,\napplication programming interface (API) attacks will\nbecome the most-frequent attack vector, causing data\nbreaches for enterprise web applications [53]. The most\ncritical issues in API security are insuf\ufb01cient access\ncontrol, injection, and Excessive Data Exposure, among\nothers [181]. A vulnerability in Microsoft Exchange\nServer allowed attackers to send unauthenticated HTTP\nrequests to any Exchange server. Broken user authen-\ntication and security miscon\ufb01gurations allowed the ad-\nversaries to leverage the back-end API of the server to\nescalate privileges and maintain persistence. A similar\nscenario could be encountered in an edge computing\n6\nenvironment. Services deployed at the edge expose API\nfunctionality to be used by devices.\n3) Virtualization issues:. Virtualization operations can be\ndistinguished into two components: Virtual Machine\nManager or Hypervisor (VMM) and the Virtual Machine\ninstances.\nVMM is the crown jewel since its compromise allows\nthe adversary to attack many virtual systems at once.\nIn 2021, a ransomware attack occurred on the VMware\nESXi hypervisor. According to Sophos \ufb01rm, defensive\nmistakes and unnecessary functionality allowed the at-\ntackers to deploy crypto-locking malware and disrupt the\noperations of all the tenant VMs.\nVM integrity must be veri\ufb01ed at all times in the cloud.\nVM could be running mission-critical applications for\nthe edge network; thus, cloud providers must ensure\nthat there are no malicious or compromised VM images.\nIn addition, vulnerabilities associated with virtualization\nenvironments may allow attackers to obtain administra-\ntor privilege in the host system due to mishandling of\nprivileges (CVE-2019-5736 [13]).\n4) Cloud Service Provider transparency:. Often, there is no\nclear understanding of how the cloud operations are per-\nformed, and thus, it is not feasible to assess the security\nposture of the edge network thoroughly. For example, it\nis unclear what protection measures the cloud provider\ntakes for data con\ufb01dentiality. How are the data stored,\nor when do they get decrypted for processing? Are there\nany process isolation mechanisms in place? Those are\njust a few of the security concerns. Of course, similar\nconsiderations apply to data integrity and availability.\nFor example, when does the signing process takes place\nand where? What is the mechanism employed for data\navailability? Another interesting aspect is if third parties\nare involved in the cloud operations, for instance, for\ndata backups. Transparency is the key factor for clients\nand network administrators to realize risks and see how\nthings can go wrong.\n5) Cloud at the Edge:.\nCloud at the Edge (aka Edge\nCloud) offers cloud computing resources to the edge of\nthe network or where the traf\ufb01c is. Various frameworks\nhave been developed, offering cloud services at the\nedge, such as KubeEdge [8], EdgeX Foundry [6], and\nOpenEdge [192]. Such frameworks are part of the cloud\nstack and bring their \ufb02aws into the edge infrastructure.\nA recent vulnerability was disclosed where speci\ufb01c\nbinaries within the OpenEdge application were suscep-\ntible to privilege escalation (CVE-2022-29849). A local\nattacker could elevate their privileges and compromise\nthe affected system. Similarly, due to improper access\ncontrol and weak password requirements in EdgeX, an\nattacker could make authenticated API calls to EdgeX\nmicroservices from an untrusted network.\nB. WebAssembly (Wasm)\nWasm [95] was proposed by the World Wide Web Consor-\ntium (W3C) as a platform-independent compilation target for\nvarious high-level languages (e.g., C, C++, Rust). Originally,\nWasm addressed the problem of safe, fast, portable low-level\ncode on the Web. As an abstraction over modern hardware,\nWasm is language-, hardware-, and platform-independent, with\nuse cases beyond the Web. Wasm adopts a linear memory\nwith a con\ufb01gurable size for all memory accesses other than\nlocal and global variables. The liner memory region is disjoint\nfrom other memory regions (e.g., code space, execution stack),\ncontaining the impact of vulnerabilities within the data of the\nprogram\u2019s own memory.\n1) Beyond all the bene\ufb01ts brought by Wasm, research has\nshown that traditional vulnerabilities re-instantiate in\nWasm [140], [238].\n2) Even worse, Wasm enables unique attacks, such as over-\nwriting constant data or manipulating the head using a\nstack over\ufb02ow. Attack primitives found in Wasm include\nbut are not limited to those that allow an attacker: 1) to\nwrite arbitrary memory, 2) to overwrite sensitive data,\nand 3) to trigger unexpected behavior by tampering with\ncontrol-\ufb02ow integrity (CFI) or the host environment.\n3) Threats to Wasm at edge.\nResearchers have explored\nthe application of Wasm under the setting of edge\ncomputing [164], [176], [260]. As Wasm is designed\nas platform-independent, exposed vulnerabilities will\nremain in edge devices that adopt Wasm, with potentially\nhigher impacts by propagating the outcome across the\nmassive and heterogeneous edge computing network.\nVI. MACHINE LEARNING WORKLOAD\nWith the increasing amount of data generated by a large\nnumber of devices in the edge network, the opportunities,\nchallenges, and applications of edge machine learning (edge-\nML) have also increased. Edge-ML has been widely used\nfor various edge computing tasks, e.g., computer vision for\ntraf\ufb01c surveillance [42], decision making for autonomous\ndriving [258], and speech recognition for personal assis-\ntance [132]. Considering the huge number of devices in\nthe edge network, training edge models from scratch will\nrequire tons of computational resources. Therefore, transfer\nlearning [250] along with other techniques [165] is introduced\nto reduce the development cost of edge-ML systems [65],\n[107]. In this section, we discuss the edge-ML system security\nfrom several aspects, including life cycle (\u00a7VI-A), threats\n(\u00a7VI-B), vulnerabilities and exploits (\u00a7VI-C), and challenges\n(\u00a7VI-D).\nA. Edge-ML Life Cycle\nFigure 2 shows the life cycle of edge-ML systems, which\nincludes stages of data collection and curation, model train-\ning, testing and validation, deployment, and inference. The\nkey feature of edge-ML is allowing model training across\ndecentralized edge devices or servers that hold local data\nsamples without exchanging them, which is also referred to as\n7\nCollect\nTrain\nEdge\nCurate\nData\nInfer\nCloud\nTest, \nvalidate\nFine-tune\nDeploy\nFig. 2. The Life Cycle of Edge Machine Learning Systems\nfederated learning [145], [256]. The diverse edge computing\ntasks atop different edge environments and the new learning\nparadigms bring about a set of domain-speci\ufb01c security prob-\nlems and challenges of edge-ML. Building trustworthy edge-\nML systems requires securing the whole life cycle of edge-ML\nsystems in terms of the data, model, and infrastructure.\nB. Edge-ML Threats\nIn edge-ML, the availability and visibility of local data\ndepend on the two different training patterns: (1) local data are\ncollected and uploaded to servers while the models are trained\nin a centralized way and (2) local data is only available to the\nlocal workers (edge devices) in federated learning scenarios.\nFor the \ufb01rst training pattern, all the known threats [152] for\ncentralized machine learning systems can be applied. For the\nsecond training pattern, there are new threats due to the nature\nof distributed learning. Distributed learning makes it dif\ufb01cult\nto audit the quality of local data and the training behaviors\nof local workers. Malicious local workers can manipulate the\n\ufb01nal models by modifying the training data in silence. In\naddition, attacks can also be performed on the data collection,\ntransmission, and processing phases by attacking benign work-\ners [18]. To make it clearer, we de\ufb01ne the threat model with\ntwo types of attacks: insider and outsider attacks [202], [254].\nWhen attacks are carried out by any participant (local workers\nor servers) in the decentralized learning system, they are de-\n\ufb01ned as insider attacks. The outside attacks are mainly carried\nout by snif\ufb01ng/inferring information about the data or models.\nC. Edge-ML Vulnerabilities\nThe new threats to edge-ML systems introduce new vul-\nnerabilities by which adversaries can further develop exploits\nto attack systems. Based on the life cycle of the edge-ML\nsystem, we consider vulnerabilities and exploits in different\nsteps of this system. In this section, we skip the discussion of\nattacks targeting data collection and curation (we present them\nin \u00a7VIII-C) to differentiate between direct and indirect attacks.\nTraining-time\nattacks.\nFor\ntraining-time\nattacks,\nthe\nadversary can manipulate the training data to perform\npoisoning attacks, injection attacks, adversarial perturbation\nattacks, and byzantine attacks.\n1) Poisoning attacks [92], [116], [214] aim to poison the\ntraining datasets by adding a small number of poisoned\nsamples (e.g., 5% of all training samples [92]). The data\npoisoning process can be achieved by providing wrong\nsamples, injecting perturbations, or \ufb02ipping labels. For\nexample, the attackers can add fake data via SSD\nattacks [30], compromise the edge software systems and\ndevices [265], and IoT spoo\ufb01ng [99]. The victim edge-\nML systems will learn the erroneous features and update\nthe model weights incorrectly.\n2) Injection Attacks [146], [246] are prosecuted by inserting\ntrojans and bias to only the target data sample, which is\noften called target attacks. The triggers can be physical\nobjects (e.g., stickers on the stop sign [80]) or the digital\ntriggers (e.g., watermarks on images [215]), which can\nfool the edge-ML systems (e.g., autonomous vehicles\nand face recognition cameras) to predict inputs with\ntriggers as the target wrong labels. Moreover, attackers\ncan also add bias, resulting in fairness problems [162]\nto victims. For example, they can manipulate the edge\nsensor data to force the classi\ufb01ers to learn unbalanced\nlabels (e.g., gender [137]).\n3) Adversarial example attacks [263], [277] are performed\nby adding perturbations into training samples, which are\ncarefully generated and indistinguishable to the human\neyes. The attackers can actively generate dynamic and\noptimized perturbations to mislead machine learning\nsystems. For example, the adversary can attack the edge\nnetwork intrusion detection systems by adaptively mu-\ntating the network features (e.g., device IP address and\nport number) by DDoS, reconnaissance, and information\ntheft attacks [130].\n4) Byzantine attacks [81], [229] are carried out when the\ncloud or edge servers select malicious clients in the\nfederated learning stage. Attackers can contaminate the\nlocal edge device data via poisoning attacks [249] and\nuse it to train the local models. Then they upload\nthe well-trained or directly tampered malicious model\nweight updates to servers [35], [217], which can dam-\nage the \ufb01nal model hosted in the servers or leave a\nbackdoor [31]. Except for malicious model weights,\nthe attackers can also directly upload the malicious\nlocal data (crafted by data manipulation [109]) to the\nservers. When data security checks fail to identify these\nvulnerabilities in servers, attacks will succeed [148].\nInference-time attacks.\nInference-time attacks can be per-\nformed in the stages of of\ufb02ine validation/testing and online in-\nference. We consider four categories of inference-time attacks,\nincluding exploratory attacks, membership inference attacks,\nevasion attacks, and spoo\ufb01ng attacks.\n1) Exploratory attacks [182], [222], [251], [262] aim\nto explore the architectures of the machine learning\nsystem and build shadow models (or edge-ML systems).\nThe adversaries (e.g., malicious edge devices) have\nblack-box access to the victim model (e.g., the \ufb01nal\nmodel) through MLaaS APIs [199], where edge or\ncloud servers provide machine learning service APIs\nto edge devices. Attackers \ufb01rst query victim models\nwith synthesized samples [182], [262] to get labels and\nthen train a functional equivalent [251] shadow models\n8\nbased on the labeled data.\n2) Membership inference attacks [143], [175], [230] are\nperformed to determine if the given data samples\nare members of the victim models\u2019 training data.\nIn edge-ML, over\ufb01tting \ufb01nal models force them to\nmemorize the training samples, which can increase the\nsuccess rate of this attack [230].\n3) Evasion attacks [46], [183], [221] are to manipulate\ninference results by carefully crafting test samples. The\nadversary can be either insider attackers or outsider\nattackers that compromise the edge devices [245]\nor invade the edge communication network [139] to\ngenerate the samples that have the close probabilistic\ndistribution as the original training data to fool victim\nmodels, resulting in prediction errors.\n4) Spoo\ufb01ng attacks [156], [219], [220] are performed by\ndirectly generating adversarial test samples from scratch\nrather than crafting existing samples. The adversary\n(e.g., malicious edge devices) can spoof edge device\ndata by GAN networks [87], which consist of two\ncomponents: generators and discriminators. Generators\ncreate\nspoo\ufb01ng\nsignals,\nand\ndiscriminators\ndetect\nwhether samples are spoofed or not, where they mini-\nmize their own low by playing minimax games [129].\nDeployment attacks.\nAfter the training, validation, and\ntesting stages, edge-ML models will be deployed in edge\nnetworks, where they can be placed in edge/cloud servers\nor edge devices. We consider two categories of deployment\nattacks: model stealing attacks and supply chain attacks.\n1) Model\nstealing\nattacks\n[242]\ncan\noccur\nin\nboth\ncloud/edge server and edge device sides. For the cloud\nservers, the edge-ML models are usually invisible to\nattackers except for the scenarios where attackers can\ninvade the servers. However, they can still indirectly\nsteal the model by the above-mentioned inference-time\nattacks (e.g., exploratory attacks). When the edge-ML\nmodels are deployed in the edge servers and devices,\nit is much easier to get the models due to the lack of\nmodel protection techniques. Sun et al. [242] \ufb01nd that\n81% of the edge-ML models can be simply extracted\nfrom edge applications and directly used. Moreover,\nmost of the edge-ML models are built atop popular and\npublicly available machine learning frameworks (e.g.,\nTensor\ufb02ow Lite [66]) [24], [269], which means that\nattackers can easily reuse the stolen models. Although\nmany countermeasures, e.g., model deployment with\ntrusted execution environments [100], [169], have been\nproposed, the limited resources of edge devices make\nthem far from practical.\n2) Supply chain attacks [102], [180], [272] are performed\non the edge-ML models distributed in the supply chain.\nAs deep neural networks become deeper and deeper,\nedge-ML models are often built on existing pre-trained\nmodels (e.g., mobileNet [108]) that are speci\ufb01cally\ndesigned for edge computing environments via trans-\nfer learning. In this case, edge-ML models need to\nbe distributed on numerous devices for both federated\nlearning and online inference tasks. However, the supply\nchain of pre-trained model acquisition [102] and model\ndistribution [180], [272] will be the target of adversaries.\nFor example, the attackers can stealthily modify the\nweights of models by man-in-the-middle attacks on the\nedge network.\nIn addition to attacks targeting the edge-ML life cycle, there\nare also threats and vulnerabilities in edge-ML frameworks.\nUnlike machine learning frameworks for cloud servers, which\nhave much larger computational resources than edge devices,\nthe edge-ML frameworks are carefully designed to overcome\nresource limitation issues. The edge-ML frameworks have\ngained more and more attention recently, and many vendors\nhave designed their own frameworks for the edge environment,\nsuch as TensorFlow Lite [66], Apple Core ML [2] and Pytorch\nmobile [10]. Moreover, it has been found that frameworks for\ngeneral machine learning are also widely used in edge devices,\ne.g. Caffe2, NCNN, and Parrots [269]. These frameworks used\nin the edge-ML system can also be vulnerable. One of the key\nvulnerabilities of the edge-ML frameworks is the calculation\nvulnerability [5]. It usually happens when an unexpected\ndata point or value is given to edge-ML frameworks, which\ninvolves physical dimensions of edge data, such as size, length,\nwidth, and height. The adversary can develop exploits of this\nattack to trigger in\ufb01nite loops or deadlock to break edge-ML\nsystems [44].\nD. Edge-ML Challenges\nThe diverse edge-ML environments bring about a set of\nchallenges in applying machine learning to edge computing.\nHere we consider the following challenges.\n1) Computational challenges. The edge devices usually\nhave a very limited computational resource budget for\nedge-ML model training and deployments. For ex-\nample, the memory on the chip of IoT devices is\n103\u00d7 and 105\u00d7 smaller than mobile devices and cloud\nservers [149]. The limited resources make it hard to\ndeploy the defenses and countermeasures of the ahead-\nmentioned attacks. Even if the defenses can be appli-\ncable for edge computing, the performance of the main\ntasks will be affected while the defenses are used. For\nexample, as discussed above, although the TEE solution\nfor model protection can be used for some edge devices,\nTEE enclaves will consume most of the on-chip memory\nto affect the other tasks on the devices [170].\n2) Life-cycle protection challenges. Except for the limita-\ntion of computational resources, protecting all stages\nof the whole life cycle of edge-ML systems itself is\nvery hard because of the large number of unprotected\nedge devices. Taking into account the federated learn-\ning paradigm, attackers can easily access local data\nand models due to the lack of protection mechanisms\nadopted in edge devices. In addition, the communication\nchannel between edge devices and servers can also be\n9\nvulnerable (as we discussed in \u00a7IV), which also presents\nchallenges to data and model protection. Hierarchical\nand collaborative protection schemes are required to\nsecure the edge-ML work\ufb02ow, which is dif\ufb01cult to\nachieve.\n3) Ethics challenges. Although edge computing has be-\ncome an inevitable part of our society and millions of\nedge-ML systems and models have been deployed [7],\nthere are several unsolved ethic issues. First, the owner\nidenti\ufb01cation issue exists in edge-ML systems. Collect-\ning various user data without user\u2019s consent or permis-\nsion is a critical problem to be addressed. Second, there\nis no clear line to differentiate private and public data,\nwhere edge devices can collect both public and private\ndata from end-users. The absence of clearly de\ufb01ned\nboundaries for data leaves attack surfaces to adversaries,\nand they can develop exploits to attack users from the\nedge-ML system. Finally, even if there are many coun-\ntermeasures, e.g., differential privacy, that have been\nproposed to address some of the problems [173], edge-\nML ethics is still an open question [154].\nVII. CRYPTOGRAPHY\nCryptography is a fundamental stone in edge computing\nsecurity in various aspects ranging from communication and\nstorage to computation and analysis. Due to the difference in\navailable resources in edge devices and servers, the strength\nof cryptographic protection on each device or server varies.\nIn this section, we focus on using cryptographic algorithms\nin the edge network, de\ufb01ne the life cycle of different aspects\nof a cryptosystem, and analyze potential threats and vulner-\nabilities we may face in this new computational framework.\nWe then discuss other cryptography topics in edge computing,\nsuch as entropy management and post-quantum cryptography.\nA. Cryptography Life Cycle\nCryptography life cycle refers to the different phases of\nuse of cryptography in and across systems, especially for\nnetwork security. The components of the cryptography life\ncycle include: key management life cycle, cryptosystem de-\nsign and implementation, protocol deployment and adoption,\ncryptosystem expiration and revocation, and supply chain.\nThe key management life cycle refers to the phases of\nusing cryptographic keys, such as key generation, updates,\nand revocation. Cryptosystem management focuses on the\nimplementation, adoption, and retirement of the protocols\nthemselves, whereas supply chains focus on the origin and\npaths in developing cryptographic libraries and packages.\nB. Cryptographic Vulnerabilities\nBased on the cryptography life cycle, we list out potential\nvulnerabilities and exploits that may be present in each stage\nof the cryptography life cycle.\nKey management. Security of cryptographic keys is the most\ncrucial component in a cryptosystem. If an adversary is able\nto obtain the symmetric key used by an edge device and edge\nserver during communication, all past and future messages\nencrypted with such key will be under the full control of the\nadversary. To protect the key, we must be aware of potential\nexploits during each stage of its life cycle.\n1) Key generation.\nBit security [166] is a notion of\nevaluating the security of cryptographic algorithms and\nis generally related to the size of the key space. Achiev-\ning more robust security of a particular cryptosystem\ntypically implies increasing the key length [144], which\ncan slow down the key generation process and limit the\nnumber of available keys of a resource-constrained edge\ndevice. Using short keys in communication can alleviate\nthe computation burden of edge devices at the cost of\nsecurity.\nExploits in the key generation stage can also originate\nfrom an active outsider adversary. Due to limited re-\nsources, an edge device may not be able to properly\nverify identity of the edge server. During the key agree-\nment process between edge devices and servers (e.g.,\nDif\ufb01e-Hellman key exchange algorithm), an adversary\ncan perform a man-in-the-middle attack to obtain the\nsymmetric encryption key [119] and tamper with all\ntransmitted messages.\n2) Key rotation. Key rotation [79], [211] is a common cryp-\ntographic practice to retire old encryption and signing\nkeys and generate new ones for future communications.\nIt reduces the number of messages each key is linked to,\nthus preventing adversaries from batch-decrypting and\ncompromising all transmitted messages in the network\nand providing forward secrecy [273] guarantee for the\nprotocol. However, frequently generating and deriving\nnew ephemeral keys is resource-consuming and may not\napply to many edge devices with limited resources.\n3) Key revocation.\nSimilar to key rotation, key revoca-\ntion is also a crucial practice to guarantee forward\nsecrecy and prevent currently unauthorized parties from\ncontinuing accessing data within the edge network. It\nis recorded through key revocation certi\ufb01cate, and a\ncerti\ufb01cate revocation list [29]. However, due to a large\nnumber of edge devices and servers, and the necessity\nof regularly refreshing keys, it is time- and space-\nconsuming to keep track of every revoked key for all\ndevices and servers on the network.\nCryptosystem management.\nAs the edge network is a\nnew computation system framework, there are frequently new\ncryptographic schemes [93], [266] being proposed to help\nalleviate vulnerabilities in network security, data protection,\nand privacy. However, translating from provable theoretical\nsecurity to software security is shown to be a not easy task.\n1) Design and implementation.\nStudies by Lazar et al.\n[136] on 269 cryptographic vulnerabilities reported in\nthe CVE database have shown that the vast majority\nof cryptographic vulnerabilities come from not bugs in\ncryptographic libraries but misuse of such libraries and\npackages during protocol and application development.\n10\nTo securely implement new cryptosystems, one need\nboth profound cryptographic knowledge and extensive\nexperience in cryptographic software development, as\notherwise it can introduce many unnecessary risks.\n2) Deployment and adoption.\nWhen a new protocol is\nstandardized and ready for public deployment after a\ncareful creation process, we now face the problem of a\nslow adoption process regarding the new protocol. For\nexample, TLS 1.3 [197] was introduced in 2018 with sig-\nni\ufb01cant improvement in performance and security guar-\nantees over the previous version, yet its adoption rate has\njust reached 63% by late 2021 [1]. The slow deployment\nprocess can be caused by public unawareness or the lack\nof compatibility with old devices and systems. During\ncommunication between an edge device and edge server,\nif an edge device does not support TLS 1.3, the server\nwill have no choice but to downgrade to using less\nsecure cryptographic algorithms and keys, leaving the\nchannel more vulnerable to malicious attacks.\n3) Expiration and revocation. With the discovery of new\nattacks and deployment of new cipher suites, certain\ncryptographic algorithms will be removed from common\nusage to provide stronger security requirements. For ex-\nample, TLS 1.3 removed MD5, RSA, and weak elliptic\ncurves from its cipher suite pool [14]. Due to the lack\nof updates or computational resources, old edge devices\nand servers may be incompatible to run secure new\nprotocols. Known weak ciphers and hashes such as DES\n[60], [168] and MD5 [9] may still be used in the edge\nnetwork, leading to simple and effective attacks [72],\n[237] against intercepting in-network communications.\nSupply chain.\nThe security of a speci\ufb01c cryptographic\nlibrary is built upon security assumptions on its dependencies,\nforming a chain of trust. If one chain link is broken, all\npackages and libraries that depend on it can be compromised.\nVulnerabilities of the cryptographic supply chain can emerge\nfrom many aspects, including cryptographic libraries them-\nselves, their library dependencies, and package developers.\n1) Outdated cryptographic libraries and packages.\nAs\ncryptographic protocols are deployed for decades or\nreplaced over time, developers may not retain frequent\nmonitoring, maintenance, and updates for the packages.\nSuch libraries do not have timely patches and \ufb01xes to\nrespond to newly discovered attacks that affect them,\nmaking themselves and their dependency successors\nsusceptible to malicious attacks.\n2) Insecure dependency sources. As mentioned in section\nVII-B, the detachment between theoretical cryptographic\nproofs and real-life cryptosystem development can in-\ntroduce many vulnerabilities in protocol implementa-\ntion. Such issues may not be re\ufb02ected in theoretical\nanalysis of the protocol, since they do not directly\noriginate from the protocol itself. Indeed, physical side-\nchannel attacks such as One&Done [19] analyze the\nsignal activity when performing modular exponentiation\nto recover RSA secret keys in OpenSSL. The heart-\nbleed bug [113] is caused by a missing check in the\nTLS heartbeat extension in OpenSSL, which did not\naffect other TLS implementations such as GnuTLS [11]\nand Windows platform implementations [210]. These\nvulnerabilities reside in the OpenSSL implementation\nrather than the TLS protocol itself. Such vulnerabilities\nare not represented in theoretical protocol analyses but\nhave detrimental effects on the actual application of the\nprotocol.\n3) Untrusted developers. The third component of the chain\nof trust falls onto its people \u2013 developers behind the\ncryptographic libraries and packages. As demonstrated\nin an empirical study by Blessing et al. [39], software de-\nvelopers re-implementing their own cryptographic tools\ninstead of referring to established libraries can produce\nvulnerabilities at a rate three times as much as with non-\ncryptographic software. Furthermore, the complexity of\ncryptographic software has a much larger negative im-\npact on implementation security when compared to non-\ncryptographic software. In a vast edge computing net-\nwork, the cryptographic software complexity is substan-\ntially higher than other systems. Not using established\ncryptographic libraries and tools created by a trusted\nsource can impose a much higher chance of introducing\nadditional vulnerabilities into the system [4], [56].\nC. Entropy Management Vulnerabilities\nMost modern cryptographic algorithms require strong and\nsecure randomness to ensure security against various attacks.\nRandomness generated from insuf\ufb01cient entropy can lead to\nserious compromises, such as the prediction of secret keys\n[104], [200]. Entropy poisoning attacks [25] can restrict,\nin\ufb02uence, or give an adversary complete control over the\nentropy pool used by devices, causing the algorithm outputs\nto be easily predictable or entirely deterministic in the eyes of\nthe adversary.\nD. Quantum Safe Cryptography\nSince data may be stored in edges servers for years or\ndecades from now, one must consider new threats from utiliz-\ning quantum computers in the not-so-distant future.\nIn the post-quantum age, many popular and traditionally-\nsecure asymmetric algorithms (e.g., RSA [201], DSA [32],\nECDSA, etc.) can be easily broken by a quantum computer\nrunning Shor\u2019s algorithm [224], while the security of sym-\nmetric schemes has been drastically decreased by Grover\u2019s\nalgorithm [89]. An adversary may be equipped with storage ca-\npabilities to store communications records among edge devices\nand servers, then utilize quantum computers to help decrypt\nand recover sensitive data after. Research has been done [83],\n[153], [255] to investigate methods for building a quantum-\nresistant algorithm that helps alleviate such issues. However,\nchallenges [83] persist in applying quantum-resistant edge\ndevices in many aspects, such as performance, standardization,\nand physical security.\n11\nPost-quantum performance concerns.\nFor a scheme to\nbe considered secure, quantum-secure cryptosystems usually\ndemand a signi\ufb01cantly heavier workload on the key genera-\ntion process [186] with a much larger key size requirement\nthan in the traditional setting. For example, most symmetric\nalgorithms such as AES [75] can be considered quantum-\nsafe at the cost of doubling the key length [36], but post-\nquantum asymmetric schemes can have a private key length as\nlarge as 14000 bits [225]! Such conditions impose additional\ncomputational burdens on resource-constrained edge devices,\nlimiting the scope of their usage and adoption.\nPost-quantum side-channel attacks.\nThere have been de-\nsigns and optimizations of lightweight post-quantum algo-\nrithms applied to the edge and IoT devices [17], [76], [120].\nEven though such schemes are theoretically secure against\nquantum attacks, the implementation of quantum-secure algo-\nrithms can still be vulnerable to physical side-channel attacks\n[184], [189], as edge devices and servers commonly lack\nstrong physical access control and protection mechanisms.\nE. Research Challenges.\nThe edge computing architecture contains diverse servers\nand end devices, which raises many challenges when we try\nto analyze the security of the entire system:\n1) Cryptosystem con\ufb01gurations. When numerous end de-\nvices and edge servers encompass the cloud, each may\nsupport different algorithms, packages, and protocols. It\nis hard to apply analysis to a general edge computing\nframework without missing speci\ufb01c details of individual\nnetworks.\n2) Adversarial models. Different edge-device network con-\n\ufb01gurations can apply different restrictions on the pos-\nsible models of outsider attacks. One needs to adjust\nthe analysis and mitigation efforts speci\ufb01c to each local\nnetwork while evaluating the security of the general edge\ninfrastructure as a whole.\nVIII. DATA SECURITY\nIn the edge computing model, a large amount of private data\nis outsourced to edge servers for computation and storage.\nInformation collected from end devices is processed, aggre-\ngated, and analyzed in multiple levels of edge servers, then\ntransmitted to the cloud. As data travel through the edge server\nhierarchy, its ownership is transferred from edge devices to\nmany servers. This raises questions on how to guarantee the\nsecurity of a device\u2019s data in an untrusted environment without\nhaving direct control. Furthermore, edge computing aims to\nprovide fast computation and real-time responses to reduce\nthe latency of device-server communication, which presents\nan additional layer of restriction on applying common data\nsecurity measures.\nWe \ufb01rst touch upon different stages of data \ufb02ow in an edge\nnetwork and discuss challenges in protecting con\ufb01dentiality,\nintegrity, and availability during each stage. Then we focus on\nanalyzing data usage issues in machine learning applications\non edge.\nA. Data Life Cycle\nThe data \ufb02ow within an edge network consists of multiple\nstages that re\ufb02ect on different states of the data, including data\ncollection and transmission (data-in-motion), data processing\nand analysis (data-in-use), and data storage and recovery (data-\nat-rest). The data shifts among the three states as it travels\nthrough the edge network from the cloud. The states interleave\nwith one another, yet each presents unique vulnerabilities in\nthe security of gathered data.\nB. General Data Threats and Vulnerabilities\nData-in-motion. Data in-motion is the process of data being\ntransmitted to different locations in the network. In edge\ncomputing, this includes data collection from various sources,\ndata sharing among edge servers, and data integration from\nedge servers into the cloud. The \ufb01rst step of data \ufb02ow in an\nedge network is collecting input data from different sources.\nSuch input can come, for example, from an IoT sensor or other\nedge devices in the network. Then, the data is shared among\nedge servers during collaborative computation tasks. In the\nend, accumulated data is transmitted from edge servers to the\ncloud. Ensuring the authenticity and the integrity of data-in-\nmotion warrants the correctness of data as it goes through\nother stages.\n1) Weak authentication.\nIoT devices and many edge\ndevices lack suf\ufb01cient resources to perform advanced\nauthentication algorithms. These operations may be of-\n\ufb02oaded to the edge server to alleviate the computational\nburden of edge devices. As a result, data transmitted\nfrom devices to edge servers are likely coupled with\nweak digital signatures [48] or message authentication\ncodes [38]. In extreme cases, authentication mechanisms\nmay be skipped entirely. This makes incoming messages\nextremely susceptible to interception and tampering by\nan active attacker controlling the network.\n2) Fabricated data.\nEven with proper message authenti-\ncation methods, incoming data may still be sent by a\ncompromised entity. A corrupted edge device or edge\nserver can send fabricated data signed by a valid key\nto pass veri\ufb01cation checks without raising suspicion of\nother parties on the network.\nData-in-use.\nData in-use refers to the phase where data is\nbeing processed by the edge server, during which it may be\ndecrypted into plaintext form or remain encrypted for certain\noperations. At this stage, data con\ufb01dentiality may be violated\nby an outside attacker manipulating the server\u2019s memory units,\nor an untrusted server extracting partial information.\n1) Memory-based attacks.\nDuring the processing stage,\nstored data is usually decrypted before being used,\nwhich provides adversaries with an opening to access\ndecryption keys or plaintext data. In the context of edge\ncomputing, since edge servers commonly lack strong\nphysical protection, an attacker with physical access\nto the edge server can launch memory attacks such\nas installing RAM scraping malware [203], executing\n12\nuntrusted functions [278], and exploiting side channels\n[40], [275].\n2) Encryption leakage attacks.\nIn cases where the edge\nserver is operating over encrypted data (e.g., via search-\nable encryption), information about the underlying plain-\ntext can still be exposed to the server via leakage. When\nperforming search, update, and retrieval requests from\nedge devices, an honest-but-curious edge server can\nrecord and analyze memory access patterns to determine\nthe number and frequency of the \ufb01les accessed. Further,\nan active server can in\ufb02uence user requests and recover\npartial plaintext of the encrypted data via leakage abuse\n[49].\nData-at-rest.\nUsually, data is encrypted while being stored\nin the edge servers. However, this does not exempt it from\npotential exploits.\n1) Data remnants and secure deletion. Even though data is\nencrypted and safely stored on a disk or removed from\nthe server, parts of it may remain in memory from the\nprocessing stage if the memory address has not been\noverwritten. An adversary can target and recover such\ndata remnants via cold boot attacks [90].\n2) Data backup and recovery.\nSince edge servers can\npossess suf\ufb01cient resources to perform relatively inten-\nsive computation on collected data, data may not be\nforwarded to the cloud until the task is done. If stored\ndata is corrupted before being processed and forwarded\nto the cloud server, it can cause severe data loss and\nservice interruption within the network. This poses an\nincentive for attackers to target edge servers and inject\nransomware [141], [142] in exchange for \ufb01le decryption\nkeys.\nData security. Cloud providers may implement weak security\npractices or have no data protection provisions. Often data are\nprocessed or stored in clear text, risking exposure in case of\ncompromise (e.g., the case of Accenture [67], [84]).\nData deletion is another critical issue. Research has shown\nthat data persists in memory if not using secure deletion\ntechniques [275]. Also, due to data replications and backups,\nincomplete data deletion processes might not erase the data in\nthe cloud infrastructure completely.\nC. ML Data\nIn edge machine learning (edge-ML) systems, the key char-\nacteristic is that data provision on edge devices and edge/cloud\nservers can be decoupled so that machine learning models can\nbe trained locally with local data (see \u00a7VI). Consequently,\nthe availability and quality of local data are vital for the\nsecurity of the edge machine learning system. Unlike threats,\nvulnerabilities, and exploits that have been analyzed in \u00a7VI\nand \u00a7VIII-B, we discuss security issues of edge-ML data\ncollection and curation procedures.\n1) Data quality. The quality of edge-ML data plays an\nimportant role in training edge-ML models. Many prior\nworks [157], [178] have found that poor data quality\ncan dramatically degrade the performance of edge-ML\nmodels. To undermine edge-ML systems, data quality\nattacks [41], [110] aim to decrease the quality of the\ncollected data from edge devices by various approaches.\nFor example, genetic attacks and probability-weighted\npacket saliency attacks have been found to be used\nto compromise edge intrusion detection systems, where\nattackers inject a large number of low-quality network\npackets through DDoS attacks [110].\n2) Data availability. The local data have to be available for\nlocal training and evaluation to train edge-ML models in\na decentralized way. Data availability attacks [51], [193]\nare the new threats to edge-ML systems, where attackers\ncompromise edge device sensors to impede data collec-\ntion and curation. For example, onboard sensors are used\nin autonomous driving systems to collect location data,\nand attackers can perform electromagnetic pulse attacks\nto damage electronic sensors and make the data unavail-\nable for training autonomous driving models [187].\nIX. PRIVACY\nSince a large amount of sensitive data is uploaded from edge\ndevices to numerous offsite servers, it is essential to ensure that\nuser\u2019s privacy is protected from outside threats.\nA. Privacy Threats\nAs the data is transferred, processed, and stored on the\nserver, it is susceptible to exploits from both an outside\nadversary attacking the system and network and an inside\nadversary snif\ufb01ng information from data on the server. Such\nexploits can include linkability, identi\ufb01ability, exposure, and\npolicy non-compliance.\nB. User Privacy\nWe separate potential vulnerabilities and exploits against\nusers\u2019 privacy into two categories: location privacy and data\nprivacy. The former concentrates on privacy during communi-\ncations between edge device and edge server, while the latter\nconcentrates on data within edge servers.\nLocation privacy. Location privacy includes preventing the\nuser\u2019s location information from tracking and pro\ufb01ling attacks.\n1) Location tracking.\nWhen an edge device (such as\nsmartwatches or other mobile devices) makes a request\nto an edge server, its location information and timestamp\ncan be included as the metadata of the sent message or\nas a direct functionality [244]. An untrusted server or\nnetwork attacker can extract and record location data\nfrom the aforementioned device and map out the user\u2019s\nmovements over time [91].\n2) Location pro\ufb01ling. Besides activity tracking, edge de-\nvice location can also be used to establish a user pro\ufb01le\nand further help narrow down or pinpoint the user\u2019s\nidentity. An attacker can analyze the device\u2019s most-\nfrequent geographic coordinates and infer the user\u2019s\nneighborhood or workplace. Such auxiliary information\n13\ncan then be applied to an anonymized dataset to separate\nentries that belong to the user with high probability.\nData privacy. Data privacy focuses on protecting the user\u2019s\npersonally identi\ufb01able information from attacks such as link-\ning, exposing, and de-anonymizing the of\ufb02oaded data.\n1) Data leakage and exposure.\nAs discussed in section\nVIII-B, user data in edge servers are vulnerable to\nthievery or leaked through various methods. If privacy\npolicies and data anonymization techniques are not in\nplace, the exposed data may iclude the user\u2019s name,\naddress, and contact information, among others.\n2) Data linkability. With an anonymized dataset (e.g. with\nthe k-anonymity model [243]), attackers cannot directly\nidentify users from decrypted data. However, attacks can\nstill be carried out on such datasets [241]. An edge\ndevice may upload the same user\u2019s data to different edge\nservers, resulting in the user\u2019s record existing across\nseveral datasets. An adversary can perform a links attack\nby analyzing the overlapping entries and identifying\nrecords that correspond to the same individual.\n3) Data de-anonymization.\nDue to the increased deploy-\nment of large edge networks in the age of \u201cbig data\u201d,\nthere is an abundance of datasets to cross-reference\nagainst each other. With the help of publicly available\ninformation, datasets stored on edge servers can also be\nde-anonymized via re-identi\ufb01cation attacks. Such attacks\ncan be carried out on privacy-insensitive data [20] or\nprivacy-preserving data analytics [240] that are common\npractices in medical and business \ufb01elds.\nC. Privacy Policies\nCompanies use Privacy policies to disclose how users\u2019\ndata are gathered, used, managed, and disclosed. These legal\ndocuments are usually extremely vague, lengthy, and com-\nplicated to read, which can cause users to skip over them\nand give unaware consent [12], [15]. In the premises of edge\ncomputing, new threats and vulnerabilities emerge as user\ndata is distributed among edge devices and servers in a vast\nnetwork. We brie\ufb02y describe some aspects in which user\nprivacy may be violated in the edge network due to non-\ncompliance and give further explanation and analysis in XI\nLack of enforcement.\nWithout a proper non-compliance\ndetection mechanism on each edge node, a rogue server can\nstore, process, or disclose unauthorized user data or fail to\nanonymize data before transmission.\nPolicy con\ufb02icts.\nEdge devices and servers are deployed\nin countless locations across the globe, where each country\nor organization has its own policy requirements. As data is\ntransmitted across the network, it can move across continents\nand arrive at a destination with policies con\ufb02icting with its\norigin. For example, certain information may be considered\npublicly accessible, or the duration of data storage may have\na longer time frame.\nX. USER AND IDENTITY AND ACCESS MANAGEMENT\nIdentity and Access Management (IAM) ensures that the\nsame identity is managed for all service interactions while\nsimultaneously ensuring security. It is used to authenticate an\nentity and grant or deny accesses to data and other system\nresources.\nUsually, a large-scale system or service does not main-\ntain its own identity store or authentication mechanism to\nauthenticate. IAM makes the identity management simpler\nfor large-scale distributed systems. It mainly deals with iden-\ntifying entities and managing access to resources based on\npre-established policies [216]. Many organizations offer IAM\nsystems, including SailPoint [131], IBM [127], Oracle [133],\nRSA [276], and Core security [3].\nThere are a number of components related to IAM [114],\nincluding 1) identity management and provisioning, 2) authen-\ntication management, 3) federated identity management, and\n4) authorization management. Those components collabora-\ntively ensure that authorized users are securely and effectively\nincorporated into the cloud. We will explore how each of those\nareas might be affected in the setting of edge computing.\n1) Diversity of identity information and APIs in edge com-\nputing.\nIdentity management is highly related to the\nsecurity issues of identity management in edge comput-\ning. Due to the diversity of devices, it is challenging\nto properly collaborate with all different types of inter-\nfaces, including proprietary ones. Competition among\nmajor vendors further poses obstacles for a uniformed\nmanagement system.\n2) Forgeable identity of edge devices. As more devices are\nout in the \ufb01eld and provide more direct public access,\nveri\ufb01cation of submitted identity information becomes\ncritical to correctly enforce further operations of the\nIAM system. For example, preventing identity spoo\ufb01ng\nbecomes much more challenging with edge computing,\nwhere a mechanism to construct unforgeable identity\ncharacteristics is under urgent call. However, unlike\nusers and general-purpose computers that share a more\nsimilar set of identity characteristics (e.g., passwords\nand \ufb01ngerprints for human beings, motherboards and OS\nversions for general-purpose computers), each edge de-\nvice embeds unique identity characteristics depending on\nthe vendor and the hardware, including customized and\nproprietary components. It requires tremendous efforts\nfrom both the manufacturer and the services provider to\nbuild a chain of trust together for edge device identities.\n3) Rogue identity providers in edge computing. Just like the\nthreats from rogue Certi\ufb01cate Authorities (CAs) in PKIs,\nsimilar problems exist in identity providers. Delegating\nthe identity management task to a trusted third party\nalso means that authenticity of the identity and all of\nthe credentials are in others\u2019 hands, and one can only\nhope the provider remains trusted and benign. In the case\nof rogue identity providers, the chain of identity will\ncompletely break under IAM. Such a threat will even\n14\nbe more daunting and in\ufb02uential under edge computing,\nif there is any identity service for edge devices, due to\nthe uncountable volume of entities that will get affected.\n4) Lack of suitable access control models for numerous het-\nerogeneous devices. The access control models designed\nfor general-purpose computers and cloud computing\nfollow a more uniform pattern thanks to the consistency\nof architecture and form factors. However, no general\nmodel would be satisfying in a complex edge computing\ninfrastructure due to the diversi\ufb01ed systems and their\nenabled applications, which calls for a \ufb01ne-grained ac-\ncess control that can handle countless scenarios. Not to\nmention, exhaustively enumerating and making sense of\nall possible threats itself is an open research question.\n5) Loose network access control.\nOften, organizations\nadopt threat models with weak adversarial assumptions.\nFor instance, they may assume that the adversary may\nnot be able to compromise end devices. Therefore,\naccess control is very loosely de\ufb01ned within the net-\nwork while enforcing more access control on network\nperimeters (i.e., \ufb01rewalls). However, this becomes a\nmajor issue once the presumably trusted devices mis-\nbehave. For example, a compromised IoT device may\nstart probing resources on the network or try to spread\nthe infection further in the network. Such an attack\nis feasible since access control is non-existent or very\nloosely de\ufb01ned [204]. In other words, one needs to\nprecisely de\ufb01ne who can access what on the network\nand for what reason [117], [118].\nXI. REGULATORY COMPLIANCE\nThe emergence of edge computing and other data-driven\ntechnologies (IoT, big data, and cloud platform services)\nsparked initiatives to regulate and protect end-user cyber\nrights. A vast amount of data are produced by end-users and\ndevices (e.g., cameras, sensors, and smartwatches) and trans-\nmitted/processed over the edge network. These data include\npersonally identi\ufb01able information, user actions, habits, health\ninformation, etc. In edge computing, these data are transmitted\nto edge devices for fast processing and response, but they\nmight as well be sent further into the network (edge servers,\ncloud). The network nodes could be geographically spread or\neven on different continents. Different privacy regulations may\napply depending on where the data is transmitted, processed,\nand stored. For instance, European countries have adopted\nthe General Data Protection Regulation (GDPR) [78], while\nthe state of California in the United States has enforced\nthe California Consumer Privacy Act (CCPA) [235]. Other\nregulations exist to protect sensitive data, such as healthcare\ndata (HIPAA) [177].\nEdge computing deployments must be compliant with such\nregulations. And given the size and distributed nature of the\ninfrastructure, this could be a challenge. Each edge node in\nthe infrastructure must only receive, process, and maintain the\ndata needed to perform its operations successfully (aka data\nminimization). In addition, data might need to be erased or\nkept for a speci\ufb01c amount of time, depending on the effective\nregulation. Also, data anonymization may need to be applied\nbefore transmitting data from one place to another.\nOne must ensure that the edge infrastructure and operations\ncomply with any enforced regulations. Considering the size\nand the geographical distribution of nodes, this could be very\nchallenging:\n1) Regulation Applicatbility. Administrators need to iden-\ntify regulations that pertain to the type of data processed\nin each edge computing node.\n2) Compliance of technical operations.\nIt requires com-\nparing the regulatory requirements with technical device\noperations. Such operations need to be identi\ufb01ed system-\natically to evaluate the compliance accurately and fairly\nacross the edge network.\n3) Compatibility issues.\nRegulations may pose compati-\nbility problems across the edge network, such as the\nscenario in which two edge devices are in different\ngeographical locations where different laws apply, and\nboth devices have the same purpose. Also, assume that\nthe processing requires access to historical healthcare\ndata. The regulation applying to one of the edge devices\nis GDPR, while the other device is HIPAA. GDPR pro-\ntects the right to be forgotten and disallows the storage\nof historical information. HIPAA does not grant the\nright to be forgotten; hence historical data are available\non the device. This is a simple scenario that raises\ncompatibility issues. Although the edge devices have the\nsame purpose, their underlying functionality changes as\none device has access to historical data while the other\nis not.\nEnsuring compliance on edge is not trivial. Edge network\nadministrators need to be equipped with tools to aid the com-\npliance process or maintain compliance. We need a systematic\napproach for formalizing each device\u2019s functionality on the\nedge network. Then we need to map the functionality to the\nregulatory requirements affecting the different subnetworks of\nthe edge network and pinpoint where the issues are and how\nto \ufb01x them.\nXII. CONCLUSIONS & FUTURE WORK\nIn this paper, we have studied edge computing security from\nmultiple points of view spanning from the hardware, cryptog-\nraphy, and network to machine learning, data, and compliance.\nWe argue that the threats and vulnerabilities emerging from\neach of those stacks can downgrade infrastructure security\nto unimaginable levels. Thus, when dealing with the edge\ninfrastructure security, it is our position that one must take\na holistic approach.\nThe con\ufb01guration and functionality of the edge network,\nthe communication protocols used, and the cloud components\nmust be well-understood and thoroughly examined. Such an\nanalysis will reveal the soft spots in the network, which\nattackers may leverage to penetrate the network. The level\nof criticality related to vulnerabilities introduced by soft spots\n15\nchanges based on factors such as risk, exploitability, and im-\npact. Of course, due to the complexity of real edge networks, a\nholistic analysis cannot be carried out manually. Thus, we plan\nto design and implement a system that will perform a holistic\nsecurity analysis of a given edge network infrastructure.\nREFERENCES\n[1] The 2021 tls telemetry report. Accessed: 2022-05-22.\n[2] Core ml. https://developer.apple.com/documentation/coreml. Accessed:\n2022-05-20.\n[3] Coresecurity iam. https://www.coresecurity.com/products. Accessed:\n2010-09-30.\n[4] Cwe-1240: Use of a cryptographic primitive with a risky implementa-\ntion. https://cwe.mitre.org/data/de\ufb01nitions/1240.html. Accessed: 2022-\n06-13.\n[5] Cwe-369: Divide by zero.\nhttps://cwe.mitre.org/data/de\ufb01nitions/369.\nhtml. Accessed: 2022-05-20.\n[6] Edgex foundry, Feb.\n[7] Intriguing amazon alexa statistics you need to know in 2022. https:\n//safeatlast.co/blog/amazon-alexa-statistics/. Accessed: 2022-05-20.\n[8] Kubeedge, Feb.\n[9] Md5 vulnerable to collision attacks. Accessed: 2022-05-22.\n[10] Pytorch mobile. https://pytorch.org/mobile/home/. Accessed: 2022-05-\n20.\n[11] The gnutls transport layer security library, 2001.\n[12] Why privacy policies are so inscrutable, 2014.\n[13] Cve-2019-5736, 2019.\n[14] Differences between tls 1.2 and tls 1.3 (tls13), 2019.\n[15] Most people just click and accept privacy policies without reading them\n\u2014 you might be surprised at what they allow companies to do, 2019.\n[16] N. Aaraj, A. Raghunathan, and N. K. Jha.\nAnalysis and design of\na hardware/software trusted platform module for embedded systems.\nACM Transactions on Embedded Computing Systems (TECS), 8(1):1\u2013\n31, 2009.\n[17] O. Abdulkader, A. M. Bamhdi, V. Thayananthan, F. Elbouraey, and\nB. Al-Ghamdi.\nA lightweight blockchain based cybersecurity for\niot environments.\nIn 2019 6th IEEE International Conference on\nCyber Security and Cloud Computing (CSCloud)/ 2019 5th IEEE\nInternational Conference on Edge Computing and Scalable Cloud\n(EdgeCom), pages 139\u2013144, 2019.\n[18] S. AbdulRahman, H. Tout, H. Ould-Slimane, A. Mourad, C. Talhi,\nand M. Guizani. A survey on federated learning: The journey from\ncentralized to distributed on-site learning and beyond. IEEE Internet\nof Things Journal, 8(7):5476\u20135497, 2020.\n[19] M. Alam, H. A. Khan, M. Dey, N. Sinha, R. Callan, A. Zajic, and\nM. Prvulovic. One&Done: A Single-Decryption EM-Based attack on\nOpenSSL\u2019s Constant-Time blinded RSA.\nIn 27th USENIX Security\nSymposium (USENIX Security 18), pages 585\u2013602, Baltimore, MD,\nAug. 2018. USENIX Association.\n[20] M. A. U. Alam. Person re-identi\ufb01cation attack on wearable sensing,\n2021.\n[21] I. Ali, S. Sabir, and Z. Ullah. Internet of things security, device authen-\ntication and access control: a review. arXiv preprint arXiv:1901.07309,\n2019.\n[22] L. Alliance. Lorawan\u21221.1 speci\ufb01cation. 2017.\n[23] Z. Alliance. Zigbee document 05-3474-21. Technical Report 05-3474-\n21, 2021.\n[24] M. Almeida, S. Laskaridis, A. Mehrotra, L. Dudziak, I. Leontiadis,\nand N. D. Lane.\nSmart at what cost? characterising mobile deep\nneural networks in the wild. In Proceedings of the 21st ACM Internet\nMeasurement Conference, pages 658\u2013672, 2021.\n[25] M. Alt, W. C. Barto, A. Fasano, and A. King. Entropy poisoning from\nthe hypervisor 6 . 857 \ufb01nal project. 2015.\n[26] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,\nJ. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,\net al.\nUnderstanding the mirai botnet.\nIn 26th USENIX security\nsymposium (USENIX Security 17), pages 1093\u20131110, 2017.\n[27] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,\nJ. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis,\net al.\nUnderstanding the mirai botnet.\nIn 26th USENIX security\nsymposium (USENIX Security 17), pages 1093\u20131110, 2017.\n[28] S. Arvind and V. A. Narayanan.\nAn overview of security in coap:\nattack and analysis. In 2019 5th international conference on advanced\ncomputing & communication systems (ICACCS), pages 655\u2013660. IEEE,\n2019.\n[29] R. Awati and M. Cobb. Certi\ufb01cate revocation list (crl), 2021.\n[30] S. Baek, Y. Jung, D. Mohaisen, S. Lee, and D. Nyang. Ssd-assisted\nransomware detection and data recovery techniques. IEEE Transactions\non Computers, 70(10):1762\u20131776, 2020.\n[31] E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov. How to\nbackdoor federated learning. In International Conference on Arti\ufb01cial\nIntelligence and Statistics, pages 2938\u20132948. PMLR, 2020.\n[32] E. Barker. Digital signature standard (dss), 2013-07-19 2013.\n[33] R. Barry et al. Freertos. Internet, Oct, 2008.\n[34] A. Barth, C. Jackson, and J. C. Mitchell. Robust defenses for cross-\nsite request forgery. In Proceedings of the 15th ACM conference on\nComputer and communications security, pages 75\u201388, 2008.\n[35] G. Baruch, M. Baruch, and Y. Goldberg.\nA little is enough: Cir-\ncumventing defenses for distributed learning.\nAdvances in Neural\nInformation Processing Systems, 32, 2019.\n[36] D. J. Bernstein.\nGrover vs. mceliece.\nIn N. Sendrier, editor,\nPost-Quantum Cryptography, pages 73\u201380, Berlin, Heidelberg, 2010.\nSpringer Berlin Heidelberg.\n[37] M. Bettayeb, Q. Nasir, and M. A. Talib. Firmware update attacks and\nsecurity for iot devices: Survey. In Proceedings of the ArabWIC 6th\nAnnual International Conference Research Track, pages 1\u20136, 2019.\n[38] M. Blanton.\nMessage Authentication Codes, pages 1715\u20131716.\nSpringer US, Boston, MA, 2009.\n[39] J. Blessing, M. A. Specter, and D. J. Weitzner. You really shouldn\u2019t roll\nyour own crypto: An empirical study of vulnerabilities in cryptographic\nlibraries. CoRR, abs/2107.04940, 2021.\n[40] J. Bonneau and I. Mironov. Cache-collision timing attacks against aes.\nIn L. Goubin and M. Matsui, editors, Cryptographic Hardware and\nEmbedded Systems - CHES 2006, pages 201\u2013215, Berlin, Heidelberg,\n2006. Springer Berlin Heidelberg.\n[41] B. Bostami, M. Ahmed, and S. Choudhury. False data injection attacks\nin internet of things. In Performability in internet of things, pages 47\u2013\n58. Springer, 2019.\n[42] I. Bozcan and E. Kayacan. Context-dependent anomaly detection for\nlow altitude traf\ufb01c surveillance. In 2021 IEEE International Conference\non Robotics and Automation (ICRA), pages 224\u2013230. IEEE, 2021.\n[43] F. Brasser, U. M\u00a8uller, A. Dmitrienko, K. Kostiainen, S. Capkun, and\nA.-R. Sadeghi.\nSoftware grand exposure:{SGX} cache attacks are\npractical. In 11th USENIX Workshop on Offensive Technologies (WOOT\n17), 2017.\n[44] J. Burnim, N. Jalbert, C. Stergiou, and K. Sen. Looper: Lightweight\ndetection of in\ufb01nite loops at runtime. In 2009 IEEE/ACM International\nConference on Automated Software Engineering, pages 161\u2013169. IEEE,\n2009.\n[45] G. Camurati, S. Poeplau, M. Muench, T. Hayes, and A. Francillon.\nScreaming channels: When electromagnetic side channels meet radio\ntransceivers. In Proceedings of the 2018 ACM SIGSAC Conference on\nComputer and Communications Security, pages 163\u2013177, 2018.\n[46] M. Canim, A. Kundu, and J. Payne. Uncheatable machine learning\ninference. arXiv preprint arXiv:1908.03270, 2019.\n[47] N. Carlini and D. Wagner. {ROP} is still dangerous: Breaking modern\ndefenses. In 23rd USENIX Security Symposium (USENIX Security 14),\npages 385\u2013399, 2014.\n[48] B. Carminati.\nDigital Signatures, pages 1093\u20131099. Springer New\nYork, New York, NY, 2018.\n[49] D. Cash, P. Grubbs, J. Perry, and T. Ristenpart.\nLeakage-abuse\nattacks against searchable encryption.\nIn Proceedings of the 22nd\nACM SIGSAC Conference on Computer and Communications Security,\nCCS \u201915, page 668\u2013679, New York, NY, USA, 2015. Association for\nComputing Machinery.\n[50] S. Cass. Nvidia makes it easy to embed ai: The jetson nano packs\na lot of machine-learning power into diy projects-[hands on]. IEEE\nSpectrum, 57(7):14\u201316, 2020.\n[51] P. M. Chanal and M. S. Kakkasageri. Security and privacy in iot: a\nsurvey. Wireless Personal Communications, 115(2):1667\u20131693, 2020.\n[52] S. Chandra, Z. Lin, A. Kundu, and L. Khan. Towards a systematic\nstudy of the covert channel attacks in smartphones. In International\nConference on Security and Privacy in Communication Networks,\npages 427\u2013435. Springer, 2014.\n[53] Checkpoint. Main cloud security issues and threats in 2021, 2020.\n16\n[54] B.-C. Choi, S.-H. Lee, J.-C. Na, and J.-H. Lee.\nSecure \ufb01rmware\nvalidation and update for consumer devices in home networking. IEEE\nTransactions on Consumer Electronics, 62(1):39\u201344, 2016.\n[55] P. Choi and D. K. Kim. Design of security enhanced tpm chip against\ninvasive physical attacks. In 2012 IEEE International Symposium on\nCircuits and Systems (ISCAS), pages 1787\u20131790. IEEE, 2012.\n[56] A. Choudhari, S. Guilley, and K. Karray. Cryscanner: Finding cryp-\ntographic libraries misuse. In 2021 8th NAFOSTED Conference on\nInformation and Computer Science (NICS), pages 230\u2013235, 2021.\n[57] C. Cimpanu. The coap protocol is the next big thing for ddos attacks,\nDec. 2018.\n[58] Cisco. Cisco fog director cross-site scripting vulnerability, Feb. 2016.\n[59] T. Cloosters, M. Rodler, and L. Davi.\n{TeeRex}: Discovery and\nexploitation of memory corruption vulnerabilities in {SGX} enclaves.\nIn 29th USENIX Security Symposium (USENIX Security 20), pages\n841\u2013858, 2020.\n[60] D. Coppersmith. The data encryption standard (des) and its strength\nagainst attacks. IBM Journal of Research and Development, 38(3):243\u2013\n250, 1994.\n[61] J. Corina, A. Machiry, C. Salls, Y. Shoshitaishvili, S. Hao, C. Kruegel,\nand G. Vigna. Difuze: Interface aware fuzzing for kernel drivers. In\nProceedings of the 2017 ACM SIGSAC Conference on Computer and\nCommunications Security, pages 2123\u20132138, 2017.\n[62] V. Costan and S. Devadas.\nIntel sgx explained.\nCryptology ePrint\nArchive, 2016.\n[63] M. Crosbie and E. H. Spafford. Defending a computer system using\nautonomous agents. 1995.\n[64] A. Cui, M. Costello, and S. Stolfo.\nWhen \ufb01rmware modi\ufb01cations\nattack: A case study of embedded exploitation. 2013.\n[65] H. Daga, P. K. Nicholson, A. Gavrilovska, and D. Lugones. Cartel: A\nsystem for collaborative transfer learning at the edge. In Proceedings\nof the ACM Symposium on Cloud Computing, pages 25\u201337, 2019.\n[66] R. David, J. Duke, A. Jain, V. Reddi, N. Jeffries, J. Li, N. Kreeger,\nI. Nappier, M. Natraj, S. Regev, et al. Tensor\ufb02ow lite micro: Embedded\nmachine learning on tinyml systems. arxiv 2020.\narXiv preprint\narXiv:2010.08678.\n[67] J. Davis. Accenture latest to breach client data due to miscon\ufb01gured\naws server, May 2017.\n[68] P. Dempsey.\nThe teardown: Apple mac mini.\nEngineering &\nTechnology, 14(1):84\u201385, 2019.\n[69] E. Derr, S. Bugiel, S. Fahl, Y. Acar, and M. Backes. Keep me updated:\nAn empirical study of third-party library updatability on android. In\nProceedings of the 2017 ACM SIGSAC Conference on Computer and\nCommunications Security, pages 2187\u20132200, 2017.\n[70] C. details. 50 products by total number of distinct vulnerabilities, May\n2022.\n[71] T. Dierks and E. Rescorla. The transport layer security (tls) protocol\nversion 1.2. 2008.\n[72] W. Dif\ufb01e and M. Hellman. Special feature exhaustive cryptanalysis of\nthe nbs data encryption standard. Computer, 10(6):74\u201384, 1977.\n[73] S. Ding, J. Cao, C. Li, K. Fan, and H. Li. A novel attribute-based access\ncontrol scheme using blockchain for iot. IEEE Access, 7:38431\u201338441,\n2019.\n[74] O. Duman, M. Ghafouri, M. Kassouf, R. Atallah, L. Wang, and\nM. Debbabi. Modeling supply chain attacks in iec 61850 substations.\nIn 2019 IEEE International Conference on Communications, Control,\nand Computing Technologies for Smart Grids (SmartGridComm), pages\n1\u20136. IEEE, 2019.\n[75] M. Dworkin, E. Barker, J. Nechvatal, J. Foti, L. Bassham, E. Roback,\nand J. Dray. Advanced encryption standard (aes), 2001-11-26 2001.\n[76] S. Ebrahimi, S. Bayat-Sarmadi, and H. Mosanaei-Boorani.\nPost-\nquantum cryptoprocessors optimized for edge and resource-constrained\ndevices in iot. IEEE Internet of Things Journal, 6(3):5500\u20135507, 2019.\n[77] R. A. Efendy, A. Almaarif, A. Budiono, M. Saputra, W. Puspitasari,\nand E. Sutoyo. Exploring the possibility of usb based fork bomb attack\non windows environment. In 2019 International Conference on ICT\nfor Smart Society (ICISS), volume 7, pages 1\u20134. IEEE, 2019.\n[78] EU. General data protection regulation (gdpr), May 2018.\n[79] A. Everspaugh, K. Paterson, T. Ristenpart, and S. Scott.\nKey rota-\ntion for authenticated encryption. Cryptology ePrint Archive, Paper\n2017/527, 2017. https://eprint.iacr.org/2017/527.\n[80] K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao,\nA. Prakash, T. Kohno, and D. Song. Robust physical-world attacks\non deep learning visual classi\ufb01cation.\nIn Proceedings of the IEEE\nconference on computer vision and pattern recognition, pages 1625\u2013\n1634, 2018.\n[81] M. Fang, X. Cao, J. Jia, and N. Gong. Local model poisoning attacks\nto {Byzantine-Robust} federated learning. In 29th USENIX Security\nSymposium (USENIX Security 20), pages 1605\u20131622, 2020.\n[82] T. Fenton and P. Kennedy. The future of esxi on arm. In Running ESXi\non a Raspberry Pi, pages 355\u2013368. Springer, 2022.\n[83] T. M. Fern\u00b4andez-Caram\u00b4es.\nFrom pre-quantum to post-quantum iot\nsecurity: A survey on quantum-resistant cryptosystems for the internet\nof things. IEEE Internet of Things Journal, 7(7):6457\u20136480, 2020.\n[84] FoxNews.\nVerizon data breach: 14 million customers reportedly\nexposed, May 2017.\n[85] D. Gens, S. Schmitt, L. Davi, and A.-R. Sadeghi. K-miner: Uncovering\nmemory corruption in linux. In NDSS, 2018.\n[86] H. M. Gisbert and I. Ripoll. On the effectiveness of nx, ssp, renewssp,\nand aslr against stack buffer over\ufb02ows. In 2014 IEEE 13th International\nSymposium on Network Computing and Applications, pages 145\u2013152.\nIEEE, 2014.\n[87] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,\nS. Ozair, A. Courville, and Y. Bengio.\nGenerative adversarial nets.\nAdvances in neural information processing systems, 27, 2014.\n[88] B. Gras, K. Razavi, H. Bos, and C. Giuffrida. Translation leak-aside\nbuffer: Defeating cache side-channel protections with {TLB} attacks.\nIn 27th USENIX Security Symposium (USENIX Security 18), pages\n955\u2013972, 2018.\n[89] L. K. Grover.\nA fast quantum mechanical algorithm for database\nsearch. In Proceedings of the Twenty-Eighth Annual ACM Symposium\non Theory of Computing, STOC \u201996, page 212\u2013219, New York, NY,\nUSA, 1996. Association for Computing Machinery.\n[90] M. Gruhn and T. M\u00a8uller. On the practicability of cold boot attacks. In\n2013 International Conference on Availability, Reliability and Security,\npages 390\u2013397, 2013.\n[91] M. Gruteser and D. Grunwald. Anonymous usage of location-based\nservices through spatial and temporal cloaking.\nIn Proceedings of\nthe 1st International Conference on Mobile Systems, Applications and\nServices, MobiSys \u201903, page 31\u201342, New York, NY, USA, 2003.\nAssociation for Computing Machinery.\n[92] T. Gu, B. Dolan-Gavitt, and S. Garg. Badnets: Identifying vulnera-\nbilities in the machine learning model supply chain. arXiv preprint\narXiv:1708.06733, 2017.\n[93] Y. Guo, F. Liu, Z. Cai, N. Xiao, and Z. Zhao. Edge-based ef\ufb01cient\nsearch over encrypted data mobile cloud storage. Sensors, 18(4), 2018.\n[94] L. Gwennap.\nQualcomm tips cortex-a57 plans: Snapdragon 810\ncombines eight 64-bit cpus, lte baseband. Microprocessor Report, The\nLinley Group, 2014.\n[95] A. Haas, A. Rossberg, D. L. Schuff, B. L. Titzer, M. Holman,\nD. Gohman, L. Wagner, A. Zakai, and J. Bastien. Bringing the web up\nto speed with webassembly. In Proceedings of the 38th ACM SIGPLAN\nConference on Programming Language Design and Implementation,\npages 185\u2013200, 2017.\n[96] W. G. Halfond, J. Viegas, A. Orso, et al.\nA classi\ufb01cation of sql-\ninjection attacks and countermeasures.\nIn Proceedings of the IEEE\ninternational symposium on secure software engineering, volume 1,\npages 13\u201315. IEEE, 2006.\n[97] J. Han, S. Kim, T. Kim, and D. Han.\nToward scaling hardware\nsecurity module for emerging cloud services. In Proceedings of the\n4th Workshop on System Software for Trusted Execution, pages 1\u20136,\n2019.\n[98] S. Han, W. Shin, J.-H. Park, and H. Kim. A bad dream: Subverting\ntrusted platform module while you are sleeping.\nIn 27th USENIX\nSecurity Symposium (USENIX Security 18), pages 1229\u20131246, 2018.\n[99] M. Hasan and S. Mohan.\nProtecting actuators in safety-critical iot\nsystems from control spoo\ufb01ng attacks.\nIn Proceedings of the 2nd\nInternational ACM Workshop on Security and Privacy for the Internet-\nof-Things, pages 8\u201314, 2019.\n[100] H. Hashemi, Y. Wang, and M. Annavaram. Darknight: An accelerated\nframework for privacy and integrity preserving deep learning using\ntrusted hardware. In MICRO-54: 54th Annual IEEE/ACM International\nSymposium on Microarchitecture, pages 212\u2013224, 2021.\n[101] M. E. Haykin, R. B. Warnar, et al. Smart card technology: new methods\nfor computer access control. 1988.\n[102] X. He, L. Lyu, Q. Xu, and L. Sun.\nModel extraction and ad-\nversarial transferability, your bert is vulnerable!\narXiv preprint\narXiv:2103.10013, 2021.\n17\n[103] W. J. Heinbockel, E. R. Laderman, and G. J. Serrao. Supply chain\nattacks and resiliency mitigations. The MITRE Corporation, 2017.\n[104] N. Heninger, Z. Durumeric, E. Wustrow, and J. A. Halderman. Mining\nyour ps and qs: Detection of widespread weak keys in network devices.\nIn 21st USENIX Security Symposium (USENIX Security 12), pages\n205\u2013220, Bellevue, WA, Aug. 2012. USENIX Association.\n[105] A. Herdrich, E. Verplanke, P. Autee, R. Illikkal, C. Gianos, R. Singhal,\nand R. Iyer. Cache qos: From concept to reality in the intel\u00ae xeon\u00ae\nprocessor e5-2600 v3 product family.\nIn 2016 IEEE International\nSymposium on High Performance Computer Architecture (HPCA),\npages 657\u2013668. IEEE, 2016.\n[106] J.-b. Hou, T. Li, and C. Chang. Research for vulnerability detection of\nembedded system \ufb01rmware. Procedia Computer Science, 107:814\u2013818,\n2017.\n[107] T. Hou, G. Feng, S. Qin, and W. Jiang. Proactive content caching by\nexploiting transfer learning for mobile edge computing. International\nJournal of Communication Systems, 31(11):e3706, 2018.\n[108] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang,\nT. Weyand, M. Andreetto, and H. Adam.\nMobilenets: Ef\ufb01cient\nconvolutional neural networks for mobile vision applications. arXiv\npreprint arXiv:1704.04861, 2017.\n[109] S. Hu, J. Lu, W. Wan, and L. Y. Zhang. Challenges and approaches\nfor mitigating byzantine attacks in federated learning. arXiv preprint\narXiv:2112.14468, 2021.\n[110] W. Huang, X. Peng, Z. Shi, and Y. Ma. Adversarial attack against\nlstm-based ddos intrusion detection system.\nIn 2020 IEEE 32nd\nInternational Conference on Tools with Arti\ufb01cial Intelligence (ICTAI),\npages 686\u2013693. IEEE, 2020.\n[111] IETF. Ampli\ufb01cation attacks using the constrained application protocol\n(coap), Feb. 2022.\n[112] M. Ihde and T. Brown.\nAn experimental study of \ufb01le permission\nvulnerabilities caused by single-bit errors in the selinux kernel policy\n\ufb01le. In UIUC SIGMIL Meeting. Citeseer, 2004.\n[113] S. Inc. The heartbleed bug, 2020.\n[114] I. Indu, P. R. Anand, and V. Bhaskar. Identity and access management\nin cloud environment: Mechanisms and challenges.\nEngineering\nscience and technology, an international journal, 21(4):574\u2013588, 2018.\n[115] H. Jafarzadeh and A. Jahanian. Real vulnerabilities in partial recon-\n\ufb01gurable design cycles; case study for implementation of hardware\nsecurity modules. In 2020 20th International Symposium on Computer\nArchitecture and Digital Systems (CADS), pages 1\u20134. IEEE, 2020.\n[116] M. Jagielski, A. Oprea, B. Biggio, C. Liu, C. Nita-Rotaru, and B. Li.\nManipulating machine learning: Poisoning attacks and countermeasures\nfor regression learning.\nIn 2018 IEEE Symposium on Security and\nPrivacy (SP), pages 19\u201335. IEEE, 2018.\n[117] C. Katsis, F. Cicala, D. Thomsen, N. Ringo, and E. Bertino. Can i reach\nyou? do i need to? new semantics in security policy speci\ufb01cation and\ntesting. In Proceedings of the 26th ACM Symposium on Access Control\nModels and Technologies, pages 165\u2013174, 2021.\n[118] C. Katsis, F. Cicala, D. Thomsen, N. Ringo, and E. Bertino. Neutron:\nA graph-based pipeline for zero-trust network architectures. In Pro-\nceedings of the Twelveth ACM Conference on Data and Application\nSecurity and Privacy, pages 167\u2013178, 2022.\n[119] A. S. Khader and D. Lai. Preventing man-in-the-middle attack in dif\ufb01e-\nhellman key exchange protocol. In 2015 22nd International Conference\non Telecommunications (ICT), pages 204\u2013208, 2015.\n[120] A. Khalid, S. McCarthy, M. O\u2019Neill, and W. Liu.\nLattice-based\ncryptography for iot in a quantum world: Are we ready? In 2019 IEEE\n8th International Workshop on Advances in Sensors and Interfaces\n(IWASI), pages 194\u2013199, 2019.\n[121] S. A. Khaliq, U. Ali, and O. Khan.\nTiming-based side-channel\nattack and mitigation on pcie connected distributed embedded systems.\nIn 2021 IEEE High Performance Extreme Computing Conference\n(HPEC), pages 1\u20137. IEEE, 2021.\n[122] Y. Kim, R. Daly, J. Kim, C. Fallin, J. H. Lee, D. Lee, C. Wilkerson,\nK. Lai, and O. Mutlu. Flipping bits in memory without accessing them:\nAn experimental study of dram disturbance errors. ACM SIGARCH\nComputer Architecture News, 42(3):361\u2013372, 2014.\n[123] S. L. Kinney. Trusted platform module basics: using TPM in embedded\nsystems. Elsevier, 2006.\n[124] G. Klein. A formally veri\ufb01ed os kernel. now what? In International\nConference on Interactive Theorem Proving, pages 1\u20137. Springer, 2010.\n[125] G. Klein, J. Andronick, M. Fernandez, I. Kuz, T. Murray, and G. Heiser.\nFormally veri\ufb01ed software in the real world. Communications of the\nACM, 61(10):68\u201377, 2018.\n[126] P. Kocher, J. Horn, A. Fogh, D. Genkin, D. Gruss, W. Haas, M. Ham-\nburg, M. Lipp, S. Mangard, T. Prescher, et al.\nSpectre attacks:\nExploiting speculative execution. In 2019 IEEE Symposium on Security\nand Privacy (SP), pages 1\u201319. IEEE, 2019.\n[127] A. Kochut, Y. Deng, M. R. Head, J. Munson, A. Sailer, H. Shaikh,\nC. Tang, A. Amies, M. Beaton, D. Geiss, et al. Evolution of the ibm\ncloud: Enabling an enterprise cloud services ecosystem. IBM Journal\nof Research and Development, 55(6):7\u20131, 2011.\n[128] C. Kolias, G. Kambourakis, A. Stavrou, and J. Voas. Ddos in the iot:\nMirai and other botnets. Computer, 50(7):80\u201384, 2017.\n[129] W. M. Koolen, A. Malek, and P. L. Bartlett.\nEf\ufb01cient minimax\nstrategies for square loss games.\nAdvances in Neural Information\nProcessing Systems, 27, 2014.\n[130] N. Koroniotis, N. Moustafa, E. Sitnikova, and B. Turnbull. Towards\nthe development of realistic botnet dataset in the internet of things\nfor network forensic analytics: Bot-iot dataset.\nFuture Generation\nComputer Systems, 100:779\u2013796, 2019.\n[131] D. Kumar and B. Kalra. A review for the risk, threat and mitigation\nof unauthorized access of accounts.\n[132] D. Kumar, R. Paccagnella, P. Murley, E. Hennenfent, J. Mason,\nA. Bates, and M. Bailey. Skill squatting attacks on amazon alexa. In\n27th USENIX security symposium (USENIX Security 18), pages 33\u201347,\n2018.\n[133] Y. R. Kumar, N. Basha, K. K. KM, B. M. Sharma, and K. Kerekovski.\nOracle High Availability, Disaster Recovery, and Cloud Services:\nExplore RAC, Data Guard, and Cloud Technology. Springer, 2019.\n[134] A. Kundu, Z. Lin, and J. Hammond. Energy attacks on mobile devices.\nIn 2020 Second IEEE International Conference on Trust, Privacy and\nSecurity in Intelligent Systems and Applications (TPS-ISA), pages 107\u2013\n117. IEEE, 2020.\n[135] H. Lasi, P. Fettke, H.-G. Kemper, T. Feld, and M. Hoffmann. Industry\n4.0. Business & information systems engineering, 6(4):239\u2013242, 2014.\n[136] D. Lazar, H. Chen, X. Wang, and N. Zeldovich. Why does crypto-\ngraphic software fail? a case study and open problems. In Proceedings\nof 5th Asia-Paci\ufb01c Workshop on Systems, APSys \u201914, New York, NY,\nUSA, 2014. Association for Computing Machinery.\n[137] S. Leavy. Gender bias in arti\ufb01cial intelligence: The need for diversity\nand gender theory in machine learning.\nIn Proceedings of the 1st\ninternational workshop on gender equality in software engineering,\npages 14\u201316, 2018.\n[138] D. Lee, D. Kohlbrenner, S. Shinde, K. Asanovi\u00b4c, and D. Song.\nKeystone: An open framework for architecting trusted execution en-\nvironments. In Proceedings of the Fifteenth European Conference on\nComputer Systems, pages 1\u201316, 2020.\n[139] M. Lee and J. Park. Analysis and study on invasion threat and security\nmeasures for smart home services in iot environment. The Journal of\nthe Institute of Internet, Broadcasting and Communication, 16(5):27\u2013\n32, 2016.\n[140] D. Lehmann, J. Kinder, and M. Pradel.\nEverything old is new\nagain: Binary security of {WebAssembly}. In 29th USENIX Security\nSymposium (USENIX Security 20), pages 217\u2013234, 2020.\n[141] I.-S. Lei, T. Su-Kit, I.-K. Chao, and R. Tse.\nSelf-recovery service\nsecuring edge server in iot network against ransomware attack. pages\n399\u2013404, 01 2020.\n[142] I.-S. Lei, S.-K. Tang, and R. Tse. Integrating consortium blockchain\ninto edge server to defense against ransomware attack. Procedia Com-\nputer Science, 177:120\u2013127, 2020. The 11th International Conference\non Emerging Ubiquitous Systems and Pervasive Networks (EUSPN\n2020) / The 10th International Conference on Current and Future\nTrends of Information and Communication Technologies in Healthcare\n(ICTH 2020) / Af\ufb01liated Workshops.\n[143] K. Leino and M. Fredrikson.\nStolen memories: Leveraging model\nmemorization for calibrated {White-Box} membership inference. In\n29th USENIX Security Symposium (USENIX Security 20), pages 1605\u2013\n1622, 2020.\n[144] A. K. Lenstra. Key lengths contribution to the handbook of information\nsecurity. 2010.\n[145] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith. Federated learning:\nChallenges, methods, and future directions. IEEE Signal Processing\nMagazine, 37(3):50\u201360, 2020.\n18\n[146] Y. Li, B. Wu, Y. Jiang, Z. Li, and S.-T. Xia. Backdoor learning: A\nsurvey. arXiv preprint arXiv:2007.08745, 2020.\n[147] Z. Li, J. Li, Y. Zhang, J. Zhou, and Z. Guo.\nPorting rt-thread to\nannikasoc.\nIn 2021 IEEE 15th International Conference on Anti-\ncounterfeiting, Security, and Identi\ufb01cation (ASID), pages 177\u2013181.\nIEEE, 2021.\n[148] Z. Li, H. Yu, T. Zhou, L. Luo, M. Fan, Z. Xu, and G. Sun. Byzantine\nresistant secure blockchained federated learning at the edge.\nIEEE\nNetwork, 35(4):295\u2013301, 2021.\n[149] J. Lin, W.-M. Chen, Y. Lin, C. Gan, S. Han, et al. Mcunet: Tiny deep\nlearning on iot devices. Advances in Neural Information Processing\nSystems, 33:11711\u201311722, 2020.\n[150] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, A. Fogh,\nJ. Horn, S. Mangard, P. Kocher, D. Genkin, et al. Meltdown: Reading\nkernel memory from user space. In 27th USENIX Security Symposium\n(USENIX Security 18), pages 973\u2013990, 2018.\n[151] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee. Last-level cache\nside-channel attacks are practical. In 2015 IEEE symposium on security\nand privacy, pages 605\u2013622. IEEE, 2015.\n[152] Q. Liu, P. Li, W. Zhao, W. Cai, S. Yu, and V. C. Leung. A survey on\nsecurity threats and defensive techniques of machine learning: A data\ndriven view. IEEE access, 6:12103\u201312117, 2018.\n[153] Z. Liu, K.-K. R. Choo, and J. Grossschadl. Securing edge devices in\nthe post-quantum internet of things using lattice-based cryptography.\nIEEE Communications Magazine, 56(2):158\u2013162, 2018.\n[154] M. Loi and M. Christen. How to include ethics in machine learning\nresearch. Ercim News, 116(3), 2019.\n[155] J. Longo, E. D. Mulder, D. Page, and M. Tunstall.\nSoc it to em:\nelectromagnetic side-channel attacks on a complex system-on-chip. In\nInternational Workshop on Cryptographic Hardware and Embedded\nSystems, pages 620\u2013640. Springer, 2015.\n[156] Z. Luo, S. Zhao, Z. Lu, Y. E. Sagduyu, and J. Xu. Adversarial machine\nlearning based partial-model attack in iot. In Proceedings of the 2nd\nACM Workshop on Wireless Security and Machine Learning, pages\n13\u201318, 2020.\n[157] M. S. Mahdavinejad, M. Rezvan, M. Barekatain, P. Adibi, P. Barnaghi,\nand A. P. Sheth. Machine learning for internet of things data analysis:\nA survey. Digital Communications and Networks, 4(3):161\u2013175, 2018.\n[158] T. Mandt, M. Solnik, and D. Wang. Demystifying the secure enclave\nprocessor. Black Hat Las Vegas, 2016.\n[159] H. Mansor, K. Markantonakis, R. N. Akram, and K. Mayes. Don\u2019t brick\nyour car: Firmware con\ufb01dentiality and rollback for vehicles. In 2015\n10th International Conference on Availability, Reliability and Security,\npages 139\u2013148. IEEE, 2015.\n[160] S. Marechal. Advances in password cracking. Journal in computer\nvirology, 4(1):73\u201381, 2008.\n[161] M. Mazzillo, G. Condorelli, D. San\ufb01lippo, G. Valvo, B. Carbone,\nG. Fallica, S. Billotta, M. Belluso, G. Bonanno, L. Cosentino, et al.\nSilicon photomultiplier technology at stmicroelectronics. IEEE Trans-\nactions on Nuclear Science, 56(4):2434\u20132442, 2009.\n[162] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan.\nA survey on bias and fairness in machine learning. ACM Computing\nSurveys (CSUR), 54(6):1\u201335, 2021.\n[163] A. N. Mencias, D. Dillenberger, P. Novotny, F. Toth, T. E. Morris,\nV. Paprotski, J. Dayka, T. Visegrady, B. O\u2019Farrell, J. Lang, et al.\nAn optimized blockchain solution for the ibm z14. IBM Journal of\nResearch and Development, 62(2/3):4\u20131, 2018.\n[164] P. Mendki. Evaluating webassembly enabled serverless approach for\nedge computing. In 2020 IEEE Cloud Summit, pages 161\u2013166. IEEE,\n2020.\n[165] M. Merenda, C. Porcaro, and D. Iero. Edge machine learning for ai-\nenabled iot devices: A review. Sensors, 20(9):2533, 2020.\n[166] D. Micciancio and M. Walter. On the bit security of cryptographic\nprimitives.\nIn J. B. Nielsen and V. Rijmen, editors, Advances in\nCryptology \u2013 EUROCRYPT 2018, pages 3\u201328, Cham, 2018. Springer\nInternational Publishing.\n[167] D. Miessler. Passwords directory, Mar. 2017.\n[168] MITRE. Cve-2013-4134, 2013.\n[169] F. Mo, H. Haddadi, K. Katevas, E. Marin, D. Perino, and N. Kourtellis.\nPp\ufb02: privacy-preserving federated learning with trusted execution envi-\nronments. In Proceedings of the 19th Annual International Conference\non Mobile Systems, Applications, and Services, pages 94\u2013108, 2021.\n[170] F. Mo, A. S. Shamsabadi, K. Katevas, S. Demetriou, I. Leontiadis,\nA. Cavallaro, and H. Haddadi. Darknetz: towards model privacy at\nthe edge using trusted execution environments. In Proceedings of the\n18th International Conference on Mobile Systems, Applications, and\nServices, pages 161\u2013174, 2020.\n[171] A. Moghimi, G. Irazoqui, and T. Eisenbarth. Cachezoom: How sgx\nampli\ufb01es the power of cache attacks.\nIn International Conference\non Cryptographic Hardware and Embedded Systems, pages 69\u201390.\nSpringer, 2017.\n[172] B. M\u00a8oller, T. Duong, and K. Kotowicz. This poodle bites: exploiting\nthe ssl 3.0 fallback. Security Advisory, 21:34\u201358, 2014.\n[173] V. Mothukuri, R. M. Parizi, S. Pouriyeh, Y. Huang, A. Dehghantanha,\nand G. Srivastava.\nA survey on security and privacy of federated\nlearning. Future Generation Computer Systems, 115:619\u2013640, 2021.\n[174] O. Nakhila, A. Attiah, Y. Jin, and C. Zou. Parallel active dictionary\nattack on wpa2-psk wi-\ufb01networks.\nIn MILCOM 2015-2015 IEEE\nMilitary Communications Conference, pages 665\u2013670. IEEE, 2015.\n[175] M. Nasr, R. Shokri, and A. Houmansadr.\nMachine learning with\nmembership privacy using adversarial regularization. In Proceedings of\nthe 2018 ACM SIGSAC conference on computer and communications\nsecurity, pages 634\u2013646, 2018.\n[176] M. Nieke, L. Almstedt, and R. Kapitza. Edgedancer: Secure mobile\nwebassembly services on the edge. In Proceedings of the 4th Inter-\nnational Workshop on Edge Systems, Analytics and Networking, pages\n13\u201318, 2021.\n[177] U. D. of Health and H. S. (HHS). Health insurance portability and\naccountability act of 1996 (hipaa), May 1996.\n[178] N. U. Okafor, Y. Alghorani, and D. T. Delaney. Improving data quality\nof low-cost iot sensors in environmental monitoring networks using\ndata fusion and machine learning approach. ICT Express, 6(3):220\u2013\n228, 2020.\n[179] O. Oleksenko, D. Kuvaiskii, P. Bhatotia, P. Felber, and C. Fetzer. Intel\nmpx explained: A cross-layer analysis of the intel mpx system stack.\nProceedings of the ACM on Measurement and Analysis of Computing\nSystems, 2(2):1\u201330, 2018.\n[180] T. Omitola and G. Wills. Towards mapping the security challenges of\nthe internet of things (iot) supply chain. Procedia Computer Science,\n126:441\u2013450, 2018.\n[181] OWASP. Owasp api security project, May 2018.\n[182] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and\nA. Swami. Practical black-box attacks against machine learning. In\nProceedings of the 2017 ACM on Asia conference on computer and\ncommunications security, pages 506\u2013519, 2017.\n[183] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and\nA. Swami. The limitations of deep learning in adversarial settings. In\n2016 IEEE European symposium on security and privacy (EuroS&P),\npages 372\u2013387. IEEE, 2016.\n[184] A. Park, K.-A. Shim, N. Koo, and D.-G. Han. Side-channel attacks\non post-quantum signature schemes based on multivariate quadratic\nequations: - rainbow and uov -. IACR Transactions on Cryptographic\nHardware and Embedded Systems, 2018(3):500\u2013523, Aug. 2018.\n[185] S. Park, S. Lee, W. Xu, H. Moon, and T. Kim.\nlibmpk: Software\nabstraction for intel memory protection keys (intel {MPK}). In 2019\nUSENIX Annual Technical Conference (USENIX ATC 19), pages 241\u2013\n254, 2019.\n[186] G. C. Pereira, C. Puodzius, and P. S. Barreto.\nShorter hash-based\nsignatures. Journal of Systems and Software, 116:95\u2013100, 2016.\n[187] J. Petit and S. E. Shladover.\nPotential cyberattacks on automated\nvehicles.\nIEEE Transactions on Intelligent transportation systems,\n16(2):546\u2013556, 2014.\n[188] S. Pinto and N. Santos. Demystifying arm trustzone: A comprehensive\nsurvey. ACM Computing Surveys (CSUR), 51(6):1\u201336, 2019.\n[189] D. Pokorn\u00b4y, P. Socha, and M. Novotn\u00b4y. Side-channel attack on rainbow\npost-quantum signature. In 2021 Design, Automation Test in Europe\nConference Exhibition (DATE), pages 565\u2013568, 2021.\n[190] J. Postel and J. Reynolds. Rfc0959: File transfer protocol, 1985.\n[191] V. Pournaghshband, M. Sarrafzadeh, and P. Reiher. Securing legacy\nmobile medical devices.\nIn International Conference on Wireless\nMobile Communication and Healthcare, pages 163\u2013172. Springer,\n2012.\n[192] Progress. Openedge, Feb.\n[193] W. B. Qaim and O. Ozkasap. Draw: Data replication for enhanced\ndata availability in iot-based sensor systems.\nIn 2018 IEEE 16th\nIntl Conf on Dependable, Autonomic and Secure Computing, 16th\nIntl Conf on Pervasive Intelligence and Computing, 4th Intl Conf\non Big Data Intelligence and Computing and Cyber Science and\n19\nTechnology Congress (DASC/PiCom/DataCom/CyberSciTech), pages\n770\u2013775. IEEE, 2018.\n[194] S. Quanjiang, S. Yan, Y. Xiaohu, L. Tinghui, H. Daojing, and\nY. Guisong. Large scale \ufb01rmware analysis for open source components,\nhard coding and weak passwords. In 2021 IEEE International Confer-\nence on Consumer Electronics and Computer Engineering (ICCECE),\npages 232\u2013236. IEEE, 2021.\n[195] R. Rajwar and M. Dixon. Intel transactional synchronization exten-\nsions. In Intel Developer Forum San Francisco, volume 2012, 2012.\n[196] M. Randolph and W. Diehl.\nPower side-channel attack analysis: A\nreview of 20 years of study for the layman. Cryptography, 4(2):15,\n2020.\n[197] E. Rescorla. The Transport Layer Security (TLS) Protocol Version 1.3.\nRFC 8446, Aug. 2018.\n[198] E. Rescorla et al. Http over tls, 2000.\n[199] M. Ribeiro, K. Grolinger, and M. A. Capretz. Mlaas: Machine learning\nas a service. In 2015 IEEE 14th International Conference on Machine\nLearning and Applications (ICMLA), pages 896\u2013902. IEEE, 2015.\n[200] T. Ristenpart and S. Yilek. When good randomness goes bad: Virtual\nmachine reset vulnerabilities and hedging deployed cryptography. In\nNDSS, 2010.\n[201] R. L. Rivest, A. Shamir, and L. Adleman. A method for obtaining\ndigital signatures and public-key cryptosystems.\nCommun. ACM,\n21(2):120\u2013126, feb 1978.\n[202] N. Rodr\u00b4\u0131guez-Barroso, D. J. L\u00b4opez, M. Luz\u00b4on, F. Herrera, and\nE. Mart\u00b4\u0131nez-C\u00b4amara. Survey on federated learning threats: concepts,\ntaxonomy on attacks and defences, experimental study and challenges.\narXiv preprint arXiv:2201.08135, 2022.\n[203] R. J. Rodr\u00b4\u0131guez.\nEvolution and characterization of point-of-sale\nram scraping malware. Journal of Computer Virology and Hacking\nTechniques, 13(3):179\u2013192, 2017.\n[204] E. Ronen, A. Shamir, A.-O. Weingarten, and C. O\u2019Flynn. Iot goes\nnuclear: Creating a zigbee chain reaction. In 2017 IEEE Symposium\non Security and Privacy (SP), pages 195\u2013212. IEEE, 2017.\n[205] C. L. Rothwell. Exploitation from malicious PCI Express peripherals.\nPhD thesis, University of Cambridge, 2018.\n[206] S. H. Russ. Circuit-board attacks and security. Signal Integrity, pages\n199\u2013213, 2022.\n[207] M. Sabt, M. Achemlal, and A. Bouabdallah.\nTrusted execution\nenvironment: what it is, and what it is not.\nIn 2015 IEEE Trust-\ncom/BigDataSE/ISPA, volume 1, pages 57\u201364. IEEE, 2015.\n[208] F. Schellenberg, D. R. Gnad, A. Moradi, and M. B. Tahoori. Remote\ninter-chip power analysis side-channel attacks at board-level.\nIn\n2018 IEEE/ACM International Conference on Computer-Aided Design\n(ICCAD), pages 1\u20137. IEEE, 2018.\n[209] T. Seals. Remote attackers can now reach protected network devices\nvia nat slipstreaming, Jan. 2021.\n[210] M. Security.\nMicrosoft services unaffected by openssl \u201cheartbleed\u201d\nvulnerability, 2014.\n[211] G. C. K. M. Services. Key rotation.\n[212] S. Sesia, I. Tou\ufb01k, and M. Baker. LTE-the UMTS long term evolution:\nfrom theory to practice. John Wiley & Sons, 2011.\n[213] A. SEV-SNP. Strengthening vm isolation with integrity protection and\nmore. White Paper, January, 2020.\n[214] A. Shafahi, W. R. Huang, M. Najibi, O. Suciu, C. Studer, T. Dumitras,\nand T. Goldstein. Poison frogs! targeted clean-label poisoning attacks\non neural networks.\nAdvances in neural information processing\nsystems, 31, 2018.\n[215] M. Sha\ufb01einejad, N. Lukas, J. Wang, X. Li, and F. Kerschbaum. On the\nrobustness of backdoor-based watermarking in deep neural networks.\nIn Proceedings of the 2021 ACM Workshop on Information Hiding and\nMultimedia Security, pages 177\u2013188, 2021.\n[216] D. H. Sharma, C. Dhote, and M. M. Potey.\nIdentity and access\nmanagement as security-as-a-service from clouds. Procedia Computer\nScience, 79:170\u2013174, 2016.\n[217] V. Shejwalkar and A. Houmansadr. Manipulating the byzantine: Op-\ntimizing model poisoning attacks and defenses for federated learning.\nIn NDSS, 2021.\n[218] Z. Shelby, K. Hartke, and C. Bormann. The constrained application\nprotocol (coap). 2014.\n[219] Y. Shi, K. Davaslioglu, and Y. E. Sagduyu.\nGenerative adversarial\nnetwork for wireless signal spoo\ufb01ng.\nIn Proceedings of the ACM\nWorkshop on Wireless Security and Machine Learning, pages 55\u201360,\n2019.\n[220] Y. Shi, K. Davaslioglu, and Y. E. Sagduyu.\nGenerative adversarial\nnetwork in the air: Deep adversarial learning for wireless signal spoof-\ning. IEEE Transactions on Cognitive Communications and Networking,\n7(1):294\u2013303, 2020.\n[221] Y. Shi and Y. E. Sagduyu.\nEvasion and causative attacks with\nadversarial deep learning.\nIn MILCOM 2017-2017 IEEE Military\nCommunications Conference (MILCOM), pages 243\u2013248. IEEE, 2017.\n[222] Y. Shi, Y. E. Sagduyu, K. Davaslioglu, and R. Levy.\nVulnerability\ndetection and analysis in adversarial deep learning.\nIn Guide to\nVulnerability Analysis for Computer Networks and Systems, pages 211\u2013\n234. Springer, 2018.\n[223] M.-W. Shih, S. Lee, T. Kim, and M. Peinado.\nT-sgx: Eradicating\ncontrolled-channel attacks against enclave programs. In NDSS, 2017.\n[224] P. Shor. Algorithms for quantum computation: discrete logarithms and\nfactoring. In Proceedings 35th Annual Symposium on Foundations of\nComputer Science, pages 124\u2013134, 1994.\n[225] V. Singh.\nA practical key exchange for the internet using lattice\ncryptography.\nCryptology ePrint Archive, Paper 2015/138, 2015.\nhttps://eprint.iacr.org/2015/138.\n[226] S. Skorobogatov. Local heating attacks on \ufb02ash memory devices. In\n2009 IEEE International Workshop on Hardware-Oriented Security\nand Trust, pages 1\u20136. IEEE, 2009.\n[227] S. Skorobogatov. Optical fault masking attacks. In 2010 Workshop on\nFault Diagnosis and Tolerance in Cryptography, pages 23\u201329. IEEE,\n2010.\n[228] S. Smalley, C. Vance, and W. Salamon. Implementing selinux as a\nlinux security module. NAI Labs Report, 1(43):139, 2001.\n[229] J. So, B. G\u00a8uler, and A. S. Avestimehr. Byzantine-resilient secure fed-\nerated learning. IEEE Journal on Selected Areas in Communications,\n39(7):2168\u20132181, 2020.\n[230] L. Song, R. Shokri, and P. Mittal. Privacy risks of securing machine\nlearning models against adversarial examples. In Proceedings of the\n2019 ACM SIGSAC Conference on Computer and Communications\nSecurity, pages 241\u2013257, 2019.\n[231] Sophos. Anatomy of a goto fail \u2013 apple\u2019s ssl bug explained, plus an\nunof\ufb01cial patch for os x!, Feb. 2014.\n[232] O. Standard. Mqtt version 5.0. Retrieved June, 22:2020, 2019.\n[233] J. A. Stankovic. Real-time and embedded systems. ACM Computing\nSurveys (CSUR), 28(1):205\u2013208, 1996.\n[234] J. A. Stankovic and R. Rajkumar. Real-time operating systems. Real-\nTime Systems, 28(2-3):237\u2013253, 2004.\n[235] D. o. J. State of California. California consumer privacy act (ccpa),\nMay 2018.\n[236] Statista.\nInternet of things (iot) connected devices installed base\nworldwide from 2015 to 2025, Nov. 2016.\n[237] M.\nStevens.\nFast\ncollision\nattack\non\nmd5,\n2006.\nm.m.j.stevens@student.tue.nl 13224 received 17 Mar 2006.\n[238] Q. Sti\u00b4evenart, C. De Roover, and M. Ghafari. Security risks of porting\nc programs to webassembly. In Proceedings of the 37th ACM/SIGAPP\nSymposium on Applied Computing, pages 1713\u20131722, 2022.\n[239] A. Stubble\ufb01eld, J. Ioannidis, A. D. Rubin, et al. Using the \ufb02uhrer,\nmantin, and shamir attack to break wep. In NDSS, 2002.\n[240] D. Su, H. T. Huynh, Z. Chen, Y. Lu, and W. Lu. Re-identi\ufb01cation\nattack to privacy-preserving data analysis with noisy sample-mean. In\nProceedings of the 26th ACM SIGKDD International Conference on\nKnowledge Discovery & Data Mining, KDD \u201920, page 1045\u20131053,\nNew York, NY, USA, 2020. Association for Computing Machinery.\n[241] Y. Sun, L. Yin, L. Liu, and S. Xin.\nToward inference attacks for\nk-anonymity. Personal and Ubiquitous Computing, 18(8):1871\u20131880,\n2014.\n[242] Z. Sun, R. Sun, L. Lu, and A. Mislove.\nMind your weight (s): A\nlarge-scale study on insuf\ufb01cient machine learning model protection in\nmobile apps. In 30th USENIX Security Symposium (USENIX Security\n21), pages 1955\u20131972, 2021.\n[243] L. Sweeney.\nK-anonymity: A model for protecting privacy.\nInt. J.\nUncertain. Fuzziness Knowl.-Based Syst., 10(5):557\u2013570, oct 2002.\n[244] T. Taleb, S. Dutta, A. Ksentini, M. Iqbal, and H. Flinck. Mobile edge\ncomputing potential in making cities smarter. IEEE Communications\nMagazine, 55(3):38\u201343, 2017.\n[245] M. Taneja. An analytics framework to detect compromised iot devices\nusing mobility behavior.\nIn 2013 International Conference on ICT\nConvergence (ICTC), pages 38\u201343. IEEE, 2013.\n20\n[246] R. Tang, M. Du, N. Liu, F. Yang, and X. Hu. An embarrassingly simple\napproach for trojan attack in deep neural networks. In Proceedings\nof the 26th ACM SIGKDD International Conference on Knowledge\nDiscovery and Data Mining, pages 218\u2013228, 2020.\n[247] A. Tatar, R. K. Konoth, E. Athanasopoulos, C. Giuffrida, H. Bos, and\nK. Razavi. Throwhammer: Rowhammer attacks over the network and\ndefenses.\nIn 2018 USENIX Annual Technical Conference (USENIX\nATC 18), pages 213\u2013226, 2018.\n[248] M. Tischer, Z. Durumeric, S. Foster, S. Duan, A. Mori, E. Bursztein,\nand M. Bailey. Users really do plug in usb drives they \ufb01nd. In 2016\nIEEE Symposium on Security and Privacy (SP), pages 306\u2013319. IEEE,\n2016.\n[249] V. Tolpegin, S. Truex, M. E. Gursoy, and L. Liu.\nData poisoning\nattacks against federated learning systems. In European Symposium on\nResearch in Computer Security, pages 480\u2013501. Springer, 2020.\n[250] L. Torrey and J. Shavlik. Transfer learning. In Handbook of research\non machine learning applications and trends: algorithms, methods, and\ntechniques, pages 242\u2013264. IGI global, 2010.\n[251] F. Tram`er, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart. Stealing\nmachine learning models via prediction {APIs}.\nIn 25th USENIX\nsecurity symposium (USENIX Security 16), pages 601\u2013618, 2016.\n[252] B. Ur, F. Noma, J. Bees, S. M. Segreti, R. Shay, L. Bauer, N. Christin,\nand L. F. Cranor. \u201d i added\u2019!\u2019at the end to make it secure\u201d: Observing\npassword creation in the lab.\nIn Eleventh Symposium On Usable\nPrivacy and Security (SOUPS 2015), pages 123\u2013140, 2015.\n[253] S. Vinoski.\nAdvanced message queuing protocol.\nIEEE Internet\nComputing, 10(6):87\u201389, 2006.\n[254] R. Walton. Balancing the insider and outsider threat. Computer fraud\n& security, 2006(11):8\u201311, 2006.\n[255] P. Wang, B. Chen, T. Xiang, and Z. Wang.\nLattice-based public\nkey searchable encryption with \ufb01ne-grained access control for edge\ncomputing. Future Generation Computer Systems, 127:373\u2013383, 2022.\n[256] S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and\nK. Chan.\nAdaptive federated learning in resource constrained edge\ncomputing systems. IEEE Journal on Selected Areas in Communica-\ntions, 37(6):1205\u20131221, 2019.\n[257] W. Wang, F. Cicala, S. R. Hussain, E. Bertino, and N. Li. Analyzing the\nattack landscape of zigbee-enabled iot systems and reinstating users\u2019\nprivacy. In Proceedings of the 13th ACM Conference on Security and\nPrivacy in Wireless and Mobile Networks, pages 133\u2013143, 2020.\n[258] Y. Wang, W.-L. Chao, D. Garg, B. Hariharan, M. Campbell, and K. Q.\nWeinberger. Pseudo-lidar from visual depth estimation: Bridging the\ngap in 3d object detection for autonomous driving. In Proceedings of\nthe IEEE/CVF Conference on Computer Vision and Pattern Recogni-\ntion, pages 8445\u20138453, 2019.\n[259] G. Wassermann and Z. Su.\nStatic detection of cross-site scripting\nvulnerabilities. In 2008 ACM/IEEE 30th International Conference on\nSoftware Engineering, pages 171\u2013180. IEEE, 2008.\n[260] E. Wen and G. Weber.\nWasmachine: Bring iot up to speed with a\nwebassembly os. In 2020 IEEE International Conference on Pervasive\nComputing and Communications Workshops (PerCom Workshops),\npages 1\u20134. IEEE, 2020.\n[261] R. Wojtczuk and J. Rutkowska.\nAttacking intel trusted execution\ntechnology. Black Hat DC, 2009:1\u20136, 2009.\n[262] X. Wu, M. Fredrikson, S. Jha, and J. F. Naughton. A methodology\nfor formalizing model-inversion attacks. In 2016 IEEE 29th Computer\nSecurity Foundations Symposium (CSF), pages 355\u2013370. IEEE, 2016.\n[263] C. Xiao, B. Li, J.-Y. Zhu, W. He, M. Liu, and D. Song.\nGenerat-\ning adversarial examples with adversarial networks.\narXiv preprint\narXiv:1801.02610, 2018.\n[264] Y. Xiao, Y. Jia, C. Liu, X. Cheng, J. Yu, and W. Lv. Edge computing\nsecurity: State of the art and challenges. Proceedings of the IEEE,\n107(8):1608\u20131631, 2019.\n[265] Y. Xiao, Y. Jia, C. Liu, X. Cheng, J. Yu, and W. Lv. Edge computing\nsecurity: State of the art and challenges. Proceedings of the IEEE,\n107(8):1608\u20131631, 2019.\n[266] H. Xiong, Y. Zhao, L. Peng, H. Zhang, and K.-H. Yeh. Partially policy-\nhidden attribute-based broadcast encryption with secure delegation in\nedge computing. Future Generation Computer Systems, 97:453\u2013461,\n2019.\n[267] Y. Xiong, Y. Sun, L. Xing, and Y. Huang. Extend cloud to edge with\nkubeedge. In 2018 IEEE/ACM Symposium on Edge Computing (SEC),\npages 373\u2013377. IEEE, 2018.\n[268] J. Xu, P. Ning, C. Kil, Y. Zhai, and C. Bookholt. Automatic diagnosis\nand response to memory corruption vulnerabilities. In Proceedings of\nthe 12th ACM conference on Computer and communications security,\npages 223\u2013234, 2005.\n[269] M. Xu, J. Liu, Y. Liu, F. X. Lin, Y. Liu, and X. Liu. A \ufb01rst look at deep\nlearning apps on smartphones. In The World Wide Web Conference,\npages 2125\u20132136, 2019.\n[270] Y. Xu, W. Cui, and M. Peinado. Controlled-channel attacks: Deter-\nministic side channels for untrusted operating systems. In 2015 IEEE\nSymposium on Security and Privacy, pages 640\u2013656. IEEE, 2015.\n[271] J. Yang, A. Cui, S. Stolfo, and S. Sethumadhavan. Concurrency attacks.\nIn 4th USENIX Workshop on Hot Topics in Parallelism (HotPar 12),\n2012.\n[272] K. Yang, D. Forte, and M. M. Tehranipoor. Protecting endpoint devices\nin iot supply chain. In 2015 IEEE/ACM International Conference on\nComputer-Aided Design (ICCAD), pages 351\u2013356. IEEE, 2015.\n[273] Z. Yang, J. He, Y. Tian, and J. Zhou.\nFaster authenticated key\nagreement with perfect forward secrecy for industrial internet-of-things.\nIEEE Transactions on Industrial Informatics, 16(10):6584\u20136596, 2020.\n[274] Y. Yarom and K. Falkner. {FLUSH+ RELOAD}: A high resolution,\nlow noise, l3 cache {Side-Channel} attack. In 23rd USENIX security\nsymposium (USENIX security 14), pages 719\u2013732, 2014.\n[275] S. F. Yitbarek, M. T. Aga, R. Das, and T. Austin. Cold boot attacks\nare still hot: Security analysis of memory scramblers in modern pro-\ncessors. In 2017 IEEE International Symposium on High Performance\nComputer Architecture (HPCA), pages 313\u2013324. IEEE, 2017.\n[276] S. H. Yoon, K. S. Lee, J. S. Cha, T. Khudaybergenov, M. S. Kim,\nD. G. Woo, and J. U. Kim. Building control box attached monitor\nbased color grid recognition methods for user access authentication.\nInternational Journal of Internet, Broadcasting and Communication,\n12(2):1\u20137, 2020.\n[277] X. Yuan, P. He, Q. Zhu, and X. Li. Adversarial examples: Attacks and\ndefenses for deep learning. IEEE transactions on neural networks and\nlearning systems, 30(9):2805\u20132824, 2019.\n[278] Q. Zhang, Z. Sura, A. Kundu, G. Su, A. Iyengar, and L. Liu.\nStackvault: Protection from untrusted functions. In 2020 Second IEEE\nInternational Conference on Trust, Privacy and Security in Intelligent\nSystems and Applications (TPS-ISA), pages 294\u2013306, Los Alamitos,\nCA, USA, oct 2020. IEEE Computer Society.\n[279] C. W. Zhao, J. Jegatheesan, and S. C. Loon. Exploring iot application\nusing raspberry pi. International Journal of Computer Networks and\nApplications, 2(1):27\u201334, 2015.\n[280] X. Zhou, Y. Lee, N. Zhang, M. Naveed, and X. Wang. The peril of frag-\nmentation: Security hazards in android device driver customizations. In\n2014 IEEE Symposium on Security and Privacy, pages 409\u2013423. IEEE,\n2014.\n21\n"
}