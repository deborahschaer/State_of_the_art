{
    "id": "2311.12785",
    "title": "Prompting Frameworks for Large Language Models: A Survey",
    "abstract": "Since the launch of ChatGPT, a powerful AI Chatbot developed by OpenAI, large\nlanguage models (LLMs) have made significant advancements in both academia and\nindustry, bringing about a fundamental engineering paradigm shift in many\nareas. While LLMs are powerful, it is also crucial to best use their power\nwhere \"prompt'' plays a core role. However, the booming LLMs themselves,\nincluding excellent APIs like ChatGPT, have several inherent limitations: 1)\ntemporal lag of training data, and 2) the lack of physical capabilities to\nperform external actions. Recently, we have observed the trend of utilizing\nprompt-based tools to better utilize the power of LLMs for downstream tasks,\nbut a lack of systematic literature and standardized terminology, partly due to\nthe rapid evolution of this field. Therefore, in this work, we survey related\nprompting tools and promote the concept of the \"Prompting Framework\" (PF), i.e.\nthe framework for managing, simplifying, and facilitating interaction with\nlarge language models. We define the lifecycle of the PF as a hierarchical\nstructure, from bottom to top, namely: Data Level, Base Level, Execute Level,\nand Service Level. We also systematically depict the overall landscape of the\nemerging PF field and discuss potential future research and challenges. To\ncontinuously track the developments in this area, we maintain a repository at\nhttps://github.com/lxx0628/Prompting-Framework-Survey, which can be a useful\nresource sharing platform for both academic and industry in this field.",
    "date": "2023-11-21T18:51:03+00:00",
    "fulltext": "Prompting Frameworks for Large Language Models: A Survey\nXIAOXIA LIU, Zhejiang University, China\nJINGYI WANG, Zhejiang University, China\nJUN SUN, Singapore Management University, Singapore\nXIAOHAN YUAN, Zhejiang University, China\nGUOLIANG DONG, Singapore Management University, Singapore\nPENG DI, Ant Group, China\nWENHAI WANG, Zhejiang University, China\nDONGXIA WANG*, Zhejiang University, China\nSince the launch of ChatGPT, a powerful AI Chatbot developed by OpenAI, large language models (LLMs) have made significant\nadvancements in both academia and industry, bringing about a fundamental engineering paradigm shift in many areas. While\nLLMs are powerful, it is also crucial to best use their power where \u201cprompt\u201d plays a core role. However, the booming LLMs\nthemselves, including excellent APIs like ChatGPT, have several inherent limitations: 1) temporal lag of training data, and 2)\nthe lack of physical capabilities to perform external actions. Recently, we have observed the trend of utilizing prompt-based\ntools to better utilize the power of LLMs for downstream tasks, but a lack of systematic literature and standardized terminology,\npartly due to the rapid evolution of this field. Therefore, in this work, we survey related prompting tools and promote the\nconcept of the \u201cPrompting Framework\" (PF), i.e. the framework for managing, simplifying, and facilitating interaction with\nlarge language models. We define the lifecycle of the PF as a hierarchical structure, from bottom to top, namely: Data Level,\nBase Level, Execute Level, and Service Level. We also systematically depict the overall landscape of the emerging PF field\nand discuss potential future research and challenges. To continuously track the developments in this area, we maintain a\nrepository at https://github.com/lxx0628/Prompting-Framework-Survey, which can be a useful resource sharing platform for\nboth academic and industry in this field.\nCCS Concepts: \u2022 Computing methodologies \u2192Natural language processing; \u2022 Software and its engineering \u2192\nDevelopment frameworks and environments.\nAdditional Key Words and Phrases: Large language models, prompting\n1\nINTRODUCTION\nSince the release of ChatGPT 1, which attracted widespread social attention, research on large language models\n(LLMs) has been in full swing in both academia and industry, resulting in a number of amazing products such as\nPaLM [27], GPT-4 [82], and LLaMA [108, 109]. These LLMs have been shown to exhibit remarkable capabilities\n1https://openai.com/blog/chatgpt/\n*Corresponding author.\nAuthors\u2019 addresses: Xiaoxia Liu, Zhejiang University, China, liuxiaoxia@zju.edu.cn; Jingyi Wang, Zhejiang University, China, wangjyee@zju.\nedu.cn; Jun Sun, Singapore Management University, Singapore, junsun@smu.edu.sg; Xiaohan Yuan, Zhejiang University, China, 22332075@zju.\nedu.cn; Guoliang Dong, Singapore Management University, Singapore, gldong@smu.edu.sg; Peng Di, Ant Group, China, dipeng.dp@antgroup.\ncom; Wenhai Wang, Zhejiang University, China, zdzzlab@zju.edu.cn; Dongxia Wang*, Zhejiang University, China, dxwang@zju.edu.cn.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that\ncopies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first\npage. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy\notherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from\npermissions@acm.org.\n\u00a9 2023 ACM.\nACM 0360-0300/2023/11-ART\nhttps://doi.org/XXXXXXX.XXXXXXX\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\narXiv:2311.12785v1  [cs.SE]  21 Nov 2023\n2\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\nin approaching or even exceeding human-level performance in dialogue, text translation, and sentiment analysis\n[2, 11, 25, 54], etc, potentially bringing in fundamental changes of many fields [18, 30, 38, 61, 65, 76, 123, 137].\nThe development of language models to the current flourishing state has undergone a series of evolutionary\nprocesses: fully supervised learning \u2192deep learning for NLP \u2192\u201cPre-train, Fine-tune\" \u2192\u201cPre-train, Prompt, Predict\"\n[60, 135]. Initially, language models (LMs) applied a fully supervised learning paradigm, where task-specific models\nwere trained solely on the target task dataset, heavily relying on feature engineering [53, 80, 98]. Subsequently,\nwith the rise of deep learning, neural networks for NLP emerged, enabling the integration of feature learning and\nmodel training, i.e., a network architecture designed to automatically learn data features [7, 8, 29, 72]. Later, as\nthe demand for LMs increased and to accommodate the growing number of NLP tasks, the \u201cPre-train, Fine-tune\"\nparadigm was introduced. In this paradigm, a model with a fixed architecture undergoes pre-training to predict\nthe probability of observed text data. Additional parameters are then introduced, and the model is fine-tuned\nusing task-specific objective functions to adapt the pre-trained LM to various downstream tasks [55, 100, 111, 128].\nThen came the era of LLMs, where the trend shifted towards downstream tasks actively adapting to pre-trained\nmodels. The paradigm of \u201cPre-train, Prompt, Predict\" became mainstream and prompts successfully empowering\nthe LLMs to effortlessly tackle a wide range of complex and diverse tasks. By providing a suitable set of prompts,\na single language model trained entirely on context-based predictions can be employed to address various tasks\n[13, 95]. Therefore, the quality and appropriateness of prompts are increasingly playing a crucial role in task\nresolution [51, 120, 136]. Both the academic and industrial communities have shown growing attention and\ninterest in research related to prompts.\nNumerous studies have demonstrated the necessity of employing appropriate methods to unleash the potential\nof LLMs [116, 120, 129, 136]. In March 2023, OpenAI officially unveiled a significant innovation known as\nChatGPT plugins, which enable ChatGPT to utilize external tools, reflecting a clear response to the growing\ndemand for enhancing LLMs\u2019 interaction capabilities with the external world. When analogized to humans, LLMs\ncan be regarded as the intelligent system\u2019s brain, responsible for perceiving instructions and generating and\ncontrolling a series of actions. Therefore, by combining their inherent knowledge and capabilities with external\ntools such as search engines, computational utilities, visual models, and more, LLMs can perform a wide array of\nreal-world tasks, including real-time data retrieval, browser-based information retrieval, database access, precise\nmathematical calculations, complex language generation, and image analysis, thus showcasing their potential\nacross diverse domains like education, healthcare, social media, finance, and natural sciences [64, 68, 78, 93].\nConsequently, the development of tools that facilitate the optimization and streamlining of the interaction process\nbecomes crucial. In this paper, we collectively refer to these forward-looking tools as a proposed novel concept:\n\u201cPrompting Framework\" (PF).\nIn general, Prompting Framework is the upper layer which enables LLMs to interact with the external world. A\nprompting framework manages, simplifies, and facilitates such interactions, helping LLMs overcome fundamental\nchallenges like data lag or \u201cbrain in a vet\u201d. Moreover, prompting frameworks also serve as the basic infrastructure\nof recently emerging autonomous agents based on LLMs, such as AutoGPT [103], HuggingGPT [122], and\nMetaGPT [46].\nSince the release of the open-source project LangChain [20] by Harrison Chase in October 2022, it has garnered\nattention from over 60,000 supporters on GitHub and stands as one of the most popular prompting frameworks to\ndate. LangChain is a framework for building applications with LLMs through composability. Besides LangChain,\nour investigation encompasses various kinds of state-of-the-art prompting frameworks, including 1) Semantic\nKernel [112], LlamaIndex [59], and OpenDAN [83], which can be arguably considered as the operating systems\nfor LLMs, as well as 2) output restrictors for LLMs such as Guidance [69], TypeChat [70], NeMo-Guardrails [79],\nand 3) language for interacting with LLMs, such as LMQL [10], gpt-jargon [14], SudoLang [40]. When referring\nto prompting frameworks, a notable challenge arises due to the rapid pace of development in the domain, making\nit difficult to track and stay informed about the multitude of methods dispersed across GitHub, preprint papers,\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n3\nTwitter, and top conferences/journals. Furthermore, the abundance of prompting framework approaches with\nvarying focuses makes it challenging to systematically categorize and compare them, hindering the selection\nof the most suitable product for specific needs. Therefore, there is currently a lack of but an urgent need of\nsystematic literature and standardized terminology for introducing and comparing these tools that are essential\nfor better using LLMs\u2019 capabilities.\nIn this survey, we introduce the concept of \u2018Prompting Framework\u2019, and provide a comprehensive and systematic\nsurvey of existing prompting frameworks. We present categorization, comparative analysis, and evaluation criteria\nfor them, assess their applicability and limitations, and provide practical recommendations for their effective\nutilization for real-world LLM-enabled tasks. Additionally, we discuss some useful toolkits related to prompts\nthat fall beyond the scope of Prompting Frameworks. We also present recommendations for future research. In a\nnutshell, we make the following main contributions:\n\u2022 We introduce the concept of Prompting Frameworks that garnered attention in both academia and industry,\nand provided systematic and standardized definitions and terminology.\n\u2022 We categorize the existing Prompting Frameworks into 3 classes, conduct a comprehensive comparison of\ntheir strengths and limitations across various dimensions, and provide practical recommendations. Based\non the research findings, we present the future directions of the Prompting Framework and extensively\nexplore its potential development and challenges in more domains.\n\u2022 We conduct extensive research beyond the scope of prompting frameworks, including works and tools\nrelated to LLMs\u2019 prompts and task execution of prompting frameworks. We put them together in our\nGitHub repository to facilitate researchers\u2019 access and exploration for further studies.\nThe rest of the article is structured as follows. Section 2 presents background knowledge of the Prompting\nFramework, including the characteristics of LLMs and the necessity of the Propmpting Framework. Section 3\ndescribes the investigation, including the methodologies and results. Section 4 provides the systematic definitions\nand taxonomy of Prompting Frameworks. Section 6 presents the comparison and challenges across various\ndimensions of various Prompting Frameworks. Section 5 reviews prompt-based work outside the scope of the\nPrompting Framework but related to LLMs. Section 7 presents the future directions of the Prompting Framework\nand the potential developments and challenges in more domains.\n2\nBACKGROUND\nIn this section, we present the background of the Prompting Framework, including the reasons behind its\nemergence and the pertinent terminologies. We aim to address the following aspects: 1) elucidating the concept\nof LLMs by tracing their development history, and 2) explicating the current capability limitations of LLMs to\nunderscore the necessity for the Prompting Framework.\n2.1\nTrends in Language Model: from LMs to \ud835\udc3f\ud835\udc3f\ud835\udc40\ud835\udc60\nEarly language models were predictive models based on Markov assumptions using statistical learning methods,\nalso known as Statistical language models (SLM) [50, 52, 80, 106]. However, due to the limitations imposed by the\nfully supervised learning approach, the curse of dimensionality was inevitably a challenge. With the rise of deep\nlearning, researchers turned to neural networks to enhance LM\u2019s capabilities, leading to the emergence of Neural\nLanguage Models (NLMs) [71, 73]. NLMs aims to establish a universal neural network framework for various\nnatural language processing (NLP) tasks. Subsequently, the introduction and popularity of the Transformer\narchitecture and self-attention mechanism [111] gave rise to a series of task-agnostic pre-trained models, such\nas BERT and GPT, called Pre-trained language models (PLM), which promoted the emergence of the \u201cpre-train,\nfine-tune\" paradigm [60]. PLMs have exhibited remarkable performance improvements across a wide range of\nNLP tasks [33, 55, 63, 94].\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n4\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\nFig. 1. The timeline of representative prompting frameworks.\nTo further explore the performance of LMs, researchers have continuously increased the scale of model\nparameters, the trend has shifted towards downstream tasks actively adapting to pre-trained models. The paradigm\nof \u201cPre-train, Prompt, Predict\" became mainstream [60]. Prompts are an important medium for interaction with\nLanguage Models, usually in text form. In this process, the augmented models not only exhibit better performance\non various NLP tasks but also demonstrate remarkable \u201cemergent abilities\" [119], which were previously unseen\nin smaller PLMs with similar architectures. For instance, ChatGPT can mimic human language style and logical\nreasoning and also demonstrates outstanding contextual comprehension, which was absent in previous models\nlike GPT-2. Based on this new capability distinction, researchers refer to these emerging PLMs with hundreds of\nbillions of parameters as Large Language Models (LLMs) [47, 51, 120], such as ChatGPT, and GPT-4 [82]. With\nthis advancement, language models have completed the leap from LMs to LLMs and inspiring new prospects for\nartificial general intelligence (AGI).\n2.2\nLLMs still \u201cBrains in a Vat\": Limitations and Mitigation\nAnalogous to humans, LLMs can be perceived as the brains of artificial intelligence systems, responsible for\nperceiving instructional information and generating and controlling actions. Although there has been evidence\nof \u201cEmergent Abilities\" [74, 117, 119, 126] in LLMs, which refers to the abilities that emerge in large-scale models\nbut have not been observed in smaller models and can be primarily categorized into four aspects: in-context\nlearning[36, 75, 115, 121], reasoning for complex content [56, 120, 136], instruction following [28, 85, 88, 116],\nand creative capacity [16, 37, 133, 134].\nHowever, the capacity limitations of LLMs cannot be ignored. Firstly, LLMs suffer from temporal lag in their\ntraining data, such as ChatGPT\u2019s latest training data being limited to September 2021 (at the time of paper writing).\nLLMs are unable to access real-time information and trends, and they may struggle to accurately comprehend\nspecific terminology or domain-specific knowledge, occasionally leading to incomplete or erroneous responses,\neven illusions [17, 19, 25, 32, 41, 57, 113]. Additionally, LLMs are bound by strict limitations on the number of\ntokens they can process during interactions, severely restricting the amount of contextual information they can\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n5\ntake in and process [9, 15, 127, 131]. Secondly, LLMs are incapable of direct interaction with external expert\nmodels, such as utilizing search engines, querying databases, and invoking external tools, or APIs, which limits\ntheir usability [68, 93, 135]. Furthermore, the majority of LLMs are offered as paid APIs, potentially imposing\nfinancial burdens on individuals, organizations, and projects with limited resources when dealing with large-scale\nor frequent requests [23, 84].\nBased on the above challenges, it is thus desirable to overcome these barriers by bridging the gap between\nLLMs and external applications. The adoption of Prompting Frameworks, such as Langchain and semantic kernel,\nbecomes imperative [22, 76]. These frameworks not only enable LLMs to stay constantly exposed to emerging\ninformation but also enable the processing of long texts and documents, and facilitate seamless integration with\nexternal applications.\n3\nSURVEY OVERVIEW\nIn this section, we provide a comprehensive description of our survey process. The domains of LLMs and associated\ntechnologies are currently undergoing an unprecedented phase of rapid development. As a consequence, the\nlandscape of relevant research and achievements is characterized by its dispersed nature. Many contributions\nhave yet to be formally published in traditional academic journals or conferences. Instead, they are often\nfound on platforms like arXiv or as open-source toolkits available on GitHub. Some noteworthy developments\nexist primarily within online communities on platforms such as Twitter, GitHub, and Discord, lacking formal\ndocumentation. Furthermore, there is a notable absence of comprehensive review literature in the field, resulting\nin a scarcity of established academic terminology and official definitions.\nOur exploration of prompting frameworks begins with an in-depth examination of LangChain, recognized as one\nof the most influential frameworks in this domain. We start by delving into LangChain\u2019s official description, which\nemphasizes the concept of \u201cBuilding applications with Large Language Models (LLMs) through composability.\"\nThis primary phase of our research seeks to establish a foundational understanding of the terminology and\nconcepts central to these frameworks. We scrutinize and analyze terms such as \u201cframeworks,\" \u201ctools,\" \u201cAgent,\"\n\u201cLarge Model,\" \u201cprompt,\" and \u201ctoolkits.\" These keywords are thoughtfully selected to ensure an encompassing\nperspective, allowing us to include a wide range of relevant materials and resources.\nIn our pursuit of a comprehensive examination, we conduct multiple rounds of keyword searches across diverse\nplatforms. This includes exhaustive searches on prominent repositories like GitHub and scholarly databases\nsuch as arXiv. Additionally, we extend our exploration to encompass reputable conferences and journals within\nthe fields of artificial intelligence (AI) and natural language processing (NLP). These additional searches ensure\nthat we are not only capturing the latest developments but also accessing academic and research-oriented\nmaterials of significance. Throughout this research process, our focus is to identify, collect, and analyze relevant\nmaterials. In total, we amass substantial works comprising 49 open-source projects available on GitHub and a\nsignificant number of academic papers. This methodical approach and rigorous examination of resources form the\ncornerstone of our research into prompting frameworks, facilitating a thorough and well-rounded exploration.\nSubsequently, our investigation delves into a meticulous and systematic assessment of the 49 works under\nscrutiny. This comprehensive evaluation begins with an exhaustive review of their technical documentation,\nwherein we scrutinize the minutiae of each work\u2019s conceptual underpinnings, functional implementations, and\ncrucial code segments. We embark on an in-depth exploration, configuring and pragmatically employing these\ntools to conduct a scientific and methodical analysis, evaluating their performance, efficiency, and applicability.\nIn detail, we conduct extensive testing and research, which involve running all the test cases provided in the\ntechnical documentation and manually creating numerous more detailed test cases that better reflect real-world\nrequirements. Following the fundamental procedures of software testing, we begin with unit testing of each\nindividual module within the framework. Subsequently, we proceed to performance testing of modules assembled\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n6\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\naccording to requirements and standards in complex applications, thus accomplishing integration testing. Finally,\nwe conduct comprehensive system testing to validate and evaluate the capabilities claimed in these tasks, while\nalso organizing aspects related to user experience.\nFinally, this multi-faceted examination enables us to identify the merits and limitations of each work, providing\nus with a nuanced understanding of their capabilities and relevance to the overarching objectives of our survey.\nFollowing this rigorous assessment, we judiciously select approximately 30 works that not only conform to the\nconceptual prerequisites of the prompting framework but also stand out in the field. These selected works are\nchosen to be included in our survey to ensure a comprehensive and representative illustration of the burgeoning\nand dynamically evolving landscape of the prompting framework, which significantly shapes interactions between\nindividuals and LLMs.\nImage\nT\next\nVideo\nSpeech\nDocument\nAzure\nHugging Face\nClaude\nPaLM\nMeta\nEducation\nLegal\nAdvertising \nand Marketing\nFinance\nScientific \nResearch\nNews and Media\nHealthcare\nOpenAI\nRaw Output\nConversation\nQuestion\nTask\nCreative\nExpert Model\nDatabase\nMathematical \nTools\nDocument Managers\nSearch Engines\nSocial Media\nMultimodal \nProcess Tools\nOthers\nAgent\nMechanical \nEquipment\n...\n...\n...\n...\n...\n...\nRetail and \nE-commerce\nVehicle\nData \nLevel\nBase\nLevel\nExecute\nLevel\nService\nLevel\nPrompting \nFramework\nData Loading\nData Process /\nData to Prompt\nAccess and Configuration\nCoordinate Data \nTransfer\nCoordinate and Respond \nto Configuration and \nInvocation based on \nSpecific Real-world \nTasks\nTask Scheduling\nExtend the Functionality \nof Different General \nIn More Domain-Targeted \nManner\nOperational Results or \nIntermediate Data\nControl Flow\nData Flow\nData Propagation Iteratively\nInter-layer \nCommunication\nIntra-layer \nScheduling\nFig. 2. The workflow for facilitating interactions between LLMs and external entities using the Prompting Framework.\n4\nSTATE-OF-THE-ART PROMPTING FRAMEWORK\nIn Sec.2, we analyze the current constraints and limitations of LLMs in practical applications. Despite these\nlimitations, LLMs exhibit remarkable emergence abilities. By combining LLMs with the Prompting Framework,\nthe limitations of LLMs can be mitigated to some extent, enabling the realization of more astonishing capabilities.\nTherefore, in this section, we provide a systematic and comprehensive definition and description of the Prompting\nFramework, which is crucial to break down the application barriers of LLMs and empowers them as critical tools\nin real-world scenarios. We also classify the state-of-the-art Prompting Frameworks to provide a systematic\nreview of various approaches.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n7\n4.1\nConceptualization\nPrompt typically serves as a crucial medium for interacting with LLMs, taking the form of textual content. A\nFramework is a general and extensible infrastructure that provides a structured approach and a set of guidelines.\nConsequently, we provide the following definition of the Prompting Framework:\nPrompting Framework (PF) is the framework for managing, simplifying, and facilitating interaction with\nlarge language models, which adheres to four essential properties: modularity, abstraction, extensibility,\nand standardization.\nSpecifically, modularity refers to breaking down the structure of the prompting framework into independent\nmodules for easy code management and reusability; abstraction refers to providing high-level, simplified interfaces\nto hide complex implementation details in the prompting framework\u2019s design; extensibility inclines to allow\nusers to customize and extend framework functionalities as needed, and standardization refers to consistency in\ndevelopment to improve code maintainability and readability.\nWe categorize the workflow for facilitating interactions between LLMs and external entities using the Prompting\nFramework into four hierarchical layers, arranged from bottom to top as Data Level, Base Level, Execute Level, and\nService Level. The Prompting Framework serves as the facilitator for inter-layer communication and intra-layer\nscheduling. It is important to note that the interactions between different levels are non-linear. In the course of a\nsingle task execution, data may iteratively propagate between various layers to accomplish intricate operations.\nThe following is a detailed exposition of these four levels and the role played by the prompting framework within\nthem:\n4.1.1\nData Level. The Data Level is typically the foundational layer, serving as the most direct interface with the\nexternal environment. The Data Level primarily handles tasks such as data transmission and preprocessing, while\nbeing responsible for managing interactions with external data sources, such as databases or file systems. Within\nthis process, the prompting framework plays a pivotal role in achieving a unified approach to dealing with various\ntypes of data, including text, images, videos, structured data, and documents. Simultaneously, the prompting\nframework has the capability to transform raw, unprocessed input into well-crafted prompts tailored to specific\ntasks or requirements, including question-answering, dialogue, and reasoning, facilitating more efficient and\neffective interactions with high-performance models at the Base Level.\n4.1.2\nBase Level. The Base Level operates as a computational hub situated between the data level and the execute\nlevel, serving as the analogical equivalent of the human brain or, in a computer analogy, the CPU. The Base Level\nprimarily takes responsibility for the management of LLMs as the computational and control center, involving\nthe reception and comprehension of instructions, execution of commands, and conducting various computations,\nwhich supports knowledge management and decision-making processes. Throughout this process, the prompting\nframework plays a critical role in coordinating data transfer and task scheduling. Furthermore, the prompting\nframework facilitates user-friendly access and flexible configuration of LLMs and can even autonomously select\nthe most suitable LLMs for specific tasks.\n4.1.3\nExecute Level. The Execute Level constitutes a critical component of the business logic and is responsible for\ninteracting with LLMs to accomplish specific real-world tasks. The Execute Level maintains communication with\nLLMs through the prompting framework collaboratively, and based on this, constructs tasks and takes appropriate\nactions based on the interactive information obtained from the prompting framework, and coordinates and\nresponds to the configuration and invocation of models in alignment with LLMs to achieve the final completion\nof tasks. The Execute Level represents the terminal stage of task execution and primarily consists of three parts.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n8\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\nTable 1. Representative Works of Prompting Frameworks.\nCategory\nSubcategory\nRepresentative Works\nThe Shell of LLMs\n(LLM-SH)\nUniversal LLM-SH\nHaystack [90]\nSemantic Kernel [112]\nLangChain [20]\nGriptape [44]\nPromptFlow [48]\nLLM-chain [105]\nLinGoose [45]\nLLMStack [26]\nOpenDAN [83]\nHyv [107]\nDomain-Specific LLM-SH\nLlamaIndex [59]\nembedchain [104]\nAgentVerse [24]\nSuperAGI [110]\nTxtai [67]\nAutoChain [42]\nTermGPT [101]\nBotpress [12]\nLanguage for Interaction with LLMs\n(LLM-LNG)\nProgramming LLM-LNG\nLQML [10]\nPseudocode LLM-LNG\nPromptLang [99]\nSudoLang [40]\ngpt-jargon [14]\nOutput Restrictors of LLMs\n(LLM-RSTR)\nContent LLM-RSTR\nNeMo-Guardrails [79]\nGuardrails [102]\nStructure LLM-RSTR\nGuidance [69]\nPromptify [86]\nReLLM [97]\nTypeChat [70]\nThe first part involves directly utilizing the Raw Output of LLMs from the Base Level to complete tasks without\nexternal assistance, representing the simplest business workflow. The second part entails selecting and invoking\none or several external specialized models based on the interactive information from the prompting framework\nto handle aspects of task execution beyond the capabilities of LLMs, enabling the achievement of relatively\ncomplex tasks. The third part involves the coordination and integration of LLMs with higher-order models, such\nas interacting with various mechanical models (robotic arms, machines, vehicles, etc.) to realize LLM-based\nembodied intelligence or engaging with different types of agents to create LLM-based intelligent autonomous\nagents, further advancing the progress of Artificial General Intelligence (AGI).\n4.1.4\nService Level. The Service Level resides at the top tier of the entire business workflow and is responsible\nfor facilitating the management, scheduling, and integration of advanced tasks within specific domains, in\ncoordination with the prompting framework. Service Level extends the functionality of different general in a\nmore targeted manner by interacting with the prompting framework, particularly in critical domains such as\neducation, healthcare, e-commerce, law, and finance.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n9\n4.2\nTaxonomy of Prompting Framework\nTaking into consideration the technical features, design objectives, and application scenarios, the current prompt-\ning framework can be broadly covered by three types: The Shell of LLMs (LLM-SH), Language for Interaction with\nLLMs (LLM-LNG), and Output Restrictors of LLMs (LLM-RSTR). In this section, we will elucidate the reasons for\nthis classification and provide a detailed description of the characteristics and distinctions among these various\ntypes of prompting frameworks. The rationale behind designing the prompting framework is to facilitate the\ninteraction between LLMs and the external world, and different types of prompting frameworks manifest this\nenhancement effect from different perspectives. LLM-SH functions are much like a shell or interface layer in\ncomputer systems, emphasizing interaction with LLMs by facilitating their engagement with highly capable third\nparties, thereby enabling stronger interaction between LLMs, users, and external models. LLM-LNG, on the other\nhand, is designed to create a language (programming or pseudo-language) for interaction with LLMs, focusing\non providing users with a more concise and compact interaction channel. LLM-RSTR, meanwhile, achieves\ncontrolled generation by emphasizing interactions with LLMs that are of higher quality and better aligned with\nrequirements. Furthermore, in the practical use of these tools, we have found that these three types of prompting\nframeworks are often compatible with each other. In other words, depending on the requirements, multiple\ndifferent categories of prompting framework can be used in parallel within the same task-solving process.\n4.2.1\nThe Shell of LLMs (LLM-SH). The shell of LLMs (LLM-SH) is a type of prompting framework aimed at\nenhancing the capabilities of LLMs by enabling them to access various external tools and knowledge sources. In\ntraditional terms, a shell is often associated with an operating system, where the operating system\u2019s shell serves\nas a command-line interpreter that receives user input commands, interprets them, and passes them on to the\noperating system for execution, facilitating users in efficiently and comprehensively utilizing the functionality\nof the operating system. In other words, a shell can be viewed as a layer of encapsulation over the kernel,\nbridging the communication gap between commands and applications. Similarly, the design motivation behind\nLLM-SH, as a prompting framework, is to expand the action potential of LLMs. Specifically, with the assistance\nof LLM-SH, LLMs can not only accomplish conventional NLP tasks such as question answering, sentiment\nanalysis, and information retrieval, but also higher-level functions across various domains including natural\nsciences, healthcare, education, finance, computer science, which encompass image processing and analysis,\nobject detection, mathematical computations, database access, utilizing search engines, code comprehension and\ngeneration, social media posting, weather forecasting, and more. The LLM-SH simplifies complex interactions\nbetween LLMs and the external world, with a focus on improving their usability, universality, and scalability.\nLLM-SH also supports customization, allowing configuration and tailoring to specific needs and requirements for\ndifferent application scenarios and specific domains.\nIn Tab. 1, we provide classification and representative works according to categories. It is worth noting that\nwe include many instances of \u201cAgent\", but this paper primarily investigates the Agent framework rather than\nindividual Agents. The distinction lies in the fact that LLMs-based Agents, exemplified by AutoGPT and BabyAGI\n[77], emphasize the formulation of plans based on user-defined goals and the autonomous execution of these plans,\nwhose main contributions lie in task acceptance, comprehension, automated decision-making, and execution\nprocesses. On the other hand, Agent frameworks, exemplified by SuperAGI [110] and AgentVerse [24] in the\ntable, focus on customizing and building, managing, and running Autonomous Agents according to user-specific\nrequirements. In simple terms, LLMs-based Agents are products primarily geared towards usage, whereas Agent\nframeworks serve as auxiliary tools to assist users in assembling and maintaining Agents, with an emphasis on\nconstruction.\nThere are two primary forms within LLM-SH. One is designed to support a wide range of applications and\ndomains and is referred to as Universal LLM-SH. The other is more specialized and focused on a specific domain,\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n10\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\nsuch as Agent building and maintenance, data processing, or chat-bot building, and is known as Domain-Specific\nLLM-SH.\nUniversal LLM-SH is designed with the intention of accommodating a wide range of application scenarios\nand domains, offering extensive functionality and flexibility to meet the diverse needs of users, which typically\npossess higher generality and scalability. Representative works include Haystack, Semantic Kernel, LangChain,\nGriptape [44], PromptFlow [48], LLM-chain [105], LinGoose [45], LLMStack [26], OpenDAN [83], Hyv [107].\nDomain-Specific LLM-SH is specifically designed for particular domains or application scenarios. They are\ntypically finely tuned and optimized for the requirements of that domain, often achieving better performance\nand higher efficiency in completing specific tasks. Representative works include LlamaIndex [59] and Txtai [67],\nwhich are data frameworks designed to assist in building LLM-based applications. For building and managing\nLLM-based autonomous agents, we have AgentVerse [24] and SuperAGI [110], along with AutoChain [42]. In the\ndomain of creating LLM-powered bots, there are embedchain [104] and botpress [12]. Additionally, for giving\nLLMs the capability to plan and execute terminal commands, there is TermGPT [101].\n4.2.2\nLanguage for Interaction with LLMs (LLM-LNG). Language for Interaction with LLMs (LLM-LNG) is\nan innovative type of prompting framework designed to facilitate more concise, direct, and compact interactions\nwith LLMs by introducing a specialized language for programming.\nPrompts serve as crucial intermediaries for interacting with LLMs and are typically presented in the form\nof natural language text. However, the capabilities of pure natural language text are limited and can increase\ncomplexity and cost when dealing with advanced tasks, sometimes even failing to yield accurate outputs. In\ncontrast to purely natural language prompts, languages that integrate both natural language and programming\nlogic are more structured, concise, and compact. They not only enhance reasoning performance but also provide\nbetter support for various prompting methods, such as chain-of-thought reasoning and decision trees. Additionally,\nthey can offer improved support for control flow.\nLLM-LNG comes in two primary forms: Programming LLM-LNG, which involves interactions with LLMs using\nprogramming languages, and Pseudocode LLM-LNG, which interacts with LLMs using a pseudo-code language.\nThe main distinction between the two lies in their nature. Programming LLM-LNG belongs to the domain of\nprogramming languages and adheres to complex syntax rules and structures, which require compliance with\nspecific syntax specifications to ensure program correctness and often require compilation or interpretation\nto transform it into executable code. On the other hand, Pseudocode LLM-LNG provides a simpler and more\nintuitive way of describing algorithms, combining natural language and structured coding with fewer formal\nconstraints. As a result, Programming LLM-LNG, due to the interpretation and compilation process, tends to be\nmore powerful in handling tasks and control flow. However, it also entails a steeper learning curve compared to\nPseudocode LLM-LNG. Each approach has its own advantages.\nProgramming LLM-LNG primarily involves designing a new programmable language for interacting with\nLLMs by simulating the syntax and architecture of existing programming languages. Given the significant overlap\nbetween user interactions with LLMs and the functionality of query languages, combining query language\nand language model prompts is a logical approach. This expansion transforms prompts from pure text-based\nprompts (natural language) to a combination of text prompts and scripts (natural language combined with\nprogramming language), enhancing the intuitiveness of interactions. In compound prompts that blend natural\nlanguage with the programming language, constraints, and control flow are embedded into the instruction parsing\nand output parsing processes of LLMs through structured query languages. This functionality aims to streamline\nthe reasoning process while reducing calls to resource-intensive underlying LLMs. Notable products in this\ncategory include LMQL [10].\nPseudocode LLM-LNG is a more open-ended form that flexibly combines natural language with structured\ncoding, relying on the inherent capabilities of LLMs. Pseudocode is a wonderful method for outlining programs\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n11\ninformally in natural language, without the constraints of specific syntax, which is like sketching out your ideas\nbefore diving into detailed coding. The design of Pseudocode LLM-LNG is driven by the need to unlock the full\npotential of LLMs, which possess strong capabilities but are hindered by inconvenient interactions or inaccurate\nprompts. Therefore, Pseudocode LLM-LNG offers a standardized structure and syntax that is easy to understand\nand interpret. It provides feasibility-verified template use cases or background explanations for communication\nwith LLMs, combining natural language with simple coding conventions. Representative works in this category\ninclude PromptLang [99], SudoLang [40], and gpt-jargon [14].\n4.2.3\nOutput Restrictors of LLMs (LLM-RSTR). Output Restrictors of LLMs (LLM-RSTR) are a type of\nprompting framework designed to enable controlled generation by LLMs. The controlled generation problem\nwith LLMs pertains to how to ensure that the generated text meets specific requirements, constraints, or demands,\nadapting to various application scenarios and professional domains. This involves control over multiple aspects\nsuch as semantic content, output structure, and semantic style. Currently, due to the uncontrolled nature of\nLLMs, the generated natural language text tends to be unstructured. Additionally, generated text may contain\npotential risks like bias, misinformation, or inappropriate content. LLMs also struggle with off-topic responses and\nmaintaining consistency with predefined requirements. However, the application of LLM-RSTR can effectively\nalleviate these issues. LLM-RSTR primarily focuses on controlled generation from two perspectives: Content\nControl, referred to as Content LLM-RSTR, and Structure Control, referred to as Structure LLM-RSTR.\nContent LLM-RSTR focuses on achieving controlled generation by LLMs in three main aspects: privacy\nprotection, security, and alignment with the topic and accuracy. As for privacy protection, Content LLM-RSTR\nensures that user-provided personal or sensitive information is not leaked or misused. Security control aims\nto filter out unsafe, or dangerous content such as societal and cultural biases about gender, race, politics, and\ninappropriate or offensive content, and also prevents the generation of false or misleading information, thereby\nmaintaining the accuracy and credibility of the generated content. The generated text should align with the user\u2019s\nor application\u2019s topic or requirements to ensure the generated content is useful. Additionally, text generation\nneeds to maintain high accuracy, especially in specific domain applications such as medicine, law, or science.\nRepresentative works in this category include NeMo-Guardrails [79] and Guardrails [102].\nStructure LLM-RSTR plays a critical role in information processing, data management, and decision support,\nenabling both computers and humans to better understand and utilize the information, for tasks such as database\nmanagement, search engine optimization, natural language processing (NLP), information extraction, data mining,\nand analysis. Unstructured original output from LLMs is challenging to use in business or other applications.\nTherefore, constraining and specifying the desired output text format is crucial. The most intuitive way to obtain\nstructured text as output from LLMs is to write extensive and cumbersome tutorials and templates to instruct\nLLMs on what format the output should take. However, this is a time-consuming and complex process. The\ndesign of Structure LLM-RSTR aims to address this issue, allowing users to interact with LLMs in a simpler, more\ndirect manner, and obtain structured outputs that are clear, easier to handle, and analyze. Representative works\nin this category include Guidance, Promptify [86], ReLLM [97], and TypeChat [70].\n4.3\nCrucial Component in the Construction of Prompting Framework\nAfter elucidating the concept of the prompting framework and conducting a comparative analysis, in this\nsection, we introduce one of the pivotal concerns within the prompting framework\u2014specifically, the essential\ncomponents required when constructing a prompting framework. Given the rapid development of both LLMs\nand the prompting framework itself, this field has not only given rise to numerous emerging technologies but\nhas also reactivated many traditional techniques.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n12\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\n4.3.1\nVector Database. In the midst of the ongoing AIGC revolution, a particular challenge lies in the capability\nof large-scale storage and querying of unstructured data, such as images, videos, and text. Vector databases\noffer developers the means to handle unstructured data in the form of vector embeddings, which becomes\nespecially crucial for the utilization and expansion of LLMs, for example, tools like OpenAI\u2019s Retrieval plugin\nrely on vector databases to assist users in retrieving relevant document excerpts from the data sources. A vector\ndatabase is a specialized database designed for storing and managing vector data. Vector data refers to data\ncomposed of multiple numerical values, often representing specific features or attributes. Vectorization is the\nprocess of transforming discrete variables, such as images and text, into continuous vector spaces. For example,\ndifferent-sized or content images can be mapped into vectors within the same space, or various lengths of text can\nbe mapped to a common vector space. In this space, adjacent vectors carry semantically similar meanings, and\nthe vector space is commonly referred to as the embedding space, the generated vectors are known as embedding\nvectors or vector embeddings. The primary characteristics of vector databases include efficient storage and\nquerying of large-scale vector data. Typically, they employ queries based on vector similarity, retrieving data\nbased on the similarity between vectors. This querying approach finds applications in various scenarios like\nimage search, music recommendation, and text classification.\nVector databases depend on three key elements: vectorization (encoding), data structure, and distance cal-\nculation. The quality of vectorization determines the upper limit of vector database performance, yet current\nvectorization processes lack universality due to their strong dependence on data types. Properly constructing\ndata structures to manage vectors ensures computational and retrieval efficiency, which determines the lower\nlimit of vector database performance. Reasonable distance calculation between vectors can minimize resource\nconsumption.\nIn recent years, there has been a proliferation of specialized database products. For instance, Milvus[114] is\nconsidered the world\u2019s first true vector database product, with over 1000 enterprise users worldwide, making it\none of the most popular open-source vector databases globally. Pinecone[91], designed for machine learning\napplications, offers speed, scalability, and support for various machine learning algorithms. Pinecone is also a\npartner of OpenAI, and users can generate language embeddings using OpenAI\u2019s Embedding API. Weaviate[34],\na vector database, can store as many as billions of vectors. Additionally, Weaviate has introduced a Plug-in for\nChatGPT, which has received recognition from OpenAI. The main distinction between Weaviate and Pinecone\nlies in how they manage services. Pinecone handles data storage and resource management fully for users,\noften in conjunction with AWS or GCP hosting. In contrast, Weaviate allows users to self-host their data while\nproviding supportive operations and services. For users who value retaining control and not relinquishing their\ndata entirely, Weaviate offers greater flexibility but may come with a relatively higher time cost.\n4.3.2\nCache for LLMs. Fundamentally, every form of computation necessitates storage. Computation and\nstorage represent the two fundamental abstractions, yet they are mutually convertible: storage can be exchanged\nfor computation, and vice versa. Achieving an optimal trade-off is crucial in enhancing the input-output ratio.\nWhether dealing with large-scale or small-scale models, they fundamentally encode global knowledge and\noperational rules, serving as a compression of all human data. However, embedding all data into LLMs is\nchallenging. For instance, some assert that ChatGPT serves as a highly efficient compression encoding, albeit not\nachieving lossless compression, in which the process inevitably introduces entropy reduction and information loss.\nEncoding all information into neural networks results in an excessively bulky model with an enormous parameter\nscale, leading to sluggish performance. Therefore, complete integration is unfeasible, implying the potential\nnecessity for external storage. Similar situations exist in computer architecture, where the CPU incorporates\non-chip SRAM, typically constrained in size due to the significantly higher cost of on-chip storage (100 times\nmore expensive than DRAM and 10,000 times more expensive than disk storage). Neural networks function as\non-chip storage for large models, with larger-scale models possessing more on-chip storage. However, utilizing\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n13\nneural networks for data storage proves costly, causing a rapid escalation in network scale. Hence, large models\nrequire a more efficient data storage method beyond neural networks, known as memory of LLMs.\nFor instance, GPTCache[139] is a tool specifically designed to build semantic caches for storing LLMs\u2019 responses.\nIt employs a modular design, including six main modules: LLM adapter, embedding generator, cache storage,\nvector store, cache manager, and similarity evaluator. The system offers multiple implementation options for each\nmodule, allowing users to customize their semantic cache to meet specific needs. Zep is a long-term memory\nstore designed for building conversational LLM applications, which supports storing, summarizing, embedding,\nindexing, and enriching the history of LLM applications/chatbots. Zep[132] enables long-term memory persistence,\nautomatic summarization based on configurable message windows, vector search, and automatic memory token\ncounting.\n4.4\nTypical Applications of Prompting Framework\nIn this section, we elucidate some typical applications of the prompting framework throughout the entire lifecycle\nof LLMs. These applications, situated at the closest proximity to the user at the application layer, are poised to\noffer boundless insights and inspiration for future developers and users.\n4.4.1\nIntegrated Application Platform. The initial goal of constructing the prompting framework was\nto reduce the interaction barriers with LLMs and facilitate the development of LLM applications. Therefore,\nafter addressing prototype issues, the subsequent challenge is to assist these applications in transitioning to\npractical development while ensuring implementation in a reliable and maintainable manner. Debugging, testing,\nevaluating, and monitoring the intricate data and control flow within LLM systems are crucial steps in this\nprocess, which ensures the robust deployment of LLMs in real-world production scenarios is of paramount\nimportance. Consequently, considering both immediate requirements and future strategic objectives, integrated\napplication platforms emerge as a typical application of the prompting framework.\nFor example, The newly developed LangSmith [20] by LangChain developers introduces innovative features\ncentered around five core pillars: debugging, testing, evaluation, monitoring, and usage metrics. LangSmith\nfacilitates the execution of these operations through a simple and intuitive user interface, significantly lowering the\nbarriers for developers without a software background. From a numerical perspective, many features of LLMs lack\nintuitiveness, making visual representation essential. We observe that a thoughtfully designed user interface can\nexpedite user prototyping and work, as handling everything through code alone can be cumbersome. Furthermore,\nvisualizing the processes and intricate command chains of LLM systems proves valuable in understanding the\nreasons behind specific outputs. As users construct more complex workflows, comprehending how queries\ntraverse different processes becomes challenging. Therefore, a user-friendly interface to visualize these processes\nand record historical data represents a forward-looking innovative application.\n4.4.2\nLLM-based Agent. For a long time, autonomous agents have been a significant research topic. However,\nbefore the advent of LLMs and related technologies, limitations in training data, training methods, and interaction\nwith the environment severely constrained the capabilities of agents. Consequently, agents struggled to make\ndecisions similar to humans and achieve remarkable performance. However, with the current prevalence of LLMs\nand their outstanding capabilities, LLM-based autonomous agents have demonstrated immense potential in task\nprocessing and autonomous decision-making.\nIn a broad sense, an agent refers to any system capable of thinking, interacting with the environment, operating\nindependently, and collaborating with other entities. In theory, given any objective, an agent should be able to\nachieve it automatically. LLM-based Agents belong to AI systems that autonomously generate sub-agents, which\ncan execute tasks independently based on user requirements without the user\u2019s direct intervention, following\nthe basic three sub-steps used by people to solve various problems: perception, decision-making, and action.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n14\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\nLLM-based Agents can handle tasks ranging from daily event analysis, marketing plan generation, and code\nprogramming, to mathematical computations, among others. If ChatGPT follows user instructions, doing what\nthe user tells it to do, then an LLM-based Agent acts on what it deems should be done. In other words, LLM-\nbased Agents demonstrate a potential form of integration between LLMs and prompting frameworks. However,\nit\u2019s important to note that this is still an experimental concept and not a fully realized commercial product.\nCurrently, LLM-based autonomous agents typically follow a unified architecture, consisting of four main modules:\na configuration module representing agent attributes, a memory module for storing historical information, a\nplanning module for formulating future action strategies, and an action module for executing plan decisions.\nAutoGPT [103], released on GitHub by Significant Gravitas, is a well-known autonomous agent capable of\nexecuting actions based on LLMs\u2019 autonomous decision results and external resources. AutoGPT uses a cyclic\nevaluation strategy to assess the degree of goal achievement in real-time, determining whether a task is complete.\nAutoGPT is mainly composed of three parts: task distribution, autonomous execution, and result output. The\nautonomous execution module is the core of AutoGPT. Currently, AutoGPT can perform basic tasks such as\ninternet searches and information collection, long-term and short-term memory management, access to common\nwebsites and platforms, and extension through plugins. HuggingGPT [122], developed by Zhejiang University and\nMicrosoft Research Asia, is a collaborative system that connects LLMs with the ML community (HuggingFace). It\ncan handle inputs from various modalities and address a wide range of complex AI tasks. In essence, HuggingGPT\ntakes introductions to all models on the HuggingFace community as input and runs them through models. Then,\nbased on the user\u2019s input question, it parses matches and decides which model to use for solving the task. Similarly,\nHuggingGPT\u2019s workflow comprises four stages: task planning, model selection, task execution, and response\ngeneration, which aligns closely with that of AutoGPT. In addition, AgentGPT [96] is a web-based solution\nthat allows for the configuration and deployment of autonomous AI agents, facilitating interactive experiences\nwith web users. CAMEL [3], short for \u201cCommunicative Agents for \u2019Mind\u2019 Exploration of Large Scale Language\nModels,\" implements a novel role-playing agent. GPTRPG [39] combines game design with large language models,\nenabling the deployment of multiple agents to autonomously participate in online games by embedding AI agents\ninto the roles within the game environment using the OpenAI API.\n5\nRELATED PROMPTING TOOLS\nIn this section, we provide an extensive overview of prominent prompting tools that contribute to generating\nhigher-quality prompts or achieving advanced functionality through prompts. Since these tools do note possess\nall four fundamental characteristics of prompting frameworks, namely modularity, abstraction, scalability, and\nstandardization, they are not classified as prompting frameworks. Nevertheless, the problems they address and\nthe functionalities they enable are also significant for future interactions with LLMs. Additionally, we introduce\nsome auxiliary tools that play a vital role in task completion of prompting frameworks. Links to these tools are\nalso organized in our GitHub repository.\nPrompt is a powerful tool that enhances the flexibility and controllability of large language models (LLMs),\nmaking them applicable across various domains. Through clever design and utilization of prompts, users can\nguide the model to generate desired text, resulting in improved performance and effectiveness across various\ntasks. It can be stated that a well-crafted prompt can significantly boost the productivity of LLMs. The significance\nof predefined prompt templates, example libraries, or prompt optimization tools that template user-inputted\nprompts for large language models lies in their ability to not only lower technical barriers, enabling non-technical\nindividuals to easily interact with the model, but also enhance interaction efficiency. In other words, users can\nselect suitable prompts from existing templates without the need to write their own from scratch. Furthermore,\nsince templates are designed and tested, they tend to be more precise and reliable, reducing errors caused by\nunclear or vague user instructions.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n15\nPrompt\u2019s Template Library. Awesome ChatGPT Prompts [1] is an open-source website and application\ncreated by JavaScript developer Fatih Kadir Ak\u0131n, which contains over 160 prompt templates for ChatGPT,\nallowing it to mimic a Linux terminal, JavaScript console, Excel page, and more. These prompts have been\ncollected from excellent real-world use cases. LangGPT [130] is designed to write high-quality prompts in\na structured, templated manner. It not only provides templates but also supports variable configuration and\nreferences based on templates. PromptSource [4] is a toolkit for creating, sharing, and using natural language\nprompts. PromptSource allows for the use of thousands of existing and newly created prompts, which are stored\nin separate structured files and written in a simple template language called Jinja.\nOptimizer for Prompts. OpenPrompt [35] provides a standardized, flexible, and extensible framework for\ndeploying prompt-based learning pipelines. It supports existing prompt learning methods and allows for the\ndesign of custom prompt learning tasks. HumanPrompt [124] is a framework that makes it easier for humans\nto design, manage, share, and use prompts and prompting methods. InstructZero [21] aims to optimize poorly\nphrased prompts provided by users to LLMs, transforming them into well-structured and compliant prompts. The\noptimization process primarily aligns humans with LLMs, rather than fine-tuning LLMs to align with humans, as\nin instruction fine-tuning.\nEvaluation of LLMs. Evaluating LLMs has always been a crucial topic to ensure their reliability, safety,\nusability, and compliance while helping identify potential issues and improvement areas [5, 49, 58, 92]. Evals\n[81] is a framework for evaluating LLMs and LLM systems and serves as an open-source registry of benchmarks.\nEvals simplifies the process of constructing evaluations with minimal code while being straightforward to\nuse. PromptBench [138] is a framework for robustness evaluations of large language models under adversarial\nprompts, which facilitates examining and analyzing interactions between large language models and various\nprompts, providing a convenient infrastructure for simulating black-box adversarial prompt attacks and evaluating\nperformance. PromptInject [89] is a framework that modularly assembles prompts to provide quantitative analysis\nof LLMs\u2019 robustness against adversarial prompt attacks.\nFig. 3. The dimensions and metrics for comparative analysis.\n6\nCOMPARISONS AND CHALLENGES\nIn this section, we provide a comparison of existing prompting frameworks from various dimensions and analyze\nthe challenges that prompting frameworks encounter in terms of development, practical implementation, and\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n16\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\nfurther advancements. The dimensions and metrics for conducting the comparative analysis are shown in Fig.\n3, and the detailed capability matrix based on the dimensions and metrics above of the mainstream prompting\nframework is illustrated in Fig. 4.\nHandling \nUnconventional Input \nContent \nExceeding \nLLM\u2019s \nToken Limit\nNon-textual \nContents \nBeyond LLMs\u2019\nCapabilities \nBeneficial Effects of \nthe Reasoning\nAcceleration \nof Reasoning\nRefining \nOutputs to \nStipulated \nCriteria\nControl of LLMs \nOutputs\nOutput\u2019s \nContent\nOutput\u2019s \nStructure\nCapability \nof Utilizing \nExternal \nTools\nMaintenance \nof Historical\nInformation\nImpact of \nInvocation Costs\nDecrease LLMs \nInvocation \nFrequency\nDecrease Token \nProcessing During \nLLMs Invocation\nPrompting \nFramework\nLangChain\n!\n\u2705\n\u26d4\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\nHaystack\n\u2705\n!\n\u2705\n\u2705\n\u2705\n\u2705\n\u26d4\n\u2705\n\u2705\nSemantic Kernel\n\u2705\n!\n\u2705\n\u2705\n\u2705\n\u2705\n\u26d4\n\u2705\n\u2705\nGriptape\nPromptFlow\nLLM-chain\nLinGoose\nLLMStack\nOpenDAN\nHyv\nUniversal \nLLM-SH\n!\n!\n!\n\u2705\n!\n\u2705\n\u2705\n\u2705\n\u2705\n\u26d4\n\u2705\n\u2705\n!\n\u2705\n\u26d4\n\u2705\n\u2705\n\u2705\n\u2705\n\u26d4\n\u2705\n\u2705\n!\n\u2705\n\u2705\n!\n\u2705\n\u2705\n\u2705\n\u2705\n\u26d4\n\u2705\n\u2705\n!\n\u2705\n\u26d4\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n!\n!\n\u2705\n\u26d4\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n!\n!\n\u2705\n\u26d4\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n!\n\u26d4\n!\n!\n!\n\u2705\n\u2705\n\u2705\n\u2705\n\u26d4\n\u26d4\nLlamaIndex\n!\n\u2705\n\u26d4\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\nembedchain\nAgentVerse\nSuperAGI\nTxtai\nAutoChain\nTermGPT\nBotpress\nDomain-\nSpecific \nLLM-SH\n!\n!\n\u2705\n!\n\u26d4\n!\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u26d4\n\u2705\n!\n\u26d4\n\u2705\n\u2705\n!\n\u26d4\n\u2705\n\u2705\n!\n\u2705\n\u2705\n\u26d4\n\u2705\n\u2705\n!\n\u2705\n\u2705\n\u26d4\n\u2705\n\u2705\n!\n\u26d4\n!\n\u2705\n\u26d4\n\u26d4\n!\n\u26d4\n\u26d4\n!\n!\n\u26d4\n\u26d4\n!\n\u2705\n!\n\u2705\n!\n\u26d4\n\u26d4\n\u2705\n\u2705\n!\nLLM-SH\nHandling \nUnconventional Input \nContent \nExceeding \nLLM\u2019s \nToken Limit\nNon-textual \nContents \nBeyond LLMs\u2019\nCapabilities \nBeneficial Effects of \nthe Reasoning\nAcceleration \nof Reasoning\nRefining \nOutputs to \nStipulated \nCriteria\nControl of LLMs \nOutputs\nOutput\u2019s \nContent\nOutput\u2019s \nStructure\nCapability \nof Utilizing \nExternal \nTools\nMaintenance \nof Historical\nInformation\nImpact of \nInvocation Costs\nDecrease LLMs \nInvocation \nFrequency\nDecrease Token \nProcessing During \nLLMs Invocation\nPrompting \nFramework\nLMQL\nProgram-\n-ming \nLLM-LNG\n\u2705\n\u2705\n\u2705\n\u2705\n!\n\u26d4\n\u26d4\n\u2705\n!\n\u26d4\nSudoLang\nPromptLang\ngpt-jargon\nPseudocode \nLLM-LNG\n\u26d4\n\u26d4\n\u2705\n\u2705\n\u2705\n\u2705\n!\n!\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u2705\n\u2705\n\u2705\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u2705\n\u2705\n\u2705\n\u26d4\n\u26d4\nLLM-LNG\nHandling \nUnconventional Input \nContent \nExceeding \nLLM\u2019s \nToken Limit\nNon-textual \nContents \nBeyond LLMs\u2019\nCapabilities \nBeneficial Effects of \nthe Reasoning\nAcceleration \nof Reasoning\nRefining \nOutputs to \nStipulated \nCriteria\nControl of LLMs \nOutputs\nOutput\u2019s \nContent\nOutput\u2019s \nStructure\nCapability \nof Utilizing \nExternal \nTools\nMaintenance \nof Historical\nInformation\nImpact of \nInvocation Costs\nDecrease LLMs \nInvocation \nFrequency\nDecrease Token \nProcessing During \nLLMs Invocation\nPrompting \nFramework\nContent \nLLM-RSTR\nGuidance\nPromptify\nReLLM\nStructure \nLLM-RSTR\nLLM-RSTR\nNeMo-Guardrails\nGuardrails\nTypeChat\n!\n\u2705\n!\n!\n\u26d4\n\u2705\n\u2705\n\u2705\n\u2705\n\u26d4\n\u26d4\n\u2705\n\u26d4\n\u26d4\n\u2705\n\u2705\n\u2705\n\u2705\n\u26d4\n\u2705\n\u26d4\n\u2705\n\u2705\n\u2705\n\u26d4\n\u2705\n\u26d4\n!\n!\n!\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u2705\n\u2705\n\u2705\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u26d4\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u2705\n\u26d4\n\u26d4\n\u26d4\n\u2705\n\u2705\n!\n!\n\u26d4\n\u26d4\n\u26d4\n!\n\u26d4\n\u2705support \npartial support\nnot support\nFig. 4. The capability matrix of representative prompting frameworks.\n6.1\nComparative Analysis of Prompting Frameworks\nWe have examined the three macro dimensions of compatibility, capabilities and features, as well as documentation\nand support. Within these dimensions, we have focused on more detailed key issues, providing a comprehensive\nanalysis and comparison of existing prompting frameworks, which offer systematic experiences and guidelines\nfor developers and users in their practical adoption of prompting frameworks and for further advancements.\n6.1.1\nCompatibility. Compatibility refers to the adaptability and interoperability of systems, software, hard-\nware, or other components in various environments or conditions. We primarily investigate the compatibility of\nthe prompting framework with programming languages and its compatibility with LLMs.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n17\nCompatibility of Programming Languages. Due to different development team preferences and project\nrequirements, prompting frameworks are typically designed to consider the use of multiple programming\nlanguages by developers. As a result, various prompting frameworks often provide interfaces supporting one or\nmultiple mainstream programming languages to allow developers to flexibly choose and interact with languages\nin different projects and environments, thereby enhancing development efficiency and adaptability. The currently\navailable prompting framework provides comprehensive coverage of programming languages, including Python,\nJava, JavaScript, C#, C++, Go (Golang), Rust, and TypeScript.\nComparative Analysis. Currently, the prompting framework is still in its early stages of rapid development.\nLanguage support tends to begin with an implementation in a specific language and then expand to support\na wider range of programming languages, accommodating more use cases and domains. Overall, LLM-SH is\ndesigned to be more adaptable to a broader range of scenarios and to support a richer set of tools. Consequently,\nLLM-SH exhibits stronger compatibility with programming languages compared to LLM-RSTR and LLM-LNG.\nFor instance, Txtai, within LLM-SH, offers impressive support for five mainstream programming languages:\nPython, Java, Rust, Golang, and JavaScript. Meanwhile, LangChain and Semantic Kernel can each support three\nprogramming languages: Python, TypeScript, and JavaScript, as well as C#, Python, and Java, respectively. Most\nprompting frameworks tend to focus on supporting one mainstream programming language, with Python and\nTypeScript being the primary choices. For instance, in LLM-SH, tools like Haystack, Griptape, PromptFlow,\nLLMStack, OpenDAN, AutoChain, TermGPT, and in LLM-LNG, LMQL, as well as in LLM-RSTR, NeMo-Guardrails,\nGuardrails, Guidance, Promptify, and ReLLM primarily support Python. On the other hand, Hyv and botpress\nbelonging to LLM-SH, and TypeChat belonging to LLM-RSTR are specifically designed for TypeScript. LlamaIndex\nand embedchain in LLM-SH support both Python and TypeScript. Furthermore, LLM-chain is exclusively focused\non Rust, while LinGoose is tailored for the Golang. As for Pseudocode LLM-LNG, its intent is to create a new\nlanguage to simplify interaction with LLMs, so SudoLang, PromptLang, and gpt-jargon support only the syntax\nof the language designed within the framework and natural language.\nIn summary, in terms of compatibility with programming languages, LLM-SH surpasses LLM-RSTR, which in\nturn surpasses LLM-LNG.\nCompatibility of LLMs. The original intention of the Prompting Framework is to establish a medium for\ninteraction between external and LLMs. Therefore, one of the key requirements for the Prompting Framework\nis its compatibility with LLMs, which means that the Prompting Framework should seamlessly integrate with\nvarious types of LLMs and handle their inputs and outputs correctly. In other words, Prompting Frameworks\nwith better compatibility generally offer a unified interface, which enables users to use the different Prompting\nFrameworks with corresponding instructions to interact with LLMs, without requiring additional handling of\nspecific details. The current prompting framework supports various LLMs, primarily including the previously\nmentioned OpenAI API, Azure OpenAI API, HuggingFace API, as well as other APIs such as Llama API, Anthropic,\nERNIE-Bot, Google PaLM, and so on.\nComparative Analysis. Currently, support for LLMs within prompting frameworks is in a phase of rapid\nevolution due to the continuous emergence of new LLMs. Developers need to swiftly integrate these models into\nprompting frameworks once they are familiar with their functionalities and usage. It\u2019s worth noting that when\nwe refer to LLMs compatibility, we mean the ability to seamlessly integrate models into prompting frameworks\nwithout the need for complex additional operations or coding, which implies direct utilization of models in\nprompting frameworks through modifications to certain configurations, using the LLMs in their native supported\nform, rather than relying on additional plugins or frameworks. Models that are natively supported by prompting\nframeworks tend to integrate better with the framework, fully leveraging the model\u2019s capabilities and minimizing\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n18\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\nTable 2. The maximum tokens supported and pricing of mainstream LLMs.\nModel\nDeveloper\nMax Token\nCost / 1K tokens\nInput\nOutput\ngpt-4\nOpenAI\n8,192\n$0.03\n$0.06\nAzure OpenAI\ngpt-4-32k\nOpenAI\n32,768\n$0.06\n$0.12\nAzure OpenAI\ngpt-3.5-turbo\nOpenAI\n4,097\n$0.0015\n$0.002\nAzure OpenAI\ngpt-3.5-turbo-16k\nOpenAI\n16,385\n$0.003\n$0.004\nAzure OpenAI\ntext-davinci-003\nOpenAI\n4,097\n$0.012\n$0.016\nAzure OpenAI\ntext-davinci-002\nOpenAI\n4,097\n$0.012\n$0.012\nAzure OpenAI\ntext-embedding-ada-002\nOpenAI\n8,191\n$0.0001\n$0.0001\nClaude Instant\nAnthropic\n100,000\n$0.00163\n$0.00551\nClaude 2\nAnthropic\n100,000\n$0.01102\n$0.03268\nLlama 2\nMetaAI\n4,096\nfree\nfree\nCohere\nCohere\n4,096\n$0.015\n$0.015\nPaLM 2\nGoogle\n8,000\n$0.0005\n$0.0005\nunexpected bugs during programming. At present, all prompting frameworks offer good support for prominent\nAPIs released by OpenAI, namely text-davinci-003, gpt-3.5-turbo, chatgpt, and gpt-4. In other words, prompting\nframeworks were originally introduced to facilitate user interactions with these mainstream APIs. Pseudocode\nLLM-LNG is a special case where this mutation-free pseudocode language can work well with any interactive\ninterface-based LLMs. Consequently, SudoLang, PromptLang, and gpt-jargon can be compatible with almost\nall interactive LLMs. Only a few prompting frameworks currently offer support for Hugging Face APIs. For\ninstance, within LLM-SH, LangChain, Semantic Kernel, Haystack, Griptape, PromptFlow, LinGoose, LlamaIndex,\nembedchain, Txtai, AutoChain, and within LLM-RSTR, TypeChat and Promptify, provide such support. The\nmentioned prompting frameworks can also be compatible with Google\u2019s Azure OpenAI API. Furthermore, for\nother popular APIs like Claude from Anthropic, Llama API, Google PaLM, etc., only LLM-SH\u2019s LangChain,\nSemantic Kernel, Haystack, Griptape, Txtai, LlmaIndex, and embedchain can offer good support.\nIn summary, all prompting frameworks offer good support for OpenAI\u2019s APIs. In general, LLM-SH exhibits the\nstrongest compatibility with LLMs, while Pseudocode LLM-LNG demonstrates exceptional compatibility when\ndealing with interactive interface-based LLMs without requiring compilation.\n6.1.2\nCapabilities and Features. Capabilities and features are a crucial dimension when comparing different\nPrompting Frameworks, as they directly determine the framework\u2019s ability and flexibility in addressing problems\nand meeting user requirements. We elaborate on various crucial stages of the interaction between LLMs and\nthe Prompting Framework, including data preprocessing, reasoning process, output control, cost considerations,\ntool learning, and information maintenance. The comparison dimensions of capabilities and features we have\nenumerated can be employed not only for analyzing the strengths and limitations of diverse prompting frameworks\nbut also as evaluation metrics for forthcoming tasks in assessing the prompting frameworks.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n19\nCapability of Handling Unconventional Contents. The ability of prompting frameworks to assist LLMs in\nhandling unconventional content primarily manifests in two aspects. Firstly, the prompting framework helps\nLLMs deal with content that exceeds the token limit, and secondly, the prompting framework empowers LLMs to\nprocess non-textual content formats that go beyond their inherent capabilities. Usually, LLMs have a token limit\ndetermined by the model\u2019s architecture and memory constraints. For example, GPT-3.5-turbo and text-davinci-003\nhave a maximum input length of 4,097 tokens, while gpt-3.5-turbo-16k allows for 16,385 tokens, and GPT-4-32k\nallows for 32,768 tokens, which results in LLMs being unable to capture the global context of a text when dealing\nwith extremely long documents without external support because only a portion of the text can be included.\nThe maximum tokens supported and pricing of mainstream LLMs are shown in Tab. 2. Moreover, processing\nsuch long text can lead to performance issues, especially in resource-constrained environments. LLMs need to\nmaintain a lot of information within a single input, which may require more computational resources and time.\nTherefore, prompting frameworks have emerged to assist LLMs in handling complex tasks involving extremely\nlong texts, such as machine translation, legal document analysis, sentiment analysis of lengthy novels or articles,\nlong-context dialogue systems, knowledge graph construction, etc. LLMs are primarily designed for processing\npure textual data, making them less suitable for unconventional formats like images, audio, or videos, whose\nmain inputs and outputs are text data. Prompting frameworks effectively mitigate this limitation, enabling LLMs\nto handle a variety of data types, which broadens the application of LLMs to a wide range of multimedia tasks.\nComparative Analysis. In terms of the capability to handle content exceeding token limits and non-textual\ncontent, only LLM-SH can achieve these functionalities without the need for additional plugins or program calls.\nLLM-LNG and LLM-RSTR achieve these capabilities by making calls to LLM-SH within their framework design.\nHowever, it\u2019s important to note that such compatibility can potentially lead to unexpected bugs.\nFor handling content that exceeds token limits, LLM-SH empowers LLMs through methods like splitting,\nfiltering, concatenation, or summarization. For instance, a classic approach is the \u201cRetrieval\" module in LangChain,\nwhere \u201cDocument transformers\" offer pre-packaged functional functions for document splitting, composition, and\nfiltering. In the \u201cChains\" module, there is a package called \u201cchains.summarize\" that provides various methods for\nsummarizing documents (PDFs, Notion pages, customer questions, etc.), including Map-Reduce, Stuff, and Refine\napproaches to organizing documents. By configuring parameters to design a \"chain\" structure differently and\nintroducing vector databases and text embedding models, LLMs can effectively manage extremely long documents.\nSimilarly, modules like \"Summarizer\" in Haystack and \"Summary Engines\" in GripTape can summarize long texts,\nand components like \"PreProcessor\" in Haystack and \"Chunkers\" in GripTape can perform text splitting and\nfiltering for long texts.\nWhen it comes to handling non-textual content, LLM-SH can process text extracted from non-text formats\nlike YouTube videos or HTML files or generate multi-modal content such as images, videos, and audio, based\non pure text content. However, it doesn\u2019t provide full-fledged processing of multimedia files throughout the\ninput-output process. For instance, the \"Tool Memory\" module in GripTape can generate images, videos, PDFs,\nand other non-textual content. Similarly, the \"Document loaders\" module in LangChain exposes a \"load\" method\nfor loading data as documents from a configured source.\nIn summary, only LLM-SH can assist LLMs in handling unconventional input contents, while LLM-LNG and\nLLM-RSTR need to rely on LLM-SH to achieve this functionality. LLM-SH deals with content exceeding token\nlimits by splitting, filtering, reassembling, or summarizing long documents. Regarding non-textual content,\nLLM-SH processes the text portions extracted from multimedia files or generates multi-modal multimedia\nfiles based on pure text content.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n20\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\nBeneficial Effects of the Reasoning Process. The benefits of prompting frameworks for LLMs in the\nreasoning process are primarily evident in two capabilities: accelerating reasoning and ensuring that reasoning\nresults meet preset requirements. In the current scenario with a surge in data volume and user usage, the speed\nof LLMs\u2019 reasoning is crucial for completing tasks efficiently. Additionally, improved reasoning results enable\nLLMs to accomplish more work in a given unit of time, greatly facilitating the application of these powerful\nnatural language processing models in tasks requiring rapid responses and high throughput. For example, it\u2019s\nuseful in online customer support (providing instant responses to customer queries for better user experiences),\nreal-time financial analysis (for timely financial decision-making by analyzing news events and market data), and\nreal-time sentiment analysis (for tracking product or brand feedback on social media in real-time).\nComparative Analysis. Regarding the crucial functionality of accelerating reasoning, most prompting frame-\nworks do not provide support. Among the prompting frameworks surveyed, only LMQL within LLM-LNG offers\nthis relevant service. LMQL accelerates inference by providing eager validation during LLM runtime. The principle\nbehind eager validation is that LLMs typically generate text sequentially, similar to how humans write. When\nusers make requests to LLMs with conditions like \"the output must satisfy A and B,\" LMQL monitors the output\nas it\u2019s being generated. If LMQL detects that the currently outputted portion no longer satisfies condition A, it\nforcibly stops the LLM\u2019s execution and triggers it to re-infer, which eliminates the need to wait until the LLM\ncompletes the entire response to determine if the output complies with the conditions. For example, if a user\ninstructs Chatgpt with the input \"Write a poem about the sky, excluding clouds and birds,\" conditions A and B are\n\"excluding clouds\" and \"excluding birds.\" If Chatgpt generates a description of \"clouds\" during the writing process,\nit no longer meets the user\u2019s request. Therefore, LMQL performs a forced termination of Chatgpt and resumes\nfrom the error-free portion to continue the task. This \"validate-as-you-go\" approach significantly accelerates\nLLM inference.\nTo ensure that inference results meet preset requirements, LLM-LNG, LLM-RSTR, and LLM-SH all utilize\nvalidate templates or allow for user-defined templates to ensure more standardized and accurate prompts (inputs).\nFor instance, features like \"Prompts\" in LangChain\u2019s Model I/O module and \"PromptTemplate\" in Haystack\nenable predefined templates as well as user-defined templates within the framework. Additionally, the previously\nmentioned eager validation not only accelerates inference but also enforces stricter compliance with output\nrequirements, making it easier to obtain outputs consistent with expectations and standards.\nIn summary, to enhance the inference process of LLMs, LLM-LNG, LLM-RSTR, and LLM-SH all use methods\nsuch as predefined templates or compatibility with user-defined templates to ensure that inference results\nbetter meet requirements. Only LMQL within LLM-LNG supports the acceleration of the reasoning process\nduring LLM runtime.\nControl of LLMs Outputs. Prompting framework\u2019s role in achieving controllable generation with LLMs\nprimarily addresses two issues: imposing fine-grained structural constraints on generated output and ensuring\nthat LLMs do not produce sensitive, non-compliant, or unsafe content. The significance of structured output\nfrom LLMs lies in its ability to transform natural language text into a structured format, making information\neasier to process, analyze, and apply. The structured output aids in tasks such as extracting key information\nfrom text, building knowledge graphs, and performing data analysis. Structured data plays a crucial role in\ninformation management and data analysis, supporting decision-making, process optimization, insight discovery,\nand the development of intelligent applications. Structured data is essential in various industries and domains,\nhelping organizations better understand and leverage their data assets. The safety and relevance of LLMs\u2019 output\ncontent are crucial because these factors directly impact whether the text generated by the model is appropriate,\naccurate, and useful. For example, content filtering on social media platforms ensures that content posted on\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n21\nthese platforms does not contain inappropriate or rule-violating material, maintaining the platform\u2019s reputation\nand user experience. In online customer support, automated response systems generate information only related\nto product support or common issues, ensuring that responses generated by automated systems are both on-topic\nand free from inappropriate content. Maintaining the online platform\u2019s brand reputation, protecting user rights,\nproviding accurate information, and enhancing the availability of automated systems are all essential. Using\nprompting frameworks to assist in the automated and intelligent handling of LLMs\u2019 output content, ensuring that\ngenerated text meets specific requirements, has practical applications in social media, news media, e-commerce,\nonline education, and many other fields.\nComparative Analysis. When it comes to constraining the output structure of LLMs, LLM-SH, LLM-LNG, and\nContent LLM-RSTR typically provide interfaces or pre-packaged functions that, when given custom structured\ntemplates provided by users, transform LLMs\u2019 output into the corresponding structured format. For example,\nLangChain\u2019s Model I/O module offers \"Output parsers,\" which are classes designed to help structure language\nmodel responses. By invoking LangChain\u2019s built-in functions and combining them with user-configured structural\ntemplates, LLM-SH\u2019s LangChain directly supports various commonly used structured output forms, such as\nlists, time formats, enumerations, JSON, and more. In Semantic Kernel within LLM-SH, LMQL within LLM-LNG,\nand SudoLang, which are designed with frameworks and syntax that allow the mixing of natural language with\ncode, support for structured data is achieved through user-configured custom structural templates. This means\nthat users need to design, describe, and write their own templates in the corresponding framework\u2019s custom\ntemplate locations. However, in the case of Structure LLM-RSTR, a category of prompting frameworks specifically\ndesigned for structured output, they offer built-in features for structured data generation and validation and\nexcel at supporting formats like JSON and dialogue-based data. For instance, in Guidance, you can use the \"gen\"\ncommand to interleave generation, prompting, and logic control in a continuous sequential flow that aligns with\nhow the language model processes text. In TypeChat, there\u2019s the provision of Schema, a data structure used to\ndescribe the expected format and fields of a prompt. By defining a Schema, you can validate and correct user\ninput to ensure it adheres to the expected format and requirements.\nSecuring and ensuring compliance with the output content of LLMs is crucial. However, except for Content LLM-\nRSTR within LLM-RSTR, no other prompting frameworks address this issue. In Content LLM-RSTR, Guardrails is\na Python package that adds type and quality assurance to LLMs\u2019 output, including semantic validation, such as\nchecking for biases in generated text and errors in generated code and takes corrective measures when validation\nfails. Guardrails provides a file format (.rail) for executing \"specifications\" (user-specified structural and type\ninformation, validators, and corrective actions) on LLMs\u2019 output and offers a lightweight API call wrapper to\nimplement these specifications on the output. NVIDIA\u2019s NeMo-Guardrails follows a similar design philosophy,\nensuring control, safety, and security of large model language generation by limiting templates and themes in\nconversations. NeMo-Guardrails employs a custom language to implement a three-layer protection mechanism,\nincluding Topical GuardRail for topic-related questions, Safety GuardRail for ensuring controlled responses, and\nSecurity GuardRail to protect against malicious or abusive questions. However, this approach, while practical, also\nintroduces potential challenges such as configuration redundancy, inflexibility, operational risks, and limitations\non the original conversational capabilities of LLMs.\nIn summary, LLM-SH, LLM-LNG, and LLM-RSTR all offer different ways to support control over the structure\nof LLMs\u2019 output, but only Content LLM-RSTR within LLM-RSTR provides constraints and validation for the\nsafety and compliance of LLMs\u2019 output content, albeit with certain potential issues in its functionality.\nImpact of Invocation Costs. Reducing the cost of LLMs invocation primarily involves two approaches: firstly,\nreducing the frequency of invoking LLMs, and secondly, decreasing the number of tokens processed during LLMs\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n22\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\ninvocation. Utilizing LLMs services on cloud computing platforms such as AWS, Azure, and Google Cloud incurs\ncharges for each model invocation. These costs escalate with the frequency of invocations and the extent of\ncomputational resources used. One of the significant challenges in implementing LLMs for practical production\nscenarios is the high cost associated with invoking LLMs, which can be burdensome for individuals and even\nenterprises with limited financial resources. LLMs are typically billed based on the number of tokens generated\nor processed, with the number of tokens subject to charges determined by the prompt and the corresponding\nresponse length. The billing unit is the \"token,\" which can represent a word, character, or punctuation symbol. In\nEnglish, one token typically corresponds to one word, but for other languages, token forms may vary due to\ndifferences in language structures. Different models have varying token pricing standards; for example, GPT-3.5\nis priced at $0.002 per 1000 tokens, while GPT-4\u2019s token price is nearly six times higher than that of GPT-3.5. The\nmaximum tokens supported and pricing of mainstream LLMs are shown in Tab. 2. While the cost per individual\ntoken may appear acceptable from a computational perspective, it becomes substantial for long-term usage and\ncomplex tasks. For instance, translating large documents, especially complex technical documents across multiple\nlanguages, may require extended processing time and additional computational resources. Similarly, employing\nLLMs for large-scale data analysis, text mining, or information extraction tasks, such as processing tens of\nthousands of news articles to extract key information, might necessitate distributed computing environments\nand substantial storage, resulting in high invocation costs.\nComparative Analysis. In terms of reducing the frequency of LLMs invocation, LLM-SH introduces the \"Memory\"\nmodule that stores historical query information. Leveraging vector databases, enables a form of \"learning from\nthe past,\" so that when encountering the same or similar questions, LLMs do not need to be invoked again, thus\nsaving unnecessary computational expenses. For instance, LLM-SH\u2019s LangChain implements a \"Memory\" module\nfor storing past interactions, Haystack includes a \"Module memory\" module with the InMemoryDocumentStore\nclass for recording and retrieving interaction content, and Griptape offers a \"Conversation Memory\" module\nwith BufferConversationMemory functionality for constructing prompts with sliding window tasks. In contrast,\nLLM-LNG primarily reduces the frequency of invoking LLMs by embedding preprocessing programs and modules\nwithin the framework. Simple questions are first handled by smaller or free models, and then LLMs are utilized for\nmore detailed processing, thus reducing the number of LLMs invocations. However, this method has limitations\nin broader tasks. Additionally, LLM-RSTR frameworks typically do not consider this functionality. Regarding\nthe prompting framework\u2019s role in reducing the number of tokens that LLMs need to process, LLM-SH employs\ntechniques like splitting, filtering, concatenating, or summarizing text segments to abbreviate and simplify the\ncontent to be processed. This aligns with the earlier-discussed approach of handling extremely long documents.\nIn summary, the current state of prompting frameworks does not fully address the crucial challenge of reducing\nthe cost of LLMs invocation. LLM-SH employs \"Memory\" functionality and text manipulation techniques to\nreduce the frequency of invocations and the number of tokens to be processed. LLM-LNG relies on embedded\npreprocessing modules, which have limited applicability, while LLM-RSTR frameworks generally do not\nimplement this capability. Therefore, in the future, reducing the cost of LLMs invocation should be an essential\narea of development for prompting frameworks.\nCapability of Utilizing External Tools. The ability to use tools is one of the most significant distinctions\nbetween humans and other species. Currently, a crucial limitation of LLMs in practical applications is their\ninability to use external tools like humans. However, the advent of prompting frameworks effectively mitigates\nthis deficiency. Typically, LLMs are generalized models, so the capability for LLMs to utilize external tools holds\nsignificant importance for enhancing their functionality, adapting to specific tasks and domain requirements,\nproviding access to more data and resource support, and meeting compliance and security demands. For example,\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n23\nin custom text generation tasks, combining external plugins with LLMs allows the generation of industry-specific\nnews reports, creative writing, or legal documents. In complex data query tasks, integrating LLMs with database\nquery plugins enables them to respond to intricate business queries such as sales reports, inventory management,\nor medical record retrieval. Furthermore, multimodal processing plugins can be integrated with LLMs to analyze\nand generate content with text, images, and audio elements, such as social media posts or advertisements.\nComparative Analysis. In terms of enabling LLMs to use external tools, LLM-SH outperforms LLM-RSTR and\nLLM-LNG due to its design focus. LLM-SH can support the integration of LLMs with a wide range of tools spanning\nvarious domains, such as web browsers, databases, email clients, image processing tools, speech recognition\nengines, code processors, and more. For instance, LangChain\u2019s Agents module offers a Toolkit function in which\na collection of tools designed for specific tasks and conveniently loaded methods are available. These tools\nencompass Gmail, GitHub, SQL Databases, Vectorstore, and various Natural Language APIs. GripTape utilizes\nthe Tools module\u2019s TextToolMemory to enhance the output of all tools, while also allowing users to perform\ndifferent degrees of customization at the structural, task, or tool activity levels. TextToolMemory empowers LLMs\nto interact with the external world, generating non-textual content such as images, videos, PDFs, and others. In\ncontrast, LLM-LNG and LLM-RSTR provide limited support for only the most commonly used external tools. For\ninstance, LMQL in LLM-LNG offers services restricted to calculators and Wikipedia tools, while Guidance in\nLLM-RSTR offers integration with the Bing search engine.\nIn summary, the current state of prompting frameworks for enabling LLMs to integrate with external tools\nis in its initial and somewhat immature stage. LLM-SH provides LLMs with the capability to use tools in\nrelatively diverse scenarios to some degree, while LLM-LNG and LLM-RSTR offer very limited support in this\nregard.\nMaintenance of Historical Information. Maintenance of historical interaction information is crucial for\nLLMs as it provides them with the ability to store, retrieve, and reference information. This capability aids in\nbetter understanding context, maintaining coherence in complex tasks and long texts, and benefiting from past\ncomputations. However, apart from chat models like ChatGPT, which can record some history within the same\nconversation interface (with no sharing of information across different interfaces), LLMs typically process only\nthe current context information provided in the prompt during service. This limitation is inconvenient for users\nas historical interaction information not only enhances interactions with LLMs, reducing the need for repetitive\nwork but also stimulates non-dialogue LLMs like GPT-3.5 in chat tasks. Prompting frameworks address this need\nby offering \"Memory\" systems, supporting two fundamental operations: reading and writing. This enables the\nstorage of historical interaction information and its utilization through queries, searches, and retrieval. Prompting\nframeworks empower LLMs with the ability to maintain historical interaction information, aiding in context\nunderstanding, information retrieval, multi-turn question-answering, document reading, error detection and\ncorrection using memory, caching intermediate computation results, and storing user preferences, historical\nbehavior, or personalized information.\nComparative Analysis. Regarding the maintenance of historical interaction information, LLM-SH excels due to\nits comprehensive Memory system, which allows integration with various tools across different domains. Taking\nLangChain as an example, the \"Memory\" can store past chat messages, queries, and results, effectively adding\nmemory to the system. This storage function can be used independently or seamlessly integrated into various\nchains. Moreover, LangChain supports the use of embedded models and vector databases to store, query, and\nmaintain historical information. During a single run, the system interacts with \"Memory\" twice, once when\nproviding a query. The prompt includes two parts, one directly from user input, and the other possibly extracted\nfrom information stored in memory. The second interaction records the current interaction in memory for\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n24\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\nfuture queries and retrieval. LLM-SH\u2019s Memory system usually offers multiple ways to manage short-term\nmemory, such as ConversionMemory and VectorStore-backed Memory. ConversionMemory summarizes ongoing\nconversations and stores the current summary in memory, passing it as short-term memory to LLMs in new\nrounds of conversation. This compression of historical conversation information is particularly useful for lengthy\nconversations. On the other hand, VectorStore-backed Memory stores all past conversations in vector form in\na vector database. In each new conversation round, it matches the user\u2019s input against the vector database to\nfind the most similar K sets of conversations. LLM-LNG and LLM-RSTR typically achieve historical information\nmaintenance by invoking the corresponding functional modules in LLM-SH. An interesting feature in LLM-LNG is\nLMQL\u2019s \"Caching Layer,\" implemented as a tree-like data structure. This layer caches all model outputs, including\nlogs and historical information, to enable more efficient exploration of the LLM\u2019s token space during runtime,\neven in the presence of multiple variables, constraints, and tool enhancements. The cache can be seen as a tree\nwith only appendices, explored during query execution and expanded based on query code, constraint conditions,\nand inferred execution scenarios.\nIn summary, LLM-SH provides a relatively complete and comprehensive memory system for maintaining\nhistorical interaction information, while LLM-LNG and LLM-RSTR typically achieve this by invoking corre-\nsponding functional modules within LLM-SH.\n6.2\nDocumentation and Support.\nDocument quality and community support are crucial for a prompting framework. Document integrity refers to\nthe accuracy, readability, and completeness of technical documentation, which assesses whether the development\nteam provides detailed, clear, and comprehensive documentation to facilitate user learning and usage. Community\nsupport involves the presence of an active developer community around the framework, allowing users to receive\ntimely assistance and feedback.\nDocument Completeness. The investigated prompting frameworks offer three primary deployment methods.\nThe first method is command-line installation, where Python-based frameworks use commands like \"pip install\"\nor \"conda install,\" and JavaScript-based frameworks use \"npm install\" for deployment. This method is available\nfor almost all prompting frameworks. The second method is a custom interactive user interface, providing a\nplayground that allows users to interact with the framework directly through a user-friendly interface without the\nneed for installation, for example, LMQL in LLM-LNG. The third method is the \"open-and-use\" approach, where\ndeployment and execution are done directly on the interface provided by LLMs, offering the most straightforward\nand simple operation. SudoLang in LLM-LNG is an example. Overall, the prompting frameworks studied provide\ncomprehensive technical documentation that covers almost all features and use cases. They also offer detailed\nexample code, tutorials, and operation guides, making it easy for users to get started, understand, and use these\nframeworks. These technical documents are readily accessible on GitHub. Additionally, some frameworks have\ncreated well-designed web pages with high readability and attractiveness, such as LangChain in LLM-SH.\nDocument Readability. At present, the technical documentation of existing prompting frameworks is\ncomprehensive and detailed but may lack readability. The rapid proliferation of LLMs and their derivatives has led\nto a need for frequent updates to the technical documentation. These updates may occur daily to accommodate\nmore products and features. The introduction of new features can sometimes render old ones unusable or\nintroduce bugs, causing significant challenges for users and developers. Furthermore, the continuous addition of\nfeatures and product introductions can make the documentation structure complex and the content increasingly\nlengthy. This can lead to a situation where the documentation becomes overwhelming and resembles a \"code\nmountain\" rather than maintaining the clarity and simplicity of its initial state, which can be frustrating for users.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n25\nIn summary, the dynamic nature of LLMs and their associated frameworks necessitates frequent documentation\nupdates, but these updates must be managed carefully to maintain clarity and usability for users and developers.\nCommunity Support. Regarding community support and user feedback channels, the development teams\nbehind these prompting frameworks typically offer Discord online community services. Users can ask questions,\nshare experiences, and engage with other users in these communities. Furthermore, they maintain official support\nteams on Twitter and have dedicated communication topics (tags) for users to provide feedback, suggestions,\nand opinions, thus facilitating framework improvements. Additionally, they provide communication spaces on\nGitHub for users and developers.\n6.3\nChallenges Confronting the Prompting Framework\nThe existing prompting frameworks currently alleviate many limitations of LLMs in practical applications,\nsignificantly enhancing the capabilities of LLMs themselves and further elevating their performance. However,\nburgeoning development still encounters numerous challenges. In this section, we will analyze the challenges\nand opportunities that the prompting framework currently faces in terms of functionality implementation and\nissues related to safety and ethics.\n6.3.1\nSecurity Mechanisms of Prompting Framework. For a developed tool, both functionality and security\nmechanisms are equally crucial. Software that cannot guarantee the security of user information and is not\nharmless to society, regardless of its robust functionality, is unlikely to gain user support. Existing evidence\nsuggests that LLMs and relatively mature prompting frameworks like LangChain have certain security issues\n[6, 62, 66, 87, 118]. However, the existing prompting frameworks have paid minimal attention to the significance\nof security ethics and privacy protection. Due to LLMs possessing an \"Achilles\u2019 heel\" \u2013 being uncontrollable\ngenerative AI, we cannot predict the outputs, which can be fatal in certain scenarios. Therefore, we argue that the\nsecurity mechanisms that prompting frameworks urgently need to enhance should consist of two parts: defense\nagainst prompt-based attacks and safeguarding the behavior of LLMs.\nDefense Against Prompt-based Attacks. We begin by introducing the concept of Prompt-based Attacks\nand then provide some suggestions to mitigate this issue within future prompting frameworks. Prompt-based\nAttacks share essential similarities with Prompt Engineering in that they both aim to obtain desired outputs\nthrough expertly crafted, rational, and optimized instructions. However, Prompt Engineering is user-oriented,\nwhile Prompt-based Attacks adopt a hacker-attack perspective. Malicious inputs from external sources can\ncontaminate the model\u2019s outputs through Prompt-based Attacks, thereby exerting influence on external systems,\nresulting in adversarial actions. The impact of such attacks depends on the capabilities granted to the model by\nthe system. Prompt-based Attacks refer to attempts to generate content that contradicts the developer\u2019s intent\nusing LLMs [31, 43, 62, 89, 125]. Typically, there are two forms of attacks: Prompt-based Deception (bypassing\nscrutiny through linguistic techniques) and Prompt-based Injection (tampering with instructions). In scenarios\nlimited to content generation, the harm caused by these attacks may be relatively insignificant. However, with the\nproliferation of various prompting frameworks and projects like AutoGPT, more individuals are granted execution\nauthority over LLMs, expanding the potential danger. These scenarios encompass not only the creation of email\nworms utilizing automated email processing functions but also poisoning email extraction systems through\nweb-based attacks, code poisoning through code completion mechanisms, and more ominous possibilities, such\nas manipulating or accessing local files or diverting funds if a private prompting framework assistant were to be\ncompromised or granted execution authority.\nAs for defense mechanisms against Prompt-based Attacks, we offer several suggestions from the perspective\nof instruction design. Firstly, when constructing prompts for interaction with LLMs, it is advisable to employ\ndelimiters to rigorously differentiate instructions from content, which involves encapsulating user-generated\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n26\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\ncontent within delimiters and imposing specific authority constraints, a practice endorsed by OpenAI and machine\nlearning expert Andrew Ng as a best practice. Secondly, place crucial instructions at the end of the prompt.\nGiven that most malicious instructions currently tend to disregard preceding instructions, positioning developer\ninstructions at the end of the entire prompt is indeed a straightforward and convenient method in practice.\nLastly, consider incorporating a pre-filtering layer, such as establishing whitelists and blacklists for prompt\ncontent. Whitelists define permissible inputs, for instance, in the case of designing a machine translation model\nfrom Chinese to English, pre-detect and allow only Chinese characters in the prompt for synthesis with the\nmodel. Conversely, blacklists prohibit specific inputs, for instance, detecting common jailbreak-related phrases or\ninstructions like \"ignore\" and refrain from inputting them into the model or checking for the presence of phrases\nprohibited by other legal regulations.\nSafeguards of LLMs\u2019 Behavior. As is widely acknowledged, LLMs while gaining favor from millions of users,\noccasionally exhibit undesirable behaviors such as escaping, hallucinating, and deception. Therefore, it is crucial\nto \"muzzle\" LLMs by adding an additional safeguard layer to their output. Starting from the design principles\nand implementations of the prompting framework, augmenting LLMs with an additional protective mechanism\nwithin the prompting framework is both reasonable and aligned with software development principles. This\naugmentation allows for the early interception and modification of objectionable or non-compliant content in\nthe output of LLMs before obtaining the final results.\nThe Nemo Guardrails developed by Microsoft, as mentioned earlier, still has several issues when it comes\nto protecting LLMs\u2019 behavior. Firstly, it uses its proprietary definition language, which may appear more user-\nfriendly but limits its extensibility. Moreover, it transforms a model\u2019s security and control problem into a manual\npolicy configuration problem. This approach brings various potential issues such as redundant configurations,\nlack of flexibility, operational risks, and potential curtailment of the original capabilities of large language models.\nIt seems to be more like a compromise solution in today\u2019s commercial scenarios where there is a desire to\neffectively utilize the generation capabilities of large models but no effective solution for controllability and\nsecurity.\nTherefore, we believe that future prompting frameworks should be designed based on mainstream programming\nlanguages, employing advanced technologies to establish flexible and automated mechanisms for extracting and\nconfiguring protection rules, which focus on three main aspects: topic relevance, content safety, and application\nsecurity, ultimately standardizing the behavior of LLMs. Thematic integrity safeguards aim to prevent LLMs from\ngoing off-topic. LLMs possess a richer imagination and are more capable of creative code and text generation\ncompared to other AIs. However, for specific applications such as coding or customer service, users do not\nwant them to \"stray from the intended scope\" while addressing issues, and generating irrelevant content. In\nsuch cases, topic-constrained safeguards are required. When a large model generates text or code that goes\nbeyond the predefined topic, these safeguards guide it back to the designated functionality and topic. Content\nsafety safeguards are intended to prevent incoherent output from large models. Incoherent output includes two\nscenarios: factual inaccuracies in the answers generated by LLMs, which are things that \"sound reasonable but\nare entirely incorrect,\" and the generation of biased or malicious output, such as using offensive language when\nprompted by users or generating unethical content. Application security refers to restricting the application\u2019s\nconnections to known secure third-party applications. The prompting framework should avoid exposing LLMs to\nmalicious attacks from external sources during task execution. This includes preventing the induction of LLMs to\ncall external virus plugins and defending against hackers who may attempt to attack LLMs through methods like\nnetwork intrusion or malicious software.\n6.3.2\nCapability Limitations of Prompting Framework. In comparing and analyzing the capabilities and\nfeatures of prompting frameworks, we delineate 6 dimensions. Prompting frameworks exhibit commendable\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n27\nperformance across these capability dimensions, but they still exhibit shortcomings in the degree of implementa-\ntion within each capability dimension. For instance, concerning the handling of unconventional inputs, current\nprompting frameworks can significantly assist LLMs in text processing leaps but remain somewhat constrained\nin multi-modal scenarios (e.g., video and images). Similarly, limitations exist in invoking external expert models.\nFurthermore, as the landscape of large models continuously evolves with the emergence of numerous LLMs and\nexternal plugins, many prompting frameworks adapt by continually adding encapsulated invocation functions to\nsupport relevant services. However, this rapid evolution introduces several challenges. The updated functionalities\nare often haphazardly aggregated and do not offer the same level of support as native capabilities provided by\nthe framework. Additionally, more intricate functionalities may lead to contradictions or duplications when\nnot properly planned, resulting in a steep learning curve for users. Consequently, we analyze the limitations\nof current prompting frameworks from these perspectives: an increasingly steep learning curve, constraints in\ninvoking external interfaces and handling multi-modal I/O.\nIncreasingly Steep Learning Curve. With the explosive growth in the field of large models, numerous related\ntools and plugins have emerged, which has posed significant challenges to the development and maintenance\nof prompting frameworks, requiring software engineers to quickly familiarize themselves with these emerging\nexternal tools and integrate their interfaces into the existing prompting framework. This has resulted in some\nfunctionality stacking and redundancy. For example, native functionalities within the prompting framework\ntypically allow for straightforward invocation with uniform interfaces, achieved by simply modifying parameters.\nConversely, newly added functionalities often necessitate users to invoke other packages and employ relatively\ncomplex and non-uniform calling procedures. Consequently, users must acquire additional knowledge before\nusage, resulting in steeper learning curves. The relatively complex processes and methods also lead to suboptimal\nuser experiences or program bugs. Furthermore, the introduction of new functionalities may disrupt the proper\nfunctioning of previously implemented native features, which is a recurring issue within existing prompting\nframeworks. As previously indicated, it has been observed that the technical documentation of the existing\nprompting framework exhibits deficiencies in terms of readability. The emergence of this problem is logical,\nand an effective mitigation strategy involves developers considering future developments and changes in the\nframework\u2019s structural design, which entails enhancing the modularity, scalability, and standardization of the\nprompting framework.\nConstraints in Invoking External Interfaces. Currently, prompting frameworks can support relatively basic\nexternal tool usage, such as browsing the web or querying databases. However, we argue that the accessibility of\nexternal expert models remains rudimentary within most prompting frameworks. For instance, current prompting\nframeworks cannot fully assist LLMs in utilizing the widely-used \"Microsoft Suite\" in commercial and office\nenvironments, including Microsoft Word, Microsoft Excel, and Microsoft PowerPoint. Additionally, prompting\nframeworks lack secure protocols for accessing and handling users\u2019 private or commercial data that meet security\nand privacy requirements. Furthermore, because current prompting frameworks can only handle text-based\ntasks, there are limitations in handling multi-modal inputs such as videos, Word documents, emails, etc. This\nmakes it challenging to provide support for widely-used functional tools like YouTube (one of the world\u2019s largest\nvideo-sharing platforms with billions of users), arXiv (a significant open-access academic preprint platform),\nTwitter (a prominent social media platform in the realm of social media and news dissemination), Outlook (one of\nMicrosoft\u2019s widely-used email and calendar management tools), and others. In the future, prompting frameworks\nshould aim to not only assist LLMs in supporting these widely-used mainstream software but also allow for the\nintegration of more emerging or niche tools or platforms to foster a more vibrant AI community ecosystem.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n28\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\n7\nFUTURE DIRECTIONS AND CONCLUSION\n7.1\nConclusion of Existing Prompting Frameworks\nIn this paper, we elucidate the genesis of the prompting framework and its underpinning technological foundations.\nSubsequently, we proffer a conceptual definition of the prompting framework, along with its requisite character-\nistics of modularity, abstraction, extensibility, and standardization. We then classify the prompting framework\nbased on usage scenarios and technical attributes into three categories: the shell of LLMs (LLM-SH), language for\ninteraction with LLMs (LLM-LNG), output restrictors of LLMs (LLM-RSTR). Following this categorization, we\nconduct a comprehensive comparative analysis of the compatibility, capabilities and features, documentation,\nand community support of these prompting frameworks across various dimensions. Finally, we delineate the\nchallenges currently confronting the development of prompting frameworks. Additionally, we introduce several\npractical relevant prompt-based tools that fall outside the purview of the prompting framework domain and\ntools that play a significant role in assisting LLMs in accomplishing tasks. In this section, we summarize the\napplicability and limitations of existing prompting frameworks.\nDespite the various attempts made by current prompting frameworks to alleviate the limitations of LLMs in\nreal-world applications, there are still challenges and limitations that need to be addressed. These frameworks\nhave emerged with different focuses and features, addressing various dimensions of user concerns, including\ndocumentation and community support, compatibility, capabilities (such as the ability to use external tools,\ncost reduction, etc.), which have indeed made strides in solving some of the issues. However, it is important\nto note that current prompting frameworks can be considered as compromise solutions to meet user needs in\ntoday\u2019s commercial scenarios, rather than fully future-proof methods. The limitations of existing prompting\nframeworks primarily revolve around the lack of support for security mechanisms and inherent limitations in\ntheir capabilities.\nSecurity Mechanisms. Regarding the security mechanisms within prompting frameworks, including resis-\ntance to prompt-related attacks and constraints on LLMs\u2019 behavior, there are currently significant limitations.\nFirstly, most prompting frameworks do not adequately address resistance against prompt-related attacks, such\nas injection and deception. These vulnerabilities pose a severe threat to system security. Additionally, in terms\nof constraining LLMs\u2019 behavior, current prompting frameworks rely primarily on manually configured safety\npolicies similar to Reinforcement Learning from Human Feedback (RLHF). They have not fully leveraged advanced\ntechnologies and methods, which can result in issues like redundant configurations, inflexibility, operational\nrisks, and even limitations on the original functionality of LLMs.\nCapability Limitations. The limitations in the capabilities of prompting frameworks themselves are evident,\nespecially when it comes to developing applications with large language models (LLMs). One of the primary\nreasons for this limitation is that many of the issues in LLM applications are rooted in the deficiencies of the\nunderlying technology of large models, emphasizing the importance of prompt engineering. For instance, when\nmanipulating LLMs to perform highly complex tasks using prompting frameworks, developers often rely on\nhighly customized, handcrafted prompts. However, many existing prompting frameworks are designed with\na \"simplification to complexity\" principle in mind. They assume that more complex structures lead to more\ncomprehensive functionality. In other words, these frameworks tend to be overly complex and do not provide\nsufficient openness in terms of prompt design. As a result, users often find themselves needing to configure\nmany aspects of the system themselves, but prompting frameworks do not provide appropriate support for this\nrequirement. Therefore, simplifying and streamlining the configuration process and providing more open and\nflexible prompt design options could enhance the usability and effectiveness of these frameworks in developing\ncomplex LLM applications. Simultaneously, the current prompting framework still faces notable shortcomings\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n29\nin its accessibility to the broader external world, such as the limited support for third-party tools, including\nmultimodal tools, and mainstream platforms like arXiv and Twitter.\n7.2\nFuture Directions\nWe believe that the next-generation of prompting frameworks should overcome the limitations mentioned above\nwhile integrating the strengths of the three prompting frameworks in this paper, which can provide users with\nmore concise and compact interaction channels, facilitate LLMs interactions with powerful third-party interfaces,\nand enable interactions with higher-quality and more tailored. The next-generation prompting framework should\nbe a comprehensive platform that is more streamlined, more secure, more versatile, and more standardized, which\nseamlessly integrates development, testing, evaluation, maintenance, expansion, and communication with LLMs,\nconstituting an organic LLM ecosystem.\nMore streamlined. The next-generation prompting framework should embody a higher degree of streamlining,\nprimarily manifested in the simplification of user interactions with LLMs and the interactions between LLMs and\nenvironments. Furthermore, the technical architecture and documentation should exhibit enhanced compatibility\nwith new products and technologies, coupled with a more user-friendly learning curve and instructional materials.\nIn essence, it should adhere to the principle of \"simplify without oversimplifying, embracing the concept of\nsimplicity as the ultimate sophistication.\"\nMore secure. The next-generation prompting framework ensures the secure and compliant generation of\ncontent by Large Language Models (LLMs) while safeguarding user privacy and security, serving as a bidirectional\nsecurity barrier between users and LLMs and between LLMs and applications.\nMore versatile. The next-generation prompting framework seamlessly integrates with more diverse, feature-\nrich external applications, enabling LLMs to excel in various domains such as healthcare, research, education,\ntransportation, and more.\nMore standardized The next-generation prompting framework adheres to established domain standards,\nwhich are widely accepted sets of rules, guidelines, specifications, or best practices within specific domains\nto ensure the quality, consistency, and reliability of products, services, or processes. Examples include ISO\n27001 for information security management systems (ISMS) in the field of information technology and GMP\nstandards for quality management in pharmaceutical and medical device manufacturing in the healthcare domain.\nThese standards facilitate compliance across different prompting frameworks, eliminating the need for users to\nacquire additional knowledge and promoting mutual support and complementarity between different prompting\nframeworks.\nOrganic LLMs ecosystem. The next-generation prompting framework seamlessly integrates with LLMs,\nserving as a comprehensive platform for LLM development, testing, comparison, evaluation, user interaction,\nand developer communication. This integration fosters an ecosystem that evolves through continuous feedback,\nultimately delivering enhanced services and enabling leaps in technology and application development.\nREFERENCES\n[1] Fatih Kadir Ak\u0131n. 2022. Awesome ChatGPT Prompts. https://github.com/f/awesome-chatgpt-prompts\n[2] Mostafa M Amin, Erik Cambria, and Bj\u00f6rn W Schuller. 2023. Will Affective Computing Emerge From Foundation Models and General\nArtificial Intelligence? A First Evaluation of ChatGPT. IEEE Intelligent Systems 38, 2 (2023), 15\u201323.\n[3] apache. 2022. CAMEL. https://github.com/apache/camel\n[4] Stephen H. Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful\nBari, Thibault Fevry, Zaid Alyafeaiu, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-David, Canwen Xu, Gunjan Chhablani, Han\nWang, Jason Alan Fries, Maged S. Al-shaibani, Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Mike Tian-Jian, and\nAlexander M. Rush. 2022. PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts.\n(2022). https://arxiv.org/abs/2202.01279\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n30\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\n[5] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung,\net al. 2023. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint\narXiv:2302.04023 (2023).\n[6] Clark Barrett, Brad Boyd, Ellie Burzstein, Nicholas Carlini, Brad Chen, Jihye Choi, Amrita Roy Chowdhury, Mihai Christodorescu,\nAnupam Datta, Soheil Feizi, et al. 2023. Identifying and Mitigating the Security Risks of Generative AI. arXiv preprint arXiv:2308.14840\n(2023).\n[7] Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE transactions\non pattern analysis and machine intelligence 35, 8 (2013), 1798\u20131828.\n[8] Yoshua Bengio, R\u00e9jean Ducharme, and Pascal Vincent. 2000. A neural probabilistic language model. Advances in neural information\nprocessing systems 13 (2000).\n[9] Amanda Bertsch, Uri Alon, Graham Neubig, and Matthew R Gormley. 2023. Unlimiformer: Long-range transformers with unlimited\nlength input. arXiv preprint arXiv:2305.01625 (2023).\n[10] Luca Beurer-Kellner, Marc Fischer, and Martin Vechev. 2023. Prompting is programming: A query language for large language models.\nProceedings of the ACM on Programming Languages 7, PLDI (2023), 1946\u20131969.\n[11] Rishi Bommasani, Percy Liang, and Tony Lee. 2023. Holistic Evaluation of Language Models. Annals of the New York Academy of\nSciences (2023).\n[12] botpress. 2023. Botpress. https://github.com/botpress/botpress\n[13] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam,\nGirish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33\n(2020), 1877\u20131901.\n[14] Jake Brukhman. 2023. gpt-jargon. https://github.com/jbrukh/gpt-jargon\n[15] Aydar Bulatov, Yuri Kuratov, and Mikhail S Burtsev. 2023. Scaling Transformer to 1M tokens and beyond with RMT. arXiv preprint\narXiv:2304.11062 (2023).\n[16] Yihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S Yu, and Lichao Sun. 2023. A comprehensive survey of ai-generated\ncontent (aigc): A history of generative ai from gan to chatgpt. arXiv preprint arXiv:2303.04226 (2023).\n[17] Yong Cao, Li Zhou, Seolhwa Lee, Laura Cabello, Min Chen, and Daniel Hershcovich. 2023. Assessing cross-cultural alignment between\nchatgpt and human societies: An empirical study. arXiv preprint arXiv:2303.17466 (2023).\n[18] Marco Cascella, Jonathan Montomoli, Valentina Bellini, and Elena Bignami. 2023. Evaluating the feasibility of ChatGPT in healthcare:\nan analysis of multiple clinical and research scenarios. Journal of Medical Systems 47, 1 (2023), 33.\n[19] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang,\net al. 2023. A survey on evaluation of large language models. arXiv preprint arXiv:2307.03109 (2023).\n[20] Harrison Chase. 2022. LangChain. https://github.com/hwchase17/langchain\n[21] Lichang Chen, Jiuhai Chen, Tom Goldstein, Heng Huang, and Tianyi Zhou. 2023. InstructZero: Efficient Instruction Optimization for\nBlack-Box Large Language Models. arXiv preprint arXiv:2306.03082 (2023).\n[22] Le Chen, Pei-Hung Lin, Tristan Vanderbruggen, Chunhua Liao, Murali Emani, and Bronis de Supinski. 2023. LM4HPC: Towards\nEffective Language Model Application in High-Performance Computing. arXiv preprint arXiv:2306.14979 (2023).\n[23] Lingjiao Chen, Matei Zaharia, and James Zou. 2023. FrugalGPT: How to Use Large Language Models While Reducing Cost and\nImproving Performance. arXiv preprint arXiv:2305.05176 (2023).\n[24] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan\nLiu, Maosong Sun, and Jie Zhou. 2023. AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in\nAgents. arXiv:2308.10848 [cs.CL]\n[25] Xuanting Chen, Junjie Ye, Can Zu, Nuo Xu, Rui Zheng, Minlong Peng, Jie Zhou, Tao Gui, Qi Zhang, and Xuanjing Huang. 2023. How\nRobust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks. arXiv preprint arXiv:2303.00293 (2023).\n[26] Ajay Kumar Chintala and Vignesh Aigal. [n. d.]. LLMStack: A platform to build and deploy LLM applications. https://github.com/\ntrypromptly/llmstack\n[27] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won\nChung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker\nBarnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski,\nXavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph,\nAlexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana\nPillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,\nBrennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and\nNoah Fiedel. 2022. PaLM: Scaling Language Modeling with Pathways. arXiv:2204.02311 [cs.CL]\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n31\n[28] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha\nBrahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416 (2022).\n[29] Ronan Collobert, Jason Weston, L\u00e9on Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing\n(almost) from scratch. Journal of machine learning research 12, ARTICLE (2011), 2493\u20132537.\n[30] Wei Dai, Jionghao Lin, Flora Jin, Tongguang Li, Yi-Shan Tsai, Dragan Gasevic, and Guanliang Chen. 2023. Can large language models\nprovide feedback to students? A case study on ChatGPT. (2023).\n[31] Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang, Zefeng Li, Haoyu Wang, Tianwei Zhang, and Yang Liu. 2023. Jailbreaker:\nAutomated Jailbreak Across Multiple Large Language Model Chatbots. arXiv preprint arXiv:2307.08715 (2023).\n[32] Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, and Karthik Narasimhan. 2023. Toxicity in chatgpt:\nAnalyzing persona-assigned language models. arXiv preprint arXiv:2304.05335 (2023).\n[33] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for\nlanguage understanding. arXiv preprint arXiv:1810.04805 (2018).\n[34] Etienne Dilocker, Bob van Luijt, Byron Voorbach, Mohd Shukri Hasan, Abdel Rodriguez, Dirk Alexander Kulawiak, Marcin Antas, and\nParker Duckworth. [n. d.]. Weaviate. https://github.com/weaviate/weaviate\n[35] Ning Ding, Shengding Hu, Weilin Zhao, Yulin Chen, Zhiyuan Liu, Hai-Tao Zheng, and Maosong Sun. 2021. OpenPrompt: An\nOpen-source Framework for Prompt-learning. arXiv preprint arXiv:2111.01998 (2021).\n[36] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. A survey for\nin-context learning. arXiv preprint arXiv:2301.00234 (2022).\n[37] Hongyang Du, Zonghang Li, Dusit Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim, et al. 2023. Enabling AI-generated content (AIGC)\nservices in wireless edge networks. arXiv preprint arXiv:2301.03220 (2023).\n[38] Yogesh K Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M Baabdullah,\nAlex Koohang, Vishnupriya Raghavan, Manju Ahuja, et al. 2023. \u201cSo what if ChatGPT wrote it?\u201d Multidisciplinary perspectives on\nopportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of\nInformation Management 71 (2023), 102642.\n[39] Chris Dzoba. 2023. GPTRPG. https://github.com/dzoba/gptrpg\n[40] Eric Elliott. 2023. SudoLang. https://github.com/paralleldrive/sudolang-llm-support\n[41] Emilio Ferrara. 2023. Should chatgpt be biased? challenges and risks of bias in large language models. arXiv preprint arXiv:2304.03738\n(2023).\n[42] Forethought-Technologies. [n. d.]. AutoChain. https://github.com/Forethought-Technologies/AutoChain\n[43] Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, and Mario Fritz. 2023. More than you\u2019ve asked\nfor: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models. arXiv preprint\narXiv:2302.12173 (2023).\n[44] griptape ai. 2023. Griptape. https://github.com/griptape-ai/griptape\n[45] henomis. 2023. LinGoose. https://github.com/henomis/lingoose\n[46] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin,\nLiyang Zhou, Chenyu Ran, Lingfeng Xiao, and Chenglin Wu. 2023. MetaGPT: Meta Programming for Multi-Agent Collaborative\nFramework. arXiv:2308.00352 [cs.AI]\n[47] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora:\nLow-rank adaptation of large language models. arXiv preprint arXiv:2106.09685 (2021).\n[48] InsuranceToolkits. 2023. PromptFlow. https://github.com/InsuranceToolkits/promptflow\n[49] Neel Jain, Khalid Saifullah, Yuxin Wen, John Kirchenbauer, Manli Shu, Aniruddha Saha, Micah Goldblum, Jonas Geiping, and Tom\nGoldstein. 2023. Bring Your Own Data! Self-Supervised Evaluation for Large Language Models. arXiv preprint arXiv:2306.13651 (2023).\n[50] Frederick Jelinek. 1998. Statistical methods for speech recognition. MIT press.\n[51] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot\nreasoners. Advances in neural information processing systems 35 (2022), 22199\u201322213.\n[52] Sotiris B Kotsiantis, Ioannis Zaharakis, P Pintelas, et al. 2007. Supervised machine learning: A review of classification techniques.\nEmerging artificial intelligence applications in computer engineering 160, 1 (2007), 3\u201324.\n[53] John Lafferty, Andrew McCallum, and Fernando CN Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and\nlabeling sequence data. (2001).\n[54] Md Tahmid Rahman Laskar, M Saiful Bari, Mizanur Rahman, Md Amran Hossen Bhuiyan, Shafiq Joty, and Jimmy Xiangji Huang. 2023.\nA Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets. arXiv preprint arXiv:2305.18486 (2023).\n[55] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer.\n2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv\npreprint arXiv:1910.13461 (2019).\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n32\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\n[56] Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil,\nImanol Schlag, Theo Gutman-Solo, et al. 2022. Solving quantitative reasoning problems with language models. Advances in Neural\nInformation Processing Systems 35 (2022), 3843\u20133857.\n[57] Xinzhe Li, Ming Liu, Shang Gao, and Wray Buntine. 2023. A survey on out-of-distribution evaluation of neural nlp models. arXiv\npreprint arXiv:2306.15261 (2023).\n[58] Yen-Ting Lin and Yun-Nung Chen. 2023. LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations\nwith Large Language Models. arXiv preprint arXiv:2305.13711 (2023).\n[59] Jerry Liu. 2022. LlamaIndex. https://doi.org/10.5281/zenodo.1234\n[60] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023. Pre-train, prompt, and predict: A\nsystematic survey of prompting methods in natural language processing. Comput. Surveys 55, 9 (2023), 1\u201335.\n[61] Siru Liu, Aileen P Wright, Barron L Patterson, Jonathan P Wanderer, Robert W Turer, Scott D Nelson, Allison B McCoy, Dean F Sittig,\nand Adam Wright. 2023. Using AI-generated suggestions from ChatGPT to optimize clinical decision support. Journal of the American\nMedical Informatics Association 30, 7 (2023), 1237\u20131245.\n[62] Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng, and Yang Liu. 2023. Prompt\nInjection attack against LLM-integrated Applications. arXiv preprint arXiv:2306.05499 (2023).\n[63] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin\nStoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019).\n[64] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. 2023. Chameleon:\nPlug-and-play compositional reasoning with large language models. arXiv preprint arXiv:2304.09842 (2023).\n[65] Brady D Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, and Ziang Wang. 2023. ChatGPT and a new academic\nreality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing. Journal of\nthe Association for Information Science and Technology 74, 5 (2023), 570\u2013581.\n[66] Kai Mei, Zheng Li, Zhenting Wang, Yang Zhang, and Shiqing Ma. 2023. NOTABLE: Transferable Backdoor Attacks Against Prompt-based\nNLP Models. arXiv preprint arXiv:2305.17826 (2023).\n[67] David Mezzetti. 2020. txtai: the all-in-one embeddings database. https://github.com/neuml/txtai\n[68] Gr\u00e9goire Mialon, Roberto Dess\u00ec, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozi\u00e8re, Timo\nSchick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. 2023. Augmented language models: a survey. arXiv preprint arXiv:2302.07842 (2023).\n[69] microsoft. 2023. Guidance. https://github.com/guidance-ai/guidance\n[70] microsoft. 2023. TypeChat. https://github.com/microsoft/TypeChat\n[71] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv\npreprint arXiv:1301.3781 (2013).\n[72] Tomas Mikolov, Martin Karafi\u00e1t, Lukas Burget, Jan Cernock`\ny, and Sanjeev Khudanpur. 2010. Recurrent neural network based language\nmodel.. In Interspeech, Vol. 2. Makuhari, 1045\u20131048.\n[73] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and\ntheir compositionality. Advances in neural information processing systems 26 (2013).\n[74] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, and Dan\nRoth. 2023. Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey. ACM Comput. Surv.\n56, 2, Article 30 (sep 2023), 40 pages. https://doi.org/10.1145/3605943\n[75] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Rethinking the\nrole of demonstrations: What makes in-context learning work? arXiv preprint arXiv:2202.12837 (2022).\n[76] Marta Montenegro-Rueda, Jos\u00e9 Fern\u00e1ndez-Cerero, Jos\u00e9 Mar\u00eda Fern\u00e1ndez-Batanero, and Eloy L\u00f3pez-Meneses. 2023. Impact of the\nImplementation of ChatGPT in Education: A Systematic Review. Computers 12, 8 (2023), 153.\n[77] Yohei Nakajima. 2023. BabyAGI. https://github.com/yoheinakajima/babyagi\n[78] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,\nWilliam Saunders, et al. 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332\n(2021).\n[79] NVIDIA. 2023. NeMo-Guardrails. https://github.com/NVIDIA/NeMo-Guardrails\n[80] Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alexander Fraser, Shankar Kumar, Libin Shen,\nDavid A Smith, Katherine Eng, et al. 2004. A smorgasbord of features for statistical machine translation. In Proceedings of the Human\nLanguage Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004.\n161\u2013168.\n[81] OpenAI. 2023. Evals. https://github.com/openai/evals\n[82] OpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL]\n[83] OpenDAN.ai. 2023. OpenDAN. https://www.opendan.ai/\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\nPrompting Frameworks for Large Language Models: A Survey\n\u2022\n33\n[84] Jonas Oppenlaender and Joonas H\u00e4m\u00e4l\u00e4inen. 2023. Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and\nGPT-4 for Cost-Efficient Question Answering. arXiv preprint arXiv:2306.05036 (2023).\n[85] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina\nSlama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information\nProcessing Systems 35 (2022), 27730\u201327744.\n[86] Ankit Pal. 2022. Promptify: Structured Output from LLMs. https://github.com/promptslab/Promptify. Prompt-Engineering components\nfor NLP tasks in Python.\n[87] Rodrigo Pedro, Daniel Castro, Paulo Carreira, and Nuno Santos. 2023. From Prompt Injections to SQL Injection Attacks: How Protected\nis Your LLM-Integrated Web Application? arXiv preprint arXiv:2308.01990 (2023).\n[88] Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023. Instruction tuning with gpt-4. arXiv preprint\narXiv:2304.03277 (2023).\n[89] F\u00e1bio Perez and Ian Ribeiro. 2022. Ignore Previous Prompt: Attack Techniques For Language Models. https://doi.org/10.48550/ARXIV.\n2211.09527\n[90] Malte Pietsch, Timo M\u00f6ller, Bogdan Kostic, Julian Risch, Massimiliano Pippi, Mayank Jobanputra, Sara Zanzottera, Silvano Cerza,\nVladimir Blagojevic, Thomas Stadelmann, Tanay Soni, and Sebastian Lee. 2019. Haystack: the end-to-end NLP framework for pragmatic\nbuilders. https://github.com/deepset-ai/haystack\n[91] Pinecone. 2023. Pinecone. https://github.com/pinecone-io\n[92] Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi Yang. 2023. Is ChatGPT a general-purpose\nnatural language processing task solver? arXiv preprint arXiv:2302.06476 (2023).\n[93] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, et al.\n2023. Tool learning with foundation models. arXiv preprint arXiv:2304.08354 (2023).\n[94] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language Models are Unsupervised Multitask\nLearners. (2019).\n[95] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020.\nExploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research 21, 1 (2020),\n5485\u20135551.\n[96] reworkd. 2023. AgentGPT. https://github.com/reworkd/AgentGPT\n[97] Matt Rickard. 2023. ReLLM. https://github.com/r2d4/rellm\n[98] Ronald Rosenfeld. 2000. Two decades of statistical language modeling: Where do we go from here? Proc. IEEE 88, 8 (2000), 1270\u20131278.\n[99] ruvnet. 2023. PromptLang. https://github.com/ruvnet/promptlang\n[100] Justyna Sarzynska-Wawer, Aleksander Wawer, Aleksandra Pawlak, Julia Szymanowska, Izabela Stefaniak, Michal Jarkiewicz, and\nLukasz Okruszek. 2021. Detecting formal thought disorder by deep contextualized word representations. Psychiatry Research 304\n(2021), 114135.\n[101] Sentdex. 2023. TermGPT. https://github.com/Sentdex/TermGPT\n[102] ShreyaR. 2023. Guardrails. https://github.com/ShreyaR/guardrails\n[103] Significant Gravitas. [n. d.]. Auto-GPT. https://github.com/Significant-Gravitas/Auto-GPT\n[104] Taranjeet Singh. 2023. Embedchain. https://github.com/embedchain/embedchain\n[105] sobelio. 2023. llm-chain. https://github.com/sobelio/llm-chain\n[106] Scott M Thede and Mary Harper. 1999. A second-order hidden Markov model for part-of-speech tagging. In Proceedings of the 37th\nannual meeting of the Association for Computational Linguistics. 175\u2013182.\n[107] TimPietrusky. [n. d.]. Hyv. https://github.com/failfa-st/hyv\n[108] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman\nGoyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971\n(2023).\n[109] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal\nBhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023).\n[110] TransformerOptimus. 2023. SuperAGI. https://github.com/TransformerOptimus/SuperAGI\n[111] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017.\nAttention is all you need. Advances in neural information processing systems 30 (2017).\n[112] Gil LaHaye Vic Perdana. 2023. Semantic-kernel. https://github.com/microsoft/semantic-kernel\n[113] Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng, Yidong Wang, Linyi Yang, Haojun Huang, Wei Ye, Xiubo Geng, et al.\n2023. On the robustness of chatgpt: An adversarial and out-of-distribution perspective. arXiv preprint arXiv:2302.12095 (2023).\n[114] Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin, Peng Xu, Shengjun Li, Xiangyu Wang, Xiangzhou Guo, Chengming Li, Xiaohai\nXu, et al. 2021. Milvus: A Purpose-Built Vector Data Management System. In Proceedings of the 2021 International Conference on\nManagement of Data. 2614\u20132627.\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n34\n\u2022\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\n[115] Xinlong Wang, Wen Wang, Yue Cao, Chunhua Shen, and Tiejun Huang. 2023. Images speak in images: A generalist painter for\nin-context visual learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 6830\u20136839.\n[116] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022. Self-instruct:\nAligning language model with self generated instructions. arXiv preprint arXiv:2212.10560 (2022).\n[117] Taylor Webb, Keith J Holyoak, and Hongjing Lu. 2023. Emergent analogical reasoning in large language models. Nature Human\nBehaviour (2023), 1\u201316.\n[118] Alexander Wei, Nika Haghtalab, and Jacob Steinhardt. 2023. Jailbroken: How does llm safety training fail? arXiv preprint arXiv:2307.02483\n(2023).\n[119] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou,\nDonald Metzler, et al. 2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682 (2022).\n[120] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought\nprompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35 (2022), 24824\u201324837.\n[121] Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, et al. 2023.\nLarger language models do in-context learning differently. arXiv preprint arXiv:2303.03846 (2023).\n[122] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Perric Cistac, Clara Ma, Yacine Jernite,\nJulien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2020. Transformers:\nState-of-the-Art Natural Language Processing. Association for Computational Linguistics, 38\u201345. https://www.aclweb.org/anthology/\n2020.emnlp-demos.6\n[123] Changrong Xiao, Sean Xin Xu, Kunpeng Zhang, Yufang Wang, and Lei Xia. 2023. Evaluating Reading Comprehension Exercises\nGenerated by LLMs: A Showcase of ChatGPT in Education Applications. In Proceedings of the 18th Workshop on Innovative Use of NLP\nfor Building Educational Applications (BEA 2023). 610\u2013625.\n[124] Tianbao Xie, Zhoujun Cheng, Yiheng Xu, Peng Shi, and Tao Yu. 2022. A framework for human-readable prompt-based method with large\nlanguage models.\n[125] Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, and Hongxia Jin. 2023. Virtual\nPrompt Injection for Instruction-Tuned Large Language Models. arXiv preprint arXiv:2307.16888 (2023).\n[126] Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. Harnessing the\npower of llms in practice: A survey on chatgpt and beyond. arXiv preprint arXiv:2304.13712 (2023).\n[127] Xianjun Yang, Yan Li, Xinlu Zhang, Haifeng Chen, and Wei Cheng. 2023. Exploring the limits of chatgpt for query or aspect-based text\nsummarization. arXiv preprint arXiv:2302.08081 (2023).\n[128] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive\npretraining for language understanding. Advances in neural information processing systems 32 (2019).\n[129] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts:\nDeliberate problem solving with large language models. arXiv preprint arXiv:2305.10601 (2023).\n[130] yzfly. 2023. LangGPT. https://github.com/yzfly/LangGPT\n[131] Zhanpeng Zeng, Cole Hawkins, Mingyi Hong, Aston Zhang, Nikolaos Pappas, Vikas Singh, and Shuai Zheng. 2023. Vcc: Scaling\nTransformers to 128K Tokens or More by Prioritizing Important Tokens. arXiv preprint arXiv:2305.04241 (2023).\n[132] Zetaphor. 2023. Zep. https://github.com/getzep/zep\n[133] Chaoning Zhang, Chenshuang Zhang, Chenghao Li, Yu Qiao, Sheng Zheng, Sumit Kumar Dam, Mengchun Zhang, Jung Uk Kim,\nSeong Tae Kim, Jinwoo Choi, et al. 2023. One small step for generative ai, one giant leap for agi: A complete survey on chatgpt in aigc\nera. arXiv preprint arXiv:2304.06488 (2023).\n[134] Chaoning Zhang, Chenshuang Zhang, Sheng Zheng, Yu Qiao, Chenghao Li, Mengchun Zhang, Sumit Kumar Dam, Chu Myaet Thwal,\nYe Lin Tun, Le Luang Huy, et al. 2023. A complete survey on generative ai (aigc): Is chatgpt from gpt-4 to gpt-5 all you need? arXiv\npreprint arXiv:2303.11717 (2023).\n[135] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican\nDong, et al. 2023. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023).\n[136] Denny Zhou, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc\nLe, et al. 2022. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625 (2022).\n[137] Jiaming Zhou, Tengyue Li, Simon James Fong, Nilanjan Dey, and Rub\u00e9n Gonz\u00e1lez Crespo. 2023. Exploring chatGPT\u2019S potential for\nconsultation, recommendations and report diagnosis: Gastric cancer and gastroscopy reports\u2019 case. IJIMAI 8, 2 (2023), 7\u201313.\n[138] Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang,\net al. 2023. PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts. arXiv preprint\narXiv:2306.04528 (2023).\n[139] zilliztech. 2023. GPTCache. https://github.com/zilliztech/GPTCache\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\n",
    "ref": [
        "2202.01279",
        "2302.04023",
        "2308.14840",
        "2305.01625",
        "2304.11062",
        "2303.04226",
        "2303.17466",
        "2307.03109",
        "2306.03082",
        "2306.14979",
        "2305.05176",
        "2308.10848",
        "2303.00293",
        "2204.02311",
        "2210.11416",
        "2307.08715",
        "2304.05335",
        "1810.04805",
        "2111.01998",
        "2301.00234",
        "2301.03220",
        "2304.03738",
        "2302.12173",
        "2308.00352",
        "2106.09685",
        "2306.13651",
        "2305.18486",
        "1910.13461",
        "2306.15261",
        "2305.13711",
        "2306.05499",
        "1907.11692",
        "2304.09842",
        "2305.17826",
        "2302.07842",
        "2202.12837",
        "2112.09332",
        "2303.08774",
        "2306.05036",
        "2308.01990",
        "2304.03277",
        "2211.09527",
        "2302.06476",
        "2304.08354",
        "2302.13971",
        "2307.09288",
        "2302.12095",
        "2212.10560",
        "2307.02483",
        "2206.07682",
        "2303.03846",
        "2307.16888",
        "2304.13712",
        "2302.08081",
        "2305.10601",
        "2305.04241",
        "2304.06488",
        "2303.11717",
        "2303.18223",
        "2205.10625",
        "2306.04528"
    ]
}