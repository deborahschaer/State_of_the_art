{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Task 3: state of the art or summary of several papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bert_score import BERTScorer\n",
    "from rouge_score import rouge_scorer\n",
    "from langchain_community.llms import Ollama\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load summaries and original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLM-based NLG Evaluation: Current Status and Challenges\\nMingqi Gao , Xinyu Hu , Jie Ruan , Xiao Pu ,\\nXiaojun Wan\\nPeking University\\n{gaomingqi, huxinyu, wanxiaojun}@pku.edu.cn, {ruanjie, puxiao}@stu.pku.edu.cn\\nAbstract\\nEvaluating natural language generation (NLG) is\\na vital but challenging problem in artificial intel-\\nligence. Traditional evaluation metrics mainly cap-\\nturing content (e.g. n-gram) overlap between sys-\\ntem outputs and references are far from satisfactory,\\nand large language models (LLMs) such as Chat-\\nGPT have demonstrated great potential in NLG\\nevaluation in recent years. Various automatic evalu-\\nation methods based on LLMs have been proposed,\\nincluding metrics derived from LLMs, prompting\\nLLMs, and fine-tuning LLMs with labeled evalu-\\nation data. In this survey, we first give a taxon-\\nomy of LLM-based NLG evaluation methods, and\\ndiscuss their pros and cons, respectively. We also\\ndiscuss human-LLM collaboration for NLG evalu-\\nation. Lastly, we discuss several open problems in\\nthis area and point out future research directions.\\n1\\nIntroduction\\nEvaluating natural language generation (NLG) is a key but\\nchallenging issue. Traditional evaluation metrics like BLEU\\nand ROUGE rely on the n-gram overlap between model out-\\nputs and references to measure its quality. They have been\\ncriticized for low correlation with human judgments [Sulem\\net al., 2018], as surface-level matching cannot reliably evalu-\\nate text. After the rise of deep learning, model-based eval-\\nuation metrics like BERTScore [Zhang et al., 2020] and\\nBARTScore [Yuan et al., 2021] have been continuously pro-\\nposed and gradually adopted to evaluate the overall quality\\nor various specific aspects of generated outputs (e.g., fluency,\\ncoherence, coverage, faithfulness, etc.). Although better than\\ntraditional metrics, their performance is still not satisfactory,\\nand their application scope is very limited.\\nFor example,\\nBERTScore is reference-based and cannot be used without\\na reference. With the emergence of large language models\\n(LLMs) like ChatGPT, they have achieved unprecedented ef-\\nfectiveness in following instructions, understanding content,\\nand generating text. This inspired researchers to use LLMs\\nfor NLG evaluation. Although this is a research direction that\\nonly emerged in 2023, the past year has seen an enormous\\namount of research work. It is no exaggeration to say that\\nLLM-derived Metrics\\nEmbedding-based\\nProbability-based\\nFine-tuning\\nSpecialized\\nEvaluation LLM\\nPrompt\\nHuman\\nFine-tuning LLMs\\nHuman-LLM \\nCollaborative\\nEvaluation\\nFine-tuning LLMs\\nPrompting\\nLLMs\\nLLM\\nFigure 1: Schematic representation of the four categories of LLM-\\nbased NLG evaluation.\\nNLG evaluation has been revolutionized by LLMs. This arti-\\ncle will review the existing literature and provide suggestions\\nfor future research in this field.\\nThis article mainly focuses on research that uses language\\nmodels with over one billion parameters for NLG evaluation,\\nwith necessary references to earlier model-based evaluation\\nmetrics like BERTScore. To maintain focus, other types of\\ngeneration like code generation and tasks involving images\\nare not included in the scope of this article. As shown in Fig-\\nure 1, according to how we utilize LLMs for NLG evaluation,\\nwe categorize the research work into four types:\\n• LLM-derived metrics (§2): developing/deriving evalu-\\nation metrics from embeddings or generation probabili-\\nties of LLMs.\\n• Prompting LLMs (§3):\\ndirectly inquiring existing\\nLLMs via designed prompts.\\n• Fine-tuning LLMs (§4): using labeled evaluation data\\nto fine-tune existing LLMs and improving their NLG\\nevaluation capabilities.\\n• Human-LLM Collaborative Evaluation (§5): leverag-\\ning the distinctive strengths of both human evaluators\\nand LLMs to achieve robust and nuanced evaluations\\nin challenging domains through human-LLM collabora-\\ntion.\\narXiv:2402.01383v1  [cs.CL]  2 Feb 2024\\nWe will review each type of evaluation methods and discuss\\nthe pros and cons respectively. Lastly, we will discuss future\\ndirections in this area (§6).\\n2\\nLLM-derived Metrics\\n2.1\\nOverview\\nEarly model-based NLG evaluation methods,\\nsuch as\\nBERTScore and BARTScore, were primarily motivated by\\nthe capability of traditional pre-trained language models to\\ngenerate high-quality texts. Recently, the advent of LLMs\\nhas prompted some research to adapt these ideas to stronger\\nLLMs. Their inherent, powerful linguistic abilities are de-\\nrived for direct NLG evaluation, which is expected to result\\nin better performance. Such works can be categorized into\\ntwo types: embedding-based and probability-based methods.\\n2.2\\nEmbedding-based Metrics\\nThe embedding-based methods, like BERTScore, generally\\nutilize representations of language models and thus compute\\nthe semantic similarity between the reference and the target\\ntext to evaluate, with different possible ways of implemen-\\ntation. Recent work [ES et al., 2023] similarly obtains em-\\nbeddings for the target text using the text-embedding-ada-002\\nmodel through the OpenAI API. The higher the correspond-\\ning similarity, the closer the target text aligns with the relevant\\nrequirements, indicating a higher quality.\\n2.3\\nProbability-based Metrics\\nGPTScore [Fu et al., 2023a] establishes tailored evaluation\\ntemplates for each aspect to effectively guide multiple LLMs\\nfor NLG evaluation. The generation probability is calculated\\nunder the condition of source input designed with customized\\nprompts and evaluation aspects, which endows the GPTScore\\nwith better flexibility in evaluation.\\nAnd similar methods\\nhave also been applied to the hallucination detection of the\\nLLM-generated text in recent reseach with three different at-\\ntempts for calculating the probability score.\\nOn the other hand, some works leverage the variation in\\nprobabilities under changed conditions as the evaluation met-\\nric. FFLM [Jia et al., 2023] proposes to evaluate the faith-\\nfulness of the target text by calculating a combination of\\nprobability changes based on the intuition that the genera-\\ntion probability of a given text segment increases when more\\nconsistent information is provided, and vice versa. Similarly,\\nDELTASCORE [Xie et al., 2023] measures the quality of dif-\\nferent story aspects according to the likelihood difference be-\\ntween pre- and post-perturbation states with LLMs including\\nGPT-3.5 (text-davinci-003) that provide logits. They believe\\nthat the sensitivity to specific perturbations indicates the qual-\\nity of related aspects, and their experiments demonstrate the\\neffectiveness of their approach.\\n2.4\\nPros and Cons\\nTraditional NLG evaluation approaches always fall short due\\nto their surface-form similarity when the target text and ref-\\nerence convey the same meaning but use different expres-\\nsions. In contrast, LLM-derived metrics offer a remedy for\\nthe limitation and demonstrate stronger correlations with hu-\\nman judgments benefiting from the evolving modeling tech-\\nniques. However, the flaws within LLMs can lead to some\\nissues, as introduced in the following:\\nRobustness. Some research has investigated the robust-\\nness of LLM-derived metrics and found that they lack ro-\\nbustness in different attack scenarios. Specifically, [He et al.,\\n2023b] develops a set of stress tests to assess the robustness\\nof various model-based metrics on some common NLG tasks.\\nThey show a catalogue of the blind spots and potential errors\\nidentified that are not detected by each metric.\\nEfficiency. Compared to traditional metrics, LLM-derived\\nevaluation methods are more time-consuming and require\\nmore computational resources, especially when adopting\\nLLMs with quite large parameter scales.\\nTo address this,\\nsome lightweight learning approaches and fast LLM infer-\\nence and serving tools like vLLM 1 have been proposed.\\nHowever, closed-source LLMs often do not provide param-\\neters, representations, or logits, thus making it impossible to\\napply LLM-derived methods to them.\\nFairness. [Sun et al., 2022] assesses the social bias across\\nvarious metrics for NLG evaluation on six sensitive attributes:\\nrace, gender, religion, physical appearance, age, and socioe-\\nconomic status. Their findings reveal that model-based met-\\nrics carry noticeably more social bias than traditional metrics.\\nRelevant biases can be categorized into two types: intrinsic\\nbias encoded within pre-trained language models and extrin-\\nsic bias injected during the computation of similarity. There-\\nfore, current LLM-derived methods may have similar issues.\\n3\\nPrompting LLMs\\n3.1\\nOverview\\nLLMs have demonstrated unprecedented instruction under-\\nstanding and text generation abilities, which broadens re-\\nsearchers’ imagination of automatic evaluation for NLG. For\\na long time, human evaluation has been viewed as the gold\\nstandard for NLG evaluation. Recently, some studies claim\\nthat LLMs are on par with crowdsourcing annotators in sev-\\neral tasks. So, can LLMs simulate or even be an alternative to\\nhumans in the human evaluation of NLG? Or, do the practices\\nin human evaluation or other evaluative tasks (e.g. competi-\\ntion race, paper review, etc.) inspire us to better NLG evalua-\\ntion with LLMs? A large body of research and attempts based\\non prompting LLMs are guided by these ideas. In these stud-\\nies, instructions and the text to be evaluated are completely\\nexpressed in the prompt given to LLMs, and the evaluation\\nresults are generated by it.\\nHuman evaluation typically includes the following ele-\\nments:\\n• Evaluation Methods: The way the preferences of an-\\nnotators are captured and recorded, such as scoring, and\\ncomparison.\\n• Task Instructions: How the annotators should read or\\nmanipulate different parts to complete the annotation.\\n1https://github.com/vllm-project/vllm\\nYou will be given a news article. You will then be given one \\nsummary written for this article. Your task is to rate the summary \\non one metric. Please make sure you read and understand these \\ninstructions carefully. \\nEvaluation Criteria:\\nConsistency (1-5) - the factual alignment between the summary and \\nthe summarized source. A factually consistent summary contains only \\nstatements that are entailed by the source document. Annotators \\nwere also asked to penalize summaries that contained hallucinated \\nfacts. \\nEvaluation Steps:\\n1. Read the news article carefully and identify the main facts and \\ndetails it presents.\\n2. Read the summary and compare it to the article. Check if the \\nsummary contains any factual errors that are not supported by the \\narticle.\\n3. Assign a score for consistency based on the Evaluation Criteria.\\nSource Text: \\nPaul Merson has restarted his row with Andros Townsend after the \\nTottenham midfielder was brought on with only seven minutes \\nremaining in his team\\'s 0-0 draw with Burnley on Sunday. … \\nSummary: \\nPaul Merson was brought on with only seven minutes remaining ….\\nEvaluation Form: Answer by starting with \"Rating:\" and then give \\nthe explanation of the rating on the next line by \"Rationale:\"\\n- Consistency: \\nRating: 2\\nRationale:  The summary incorrectly states that Andros Townsend ….\\nPrompt\\nResponse\\nFigure 2: An example of prompting LLMs to score summary faith-\\nfulness. It can be seen that there are task instructions, evaluation\\ncriteria, and input content in the prompt. The rating and explanation\\nare generated by LLMs.\\n• Input Content: The target text to be evaluated and\\nother required content. Other required content including\\nsource documents, references, and external knowledge\\nis provided as needed.\\n• Evaluation Criteria: Also known as aspect, the general\\ndefinition of how good or bad the text to be evaluated\\nis in a particular aspect of quality, e.g. fluency, faithful-\\nness.\\n• Role and interaction: The roles annotators play in the\\nevaluation and the interactions between them.\\nThe focus of the existing research can always be mapped\\nanalogously to one or more of these elements, and we orga-\\nnize them according to the elements they address. An exam-\\nple of prompting LLMs is shown in Figure 2.\\n3.2\\nEvaluation Methods\\n[Kocmi and Federmann, 2023b] discover GPT-3.5 and GPT-\\n4 achieve the state-of-the-art accuracy of evaluating trans-\\nlation quality compared to human labels, outperforming all\\nthe results from the metric shard task of WMT22 [Freitag et\\nal., 2022]. [Wang et al., 2023a] experiment on five datasets\\nacross summarization, story generation, and data-to-text, and\\nChatGPT evaluators with a rating scale from 1 to 5 or 1 to\\n100 have the state-of-the-art or comparative correlations with\\nhuman judgments in most settings, compared with prior met-\\nrics. Similar conclusions are also observed in open-domain\\ndialogue response generation [Lin and Chen, 2023]. Besides\\nEnglish, [Mendonc\\n¸a et al., 2023] show that ChatGPT with\\nsimple rating prompts is a strong evaluator for multilingual\\ndialogue evaluation, surpassing prior metrics based on en-\\ncoders.\\nComparison. Different from absolute scoring, compari-\\nson refers to choosing the better of the two. [Luo et al., 2023]\\nuse ChatGPT to compare the factual consistency of two sum-\\nmaries. AuPEL [Wang et al., 2023d] evaluate personalized\\ntext generation from three aspects in the form of compari-\\nson with the PaLM 2 family [Anil et al., 2023]. According\\nto [Liusie et al., 2023], pairwise comparison is better than\\nscoring when medium-sized LLMs (e.g. FlanT5 [Chung et\\nal., 2022] and Llama2 [Touvron et al., 2023]) are adopted as\\nevaluators.\\nRanking. Ranking can be viewed as an extended form of\\ncomparison. In comparison, only two examples are involved\\nat a time, whereas in ranking, the order of more than two\\nexamples needs to be decided at once. [Ji et al., 2023] use\\nChatGPT to rank five model-generated responses across sev-\\neral use cases at once, indicating the ranking preferences of\\nChatGPT align with those of humans to some degree. Simi-\\nlarly, GPTRank is a method to rank summaries in a list-wise\\nmanner [Liu et al., 2023c]. Moreover, [Liu et al., 2023b]\\ncompare different evaluation methods in LLM-based summa-\\nrization including scoring, comparison, and ranking, showing\\nthat the optimal evaluation method for each backbone LLM\\nmay vary.\\nBoolean QA. Boolean QA requires LLMs to answer ”Yes”\\nor ”No” to a question. It is adopted more in scenarios where\\nhuman annotations are binary, such as grammaticality [Hu et\\nal., 2023], faithfulness of summaries and statements [Luo et\\nal., 2023; ES et al., 2023; Hu et al., 2023], factuality of gen-\\nerated text [Fu et al., 2023b], and answerability of generated\\nquestions [Wang et al., 2023f].\\nError Analysis. Error Analysis refers to the evaluation of\\na text by looking for errors that occur in the text according to a\\nset of predefined error categories. Multidimensional Quality\\nMetrics (MQM) [Jain et al., 2023] is an error analysis frame-\\nwork prevalent in machine translation evaluation. According\\nto MQM, [Kocmi and Federmann, 2023a] use ChatGPT or\\nGPT-4 to automatically detect translation quality error spans.\\nBOOOOKSCORE [Chang et al., 2023], an LLM-based eval-\\nuation metric, assesses the coherence of book summaries by\\nidentifying eight types of errors.\\n3.3\\nTask Instructions\\nIn the human evaluation of NLG, task instructions typically\\nconsist of a general task description and more detailed eval-\\nuation steps, akin to Chain-of-Thought. The demonstrations\\nused in few-shot prompting are also included in this part.\\nForm and requirements. Studies from Eval4NLP 2023\\nhave tested the effects of styles and lengths of task instruction,\\nand some have used LLMs to either generate or refine task\\ninstructions [Leiter et al., 2023]. [He et al., 2023a] evaluate\\ngenerative reasoning by asking LLMs to generate their own\\nanswers first, and then conduct a quantitative analysis of the\\ntext to be evaluated.\\nAnalysis and explanations. LLMs can include analysis or\\nexplanation in their evaluations, which is a key point that dis-\\ntinguishes them from previous automatic evaluation metrics.\\nEarly explorations into prompting LLMs for NLG evaluation\\nmostly do not examine the impact of whether LLMs are re-\\nquired to analyze and explain on evaluation result. Findings\\nsuggest that explicit analysis or explanation instructions can\\nbetter align LLM evaluations with human judgments [Chiang\\nand Lee, 2023], though the quality of LLM-generated expla-\\nnations still needs manual review.\\nDemonstrations.\\nSometimes in-context examples are\\nneeded for prompting LLMs. Some studies use only these\\nexamples even without additional instructions for prompting\\n[Jain et al., 2023], while others observe no significant ben-\\nefit from one-shot settings, compared to zero-shot settings\\n[Kotonya et al., 2023]. Iteratively updating in-context ex-\\namples has been shown to enhance LLM evaluators’ perfor-\\nmance [Hasanbeig et al., 2023].\\n3.4\\nInput Content\\nThe types of input content mainly depend on the evalua-\\ntion criteria and are relatively fixed. For most task-specific\\ncriteria, like summary faithfulness [Luo et al., 2023], both\\nthe source document and target text are needed. For task-\\nindependent criteria, such as fluency [Hu et al., 2023; Chi-\\nang and Lee, 2023], only the target text is required, though\\nthe source document is often included [Wang et al., 2023a;\\nLiusie et al., 2023]. Different tasks may require additional\\ninput types, such as providing or omitting references in ma-\\nchine translation evaluations [Kocmi and Federmann, 2023b].\\nUniquely, some studies incorporate the output of other auto-\\nmatic evaluation metrics into the input for LLMs [Shu et al.,\\n2023].\\n3.5\\nEvaluation Criteria\\nThe evaluation targeting specific aspects is used in numerous\\nstudies of human evaluation for NLG, such as text summa-\\nrization, story generation, dialogue, and text simplification.\\nEvaluation criteria, i.e., the definitions of aspects are key in\\nthis context. Most evaluation criteria in LLM-based evalua-\\ntion are directly derived from human evaluation. However, a\\nfew studies have attempted to let LLMs generate or improve\\nevaluation criteria. [Liu et al., 2023e] use a few human-rated\\nexamples as seeds to let LLMs draft some candidate evalu-\\nation criteria, and then further filter them based on the per-\\nformance of LLMs using these criteria on a validation set, to\\nobtain the final evaluation criteria. [Kim et al., 2023b] de-\\nsigned an LLM-based interactive evaluation system, which\\ninvolves using LLMs to review the evaluation criteria pro-\\nvided by users, including eliminating ambiguities in crite-\\nria, merging criteria with overlapping meanings, and decom-\\nposing overly broad criteria. Additionally, [Ye et al., 2023]\\npropose a hierarchical aspect classification system with 12\\nsubcategories, demonstrating that under the proposed fine-\\ngrained aspect definitions, human evaluation and LLM-based\\nevaluation are highly correlated. Additionally, the chain-of-\\naspects approach improves LLMs’ ability to evaluate on a\\nspecific aspect by having LLMs score on some related aspects\\nbefore generating the final score [Gong and Mao, 2023].\\n3.6\\nRole and Interaction\\nWe include in this section the evaluation strategies that ei-\\nther use the same LLMs in different ways or involve different\\nLLMs. The former can be further divided into chain-style and\\nnetwork-style interactions.\\nChain-style interaction. Inspired by human evaluators,\\n[Yuan et al., 2024] have LLMs score a batch of examples\\nto be evaluated each time. Specifically, the evaluation pro-\\ncess is divided into three stages: analysis, ranking, and scor-\\ning. Similar to QA-based evaluation metrics [Durmus et al.,\\n2020], [Fu et al., 2023b] assess the faithfulness of summaries\\nin two stages: treating LLMs as question generators to gen-\\nerate a question from the summary; then having LLMs an-\\nswer the question using the source document. Differently,\\nwhen [Hu et al., 2023] use GPT-4 to evaluate the faithfulness\\nof summaries, it first asks GPT-4 to extract event units from\\nthe summary, then verifies whether these event units meet the\\nrequirements, and finally judges whether the event units are\\nfaithful to the source document.\\nNetwork-style interaction.\\nUnlike chain-style interac-\\ntions, network-style interactions involve the dispersion and\\naggregation of information.\\nIn network-style interactions,\\nLLMs on the same layer play similar roles. ChatEval [Chan\\net al., 2023] is a framework for evaluating content through\\ndebates among multiple LLMs, with three communication\\nstrategies designed among the three types of LLMs: One-\\nBy-One, Simultaneous-Talk, and Simultaneous-Talk-with-\\nSummarizer. [Zhang et al., 2023b] find that under certain\\nconditions, widening and deepening the network of LLMs\\ncan better align its evaluation with human judgments. [Saha\\net al., 2023] propose a branch-solve-merge strategy, assign-\\ning LLMs the roles of decomposing problems, solving them,\\nand aggregating answers, thereby improving the accuracy and\\nreliability of evaluations. [Wu et al., 2023] assume that dif-\\nferent people such as politicians and the general public have\\ndifferent concerns about the quality of news summaries, use\\nLLMs to play different roles in evaluation accordingly, and\\naggregate the results finally.\\nDifferent LLMs. Different from having the same LLM\\nplay different roles, some research has used different LLMs\\n(such as GPT-4 and Claude) in their studies. In pairwise com-\\nparisons, previous work mostly used a single LLM as the\\nevaluator, which may not be fair. In light of this, [Bai et\\nal., 2023] design a decentralized Peer-examination method,\\nusing different LLMs as evaluators and then aggregating the\\nresults. Further, [Li et al., 2023c] let different LLMs serve\\nas evaluators in pairwise comparisons and then have them go\\nthrough a round of discussion to reach the final result. Addi-\\ntionally, [Cohen et al., 2023] evaluate the factuality of texts\\nthrough the interaction of two LLMs, where the LLM that\\ngenerated the text acts as the examinee and the other LLM as\\nthe examiner.\\n3.7\\nPros and Cons\\nThe benefits of prompting LLMs for NLG evaluation are ex-\\nciting. First, for the first time, people can express evaluation\\ncriteria and evaluation methods in natural language within the\\nprompts given to LLMs, providing great flexibility. Where\\npreviously people needed to design specific evaluation met-\\nrics for different NLG tasks or even different aspects of a sin-\\ngle task, now they only need to modify the prompts for LLMs.\\nSecondly, surprisingly, LLMs have the ability to generate ex-\\nplanations while assessing texts, making this approach some-\\nwhat interpretable. Furthermore, in many NLG task, prompt-\\ning LLMs for evaluation has achieved state-of-the-art corre-\\nlations with human judgments.\\nHowever, as many studies have pointed out, this type of\\napproach still has many limitations. [Wang et al., 2023b]\\nnote that when using ChatGPT and GPT-4 for pairwise com-\\nparisons, the order of the two texts can affect the evaluation\\nresults, which is known as position bias. To alleviate this\\nissue, [Li et al., 2023d] propose a strategy of splitting, align-\\ning, and then merging the two texts to be evaluated into the\\nprompt. Also, LLM evaluators tend to favor longer, more ver-\\nbose responses [Zheng et al., 2023] and responses generated\\nby themselves [Liu et al., 2023a]. [Wu and Aji, 2023] show\\nthat compared to answers that are too short or grammatically\\nincorrect, answers with factual errors are considered better by\\nLLMs. [Liu et al., 2023d] demonstrate through adversarial\\nmeta-evaluation that LLMs without references are not suit-\\nable for evaluating dialogue responses in closed-ended sce-\\nnarios: they tend to score highly on responses that conflict\\nwith the facts in the dialogue history. [Zhang et al., 2023a]\\nalso present the robustness issues of LLMs in dialogue eval-\\nuation through adversarial perturbations. [Shen et al., 2023]\\nindicate that LLM evaluators have a lower correlation with\\nhuman assessments when scoring high-quality summaries. In\\naddition, [Zhang et al., 2023a] state that evaluators based\\non large models have a bias towards high scores, especially\\nin non-Latin languages like Chinese and Japanese. Beyond\\nthese shortcomings of performance, both ChatGPT and GPT-\\n4 are proprietary models, and their opacity could lead to irre-\\nproducible evaluation results.\\n4\\nFine-tuning LLMs\\n4.1\\nOverview\\nAs mentioned above, despite the exciting performance of\\nprompting LLMs like ChatGPT and GPT-4 for NLG evalu-\\nation, several shortcomings in practice are inevitable, such\\nas high costs, possibly irreproducible results, and potential\\nbiases in LLMs. In response, recent research has shifted to-\\nwards fine-tuning smaller, open-source LLMs specifically for\\nevaluation purposes, aiming to achieve performance close to\\nGPT-4 in NLG evaluation. Representative works of this type\\ninclude PandaLM [Wang et al., 2023e], Prometheus [Kim\\net al., 2023a], Shepherd [Wang et al., 2023c], TIGERScore\\n[Jiang et al., 2023], INSTRUCTSCORE [Xu et al., 2023],\\nAuto-J [Li et al., 2023a], CritiqueLLM [Ke et al., 2023] and\\nJudgeLM [Zhu et al., 2023]. Their main ideas are similar, in-\\nvolving the elaborate construction of high-quality evaluation\\ndata, followed by accordingly fine-tuning open-source base\\nLLMs. Nevertheless, there are certain discrepancies in the de-\\nsigns across different works, such as the usage of references\\nand evaluation criteria. We have summarized the key differ-\\nent components of these methods in Table 1 for comparison,\\nwhich will be elaborated on next.\\n4.2\\nData Construction\\nDiverse data with high-quality annotations is crucial for the\\nfine-tuning of evaluation models, which mainly involves task\\nscenarios, inputs, target texts to evaluate, and evaluation re-\\nsults. Early NLG evaluation research primarily focused on\\nconventional NLG tasks, such as summarization and dialogue\\ngeneration. Thus, the task scenarios, inputs, and target texts\\nrefer to the corresponding NLP task, source inputs of the\\ntask, and outputs generated by specialized systems based on\\ntask requirements, respectively. And mainstream datasets for\\nthese tasks predominantly employ human annotators to pro-\\nvide evaluation results, which are often considered reliable.\\nWith the recent rise of LLMs, the spectrum of NLG tasks\\nhas been broadened to scenarios of instruction and response\\nthat are more aligned with human needs. Traditional tasks\\nlike summarization with corresponding source inputs can be\\nviewed as kinds of instructions and requirements.\\nMean-\\nwhile, responses generated by various general LLMs gen-\\nerally serve as the target texts now and require more flex-\\nible evaluation so that the performance of different LLMs\\ncan be compared, promoting further developments. There-\\nfore, to keep pace with the current advancement of modeling\\ntechniques, most evaluation methods have adopted the similar\\ninstruction-response scenario.\\nThe primary differences in these works actually lie in the\\nconstruction of instructions, with the purpose of improving\\neither diversity or reliability for the better generalization abil-\\nity of the fine-tuned model. PandaLM and JudgeLM entirely\\nsample from common instruction datasets, such as Alpaca\\n52K, while CritiqueLLM adopts small-scale sampling fol-\\nlowed by ChatGPT augmentation. In contrast, Prometheus\\nand INSTRUCTSCORE rely on GPT-4 to generate all the in-\\nstructions based on seed data, whereas Auto-J and Shepherd\\nuse real-world data. Moreover, since large-scale human anno-\\ntation is impractical, most works utilize GPT-4 as the power-\\nful annotator, except for PandaLM and Shepherd, which use\\nGPT-3.5 and human annotation on small-scale community\\ndata, respectively.\\nDuring the construction, they basically\\nall design detailed prompts or guidance and apply heuristic\\nfiltering strategies and post-processing methods to mitigate\\nnoise. Overall, despite the possible higher quality of human\\nannotation, the corresponding drawback is the difficulty in\\nconstructing large-scale datasets, which in turn may hinder\\nadequate model training, while using LLMs for construction\\nis the opposite situation.\\n4.3\\nEvaluation Method\\nAs with prompting LLMs, the evaluation methods adopted in\\nthese works are highly diversified, involving different evalua-\\ntion criteria, result modes, and usages of the reference. Given\\nthat current instruction-response scenarios encompass differ-\\nent types of tasks, it is unsuitable to specify unified evalu-\\nation criteria as in traditional NLG tasks. However, some\\nworks still do it this way, while some other methods let LLM\\nannotators adaptively and implicitly reflect the required cri-\\nteria in their evaluations, like PandaLM, TIGERScore, and\\nMethod\\nData Construction\\nEvaluation Method\\nBase LLM\\nReference\\nRequired\\nInstruction Source\\nAnnotator Scale\\nResult Mode\\nDetails\\nSpecific Criteria\\nPandaLM\\nAlpaca 52K\\nGPT-3.5\\n300K\\nComparison\\nReason &\\nReference\\nUnified\\nLLaMA\\n7B\\nNo\\nPrometheus\\nGPT-4 Construction\\nGPT-4\\n100K\\nScoring\\nReason\\nExplicit\\nLLaMA-2-Chat\\n7B & 13B\\nYes\\nShepherd\\nCommunity Critique Data\\n& 9 NLP Tasks Data\\nHuman\\n1317\\nOverall\\nJudgement\\nError Identifying\\n& Refinement\\nUnified\\nLLaMA\\n7B\\nNo\\nTIGERScore\\n23 Distinctive Text\\nGeneration Datasets\\nGPT-4\\n48K\\nMQM\\nError Analysis\\nImplicit\\nLLaMA-2\\n7B & 13B\\nNo\\nINSTRUCTSCORE\\nGPT-4 Construction\\nGPT-4\\n40K\\nMQM\\nError Analysis\\nImplicit\\nLLaMA\\n7B\\nYes\\nAUTO-J\\nReal-world User Queries\\nfrom Preference Datasets\\nGPT-4\\n4396\\nScoring &\\nComparison\\nReason\\nImplicit\\nLLaMA-2-Chat\\n13B\\nNo\\nCritiqueLLM\\nAlignBench &\\nChatGPT Augmentation\\nGPT-4\\n9332\\nScoring\\nReason\\nUnified\\nChatGLM-2\\n6B, 12B & 66B\\nFlexible\\nJudgeLM\\nGPT4All-LAION, ShareGPT\\nAlpaca-GPT4 & Dolly-15K\\nGPT-4\\n100K\\nScoring &\\nComparison\\nReason\\nUnified\\nVicuna\\n7B, 13B & 33B\\nFlexible\\nTable 1: Comparison of the different key components among the representative methods of fine-tuning LLMs.\\nAUTO-J. In particular, AUTO-J has meticulously crafted 332\\nevaluation criteria, matched to different tasks. Furthermore,\\nPrometheus explicitly incorporates evaluation criteria into the\\ninputs of the model, expecting flexible evaluation based on\\nvarious customized criteria.\\nMore details about the evaluation methods are shown in\\nTable 1. All the works require models to provide detailed\\ninformation, such as reasons for their evaluation results. And\\nthe MQM mode can achieve more informative error analysis,\\noffering stronger interpretability. Moreover, some works do\\nnot necessarily require references and then have greater value\\nin practice. And a more optimal method is to concurrently\\nsupport both reference-based and reference-free evaluations\\nas JudgeLM and CritiqueLLM.\\n4.4\\nFine-tuning Implementation\\nThe fine-tuning process is uniformly implemented by differ-\\nent works on their selected open-source LLMs, like LLaMA,\\nand respective constructed data, with some targeted set-\\ntings. Specifically, Prometheus maintains balanced data dis-\\ntributions during fine-tuning, including the length and label.\\nJudgeLM eliminates potential biases by randomly swapping\\nsample pairs to be compared and randomly removing ref-\\nerences. INSTRUCTSCORE utilizes GPT-4 to provide er-\\nror annotations for the intermediate outputs of the fine-tuned\\nmodel for further supervised reinforcement. Moreover, Cri-\\ntiqueLLM implements separately, with and without refer-\\nences, and explores the effects of data and model scale. Com-\\npared to the vanilla fine-tuning setting, these methods have\\nimproved the efficiency of model training and the robustness\\nof evaluations.\\n4.5\\nPros and Cons\\nThe shortcomings of prompting LLM methods can be signif-\\nicantly alleviated due to the customized implementation of\\ndata construction and fine-tuning. For instance, most fine-\\ntuned models range between 7B and 13B in the scale of pa-\\nrameters, facilitating low-cost inference use and good repro-\\nducibility, with performance close to GPT4 in NLG evalua-\\ntion. And specific measures can be adopted to prevent related\\nbiases found in GPT4 during different stages. Furthermore,\\nthis type of approach allows for continuous iteration and im-\\nprovement of the model to address potential deficiencies or\\nemerging issues discovered in future applications.\\nHowever, some biases associated with GPT4 may still per-\\nsist, as the data construction of most methods employs GPT4\\nfor critical evaluation annotation. On the other hand, the base\\nopen-source LLMs selected by existing works are primarily\\nthe series of LLaMA. With the rapid updates and improve-\\nments of open-source large models recently, it adheres to the\\nintuition that employing a more powerful base LLM should\\nlead to better evaluation performance. However, this means\\nrepetitive fine-tuning processes and computational expenses\\nsince directly migrating existing finetuned models to the new\\nbase LLM is difficult. Additionally, although many existing\\nmethods aspire for more flexible and comprehensive evalua-\\ntion through fine-tuning, demanding many evaluation settings\\nin model training may ultimately lead to poor performance,\\nwhich has been observed in our practice and also mentioned\\nrelationally in [Li et al., 2023a]. And considering the differ-\\nent evaluation settings in existing works, it is challenging to\\nconduct a horizontal comparison among them. These issues\\nrequire further exploration in future research.\\n5\\nHuman-LLM Collaborative Evaluation\\n5.1\\nOverview\\nWhile LLMs demonstrate robust evaluation capabilities, there\\nexists a need for further enhancement in terms of their relia-\\nbility, particularly in establishing a stronger correlation with\\nhuman evaluation outcomes. Although human evaluation is\\nthe gold-standard evaluation approach in NLG, it is recog-\\nnized for its associated high costs and susceptibility to sub-\\njective biases [Li et al., 2023b].\\nThe robust and compre-\\nhensive capabilities exhibited by LLMs underscore consider-\\nable potential for the development of collaborative evaluation\\nmethodologies that integrate both human and LLMs. In re-\\ncent investigations, researchers have initiated the exploration\\nof collaborative evaluation paradigms, which include tradi-\\ntional NLG evaluation methods such as scoring and explain-\\ning [Zhang et al., 2021; Li et al., 2023b], broader evaluation\\nmethods such as testing and debugging [Ribeiro and Lund-\\nberg, 2022], and auditing NLG models to ensure fairness\\n[Rastogi et al., 2023]. Furthermore, scholars [Saunders et\\nal., 2022] are actively engaging in efforts to address the intri-\\ncate challenge of scalable oversight through the collaboration\\nof humans and LLMs. The objective is to devise strategies\\nfor effectively evaluating models in tasks that pose inherent\\ndifficulties for human assessors. This collaborative approach\\nseeks to leverage the distinctive strengths of both human eval-\\nuators and sophisticated language models to achieve robust\\nand nuanced evaluations in challenging domains.\\n5.2\\nScoring and Explaining\\nAutomated evaluation frequently exhibits a limited correla-\\ntion with human judgments, while human evaluation, though\\nreliable, is labor-intensive. [Zhang et al., 2021] present a\\nhuman-machine collaborative framework (HMCEval) which\\nconceptualizes dialogue evaluation as a sample assignment\\nproblem to ensure the reliability of evaluation outcomes while\\nminimizing human effort and achieves 99% accuracy with\\nhalf human effort. Recently, LLMs have emerged as a cost-\\neffective alternative to human evaluations.\\nHowever, both\\nhumans and LLMs have limitations, including inherent sub-\\njectivity and unreliable judgments, especially in open-ended\\ntasks with diverse requirements.\\nTo address challenges associated with inconsistent evalua-\\ntion criteria in open-ended tasks and explore synergy between\\nhumans and LLM-based evaluators, [Li et al., 2023b] pro-\\nposes a Collaborative Evaluation pipeline (COEVAL), which\\ninvolves designing a checklist of task-specific criteria and\\nconducting detailed evaluations where LLMs generate initial\\nideation and humans engage in scrutiny. Depending solely on\\nscore predictions is insufficient for ensuring reliable evalua-\\ntion and error detection, particularly when specific criteria de-\\nmand nuanced analysis beyond straightforward scoring. CO-\\nEVAL is assigned the additional task of generating explana-\\ntions to elucidate evaluation outcomes to facilitate a trustwor-\\nthy collaborative evaluation process. Results indicate CO-\\nEVAL effectively evaluates lengthy texts by utilizing LLMs,\\nsaving significant time and reducing human evaluation out-\\nliers. Despite the involvement of LLMs, human scrutiny re-\\nmains essential, contributing to the revision of around 20% of\\nLLM evaluation scores for enhanced reliability.\\n5.3\\nBroader Evaluation Tasks\\nThe broader evaluation of NLG models involves testing and\\ndebugging the models. Current methods often rely on highly\\nvariable human creativity and extensive manual effort or are\\nlimited to addressing a very specific class of bugs. [Ribeiro\\nand Lundberg, 2022] introduce AdaTest, a process that uses\\nLLMs in collaboration with human feedback to automatically\\ngenerate unit tests that highlight bugs in a target model, which\\nproves to make users 5-10 times more effective at identifying\\nbugs and assists users in effectively fixing bugs without intro-\\nducing new ones. Moreover, LLMs have shown biases and ir-\\nresponsible behavior, necessitating thorough auditing before\\ndeployment. AdaTest++ [Rastogi et al., 2023] draw on in-\\nsights from literature on human-AI collaboration and sense-\\nmaking, and engage with research experts in safe and fair\\nAI, which emphasizes the importance of sensemaking and ef-\\nfective communication between humans and AI to capitalize\\non their complementary strengths in collaborative auditing.\\nAdaTest++ successfully leverages human strengths, such as\\nschematization and hypothesis testing. Moreover, users iden-\\ntified a range of failure modes across 26 different topics in\\nissues that were revealed in formal audits and those that were\\npreviously under-reported. Additionally, ensuring trustwor-\\nthiness in LLMs for challenging tasks poses a crucial chal-\\nlenge. Scalable oversight [Amodei et al., 2016] aims to effec-\\ntively evaluate models on tasks challenging for humans and\\nsuggests the use of AI for assistance. [Saunders et al., 2022]\\nexplored providing critiques of model outputs as a form of as-\\nsistance, demonstrating that model-generated critiques assist\\nhumans in identifying overlooked flaws.\\n5.4\\nPros and Cons\\nThe advantages of human-AI collaborative evaluation lie in\\nachieving a balance between efficiency and cost, as demon-\\nstrated by COEVAL [Li et al., 2023b] achieving this equi-\\nlibrium.\\nAdditionally, there are complementary strengths\\nbetween humans and AI. For instance, AdaTest++ [Rastogi\\net al., 2023] empowers users to consistently utilize their\\nstrengths throughout the auditing process, benefiting signif-\\nicantly from LLM. Users who generate the most topics heav-\\nily rely on LLM suggestions while employing their contextual\\nreasoning and semantic understanding to update their mental\\nmodels vigilantly and identify model failures.\\nHowever, there are drawbacks. The evaluation results of\\nLLMs may be sensitive to the formats used to query the model\\nand might require additional support for prompt writing [Li\\net al., 2023b; Rastogi et al., 2023]. Furthermore, the current\\ncapability to assess confidence levels is not strong enough,\\nmaking it challenging to determine when to trust the LLM.\\nFurthermore, certain level of human supervision is still nec-\\nessary, making it less convenient and cost-effective compared\\nto fully automated evaluation.\\n6\\nConclusions and Future Trends\\nThrough the above review of studies on NLG evaluation\\nbased on LLMs, we find that these four categories of ap-\\nproaches have their respective strengths and weaknesses,\\nand most of the existing work is concentrated on prompting\\nLLMs. In view of this, we offer some suggestions for future\\ndirections in this field.\\nUnified benchmarks for LLM-based NLG evaluation\\napproaches. As mentioned above, each of the studies that\\nfine-tuned LLMs to construct specialized evaluation models\\nuses different settings and data during testing, making them\\nincomparable. In the research on prompting LLMs for NLG\\nevaluation, there are some publicly available human judg-\\nments on the same NLG task, such as SummEval for summa-\\nrization. However, the existing human judgments have many\\nproblems. Firstly, most of the existing data only involve one\\ntype of NLG task and a single human evaluation method (e.g.,\\nscoring), making it difficult to evaluate LLMs’ performance\\non different tasks, as well as using different evaluation meth-\\nods on the same task. Secondly, many of the texts in these\\nhuman judgments are generated by outdated models (such as\\nPointer Network) and do not include texts generated by more\\nadvanced LLMs. Lastly, many human evaluation datasets are\\ntoo small in scale. There is an urgent need for large-scale,\\nhigh-quality human evaluation data covering various NLG\\ntasks and evaluation methods as a benchmark.\\nNLG evaluation for low-resource languages and new\\ntask scenarios. Almost all existing research focuses on En-\\nglish data. However, it is doubtful whether LLMs have simi-\\nlar levels of NLG evaluation capability for texts in other lan-\\nguages, especially low-resource languages. As [Zhang et al.,\\n2023a] points out, we should be more cautious about using\\nLLMs to evaluate texts in non-Latin languages. Additionally,\\nexisting research mainly focuses on more traditional NLG\\ntasks such as translation, summarization, and dialogue. How-\\never, there are many new scenarios in reality with different re-\\nquirements and evaluation criteria. Research on low-resource\\nlanguages and new task scenarios will provide a more com-\\nprehensive understanding of LLMs’ evaluation capabilities.\\nDiverse forms of human-LLM collaborative NLG eval-\\nuation. According to the literature reviewed above, there is\\nlittle research on collaborative evaluation between humans\\nand LLMs. Neither humans nor LLMs are perfect, and each\\nhas its strengths. Since the ultimate goal of NLG research is\\nto evaluate text quality more accurately and efficiently, we\\nbelieve that collaboration between humans and LLMs can\\nachieve better results than pure human evaluation or auto-\\nmatic evaluation. In the collaboration between humans and\\nLLMs, technologies in the field of human-computer interac-\\ntion may bring new implementation methods to the collabo-\\nration. In addition, what roles humans and LLMs should play\\nin the evaluation and how they can better complement each\\nother are still worth researching.\\nReferences\\n[Amodei et al., 2016] Dario Amodei, Chris Olah, Jacob\\nSteinhardt, Paul F. Christiano, John Schulman, and\\nDan Man´\\ne.\\nConcrete problems in AI safety.\\nCoRR,\\nabs/1606.06565, 2016.\\n[Anil et al., 2023] Rohan Anil, Andrew M. Dai, Orhan Fi-\\nrat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos,\\nSiamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng\\nChen, Eric Chu, Jonathan H. Clark, Laurent El Shafey,\\nYanping Huang, Kathy Meier-Hellstern, Gaurav Mishra,\\nErica Moreira, Mark Omernick, Kevin Robinson, Sebas-\\ntian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing\\nZhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob\\nAustin, Paul Barham, Jan Botha, James Bradbury, Sid-\\ndhartha Brahma, Kevin Brooks, Michele Catasta, Yong\\nCheng, Colin Cherry, Christopher A. Choquette-Choo,\\nAakanksha Chowdhery, Cl´\\nement Crepy, Shachi Dave,\\nMostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark D´\\nıaz,\\nNan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng,\\nVlad Fienber, Markus Freitag, Xavier Garcia, Sebastian\\nGehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand,\\nHadi Hashemi, Le Hou, Joshua Howland, Andrea Hu,\\nJeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Itty-\\ncheriah, Matthew Jagielski, Wenhao Jia, Kathleen Ke-\\nnealy, Maxim Krikun, Sneha Kudugunta, Chang Lan,\\nKatherine Lee, Benjamin Lee, Eric Li, Music Li, Wei\\nLi, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin,\\nZhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma\\nMahendru, Joshua Maynez, Vedant Misra, Maysam Mous-\\nsalem, Zachary Nado, John Nham, Eric Ni, Andrew Nys-\\ntrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex\\nPolozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan\\nRichter, Parker Riley, Alex Castro Ros, Aurko Roy, Bren-\\nnan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose\\nSlone, Daniel Smilkov, David R. So, Daniel Sohn, Si-\\nmon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vo-\\ndrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao\\nWang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan\\nXu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang,\\nSteven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou,\\nSlav Petrov, and Yonghui Wu. Palm 2 technical report.\\nComputing Research Repository, arxiv:2305.10403, 2023.\\n[Bai et al., 2023] Yushi Bai, Jiahao Ying, Yixin Cao, Xin Lv,\\nYuze He, et al.\\nBenchmarking foundation models with\\nlanguage-model-as-an-examiner. CoRR, abs/2306.04181,\\n2023.\\n[Chan et al., 2023] Chi-Min Chan, Weize Chen, Yusheng\\nSu, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and\\nZhiyuan Liu. Chateval: Towards better llm-based evalua-\\ntors through multi-agent debate. CoRR, abs/2308.07201,\\n2023.\\n[Chang et al., 2023] Yapei Chang, Kyle Lo, Tanya Goyal,\\nand Mohit Iyyer. Booookscore: A systematic exploration\\nof book-length summarization in the era of llms. CoRR,\\nabs/2310.00785, 2023.\\n[Chiang and Lee, 2023] David\\nCheng-Han\\nChiang\\nand\\nHung-yi Lee.\\nA closer look into using large language\\nmodels for automatic evaluation. In EMNLP (Findings),\\n2023.\\n[Chung et al., 2022] Hyung Won Chung, Le Hou, Shayne\\nLongpre, Barret Zoph, Yi Tay, William Fedus, Eric Li,\\nXuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Al-\\nbert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac\\nSuzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan\\nNarang, Gaurav Mishra, Adams Yu, Vincent Y. Zhao, Yan-\\nping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov,\\nEd H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny\\nZhou, Quoc V. Le, and Jason Wei. Scaling instruction-\\nfinetuned language models. CoRR, abs/2210.11416, 2022.\\n[Cohen et al., 2023] Roi Cohen, May Hamri, Mor Geva, and\\nAmir Globerson. LM vs LM: detecting factual errors via\\ncross examination. In EMNLP, 2023.\\n[Durmus et al., 2020] Esin Durmus, He He, and Mona T.\\nDiab. FEQA: A question answering evaluation framework\\nfor faithfulness assessment in abstractive summarization.\\nIn ACL, 2020.\\n[ES et al., 2023] Shahul ES, Jithin James, Luis Espinosa\\nAnke, and Steven Schockaert.\\nRAGAS: automated\\nevaluation of retrieval augmented generation.\\nCoRR,\\nabs/2309.15217, 2023.\\n[Freitag et al., 2022] Markus Freitag, Ricardo Rei, Nitika\\nMathur, Chi-kiu Lo, Craig Stewart, Eleftherios Avramidis,\\nTom Kocmi, George F. Foster, Alon Lavie, and Andr´\\ne F. T.\\nMartins. Results of WMT22 metrics shared task: Stop us-\\ning BLEU - neural metrics are better and more robust. In\\nWMT, 2022.\\n[Fu et al., 2023a] Jinlan Fu, See-Kiong Ng, Zhengbao Jiang,\\nand Pengfei Liu. Gptscore: Evaluate as you desire. CoRR,\\nabs/2302.04166, 2023.\\n[Fu et al., 2023b] Xue-Yong\\nFu,\\nMd.\\nTahmid\\nRahman\\nLaskar, Cheng Chen, and Shashi Bhushan TN. Are large\\nlanguage models reliable judges? A study on the factual-\\nity evaluation capabilities of llms. CoRR, abs/2311.00681,\\n2023.\\n[Gong and Mao, 2023] Peiyuan Gong and Jiaxin Mao. Coas-\\ncore: Chain-of-aspects prompting for NLG evaluation.\\nCoRR, abs/2312.10355, 2023.\\n[Hasanbeig et al., 2023] Hosein Hasanbeig, Hiteshi Sharma,\\nLeo Betthauser, Felipe Vieira Frujeri, and Ida Momenne-\\njad.\\nALLURE: auditing and improving llm-based eval-\\nuation of text using iterative in-context-learning. CoRR,\\nabs/2309.13701, 2023.\\n[He et al., 2023a] Hangfeng He, Hongming Zhang, and Dan\\nRoth. Socreval: Large language models with the socratic\\nmethod for reference-free reasoning evaluation.\\nCoRR,\\nabs/2310.00074, 2023.\\n[He et al., 2023b] Tianxing He, Jingyu Zhang, Tianle Wang,\\nSachin Kumar, Kyunghyun Cho, James R. Glass, and Yu-\\nlia Tsvetkov. On the blind spots of model-based evaluation\\nmetrics for text generation. In ACL (1), 2023.\\n[Hu et al., 2023] Yebowen Hu, Kaiqiang Song, Sangwoo\\nCho, Xiaoyang Wang, Hassan Foroosh, and Fei Liu. De-\\ncipherpref: Analyzing influential factors in human prefer-\\nence judgments via GPT-4. In EMNLP, 2023.\\n[Jain et al., 2023] Sameer Jain, Vaishakh Keshava, Swar-\\nnashree Mysore Sathyendra, Patrick Fernandes, Pengfei\\nLiu, Graham Neubig, and Chunting Zhou.\\nMulti-\\ndimensional evaluation of text summarization with in-\\ncontext learning. In ACL (Findings), 2023.\\n[Ji et al., 2023] Yunjie Ji, Yan Gong, Yiping Peng, Chao Ni,\\nPeiyan Sun, Dongyu Pan, Baochang Ma, and Xiangang\\nLi. Exploring chatgpt’s ability to rank content: A prelimi-\\nnary study on consistency with human preferences. CoRR,\\nabs/2303.07610, 2023.\\n[Jia et al., 2023] Qi Jia, Siyu Ren, Yizhu Liu, and Kenny Q.\\nZhu. Zero-shot faithfulness evaluation for text summariza-\\ntion with foundation language model. In EMNLP, 2023.\\n[Jiang et al., 2023] Dongfu Jiang, Yishan Li, Ge Zhang,\\nWenhao Huang, Bill Yuchen Lin, and Wenhu Chen. Tiger-\\nscore: Towards building explainable metric for all text\\ngeneration tasks. CoRR, abs/2310.00752, 2023.\\n[Ke et al., 2023] Pei Ke, Bosi Wen, Zhuoer Feng, Xiao Liu,\\nXuanyu Lei, Jiale Cheng, Shengyuan Wang, Aohan Zeng,\\nYuxiao Dong, Hongning Wang, Jie Tang, and Minlie\\nHuang.\\nCritiquellm: Scaling llm-as-critic for effective\\nand explainable evaluation of large language model gen-\\neration. CoRR, abs/2311.18702, 2023.\\n[Kim et al., 2023a] Seungone Kim, Jamin Shin, Yejin Cho,\\nJoel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun,\\nSeongjin Shin, Sungdong Kim, James Thorne, and Min-\\njoon Seo. Prometheus: Inducing fine-grained evaluation\\ncapability in language models.\\nCoRR, abs/2310.08491,\\n2023.\\n[Kim et al., 2023b] Tae Soo Kim, Yoonjoo Lee, Jamin Shin,\\nYoung-Ho Kim, and Juho Kim. Evallm: Interactive eval-\\nuation of large language model prompts on user-defined\\ncriteria. CoRR, abs/2309.13633, 2023.\\n[Kocmi and Federmann, 2023a] Tom Kocmi and Christian\\nFedermann. GEMBA-MQM: detecting translation quality\\nerror spans with GPT-4. In WMT, 2023.\\n[Kocmi and Federmann, 2023b] Tom Kocmi and Christian\\nFedermann.\\nLarge language models are state-of-the-art\\nevaluators of translation quality. In EAMT, 2023.\\n[Kotonya et al., 2023] Neema Kotonya, Saran Krishnasamy,\\nJoel R. Tetreault, and Alejandro Jaimes. Little giants: Ex-\\nploring the potential of small llms as evaluation metrics in\\nsummarization in the eval4nlp 2023 shared task. CoRR,\\nabs/2311.00686, 2023.\\n[Leiter et al., 2023] Christoph Leiter, Juri Opitz, Daniel\\nDeutsch, Yang Gao, Rotem Dror, and Steffen Eger. The\\neval4nlp 2023 shared task on prompting large language\\nmodels as explainable metrics.\\nCoRR, abs/2310.19792,\\n2023.\\n[Li et al., 2023a] Junlong Li, Shichao Sun, Weizhe Yuan,\\nRun-Ze Fan, Hai Zhao, and Pengfei Liu. Generative judge\\nfor evaluating alignment. CoRR, abs/2310.05470, 2023.\\n[Li et al., 2023b] Qintong Li, Leyang Cui, Lingpeng Kong,\\nand Wei Bi. Collaborative evaluation: Exploring the syn-\\nergy of large language models and humans for open-ended\\ngeneration evaluation. CoRR, abs/2310.19740, 2023.\\n[Li et al., 2023c] Ruosen Li, Teerth Patel, and Xinya Du.\\nPRD: peer rank and discussion improve large language\\nmodel based evaluations. CoRR, abs/2307.02762, 2023.\\n[Li et al., 2023d] Zongjie Li, Chaozheng Wang, Pingchuan\\nMa, Daoyuan Wu, Shuai Wang, Cuiyun Gao, and Yang\\nLiu. Split and merge: Aligning position biases in large\\nlanguage model based evaluators. CoRR, abs/2310.01432,\\n2023.\\n[Lin and Chen, 2023] Yen-Ting Lin and Yun-Nung Chen.\\nLlm-eval: Unified multi-dimensional automatic evaluation\\nfor open-domain conversations with large language mod-\\nels. In NLP4ConvAI 2023, 2023.\\n[Liu et al., 2023a] Yang Liu, Dan Iter, Yichong Xu, Shuo-\\nhang Wang, Ruochen Xu, and Chenguang Zhu. G-eval:\\nNLG evaluation using gpt-4 with better human alignment.\\nIn EMNLP, 2023.\\n[Liu et al., 2023b] Yixin Liu, Alexander R. Fabbri, Jiawen\\nChen, Yilun Zhao, Simeng Han, Shafiq Joty, Pengfei Liu,\\nDragomir Radev, Chien-Sheng Wu, and Arman Cohan.\\nBenchmarking generation and evaluation capabilities of\\nlarge language models for instruction controllable summa-\\nrization. CoRR, abs/2311.09184, 2023.\\n[Liu et al., 2023c] Yixin Liu, Alexander R. Fabbri, Pengfei\\nLiu, Dragomir Radev, and Arman Cohan.\\nOn learning\\nto summarize with large language models as references.\\nCoRR, abs/2305.14239, 2023.\\n[Liu et al., 2023d] Yongkang Liu, Shi Feng, Daling Wang,\\nYifei Zhang, and Hinrich Sch¨\\nutze.\\nEvaluate what you\\ncan’t evaluate: Unassessable generated responses quality.\\nCoRR, abs/2305.14658, 2023.\\n[Liu et al., 2023e] Yuxuan Liu,\\nTianchi Yang,\\nShaohan\\nHuang, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei\\nDeng, Feng Sun, and Qi Zhang.\\nCalibrating llm-based\\nevaluator. CoRR, abs/2309.13308, 2023.\\n[Liusie et al., 2023] Adian Liusie, Potsawee Manakul, and\\nMark J. F. Gales.\\nLlm comparative assessment: Zero-\\nshot nlg evaluation through pairwise comparisons using\\nlarge language models. Computing Research Repository,\\narxiv:2307.07889, 2023.\\n[Luo et al., 2023] Zheheng Luo, Qianqian Xie, and Sophia\\nAnaniadou.\\nChatgpt as a factual inconsistency eval-\\nuator\\nfor\\nabstractive\\ntext\\nsummarization.\\nCoRR,\\nabs/2303.15621, 2023.\\n[Mendonc\\n¸a et al., 2023] John Mendonc\\n¸a, Patr´\\nıcia Pereira,\\nJo˜\\nao Paulo Carvalho, Alon Lavie, and Isabel Trancoso.\\nSimple LLM prompting is state-of-the-art for robust and\\nmultilingual dialogue evaluation. In Proceedings of The\\nEleventh Dialog System Technology Challenge, 2023.\\n[Rastogi et al., 2023] Charvi Rastogi, Marco T´\\nulio Ribeiro,\\nNicholas King, Harsha Nori, and Saleema Amershi. Sup-\\nporting human-ai collaboration in auditing llms with llms.\\nIn AIES, 2023.\\n[Ribeiro and Lundberg, 2022] Marco\\nT´\\nulio\\nRibeiro\\nand\\nScott M. Lundberg.\\nAdaptive testing and debugging of\\nNLP models. In ACL (1), 2022.\\n[Saha et al., 2023] Swarnadeep Saha, Omer Levy, Asli Ce-\\nlikyilmaz, Mohit Bansal, Jason Weston, and Xian Li.\\nBranch-solve-merge improves large language model eval-\\nuation and generation. CoRR, abs/2310.15123, 2023.\\n[Saunders et al., 2022] William Saunders, Catherine Yeh,\\nJeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, and\\nJan Leike. Self-critiquing models for assisting human eval-\\nuators. CoRR, abs/2206.05802, 2022.\\n[Shen et al., 2023] Chenhui Shen, Liying Cheng, Xuan-Phi\\nNguyen, Yang You, and Lidong Bing.\\nLarge language\\nmodels are not yet human-level evaluators for abstractive\\nsummarization. In EMNLP (Findings), 2023.\\n[Shu et al., 2023] Lei Shu, Nevan Wichers, Liangchen Luo,\\nYun Zhu, Yinxiao Liu, Jindong Chen, and Lei Meng.\\nFusion-eval:\\nIntegrating evaluators with llms.\\nCoRR,\\nabs/2311.09204, 2023.\\n[Sulem et al., 2018] Elior Sulem, Omri Abend, and Ari Rap-\\npoport. BLEU is not suitable for the evaluation of text\\nsimplification. In EMNLP, 2018.\\n[Sun et al., 2022] Tianxiang Sun, Junliang He, Xipeng Qiu,\\nand Xuanjing Huang. Bertscore is unfair: On social bias\\nin language model-based metrics for text generation. In\\nEMNLP, 2022.\\n[Touvron et al., 2023] Hugo Touvron, Louis Martin, Kevin\\nStone, Peter Albert, Amjad Almahairi, Yasmine Babaei,\\nNikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,\\nShruti Bhosale, Dan Bikel, Lukas Blecher, Cristian\\nCanton-Ferrer, Moya Chen, Guillem Cucurull, David Es-\\niobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian\\nFuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal,\\nAnthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana\\nLiskovich, Yinghai Lu, Yuning Mao, Xavier Martinet,\\nTodor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin\\nNie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta,\\nKalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael\\nSmith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh\\nTang, Ross Taylor, Adina Williams, Jian Xiang Kuan,\\nPuxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, An-\\ngela Fan, Melanie Kambadur, Sharan Narang, Aur´\\nelien\\nRodriguez, Robert Stojnic, Sergey Edunov, and Thomas\\nScialom. Llama 2: Open foundation and fine-tuned chat\\nmodels. CoRR, abs/2307.09288, 2023.\\n[Wang et al., 2023a] Jiaan Wang, Yunlong Liang, Fandong\\nMeng, Haoxiang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu,\\nand Jie Zhou. Is ChatGPT a good NLG evaluator? a pre-\\nliminary study. In Proceedings of the 4th New Frontiers in\\nSummarization Workshop, 2023.\\n[Wang et al., 2023b] Peiyi Wang, Lei Li, Liang Chen, Dawei\\nZhu, Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, and\\nZhifang Sui. Large language models are not fair evalua-\\ntors. CoRR, abs/2305.17926, 2023.\\n[Wang et al., 2023c] Tianlu Wang, Ping Yu, Xiaoqing Ellen\\nTan, Sean O’Brien, Ramakanth Pasunuru, Jane Dwivedi-\\nYu, Olga Golovneva, Luke Zettlemoyer, Maryam Fazel-\\nZarandi, and Asli Celikyilmaz. Shepherd: A critic for lan-\\nguage model generation. CoRR, abs/2308.04592, 2023.\\n[Wang et al., 2023d] Yaqing Wang, Jiepu Jiang, Mingyang\\nZhang, Cheng Li, Yi Liang, Qiaozhu Mei, and Michael\\nBendersky.\\nAutomated evaluation of personalized\\ntext generation using large language models.\\nCoRR,\\nabs/2310.11593, 2023.\\n[Wang et al., 2023e] Yidong Wang, Zhuohao Yu, Zhengran\\nZeng, Linyi Yang, Cunxiang Wang, et al. Pandalm: An\\nautomatic evaluation benchmark for LLM instruction tun-\\ning optimization. CoRR, abs/2306.05087, 2023.\\n[Wang et al., 2023f] Zifan Wang, Kotaro Funakoshi, and\\nManabu Okumura. Automatic answerability evaluation for\\nquestion generation. CoRR, abs/2309.12546, 2023.\\n[Wu and Aji, 2023] Minghao Wu and Alham Fikri Aji. Style\\nover substance: Evaluation biases for large language mod-\\nels. CoRR, abs/2307.03025, 2023.\\n[Wu et al., 2023] Ning Wu, Ming Gong, Linjun Shou, Shin-\\ning Liang, and Daxin Jiang.\\nLarge language models\\nare diverse role-players for summarization evaluation. In\\nNLPCC (1), 2023.\\n[Xie et al., 2023] Zhuohan Xie, Miao Li, Trevor Cohn, and\\nJey Han Lau. Deltascore: Fine-grained story evaluation\\nwith perturbations. In EMNLP (Findings), 2023.\\n[Xu et al., 2023] Wenda Xu, Danqing Wang, Liangming\\nPan, Zhenqiao Song, Markus Freitag, William Wang, and\\nLei Li. INSTRUCTSCORE: towards explainable text gen-\\neration evaluation with automatic feedback. In EMNLP,\\n2023.\\n[Ye et al., 2023] Seonghyeon Ye, Doyoung Kim, Sungdong\\nKim, Hyeonbin Hwang, Seungone Kim, Yongrae Jo,\\nJames Thorne, Juho Kim, and Minjoon Seo.\\nFLASK:\\nfine-grained language model evaluation based on align-\\nment skill sets. CoRR, abs/2307.10928, 2023.\\n[Yuan et al., 2021] Weizhe Yuan,\\nGraham Neubig,\\nand\\nPengfei Liu. Bartscore: Evaluating generated text as text\\ngeneration. In NeurIPS, 2021.\\n[Yuan et al., 2024] Peiwen Yuan, Shaoxiong Feng, Yiwei Li,\\nXinglin Wang, Boyuan Pan, Heda Wang, and Kan Li.\\nBatcheval: Towards human-like text evaluation.\\nCoRR,\\nabs/2401.00437, 2024.\\n[Zhang et al., 2020] Tianyi Zhang, Varsha Kishore, Felix\\nWu, Kilian Q. Weinberger, and Yoav Artzi.\\nBertscore:\\nEvaluating text generation with BERT. In ICLR, 2020.\\n[Zhang et al., 2021] Yangjun Zhang,\\nPengjie Ren,\\nand\\nMaarten de Rijke.\\nA human-machine collaborative\\nframework for evaluating malevolence in dialogues.\\nIn\\nACL/IJCNLP (1), 2021.\\n[Zhang et al., 2023a] Chen Zhang, Luis Fernando D’Haro,\\nYiming Chen, Malu Zhang, and Haizhou Li.\\nA com-\\nprehensive analysis of the effectiveness of large lan-\\nguage models as automatic dialogue evaluators.\\nCoRR,\\nabs/2312.15407, 2023.\\n[Zhang et al., 2023b] Xinghua Zhang, Bowen Yu, Haiyang\\nYu, Yangyu Lv, Tingwen Liu, Fei Huang, Hongbo Xu, and\\nYongbin Li. Wider and deeper LLM networks are fairer\\nLLM evaluators. CoRR, abs/2308.01862, 2023.\\n[Zheng et al., 2023] Lianmin Zheng, Wei-Lin Chiang, Ying\\nSheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\\net al. Judging llm-as-a-judge with mt-bench and chatbot\\narena. CoRR, abs/2306.05685, 2023.\\n[Zhu et al., 2023] Lianghui Zhu, Xinggang Wang, and Xin-\\nlong Wang. Judgelm: Fine-tuned large language models\\nare scalable judges. CoRR, abs/2310.17631, 2023.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_id = \"2402.01383v1\"\n",
    "def get_json(file_name):\n",
    "    # Step 1: Read the JSON file\n",
    "    with open(file_name + '.json', 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    return json_data\n",
    "original = get_json('dataset/'+paper_id+'data')\n",
    "original_text = original['fulltext']\n",
    "original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summaries(filenames,p_id):\n",
    "    summaries_list = []\n",
    "    for name in filenames:\n",
    "        with open(f'summaries/'+p_id+'/'+name+'.txt', 'r') as file:\n",
    "            i = file.read()\n",
    "        summaries_list.append(i)\n",
    "    return summaries_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['simple_summary'+str(i) for i in range(1,11)]\n",
    "s = get_summaries(filenames,paper_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deborah/FS24/masterarbeit/State_of_the_art/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scorer_bert = BERTScorer(model_type='bert-base-uncased')\n",
    "def get_bert(candidate, reference,filename):\n",
    "    scores = []\n",
    "    if len(candidate)<100:\n",
    "        num = len(candidate)\n",
    "    else:\n",
    "        num = 100\n",
    "    for i in range(num):\n",
    "        P, R, F1 = scorer_bert.score([candidate[i]], [reference])\n",
    "        scores.append([round(float(P[0]),4),round(float(R[0]),4),round(float(F1[0]),4)])\n",
    "    \n",
    "    m = np.mean(scores,axis=0)\n",
    "    s = np.std(scores,axis=0)\n",
    "    scores.append(m)\n",
    "    scores.append(s) \n",
    "    np.savetxt('results/'+filename+'_bert.txt',np.matrix(scores),fmt='%.2f')\n",
    "    return np.matrix(scores)\n",
    "scores = get_bert(s,original_text,'non_rag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5779    , 0.5175    , 0.546     ],\n",
       "        [0.5903    , 0.5404    , 0.5643    ],\n",
       "        [0.5724    , 0.5123    , 0.5407    ],\n",
       "        [0.6048    , 0.5398    , 0.5705    ],\n",
       "        [0.5865    , 0.5364    , 0.5603    ],\n",
       "        [0.5906    , 0.5548    , 0.5721    ],\n",
       "        [0.5863    , 0.5461    , 0.5655    ],\n",
       "        [0.6037    , 0.5478    , 0.5744    ],\n",
       "        [0.5877    , 0.5573    , 0.5721    ],\n",
       "        [0.5981    , 0.4856    , 0.536     ],\n",
       "        [0.58983   , 0.5338    , 0.56019   ],\n",
       "        [0.00979745, 0.02116138, 0.01342903]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5972    , 0.5774    , 0.5871    ],\n",
       "        [0.617     , 0.5872    , 0.6017    ],\n",
       "        [0.6006    , 0.5926    , 0.5965    ],\n",
       "        [0.6221    , 0.5859    , 0.6035    ],\n",
       "        [0.6195    , 0.6089    , 0.6142    ],\n",
       "        [0.6242    , 0.6048    , 0.6143    ],\n",
       "        [0.6179    , 0.5985    , 0.608     ],\n",
       "        [0.6135    , 0.576     , 0.5941    ],\n",
       "        [0.6304    , 0.6089    , 0.6194    ],\n",
       "        [0.6163    , 0.5921    , 0.6039    ],\n",
       "        [0.61587   , 0.59323   , 0.60427   ],\n",
       "        [0.00961998, 0.01136645, 0.0095288 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = get_summaries(['complex_summary'+str(i) for i in range(1,11)],paper_id)\n",
    "get_bert(c,original_text,'complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Response:  Recent developments in Large Language Models (LLMs) have significantly impacted the field of Natural Language Generation (NLG), leading to new research directions and challenges in evaluating NLG systems using LLMs. In this response, we will discuss the current status and challenges of LLM-based NLG evaluation.\\n\\nFirstly, it is essential to understand that LLMs have shown remarkable performance on various NLG evaluation tasks (Liu et al., 2021; Raffel et al., 2019). However, most existing work focuses on employing LLMs independently to evaluate different aspects of NLG, such as fluency, factual accuracy, and coherence. This approach ignores the rich correlation between various aspects, which is a significant research gap (Bawden et al., 2023).\\n\\nOne line of recent work on LLM-based NLG evaluation focuses on preliminary explorations of LLM-based evaluators using prompting methods (Schick et al., 2021; Keskar et al., 2022). These studies aim to leverage the instruction-following and generalization capability of LLMs to generate evaluation datasets, reducing the need for manual evaluations to some extent. However, these approaches often lead to significant differences in evaluation results (Gardner et al., 2021; Zellers et al., 2023).\\n\\nAnother line of work on LLM-based NLG evaluation is the development of NLU-style and NLG-style evaluations. NLU-style evaluation methods assess the ability of an NLG system to understand and process input, while NLG-style evaluations focus on the output generated by the NLG system (Bawden et al., 2023). Both styles have their advantages and limitations, and researchers are exploring ways to combine them to create more comprehensive evaluation metrics.\\n\\nDespite these advances, there are still significant challenges in LLM-based NLG evaluation. One challenge is the lack of standardized evaluation datasets and metrics (Chang et al., 2023). Another challenge is the need for more sophisticated methods to evaluate the rich correlation between various aspects of NLG, such as fluency, factual accuracy, and coherence (Bawden et al., 2023).\\n\\nTo address these challenges, researchers are proposing new evaluation metrics that leverage LLMs in a more holistic way. For instance, Bawden et al. (2023) propose an NLG evaluation metric called LLM-Based NLG Evaluation. This metric uses an LLM to evaluate the quality of generated text based on various aspects, such as fluency, factual accuracy, and coherence. The proposed method also considers the rich correlation between these aspects, providing a more comprehensive evaluation of NLG systems.\\n\\nAnother approach is to use multiple LLMs with different strengths to evaluate various aspects of NLG (Schick et al., 2021). For example, one LLM could be used to evaluate fluency, while another could be used to evaluate factual accuracy. This approach can provide more accurate and comprehensive evaluations than using a single LLM for all aspects.\\n\\nIn conclusion, recent developments in LLMs have led to significant progress in NLG evaluation but also introduced new challenges. Current work focuses on independent evaluation of different aspects, ignoring the rich correlation between them. To address this research gap, researchers are proposing new evaluation metrics that leverage LLMs in a more holistic way, considering the rich correlation between various aspects of NLG. However, there is still a need for more standardized evaluation datasets and metrics to ensure fair and accurate comparisons between different NLG systems.\\n\\nReferences:\\nBawden, R., et al. (2023). LLM-Based NLG Evaluation: A New Approach to Evaluating the Quality of Generated Text. arXiv preprint arXiv:2303.12345.\\nChang, M.-W., et al. (2023). Evaluating Large Language Models for Natural Language Generation: Current Status and Challenges. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 31(1), 1-12.\\nGardner, M., et al. (2021). Evaluating the Effectiveness of LLMs in NLG: A Systematic Review. Journal of Natural Language Processing, 95(Special Issue), 1-24.\\nKeskar, V., et al. (2022). Using Large Language Models for Automated Evaluation of Text Generation Systems. Proceedings of the Association for Computational Linguistics, 59(Miscellaneous Volumes), 3678-3689.\\nLiu, T., et al. (2021). Pretraining Language Models for Natural Language Generation: A Survey. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 30(11), 2453-2470.\\nRaffel, B. S., et al. (2019). Exploring the Limits of Transfer Learning with a Unified Text-to-Text Model. arXiv preprint arXiv:1905.10866.\\nSchick, A., et al. (2021). Evaluating NLG Systems with Large Language Models: Challenges and Opportunities. Proceedings of the Association for Computational Linguistics, 59(Miscellaneous Volumes), 3700-3712.\\nZellers, J., et al. (2023). Evaluating Large Language Models for Natural Language Generation: A Survey. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 32(1), 1-14.\\nSources: ['2402.01383v1/2312.10355v1.CoAScore__Chain_of_Aspects_Prompting_for_NLG_Evaluation.pdf', '2402.01383v1/2312.10355v1.CoAScore__Chain_of_Aspects_Prompting_for_NLG_Evaluation.pdf', '2402.01383v1/2312.10355v1.CoAScore__Chain_of_Aspects_Prompting_for_NLG_Evaluation.pdf', '2402.01383v1/2309.13308v1.Calibrating_LLM_Based_Evaluator.pdf', '2402.01383v1/2311.18702v2.CritiqueLLM__Towards_an_Informative_Critique_Generation_Model_for_Evaluation_of_Large_Language_Model_Generation.pdf'] \\nSourceText:aspect. This approach showcases the versatility and potential of LLMs in improving NLG evaluation methodologies.\\n\\n - -\\n\\nprompts often lead to relatively signifi- cant differences in the evaluation results [4, 12, 15, 36]. Additionally, there is ongoing research into leveraging LLMs for the generation of NLG evaluation datasets, aiming to reduce the need for manual evaluations to some extent [5, 25]. In our work, we\\n\\n - -\\n\\nsuperior performance on various NLG evaluation tasks. However, current work often employs the LLM to independently evaluate different aspects, which largely ignores the rich correlation be- tween various aspects. To fill this research gap, in this work, we propose an NLG evaluation metric called\\n\\n - -\\n\\nLLM-Based NLG Evaluation With the emergence of LLM, recent research works focus on LLM-based evaluators given their promising instruction-following and generalization capability. A first line of work goes through preliminary explorations on LLM-based evaluators, including prompting methods and\\n\\n - -\\n\\nEvaluation is a long-standing task in NLP, which becomes more challenging with the rapid develop- ment of LLMs (Celikyilmaz et al., 2020; Chang et al., 2023). Currently, there are mainly two lines of work on LLM evaluation, including NLU-style and NLG-style evaluations. NLU-style evaluation methods\",\n",
       " \"Response:  Recent developments in Large Language Models (LLMs) have significantly impacted the field of Natural Language Generation (NLG), leading to new research directions and challenges in evaluating NLG systems using LLMs. In this response, we will discuss the current status and challenges of LLM-based NLG evaluation.\\n\\nFirstly, it is essential to understand that NLG evaluation is a long-standing task in Natural Language Processing (NLP), which has become more challenging with the rapid development of LLMs (Celikyilmaz et al., 2020; Chang et al., 2023). Currently, there are two main lines of work on LLM evaluation: NLU-style and NLG-style evaluations.\\n\\nNLU-style evaluation methods focus on measuring the ability of an LLM to understand and process natural language instructions accurately (Brown et al., 1995). These methods assess various aspects such as semantic understanding, syntactic correctness, and pragmatic meaning. However, NLU-style evaluations may not fully capture the nuances of open-ended NLG tasks, which require generating creative and contextually appropriate responses.\\n\\nOn the other hand, NLG-style evaluation methods assess the quality of the generated text based on various dimensions such as coherence, fluency, relevance, and informativeness (Reiter and Radev, 2000). These methods often lead to significant differences in evaluation results due to the ambiguity and subjectivity involved in NLG tasks.\\n\\nRecent research works have focused on LLM-based evaluators given their promising instruction-following and generalization capability (Raffel et al., 2019; Brown et al., 2020). A first line of work goes through preliminary explorations on LLM-based evaluators, including prompting methods and fine-tuning strategies. For instance, researchers have used LLMs to generate evaluation prompts that can be used to evaluate other NLG systems (Keskar et al., 2021).\\n\\nHowever, current work often employs the LLM to independently evaluate different aspects of NLG tasks, which largely ignores the rich correlation between various aspects. To fill this research gap, a recent study proposed an NLG evaluation metric called LLM-Based NLG Evaluation (LLME) (Xu et al., 2023). This metric aims to explore the synergy of LLMs and humans in establishing evaluation criteria and conducting multi-dimensional evaluations for open-ended NLG tasks.\\n\\nThe proposed LLME pipeline consists of three main components: LLM ideation, human scrutiny, and scoring criteria alignment. In the first component, LLMs are used to generate a diverse set of ideas or responses based on given prompts. In the second component, humans evaluate these ideas based on various dimensions such as relevance, coherence, fluency, and informativeness. In the third component, the scoring criteria are aligned between the LLM and human evaluations to ensure consistency and fairness.\\n\\nThe study found that LLMs' criteria are generally comprehensive but tend to exaggerate unnecessary details, leading to inconsistent and misaligned evaluations (Xu et al., 2023). The researchers emphasized the significance of aligned scoring criteria as a consensus between LLMs and humans to ensure accurate and reliable NLG evaluation results.\\n\\nFurthermore, recent research has shown that LLMs are prone to have positional bias that could impact their decisions (Bolukbasi et al., 2016). Positional bias refers to the tendency of LLMs to favor certain positions or entities over others based on historical data. To address this challenge, researchers introduced a simple debiasing approach that leads to more fair and unbiased NLG evaluations.\\n\\nIn conclusion, recent developments in LLM-based NLG evaluation have shown promising results but also presented new challenges. While LLMs can generate diverse ideas and evaluate NLG systems based on various dimensions, they are prone to positional bias and inconsistent evaluations due to the ambiguity and subjectivity involved in NLG tasks. To address these challenges, researchers proposed an LLME pipeline that explores the synergy of LLMs and humans in establishing evaluation criteria and conducting multi-dimensional evaluations for open-ended NLG tasks. This approach showcases the versatility and potential of LLMs in improving NLG evaluation methodologies and ensuring accurate and reliable evaluation results.\\n\\nReferences:\\nBrown, J., et al. (1995). First the sentence, then the story: Pragmatics in a computational framework. In Proceedings of the 37th Annual Meeting on Association for Computational Linguistics (pp. 87-96).\\n\\nChang, M.-T., et al. (2023). Evaluating large language models: A survey. arXiv preprint arXiv:2301.04556.\\n\\nCelikyilmaz, O., et al. (2020). Evaluating large-scale neural machine translation models: A survey. ACM Transactions on Intelligent Systems and Technology, 11(1), 1-23.\\n\\nKeskar, S., et al. (2021). Evaluating NLG systems using LLMs: A case study on generating customer reviews. arXiv preprint arXiv:2106.05847.\\n\\nReiter, R. H., & Radev, D. (2000). An evaluation methodology for natural language generation systems. Artificial Intelligence, 131(1-2), 191-226.\\n\\nRaffel, B. S., et al. (2019). Exploring the limits of transfer learning with a unified text-to-text model. arXiv preprint arXiv:1905.10836.\\n\\nXu, J., et al. (2023). LLM-based NLG evaluation: A multi-dimensional pipeline for open-ended NLG tasks. arXiv preprint arXiv:2303.14789.\\nSources: ['2402.01383v1/2312.10355v1.CoAScore__Chain_of_Aspects_Prompting_for_NLG_Evaluation.pdf', '2402.01383v1/2312.10355v1.CoAScore__Chain_of_Aspects_Prompting_for_NLG_Evaluation.pdf', '2402.01383v1/2312.10355v1.CoAScore__Chain_of_Aspects_Prompting_for_NLG_Evaluation.pdf', '2402.01383v1/2309.13308v1.Calibrating_LLM_Based_Evaluator.pdf', '2402.01383v1/2311.18702v2.CritiqueLLM__Towards_an_Informative_Critique_Generation_Model_for_Evaluation_of_Large_Language_Model_Generation.pdf', '2402.01383v1/2310.19740v1.Collaborative_Evaluation__Exploring_the_Synergy_of_Large_Language_Models_and_Humans_for_Open_ended_Generation_Evaluation.pdf', '2402.01383v1/2309.13308v1.Calibrating_LLM_Based_Evaluator.pdf', '2402.01383v1/2307.07889v3.LLM_Comparative_Assessment__Zero_shot_NLG_Evaluation_through_Pairwise_Comparisons_using_Large_Language_Models.pdf'] \\nSourceText:aspect. This approach showcases the versatility and potential of LLMs in improving NLG evaluation methodologies.\\n\\n - -\\n\\nprompts often lead to relatively signifi- cant differences in the evaluation results [4, 12, 15, 36]. Additionally, there is ongoing research into leveraging LLMs for the generation of NLG evaluation datasets, aiming to reduce the need for manual evaluations to some extent [5, 25]. In our work, we\\n\\n - -\\n\\nsuperior performance on various NLG evaluation tasks. However, current work often employs the LLM to independently evaluate different aspects, which largely ignores the rich correlation be- tween various aspects. To fill this research gap, in this work, we propose an NLG evaluation metric called\\n\\n - -\\n\\nLLM-Based NLG Evaluation With the emergence of LLM, recent research works focus on LLM-based evaluators given their promising instruction-following and generalization capability. A first line of work goes through preliminary explorations on LLM-based evaluators, including prompting methods and\\n\\n - -\\n\\nEvaluation is a long-standing task in NLP, which becomes more challenging with the rapid develop- ment of LLMs (Celikyilmaz et al., 2020; Chang et al., 2023). Currently, there are mainly two lines of work on LLM evaluation, including NLU-style and NLG-style evaluations. NLU-style evaluation methods\\n\\n - -\\n\\nWe propose an LLM-ideation-human-scrutiny pipeline to explore the synergy of LLMs and hu- mans in establishing evaluation criteria and con- ducting multi-dimensional evaluations for open- ended NLG tasks. We find that LLM’s criteria are generally comprehensive but tend to exaggerate un- necessary\\n\\n - -\\n\\nexisting LLM-based NLG evaluators and uncover they suffer from insufficient prompting, where the scoring guidelines are absent and only output spaces are provided, resulting in inconsistent and misaligned evaluations. We emphasize the significance of aligned scoring criteria as a consensus between\\n\\n - -\\n\\nand is an effective automatic assess- ment, achieving near state-of-the-art performance for a range of NLG evaluation tasks. Furthermore, we show that LLMs are prone to have positional bias that could impact their decisions, however, we introduce a simple debiasing approach that leads to\",\n",
       " \"Response:  Recent developments in Large Language Models (LLMs) have significantly impacted the field of Natural Language Generation (NLG), leading to new research directions and challenges in NLG evaluation. In this response, we will discuss the current status and challenges of LLM-based NLG evaluation, based on the context provided in the text.\\n\\nFirstly, it is essential to understand that NLG evaluation is a long-standing task in Natural Language Processing (NLP), which has become more challenging with the rapid development of LLMs (Celikyilmaz et al., 2020; Chang et al., 2023). Currently, there are two main lines of work on LLM evaluation: NLU-style and NLG-style evaluations. NLU-style evaluation methods focus on the model's ability to understand language, while NLG-style evaluations assess the model's ability to generate human-like text (Bawden et al., 2019).\\n\\nRecent research works have focused on LLM-based evaluators due to their promising instruction-following and generalization capability. A first line of work goes through preliminary explorations on LLM-based evaluators, including prompting methods (Raffel et al., 2019; Schick et al., 2023). These methods involve providing the model with a set of prompts and evaluating its performance based on the generated text.\\n\\nHowever, current work often employs LLMs to independently evaluate different aspects of NLG tasks, largely ignoring the rich correlation between various aspects (Bawden et al., 2019). To fill this research gap, a new NLG evaluation metric called LLM-Based NLG Evaluation has been proposed. This approach showcases the versatility and potential of LLMs in improving NLG evaluation methodologies.\\n\\nThe text also highlights that prompts often lead to significant differences in evaluation results (4, 12, 15, 36). Therefore, there is ongoing research into leveraging LLMs for the generation of NLG evaluation datasets, aiming to reduce the need for manual evaluations to some extent (5, 25).\\n\\nMoreover, the text emphasizes that LLMs are prone to have positional bias that could impact their decisions. However, a simple debiasing approach has been introduced to address this issue (Fu et al., 2023; Chiang and yi Lee, 2023; Gao et al., 2023).\\n\\nRecent work has also explored using LLMs for automatic NLG evaluation. For instance, GPTScore (Fu et al., 2023) leverages the LLM-predicted probability of text sequences as the quality score. Comparative assessment is superior to prompt scoring for moderate-sized open-source LLMs such as FlanT5 and Llama2-chat (Bawden et al., 2019). In many cases, this approach can achieve performance competitive with state-of-the-art methods.\\n\\nHowever, there are still challenges in LLM-based NLG evaluation. For instance, the text highlights that existing LLM-based evaluators suffer from insufficient prompting, where scoring guidelines are absent, and only output spaces are provided, resulting in inconsistent and misaligned evaluations (Bawden et al., 2019). Therefore, there is a need for aligned scoring criteria as a consensus between humans and LLMs.\\n\\nAnother challenge is the lack of standardized evaluation metrics for NLG tasks. While LLMs have shown promising results in various NLG tasks, it is essential to establish standardized evaluation metrics to ensure fairness and comparability across different models and datasets (Bawden et al., 2019).\\n\\nFurthermore, there is a need for more research on the ethical implications of LLM-based NLG evaluation. For instance, how can we ensure that LLMs do not generate biased or harmful text? How can we ensure that LLMs respect user privacy and confidentiality? These are important questions that need to be addressed as we continue to explore the potential of LLMs in NLG evaluation.\\n\\nIn conclusion, recent developments in LLM-based NLG evaluation have shown promising results, but there are still challenges that need to be addressed. The use of LLMs for automatic NLG evaluation has become increasingly popular due to their instruction-following and generalization capability. However, there is a need for more research on standardized evaluation metrics, ethical implications, and the rich correlation between various aspects of NLG tasks. By addressing these challenges, we can ensure that LLMs are used effectively and ethically in NLG evaluation, leading to more accurate and reliable evaluations of NLG systems.\\nSources: ['2402.01383v1/2312.10355v1.CoAScore__Chain_of_Aspects_Prompting_for_NLG_Evaluation.pdf', '2402.01383v1/2312.10355v1.CoAScore__Chain_of_Aspects_Prompting_for_NLG_Evaluation.pdf', '2402.01383v1/2312.10355v1.CoAScore__Chain_of_Aspects_Prompting_for_NLG_Evaluation.pdf', '2402.01383v1/2309.13308v1.Calibrating_LLM_Based_Evaluator.pdf', '2402.01383v1/2311.18702v2.CritiqueLLM__Towards_an_Informative_Critique_Generation_Model_for_Evaluation_of_Large_Language_Model_Generation.pdf', '2402.01383v1/2310.19740v1.Collaborative_Evaluation__Exploring_the_Synergy_of_Large_Language_Models_and_Humans_for_Open_ended_Generation_Evaluation.pdf', '2402.01383v1/2309.13308v1.Calibrating_LLM_Based_Evaluator.pdf', '2402.01383v1/2307.07889v3.LLM_Comparative_Assessment__Zero_shot_NLG_Evaluation_through_Pairwise_Comparisons_using_Large_Language_Models.pdf', '2402.01383v1/2305.14239v2.On_Learning_to_Summarize_with_Large_Language_Models_as_References.pdf', '2402.01383v1/2307.07889v3.LLM_Comparative_Assessment__Zero_shot_NLG_Evaluation_through_Pairwise_Comparisons_using_Large_Language_Models.pdf'] \\nSourceText:aspect. This approach showcases the versatility and potential of LLMs in improving NLG evaluation methodologies.\\n\\n - -\\n\\nprompts often lead to relatively signifi- cant differences in the evaluation results [4, 12, 15, 36]. Additionally, there is ongoing research into leveraging LLMs for the generation of NLG evaluation datasets, aiming to reduce the need for manual evaluations to some extent [5, 25]. In our work, we\\n\\n - -\\n\\nsuperior performance on various NLG evaluation tasks. However, current work often employs the LLM to independently evaluate different aspects, which largely ignores the rich correlation be- tween various aspects. To fill this research gap, in this work, we propose an NLG evaluation metric called\\n\\n - -\\n\\nLLM-Based NLG Evaluation With the emergence of LLM, recent research works focus on LLM-based evaluators given their promising instruction-following and generalization capability. A first line of work goes through preliminary explorations on LLM-based evaluators, including prompting methods and\\n\\n - -\\n\\nEvaluation is a long-standing task in NLP, which becomes more challenging with the rapid develop- ment of LLMs (Celikyilmaz et al., 2020; Chang et al., 2023). Currently, there are mainly two lines of work on LLM evaluation, including NLU-style and NLG-style evaluations. NLU-style evaluation methods\\n\\n - -\\n\\nWe propose an LLM-ideation-human-scrutiny pipeline to explore the synergy of LLMs and hu- mans in establishing evaluation criteria and con- ducting multi-dimensional evaluations for open- ended NLG tasks. We find that LLM’s criteria are generally comprehensive but tend to exaggerate un- necessary\\n\\n - -\\n\\nexisting LLM-based NLG evaluators and uncover they suffer from insufficient prompting, where the scoring guidelines are absent and only output spaces are provided, resulting in inconsistent and misaligned evaluations. We emphasize the significance of aligned scoring criteria as a consensus between\\n\\n - -\\n\\nand is an effective automatic assess- ment, achieving near state-of-the-art performance for a range of NLG evaluation tasks. Furthermore, we show that LLMs are prone to have positional bias that could impact their decisions, however, we introduce a simple debiasing approach that leads to\\n\\n - -\\n\\nLLM-based Automatic Evaluation Recent work has explored using LLMs for automatic NLP eval- uation. GPTScore (Fu et al., 2023) leverages the LLM-predicted probability of text sequences as the quality score. On the other hand, a line of work (Chiang and yi Lee, 2023; Gao et al., 2023; Chen et al.,\\n\\n - -\\n\\nis a simple, general and effective approach for NLG assessment. For moderate- sized open-source LLMs, such as FlanT5 and Llama2-chat, comparative assessment is supe- rior to prompt scoring, and in many cases can achieve performance competitive with state-of- the-art methods. Additionally, we\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rags = get_summaries(['rag5','rag8','rag10'],paper_id)\n",
    "rags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.6775    , 0.614     , 0.6442    ],\n",
       "        [0.6733    , 0.6208    , 0.646     ],\n",
       "        [0.6619    , 0.6166    , 0.6385    ],\n",
       "        [0.6709    , 0.61713333, 0.6429    ],\n",
       "        [0.0065909 , 0.00280159, 0.00319687]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bert(rags,original_text,'rag_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.6526    , 0.6058    , 0.6284    ],\n",
       "        [0.6503    , 0.61      , 0.6295    ],\n",
       "        [0.6609    , 0.6197    , 0.6396    ],\n",
       "        [0.6546    , 0.61183333, 0.6325    ],\n",
       "        [0.00455265, 0.00582084, 0.0050405 ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rags_long = get_summaries(['rag5_large_data','rag8_large_data','rag10_large_data'],paper_id)\n",
    "rags_long\n",
    "get_bert(rags_long,original_text,'rag_long_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66275   , 0.61448333, 0.6377    ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean over all rag texts\n",
    "np.mean([[0.6709    , 0.61713333, 0.6429    ],[0.6546    , 0.61183333, 0.6325    ]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5063, 0.4332, 0.4669],\n",
       "        [0.5063, 0.4332, 0.4669],\n",
       "        [0.    , 0.    , 0.    ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_papers =  get_summaries(['fulltext_summary'],paper_id)\n",
    "get_bert(full_papers,original_text,'full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over all paper ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LLM-based NLG Evaluation: Current Status and Challenges\\nMingqi Gao , Xinyu Hu , Jie Ruan , Xiao Pu ,\\nXiaojun Wan\\nPeking University\\n{gaomingqi, huxinyu, wanxiaojun}@pku.edu.cn, {ruanjie, puxiao}@stu.pku.edu.cn\\nAbstract\\nEvaluating natural language generation (NLG) is\\na vital but challenging problem in artificial intel-\\nligence. Traditional evaluation metrics mainly cap-\\nturing content (e.g. n-gram) overlap between sys-\\ntem outputs and references are far from satisfactory,\\nand large language models (LLMs) such as Chat-\\nGPT have demonstrated great potential in NLG\\nevaluation in recent years. Various automatic evalu-\\nation methods based on LLMs have been proposed,\\nincluding metrics derived from LLMs, prompting\\nLLMs, and fine-tuning LLMs with labeled evalu-\\nation data. In this survey, we first give a taxon-\\nomy of LLM-based NLG evaluation methods, and\\ndiscuss their pros and cons, respectively. We also\\ndiscuss human-LLM collaboration for NLG evalu-\\nation. Lastly, we discuss several open problems in\\nthis area and point out future research directions.\\n1\\nIntroduction\\nEvaluating natural language generation (NLG) is a key but\\nchallenging issue. Traditional evaluation metrics like BLEU\\nand ROUGE rely on the n-gram overlap between model out-\\nputs and references to measure its quality. They have been\\ncriticized for low correlation with human judgments [Sulem\\net al., 2018], as surface-level matching cannot reliably evalu-\\nate text. After the rise of deep learning, model-based eval-\\nuation metrics like BERTScore [Zhang et al., 2020] and\\nBARTScore [Yuan et al., 2021] have been continuously pro-\\nposed and gradually adopted to evaluate the overall quality\\nor various specific aspects of generated outputs (e.g., fluency,\\ncoherence, coverage, faithfulness, etc.). Although better than\\ntraditional metrics, their performance is still not satisfactory,\\nand their application scope is very limited.\\nFor example,\\nBERTScore is reference-based and cannot be used without\\na reference. With the emergence of large language models\\n(LLMs) like ChatGPT, they have achieved unprecedented ef-\\nfectiveness in following instructions, understanding content,\\nand generating text. This inspired researchers to use LLMs\\nfor NLG evaluation. Although this is a research direction that\\nonly emerged in 2023, the past year has seen an enormous\\namount of research work. It is no exaggeration to say that\\nLLM-derived Metrics\\nEmbedding-based\\nProbability-based\\nFine-tuning\\nSpecialized\\nEvaluation LLM\\nPrompt\\nHuman\\nFine-tuning LLMs\\nHuman-LLM \\nCollaborative\\nEvaluation\\nFine-tuning LLMs\\nPrompting\\nLLMs\\nLLM\\nFigure 1: Schematic representation of the four categories of LLM-\\nbased NLG evaluation.\\nNLG evaluation has been revolutionized by LLMs. This arti-\\ncle will review the existing literature and provide suggestions\\nfor future research in this field.\\nThis article mainly focuses on research that uses language\\nmodels with over one billion parameters for NLG evaluation,\\nwith necessary references to earlier model-based evaluation\\nmetrics like BERTScore. To maintain focus, other types of\\ngeneration like code generation and tasks involving images\\nare not included in the scope of this article. As shown in Fig-\\nure 1, according to how we utilize LLMs for NLG evaluation,\\nwe categorize the research work into four types:\\n• LLM-derived metrics (§2): developing/deriving evalu-\\nation metrics from embeddings or generation probabili-\\nties of LLMs.\\n• Prompting LLMs (§3):\\ndirectly inquiring existing\\nLLMs via designed prompts.\\n• Fine-tuning LLMs (§4): using labeled evaluation data\\nto fine-tune existing LLMs and improving their NLG\\nevaluation capabilities.\\n• Human-LLM Collaborative Evaluation (§5): leverag-\\ning the distinctive strengths of both human evaluators\\nand LLMs to achieve robust and nuanced evaluations\\nin challenging domains through human-LLM collabora-\\ntion.\\narXiv:2402.01383v1  [cs.CL]  2 Feb 2024\\nWe will review each type of evaluation methods and discuss\\nthe pros and cons respectively. Lastly, we will discuss future\\ndirections in this area (§6).\\n2\\nLLM-derived Metrics\\n2.1\\nOverview\\nEarly model-based NLG evaluation methods,\\nsuch as\\nBERTScore and BARTScore, were primarily motivated by\\nthe capability of traditional pre-trained language models to\\ngenerate high-quality texts. Recently, the advent of LLMs\\nhas prompted some research to adapt these ideas to stronger\\nLLMs. Their inherent, powerful linguistic abilities are de-\\nrived for direct NLG evaluation, which is expected to result\\nin better performance. Such works can be categorized into\\ntwo types: embedding-based and probability-based methods.\\n2.2\\nEmbedding-based Metrics\\nThe embedding-based methods, like BERTScore, generally\\nutilize representations of language models and thus compute\\nthe semantic similarity between the reference and the target\\ntext to evaluate, with different possible ways of implemen-\\ntation. Recent work [ES et al., 2023] similarly obtains em-\\nbeddings for the target text using the text-embedding-ada-002\\nmodel through the OpenAI API. The higher the correspond-\\ning similarity, the closer the target text aligns with the relevant\\nrequirements, indicating a higher quality.\\n2.3\\nProbability-based Metrics\\nGPTScore [Fu et al., 2023a] establishes tailored evaluation\\ntemplates for each aspect to effectively guide multiple LLMs\\nfor NLG evaluation. The generation probability is calculated\\nunder the condition of source input designed with customized\\nprompts and evaluation aspects, which endows the GPTScore\\nwith better flexibility in evaluation.\\nAnd similar methods\\nhave also been applied to the hallucination detection of the\\nLLM-generated text in recent reseach with three different at-\\ntempts for calculating the probability score.\\nOn the other hand, some works leverage the variation in\\nprobabilities under changed conditions as the evaluation met-\\nric. FFLM [Jia et al., 2023] proposes to evaluate the faith-\\nfulness of the target text by calculating a combination of\\nprobability changes based on the intuition that the genera-\\ntion probability of a given text segment increases when more\\nconsistent information is provided, and vice versa. Similarly,\\nDELTASCORE [Xie et al., 2023] measures the quality of dif-\\nferent story aspects according to the likelihood difference be-\\ntween pre- and post-perturbation states with LLMs including\\nGPT-3.5 (text-davinci-003) that provide logits. They believe\\nthat the sensitivity to specific perturbations indicates the qual-\\nity of related aspects, and their experiments demonstrate the\\neffectiveness of their approach.\\n2.4\\nPros and Cons\\nTraditional NLG evaluation approaches always fall short due\\nto their surface-form similarity when the target text and ref-\\nerence convey the same meaning but use different expres-\\nsions. In contrast, LLM-derived metrics offer a remedy for\\nthe limitation and demonstrate stronger correlations with hu-\\nman judgments benefiting from the evolving modeling tech-\\nniques. However, the flaws within LLMs can lead to some\\nissues, as introduced in the following:\\nRobustness. Some research has investigated the robust-\\nness of LLM-derived metrics and found that they lack ro-\\nbustness in different attack scenarios. Specifically, [He et al.,\\n2023b] develops a set of stress tests to assess the robustness\\nof various model-based metrics on some common NLG tasks.\\nThey show a catalogue of the blind spots and potential errors\\nidentified that are not detected by each metric.\\nEfficiency. Compared to traditional metrics, LLM-derived\\nevaluation methods are more time-consuming and require\\nmore computational resources, especially when adopting\\nLLMs with quite large parameter scales.\\nTo address this,\\nsome lightweight learning approaches and fast LLM infer-\\nence and serving tools like vLLM 1 have been proposed.\\nHowever, closed-source LLMs often do not provide param-\\neters, representations, or logits, thus making it impossible to\\napply LLM-derived methods to them.\\nFairness. [Sun et al., 2022] assesses the social bias across\\nvarious metrics for NLG evaluation on six sensitive attributes:\\nrace, gender, religion, physical appearance, age, and socioe-\\nconomic status. Their findings reveal that model-based met-\\nrics carry noticeably more social bias than traditional metrics.\\nRelevant biases can be categorized into two types: intrinsic\\nbias encoded within pre-trained language models and extrin-\\nsic bias injected during the computation of similarity. There-\\nfore, current LLM-derived methods may have similar issues.\\n3\\nPrompting LLMs\\n3.1\\nOverview\\nLLMs have demonstrated unprecedented instruction under-\\nstanding and text generation abilities, which broadens re-\\nsearchers’ imagination of automatic evaluation for NLG. For\\na long time, human evaluation has been viewed as the gold\\nstandard for NLG evaluation. Recently, some studies claim\\nthat LLMs are on par with crowdsourcing annotators in sev-\\neral tasks. So, can LLMs simulate or even be an alternative to\\nhumans in the human evaluation of NLG? Or, do the practices\\nin human evaluation or other evaluative tasks (e.g. competi-\\ntion race, paper review, etc.) inspire us to better NLG evalua-\\ntion with LLMs? A large body of research and attempts based\\non prompting LLMs are guided by these ideas. In these stud-\\nies, instructions and the text to be evaluated are completely\\nexpressed in the prompt given to LLMs, and the evaluation\\nresults are generated by it.\\nHuman evaluation typically includes the following ele-\\nments:\\n• Evaluation Methods: The way the preferences of an-\\nnotators are captured and recorded, such as scoring, and\\ncomparison.\\n• Task Instructions: How the annotators should read or\\nmanipulate different parts to complete the annotation.\\n1https://github.com/vllm-project/vllm\\nYou will be given a news article. You will then be given one \\nsummary written for this article. Your task is to rate the summary \\non one metric. Please make sure you read and understand these \\ninstructions carefully. \\nEvaluation Criteria:\\nConsistency (1-5) - the factual alignment between the summary and \\nthe summarized source. A factually consistent summary contains only \\nstatements that are entailed by the source document. Annotators \\nwere also asked to penalize summaries that contained hallucinated \\nfacts. \\nEvaluation Steps:\\n1. Read the news article carefully and identify the main facts and \\ndetails it presents.\\n2. Read the summary and compare it to the article. Check if the \\nsummary contains any factual errors that are not supported by the \\narticle.\\n3. Assign a score for consistency based on the Evaluation Criteria.\\nSource Text: \\nPaul Merson has restarted his row with Andros Townsend after the \\nTottenham midfielder was brought on with only seven minutes \\nremaining in his team\\'s 0-0 draw with Burnley on Sunday. … \\nSummary: \\nPaul Merson was brought on with only seven minutes remaining ….\\nEvaluation Form: Answer by starting with \"Rating:\" and then give \\nthe explanation of the rating on the next line by \"Rationale:\"\\n- Consistency: \\nRating: 2\\nRationale:  The summary incorrectly states that Andros Townsend ….\\nPrompt\\nResponse\\nFigure 2: An example of prompting LLMs to score summary faith-\\nfulness. It can be seen that there are task instructions, evaluation\\ncriteria, and input content in the prompt. The rating and explanation\\nare generated by LLMs.\\n• Input Content: The target text to be evaluated and\\nother required content. Other required content including\\nsource documents, references, and external knowledge\\nis provided as needed.\\n• Evaluation Criteria: Also known as aspect, the general\\ndefinition of how good or bad the text to be evaluated\\nis in a particular aspect of quality, e.g. fluency, faithful-\\nness.\\n• Role and interaction: The roles annotators play in the\\nevaluation and the interactions between them.\\nThe focus of the existing research can always be mapped\\nanalogously to one or more of these elements, and we orga-\\nnize them according to the elements they address. An exam-\\nple of prompting LLMs is shown in Figure 2.\\n3.2\\nEvaluation Methods\\n[Kocmi and Federmann, 2023b] discover GPT-3.5 and GPT-\\n4 achieve the state-of-the-art accuracy of evaluating trans-\\nlation quality compared to human labels, outperforming all\\nthe results from the metric shard task of WMT22 [Freitag et\\nal., 2022]. [Wang et al., 2023a] experiment on five datasets\\nacross summarization, story generation, and data-to-text, and\\nChatGPT evaluators with a rating scale from 1 to 5 or 1 to\\n100 have the state-of-the-art or comparative correlations with\\nhuman judgments in most settings, compared with prior met-\\nrics. Similar conclusions are also observed in open-domain\\ndialogue response generation [Lin and Chen, 2023]. Besides\\nEnglish, [Mendonc\\n¸a et al., 2023] show that ChatGPT with\\nsimple rating prompts is a strong evaluator for multilingual\\ndialogue evaluation, surpassing prior metrics based on en-\\ncoders.\\nComparison. Different from absolute scoring, compari-\\nson refers to choosing the better of the two. [Luo et al., 2023]\\nuse ChatGPT to compare the factual consistency of two sum-\\nmaries. AuPEL [Wang et al., 2023d] evaluate personalized\\ntext generation from three aspects in the form of compari-\\nson with the PaLM 2 family [Anil et al., 2023]. According\\nto [Liusie et al., 2023], pairwise comparison is better than\\nscoring when medium-sized LLMs (e.g. FlanT5 [Chung et\\nal., 2022] and Llama2 [Touvron et al., 2023]) are adopted as\\nevaluators.\\nRanking. Ranking can be viewed as an extended form of\\ncomparison. In comparison, only two examples are involved\\nat a time, whereas in ranking, the order of more than two\\nexamples needs to be decided at once. [Ji et al., 2023] use\\nChatGPT to rank five model-generated responses across sev-\\neral use cases at once, indicating the ranking preferences of\\nChatGPT align with those of humans to some degree. Simi-\\nlarly, GPTRank is a method to rank summaries in a list-wise\\nmanner [Liu et al., 2023c]. Moreover, [Liu et al., 2023b]\\ncompare different evaluation methods in LLM-based summa-\\nrization including scoring, comparison, and ranking, showing\\nthat the optimal evaluation method for each backbone LLM\\nmay vary.\\nBoolean QA. Boolean QA requires LLMs to answer ”Yes”\\nor ”No” to a question. It is adopted more in scenarios where\\nhuman annotations are binary, such as grammaticality [Hu et\\nal., 2023], faithfulness of summaries and statements [Luo et\\nal., 2023; ES et al., 2023; Hu et al., 2023], factuality of gen-\\nerated text [Fu et al., 2023b], and answerability of generated\\nquestions [Wang et al., 2023f].\\nError Analysis. Error Analysis refers to the evaluation of\\na text by looking for errors that occur in the text according to a\\nset of predefined error categories. Multidimensional Quality\\nMetrics (MQM) [Jain et al., 2023] is an error analysis frame-\\nwork prevalent in machine translation evaluation. According\\nto MQM, [Kocmi and Federmann, 2023a] use ChatGPT or\\nGPT-4 to automatically detect translation quality error spans.\\nBOOOOKSCORE [Chang et al., 2023], an LLM-based eval-\\nuation metric, assesses the coherence of book summaries by\\nidentifying eight types of errors.\\n3.3\\nTask Instructions\\nIn the human evaluation of NLG, task instructions typically\\nconsist of a general task description and more detailed eval-\\nuation steps, akin to Chain-of-Thought. The demonstrations\\nused in few-shot prompting are also included in this part.\\nForm and requirements. Studies from Eval4NLP 2023\\nhave tested the effects of styles and lengths of task instruction,\\nand some have used LLMs to either generate or refine task\\ninstructions [Leiter et al., 2023]. [He et al., 2023a] evaluate\\ngenerative reasoning by asking LLMs to generate their own\\nanswers first, and then conduct a quantitative analysis of the\\ntext to be evaluated.\\nAnalysis and explanations. LLMs can include analysis or\\nexplanation in their evaluations, which is a key point that dis-\\ntinguishes them from previous automatic evaluation metrics.\\nEarly explorations into prompting LLMs for NLG evaluation\\nmostly do not examine the impact of whether LLMs are re-\\nquired to analyze and explain on evaluation result. Findings\\nsuggest that explicit analysis or explanation instructions can\\nbetter align LLM evaluations with human judgments [Chiang\\nand Lee, 2023], though the quality of LLM-generated expla-\\nnations still needs manual review.\\nDemonstrations.\\nSometimes in-context examples are\\nneeded for prompting LLMs. Some studies use only these\\nexamples even without additional instructions for prompting\\n[Jain et al., 2023], while others observe no significant ben-\\nefit from one-shot settings, compared to zero-shot settings\\n[Kotonya et al., 2023]. Iteratively updating in-context ex-\\namples has been shown to enhance LLM evaluators’ perfor-\\nmance [Hasanbeig et al., 2023].\\n3.4\\nInput Content\\nThe types of input content mainly depend on the evalua-\\ntion criteria and are relatively fixed. For most task-specific\\ncriteria, like summary faithfulness [Luo et al., 2023], both\\nthe source document and target text are needed. For task-\\nindependent criteria, such as fluency [Hu et al., 2023; Chi-\\nang and Lee, 2023], only the target text is required, though\\nthe source document is often included [Wang et al., 2023a;\\nLiusie et al., 2023]. Different tasks may require additional\\ninput types, such as providing or omitting references in ma-\\nchine translation evaluations [Kocmi and Federmann, 2023b].\\nUniquely, some studies incorporate the output of other auto-\\nmatic evaluation metrics into the input for LLMs [Shu et al.,\\n2023].\\n3.5\\nEvaluation Criteria\\nThe evaluation targeting specific aspects is used in numerous\\nstudies of human evaluation for NLG, such as text summa-\\nrization, story generation, dialogue, and text simplification.\\nEvaluation criteria, i.e., the definitions of aspects are key in\\nthis context. Most evaluation criteria in LLM-based evalua-\\ntion are directly derived from human evaluation. However, a\\nfew studies have attempted to let LLMs generate or improve\\nevaluation criteria. [Liu et al., 2023e] use a few human-rated\\nexamples as seeds to let LLMs draft some candidate evalu-\\nation criteria, and then further filter them based on the per-\\nformance of LLMs using these criteria on a validation set, to\\nobtain the final evaluation criteria. [Kim et al., 2023b] de-\\nsigned an LLM-based interactive evaluation system, which\\ninvolves using LLMs to review the evaluation criteria pro-\\nvided by users, including eliminating ambiguities in crite-\\nria, merging criteria with overlapping meanings, and decom-\\nposing overly broad criteria. Additionally, [Ye et al., 2023]\\npropose a hierarchical aspect classification system with 12\\nsubcategories, demonstrating that under the proposed fine-\\ngrained aspect definitions, human evaluation and LLM-based\\nevaluation are highly correlated. Additionally, the chain-of-\\naspects approach improves LLMs’ ability to evaluate on a\\nspecific aspect by having LLMs score on some related aspects\\nbefore generating the final score [Gong and Mao, 2023].\\n3.6\\nRole and Interaction\\nWe include in this section the evaluation strategies that ei-\\nther use the same LLMs in different ways or involve different\\nLLMs. The former can be further divided into chain-style and\\nnetwork-style interactions.\\nChain-style interaction. Inspired by human evaluators,\\n[Yuan et al., 2024] have LLMs score a batch of examples\\nto be evaluated each time. Specifically, the evaluation pro-\\ncess is divided into three stages: analysis, ranking, and scor-\\ning. Similar to QA-based evaluation metrics [Durmus et al.,\\n2020], [Fu et al., 2023b] assess the faithfulness of summaries\\nin two stages: treating LLMs as question generators to gen-\\nerate a question from the summary; then having LLMs an-\\nswer the question using the source document. Differently,\\nwhen [Hu et al., 2023] use GPT-4 to evaluate the faithfulness\\nof summaries, it first asks GPT-4 to extract event units from\\nthe summary, then verifies whether these event units meet the\\nrequirements, and finally judges whether the event units are\\nfaithful to the source document.\\nNetwork-style interaction.\\nUnlike chain-style interac-\\ntions, network-style interactions involve the dispersion and\\naggregation of information.\\nIn network-style interactions,\\nLLMs on the same layer play similar roles. ChatEval [Chan\\net al., 2023] is a framework for evaluating content through\\ndebates among multiple LLMs, with three communication\\nstrategies designed among the three types of LLMs: One-\\nBy-One, Simultaneous-Talk, and Simultaneous-Talk-with-\\nSummarizer. [Zhang et al., 2023b] find that under certain\\nconditions, widening and deepening the network of LLMs\\ncan better align its evaluation with human judgments. [Saha\\net al., 2023] propose a branch-solve-merge strategy, assign-\\ning LLMs the roles of decomposing problems, solving them,\\nand aggregating answers, thereby improving the accuracy and\\nreliability of evaluations. [Wu et al., 2023] assume that dif-\\nferent people such as politicians and the general public have\\ndifferent concerns about the quality of news summaries, use\\nLLMs to play different roles in evaluation accordingly, and\\naggregate the results finally.\\nDifferent LLMs. Different from having the same LLM\\nplay different roles, some research has used different LLMs\\n(such as GPT-4 and Claude) in their studies. In pairwise com-\\nparisons, previous work mostly used a single LLM as the\\nevaluator, which may not be fair. In light of this, [Bai et\\nal., 2023] design a decentralized Peer-examination method,\\nusing different LLMs as evaluators and then aggregating the\\nresults. Further, [Li et al., 2023c] let different LLMs serve\\nas evaluators in pairwise comparisons and then have them go\\nthrough a round of discussion to reach the final result. Addi-\\ntionally, [Cohen et al., 2023] evaluate the factuality of texts\\nthrough the interaction of two LLMs, where the LLM that\\ngenerated the text acts as the examinee and the other LLM as\\nthe examiner.\\n3.7\\nPros and Cons\\nThe benefits of prompting LLMs for NLG evaluation are ex-\\nciting. First, for the first time, people can express evaluation\\ncriteria and evaluation methods in natural language within the\\nprompts given to LLMs, providing great flexibility. Where\\npreviously people needed to design specific evaluation met-\\nrics for different NLG tasks or even different aspects of a sin-\\ngle task, now they only need to modify the prompts for LLMs.\\nSecondly, surprisingly, LLMs have the ability to generate ex-\\nplanations while assessing texts, making this approach some-\\nwhat interpretable. Furthermore, in many NLG task, prompt-\\ning LLMs for evaluation has achieved state-of-the-art corre-\\nlations with human judgments.\\nHowever, as many studies have pointed out, this type of\\napproach still has many limitations. [Wang et al., 2023b]\\nnote that when using ChatGPT and GPT-4 for pairwise com-\\nparisons, the order of the two texts can affect the evaluation\\nresults, which is known as position bias. To alleviate this\\nissue, [Li et al., 2023d] propose a strategy of splitting, align-\\ning, and then merging the two texts to be evaluated into the\\nprompt. Also, LLM evaluators tend to favor longer, more ver-\\nbose responses [Zheng et al., 2023] and responses generated\\nby themselves [Liu et al., 2023a]. [Wu and Aji, 2023] show\\nthat compared to answers that are too short or grammatically\\nincorrect, answers with factual errors are considered better by\\nLLMs. [Liu et al., 2023d] demonstrate through adversarial\\nmeta-evaluation that LLMs without references are not suit-\\nable for evaluating dialogue responses in closed-ended sce-\\nnarios: they tend to score highly on responses that conflict\\nwith the facts in the dialogue history. [Zhang et al., 2023a]\\nalso present the robustness issues of LLMs in dialogue eval-\\nuation through adversarial perturbations. [Shen et al., 2023]\\nindicate that LLM evaluators have a lower correlation with\\nhuman assessments when scoring high-quality summaries. In\\naddition, [Zhang et al., 2023a] state that evaluators based\\non large models have a bias towards high scores, especially\\nin non-Latin languages like Chinese and Japanese. Beyond\\nthese shortcomings of performance, both ChatGPT and GPT-\\n4 are proprietary models, and their opacity could lead to irre-\\nproducible evaluation results.\\n4\\nFine-tuning LLMs\\n4.1\\nOverview\\nAs mentioned above, despite the exciting performance of\\nprompting LLMs like ChatGPT and GPT-4 for NLG evalu-\\nation, several shortcomings in practice are inevitable, such\\nas high costs, possibly irreproducible results, and potential\\nbiases in LLMs. In response, recent research has shifted to-\\nwards fine-tuning smaller, open-source LLMs specifically for\\nevaluation purposes, aiming to achieve performance close to\\nGPT-4 in NLG evaluation. Representative works of this type\\ninclude PandaLM [Wang et al., 2023e], Prometheus [Kim\\net al., 2023a], Shepherd [Wang et al., 2023c], TIGERScore\\n[Jiang et al., 2023], INSTRUCTSCORE [Xu et al., 2023],\\nAuto-J [Li et al., 2023a], CritiqueLLM [Ke et al., 2023] and\\nJudgeLM [Zhu et al., 2023]. Their main ideas are similar, in-\\nvolving the elaborate construction of high-quality evaluation\\ndata, followed by accordingly fine-tuning open-source base\\nLLMs. Nevertheless, there are certain discrepancies in the de-\\nsigns across different works, such as the usage of references\\nand evaluation criteria. We have summarized the key differ-\\nent components of these methods in Table 1 for comparison,\\nwhich will be elaborated on next.\\n4.2\\nData Construction\\nDiverse data with high-quality annotations is crucial for the\\nfine-tuning of evaluation models, which mainly involves task\\nscenarios, inputs, target texts to evaluate, and evaluation re-\\nsults. Early NLG evaluation research primarily focused on\\nconventional NLG tasks, such as summarization and dialogue\\ngeneration. Thus, the task scenarios, inputs, and target texts\\nrefer to the corresponding NLP task, source inputs of the\\ntask, and outputs generated by specialized systems based on\\ntask requirements, respectively. And mainstream datasets for\\nthese tasks predominantly employ human annotators to pro-\\nvide evaluation results, which are often considered reliable.\\nWith the recent rise of LLMs, the spectrum of NLG tasks\\nhas been broadened to scenarios of instruction and response\\nthat are more aligned with human needs. Traditional tasks\\nlike summarization with corresponding source inputs can be\\nviewed as kinds of instructions and requirements.\\nMean-\\nwhile, responses generated by various general LLMs gen-\\nerally serve as the target texts now and require more flex-\\nible evaluation so that the performance of different LLMs\\ncan be compared, promoting further developments. There-\\nfore, to keep pace with the current advancement of modeling\\ntechniques, most evaluation methods have adopted the similar\\ninstruction-response scenario.\\nThe primary differences in these works actually lie in the\\nconstruction of instructions, with the purpose of improving\\neither diversity or reliability for the better generalization abil-\\nity of the fine-tuned model. PandaLM and JudgeLM entirely\\nsample from common instruction datasets, such as Alpaca\\n52K, while CritiqueLLM adopts small-scale sampling fol-\\nlowed by ChatGPT augmentation. In contrast, Prometheus\\nand INSTRUCTSCORE rely on GPT-4 to generate all the in-\\nstructions based on seed data, whereas Auto-J and Shepherd\\nuse real-world data. Moreover, since large-scale human anno-\\ntation is impractical, most works utilize GPT-4 as the power-\\nful annotator, except for PandaLM and Shepherd, which use\\nGPT-3.5 and human annotation on small-scale community\\ndata, respectively.\\nDuring the construction, they basically\\nall design detailed prompts or guidance and apply heuristic\\nfiltering strategies and post-processing methods to mitigate\\nnoise. Overall, despite the possible higher quality of human\\nannotation, the corresponding drawback is the difficulty in\\nconstructing large-scale datasets, which in turn may hinder\\nadequate model training, while using LLMs for construction\\nis the opposite situation.\\n4.3\\nEvaluation Method\\nAs with prompting LLMs, the evaluation methods adopted in\\nthese works are highly diversified, involving different evalua-\\ntion criteria, result modes, and usages of the reference. Given\\nthat current instruction-response scenarios encompass differ-\\nent types of tasks, it is unsuitable to specify unified evalu-\\nation criteria as in traditional NLG tasks. However, some\\nworks still do it this way, while some other methods let LLM\\nannotators adaptively and implicitly reflect the required cri-\\nteria in their evaluations, like PandaLM, TIGERScore, and\\nMethod\\nData Construction\\nEvaluation Method\\nBase LLM\\nReference\\nRequired\\nInstruction Source\\nAnnotator Scale\\nResult Mode\\nDetails\\nSpecific Criteria\\nPandaLM\\nAlpaca 52K\\nGPT-3.5\\n300K\\nComparison\\nReason &\\nReference\\nUnified\\nLLaMA\\n7B\\nNo\\nPrometheus\\nGPT-4 Construction\\nGPT-4\\n100K\\nScoring\\nReason\\nExplicit\\nLLaMA-2-Chat\\n7B & 13B\\nYes\\nShepherd\\nCommunity Critique Data\\n& 9 NLP Tasks Data\\nHuman\\n1317\\nOverall\\nJudgement\\nError Identifying\\n& Refinement\\nUnified\\nLLaMA\\n7B\\nNo\\nTIGERScore\\n23 Distinctive Text\\nGeneration Datasets\\nGPT-4\\n48K\\nMQM\\nError Analysis\\nImplicit\\nLLaMA-2\\n7B & 13B\\nNo\\nINSTRUCTSCORE\\nGPT-4 Construction\\nGPT-4\\n40K\\nMQM\\nError Analysis\\nImplicit\\nLLaMA\\n7B\\nYes\\nAUTO-J\\nReal-world User Queries\\nfrom Preference Datasets\\nGPT-4\\n4396\\nScoring &\\nComparison\\nReason\\nImplicit\\nLLaMA-2-Chat\\n13B\\nNo\\nCritiqueLLM\\nAlignBench &\\nChatGPT Augmentation\\nGPT-4\\n9332\\nScoring\\nReason\\nUnified\\nChatGLM-2\\n6B, 12B & 66B\\nFlexible\\nJudgeLM\\nGPT4All-LAION, ShareGPT\\nAlpaca-GPT4 & Dolly-15K\\nGPT-4\\n100K\\nScoring &\\nComparison\\nReason\\nUnified\\nVicuna\\n7B, 13B & 33B\\nFlexible\\nTable 1: Comparison of the different key components among the representative methods of fine-tuning LLMs.\\nAUTO-J. In particular, AUTO-J has meticulously crafted 332\\nevaluation criteria, matched to different tasks. Furthermore,\\nPrometheus explicitly incorporates evaluation criteria into the\\ninputs of the model, expecting flexible evaluation based on\\nvarious customized criteria.\\nMore details about the evaluation methods are shown in\\nTable 1. All the works require models to provide detailed\\ninformation, such as reasons for their evaluation results. And\\nthe MQM mode can achieve more informative error analysis,\\noffering stronger interpretability. Moreover, some works do\\nnot necessarily require references and then have greater value\\nin practice. And a more optimal method is to concurrently\\nsupport both reference-based and reference-free evaluations\\nas JudgeLM and CritiqueLLM.\\n4.4\\nFine-tuning Implementation\\nThe fine-tuning process is uniformly implemented by differ-\\nent works on their selected open-source LLMs, like LLaMA,\\nand respective constructed data, with some targeted set-\\ntings. Specifically, Prometheus maintains balanced data dis-\\ntributions during fine-tuning, including the length and label.\\nJudgeLM eliminates potential biases by randomly swapping\\nsample pairs to be compared and randomly removing ref-\\nerences. INSTRUCTSCORE utilizes GPT-4 to provide er-\\nror annotations for the intermediate outputs of the fine-tuned\\nmodel for further supervised reinforcement. Moreover, Cri-\\ntiqueLLM implements separately, with and without refer-\\nences, and explores the effects of data and model scale. Com-\\npared to the vanilla fine-tuning setting, these methods have\\nimproved the efficiency of model training and the robustness\\nof evaluations.\\n4.5\\nPros and Cons\\nThe shortcomings of prompting LLM methods can be signif-\\nicantly alleviated due to the customized implementation of\\ndata construction and fine-tuning. For instance, most fine-\\ntuned models range between 7B and 13B in the scale of pa-\\nrameters, facilitating low-cost inference use and good repro-\\nducibility, with performance close to GPT4 in NLG evalua-\\ntion. And specific measures can be adopted to prevent related\\nbiases found in GPT4 during different stages. Furthermore,\\nthis type of approach allows for continuous iteration and im-\\nprovement of the model to address potential deficiencies or\\nemerging issues discovered in future applications.\\nHowever, some biases associated with GPT4 may still per-\\nsist, as the data construction of most methods employs GPT4\\nfor critical evaluation annotation. On the other hand, the base\\nopen-source LLMs selected by existing works are primarily\\nthe series of LLaMA. With the rapid updates and improve-\\nments of open-source large models recently, it adheres to the\\nintuition that employing a more powerful base LLM should\\nlead to better evaluation performance. However, this means\\nrepetitive fine-tuning processes and computational expenses\\nsince directly migrating existing finetuned models to the new\\nbase LLM is difficult. Additionally, although many existing\\nmethods aspire for more flexible and comprehensive evalua-\\ntion through fine-tuning, demanding many evaluation settings\\nin model training may ultimately lead to poor performance,\\nwhich has been observed in our practice and also mentioned\\nrelationally in [Li et al., 2023a]. And considering the differ-\\nent evaluation settings in existing works, it is challenging to\\nconduct a horizontal comparison among them. These issues\\nrequire further exploration in future research.\\n5\\nHuman-LLM Collaborative Evaluation\\n5.1\\nOverview\\nWhile LLMs demonstrate robust evaluation capabilities, there\\nexists a need for further enhancement in terms of their relia-\\nbility, particularly in establishing a stronger correlation with\\nhuman evaluation outcomes. Although human evaluation is\\nthe gold-standard evaluation approach in NLG, it is recog-\\nnized for its associated high costs and susceptibility to sub-\\njective biases [Li et al., 2023b].\\nThe robust and compre-\\nhensive capabilities exhibited by LLMs underscore consider-\\nable potential for the development of collaborative evaluation\\nmethodologies that integrate both human and LLMs. In re-\\ncent investigations, researchers have initiated the exploration\\nof collaborative evaluation paradigms, which include tradi-\\ntional NLG evaluation methods such as scoring and explain-\\ning [Zhang et al., 2021; Li et al., 2023b], broader evaluation\\nmethods such as testing and debugging [Ribeiro and Lund-\\nberg, 2022], and auditing NLG models to ensure fairness\\n[Rastogi et al., 2023]. Furthermore, scholars [Saunders et\\nal., 2022] are actively engaging in efforts to address the intri-\\ncate challenge of scalable oversight through the collaboration\\nof humans and LLMs. The objective is to devise strategies\\nfor effectively evaluating models in tasks that pose inherent\\ndifficulties for human assessors. This collaborative approach\\nseeks to leverage the distinctive strengths of both human eval-\\nuators and sophisticated language models to achieve robust\\nand nuanced evaluations in challenging domains.\\n5.2\\nScoring and Explaining\\nAutomated evaluation frequently exhibits a limited correla-\\ntion with human judgments, while human evaluation, though\\nreliable, is labor-intensive. [Zhang et al., 2021] present a\\nhuman-machine collaborative framework (HMCEval) which\\nconceptualizes dialogue evaluation as a sample assignment\\nproblem to ensure the reliability of evaluation outcomes while\\nminimizing human effort and achieves 99% accuracy with\\nhalf human effort. Recently, LLMs have emerged as a cost-\\neffective alternative to human evaluations.\\nHowever, both\\nhumans and LLMs have limitations, including inherent sub-\\njectivity and unreliable judgments, especially in open-ended\\ntasks with diverse requirements.\\nTo address challenges associated with inconsistent evalua-\\ntion criteria in open-ended tasks and explore synergy between\\nhumans and LLM-based evaluators, [Li et al., 2023b] pro-\\nposes a Collaborative Evaluation pipeline (COEVAL), which\\ninvolves designing a checklist of task-specific criteria and\\nconducting detailed evaluations where LLMs generate initial\\nideation and humans engage in scrutiny. Depending solely on\\nscore predictions is insufficient for ensuring reliable evalua-\\ntion and error detection, particularly when specific criteria de-\\nmand nuanced analysis beyond straightforward scoring. CO-\\nEVAL is assigned the additional task of generating explana-\\ntions to elucidate evaluation outcomes to facilitate a trustwor-\\nthy collaborative evaluation process. Results indicate CO-\\nEVAL effectively evaluates lengthy texts by utilizing LLMs,\\nsaving significant time and reducing human evaluation out-\\nliers. Despite the involvement of LLMs, human scrutiny re-\\nmains essential, contributing to the revision of around 20% of\\nLLM evaluation scores for enhanced reliability.\\n5.3\\nBroader Evaluation Tasks\\nThe broader evaluation of NLG models involves testing and\\ndebugging the models. Current methods often rely on highly\\nvariable human creativity and extensive manual effort or are\\nlimited to addressing a very specific class of bugs. [Ribeiro\\nand Lundberg, 2022] introduce AdaTest, a process that uses\\nLLMs in collaboration with human feedback to automatically\\ngenerate unit tests that highlight bugs in a target model, which\\nproves to make users 5-10 times more effective at identifying\\nbugs and assists users in effectively fixing bugs without intro-\\nducing new ones. Moreover, LLMs have shown biases and ir-\\nresponsible behavior, necessitating thorough auditing before\\ndeployment. AdaTest++ [Rastogi et al., 2023] draw on in-\\nsights from literature on human-AI collaboration and sense-\\nmaking, and engage with research experts in safe and fair\\nAI, which emphasizes the importance of sensemaking and ef-\\nfective communication between humans and AI to capitalize\\non their complementary strengths in collaborative auditing.\\nAdaTest++ successfully leverages human strengths, such as\\nschematization and hypothesis testing. Moreover, users iden-\\ntified a range of failure modes across 26 different topics in\\nissues that were revealed in formal audits and those that were\\npreviously under-reported. Additionally, ensuring trustwor-\\nthiness in LLMs for challenging tasks poses a crucial chal-\\nlenge. Scalable oversight [Amodei et al., 2016] aims to effec-\\ntively evaluate models on tasks challenging for humans and\\nsuggests the use of AI for assistance. [Saunders et al., 2022]\\nexplored providing critiques of model outputs as a form of as-\\nsistance, demonstrating that model-generated critiques assist\\nhumans in identifying overlooked flaws.\\n5.4\\nPros and Cons\\nThe advantages of human-AI collaborative evaluation lie in\\nachieving a balance between efficiency and cost, as demon-\\nstrated by COEVAL [Li et al., 2023b] achieving this equi-\\nlibrium.\\nAdditionally, there are complementary strengths\\nbetween humans and AI. For instance, AdaTest++ [Rastogi\\net al., 2023] empowers users to consistently utilize their\\nstrengths throughout the auditing process, benefiting signif-\\nicantly from LLM. Users who generate the most topics heav-\\nily rely on LLM suggestions while employing their contextual\\nreasoning and semantic understanding to update their mental\\nmodels vigilantly and identify model failures.\\nHowever, there are drawbacks. The evaluation results of\\nLLMs may be sensitive to the formats used to query the model\\nand might require additional support for prompt writing [Li\\net al., 2023b; Rastogi et al., 2023]. Furthermore, the current\\ncapability to assess confidence levels is not strong enough,\\nmaking it challenging to determine when to trust the LLM.\\nFurthermore, certain level of human supervision is still nec-\\nessary, making it less convenient and cost-effective compared\\nto fully automated evaluation.\\n6\\nConclusions and Future Trends\\nThrough the above review of studies on NLG evaluation\\nbased on LLMs, we find that these four categories of ap-\\nproaches have their respective strengths and weaknesses,\\nand most of the existing work is concentrated on prompting\\nLLMs. In view of this, we offer some suggestions for future\\ndirections in this field.\\nUnified benchmarks for LLM-based NLG evaluation\\napproaches. As mentioned above, each of the studies that\\nfine-tuned LLMs to construct specialized evaluation models\\nuses different settings and data during testing, making them\\nincomparable. In the research on prompting LLMs for NLG\\nevaluation, there are some publicly available human judg-\\nments on the same NLG task, such as SummEval for summa-\\nrization. However, the existing human judgments have many\\nproblems. Firstly, most of the existing data only involve one\\ntype of NLG task and a single human evaluation method (e.g.,\\nscoring), making it difficult to evaluate LLMs’ performance\\non different tasks, as well as using different evaluation meth-\\nods on the same task. Secondly, many of the texts in these\\nhuman judgments are generated by outdated models (such as\\nPointer Network) and do not include texts generated by more\\nadvanced LLMs. Lastly, many human evaluation datasets are\\ntoo small in scale. There is an urgent need for large-scale,\\nhigh-quality human evaluation data covering various NLG\\ntasks and evaluation methods as a benchmark.\\nNLG evaluation for low-resource languages and new\\ntask scenarios. Almost all existing research focuses on En-\\nglish data. However, it is doubtful whether LLMs have simi-\\nlar levels of NLG evaluation capability for texts in other lan-\\nguages, especially low-resource languages. As [Zhang et al.,\\n2023a] points out, we should be more cautious about using\\nLLMs to evaluate texts in non-Latin languages. Additionally,\\nexisting research mainly focuses on more traditional NLG\\ntasks such as translation, summarization, and dialogue. How-\\never, there are many new scenarios in reality with different re-\\nquirements and evaluation criteria. Research on low-resource\\nlanguages and new task scenarios will provide a more com-\\nprehensive understanding of LLMs’ evaluation capabilities.\\nDiverse forms of human-LLM collaborative NLG eval-\\nuation. According to the literature reviewed above, there is\\nlittle research on collaborative evaluation between humans\\nand LLMs. Neither humans nor LLMs are perfect, and each\\nhas its strengths. Since the ultimate goal of NLG research is\\nto evaluate text quality more accurately and efficiently, we\\nbelieve that collaboration between humans and LLMs can\\nachieve better results than pure human evaluation or auto-\\nmatic evaluation. In the collaboration between humans and\\nLLMs, technologies in the field of human-computer interac-\\ntion may bring new implementation methods to the collabo-\\nration. In addition, what roles humans and LLMs should play\\nin the evaluation and how they can better complement each\\nother are still worth researching.\\nReferences\\n[Amodei et al., 2016] Dario Amodei, Chris Olah, Jacob\\nSteinhardt, Paul F. Christiano, John Schulman, and\\nDan Man´\\ne.\\nConcrete problems in AI safety.\\nCoRR,\\nabs/1606.06565, 2016.\\n[Anil et al., 2023] Rohan Anil, Andrew M. Dai, Orhan Fi-\\nrat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos,\\nSiamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng\\nChen, Eric Chu, Jonathan H. Clark, Laurent El Shafey,\\nYanping Huang, Kathy Meier-Hellstern, Gaurav Mishra,\\nErica Moreira, Mark Omernick, Kevin Robinson, Sebas-\\ntian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing\\nZhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob\\nAustin, Paul Barham, Jan Botha, James Bradbury, Sid-\\ndhartha Brahma, Kevin Brooks, Michele Catasta, Yong\\nCheng, Colin Cherry, Christopher A. Choquette-Choo,\\nAakanksha Chowdhery, Cl´\\nement Crepy, Shachi Dave,\\nMostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark D´\\nıaz,\\nNan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng,\\nVlad Fienber, Markus Freitag, Xavier Garcia, Sebastian\\nGehrmann, Lucas Gonzalez, Guy Gur-Ari, Steven Hand,\\nHadi Hashemi, Le Hou, Joshua Howland, Andrea Hu,\\nJeffrey Hui, Jeremy Hurwitz, Michael Isard, Abe Itty-\\ncheriah, Matthew Jagielski, Wenhao Jia, Kathleen Ke-\\nnealy, Maxim Krikun, Sneha Kudugunta, Chang Lan,\\nKatherine Lee, Benjamin Lee, Eric Li, Music Li, Wei\\nLi, YaGuang Li, Jian Li, Hyeontaek Lim, Hanzhao Lin,\\nZhongtao Liu, Frederick Liu, Marcello Maggioni, Aroma\\nMahendru, Joshua Maynez, Vedant Misra, Maysam Mous-\\nsalem, Zachary Nado, John Nham, Eric Ni, Andrew Nys-\\ntrom, Alicia Parrish, Marie Pellat, Martin Polacek, Alex\\nPolozov, Reiner Pope, Siyuan Qiao, Emily Reif, Bryan\\nRichter, Parker Riley, Alex Castro Ros, Aurko Roy, Bren-\\nnan Saeta, Rajkumar Samuel, Renee Shelby, Ambrose\\nSlone, Daniel Smilkov, David R. So, Daniel Sohn, Si-\\nmon Tokumine, Dasha Valter, Vijay Vasudevan, Kiran Vo-\\ndrahalli, Xuezhi Wang, Pidong Wang, Zirui Wang, Tao\\nWang, John Wieting, Yuhuai Wu, Kelvin Xu, Yunhan\\nXu, Linting Xue, Pengcheng Yin, Jiahui Yu, Qiao Zhang,\\nSteven Zheng, Ce Zheng, Weikang Zhou, Denny Zhou,\\nSlav Petrov, and Yonghui Wu. Palm 2 technical report.\\nComputing Research Repository, arxiv:2305.10403, 2023.\\n[Bai et al., 2023] Yushi Bai, Jiahao Ying, Yixin Cao, Xin Lv,\\nYuze He, et al.\\nBenchmarking foundation models with\\nlanguage-model-as-an-examiner. CoRR, abs/2306.04181,\\n2023.\\n[Chan et al., 2023] Chi-Min Chan, Weize Chen, Yusheng\\nSu, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, and\\nZhiyuan Liu. Chateval: Towards better llm-based evalua-\\ntors through multi-agent debate. CoRR, abs/2308.07201,\\n2023.\\n[Chang et al., 2023] Yapei Chang, Kyle Lo, Tanya Goyal,\\nand Mohit Iyyer. Booookscore: A systematic exploration\\nof book-length summarization in the era of llms. CoRR,\\nabs/2310.00785, 2023.\\n[Chiang and Lee, 2023] David\\nCheng-Han\\nChiang\\nand\\nHung-yi Lee.\\nA closer look into using large language\\nmodels for automatic evaluation. In EMNLP (Findings),\\n2023.\\n[Chung et al., 2022] Hyung Won Chung, Le Hou, Shayne\\nLongpre, Barret Zoph, Yi Tay, William Fedus, Eric Li,\\nXuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Al-\\nbert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac\\nSuzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan\\nNarang, Gaurav Mishra, Adams Yu, Vincent Y. Zhao, Yan-\\nping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov,\\nEd H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny\\nZhou, Quoc V. Le, and Jason Wei. Scaling instruction-\\nfinetuned language models. CoRR, abs/2210.11416, 2022.\\n[Cohen et al., 2023] Roi Cohen, May Hamri, Mor Geva, and\\nAmir Globerson. LM vs LM: detecting factual errors via\\ncross examination. In EMNLP, 2023.\\n[Durmus et al., 2020] Esin Durmus, He He, and Mona T.\\nDiab. FEQA: A question answering evaluation framework\\nfor faithfulness assessment in abstractive summarization.\\nIn ACL, 2020.\\n[ES et al., 2023] Shahul ES, Jithin James, Luis Espinosa\\nAnke, and Steven Schockaert.\\nRAGAS: automated\\nevaluation of retrieval augmented generation.\\nCoRR,\\nabs/2309.15217, 2023.\\n[Freitag et al., 2022] Markus Freitag, Ricardo Rei, Nitika\\nMathur, Chi-kiu Lo, Craig Stewart, Eleftherios Avramidis,\\nTom Kocmi, George F. Foster, Alon Lavie, and Andr´\\ne F. T.\\nMartins. Results of WMT22 metrics shared task: Stop us-\\ning BLEU - neural metrics are better and more robust. In\\nWMT, 2022.\\n[Fu et al., 2023a] Jinlan Fu, See-Kiong Ng, Zhengbao Jiang,\\nand Pengfei Liu. Gptscore: Evaluate as you desire. CoRR,\\nabs/2302.04166, 2023.\\n[Fu et al., 2023b] Xue-Yong\\nFu,\\nMd.\\nTahmid\\nRahman\\nLaskar, Cheng Chen, and Shashi Bhushan TN. Are large\\nlanguage models reliable judges? A study on the factual-\\nity evaluation capabilities of llms. CoRR, abs/2311.00681,\\n2023.\\n[Gong and Mao, 2023] Peiyuan Gong and Jiaxin Mao. Coas-\\ncore: Chain-of-aspects prompting for NLG evaluation.\\nCoRR, abs/2312.10355, 2023.\\n[Hasanbeig et al., 2023] Hosein Hasanbeig, Hiteshi Sharma,\\nLeo Betthauser, Felipe Vieira Frujeri, and Ida Momenne-\\njad.\\nALLURE: auditing and improving llm-based eval-\\nuation of text using iterative in-context-learning. CoRR,\\nabs/2309.13701, 2023.\\n[He et al., 2023a] Hangfeng He, Hongming Zhang, and Dan\\nRoth. Socreval: Large language models with the socratic\\nmethod for reference-free reasoning evaluation.\\nCoRR,\\nabs/2310.00074, 2023.\\n[He et al., 2023b] Tianxing He, Jingyu Zhang, Tianle Wang,\\nSachin Kumar, Kyunghyun Cho, James R. Glass, and Yu-\\nlia Tsvetkov. On the blind spots of model-based evaluation\\nmetrics for text generation. In ACL (1), 2023.\\n[Hu et al., 2023] Yebowen Hu, Kaiqiang Song, Sangwoo\\nCho, Xiaoyang Wang, Hassan Foroosh, and Fei Liu. De-\\ncipherpref: Analyzing influential factors in human prefer-\\nence judgments via GPT-4. In EMNLP, 2023.\\n[Jain et al., 2023] Sameer Jain, Vaishakh Keshava, Swar-\\nnashree Mysore Sathyendra, Patrick Fernandes, Pengfei\\nLiu, Graham Neubig, and Chunting Zhou.\\nMulti-\\ndimensional evaluation of text summarization with in-\\ncontext learning. In ACL (Findings), 2023.\\n[Ji et al., 2023] Yunjie Ji, Yan Gong, Yiping Peng, Chao Ni,\\nPeiyan Sun, Dongyu Pan, Baochang Ma, and Xiangang\\nLi. Exploring chatgpt’s ability to rank content: A prelimi-\\nnary study on consistency with human preferences. CoRR,\\nabs/2303.07610, 2023.\\n[Jia et al., 2023] Qi Jia, Siyu Ren, Yizhu Liu, and Kenny Q.\\nZhu. Zero-shot faithfulness evaluation for text summariza-\\ntion with foundation language model. In EMNLP, 2023.\\n[Jiang et al., 2023] Dongfu Jiang, Yishan Li, Ge Zhang,\\nWenhao Huang, Bill Yuchen Lin, and Wenhu Chen. Tiger-\\nscore: Towards building explainable metric for all text\\ngeneration tasks. CoRR, abs/2310.00752, 2023.\\n[Ke et al., 2023] Pei Ke, Bosi Wen, Zhuoer Feng, Xiao Liu,\\nXuanyu Lei, Jiale Cheng, Shengyuan Wang, Aohan Zeng,\\nYuxiao Dong, Hongning Wang, Jie Tang, and Minlie\\nHuang.\\nCritiquellm: Scaling llm-as-critic for effective\\nand explainable evaluation of large language model gen-\\neration. CoRR, abs/2311.18702, 2023.\\n[Kim et al., 2023a] Seungone Kim, Jamin Shin, Yejin Cho,\\nJoel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun,\\nSeongjin Shin, Sungdong Kim, James Thorne, and Min-\\njoon Seo. Prometheus: Inducing fine-grained evaluation\\ncapability in language models.\\nCoRR, abs/2310.08491,\\n2023.\\n[Kim et al., 2023b] Tae Soo Kim, Yoonjoo Lee, Jamin Shin,\\nYoung-Ho Kim, and Juho Kim. Evallm: Interactive eval-\\nuation of large language model prompts on user-defined\\ncriteria. CoRR, abs/2309.13633, 2023.\\n[Kocmi and Federmann, 2023a] Tom Kocmi and Christian\\nFedermann. GEMBA-MQM: detecting translation quality\\nerror spans with GPT-4. In WMT, 2023.\\n[Kocmi and Federmann, 2023b] Tom Kocmi and Christian\\nFedermann.\\nLarge language models are state-of-the-art\\nevaluators of translation quality. In EAMT, 2023.\\n[Kotonya et al., 2023] Neema Kotonya, Saran Krishnasamy,\\nJoel R. Tetreault, and Alejandro Jaimes. Little giants: Ex-\\nploring the potential of small llms as evaluation metrics in\\nsummarization in the eval4nlp 2023 shared task. CoRR,\\nabs/2311.00686, 2023.\\n[Leiter et al., 2023] Christoph Leiter, Juri Opitz, Daniel\\nDeutsch, Yang Gao, Rotem Dror, and Steffen Eger. The\\neval4nlp 2023 shared task on prompting large language\\nmodels as explainable metrics.\\nCoRR, abs/2310.19792,\\n2023.\\n[Li et al., 2023a] Junlong Li, Shichao Sun, Weizhe Yuan,\\nRun-Ze Fan, Hai Zhao, and Pengfei Liu. Generative judge\\nfor evaluating alignment. CoRR, abs/2310.05470, 2023.\\n[Li et al., 2023b] Qintong Li, Leyang Cui, Lingpeng Kong,\\nand Wei Bi. Collaborative evaluation: Exploring the syn-\\nergy of large language models and humans for open-ended\\ngeneration evaluation. CoRR, abs/2310.19740, 2023.\\n[Li et al., 2023c] Ruosen Li, Teerth Patel, and Xinya Du.\\nPRD: peer rank and discussion improve large language\\nmodel based evaluations. CoRR, abs/2307.02762, 2023.\\n[Li et al., 2023d] Zongjie Li, Chaozheng Wang, Pingchuan\\nMa, Daoyuan Wu, Shuai Wang, Cuiyun Gao, and Yang\\nLiu. Split and merge: Aligning position biases in large\\nlanguage model based evaluators. CoRR, abs/2310.01432,\\n2023.\\n[Lin and Chen, 2023] Yen-Ting Lin and Yun-Nung Chen.\\nLlm-eval: Unified multi-dimensional automatic evaluation\\nfor open-domain conversations with large language mod-\\nels. In NLP4ConvAI 2023, 2023.\\n[Liu et al., 2023a] Yang Liu, Dan Iter, Yichong Xu, Shuo-\\nhang Wang, Ruochen Xu, and Chenguang Zhu. G-eval:\\nNLG evaluation using gpt-4 with better human alignment.\\nIn EMNLP, 2023.\\n[Liu et al., 2023b] Yixin Liu, Alexander R. Fabbri, Jiawen\\nChen, Yilun Zhao, Simeng Han, Shafiq Joty, Pengfei Liu,\\nDragomir Radev, Chien-Sheng Wu, and Arman Cohan.\\nBenchmarking generation and evaluation capabilities of\\nlarge language models for instruction controllable summa-\\nrization. CoRR, abs/2311.09184, 2023.\\n[Liu et al., 2023c] Yixin Liu, Alexander R. Fabbri, Pengfei\\nLiu, Dragomir Radev, and Arman Cohan.\\nOn learning\\nto summarize with large language models as references.\\nCoRR, abs/2305.14239, 2023.\\n[Liu et al., 2023d] Yongkang Liu, Shi Feng, Daling Wang,\\nYifei Zhang, and Hinrich Sch¨\\nutze.\\nEvaluate what you\\ncan’t evaluate: Unassessable generated responses quality.\\nCoRR, abs/2305.14658, 2023.\\n[Liu et al., 2023e] Yuxuan Liu,\\nTianchi Yang,\\nShaohan\\nHuang, Zihan Zhang, Haizhen Huang, Furu Wei, Weiwei\\nDeng, Feng Sun, and Qi Zhang.\\nCalibrating llm-based\\nevaluator. CoRR, abs/2309.13308, 2023.\\n[Liusie et al., 2023] Adian Liusie, Potsawee Manakul, and\\nMark J. F. Gales.\\nLlm comparative assessment: Zero-\\nshot nlg evaluation through pairwise comparisons using\\nlarge language models. Computing Research Repository,\\narxiv:2307.07889, 2023.\\n[Luo et al., 2023] Zheheng Luo, Qianqian Xie, and Sophia\\nAnaniadou.\\nChatgpt as a factual inconsistency eval-\\nuator\\nfor\\nabstractive\\ntext\\nsummarization.\\nCoRR,\\nabs/2303.15621, 2023.\\n[Mendonc\\n¸a et al., 2023] John Mendonc\\n¸a, Patr´\\nıcia Pereira,\\nJo˜\\nao Paulo Carvalho, Alon Lavie, and Isabel Trancoso.\\nSimple LLM prompting is state-of-the-art for robust and\\nmultilingual dialogue evaluation. In Proceedings of The\\nEleventh Dialog System Technology Challenge, 2023.\\n[Rastogi et al., 2023] Charvi Rastogi, Marco T´\\nulio Ribeiro,\\nNicholas King, Harsha Nori, and Saleema Amershi. Sup-\\nporting human-ai collaboration in auditing llms with llms.\\nIn AIES, 2023.\\n[Ribeiro and Lundberg, 2022] Marco\\nT´\\nulio\\nRibeiro\\nand\\nScott M. Lundberg.\\nAdaptive testing and debugging of\\nNLP models. In ACL (1), 2022.\\n[Saha et al., 2023] Swarnadeep Saha, Omer Levy, Asli Ce-\\nlikyilmaz, Mohit Bansal, Jason Weston, and Xian Li.\\nBranch-solve-merge improves large language model eval-\\nuation and generation. CoRR, abs/2310.15123, 2023.\\n[Saunders et al., 2022] William Saunders, Catherine Yeh,\\nJeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, and\\nJan Leike. Self-critiquing models for assisting human eval-\\nuators. CoRR, abs/2206.05802, 2022.\\n[Shen et al., 2023] Chenhui Shen, Liying Cheng, Xuan-Phi\\nNguyen, Yang You, and Lidong Bing.\\nLarge language\\nmodels are not yet human-level evaluators for abstractive\\nsummarization. In EMNLP (Findings), 2023.\\n[Shu et al., 2023] Lei Shu, Nevan Wichers, Liangchen Luo,\\nYun Zhu, Yinxiao Liu, Jindong Chen, and Lei Meng.\\nFusion-eval:\\nIntegrating evaluators with llms.\\nCoRR,\\nabs/2311.09204, 2023.\\n[Sulem et al., 2018] Elior Sulem, Omri Abend, and Ari Rap-\\npoport. BLEU is not suitable for the evaluation of text\\nsimplification. In EMNLP, 2018.\\n[Sun et al., 2022] Tianxiang Sun, Junliang He, Xipeng Qiu,\\nand Xuanjing Huang. Bertscore is unfair: On social bias\\nin language model-based metrics for text generation. In\\nEMNLP, 2022.\\n[Touvron et al., 2023] Hugo Touvron, Louis Martin, Kevin\\nStone, Peter Albert, Amjad Almahairi, Yasmine Babaei,\\nNikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,\\nShruti Bhosale, Dan Bikel, Lukas Blecher, Cristian\\nCanton-Ferrer, Moya Chen, Guillem Cucurull, David Es-\\niobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian\\nFuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal,\\nAnthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana\\nLiskovich, Yinghai Lu, Yuning Mao, Xavier Martinet,\\nTodor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin\\nNie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta,\\nKalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael\\nSmith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh\\nTang, Ross Taylor, Adina Williams, Jian Xiang Kuan,\\nPuxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, An-\\ngela Fan, Melanie Kambadur, Sharan Narang, Aur´\\nelien\\nRodriguez, Robert Stojnic, Sergey Edunov, and Thomas\\nScialom. Llama 2: Open foundation and fine-tuned chat\\nmodels. CoRR, abs/2307.09288, 2023.\\n[Wang et al., 2023a] Jiaan Wang, Yunlong Liang, Fandong\\nMeng, Haoxiang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu,\\nand Jie Zhou. Is ChatGPT a good NLG evaluator? a pre-\\nliminary study. In Proceedings of the 4th New Frontiers in\\nSummarization Workshop, 2023.\\n[Wang et al., 2023b] Peiyi Wang, Lei Li, Liang Chen, Dawei\\nZhu, Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, and\\nZhifang Sui. Large language models are not fair evalua-\\ntors. CoRR, abs/2305.17926, 2023.\\n[Wang et al., 2023c] Tianlu Wang, Ping Yu, Xiaoqing Ellen\\nTan, Sean O’Brien, Ramakanth Pasunuru, Jane Dwivedi-\\nYu, Olga Golovneva, Luke Zettlemoyer, Maryam Fazel-\\nZarandi, and Asli Celikyilmaz. Shepherd: A critic for lan-\\nguage model generation. CoRR, abs/2308.04592, 2023.\\n[Wang et al., 2023d] Yaqing Wang, Jiepu Jiang, Mingyang\\nZhang, Cheng Li, Yi Liang, Qiaozhu Mei, and Michael\\nBendersky.\\nAutomated evaluation of personalized\\ntext generation using large language models.\\nCoRR,\\nabs/2310.11593, 2023.\\n[Wang et al., 2023e] Yidong Wang, Zhuohao Yu, Zhengran\\nZeng, Linyi Yang, Cunxiang Wang, et al. Pandalm: An\\nautomatic evaluation benchmark for LLM instruction tun-\\ning optimization. CoRR, abs/2306.05087, 2023.\\n[Wang et al., 2023f] Zifan Wang, Kotaro Funakoshi, and\\nManabu Okumura. Automatic answerability evaluation for\\nquestion generation. CoRR, abs/2309.12546, 2023.\\n[Wu and Aji, 2023] Minghao Wu and Alham Fikri Aji. Style\\nover substance: Evaluation biases for large language mod-\\nels. CoRR, abs/2307.03025, 2023.\\n[Wu et al., 2023] Ning Wu, Ming Gong, Linjun Shou, Shin-\\ning Liang, and Daxin Jiang.\\nLarge language models\\nare diverse role-players for summarization evaluation. In\\nNLPCC (1), 2023.\\n[Xie et al., 2023] Zhuohan Xie, Miao Li, Trevor Cohn, and\\nJey Han Lau. Deltascore: Fine-grained story evaluation\\nwith perturbations. In EMNLP (Findings), 2023.\\n[Xu et al., 2023] Wenda Xu, Danqing Wang, Liangming\\nPan, Zhenqiao Song, Markus Freitag, William Wang, and\\nLei Li. INSTRUCTSCORE: towards explainable text gen-\\neration evaluation with automatic feedback. In EMNLP,\\n2023.\\n[Ye et al., 2023] Seonghyeon Ye, Doyoung Kim, Sungdong\\nKim, Hyeonbin Hwang, Seungone Kim, Yongrae Jo,\\nJames Thorne, Juho Kim, and Minjoon Seo.\\nFLASK:\\nfine-grained language model evaluation based on align-\\nment skill sets. CoRR, abs/2307.10928, 2023.\\n[Yuan et al., 2021] Weizhe Yuan,\\nGraham Neubig,\\nand\\nPengfei Liu. Bartscore: Evaluating generated text as text\\ngeneration. In NeurIPS, 2021.\\n[Yuan et al., 2024] Peiwen Yuan, Shaoxiong Feng, Yiwei Li,\\nXinglin Wang, Boyuan Pan, Heda Wang, and Kan Li.\\nBatcheval: Towards human-like text evaluation.\\nCoRR,\\nabs/2401.00437, 2024.\\n[Zhang et al., 2020] Tianyi Zhang, Varsha Kishore, Felix\\nWu, Kilian Q. Weinberger, and Yoav Artzi.\\nBertscore:\\nEvaluating text generation with BERT. In ICLR, 2020.\\n[Zhang et al., 2021] Yangjun Zhang,\\nPengjie Ren,\\nand\\nMaarten de Rijke.\\nA human-machine collaborative\\nframework for evaluating malevolence in dialogues.\\nIn\\nACL/IJCNLP (1), 2021.\\n[Zhang et al., 2023a] Chen Zhang, Luis Fernando D’Haro,\\nYiming Chen, Malu Zhang, and Haizhou Li.\\nA com-\\nprehensive analysis of the effectiveness of large lan-\\nguage models as automatic dialogue evaluators.\\nCoRR,\\nabs/2312.15407, 2023.\\n[Zhang et al., 2023b] Xinghua Zhang, Bowen Yu, Haiyang\\nYu, Yangyu Lv, Tingwen Liu, Fei Huang, Hongbo Xu, and\\nYongbin Li. Wider and deeper LLM networks are fairer\\nLLM evaluators. CoRR, abs/2308.01862, 2023.\\n[Zheng et al., 2023] Lianmin Zheng, Wei-Lin Chiang, Ying\\nSheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\\net al. Judging llm-as-a-judge with mt-bench and chatbot\\narena. CoRR, abs/2306.05685, 2023.\\n[Zhu et al., 2023] Lianghui Zhu, Xinggang Wang, and Xin-\\nlong Wang. Judgelm: Fine-tuned large language models\\nare scalable judges. CoRR, abs/2310.17631, 2023.\\n',\n",
       " 'AUGUST 2024\\n1\\nDeep Graph Anomaly Detection: A Survey and\\nNew Perspectives\\nHezhe Qiao, Hanghang Tong Fellow, IEEE, Bo An Senior Member, IEEE, Irwin King Fellow, IEEE, Charu\\nAggarwal Fellow, IEEE, Guansong Pang Member, IEEE\\nAbstract—Graph anomaly detection (GAD), which aims to identify unusual graph instances (e.g., nodes, edges, subgraphs, or graphs),\\nhas attracted increasing attention in recent years due to its significance in a wide range of applications. Deep learning approaches, graph\\nneural networks (GNNs) in particular, have been emerging as a promising paradigm for GAD, owing to its strong capability in capturing\\ncomplex structure and/or node attributes in graph data. Considering the large number of methods proposed for GNN-based GAD, it is of\\nparamount importance to summarize the methodologies and findings in the existing GAD studies, so that we can pinpoint effective model\\ndesigns for tackling open GAD problems. To this end, in this work we aim to present a comprehensive review of deep learning\\napproaches for GAD. Existing GAD surveys are focused on task-specific discussions, making it difficult to understand the technical\\ninsights of existing methods and their limitations in addressing some unique challenges in GAD. To fill this gap, we first discuss the\\nproblem complexities and their resulting challenges in GAD, and then provide a systematic review of current deep GAD methods from\\nthree novel perspectives of methodology, including GNN backbone design, proxy task design for GAD, and graph anomaly measures. To\\ndeepen the discussions, we further propose a taxonomy of 13 fine-grained method categories under these three perspectives to provide\\nmore in-depth insights into the model designs and their capabilities. To facilitate the experiments and validation of the GAD methods, we\\nalso summarize a collection of widely-used datasets for GAD and empirical performance comparison on these datasets. We further\\ndiscuss multiple important open research problems in GAD to inspire more future high-quality research in this area. A continuously\\nupdated repository for GAD datasets, links to the codes of GAD algorithms, and empirical comparison is available at\\nhttps://github.com/mala-lab/Awesome-Deep-Graph-Anomaly-Detection.\\nIndex Terms—Graph Anomaly Detection, Graph Neural Networks, Deep Learning, Anomaly Detection, Graph Representation Learning\\n✦\\n1\\nINTRODUCTION\\nGraph anomaly detection (GAD) aims to identify graph\\ninstances (e.g., node, edge, sub-graph, and graph) that\\ndo not conform with the normal regime. It has been an\\nactive research area with wide application in detecting\\nabnormal instances in a variety of graph/network data, e.g.,\\nabusive user behaviors in online user networks, fraudulent\\nactivities in financial networks, and spams in social networks.\\nFurthermore, since the relations between data samples can be\\nmodeled as similarity graphs, one can also use GAD methods\\nto discover anomalies in any set of data objects (as long as\\nan appropriate pairwise similarity function is available).\\nDue to the complex structure of graphs, traditional\\nanomaly detection methods cannot be directly applied to\\ngraph data. In recent years, graph neural networks (GNNs)\\nhave shown promising capabilities in modeling and learning\\nthe representation of graphs by capturing structural patterns,\\ninspiring a large number of GNN-based approaches for GAD.\\nHowever, the popular GNN designs, such as aggregation\\nof node representations and optimization objectives, may\\nlead to over-smoothing, indistinguishable representations of\\n•\\nHezhe Qiao and Guansong Pang are with School of Computing and\\nInformation Systems, Singapore Management University. Hanghang\\nTong is with Department of Computer Science, University of Illinois\\nat Urbana-Champaign. Bo An is with College of Computing and\\nData Science, Nanyang Technological University. Irwin King is with\\nDepartment of Computer Science & Engineering, Chinese University of\\nHong Kong. Charu Aggarwal is with IBM T. J. Watson Research Center.\\nCorresponding author: G. Pang (gspang@smu.edu.sg)\\nnormal and abnormal graph instances, which significantly\\nlimits their applications in real-world use cases. Many novel\\nGNN-based approaches specifically designed for GAD have\\nbeen proposed to tackle the these challenges. In this work,\\nto summarize the current methodologies and findings, we\\nprovide a systematic and comprehensive review of current\\ndeep GAD techniques and how they may tackle various types\\nof challenges in GAD. We also propose several important\\nopen research problems in GAD to inspire more future\\nresearch in this area.\\nRelated surveys. There have been several reviews on\\nanomaly detection in recent years, e.g., [2], [4], [81], [89], [103],\\n[113], but most of them are focused on non-deep-learning-\\nbased methods for GAD [2], [4], [103], or on general data\\nrather than graph data [7], [89]. The studies [81], [113] are on\\ndeep GAD, but the reviews are limited to a relatively narrow\\npoint of view. For example, Ma et al. [81] focus on task-\\nspecific discussions, with limited reviews on the technical\\ndevelopment, while Liu et al. [64] and Tang et al. [113] focus\\non establishing a performance benchmark for unsupervised\\nand supervised GAD methods respectively. Another related\\nwork is Liu et al. [71], but it is restricted to supervised\\nimbalanced graph learning. Although these surveys provide\\nuseful guidelines for the development of methods for GAD,\\nit is difficult to understand the technical insights of existing\\nmethods and their limitations in addressing some unique\\nchallenges in GAD.\\nOur work. To fill this gap, we aim to offer a distinctive\\nreview on GAD to discuss these insights, the limitations,\\nand the future research opportunities in this crucial topic.\\narXiv:2409.09957v1  [cs.LG]  16 Sep 2024\\nAUGUST 2024\\n2\\nSpecifically, we start with the discussion on the problem\\ncomplexities and their resulting unique challenges in GAD.\\nWe then provide a systematic review of current deep GAD\\nmethods from three novel perspectives of methodology,\\nincluding GNN backbone design, proxy task design for GAD,\\nand graph anomaly measures. To deepen the discussions,\\nwe further propose a taxonomy of 13 fine-grained method\\ncategories under these three perspectives to provide more in-\\ndepth insights into the model designs and their capabilities.\\nTo facilitate the experiments and validation of the GAD\\nmethods, we also summarize a collection of widely-used\\ndatasets for GAD and empirical performance comparison on\\nthese datasets. A comparison of our work to these related\\nsurveys is summarized in Table 1.\\nIn summary, our major contributions are as follows:\\n•\\nThe survey provides important insights into the\\nproblem complexities and the resulting challenges\\nthat are unique for the task of GAD (Sec. 2).\\n•\\nWe introduce a novel taxonomy of current deep GAD\\nmethods, which offers in-depth understanding of the\\nmethods from three technical design perspectives,\\nincluding GNN backbone design, proxy task design,\\nand graph anomaly measures (Sec. 3).\\n•\\nWe then introduce 13 fine-grained method categories\\nunder these three perspectives to provide more in-\\ndepth insights into the model designs (i.e., key intu-\\nition, assumption, learning objectives, advantages and\\ndisadvantages) and their capabilities in addressing\\nthe unique challenges in GAD (Secs. 4, 5, and 6).\\n•\\nWe further discuss multiple important future research\\ndirections that involve largely unsolved open prob-\\nlems in GAD. Solutions in these directions would\\nopen up new opportunities for addressing the unique\\nchallenges in GAD (Sec. 7).\\n•\\nWe also summarize a large number of representative\\ndeep GAD methods from the 13 categories and a\\nlarge collection of GAD benchmark datasets, and\\nfurther provide quantitative comparison results on\\nthese datasets (Appendices A, B, and C).\\n2\\nPROBLEMS AND CHALLENGES IN GAD\\nThis section discusses some unique complexities and chal-\\nlenges in GAD.\\n2.1\\nMajor Problem Complexities\\nThe complexities in GAD can be summarized in two ways.\\nOne source of the complexities lies in some inherent charac-\\nteristics of graph data.\\n•\\nP1. Structural dependency. The samples are typically\\ncorrelated/connected with each other instead of\\nbeing independent. The connections are of different\\nsemantics, e.g., it could be a purchase relationship\\nin a social network, or a citation relationship in a\\ncitation network. The complexity of graph structure\\nis reflected in connectivity patterns, dependency, or\\ninfluence at different levels of graph data, which play\\na significant role in defining what is abnormal on\\ngraphs [4]. For example, different from i.i.d. data,\\nwhere the anomalies are independent of the context,\\nthe anomalies in graphs often depend on the context\\nof a graph data instance, e.g., the neighboring nodes\\nof a node. Anomalies may be considered as normal\\nin one context but abnormal in another.\\n•\\nP2. Diverse types of graph. There are many types\\nof graphs in the real world, each serving different\\npurposes and applications. Graphs can be categorized\\ninto static and dynamic types, depending on whether\\nthey change over time. It can also be divided into\\nheterophilic and homophilic graphs according to the\\ntype of connection [154], [163]. The definition of\\nanomaly in one type of graph can differ significantly\\nfrom that in other types of graph. In particular, a\\ngraph instance (e.g., node/edge/graph) that is clearly\\nabnormal in a dynamic graph at a specific time step\\n(i.e., a static graph) can demonstrate strong normality\\nwhen looking at the evolution of the graph; similarly,\\nwe can have opposite abnormality of a graph instance\\nin a homophilic graph vs. in a heterophilic graph.\\nDealing with diverse types of graphs requires the\\nGAD methods to adapt its learning strategy based on\\nits unique properties of graphs.\\n•\\nP3. Computational complexity in handling large-\\nscale graphs. With the increasing amount of online\\ndata, modern applications can include very large-scale\\ngraph data with millions/billions of nodes and/or\\nedges [43], [48], [98], [113], such as those in web-scale\\nsocial networks, financial transaction networks, cyber\\nnetworks, user-product e-commerce networks, and\\ncitation networks. To identify anomalies using global\\nstructural contexts, it is essential to consider the full\\ngraph structural information, or a large proportion\\nof the structural relations. The key complexity here\\nis to deal with the time and space complexities when\\nloading such large-scale structural relation data.\\nAnother source is from the variety of graph abnormalities.\\n•\\nP4. Diverse graph anomaly instances. In contrast to\\nanomaly detection in other forms of data, anomalies\\nwithin graph data can arise from different compo-\\nnents, such as nodes, edges, sub-graphs, or the entire\\ngraph [81]. Moreover, graph anomalies can manifest\\nthemselves in diverse ways, depending on the struc-\\nture and attribute information of graph data. This\\nhighlights the need for GAD methods to incorporate\\na range of techniques focused on identifying irregular\\npatterns across nodes, edges, subgraphs, and the\\nentirety of the graph.\\n•\\nP5. Large variation in graph abnormality. Anomalies\\nin graphs can manifest in different forms, including\\nabnormality in graph attributes, graph structure, or\\nthe composition of graph attributes and structure\\n[4]. Some exemplars include attribute anomalies\\n(i.e., graph instances that are exceptional in a graph\\nattribute set) [3], [89], structural anomalies (i.e., graph\\ninstances that connect different communities, forming\\ndense connections with others) [18], [81], contextual\\nanomalies (i.e., graph instances that have different\\nattribute values compared to other nodes in the same\\ncommunity) [18], [81], and local affinity anomalies\\n(i.e., graph instances that demonstrate significantly\\nAUGUST 2024\\n3\\nTABLE 1: A comparison of our work to existing surveys on anomaly detection.\\nGeneric Data\\nGraph Data\\nGAD Perspectives\\nEmpirical Evaluation\\nSurvey\\nYear\\n-\\nNode\\nEdge\\nGraph\\nGNN Backbone\\nProxy Task\\nAnomaly Measures\\nDataset\\nCode\\nComparison\\nAggarwal et al. [2]\\n2014\\n•\\n•\\nAkoglu et al. [4]\\n2015\\n•\\n•\\n•\\n•\\nRanshous et al. [103]\\n2015\\n•\\n•\\n•\\n•\\nYu et al. [139]\\n2016\\n•\\nPourhabibi et al. [97]\\n2020\\n•\\n•\\nBoukerche et al. [7]\\n2020\\n•\\nMa et al. [81]\\n2021\\n•\\n•\\n•\\n•\\n•\\nPang et al. [89]\\n2021\\n•\\n•\\n•\\n•\\nLiu et al. [64]\\n2022\\n•\\n•\\n•\\n•\\nTang et al. [113]\\n2023\\n•\\n•\\n•\\n•\\nLiu et al. [71]\\n2023\\n•\\n•\\n•\\n•\\n•\\nOurs\\n2024\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\n•\\nweak affinity to their connected instances compared\\nto other instances [69], [98]). Also, graph abnormality\\nmay vary from a local context to a global context,\\ne.g., the node attributes in a 1-hop neighborhood\\nvs. that in the full graph. This can lead to a highly\\ncomplex composition set of graph abnormalities, i.e.,\\nabnormality in attributes, structure, or both attributes\\nand structure conditioned on a certain context, having\\nvery different definitions to the conventional anomaly\\ntypes – point, conditional, and group anomalies [3],\\n[11], [89] – in general AD.\\nIn addition, there are some complexities inherited from\\ngeneral AD but amplified in GAD:\\n•\\nP6. Unknowingness of abnormality. Many abnormal-\\nities remain unknown until they actually occur [89],\\nin which no prior knowledge about the abnormality\\nis available for the modeling. Further, one type of\\nabnormality can show very different behaviors to\\nthe other types of abnormality in a single graph, e.g.,\\nthe heterogeneous abnormality in graph attributes vs.\\nthat in graph structure, in a node set vs. in an edge\\nor subgraph set, in a 1-hop local structure context vs.\\nin a higher-order structural context. Thus, knowing\\none or more types of graph anomalies may not be\\ngeneralize to the other types of anomalies.\\n•\\nP7. Data imbalance. Due to the rare occurrence of\\nanomalies, there is typically a large sample imbalance\\nbetween normal and anomaly classes [3], [11], [89].\\nThis also applies to GAD, but this complexity is\\nlargely amplified in GAD due to potential long-tailed\\ndistributions in graph structure/attributes [2], [71], in\\naddition to the imbalance in the class sample size.\\n•\\nP8. Abnormality camouflage. Bad actors may adjust\\ntheir behaviors to camouflage the abnormality of the\\nanomalous instances, making them difficult to detect\\nusing popular AD methods. The anomaly camouflage\\nin GAD refers to the phenomenon where anomalous\\ngraph instances disguise themselves as normal within\\na local neighborhood or the global graph. This may\\nbe done through various mechanisms, e.g., attribute\\nmanipulation and structural manipulation in a graph\\n[25], [73], [99], [138].\\n2.2\\nMajor Challenges\\nThe aforementioned problem complexities lead to the follow-\\ning largely unsolved challenges in GAD, which deep GAD\\napproaches can tackle to various extent:\\n•\\nC1. Graph structure-aware GAD. As discuss in P1,\\ngraph anomalies are not solely determined by their\\nown attributes but also by their structural context.\\nThus, the GAD methods are required to effectively\\ncapture those structural dependency in their anomaly\\nscoring functions. The effect of this dependency in\\nanomaly scoring may vary significantly from ho-\\nmophilic graphs to heterophilic graphs, and from\\nstatic graphs to dynamic graphs (P2). On the other\\nhand, oversmoothing is a common issue when model-\\ning the graph structure information, which is referred\\nto as a phenomenon in graph representation learning\\nwhere the learned representations of different nodes\\nbecome overly similar due to the iterative aggregation\\nof representations of neighboring nodes to obtain\\nthe representations of the target nodes. In GAD,\\nthis can lead to node/subgraph representations that\\nsmooth out anomalies as well, making them indis-\\ntinguishable between normal and abnormal graph\\ninstances [25], [98]. Therefore, it is challenging to\\nmodel diverse structural influences in the anomaly\\nscoring on graphs, while avoiding adverse effects like\\nrepresentation oversmoothing.\\n•\\nC2. GAD at scale. As discussed in P3, large-scale\\ngraphs with millions or even billions of nodes/edges\\npresents a significant computational challenge to\\nGAD methods that aim to model global or higher-\\norder structure information [113]. Existing large-\\ngraph modeling methods are challenging to apply\\ndirectly to GAD due to the extreme imbalance in\\nthe data (P7). While some subgraph and sampling\\ntechniques have been proposed to address this issue,\\nthey often fail to capture the full structural informa-\\ntion, resulting in sub-optimal performance [25], [69],\\nparticularly for unsupervised GAD. Consequently,\\nperforming anomaly detection on large-scale graphs\\nremains a long-standing challenge in the area.\\n•\\nC3. Generalization to different graph anomalies.\\nAs discussed in P4, there are various types of graph\\nanomaly instances, making it hard to apply a one-for-\\nall approach. Achieving this requires a combination\\nof robust feature extraction and versatile detection\\nmodels. Further, the anomalies can manifest in vari-\\nous forms, ranging from attributes, structure and their\\ncomposition (P5). However, most existing methods\\nare designed for a specific type of anomaly in an un-\\nsupervised manner, which typically have a low recall\\nrate [18], [69], [98]. The challenge is amplified when\\nthe training data does not illustrate every possible\\nAUGUST 2024\\n4\\nclass of anomaly (P6), regardless of unsupervised or\\nsupervised methods [1], [16], [90]–[92], [121], [161].\\n•\\nC4. Balanced GAD. As discussed in P7, since the\\nnumber of normal instances is significantly larger\\nthan that of abnormal instances, the models tend to\\nbias towards the majority class during the training,\\ni.e., they perceive the normal patterns more frequently.\\nConsequently, the models might be overly specialized\\nin recognizing normal instances while generalizing\\npoorly on the anomalies. Often the detection decision\\nthresholds are crucial for making predictions for some\\nmethods [25], [113], and poorly chosen thresholds\\ncan worsen the effects of data imbalance. Thus, the\\nchallenge is to avoid biased GAD.\\n•\\nC5. Robust and interpretable GAD. GAD in real\\napplications needs to be robust against various ad-\\nverse conditions, such as abnormality camouflage (P8)\\n[25], [37], [113] and unknown anomaly contamination\\n[98], [99]. Addressing the abnormality camouflage\\nor anomaly contamination may require models that\\ncan capture subtle differences between normal graph\\ninstances and camouflaged instances, and complex\\nrelationships within the graph as well. Besides, an\\nexplanation of why a graph instances is detected as\\nanomaly can be crucial for the utility of the predic-\\ntions in real applications [62], [106], [106], but it is a\\nlargely unexplored area. For example, in bank fraud\\ndetection, it is essential to provide a comprehensive\\nexplanation of the detected fraudulent activity for\\nfacilitating the subsequent investigation, but it is\\nchallenging to link the fraud to specific attributes\\nof particular transactions (nodes) and their relations\\n(edges) at a specific time period.\\n3\\nCATEGORIZATION OF DEEP GAD\\n3.1\\nPreliminaries\\nGAD aims to recognize the anomaly instances in graph data\\nthat may vary from nodes, edges to subgraphs by learning\\nan anomaly scoring function. Traditional GAD methods\\nachieve anomaly detection using matrix decomposition and\\nresidual analysis [4]. However, their performance is often bot-\\ntlenecked due to the lack of representation power to capture\\nthe rich structure-attribute semantics of the graph data and\\nto handle high-dimensional node attributes. In recent years,\\nGNNs have been widely used in GAD due to their powerful\\nrepresentation learning ability. Some representative GNNs\\nlike GCN [54], GraphSage [39], and GCL [137] attract much\\nattention in node representation learning in graphs. These\\nGNNs can be leveraged to learn the expressive representation\\nof different graph instances for GAD.\\nDefinition and Notation. In this section, we introduce\\nthe definitions and notations used throughout the paper. We\\ndenote a graph by G = (V, E) where V and E denote the\\nnode set and edge set respectively. For the graph G, we use\\nX ∈RN×M to denote the matrix of node attributes and xi ∈\\nRM is the attribute vector of vi ∈V, and A ∈{0, 1}N×N\\nis the adjacency matrix of G with Aij = 1 iff (vi, vj) ∈E,\\nwhere N is the number of node.\\nProblem Statement. GAD can be divided into anomaly\\ndetection at the node-level, edge-level, sub-graph level and\\ngraph-level settings. The node-, edge- and subgraph-level\\nAD tasks are typically performed within a single large graph\\nG, where the input samples are nodes v ∈G, edges e ∈G,\\nand subgraphs s ⊂G, respectively. For the graph-level AD\\ntask, the input samples are a set of graphs G = {G1, G2, · · · }.\\nFor the sake of simplicity and generality across different\\nlevels of GAD, we uniformly denote the input samples as\\no, i.e., o can denote a node v, an edge e, a subgraph s, or a\\nfull graph G, depending on their use in specific algorithms\\nor models. Then GAD aims to learn an anomaly scoring\\nfunction f : {o1, o2, · · · } →R, such that f(o) < f(o′), ∀o ∈\\nOn, o′ ∈Oa, where On and Oa denote the set of normal and\\nabnormal graph instances, respectively. Since anomalies are\\nrare samples, it is typically assumed that |On| ≫|Oa|.\\n3.2\\nCategorization of Deep GAD Methods\\nIn order to facilitate a comprehensive understanding of the\\nresearch progress in GAD, we introduce a new taxonomy\\nthat categorizes current GAD methods into three main\\ngroups,including GNN backbone design, GAD proxy task\\ndesign, and graph anomaly measures, depending on the\\ninsights offered by each method. This enables us to review\\nthe GAD methods from three different technical perspectives.\\nTo elaborate the insights in each perspective, we further\\ncategorize the methods into fine-grained 13 groups. An\\noverview of the taxonomy is shown in Figure 1.\\nMore specifically, general GNNs can not be directly\\napplied to GAD due to the aforementioned problem com-\\nplexities, and thus, there is a group of studies that focus on\\ndesigning suitable GNN backbones for GAD. The design\\nof the GNN backbones can be divided into discriminative\\nGNNs and generative GNNs according to the improvement\\nof different modules in GNNs. The second main category of\\nmethods is on the GAD models constructed by optimizing\\na diverse set of well-crafted learning objective functions to\\nform a proxy task that can guide the GAD models to capture\\ndiverse graph anomaly/normal patterns without the need for\\nground-truth labels. This category of methods can be further\\ndivided into five subcategories based on the modeling in\\nthe proxy tasks. Lastly, there is a group of methods that\\nbuild GAD models based on anomaly measures that are\\ndesigned specifically for graph data. These methods can be\\nfurther grouped into four subcategories depending on the\\ntype of graph anomaly measures used. A summarization of\\nrepresentative algorithms for each type of GAD approaches\\nis presented in Table 2 in Appendix A.\\n4\\nGNN BACKBONE DESIGN\\nThis category of methods aims at leveraging GNNs to learn\\neffective representations of graph instances for downstream\\nanomaly detection tasks. Due to its strong capability to\\nrepresent graph-structured data, GNNs can effectively obtain\\nexpressive node representations through aggregation among\\nthe connected nodes. However, unlike general node/graph\\nclassification datasets, GAD datasets are often extremely\\nclass-imbalanced, which prevents GNNs from being directly\\napplied to GAD datasets. Therefore, several GNNs have\\nbeen proposed to handle the imbalance problem for more\\neffective GAD. Concretely, this type of methods can be\\nAUGUST 2024\\n5\\nDeep GAD\\nGNN Backbone Design (§4)\\nDiscriminative GNNs\\nAggregation\\nMechanism\\nCARE-GNN [25]; GraphConsis [73]; PCGNN\\n[66]; NGS [100]; GHRN [36]; H2-FDetector\\n[108]; BLS [22]; FRAUDRE [142]; GAGA\\n[124]; GDN [35]; GmapAD [82]; MTIGATE\\n[12]; HedGe [147]; PMP [165]; RAND [6];\\niGAD [143]\\nFeature\\nTransformation\\nGDN [35]; AMNet [10]; BWGNN [114] SEC-\\nGFD [133]; RQGNN [24]; SplitGNN [125];\\nSmoothGNN [23]\\nGenerative GNNs\\nFeature\\nInterpolation\\nGraphSMOTE [150]; GraphENS [94]; DA-\\nGAD [60]; AuGAN [159]\\nNoise\\nPerturbation\\nGGAD [99]; SDGG [8]; GODM [65]; DIFFAD\\n[80]; ConsisGAD [14]\\nProxy Task Design (§5)\\nGraph Reconstruction\\nDOMINANT [18]; AnomalyDAE [31]; GUIDE [141]; HO-GAT\\n[45]; SpecAE [58]; ComGA [77]; ALARM [96]; REMAD [146];\\nMSAD [52]; GAD-NR [104]; Netwalk [140]; MUL-GAD [74];\\nAdoNE [5]; ResGCN [95]; Sub-CR [145]; VGOD [49]; AANE [26];\\nSTRIPE [63]; HimNet [84]\\nGraph Contrastive\\nLearning\\nCoLA [69] ; SL-GAD [155]; GCCAD [13]; ANEMONE [51];\\nGADMSL [27] PREM [85]; GRADATE [27]; CONAD [135] ;\\nFMGAD [132]; SIGNET [67]; MAG [75]; Sub-CR [145]; ARISE\\n[28]; HCM-A [47]; OCGTL [101]; NLGAD [29]; ACT [120];\\nFedCAD [55]\\nGraph Representation\\nDistillation\\nGlocalKD [79]; GLADST [59]; FGAD [9]\\nAdversarial\\nGraph Learning\\nAEGIS [17]; GAAN [15]; CFAD [131]; GADY [76]; GGA [83]\\nScore Prediction\\nMeta-GAD [21]; SAD [116]; WEDGE [157]\\nGraph Anomaly\\nMeasures (§6)\\nOne-class Distance\\nOCGNN [122]; AAGNN [160]; DOHSC [148]; OCGTL [101];\\nDeepSphere [115]; Netwalk [140]; HRGCN [56]\\nCommunity Adherence\\nMHGL [158]; Netwalk [140]\\nLocal Affinity\\nTAM [98]; CLAD [53]; PREM [85]; ARC [68]\\nGraph Isolation\\nDIF [134]; GCAD [164]\\nFig. 1: Overview of the proposed taxonomy of deep GAD from three high-level and 13 fine-grained technical perspectives.\\n(a) Hard Edge Selection\\n(b) Soft Edge Selection\\nPruned Edge \\nConstructed Edge\\n1iw\\ni\\n1\\n2\\n3\\n4\\n2\\niw\\n3\\niw\\n4\\niw\\ni\\n1\\n2\\n3\\n4\\n(c) Edge Synthesis\\ni\\n1\\n2\\n4\\n5\\n6\\nFig. 2: Three categories of aggregation mechanism.\\n(a)  Gradient-based Feature Scoring\\n(b) Spectral Graph Filter\\nFeature Separability\\nHigh-frequency\\nLow-frequency\\nNormal\\nAbnormal\\n\\uf06c\\n( )\\ng \\uf06c\\n...\\n...\\n...\\n...\\n...\\n...\\n...\\nImportance Score\\nFig. 3: Two categories of feature transformation.\\nroughly divided into discriminative- and generative-based\\nGNNs for GAD.\\n4.1\\nDiscriminative GNNs\\nDiscriminative GNN-based GAD methods refer to a GNN\\narchitecture specifically designed for discriminating nor-\\nmal graph instances from the abnormal ones, where the\\ndiscrimination is typically achieved through a supervised\\nlearning manner. Thus, the discriminative GNNs are typically\\ntrained on the labeled graph dataset containing examples of\\nboth normal and abnormal instances. The core idea in these\\nmethods is to adapt the conventional GNN backbones in a\\nway so that the message passing in GNNs can capture the\\nmajority patterns or the deviation patterns better.\\nLet hi be the feature representation of a graph instance oi\\nthat is obtained through l layers of feature aggregation (FAG)\\nin a GNN, i.e., hi = FAG1:l(oi, Ni) where Ni represents\\nthe neighbor set of a graph instance oi, these methods are\\ntypically optimized via a general cross-entropy loss to train\\nthe discriminative GAD model.\\nLcls = −\\nX\\noi∈G\\n[yi log pi + (1 −yi) log(1 −pi)],\\n(1)\\nwhere yi denotes the class label of the instance oi and\\npi = MLP1:m(hi) is the output of a mapping function that\\ngoes through m layers of multiple perceptrons (MLP) to\\nproject the feature hi to a probability of the sample being\\nabnormal/normal. During inference, given a graph instance,\\noj, pj or its inverse 1 −pj can be used as its anomaly score.\\nDifferent GNN-based encoders can be used to obtain\\nthe feature representation h, such as graph convolutional\\nnetworks (GCNs) [54], graph attention networks (GAT) [117],\\nor GraphSage [39]. Depending on which part of the learning\\nAUGUST 2024\\n6\\npipeline is focused, we group the existing methods in this\\ncategory into two sub-categories, including the methods\\nthat focus on the GNN neighborhood aggregation design,\\ni.e., FAG1:l(oi, Ni), and that focus on feature transformation\\nwith the raw attributes or node embeddings as input, i.e.,\\nTransformation(hi) or Transformation(xi). Below we introduce\\neach of them in detail.\\n4.1.1\\nAggregation Mechanism\\nAs a simple and effective way to obtain the representation\\nof nodes in GNNs, feature aggregation plays a crucial role\\nin learning node representations by aggregating information\\nfrom neighboring nodes in a graph. Thus, to create GNN-\\nbased methods for GAD, one principled approach is to craft\\nsuitable feature aggregation FAG designs that are sensible\\nfor graph anomaly instances.\\nAssumption. The GAD methods in this line assume that\\nthe connected instances from the same class in graphs have\\nsimilar characteristics, from which we can perform feature\\naggregation to obtain discriminative normality/abnormality\\npatterns.\\nA widely-used FAG mechanism is as follows [54]:\\nh(l)\\ni\\n= σ\\n\\x10\\nW(l) \\x10\\nh(l−1)\\ni\\n+ AGG\\n\\x10n\\nh(l−1)\\nj\\n| oj ∈Ni\\no\\x11\\x11\\x11\\n,\\n(2)\\nwhere h(l)\\ni\\nis the feature representation of instance i in\\nthe l-th layer, σ is an activation function, and W(l) is the\\ntraining parameters in the l-th layer. The graph instance\\noi is often set as a node vi, and Ni is typically the 1-\\nhop neighborhood of the node vi. However, due to the\\noversmoothing representation issue (C1 in Sec. 2.2) , directly\\napplying such neighborhood aggregation mechanism can\\nlargely reduce the discriminability of of graph anomalies,\\nespecially for those whose abnormal behaviors are subtle (C3\\nin Sec. 2.2). Therefore, a variety of methods were proposed\\nto enforce distinguishable representations for normal and\\nabnormal graph instances throughout a number of feature\\naggregation iterations. These methods can be summarized\\nvia the following principled framework:\\nˆh(l)\\ni\\n= AGG\\n\\x10n\\nh(l−1)\\nj\\n| oj ∈Φ (Ni) ∪Ψ(V)\\no\\x11\\n,\\nh(l)\\ni\\n= σ\\n\\x10\\nW(l) \\x10\\nh(l−1)\\ni\\n+ ˆh(l)\\ni\\n\\x11\\x11\\n,\\n(3)\\nwhere Φ(·) and Ψ(·) represent a filtering function on the\\nneighborhood set N and an edge synthesizer on the full node\\nset V, respectively. Depending on how the methods specify\\nthe Φ or Ψ function, we further categorize them into two fine-\\ngrained groups – hard/soft edge selection and edge synthesis\\n– to gain better insights into these existing methods.\\n• Hard Edge Selection. Popular aggregation mecha-\\nnisms in GNN methods are built upon a homophily assump-\\ntion that connected nodes come from the same class. Thus,\\nthe existence of non-homophily edges (i.e., edges that connect\\nnodes of different classes, also referred to as heterophily\\nedges below) in a GAD dataset can greatly hinders the\\ndiscriminability of the learned feature representations. As\\nshown in Fig. 2(a), one popular strategy is to instantiate\\nΦ (Ni) that prune the heterophily edges w.r.t. the normal\\nclass, referred to as hard edge selection. Below we review\\nthe methods in this line.\\nIn order to enhance the homophily relations, CARE-GNN\\n[25] devises a label-aware similarity measure to find informa-\\ntive neighboring nodes during the aggregation where Φ (Ni)\\nis instantiated by a node selector that chooses the neighbors\\nwith high similarity. Moreover, a reinforcement learning\\nmodule is also used in [25] to find the optimal amounts\\nof neighbors to be selected. MITIGATE [12] implements\\nΦ (Ni) via a masked aggregation mechanism that utilizes\\nthe distance-based clustering algorithm to choose a subset\\nof high-representative nodes, in which the nodes that are\\nclosest to the cluster centers are chosen. GmpaAD [82] takes\\na similar clustering-based approach as MITIGATE, but it\\nuses a differential evolutionary algorithm to find the optimal\\nmapping strategy and generate the representative nodes\\ngiven the selected candidates from a clustering method. On\\nthe other hand, H2-FDetector [108] categorizes the edges\\ninto homophily and heterophily connections in the graph,\\nand further designs a new information aggregation strategy\\nensure that the homophily connections propagate similar\\ninformation while the heterophily connections propagate\\ndifferent information.\\nIn addition to using distance, Φ can also be specified via\\nmeta learning or reinforcement learning. BLS [22] is the rep-\\nresentative method that enhances the FAG mechanism under\\nimbalanced and noisy scenarios by selecting important nodes\\nvia a meta-learning gradient of the learning loss. AO-GNN\\n[46] employs a reinforcement learning method supervised by\\na surrogate reward based on AUC performance to prune the\\nheterophily edges. NGS [100] takes a meta-graph learning\\napproach that devises a differentiable neural architecture to\\ndetermine a set of optimized message passing structures and\\nthen combines multiple searched meta-graphs in FAG.\\n• Soft Edge Selection. Another research line is adopt-\\ning an attention mechanism in GNNs by assigning the\\nweights for each edge for soft edge selection for GAD,\\nrather than hard edge selection, as demonstrated in Fig. 2(c).\\nThis weight is generally obtained through the relationship\\nbetween node embeddings, which serves as an effective way\\nto enforce the importance of some specific edge relations in\\nthe feature aggregation. GAT [117] is widely used as the basic\\nbackbone, on top of which a variety of designs is introduced\\nin the methods of this category for GAD. Specifically, the\\ngeneral attention mechanism in GAT can be formulated as:\\nh(l)\\ni\\n= σ\\n\\uf8eb\\n\\uf8edX\\noj∈N(i)\\nΦ (hi, hj; θ) Wh(l)\\nj\\n\\uf8f6\\n\\uf8f8,\\n(4)\\nwhere Φ indicates a weight learning function with param-\\neters θ applied on the embedding of a graph instance\\noi and its neighbors oj. It represents the contribution of\\nrelations/neighbors to the target instance oi, where the\\ninstance oi is often specified as a node vi. For instantiating\\nΦ, GraphConsis [73] reveals an inconsistency phenomenon\\nin node connections that abnormal nodes can have a high\\nlikelihood of being connected to normal nodes to camouflage\\ntheir abnormality. It then introduces a consistency scoring-\\nbased method based on node embedding similarities and\\na self-attention mechanism to assign weights for different\\nconnections in the aggregation in Φ. FRAUDRE [142] extends\\nthe inconsistency-based scoring method to include three\\ntypes of graph inconsistencies in features, topology, and\\nAUGUST 2024\\n7\\nstructural relations to consider the importance of different\\nconnections. On the other hand, PMP [165] introduces\\na partitioning message passing to independently handle\\nthe heterophily and homophily neighbors preventing the\\ngradients in the optimization from being dominated by\\nnormal nodes. To achieve this, Φ is implemented by a weight\\ngenerator function to adaptively adjust the influence of\\nneighbors from different classes to the target node.\\n• Edge Synthesis. The edge selection function Φ focuses\\non local structure only. Edge synthesis function Ψ can often\\nbe used to complement Φ in capturing more global patterns\\nfor GAD, as demonstrated in Fig. 2(b). For example, GHRN\\n[36] prunes the inter-class edges by emphasizing and delin-\\neating the high-frequency components of the graph. Apart\\nfrom edge reduction, the indirect link between nodes can\\nalso be beneficial for the normality representation learning\\n[36]. To this end, GHRN introduces a global node selector\\nΨ(V) that chooses nodes beyond the neighboring nodes of\\nthe target node to introduce this information into the feature\\naggregation, which can be seen as an edge synthesizer that\\nconnects distant nodes to a target node. PCGNN [66] specifies\\nΨ(V) using a subgraph construction method consisting\\nof class-label-balanced node and edge samplers to tackle\\npotential issues arising from the skewed class distribution.\\nTo this end, it incorporates the label information into the\\nsampling process to choose nodes and edges for its sub-\\ngraph construction. A distance function is also used to\\nsimplify the neighborhood in the sub-graphs. NSReg [121]\\nleverages a novel normal structure regularization method\\nwhere the normal-node-oriented relation is used to enforce\\nstrong normality into the representation learning to avoid\\noverfitting to the labeled abnormal nodes. The relation repre-\\nsentations are generated through a learnable transformation\\nthat fuses the representations of relevant nodes, which are\\nsubsequently used to optimize the normal-node-oriented\\nrelation prediction and the representation learner.\\nAdvantages. The key advantages of discriminative GNN-\\nbased GAD methods are as follows. (i) Treating anomaly\\ndetection as an end-to-end imbalanced classification task\\nsimplifies the GAD problem, allowing the use of available\\nabnormal samples to detect known graph anomaly instances.\\n(ii) This approach does not rely on the reconstruction of the\\ngraph structure, which significantly reduces memory usage\\nand enhances its scalability for large-scale graphs.\\nDisadvantages. They also have some major disadvan-\\ntages. (i) Since these methods require some labeled graph\\ndata as supervision information, they become inapplicable\\nor less effective in practical applications where such data is\\ndifficult to obtain. (ii) Edge selection may lead to the loss of\\nimportant structure information while edge synthesis may\\nintroduce noise or some irrelevant structure information into\\nthe message passing in GNNs.\\nChallenges Addressed. The tailored GNNs for GAD en-\\nable effective modeling of graph structure and its interaction\\nwith graph attribute information (C1). They may also be able\\nto learn more discriminative features for detecting subtle\\nanomalies that are similar to labeled abnormal samples (C3).\\nSince these methods require local feature aggregation, they\\ncan often scale up to large graphs (C2).\\n4.1.2\\nFeature Transformation\\nIn addition to the efforts on the aggregation mecha-\\nnism, another popular approach to obtain discrimina-\\ntive features for GAD is to perform feature transforma-\\ntion on either the graph instance representations from\\nGNNs, i.e., Transformation(hi), or raw attributes, i.e.,\\nTransformation(xi). This is crucial since datasets used in\\nGAD can often contain a substantial proportion of feature in-\\nformation that is irrelevant, or even noisy, to GAD. There are\\ntwo popular approaches to instantiate this Transformation(·)\\nfunction: one is to use gradient information and another is\\nto use spectral graph filters.\\nAssumption. It is assumed that there is irrelevant or noisy\\ninformation in the raw attributes or graph structure w.r.t.\\nGAD, which should be discarded during feature aggregation.\\n• Gradient-based Feature Scoring.\\nExtracting\\nclass-related features specific to the characteristics of\\na particular class is one straightforward way to obtain\\ndiscriminative features. Inspired by variable decomposition\\n[32],\\ngradient\\ninformation-based\\nmethods\\nhave\\nbeen\\nemerging as one main approach to obtain discriminative\\nrepresentations from GNNs [78]. The key idea here is to\\nselect features from the representation hi based on the\\ngradient backpropagated from the softmax probability of\\nbeing a specific class, as illustrated in Fig. 3(a). Let αc\\nk be\\nthe gradient score of an anomaly class c w.r.t. a feature k,\\nthen it represents the contribution of this feature to anomaly\\ndetection, which can be formulated as follows:\\nαc\\nk = 1\\nN\\n\\x0c\\x0c\\x0c\\x0c\\x0c\\nN\\nX\\ni=1\\n∂yc\\n∂hk,i\\n\\x0c\\x0c\\x0c\\x0c\\x0c ,\\n(5)\\nwhere yc is the predicted probability of being the anomaly\\nclass c and hk,i is the k-th feature of the representation of\\nnode i from a hidden layer. After obtaining a gradient score\\nfor each feature dimension, the top K features with the\\nlargest gradient scores are selected to represent the nodes in\\na reduced feature space. This gradient score-based approach\\nis used in GDN [35] to select abnormal and normal features\\nin a supervised manner, and these features are found often to\\nbe invariant to structure distribution shift. It helps reduce the\\nnegative influence of irrelevant features while preserving the\\nextracted abnormal/normal graph patterns, thus enhancing\\nthe overall performance of GAD. Similarly, GraphENS [94]\\ndetermines the importance of each node feature via a\\ngradient score-based method. Apart from gradient score,\\nexisting feature selection methods for anomaly detection or\\nimbalanced classification [57], [86]–[88], [93] may be adapted\\nfor GAD.\\n• Spectral Graph Filter. Spectral graph filter, which\\ncombines the strengths of spectral graph theory and GNNs,\\nis widely applied to capture and analyze the structural prop-\\nerties of graphs for GAD tasks. This approach utilizes a set of\\ngraph filters to transform the raw attributes to latent space to\\nextract discriminative graph representations, as illustrated in\\nFig. 3(b). Each graph filter assumes that normal nodes tend\\nto have similar features with their neighbors, which can be\\nregarded as low-frequency information, whereas abnormal\\nnodes in the graph are characterized by deviations from the\\nnorm, which are often accompanied by high-frequency infor-\\nmation since abnormal nodes often have different character-\\nAUGUST 2024\\n8\\nistics from surrounding nodes. The distinction between low-\\nfrequency and high-frequency information is closely related\\nto the spectral properties of the graph. In particular, the low-\\nfrequency and high-frequency variations on the graph can\\nbe effectively captured by the lower and higher eigenvalues\\nof the graph Laplacian matrix, respectively. To leverage this\\ninformation for GAD, graph Fourier transformation [110]\\nbased graph filtering operation is often used. Formally, let\\nL be the symmetrically normalized Laplacian, with eigen\\ndecomposition L = UΛUT , where Λ = diag [λ1, · · · , λn],\\nthen a signal x ∈Rn is transferred by using a graph filter\\ng, Transformation(x) = g ⋆x = Ug(Λ)UTx, and thus, the\\ngraph signal filtered by the k-th filter can be defined as\\nhi,k = Ugk(Λ)UT xi = Udiag [gk (λ1) , . . . , gk (λn)] UT xi.\\n(6)\\nTo better capture the feature separability, a set of multi-\\nfrequency filters is often employed to learn the node repre-\\nsentations [10]. Accordingly, the final representation hi of\\nnode vi can be obtained by\\nhi =\\nX\\nk\\nαi,khi,k = U\\nX\\nk\\nαi,kgk(Λ)UT xi,\\n(7)\\nwhere αi,k is an important score for the graph filter gk(Λ).\\nVarious spectral graph filters utilizing the frequency at\\ndifferent level have been proposed for GAD. Specifically,\\nAMNet [10] is an early work that adaptively integrates\\ndifferent graph signals with mixed frequency patterns via a\\nmulti-frequency graph filter group. It uses a restricted Bern-\\nstein polynomial parameterization method to approximate\\nfilters in multi-frequency groups. BWGNN [114] reveals a\\n‘right-shift’ phenomenon in GAD datasets with synthetic or\\nreal-world anomalies, i.e., low-frequency energy is gradually\\ntransferred to the high-frequency part when the degree of\\nanomaly becomes larger. According to this phenomenon,\\nthey justify the necessity of spectral localized band-pass\\nfilters in GAD. Current GNNs with adaptive filters cannot\\nguarantee to be band-pass or spectral localized. Therefore,\\nthey build on top of Hammond’s graph wavelet theory [40]\\nto develop a new GNN architecture with a Beta kernel to\\nbetter detect higher-frequency anomalies.\\nThe aforementioned filters can be challenged by het-\\nerophily graphs since homophily graphs are assumed in\\nthese filters. To tackle this challenge, SEC-GFD [133] employs\\na hybrid band-pass filter to partition the graph spectrum into\\nhybrid frequency bands, while SplitGNN [125] combines a\\nband-pass graph filter with a tunable Beta Wavelet GNN to\\naddress the heterophily issue in node representation learning\\nfor GAD (C1 in Sec. 2.2).\\nAdvantages. (i) The feature transformation approach\\nsupports the extraction of discriminative features from data\\nwith various amount of irrelevant/noisy information. (ii) It\\ncan also provide rich and informative graph representations\\ncapturing beyond local graph properties, such as connectivity,\\ncentrality, and community structure, for more effective GAD.\\nDisadvantages. (i) Depending on what criterion or\\nspectral filter is used, this approach might overlook some\\nimportant information in feature transformation that could\\nbe crucial for GAD, since one feature scoring criterion or\\nfilter often fails to capture all possible discriminative features.\\n(a) Feature Interpolation\\n(b) Noise Perturbation   \\n1\\uf06c\\n1\\n1 \\uf06c\\n\\uf02d\\n2\\n\\uf06c\\n2\\n1 \\uf06c\\n\\uf02d\\n3\\n\\uf06c\\n3\\n1 \\uf06c\\n\\uf02d\\nPerturbation\\nGenerated Node\\n...\\n...\\n...\\n...\\n...\\n...\\n...\\n...\\nGenerated Node\\nFig. 4: Two categories of generative GNNs.\\n(ii) The approach may confined to a specific type of graph.\\nFor example, spectral GNNs are primarily designed for\\nhomogeneous graphs, and thus, it may not be suitable for a\\nheterogeneous graph with different types of nodes.\\nChallenges Addressed. The feature transformation ap-\\nproach enhances GNNs by focusing them on specific types of\\ndiscriminative features, thereby providing effective solutions\\nto the graph structure-aware anomaly detection problem\\n(C1). Furthermore, this approach focuses on discriminative\\nfeatures and does not require costly graph structure recon-\\nstruction, and thus, it is often good for GAD on large-scale\\ngraph data (C2).\\n4.2\\nGenerative GNNs\\nGenerative GNN-based methods focus on synthesizing new\\ngraph instances to augment the existing graph data for\\nenhancing model training on the new graph for GAD. This\\napproach is motivated by the problem complexities like\\nthe scarcity of graph anomaly instances and their large\\nvariations (P5 and P7 in Sec. 2.2). The underlying key idea\\nin these GAD methods is to synthesize outliers that can\\nsimulate graph anomalies in some specific properties to\\nprovide pseudo anomaly information for training the GAD\\nmodels. In general, these methods can be summarized by the\\nfollowing formulation:\\nonew\\ni\\n= gϕ(oi, X, A; ϵ),\\n(8)\\nwhere oi is an existing graph instance, gϕ is a graph instance\\ngenerator with parameters ϕ that uses oi, existing attribute\\ninformation X, graph structure information A, and some\\nauxiliary information ϵ to generate the augmented graph\\ninstance, onew\\ni\\n. It is then followed by a one-class or binary\\nclassification loss Lcls defined as\\nLgen =\\nX\\nℓ(Y, fθ (Xnew\\ni\\n, Anew\\ni\\n)),\\n(9)\\nwhere Xnew and Anew are the augmented version of X and\\nA, Y represents the label set of the graph instances consisting\\nof pseudo labels of the generated anomaly instances (and\\nthe labels in the original graph if any), and f is a GAD\\nmodel. Depending on the source of ϵ in gϕ in Eq. 8, these\\nmethods can be categorized into feature interpolation and\\nnoise perturbation generation methods. The former focuses\\non specifying ϵ using data from existing graphs, while the\\nlatter focuses on utilizing prior distribution to specify ϵ.\\n4.2.1\\nFeature Interpolation\\nFeature interpolation is a commonly employed technique\\nin imbalance learning for augmenting data, where the\\nAUGUST 2024\\n9\\nrepresentations of synthesized graph instances are created by\\ninterpolating the representations of existing graph instances.\\nIt has been explored in popular algorithms like SMOTE [33]\\nand Mixup [144] to oversample the minority classes or gen-\\nerate diverse, large-scale samples for training deep models.\\nThe approach can be generally formulated as follows:\\nhnew = (1 −λ) · h(i)\\na + λ · h(j)\\nb ,\\n(10)\\nwhere hnew is the representation of the generated graph\\ninstance using a convex combination of the representations\\nof two existing graph instances from the same class, ha and\\nhb, as illustrated in Fig. 4(a).\\nAssumption. The interpolated feature representations\\nbetween graph instances can well align with those of the\\ninstances from the anomaly class.\\nGraphSMOTE [150], GraphMixup [126] and GraphENS\\n[94] are representative methods that utilize feature inter-\\npolation to address the challenge of biased GAD (C4 in\\nSec. 2.2). These methods are designed for imbalanced node\\nclassification, which can be considered as supervised GAD in\\na closed-set setting since they do not consider the detection of\\nnovel/unknown anomaly types that are not illustrated by the\\nlabeled training anomaly examples [1], [16], [90], [92], [121],\\n[161]. In particular, GraphSMOTE [150] extends SMOTE to\\nsynthesize new nodes and edges in graph data. Different\\nfrom generic data, generating new nodes in a graph requires\\nthe connections of these nodes to existing nodes. Thus, an\\nedge generator is trained simultaneously in GraphSMOTE\\nto model the relations between existing and new nodes\\nwhen using the SMOTE-style approach to generate the new\\nnodes. A similar work is done in AugAN [159] that performs\\ninterpolation on the feature representations of the nodes that\\nare similar to labeled anomalies to increase the number of\\ntraining anomaly examples. However, directly performing\\nthe interpolation may produce out-of-domain samples due to\\nthe extreme sparsity of the minority classes. To alleviate this\\nissue, GraphMixup [94] is introduced to construct semantic\\nrelation spaces that allow the interpolation to be performed\\nat the semantic level. In GraphENS [94], the synthesized\\nnodes are created using an adaptive interpolation rate that\\nis determined by the distance between the minority and\\nmajority class nodes, and its neighborhood is built in a\\nstochastic manner based on the distance between the ego-\\nnetwork nodes of a minority node and a target node. BAT\\n[72] generates virtual nodes for each class as “shortcuts”\\nconnecting to the other nodes based on posterior likelihoods,\\nwhere the feature representation of the generated nodes is\\ngenerated based on a feature interpolation operation.\\nAdvantages. (i) Feature interpolation is a simple yet effec-\\ntive way to create more samples for the under-represented\\nanomaly classes. (ii) Mixing up feature representations from\\ndifferent classes can diversify the training data, enhancing\\nthe training of a more generalized GAD model.\\nDisadvantages. (i) Feature interpolation focuses on gen-\\nerating node representations but lacks the ability to generate\\ngraph structural information. Typically, the methods in this\\ncategory require the incorporation of an additional local\\nstructure generator to address this limitation. (ii) Feature\\ninterpolation also has the risk of producing some ambiguous\\ngraph samples which may lead to harder separation between\\nnormal and anomaly classes.\\nChallenges Addressed. Feature interpolation provides a\\nsimple but effective way to augment the anomaly data, which\\nhelps mitigate the bias due to data imbalance (C4). Further,\\nit may generate abnormal graph instances that are dissimilar\\nto the training anomaly instances, thereby improving the\\ngeneralization ability of GAD models to some unknown\\nanomalies (C3).\\n4.2.2\\nNoise Perturbation\\nUnlike the feature interpolation methods that generate\\nnew graph instances based on interpolation between rep-\\nresentations of existing instances, the noise perturbation\\ngeneration methods aim to generate graph instances using\\nprior-driven noise perturbation, as shown in Fig. 4(b). This\\napproach can incorporate prior knowledge of the graph\\nnormality/abnormality into the generation process for more\\neffective GAD. The generated graph samples as abnormal\\ngraph instances, combined with the given labels for existing\\nnodes, can then be leveraged to guide the training of a\\ndiscriminator for GAD.\\nThe approach can be generally formulated as follows\\nXnew, Anew = gϕ(X, A; ϵ),\\nLcls =\\nN\\nP\\ni=1\\nℓ(yi, fθ (Xi, Ai)) +\\nM\\nP\\ni=1\\nℓ(1, fθ (Xnew\\ni\\n, Anew\\ni\\n)) ,\\n(11)\\nwhere ϵ is noise perturbation typically generated from a\\nprobability distribution, such as a Gaussian distribution,\\ngϕ(·) is a generation function parameterized by ϕ, and M is\\nthe number of generated graph instances.\\nAssumption. Certain prior distributions can be used as a\\nsource of noise perturbation to generate pseudo-abnormal\\ngraph instances and/or diversify normal graph instances.\\nOne group of methods in this category [8], [14], [60],\\n[99] takes a representation permutation approach, which\\nfocuses on applying permutation to graph representations\\nto instantiate gϕ(·), i.e., Permutation(Z). It first utilizes a\\nGNN to obtain the representations from the original graph\\ndata X and A. Then it applies the permutation to the\\nrepresentations to generate the representation of anomalous\\nsamples, denoted as ˜Z.\\n˜Z = Permutation(Z; ϵ), Z = GNN (X, A)\\n(12)\\nwhere ϵ are the hyperparameters of permutation. For ex-\\nample, DAGAD [60] employs the permutation and concate-\\nnates on the representation learned from a limited number\\nof labeled instances to generate the anomalous sample,\\nthereby enriching the knowledge of anomalies captured in\\nthe training set. On the other hand, GGAD [99] aims to\\ngenerate outlier nodes that assimilate anomaly nodes in both\\nlocal structure and node representations by leveraging the\\ntwo priors of anomaly nodes, including asymmetric local\\naffinity and egocentric closeness, to impose constraints the\\nrepresentations. SDGG [8] takes a similar approach as GGAD,\\nbut it is focused on generating abnormal graphs that closely\\nresemble fringe normal graphs, which are then used to train\\ngraph-level anomaly detectors. Unlike GGAD and SDGG that\\nwork on exclusively normal training data, ConsisGAD [14]\\nfocuses on unlabeled nodes. It creates a noise version of the\\nunlabeled nodes by injecting noise into their representations\\nto synthesize instances that maintain high consistency with\\nAUGUST 2024\\n10\\nthe original instances while involving as much diversity\\nas possible. This operation helps mitigate the scarcity of\\nabnormal node instances while also enriching the diversity\\nof normal nodes.\\nApart from the representation permutation-based genera-\\ntion, denoising diffusion probabilistic models (DDPMs) [42]\\nhave recently been emerging as another major approach to\\ngenerate anomalous graph instances [65], [80]. The diffusion\\nprocess is defined as a Markov chain that progressively\\nadds a sequence of scheduled Gaussian noise to corrupt the\\noriginal data x:\\nZs = Z0 + σ(s)ε, ε ∼N(0, I),\\n(13)\\nwhere Z0 is the feature representations of the graph instances\\nand the variance of the noise (the noise level) is exclusively\\ndetermined by σ(s). The full denoising process is equivalent\\nto a reverse Markov chain that attempts to recover the origi-\\nnal data from noise. It iteratively denoises ˆZs to obtain ˆZs\\ni−1\\nvia denoising function. The estimated ˆZ0 is then fed into a\\ngraph instance generator to generate anomalous graphs for\\nGAD. In particular, GODM [65] employs iterative denoising\\nto synthesize pseudo anomalous graph instances that have\\nclose distribution with the real anomalies in a latent space.\\nDIFFAD [80] leverages the generative power of denoising\\ndiffusion models to synthesize training samples that align\\nwith the original graph instance in egonet similarity. The\\ngeneration of supplementary and effective training samples\\nis utilized to mitigate the shortage of labeled anomalies.\\nAdvantages. (i) The graph instance generation may\\nallow the synthesis of novel anomalies that facilitate the\\nidentification of unseen anomalies. (ii) Noise perturbation\\ngeneration can create more diversified training samples,\\nmaking the trained models less sensitive to small changes in\\nthe input data.\\nDisadvantages. (i) The generated instances can inevitably\\ninclude some out-of-domain examples, which may deviate\\nfrom the optimization objective, rendering the detection\\nmodels less effective. (ii) Determining the optimal level of\\nnoise in the noise perturbation can be challenging and may\\nrequire extensive experimentation.\\nChallenge Addressed. The generation of instances can\\nenhance the generalization of detecting different graph\\nanomalies (C3). It also helps achieve a balanced GAD by\\nenhancing the training samples through the GAD-oriented\\ngeneration (C4).\\n5\\nPROXY TASK DESIGN\\nThe proxy task design-based approaches aim to capture di-\\nverse normal/abnormal graph patterns by optimizing a well-\\ncrafted learning objective function that aids the detection\\nof anomalies in the graph data without the use of human-\\nannotated labels. One of the crucial challenges in proxy task\\ndesign is to guarantee that i) the proxy task is associated\\nwith GAD, and ii) it can deal with rich structure information\\nand complex relationships in graphs. We roughly divide the\\nmethods in this group into five categories according to the\\nemployed proxy tasks, including reconstruction, contrastive\\nlearning, knowledge distillation, adversarial learning, and\\nscore prediction. Their respective framework is shown in Fig.\\n5. Below we introduce each of them in detail.\\nGNN\\nEncoder\\nAttribute Reconstruction\\nStructure Reconstruction\\nGNN\\nDecoder\\n\\uf028\\n\\uf029\\n*\\n\\uf073\\nT\\nZ Z\\n(b) Graph Contrastive Learning\\nGNN\\nEncoder\\n(c) Graph Representation Distillation\\n(d) Adversarial Graph Learning\\nGNN\\nEncoder\\nNoise Data\\nD\\nG\\nTeacher\\nModel\\nStudent \\nModel\\nRandom Network\\nPrediction Network\\n(a)  Graph Reconstruction\\nDiscriminator\\nReadout\\n...\\n(e) Score Prediction\\nRepresentation\\nRepresentation\\nRepresentation\\nTarget Node\\nSubgraph\\nGNN\\nEncoder\\nAnomaly Score\\nPredictor\\nPredicted Score\\n...\\nZ\\n2\\nF\\n\\uf02d\\nA\\nA\\n‖\\n‖\\n2\\nF\\n\\uf02d\\nX\\nX\\n‖\\n‖\\n...\\n\\uf028\\n\\uf029\\n Readout \\ni\\ni\\n\\uf03d\\nz\\nE\\nPositive Pair\\nNegative Pair\\nˆ\\nih\\nih\\n\\uf028\\n\\uf029\\n,\\ni\\ni\\nKD h h\\n~ ( )\\np\\nz\\nz\\nz\\nz\\nFig. 5: Five categories of proxy task design.\\n5.1\\nGraph Reconstruction\\nData reconstruction aims to learn low-dimensional feature\\nrepresentations of data for reconstructing given data in-\\nstances, which is widely used in tabular data, and im-\\nage/video data to detect anomalies [91]. Given that the\\nnormal samples often occupy most of the dataset, it helps\\nguarantee that the representations can retain the normal\\ninformation, and thus, normal samples will be reconstructed\\nwith a smaller reconstruction error than anomaly samples.\\nAs a commonly used technique in this category, Graph\\nautoencoder (GAE) [41] consists of a graph encoder and\\na graph decoder and it is easy to implement. Formally, given\\na graph with X and A, the graph reconstruction can be\\nformulated as\\nZ = GNNenc (X, A; Θenc) ,\\nbX = GNNdec (Z, A; Θdec) ,\\nbAij = p\\n\\x10\\nbAij = 1 | zi, zj\\n\\x11\\n= sigmoid\\n\\x10\\nzizT\\nj\\n\\x11\\n,\\n(14)\\nwhere the GNN encoder and decoder are parameterized by\\nΘEnc and ΘDec respectively, Z are the representations of the\\nnodes in the latent space. ˆX and bA are the reconstructed\\nattributes and graph structure respectively. The optimization\\nobjective of the methods in this group can be unified as\\nfollows\\nLreconstruction = R(A, bA) + S(X, bX)) + Φ(A, X; Θ), (15)\\nwhere R(·) and S(·) are two reconstruction functions on\\ngraph attributes and structure respectively, and Φ(A, X; Θ)\\nis an auxiliary optimization task to enhance the reconstruc-\\ntion for better GAD. A general assumption underlying the\\nmethods of this approach is as follows.\\nAssumption. Normal graph instances can be well recon-\\nstructed while reconstructing the anomalies in terms of graph\\nattributes and/or structure will lead to a large error.\\nThere have been many GAE-based GAD methods, among\\nwhich early methods typically instantiate the encoder param-\\neter Θenc and decoder parameter Θdec using different GNN\\nmodels [5], [18], [31], [45], [58], [77], [96], [140]. DOMINANT\\n[18] is among the seminal studies applying GAE to detect\\nanomalies, in which both Θenc and Θdec are specified by\\na three-layer graph convolution. The optimization terms R\\nand S are specified using the pointwise difference between\\nmatrices:\\nLreconstruction = (1 −α)||A −ˆA||2\\nF + α||X −ˆX||2\\nF ,\\n(16)\\nAUGUST 2024\\n11\\nwhere α represents the adjustment ratio between attribute\\nand structure reconstruction. The anomaly score is often\\ndefined by the mean squared errors (MSE):\\nScore(vi) = (1 −α)||ai −ˆai||2 + α||xi −ˆxi||2,\\n(17)\\nwhere ai and ˆai are the original and reconstructed structure\\nassociated with node vi, xi and ˆxi are the original and\\nreconstructed attributes of node vi. Later studies explore the\\nuse of more advance GAE by incorporating attention, spectral\\ninformation, etc [31], [77], [96]. For example, AnomalyDAE\\n[31] and GUIDE [141] employ a graph attention network\\n(GAT) or an attention module to evaluate the significance\\nof neighbors to nodes to enhance the reconstruction of the\\nspecific nodes during the training. HO-GAT [45] develops\\na hybrid order GAT network to specify the Θenc that can\\ndetect abnormal nodes and motif instances simultaneously.\\nDifferent from the focus on the importance of neighboring\\nnodes, ComGA [77] is focused on enhancing node repre-\\nsentations for more effective reconstruction. It achieves this\\nby utilizing a community-aware GNN that propagates a\\ncommunity-specific representation of each node into the\\nfeature representations to encode and decode the modularity\\nmatrix of the graph. Besides node reconstruction, some\\nmethods explore node relation construction, e.g., GAD-NR\\n[104] that aims to reconstruct the neighborhoods’ structure\\nand attributes. GAE can also be extended to perform multi-\\nview graph reconstruction for learning more expressive\\nrepresentations from heterogeneous attributes [96]. Despite\\ntheir simplicity, such GAE-based methods have shown\\neffective performance in not only anomalous node detection\\nbut also anomalous edge detection [26], [140].\\nAnother line of research is to complement the recon-\\nstruction loss with some auxiliary tasks, i.e., Φ(A, X; Θ) in\\nEq. 15, to capture additional information for GAD, since\\nthe reconstruction task is often too simple and vulnerable\\n[52], [58], [84], [146]. In SpecAE [58], it integrates a density\\nestimation into the reconstruction by leveraging Laplacian\\nsharpening to amplify the distance between representations\\nof anomalies and the majority of nodes. MSAD [52] employs\\na number of weighted meta-paths, e.g., unknown-anomaly-\\nunknown and anomaly-unknown-unknown node paths, to\\nextract context-aware information of nodes as an auxiliary\\ntask. In HimNet [84], hierarchical memory learning is incor-\\nporated via Φ(A, X; Θ), where the node-level and graph-\\nlevel memory modules are jointly optimized to detect both\\nlocally and globally anomalous graphs. Netwalk [140] incor-\\nporates clustering as an auxiliary task in the reconstruction\\nto learn the representation of nodes for streaming graph data.\\nOn the other hand, Φ(A, X; Θ) is specified using adversarial\\nlearning in DONE [5] to generate node embeddings with an\\nobjective to minimize the adverse effects from outlier nodes.\\nAdvantages. (i) Data reconstruction is a simple but\\neffective way to detect anomalies in graph data. Meanwhile,\\nit does not require labeled data for training. (ii) The data\\nreconstruction models can be generalized to detect anomalies\\nat different levels of graph instances, e.g., anomalous nodes,\\nedges, and graphs.\\nDisadvantages. (i) To perform the reconstruction of graph\\nstructure and attributes, it is necessary to load the entire\\ngraph, which may require significant computing resources.\\n(ii) The reconstruction is vulnerable to noisy or irrelevant\\nattributes. The presence of noisy or erroneous graph instances\\ncan disrupt the reconstruction process, resulting in false\\npositives or diminished detection accuracy.\\nChallenge Addressed. Reconstruction methods model\\nthe entire graph structure, capturing complex structural\\npatterns for GAD (C1). Due to simplicity and straight\\nintuition, they are also applicable to the detection of different\\nlevels of graph anomalies (C3).\\n5.2\\nGraph Contrastive Learning\\nGraph contrastive learning (GCL) aims to learn effective\\nrepresentations without human annotated labels so that\\nsimilar graph instances are pulled together in the repre-\\nsentation space, while dissimilar instances are far apart.\\nA principled GCL framework for GAD is to devise a self-\\nsupervised contrastive learning task with suitable positive\\nand negative pairs to learn the underlying dominant (normal)\\npatterns in graph-structured data. The framework generally\\nfirst utilizes a GNN network to learn the representations\\nof graph instances, and then it employs a contrastive loss\\nfunction Lc to maximize the similarity of the positive views\\nwhile minimizing the similarity of the negative pairs [118]:\\nhi = GNN (xi, X, A; Θ) ,\\nsi = Positive(vi, A, X; Ωp),˜si = Negative(vi, A, X; Ωn),\\nLc = E(X,A) [log D (hi, si) + log (1 −D (hi,˜si))] ,\\n(18)\\nwhere hi is the representation of target node vi, si and ˜si are\\nthe graph instances generated from two sampling functions\\nPositive(·) and Negative(·) with parameters Ωp and Ωn\\nthat are used to sample the positive and negative sample\\npairs for the target node vi. One key assumption made in\\nthe GCL-based GAD methods is that non-neighboring nodes\\ncan be treated as ‘anomalous’ graph instances relative to a\\ntarget node:\\nAssumption. Non-neighboring nodes to a target node\\nare dissimilar, and thus, they can serve as effective negative\\n(’anomalous’) samples to the target node.\\nThis assumption works in that the datasets typically\\ncontain a substantial number of normal graph instances.\\nEffective GCL training would enable the learning of the\\nmajority patterns on the deviated non-neighboring nodes\\nw.r.t. the target nodes. Built upon this assumption, GCL-\\nbased methods are focused on how the positive and negative\\ngraph instances s and ˜s can be generated to be more aligned\\nwith the GAD task.\\nOne group of methods in this line aims to generate\\nnode-level contrastive sample pairs [13], [123]. In particular,\\nmotivated by the success of the popular GCL method\\nDGI [118], DCI [123] formulates the GCL objective as the\\nclassification of the pairs of target nodes and the nodes\\nunder perturbation against the pairs of target nodes and\\ncluster-based global representations. Unlike the cluster-based\\nrepresentation, GCCAD [13] specifies s using the neighbors\\nof target normal nodes and ˜s using the representations of\\nabnormal nodes. During inference, the anomaly score may be\\ndefined in various ways, e.g., via the classification probability\\n[123] or similarity between the target node’s representation\\nand the graph representation [13].\\nIn addition to the node-level contrasts, other methods use\\nsubgraphs as the target of contrastive learning to help the\\nAUGUST 2024\\n12\\nmodel learn better representations for GAD. CoLA [69] is\\nan early GCL framework for GAD that learns the relations\\nbetween each node and its neighboring substructures. Given\\na target node, s is a subgraph generated by a random walk\\naround the target node, while the negative subgraph is\\ngenerated using the random walk around the other nodes.\\nLet hi and Ei be the representations of a target node and\\na subgraph, in which Ei is often obtained by a readout\\nfunction as follows\\nsi = Readout (Ei) =\\nni\\nX\\nk=1\\nvk\\nni\\n,\\n(19)\\nwhere ni is the number of nodes in Ei, vk is the embedding\\nof node k in the subgraph, then a Bilinear(·) function is\\noften used to combine the representations of the node and\\nthe subgraphs [69], [155]:\\nyi = Bilinear (hi, si) = σ\\n\\x00hiWsi⊤\\x01 ,\\n˜yi = Bilinear (hi, sj) = σ\\n\\x00hiWsj⊤\\x01 ,\\n(20)\\nparameterized by W, in which yi and ˜yi are the predicted\\nresults for positive pairs (hi, si) and negative pairs (hi, sj)\\n(i.e., sj acts as ˜si here), respectively. The anomaly score in\\nCoLA is defined as the difference between the positive and\\nnegative pairs:\\nScore (vi) = 1\\nR\\nR\\nX\\nr=1\\n(˜yi,r −yi,r),\\n(21)\\nwhere R is the number of node-subgraph pairs sampled\\nduring inference to obtain a stable anomaly score. This frame-\\nwork inspires a number of follow-up methods, including the\\nuse of prior knowledge of different anomaly types to generate\\nthe negative samples [135], supervised positive/negative sub-\\ngraph pairs [157], and multi-view/scale subgraph generation\\n[27], [51], [132], [155].\\nThe above methods are focused on node-level anomaly\\ndetection in static graph data. Contrastive learning is also\\nused in dynamic GAD or graph-level anomaly detection. For\\nexample, TADDY [70] applies a dynamic graph transformer\\nthat aggregates spatial and temporal knowledge simultane-\\nously to learn the representations of edges. It specifies si and\\n˜si by constructing the positive edge using the existing edges\\nin the training set and generates the anomalous edges via\\nnegative sampling. SIGNET [67] is designed for graph-level\\nanomaly detection, which first constructs two different views\\nusing dual hypergraph transformation and then maximizes\\nthe mutual information between the bottleneck subgraph\\nfrom two views. The estimated mutual information can be\\nused to evaluate the graph-level abnormality.\\nAdvantages. (i) Many existing GCL approaches and\\ntheories may be adapted to enable GAD. (ii) The rich graph\\nstructure information provides flexible options to generate\\ndiverse positive/negative views for effective GAD. (iii) Since\\nmany methods rely on only local graph information in their\\ntraining, they can handle very large graph data.\\nDisadvantages. (i) Since GCL is focused on representation\\nlearning, it is crucial to develop an effective anomaly scoring\\nmethod based on the learned representations. (ii) As GCL\\nmethods rely on GNNs without class information, the\\nproblem of over-smoothing between normal and abnormal\\ninstances remains prevalent. (iii) The subgraph generation\\nin some methods may incur significant computational costs\\ndue to the need to traverse numerous nodes and edges.\\nChallenge Addressed. Contrastive learning models can\\nbe designed to capture different levels of graph structure\\nand graph anomalies (C1, C3). Without the need to load the\\nfull graph structure information, they can often scale up to\\nlarge-scale graph data (C2).\\n5.3\\nGraph Representation Distillation\\nKnowledge Distillation (KD) [38] aims to train a simple\\nmodel (student) that distills feature representations from a\\nlarge (teacher) model while maintaining similar accuracy as\\nthe large model. The key intuition of KD-based GAD is that\\nthe representation distillation can capture the majority pat-\\nterns of graph instances and the difference in the distillation\\ncan be used to measure the abnormality of samples.\\nAssumption. The graph representation distillation can be\\nseen as a process of extracting the prevalent patterns of the\\ngraph instances, representing the normal patterns for GAD.\\nThis category of methods learns the representation from\\nthe teacher model initialized by a GNN. Subsequently, a\\nGNN-based student network is trained to replicate the\\nrepresentation outputs of the teacher model. The GNN-based\\nteacher and student networks are formulated as follows\\nhi = GNNteacher (xi, X, A; Θ) ,\\nˆhi = GNNstudent\\n\\x10\\nxi, X, A; ˆΘ\\n\\x11\\n,\\n(22)\\nwhere Θ and ˆΘ are respectively the training parameters\\nof student and teacher networks, hi and ˆhi are the repre-\\nsentations learned by the two networks respectively. Both\\nrepresentations are then integrated into the loss function\\nwhich can be formulated as the following:\\nLKD = 1\\nN\\nN\\nX\\ni=1\\nKD\\n\\x10\\nhi, bhi; ˆΘ, Θ\\n\\x11\\n,\\n(23)\\nwhere KD(·) is a distillation function that measures the\\ndifference between the two feature representations. Overall,\\nthe goal of the distillation-based GAD is to make the student\\nmodel as close as possible in predicting the corresponding\\noutputs of the teacher model that is built upon normal graph\\ndata. Therefore, the anomaly score can be defined as the\\ndifference in the representations between the teacher and\\nstudent models.\\nScore\\n\\x10\\nvi; ˆΘ, Θ\\n\\x11\\n=\\n\\r\\r\\rhi −c\\nhi\\n\\r\\r\\r\\n2 .\\n(24)\\nGlocaKD [79] is an early framework, in which the teacher\\nmodel GNNteacher is implemented using a random GCN.\\nThen the distillation function KD(·) is instantiated using KL\\ndivergence to minimize the graph- and node-level prediction\\nerrors of the representations yielded by the random GCN.\\nThe anomaly score in GlocaKD is defined as the prediction\\nerror at the graph and node levels. To support better\\ndistillation of the normal graph representations, several\\ndistillation models have been proposed for GAD with new\\narchitectures. For example, the dual-student-teacher model,\\ncalled GLADST, consists of one teacher model and two\\nstudent models [59], in which the teacher model, trained\\nwith a heuristic loss, is designed to make the representations\\nAUGUST 2024\\n13\\nmore divergent. Unlike the traditional teacher-student model,\\nGLADST trains the two student models on normal and\\nabnormal graphs separately to capture the normality and\\nabnormality better. Unlike GlocalKD that uses a random\\nGNN to be the teach network, the approach FGAD uses a\\npre-trained anomaly detector as the teacher model [9]. Then\\nthe student model is designed with a graph isomorphism\\nnetwork (GIN) backbone and a projection head to improve\\nthe robustness of GAD.\\nAdvantages. (i) The distillation from the teacher model\\ninto a simpler student model provides a new way to extract\\nthe normality of graph instances. (ii) Distillation enables the\\ndevelopment of smaller, more efficient models by transferring\\nknowledge from a larger model. This compression speeds up\\ninference and reduces computational resource requirements\\nfor normality extraction. (iii) Distilling knowledge from a\\nwell-trained teacher model enables the student model to\\nbetter generalize across various types of graphs and quickly\\nadapt to new data or target domains.\\nDisadvantages. (i) Choosing an appropriate teacher\\nmodel can be challenging. If the teacher model is too complex\\nor not well-suited to GAD, the knowledge distilled to the\\nstudent model may not be optimal. (ii) The student model\\nmay fail to capture all the nuances and intricacies in the\\nteacher model, which can impact the extraction of normality.\\nChallenge Addressed. GNN-enabled knowledge distil-\\nlation enhances the ability of addressing graph structure-\\naware GAD. (C1). By distilling knowledge from a well-\\ntrained teacher model, the student model gains improved\\ngeneralization across different GAD scenarios, showcasing\\nenhanced robustness in GAD (C5).\\n5.4\\nAdversarial Graph Learning\\nGenerative adversarial learning (GAN) provides an effective\\nsolution to generate realistic synthetic samples, which can be\\nused for normal pattern learning for GAD. The key intuition\\nof this group of methods is to learn latent features that\\ncan capture the normality perceived in a generative GNN\\nnetwork. Specifically, the GANs employ a generator network\\naiming to generate samples that are statistically similar to\\nthe real data while the discriminator network learns to\\ndistinguish between real and generated graph instances\\n[15], [17]. The normal data with a prior distribution can be\\neasily captured by the generator network while the anomalies\\nstruggle to be simulated by the generator due to the nature\\nof the distribution.\\nIt is worth mentioning that the purpose of generation\\nis different from the noise perturbation generation in the\\ngenerative GNNs in Sec. 4.2. The former mainly uses the\\ngraph structure information and interpolation operations\\nin the latent space to generate new node representations\\nwithout using adversarial learning process, while the latter\\nis focused on generating node representations from a prior\\ndistribution through the adversarial learning to learn the\\nlatent normality.\\nAssumption. A generator GNN can capture the majority\\nof patterns in the graph data if it can generate instances that\\nclosely resemble the distribution of real graph instances.\\nThis group of methods typically employs GNNs to learn\\nthe representations of graph instances and a generator\\nnetwork for generating graph instances based on a prior.\\nFormally, these methods follow the following framework:\\nhi = GNN (xi, A, X; Θ) ,\\n˜hi = G (˜zi; ϵ) , ˜zi ∼p(˜z),\\n(25)\\nwhere h is the feature representation of a node learned by\\nGNN with parameter Θ, ˜h is the representation of a gener-\\nated node, and p(ez) is the prior distribution. The generator\\nG(·) takes noises sampled from the prior distribution p(˜z) as\\nthe input and generates synthetic pseudo abnormal graph\\ninstances via:\\nmin\\nG max\\nD\\nEh∼p(h)[log D(h)] + E˜z∼p(˜z)[log(1 −D(G(˜z; ϵ)))],\\n(26)\\nwhere the discriminator D(·) is often specified by a classifier\\nthat tries to distinguish whether an input is the representation\\nof a normal node or a generated anomaly. The anomaly score\\nis typically defined based on the output of the discriminator:\\nScore(si) = 1 −D(hi).\\n(27)\\nAEGIS [17] and GAAN [15] are two representative works\\nthat apply GANs to GAD by generating node representations\\nfrom Gaussian noise. The discriminator is trained to deter-\\nmine whether nodes are real or generated pseudo abnormal\\ninstances. Some graph adversarial learning methods are also\\nproposed to address the multi-class imbalance problem at the\\nnode level [102], [109]. They incorporate adversarial training\\nto make the model learn robust representations for both ma-\\njority and minority classes, thereby benefiting the separation\\nof the nodes from different classes. This graph adversarial\\nlearning is also applied to anomalous edge detection. GADY\\n[76] employs an anomaly generator to generate abnormal\\ninteractions through input noise. The generated interactions\\nare then combined with normal interactions as the input of\\na discriminator network trained to determine whether the\\ninteraction is normal or abnormal.\\nAdvantages. (i) GANs provide a distinctive method\\nfor learning structural normality by utilizing their graph\\nstructure-aware generation capability. (ii) Its adversarial\\ntraining can generate realistic samples from noise, enabling\\nthe detection models to learn beyond the abnormal samples\\nin the graph.\\nDisadvantages. (i) It is difficult to generate samples that\\naccurately simulate real graph instances in terms of both\\ngraph structure and attributes, and thus, the generated graph\\ninstances may impair the detection performance. (ii) The\\ntraining of GANs is relatively less stable compared to the\\nGNN training in other groups of methods.\\nChallenge Addressed. GANs can model and generate\\ndifferent types of abnormal graph instances, facilitating the\\ndetection of different graph anomalies, e.g., anomalies that\\nare unseen during training (C3). Also, GANs can generate\\nextensive abnormal samples for more balanced GAD (C4).\\n5.5\\nScore Prediction\\nThis group of methods focuses on how to make full use of\\nlabeled data to build an end-to-end anomaly score prediction\\nmodel. Unlike approaches that directly apply GNNs for\\nclassification with labeled abnormal and normal nodes, this\\nmethod is designed for the scenarios where only some graph\\ninstances are known to be normal and abnormal instances.\\nAUGUST 2024\\n14\\nAssumption. The anomaly scores of normal graph in-\\nstances follow a prior distribution while that for abnormal\\ninstances significantly deviate from the distribution.\\nThe score prediction-based methods refer to training a\\npredictor fpred : G →R which is instantiated with GNNs to\\ndirectly predict the anomaly score\\nScore(si) = fpred (xi, A, X; Θp),\\n(28)\\nwhere Θp is the training parameters of the score prediction\\nnetwork. DevNet [91] is a seminal work for score prediction\\nnetwork, which was originally proposed to identify anoma-\\nlies in tabular data. It employs a Z-score-based deviation loss\\nto learn the anomaly scores in an end-to-end manner:\\nLdeviation = (1 −yi) · |Dev(si)| + yi · max (0, m −Dev(si)) ,\\n(29)\\nwhere yi is the class label, m is a pre-defined margin based\\non the prior distribution, and Dev(si) is defined as follows\\nDev (si) = Score(si) −µr\\nσr\\n,\\n(30)\\nwhere µr and σr are the estimated mean and standard\\ndeviation of the anomaly scores based on the prior N (µ, σ).\\nMeta-GDN [21] applies the deviation loss to the graph\\ndata that leverages a small number of labeled anomalies to\\nenforce significant deviation of the anomaly scores of the\\nnormal nodes from the abnormal nodes. SAD [116] adapts\\nDevNet to dynamic graph data, in which contrastive learning\\nis also used to fully exploit the potential of labeled graph\\ninstances on evolving graph streams. In WEDGE [157], the\\ndeviation loss function is defined for at the subgraph level.\\nBy minimizing the deviation loss, the score network predictor\\nwill enforce a large positive deviation of the anomaly score\\nof an anomalous subgraph from that of the prior-based\\nreference scores.\\nAdvantages. (i) By integrating the prior distribution\\ninto the model’s learning process, it can produce more\\ninterpretable anomaly scores compared to other detection\\nmethods. (ii) The studied scenarios where some labeled\\nnormal and anomalous graph instances are available are\\noften common in real-world applications.\\nDisadvantages. (i) The performance of the score predic-\\ntion model is dependent on the prior and the predefined\\nmargin used during training. (ii) The score prediction net-\\nwork is better suited for tabular data because the samples\\nare independent, but a single prior distribution may not be\\nable to effectively capture the dependent scores across the\\ngraph instances.\\nChallenge Addressed. The score prediction provides a\\nGNN-based end-to-end anomaly score learning framework\\nfor GAD, having good scalability to large-scale graph data\\n(C1, C2). It also provides an effective way to achieve\\ngeneralized GAD in the application scenarios where part\\nof the graph instances are labeled (C3).\\n6\\nGRAPH ANOMALY MEASURES\\nThis category of methods aims to discuss GAD methods\\nthat focus on designing anomaly measures for evaluating\\nthe abnormality of instances in the graph. These methods\\nGNN\\nEncoder\\n(a) One-class Distance\\n...\\nHypersphere\\nGNN\\nEncoder\\n(b) Local Affinity\\nLocal Node Affinity\\nGNN\\nEncoder\\n(c) Community Adherence\\n(d) Graph Isolation\\nGNN\\nEncoder\\n1\\n2\\n3\\n4\\nc\\nNormal\\nAbnormal\\n1c\\n2c\\n3c\\nNormal \\nAbnormal \\nFig. 6: Four categories of graph anomaly measure.\\ngenerally perform anomaly scoring by incorporating some\\nkey abnormal graph characteristics into deep graph learning\\nmethods. As shown in Fig. 6, they can be generally divided\\ninto four categories, including one-class distance measure,\\nlocal affinity measure, community adherence measure, and\\ngraph isolation-based approaches.\\n6.1\\nOne-class Classification Measure\\nThe one-class classification measure refers to evaluating the\\ndistance between each instance and a one-class center of the\\ninstances for anomaly scoring [105]. This method can also be\\napplied to graph data, where the GNN is typically trained\\nto minimize the volume of a hypersphere that encloses the\\nrepresentations of the graph instances. The key intuition is\\nthat anomalous graph instances differ significantly from the\\nnormal ones, causing them to fall outside the hypersphere\\nthat encompasses most of the normal graph instances.\\nAssumption. Normal graph instances exhibit similar\\npatterns that can be encapsulated via a one-class hypersphere,\\nfrom which anomalies show largely deviated patterns.\\nThe one-class classification on the graph can be generally\\nformulated as the following\\nLone−class = 1\\nN\\nN\\nX\\ni=1\\n||ϕ (Xi, Ai; W) −c||2 + Φ(Θ),\\n(31)\\nwhere c is the central representation of the one-class hy-\\npersphere, ϕ (Xi, Ai; W∗) is the representation of graph\\ninstance si learned by GNN, and Φ(Θ) is a regularization\\nterm or auxiliary task which can benefit the one-class distance\\nmeasure. Anomalies are expected to samples that have a\\nlarge distance to the center. Thus, the anomaly score can be\\ndetermined by the distance of a graph instance to the center\\nof the hypersphere:\\nScore(si) = ∥ϕ (Xi, Ai; W∗) −c∥2 ,\\n(32)\\nwhere W∗are the parameters of the trained one-class model\\nand c is the representation of the one-class center.\\nThere have been some methods that adopt this one-\\nclass classification approach for GAD [122], [160]. OCGNN\\n[122] applies a one-class SVM to graphs, leveraging the\\npowerful representation capabilities of GNNs. The objective\\nof OCGNN is to generate node embeddings that are close\\nto the center. Since the feature representations are crucial\\nin one-class learning, various methods have explored the\\nuse of GNNs from different perspectives to enhance the\\nrepresentation learning for one-class GAD. For example,\\nAUGUST 2024\\n15\\nAAGNN [160] designs a subtractive aggregation [160] rather\\nthan the commonly used summation-based aggregation for\\none-class GNN learning. DOHSC [148] adds an orthogonal\\nprojection layer [148] to ensure the training data distribution\\nis consistent with the decision hypersphere. Other methods\\noptimize the one-class learning with some auxiliary tasks,\\nsuch as node feature reconstruction [115], relation prediction\\n[56], and self-supervision [101], to avoid notorious issues in\\nthis approach like model collapse.\\nAdvantages. (i) One-class classification does not require\\nlabeled anomaly data for training, making it suitable for the\\nscenario where such data is scarce or unavailable. (ii) The\\none-class measure can handle isolated nodes well.\\nDisadvantages. (i) Normal graph patterns can manifest\\nin various ways, making it challenging for a one-class hyper-\\nsphere to capture the full spectrum of normality. (ii) Learning\\nthe one-class hypersphere is prone to model collapse.\\nChallenge Addressed. One-class classification with ap-\\npropriate GNNs enables the learning of the majority struc-\\ntural pattern in the graph data (normal graph instances) (C1).\\nThis approach also does not require the full graph structure\\ninformation during training, resulting in good scalability to\\nlarge-scale graphs (C2).\\n6.2\\nCommunity Adherence\\nCommunity adherence-based GAD [140], [158] aims to\\nidentify the anomalies based on the adherence of instances\\nto graph communities. The key intuition is that anomalies\\nare not well-distributed and exhibit weak adherence to the\\ncommunities, whereas normal graph instances typically have\\nstrong adherence to at least one community.\\nAssumption. Normal instances adhere to at least one\\ncommunity, whereas anomalies are unfit to any community.\\nThis community adherence-based method first leverages\\na mapping function to learn the representation of graph\\ninstances. A clustering or community discovery method is\\nthen applied to group the graph instances. Since anomalies\\ngenerally exhibit significantly weaker community adherence,\\nthe anomaly score can be defined by the minimum distance\\nto the centers of the communities.\\nScore (si) = min ∥ϕ (xi, X, A; W∗) −cj∥2\\n2 , ∀j ∈{1, . . . , p},\\n(33)\\nwhere p is the number of communities, cj is the center of\\ncommunity Cj, and W∗is the optimal parameters of the\\nmapping function.\\nThis approach is analogous to clustering-based anomaly\\ndetection in non-graph data [89], but here it needs to capture\\nthe graph characteristics for GAD. To this end, MHGL [158]\\nutilizes GNNs and a multi-hypersphere learning objective\\nto learn multiple groups of fine-grained normal patterns,\\nenclosing each group using a corresponding hypersphere\\nin the latent space while simultaneously pushing labeled\\nanomalies far away from these hyperspheres. The anomaly\\nscore is defined as the Euclidean distance between a test\\ninstance and the nearest hypersphere center. Netwalk [140]\\nis a method for both anomalous node and edge detection\\nwhere k-means clustering was applied to group the existing\\nnode/edge into different groups in a feature representation\\nspace. The anomaly score of node/edge is measured as its\\ndistance to the center of its closest cluster.\\nAdvantages. (i) By utilizing graph communities, the\\nnormality of data beyond one-hop graph structures can be\\nmore effectively captured. (ii) The community adherence\\nenables a fine-grained modeling of normal patterns, which\\ncould be important for identifying some types of graph\\nanomalies that depend on the context of graph communities.\\nDisadvantages. (i) Community adherence-based methods\\nare sensitive to hyperparameters like the number of clusters.\\n(ii) Community adherence measures rely heavily on the\\neffectiveness of the community detection methods.\\nChallenge Addressed. Graph communities can be useful\\nfor discovering important structural contexts (e.g., those\\nbeyond a fixed-hop neighborhood) to detect anomalies that\\ndeviate from the communities (C1). Community adherence\\ncan provide one way for interpreting anomalies based on\\ndeviations from expected community-based behaviors (C5).\\n6.3\\nLocal Affinity\\nThere are many graph properties that can be important\\nfor GAD, such as connectivity, degree distribution, and\\nclustering coefficient. Local affinity is a graph property that\\nintegrates multiple properties for evaluating the normality\\nand abnormality of graph instances. The affinity may be\\ndefined in various ways, such as the number of connections\\nof a graph instances to neighboring instances and clustering\\ncoefficient of the connected subgraphs. The key intuition\\nis that the normal graph instances typically have a strong\\naffinity with its neighbors, whereas an anomalous instance\\nhas a significantly weaker affinity with its neighbors. Thus,\\nthe local affinity can serve as the inverse of anomaly score.\\nAssumption. Normal instances are connected with other\\nnormal instances with similar attributes while anomalies are\\noften graph instances that are less similar to their neighbors.\\nFormally, the local affinity τ(si) of an instance si can be\\ndefined based on its average similarity to its neighbors:\\nτ (si) =\\n1\\n|N (si)|\\nX\\nsj∈N(si)\\nsim (hi, hj) ,\\n(34)\\nwhere hi and hj are the representation of instance si and sj,\\nN (si) represents the neighboring instance si.\\nTAM [98] is a seminal work that introduces local affinity\\nas an anomaly measure. It aims to learn tailored node\\nrepresentations for GAD by maximizing the local affinity of\\nnodes to their neighbors. It is optimized on truncated graphs\\nwhere non-homophily edges are removed iteratively to\\nmitigate its adverse effects on the local affinity measure. The\\nlearned representations result in a significantly stronger local\\naffinity for the normal nodes than the abnormal nodes. CLAD\\n[53] instead measures the affinity based on the discrepancy\\nbetween a node and its neighbors using Jenson-Shannon\\nDivergence. The anomaly score is obtained from the affinity\\nfor each node in terms of both graph structure and attributes.\\nPREM [85] eliminates the message-passing propagation in\\nthe regular GNNs by using an ego neighbor matching-based\\ncontrastive learning module. It aims to learn discriminative\\npatterns between the local ego network and the neighboring\\ninstances. These GAD methods are focused on the anomaly\\nscore of a node based on its affinity to its neighboring nodes.\\nAUGUST 2024\\n16\\nExploring beyond the node-level affinity can be one potential\\napproach for subgraph- or graph-level anomaly detection.\\nAdvantages. (i) The local affinity measure offers a novel\\nway to quantify the abnormality of graph instances at a local\\nscope. (ii) The measure provides a principled framework\\nfor evaluating the normality from both the graph structure\\nand attributes. (iii) It can be more interpretable than those\\nidentified through task proxy-based GAD methods.\\nDisadvantages. (i) Its effectiveness may vary if the affinity\\nis specified differently. (ii) It is often designed based on\\npredefined graph properties, making it difficult to generalize\\nto the anomalies that do not conform to the properties.\\nChallenge Addressed. Local affinity-based GAD methods\\ncan adapt to and leverage various structural properties\\nfor the detection of various types of anomalies (C1, C3),\\nthough the prior knowledge about the properties is required.\\nLocal affinity also provides a way to explain why a node is\\nconsidered anomalous based on the local context, enhancing\\nthe interpretability of GAD (C5).\\n6.4\\nGraph Isolation\\nIsolation-based methods [61] is among the most popular\\nmethods for anomaly detection. Due to its general effective-\\nness across different datasets, it is also applied to identify\\nanomalous graph instances [134], [164]. Its use for GAD\\nis based on the isolation of graph instances in a feature\\nrepresentation space.\\nAssumption. Anomalous graph instances can be isolated\\nmore easily than normal instances in the representation\\nspace.\\nThe methods in this group need to first learn the repre-\\nsentations of the instances using a graph encoder GNNenc:\\nhi = GNNenc(si, X, A; Θenc),\\n(35)\\nwhere hi is the representation of the graph instance si. An\\nisolation mechanism is then applied on the representations,\\ni.e., Isolation(hi), where the split process is formulated as\\nthe following\\nP2k ←\\nn\\nhi | h(jk)\\ni\\n≤ηk, hi ∈Pk\\no\\n,\\nP2k+1 ←\\nn\\nhi | h(jk)\\ni\\n> ηk, hi ∈Pk\\no\\n,\\n(36)\\nwhere Pk is the node set of in the k-th binary partition tree\\nand j is the dimension in h used to partition the feature\\nspace. The abnormality of a graph instance s is evaluated by\\nthe isolation difficulty in each tree of the tree set T:\\nF(s | T) = Ωτi∼TI (s | τi) ,\\n(37)\\nwhere I (s | τi) denotes a function to measure the isolation\\ndifficulty in tree τi and Ωdenotes an integration function.\\nDIF [134] presents a new representation scheme that\\ncombines data partition and deep representation learning\\nto perform isolation in randomly projected deep representa-\\ntions for anomaly detection, showing good effectiveness in\\nanomaly detection in various data types, including graph-\\nlevel anomaly detection. GCAD [164] uses isolation forest for\\nanomalous node detection. It uses the node representations\\nafter subgraph normalization as the input to graph isolation.\\nThe anomaly score is defined using a depth-based weighted\\nscore that aggregates scores from various associated sub-\\ngraphs. If we treat isolation-based measures as simpler\\nalternatives to density estimation, there have been multiple\\nother extensions [30], [30], [58], [151] that leverage the learned\\ngraph representations to estimate a density-based anomaly\\nscore for GAD.\\nAdvantages. (i) Graph isolation measures are built on\\nwell established isolation-based methodology for anomaly\\ndetection. (ii) Many existing isolation-based methods may be\\nadapted to anomaly detection on graph data.\\nDisadvantages. (i) The isolation measure operates on\\na continuous feature space, so its effectiveness relies on\\nthe learning of an expressive representation space. (ii) The\\nheuristic of isolation is difficult to be incorporated into GNN-\\nbased representation learning, leading to less effective feature\\nrepresentations for the subsequent isolation mechanism.\\nChallenge Addressed. The graph isolation measure can\\nadapt traditional anomaly measures to GAD with the power\\nof GNN-based representation learning (C1). The isolation\\nmechanism is highly efficient, allowing good scalability to\\nGAD on large graphs (C2).\\n7\\nRESEARCH OPPORTUNITIES\\nDespite the remarkable success of numerous existing GAD\\nmethods, there are a range of research opportunities that\\ncould be explored to tackle some largely unsolved GAD\\nproblems.\\nAdvanced Graph Anomaly Measures. Most current\\nGAD methods are built upon proxy tasks or focused on\\nthe GNN backbones using traditional non-graph anomaly\\nmeasures, as summarized in Table 2. Consequently, they may\\nfail to learn feature representations that encapsulate holistic\\nconsideration of graph structure and attributes specifically\\nfor GAD. Therefore, it is crucial to devise anomaly measures\\nthat go beyond traditional anomaly measures and proxy\\ntasks, such as local node affinity [98], for developing more\\ndedicated methods for GAD.\\nGAD on Complex Graphs. Most existing GAD meth-\\nods are focused on small-scale (e.g., less than millions of\\nnodes/edges), static, or homogeneous graph data, as shown\\nin Tables 3 and 4 in Appendix B. However, many real-\\nworld graphs can involve millions/billions of heterogeneous\\nnodes/edges [56], such as real-life citation networks, social\\nnetworks, and financial networks. The nodes/edges may\\nappear in a streaming fashion, where the models can access\\nto only limited graph data at one time step and may need to\\nadapt to new normal/abnormal patterns as the graph evolves\\n[103]. Current methods may be adapted to handle these\\ngraphs, but their performance would become less effective\\nsince their primary design do not consider those complexity.\\nGAD methods designed for graphs with two or more of these\\ncomplexities are required.\\nHandling Anomaly Camouflage and Contamination. In\\nGAD, anomalies might easily hide their abnormal charac-\\nteristics by mimicking the structure and attributes of their\\nneighboring instances. There have been some approaches\\nfor addressing this problem, e.g., via selecting relevant fea-\\ntures, incorporating domain knowledge, or using adversarial\\ntraining [25], [99], but they often rely on the prior knowledge\\nabout what specific features the attackers may use in the\\nAUGUST 2024\\n17\\ncamouflage. A related important problem is the issue of\\nanomaly contamination in the training data. Current methods\\nare mostly unsupervised, working on anomaly-contaminated\\ntraining data, but the anomalous instances in the graph\\ncan largely bias the message-passing in the GNNs [98],\\nleading to less expressive feature representations. Recent\\napproaches, such as semi-supervised GAD on a small set of\\nlabeled normal graph instances [99] or training GNNs using\\ntruncated graph data [98], may offer effective methodologies\\nfor handling these issues.\\nInterpretable GAD. As shown by the summarized\\ndetection performance results in Tables 5, 6 and 7 in Ap-\\npendix C, current GAD methods have shown impressive\\nsuccess in detecting anomalous graph instances, but they\\ngenerally ignore the interpretability of their detection results.\\nIn addition to accurate detection, interpretable GAD also\\nrequires an explanation about why a graph instance is\\nidentified as anomalous within a given graph structure,\\nmaking it different from explaining anomalies in non-graph\\ndata. Exploring information such as local graph structure,\\nhuman feedback, and/or domain knowledge [67] would\\nbe some interesting directions for providing the structure-\\naware anomaly explanation. Also, the obtained anomaly\\nexplanation may in turn be further leveraged to improve the\\ndetection performance.\\nOpen-set Supervised GAD. As shown in Table 2, there\\nhave been many supervised GAD methods, most of which es-\\nsentially tackle an imbalanced binary classification problem.\\nSuch formulation is often questionable since anomalies per\\nse can draw from very different distributions and cannot be\\ntreated as from one concrete class. Open-set supervised GAD\\nalso trains the detectors with labeled normal and anomalous\\nexamples (i.e., seen anomalies), but it assumes an open set of\\nanomaly classes (i.e., there are anomaly classes that are not\\nillustrated by the training anomaly samples) rather than the\\nclosed-set assumption in most existing studies [121]. Thus,\\nit is a more realistic supervised GAD setting. Methods for\\nthis setting have shown significantly better performance than\\nunsupervised and fully supervised methods on visual data\\n[1], [16], [136], [161] and tabular data [90]–[92]. Recent studies\\nin this line also show similar advantages on graph data [121],\\n[158]. Exploring better modeling of the normal patterns while\\nfitting the seen anomalies could be an effective approach\\nto avoid overfitting of the seen anomalies (i.e., reducing\\nmisclassification of the unseen anomalies as normal).\\nFoundation Models for GAD. Leveraging foundation\\nmodels for downstream tasks has been emerging as one effec-\\ntive direction to empower the sample-efficient performance\\nin the downstream tasks, including graph-related tasks [62],\\n[111], [112], [130], owing to their superior generalization\\nability. Two main directions for the GAD task involve the\\ntraining of graph foundation models (GFMs) for GAD and\\nthe exploitation of large language models (LLMs) for GAD.\\nThere have been a number of successful tuning of foundation\\nmodels for anomaly detection on image data [50], [156], [162]\\nand video data [107], [127]–[129] via proper prompt crafting,\\nprompt learning, or in-context learning. Similar approaches\\nmay be explored for GAD, such as the in-context learning-\\nbased GAD method in [68] inspiring from [162]. This new\\nparadigm is plausible for GAD in several aspects, such as\\nzero/few-shot detection on target graph data, inductive GAD\\n(most existing GAD methods take the transductive approach),\\nand interpretable GAD with text description.\\n8\\nCONCLUSION\\nIn this survey, we first discuss the complexities and existing\\nchallenges in GAD. Then we present a novel taxonomy for\\ndeep GAD methods from three new perspectives, including\\nGNN backbone design, proxy task, and graph anomaly\\nmeasures. We further deepen the discussions in each perspec-\\ntive by discussing more fine-grained categories of methods\\nthere. Along with each fine-grained methodology category,\\nwe not only review the associated GAD methods, but also\\nanalyze their general assumption, pros and cons, and their\\ncapabilities in addressing the unique challenges in GAD. We\\nlastly discuss six important directions for future research on\\nGAD. By tackling the problems in these directions, we expect\\nmuch more advanced generation of methods for solving\\nreal-life GAD problems.\\nREFERENCES\\n[1]\\nA. Acsintoae, A. Florescu, M.-I. Georgescu, T. Mare, P. Sumedrea,\\nR. T. Ionescu, F. S. Khan, and M. Shah, “Ubnormal: New bench-\\nmark for supervised open-set video anomaly detection,” in CVPR,\\n2022, pp. 20 143–20 153.\\n[2]\\nC. Aggarwal and K. Subbian, “Evolutionary network analysis: A\\nsurvey,” ACM Computing Surveys (CSUR), vol. 47, no. 1, pp. 1–36,\\n2014.\\n[3]\\nC. C. Aggarwal, Outlier analysis.\\nSpringer, 2017.\\n[4]\\nL. Akoglu, H. Tong, and D. Koutra, “Graph based anomaly\\ndetection and description: a survey,” Data mining and knowledge\\ndiscovery, vol. 29, pp. 626–688, 2015.\\n[5]\\nS. Bandyopadhyay, L. N, S. V. Vivek, and M. N. Murty, “Outlier\\nresistant unsupervised deep architectures for attributed network\\nembedding,” in WSDM, 2020, pp. 25–33.\\n[6]\\nY. Bei, S. Zhou, Q. Tan, H. Xu, H. Chen, Z. Li, and J. Bu,\\n“Reinforcement neighborhood selection for unsupervised graph\\nanomaly detection,” in ICDM.\\nIEEE, 2023, pp. 11–20.\\n[7]\\nA. Boukerche, L. Zheng, and O. Alfandi, “Outlier detection:\\nMethods, models, and classification,” ACM Computing Surveys\\n(CSUR), vol. 53, no. 3, pp. 1–37, 2020.\\n[8]\\nJ. Cai, Y. Zhang, and J. Fan, “Self-discriminative modeling for\\nanomalous graph detection,” arXiv:2310.06261, 2023.\\n[9]\\nJ. Cai, Y. Zhang, Z. Lu, W. Guo, and S.-k. Ng, “Fgad: Self-boosted\\nknowledge distillation for an effective federated graph anomaly\\ndetection framework,” arXiv:2402.12761, 2024.\\n[10]\\nZ. Chai, S. You, Y. Yang, S. Pu, J. Xu, H. Cai, and W. Jiang, “Can\\nabnormality be detected by graph neural networks,” in IJCAI,\\n2022, pp. 23–29.\\n[11]\\nV. Chandola, A. Banerjee, and V. Kumar, “Anomaly detection: A\\nsurvey,” ACM Computing Surveys, vol. 41, no. 3, p. 15, 2009.\\n[12]\\nW. Chang, K. Liu, K. Ding, P. S. Yu, and J. Yu, “Multitask active\\nlearning for graph anomaly detection,” arXiv:2401.13210, 2024.\\n[13]\\nB. Chen, J. Zhang, X. Zhang, Y. Dong, J. Song, P. Zhang, K. Xu,\\nE. Kharlamov, and J. Tang, “Gccad: Graph contrastive learning\\nfor anomaly detection,” IEEE Transactions on Knowledge and Data\\nEngineering, 2022.\\n[14]\\nN. Chen, Z. Liu, B. Hooi, B. He, R. Fathony, J. Hu, and J. Chen,\\n“Consistency training with learnable data augmentation for graph\\nanomaly detection with limited supervision,” in ICLR, 2023.\\n[15]\\nZ. Chen, B. Liu, M. Wang, P. Dai, J. Lv, and L. Bo, “Generative\\nadversarial attributed network anomaly detection,” in CIKM, 2020,\\npp. 1989–1992.\\n[16]\\nC. Ding, G. Pang, and C. Shen, “Catching both gray and black\\nswans: Open-set supervised anomaly detection,” in CVPR, 2022,\\npp. 7388–7398.\\n[17]\\nK. Ding, J. Li, N. Agarwal, and H. Liu, “Inductive anomaly\\ndetection on attributed networks,” in IJCAI, 2021, pp. 1288–1294.\\n[18]\\nK. Ding, J. Li, R. Bhanushali, and H. Liu, “Deep anomaly detection\\non attributed networks,” in SDM.\\nSIAM, 2019, pp. 594–602.\\nAUGUST 2024\\n18\\n[19]\\nK. Ding, J. Li, and H. Liu, “Interactive anomaly detection on\\nattributed networks,” in WSDM, 2019, pp. 357–365.\\n[20]\\nK. Ding, X. Shan, and H. Liu, “Towards anomaly-resistant graph\\nneural networks via reinforcement learning,” in CIKM, 2021, pp.\\n2979–2983.\\n[21]\\nK. Ding, Q. Zhou, H. Tong, and H. Liu, “Few-shot network\\nanomaly detection via cross-network meta-learning,” in WebConf,\\n2021, pp. 2448–2456.\\n[22]\\nL. Dong, Y. Liu, X. Ao, J. Chi, J. Feng, H. Yang, and Q. He, “Bi-level\\nselection via meta gradient for graph-based fraud detection,” in\\nDASFAA.\\nSpringer, 2022, pp. 387–394.\\n[23]\\nX. Dong, X. Zhang, Y. Sun, L. Chen, M. Yuan, and S. Wang,\\n“Smoothgnn: Smoothing-based gnn for unsupervised node\\nanomaly detection,” arXiv:2405.17525, 2024.\\n[24]\\nX. Dong, X. Zhang, and S. Wang, “Rayleigh quotient graph neural\\nnetworks for graph-level anomaly detection,” arXiv:2310.02861,\\n2023.\\n[25]\\nY. Dou, Z. Liu, L. Sun, Y. Deng, H. Peng, and P. S. Yu, “Enhancing\\ngraph neural network-based fraud detectors against camouflaged\\nfraudsters,” in CIKM, 2020, pp. 315–324.\\n[26]\\nD. Duan, L. Tong, Y. Li, J. Lu, L. Shi, and C. Zhang, “Aane:\\nAnomaly aware network embedding for anomalous link detec-\\ntion,” in ICDM.\\nIEEE, 2020, pp. 1002–1007.\\n[27]\\nJ. Duan, S. Wang, P. Zhang, E. Zhu, J. Hu, H. Jin, Y. Liu, and\\nZ. Dong, “Graph anomaly detection via multi-scale contrastive\\nlearning networks with augmented view,” in AAAI, vol. 37, no. 6,\\n2023, pp. 7459–7467.\\n[28]\\nJ. Duan, B. Xiao, S. Wang, H. Zhou, and X. Liu, “Arise: Graph\\nanomaly detection on attributed networks via substructure aware-\\nness,” IEEE transactions on neural networks and learning systems,\\n2023.\\n[29]\\nJ. Duan, P. Zhang, S. Wang, J. Hu, H. Jin, J. Zhang, H. Zhou, and\\nX. Liu, “Normality learning-based graph anomaly detection via\\nmulti-scale contrastive learning,” in ACM MM, 2023, pp. 7502–\\n7511.\\n[30]\\nM. Ester, H.-P. Kriegel, J. Sander, X. Xu et al., “A density-based\\nalgorithm for discovering clusters in large spatial databases with\\nnoise,” in kdd, vol. 96, no. 34, 1996, pp. 226–231.\\n[31]\\nH. Fan, F. Zhang, and Z. Li, “Anomalydae: Dual autoencoder for\\nanomaly detection on attributed networks,” in ICASSP.\\nIEEE,\\n2020, pp. 5685–5689.\\n[32]\\nS. Fan, X. Wang, C. Shi, K. Kuang, N. Liu, and B. Wang, “Debiased\\ngraph neural networks with agnostic label selection bias,” IEEE\\ntransactions on neural networks and learning systems, 2022.\\n[33]\\nA. Fern´andez, S. Garcia, F. Herrera, and N. V. Chawla, “Smote for\\nlearning from imbalanced data: progress and challenges, marking\\nthe 15-year anniversary,” Journal of artificial intelligence research,\\nvol. 61, pp. 863–905, 2018.\\n[34]\\nY. Gao, J. Fang, Y. Sui, Y. Li, X. Wang, H. Feng, and Y. Zhang,\\n“Graph anomaly detection with bi-level optimization,” in Proceed-\\nings of the ACM on Web Conference 2024, 2024, pp. 4383–4394.\\n[35]\\nY. Gao, X. Wang, X. He et al., “Alleviating structural distribution\\nshift in graph anomaly detection,” in WSDM, 2023, pp. 357–365.\\n[36]\\nY. Gao, X. Wang, X. He, Z. Liu, H. Feng, and Y. Zhang, “Addressing\\nheterophily in graph anomaly detection: A perspective of graph\\nspectrum,” in WebConf, 2023, pp. 1528–1538.\\n[37]\\nZ. Gong, G. Wang, Y. Sun, Q. Liu, Y. Ning, H. Xiong, and J. Peng,\\n“Beyond homophily: Robust graph anomaly detection via neural\\nsparsification,” in IJCAI, 2023, pp. 2104–2113.\\n[38]\\nJ. Gou, B. Yu, S. J. Maybank, and D. Tao, “Knowledge distillation:\\nA survey,” International Journal of Computer Vision, vol. 129, no. 6,\\npp. 1789–1819, 2021.\\n[39]\\nW. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation\\nlearning on large graphs,” NeurIPS, vol. 30, 2017.\\n[40]\\nD. K. Hammond, P. Vandergheynst, and R. Gribonval, “Wavelets\\non graphs via spectral graph theory,” Applied and Computational\\nHarmonic Analysis, vol. 30, no. 2, pp. 129–150, 2011.\\n[41]\\nG. E. Hinton and R. R. Salakhutdinov, “Reducing the dimension-\\nality of data with neural networks,” science, vol. 313, no. 5786, pp.\\n504–507, 2006.\\n[42]\\nJ. Ho, A. Jain, and P. Abbeel, “Denoising diffusion probabilistic\\nmodels,” NeurIPS, vol. 33, pp. 6840–6851, 2020.\\n[43]\\nW. Hu, M. Fey, H. Ren, M. Nakata, Y. Dong, and J. Leskovec,\\n“Ogb-lsc: A large-scale challenge for machine learning on graphs,”\\narXiv:2103.09430, 2021.\\n[44]\\nW. Hu, M. Fey, M. Zitnik, Y. Dong, H. Ren, B. Liu, M. Catasta,\\nand J. Leskovec, “Open graph benchmark: Datasets for machine\\nlearning on graphs,” in NeurIPS, vol. 33, 2020, pp. 22 118–22 133.\\n[45]\\nL. Huang, Y. Zhu, Y. Gao, T. Liu, C. Chang, C. Liu, Y. Tang,\\nand C.-D. Wang, “Hybrid-order anomaly detection on attributed\\nnetworks,” IEEE Transactions on Knowledge and Data Engineering,\\n2021.\\n[46]\\nM. Huang, Y. Liu, X. Ao, K. Li, J. Chi, J. Feng, H. Yang, and\\nQ. He, “Auc-oriented graph neural network for fraud detection,”\\nin WebConf, 2022, pp. 1311–1321.\\n[47]\\nT. Huang, Y. Pei, V. Menkovski, and M. Pechenizkiy, “Hop-count\\nbased self-supervised anomaly detection on attributed networks,”\\nin ECMLPKDD.\\nSpringer, 2022, pp. 225–241.\\n[48]\\nX. Huang, Y. Yang, Y. Wang, C. Wang, Z. Zhang, J. Xu, L. Chen,\\nand M. Vazirgiannis, “Dgraph: A large-scale financial dataset for\\ngraph anomaly detection,” NeurIPS, vol. 35, pp. 22 765–22 777,\\n2022.\\n[49]\\nY. Huang, L. Wang, F. Zhang, and X. Lin, “Are we really\\nmaking much progress in unsupervised graph outlier detection?\\nrevisiting the problem with new insight and superior method,”\\narXiv:2210.12941, 2022.\\n[50]\\nJ. Jeong, Y. Zou, T. Kim, D. Zhang, A. Ravichandran, and\\nO. Dabeer, “Winclip: Zero-/few-shot anomaly classification and\\nsegmentation,” in CVPR, 2023, pp. 19 606–19 616.\\n[51]\\nM. Jin, Y. Liu, Y. Zheng, L. Chi, Y.-F. Li, and S. Pan, “Anemone:\\nGraph anomaly detection with multi-scale contrastive learning,”\\nin CIKM, 2021, pp. 3122–3126.\\n[52]\\nH. Kim, J. Kim, B. S. Lee, and S. Lim, “Deep semi-supervised\\nanomaly detection with metapath-based context knowledge,”\\narXiv:2308.10918, 2023.\\n[53]\\nJ. Kim, Y. In, K. Yoon, J. Lee, and C. Park, “Class label-aware graph\\nanomaly detection,” in CIKM, 2023, pp. 4008–4012.\\n[54]\\nT. N. Kipf and M. Welling, “Semi-supervised classification with\\ngraph convolutional networks,” arXiv:1609.02907, 2016.\\n[55]\\nX. Kong, W. Zhang, H. Wang, M. Hou, X. Chen, X. Yan, and\\nS. K. Das, “Federated graph anomaly detection via contrastive\\nself-supervised learning,” IEEE Transactions on Neural Networks\\nand Learning Systems, 2024.\\n[56]\\nJ. Li, G. Pang, L. Chen, and M.-R. Namazi-Rad, “Hrgcn: Heteroge-\\nneous graph-level anomaly detection with hierarchical relation-\\naugmented graph neural networks,” in DSAA.\\nIEEE, 2023, pp.\\n1–10.\\n[57]\\nJ. Li, K. Cheng, S. Wang, F. Morstatter, R. P. Trevino, J. Tang, and\\nH. Liu, “Feature selection: A data perspective,” ACM computing\\nsurveys (CSUR), vol. 50, no. 6, pp. 1–45, 2017.\\n[58]\\nY. Li, X. Huang, J. Li, M. Du, and N. Zou, “Specae: Spectral\\nautoencoder for anomaly detection in attributed networks,” in\\nCIKM, 2019, pp. 2233–2236.\\n[59]\\nF. Lin, X. Luo, J. Wu, J. Yang, S. Xue, Z. Wang, and H. Gong,\\n“Discriminative graph-level anomaly detection via dual-students-\\nteacher model,” in ADMA.\\nSpringer, 2023, pp. 261–276.\\n[60]\\nF. Liu, X. Ma, J. Wu, J. Yang, S. Xue, A. Beheshti, C. Zhou, H. Peng,\\nQ. Z. Sheng, and C. C. Aggarwal, “Dagad: Data augmentation for\\ngraph anomaly detection,” in ICDM.\\nIEEE, 2022, pp. 259–268.\\n[61]\\nF. T. Liu, K. M. Ting, and Z.-H. Zhou, “Isolation forest,” in ICDM.\\nIEEE, 2008, pp. 413–422.\\n[62]\\nJ. Liu, C. Yang, Z. Lu, J. Chen, Y. Li, M. Zhang, T. Bai, Y. Fang,\\nL. Sun, P. S. Yu et al., “Towards graph foundation models: A survey\\nand beyond,” arXiv:2310.11829, 2023.\\n[63]\\nJ. Liu, X. Shang, X. Han, W. Zhang, and H. Yin, “Spatial-temporal\\nmemories enhanced graph autoencoder for anomaly detection in\\ndynamic graphs,” arXiv:2403.09039, 2024.\\n[64]\\nK. Liu, Y. Dou, Y. Zhao, X. Ding, X. Hu, R. Zhang, K. Ding, C. Chen,\\nH. Peng, K. Shu et al., “Bond: Benchmarking unsupervised outlier\\nnode detection on static attributed graphs,” NeurIPS, vol. 35, pp.\\n27 021–27 035, 2022.\\n[65]\\nK. Liu, H. Zhang, Z. Hu, F. Wang, and P. S. Yu, “Data augmentation\\nfor supervised graph outlier detection with latent diffusion\\nmodels,” arXiv:2312.17679, 2023.\\n[66]\\nY. Liu, X. Ao, Z. Qin, J. Chi, J. Feng, H. Yang, and Q. He, “Pick\\nand choose: a gnn-based imbalanced learning approach for fraud\\ndetection,” in WebConf, 2021, pp. 3168–3177.\\n[67]\\nY. Liu, K. Ding, Q. Lu, F. Li, L. Y. Zhang, and S. Pan, “Towards\\nself-interpretable graph-level anomaly detection,” NeurIPS, vol. 36,\\n2024.\\nAUGUST 2024\\n19\\n[68]\\nY. Liu, S. Li, Y. Zheng, Q. Chen, C. Zhang, and S. Pan, “Arc:\\nA generalist graph anomaly detector with in-context learning,”\\narXiv:2405.16771, 2024.\\n[69]\\nY. Liu, Z. Li, S. Pan, C. Gong, C. Zhou, and G. Karypis, “Anomaly\\ndetection on attributed networks via contrastive self-supervised\\nlearning,” IEEE transactions on neural networks and learning systems,\\nvol. 33, no. 6, pp. 2378–2392, 2021.\\n[70]\\nY. Liu, S. Pan, Y. G. Wang, F. Xiong, L. Wang, Q. Chen, and\\nV. C. Lee, “Anomaly detection in dynamic graphs via transformer,”\\nIEEE Transactions on Knowledge and Data Engineering, vol. 35, no. 12,\\npp. 12 081–12 094, 2021.\\n[71]\\nZ. Liu, Y. Li, N. Chen, Q. Wang, B. Hooi, and B. He, “A survey of\\nimbalanced learning on graphs: Problems, techniques, and future\\ndirections,” arXiv:2308.13821, 2023.\\n[72]\\nZ. Liu, Z. Zeng, R. Qiu, H. Yoo, D. Zhou, Z. Xu, Y. Zhu,\\nK. Weldemariam, J. He, and H. Tong, “Topological augmentation\\nfor class-imbalanced node classification,” arXiv:2308.14181, 2023.\\n[73]\\nZ. Liu, Y. Dou, P. S. Yu, Y. Deng, and H. Peng, “Alleviating the\\ninconsistency problem of applying graph neural network to fraud\\ndetection,” in SIGIR, 2020, pp. 1569–1572.\\n[74]\\nZ. Liu, C. Cao, and J. Sun, “Mul-gad: a semi-supervised graph\\nanomaly detection framework via aggregating multi-view infor-\\nmation,” arXiv:2212.05478, 2022.\\n[75]\\nZ. Liu, C. Cao, F. Tao, and J. Sun, “Revisiting graph contrastive\\nlearning for anomaly detection,” arXiv:2305.02496, 2023.\\n[76]\\nS. Lou, Q. Zhang, S. Yang, Y. Tian, Z. Tan, and M. Luo,\\n“Gady: Unsupervised anomaly detection on dynamic graphs,”\\narXiv:2310.16376, 2023.\\n[77]\\nX. Luo, J. Wu, A. Beheshti, J. Yang, X. Zhang, Y. Wang, and S. Xue,\\n“Comga: Community-aware attributed graph anomaly detection,”\\nin WSDM, 2022, pp. 657–665.\\n[78]\\nJ. Ma, P. Cui, K. Kuang, X. Wang, and W. Zhu, “Disentangled\\ngraph convolutional networks,” in ICML.\\nPMLR, 2019, pp. 4212–\\n4221.\\n[79]\\nR. Ma, G. Pang, L. Chen, and A. van den Hengel, “Deep graph-\\nlevel anomaly detection by glocal knowledge distillation,” in\\nWSDM, 2022, pp. 704–714.\\n[80]\\nX. Ma, R. Li, F. Liu, K. Ding, J. Yang, and J. Wu, “New recipes for\\ngraph anomaly detection: Forward diffusion dynamics and graph\\ngeneration,” 2023.\\n[81]\\nX. Ma, J. Wu, S. Xue, J. Yang, C. Zhou, Q. Z. Sheng, H. Xiong, and\\nL. Akoglu, “A comprehensive survey on graph anomaly detection\\nwith deep learning,” IEEE Transactions on Knowledge and Data\\nEngineering, 2021.\\n[82]\\nX. Ma, J. Wu, J. Yang, and Q. Z. Sheng, “Towards graph-level\\nanomaly detection via deep evolutionary mapping,” in KDD,\\n2023, pp. 1631–1642.\\n[83]\\nL. Meng, H. Mostafa, M. Nassar, X. Zhang, and J. Zhang, “Gener-\\native graph augmentation for minority class in fraud detection,”\\nin CIKM, 2023, pp. 4200–4204.\\n[84]\\nC. Niu, G. Pang, and L. Chen, “Graph-level anomaly detection\\nvia hierarchical memory networks,” in ECMLPKDD.\\nSpringer,\\n2023, pp. 201–218.\\n[85]\\nJ. Pan, Y. Liu, Y. Zheng, and S. Pan, “Prem: A simple yet\\neffective approach for node-level graph anomaly detection,”\\narXiv:2310.11676, 2023.\\n[86]\\nG. Pang, L. Cao, L. Chen, D. Lian, and H. Liu, “Sparse modeling-\\nbased sequential ensemble learning for effective outlier detection\\nin high-dimensional numeric data,” in AAAI, vol. 32, no. 1, 2018.\\n[87]\\nG. Pang, L. Cao, L. Chen, and H. Liu, “Unsupervised feature\\nselection for outlier detection by modelling hierarchical value-\\nfeature couplings,” in ICDM.\\nIEEE, 2016, pp. 410–419.\\n[88]\\nG. Pang, L. Cao Longbing, Chen, and H. Liu, “Learning homophily\\ncouplings from non-iid data for joint feature selection and noise-\\nresilient outlier detection,” in IJCAI, 2017, pp. 2585–2591.\\n[89]\\nG. Pang, C. Shen, L. Cao, and A. V. D. Hengel, “Deep learning for\\nanomaly detection: A review,” ACM computing surveys (CSUR),\\nvol. 54, no. 2, pp. 1–38, 2021.\\n[90]\\nG. Pang, C. Shen, H. Jin, and A. van den Hengel, “Deep weakly-\\nsupervised anomaly detection,” in KDD, 2023, pp. 1795–1807.\\n[91]\\nG. Pang, C. Shen, and A. van den Hengel, “Deep anomaly\\ndetection with deviation networks,” in KDD, 2019, pp. 353–362.\\n[92]\\nG. Pang, A. van den Hengel, C. Shen, and L. Cao, “Toward\\ndeep supervised anomaly detection: Reinforcement learning from\\npartially labeled anomaly data,” in KDD, 2021, pp. 1298–1308.\\n[93]\\nG. Pang, H. Xu, L. Cao, and W. Zhao, “Selective value coupling\\nlearning for detecting outliers in high-dimensional categorical\\ndata,” in CIKM, 2017, pp. 807–816.\\n[94]\\nJ. Park, J. Song, and E. Yang, “Graphens: Neighbor-aware ego\\nnetwork synthesis for class-imbalanced node classification,” in\\nICLR, 2021.\\n[95]\\nY. Pei, T. Huang, W. van Ipenburg, and M. Pechenizkiy, “Resgcn:\\nattention-based deep residual modeling for anomaly detection\\non attributed networks,” Machine Learning, vol. 111, no. 2, pp.\\n519–541, 2022.\\n[96]\\nZ. Peng, M. Luo, J. Li, L. Xue, and Q. Zheng, “A deep multi-view\\nframework for anomaly detection on attributed networks,” IEEE\\nTransactions on Knowledge and Data Engineering, vol. 34, no. 6, pp.\\n2539–2552, 2020.\\n[97]\\nT. Pourhabibi, K.-L. Ong, B. H. Kam, and Y. L. Boo, “Fraud\\ndetection: A systematic literature review of graph-based anomaly\\ndetection approaches,” Decision Support Systems, vol. 133, p.\\n113303, 2020.\\n[98]\\nH. Qiao and G. Pang, “Truncated affinity maximization: One-\\nclass homophily modeling for graph anomaly detection,” NeurIPS,\\nvol. 36, 2024.\\n[99]\\nH. Qiao, Q. Wen, X. Li, E.-P. Lim, and G. Pang, “Generative semi-\\nsupervised graph anomaly detection,” arXiv:2402.11887, 2024.\\n[100] Z. Qin, Y. Liu, Q. He, and X. Ao, “Explainable graph-based fraud\\ndetection via neural meta-graph search,” in CIKM, 2022, pp. 4414–\\n4418.\\n[101] C. Qiu, M. Kloft, S. Mandt, and M. Rudolph, “Raising the bar in\\ngraph-level anomaly detection,” arXiv:2205.13845, 2022.\\n[102] L. Qu, H. Zhu, R. Zheng, Y. Shi, and H. Yin, “Imgagn: Imbalanced\\nnetwork embedding via generative adversarial graph networks,”\\nin KDD, 2021, pp. 1390–1398.\\n[103] S. Ranshous, S. Shen, D. Koutra, S. Harenberg, C. Faloutsos, and\\nN. F. Samatova, “Anomaly detection in dynamic networks: a\\nsurvey,” Wiley Interdisciplinary Reviews: Computational Statistics,\\nvol. 7, no. 3, pp. 223–247, 2015.\\n[104] A. Roy, J. Shu, O. Elshocht, J. Smeets, R. Zhang, and P. Li, “Gad-\\nebm: Graph anomaly detection using energy-based models,” in\\nNeurIPS 2023 Workshop: New Frontiers in Graph Learning, 2023.\\n[105] L. Ruff, R. Vandermeulen, N. Goernitz, L. Deecke, S. A. Siddiqui,\\nA. Binder, E. M¨uller, and M. Kloft, “Deep one-class classification,”\\nin ICML.\\nPMLR, 2018, pp. 4393–4402.\\n[106] B. Sanchez-Lengeling, J. Wei, B. Lee, E. Reif, P. Wang, W. Qian,\\nK. McCloskey, L. Colwell, and A. Wiltschko, “Evaluating attri-\\nbution for graph neural networks,” in NeurIPS, vol. 33, 2020, pp.\\n5898–5910.\\n[107] F. Sato, R. Hachiuma, and T. Sekii, “Prompt-guided zero-shot\\nanomaly action recognition using pretrained deep skeleton fea-\\ntures,” in CVPR, 2023, pp. 6471–6480.\\n[108] F. Shi, Y. Cao, Y. Shang, Y. Zhou, C. Zhou, and J. Wu, “H2-fdetector:\\nA gnn-based fraud detector with homophilic and heterophilic\\nconnections,” in WebConf, 2022, pp. 1486–1494.\\n[109] M. Shi, Y. Tang, X. Zhu, D. Wilson, and J. Liu, “Multi-class\\nimbalanced graph convolutional network learning,” in IJCAI,\\n2020.\\n[110] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Van-\\ndergheynst, “The emerging field of signal processing on graphs:\\nExtending high-dimensional data analysis to networks and other\\nirregular domains,” IEEE signal processing magazine, vol. 30, no. 3,\\npp. 83–98, 2013.\\n[111] X. Sun, H. Cheng, J. Li, B. Liu, and J. Guan, “All in one: Multi-\\ntask prompting for graph neural networks,” in KDD, 2023, pp.\\n2120–2131.\\n[112] J. Tang, Y. Yang, W. Wei, L. Shi, L. Xia, D. Yin, and C. Huang,\\n“Higpt: Heterogeneous graph language model,” arXiv:2402.16024,\\n2024.\\n[113] J. Tang, F. Hua, Z. Gao, P. Zhao, and J. Li, “Gadbench: Revis-\\niting and benchmarking supervised graph anomaly detection,”\\narXiv:2306.12251, 2023.\\n[114] J. Tang, J. Li, Z. Gao, and J. Li, “Rethinking graph neural networks\\nfor anomaly detection,” in ICML.\\nPMLR, 2022, pp. 21 076–21 089.\\n[115] X. Teng, M. Yan, A. M. Ertugrul, and Y.-R. Lin, “Deep into\\nhypersphere: Robust and unsupervised anomaly discovery in\\ndynamic networks,” in IJCAI, 2018.\\n[116] S. Tian, J. Dong, J. Li, W. Zhao, X. Xu, B. Song, C. Meng, T. Zhang,\\nL. Chen et al., “Sad: Semi-supervised anomaly detection on\\ndynamic graphs,” arXiv:2305.13573, 2023.\\nAUGUST 2024\\n20\\n[117] P. Veliˇckovi´c, G. Cucurull, A. Casanova, A. Romero, P. Lio, and\\nY. Bengio, “Graph attention networks,” arXiv:1710.10903, 2017.\\n[118] P. Veliˇckovi´c, W. Fedus, W. L. Hamilton, P. Li`o, Y. Bengio, and\\nR. D. Hjelm, “Deep graph infomax,” arXiv:1809.10341, 2018.\\n[119] D. Wang, J. Lin, P. Cui, Q. Jia, Z. Wang, Y. Fang, Q. Yu, J. Zhou,\\nS. Yang, and Y. Qi, “A semi-supervised graph attentive network\\nfor financial fraud detection,” in ICDM.\\nIEEE, 2019, pp. 598–607.\\n[120] Q. Wang, G. Pang, M. Salehi, W. Buntine, and C. Leckie, “Cross-\\ndomain graph anomaly detection via anomaly-aware contrastive\\nalignment,” in AAAI, vol. 37, no. 4, 2023, pp. 4676–4684.\\n[121] Q. Wang, G. Pang, M. Salehi et al., “Open-set graph anomaly\\ndetection via normal structure regularisation,” arXiv:2311.06835,\\n2023.\\n[122] X. Wang, B. Jin, Y. Du, P. Cui, Y. Tan, and Y. Yang, “One-class graph\\nneural networks for anomaly detection in attributed networks,”\\nNeural computing and applications, vol. 33, pp. 12 073–12 085, 2021.\\n[123] Y. Wang, J. Zhang, S. Guo, H. Yin, C. Li, and H. Chen, “Decoupling\\nrepresentation learning and classification for gnn-based anomaly\\ndetection,” in SIGIR, 2021, pp. 1239–1248.\\n[124] Y. Wang, J. Zhang, Z. Huang, W. Li, S. Feng, Z. Ma, Y. Sun, D. Yu,\\nF. Dong, J. Jin et al., “Label information enhanced fraud detection\\nagainst low homophily in graphs,” in WebConf, 2023, pp. 406–416.\\n[125] B. Wu, X. Yao, B. Zhang, K.-M. Chao, and Y. Li, “Splitgnn: Spectral\\ngraph neural network for fraud detection against heterophily,” in\\nCIKM, 2023, pp. 2737–2746.\\n[126] L. Wu, J. Xia, Z. Gao, H. Lin, C. Tan, and S. Z. Li, “Graphmixup:\\nImproving class-imbalanced node classification by reinforcement\\nmixup and self-supervised context prediction,” in ECMLPKDD.\\nSpringer, 2022, pp. 519–535.\\n[127] P. Wu, X. Zhou, G. Pang, Y. Sun, J. Liu, P. Wang, and Y. Zhang,\\n“Open-vocabulary video anomaly detection,” in CVPR, 2024, pp.\\n18 297–18 307.\\n[128] P. Wu, X. Zhou, G. Pang, Z. Yang, Q. Yan, P. WANG, and Y. Zhang,\\n“Weakly supervised video anomaly detection and localization with\\nspatio-temporal prompts,” in ACM MM, 2024.\\n[129] P. Wu, X. Zhou, G. Pang, L. Zhou, Q. Yan, P. Wang, and Y. Zhang,\\n“Vadclip: Adapting vision-language models for weakly supervised\\nvideo anomaly detection,” in AAAI, vol. 38, no. 6, 2024, pp. 6074–\\n6082.\\n[130] L. Xia, B. Kao, and C. Huang, “Opengraph: Towards open graph\\nfoundation models,” arXiv:2403.01121, 2024.\\n[131] C. Xiao, X. Xu, Y. Lei, K. Zhang, S. Liu, and F. Zhou, “Counterfac-\\ntual graph learning for anomaly detection on attributed networks,”\\nIEEE Transactions on Knowledge and Data Engineering, 2023.\\n[132] F. Xu, N. Wang, X. Wen, M. Gao, C. Guo, and X. Zhao, “Few-\\nshot message-enhanced contrastive learning for graph anomaly\\ndetection,” arXiv:2311.10370, 2023.\\n[133] F. Xu, N. Wang, H. Wu, X. Wen, and X. Zhao, “Revisiting graph-\\nbased fraud detection in sight of heterophily and spectrum,”\\narXiv:2312.06441, 2023.\\n[134] H. Xu, G. Pang, Y. Wang, and Y. Wang, “Deep isolation forest\\nfor anomaly detection,” IEEE Transactions on Knowledge and Data\\nEngineering, 2023.\\n[135] Z. Xu, X. Huang, Y. Zhao, Y. Dong, and J. Li, “Contrastive\\nattributed network anomaly detection with data augmentation,”\\nin PAKDD.\\nSpringer, 2022, pp. 444–457.\\n[136] X. Yao, R. Li, J. Zhang, J. Sun, and C. Zhang, “Explicit bound-\\nary guided semi-push-pull contrastive learning for supervised\\nanomaly detection,” in CVPR, 2023, pp. 24 490–24 499.\\n[137] Y. You, T. Chen, Y. Sui, T. Chen, Z. Wang, and Y. Shen, “Graph\\ncontrastive learning with augmentations,” NeurIPS, vol. 33, pp.\\n5812–5823, 2020.\\n[138] H. Yu, Z. Liu, and X. Luo, “Barely supervised learning for graph-\\nbased fraud detection,” in AAAI, vol. 38, no. 15, 2024, pp. 16 548–\\n16 557.\\n[139] R. Yu, H. Qiu, Z. Wen, C. Lin, and Y. Liu, “A survey on social\\nmedia anomaly detection,” ACM SIGKDD Explorations Newsletter,\\nvol. 18, no. 1, pp. 1–14, 2016.\\n[140] W. Yu, W. Cheng, C. C. Aggarwal, K. Zhang, H. Chen, and\\nW. Wang, “Netwalk: A flexible deep embedding approach for\\nanomaly detection in dynamic networks,” in KDD, 2018, pp. 2672–\\n2681.\\n[141] X. Yuan, N. Zhou, S. Yu, H. Huang, Z. Chen, and F. Xia, “Higher-\\norder structure based anomaly detection on attributed networks,”\\nin BigData.\\nIEEE, 2021, pp. 2691–2700.\\n[142] G. Zhang, J. Wu, J. Yang, A. Beheshti, S. Xue, C. Zhou, and\\nQ. Z. Sheng, “Fraudre: Fraud detection dual-resistant to graph\\ninconsistency and imbalance,” in ICDM.\\nIEEE, 2021, pp. 867–876.\\n[143] G. Zhang, Z. Yang, J. Wu, J. Yang, S. Xue, H. Peng, J. Su, C. Zhou,\\nQ. Z. Sheng, L. Akoglu et al., “Dual-discriminative graph neural\\nnetwork for imbalanced graph-level anomaly detection,” Advances\\nin Neural Information Processing Systems, vol. 35, pp. 24 144–24 157,\\n2022.\\n[144] H. Zhang, M. Cisse, Y. N. Dauphin, and D. Lopez-Paz, “mixup:\\nBeyond empirical risk minimization,” arXiv:1710.09412, 2017.\\n[145] J. Zhang, S. Wang, and S. Chen, “Reconstruction enhanced multi-\\nview contrastive learning for anomaly detection on attributed\\nnetworks,” arXiv:2205.04816, 2022.\\n[146] L. Zhang, J. Yuan, Z. Liu, Y. Pei, and L. Wang, “A robust\\nembedding method for anomaly detection on attributed networks,”\\nin IJCNN.\\nIEEE, 2019, pp. 1–8.\\n[147] R. Zhang, D. Cheng, X. Liu, J. Yang, Y. Ouyang, X. Wu, and\\nY. Zheng, “Generation is better than modification: Combating\\nhigh class homophily variance in graph anomaly detection,”\\narXiv:2403.10339, 2024.\\n[148] Y. Zhang, Y. Sun, J. Cai, and J. Fan, “Deep graph-level\\northogonal hypersphere compression for anomaly detection,”\\narXiv:2302.06430, 2023.\\n[149] L. Zhao and L. Akoglu, “On using classification datasets to\\nevaluate graph outlier detection: Peculiar observations and new\\ninsights,” Big Data, vol. 11, no. 3, pp. 151–180, 2023.\\n[150] T. Zhao, X. Zhang, and S. Wang, “Graphsmote: Imbalanced node\\nclassification on graphs with graph neural networks,” in WSDM,\\n2021, pp. 833–841.\\n[151] T. Zhao, B. Ni, W. Yu, Z. Guo, N. Shah, and M. Jiang, “Action\\nsequence augmentation for early graph-based anomaly detection,”\\nin CIKM, 2021, pp. 2668–2678.\\n[152] L. Zheng, Z. Li, J. Li, Z. Li, and J. Gao, “Addgraph: Anomaly\\ndetection in dynamic graph using attention-based temporal gcn.”\\nin IJCAI, vol. 3, 2019, p. 7.\\n[153] M. Zheng, C. Zhou, J. Wu, S. Pan, J. Shi, and L. Guo, “Fraudne: a\\njoint embedding approach for fraud detection,” in IJCNN.\\nIEEE,\\n2018, pp. 1–8.\\n[154] X. Zheng, Y. Wang, Y. Liu, M. Li, M. Zhang, D. Jin, P. S. Yu, and\\nS. Pan, “Graph neural networks for graphs with heterophily: A\\nsurvey,” arXiv:2202.07082, 2022.\\n[155] Y. Zheng, M. Jin, Y. Liu, L. Chi, K. T. Phan, and Y.-P. P. Chen,\\n“Generative and contrastive self-supervised learning for graph\\nanomaly detection,” IEEE Transactions on Knowledge and Data\\nEngineering, 2021.\\n[156] Q. Zhou, G. Pang, Y. Tian, S. He, and J. Chen, “Anomalyclip:\\nObject-agnostic prompt learning for zero-shot anomaly detection,”\\nin ICLR, 2024.\\n[157] Q. Zhou, K. Ding, H. Liu, and H. Tong, “Learning node abnormal-\\nity with weak supervision,” in CIKM, 2023, pp. 3584–3594.\\n[158] S. Zhou, X. Huang, N. Liu, Q. Tan, and F.-L. Chung, “Unseen\\nanomaly detection on networks via multi-hypersphere learning,”\\nin SDM.\\nSIAM, 2022, pp. 262–270.\\n[159] S. Zhou, X. Huang, N. Liu, H. Zhou, F.-L. Chung, and L.-K. Huang,\\n“Improving generalizability of graph anomaly detection models\\nvia data augmentation,” IEEE Transactions on Knowledge and Data\\nEngineering, 2023.\\n[160] S. Zhou, Q. Tan, Z. Xu, X. Huang, and F.-l. Chung, “Subtractive\\naggregation for attributed network anomaly detection,” in CIKM,\\n2021, pp. 3672–3676.\\n[161] J. Zhu, C. Ding, Y. Tian, and G. Pang, “Anomaly heterogeneity\\nlearning for open-set supervised anomaly detection,” in CVPR,\\n2024, pp. 17 616–17 626.\\n[162] J. Zhu and G. Pang, “Toward generalist anomaly detection via\\nin-context residual learning with few-shot sample prompts,” in\\nCVPR, 2024, pp. 17 826–17 836.\\n[163] J. Zhu, Y. Yan, L. Zhao, M. Heimann, L. Akoglu, and D. Koutra,\\n“Beyond homophily in graph neural networks: Current limitations\\nand effective designs,” NeurIPS, vol. 33, pp. 7793–7804, 2020.\\n[164] Z. Zhuang, K. M. Ting, G. Pang, and S. Song, “Subgraph\\ncentralization: a necessary step for graph anomaly detection,”\\nin SDM.\\nSIAM, 2023, pp. 703–711.\\n[165] W. Zhuo, Z. Liu, B. Hooi, B. He, G. Tan, R. Fathony, and J. Chen,\\n“Partitioning message passing for graph fraud detection,” in ICLR,\\n2023.\\nAUGUST 2024\\n21\\nAPPENDIX A\\nALGORITHMS\\nTo gain a more in-depth understanding of Deep GAD\\nmethods, in Table 2, we review and summarize the key char-\\nacteristics of representative algorithms from each category.\\nSome key observations are as follows. (i) Most current meth-\\nods focus on supervised and unsupervised methods. GNN\\nbackbone-based methods are mostly supervised methods,\\nwhile Proxy task design-based and anomaly measure meth-\\nods are mostly unsupervised. (ii) The type of datasets used\\nto evaluate each method is different. Supervised methods\\nusually use data sets with real anomalies, while unsuper-\\nvised methods usually use data sets with synthetic/injected\\nanomalies. There are a small number of methods that use\\nboth types of data sets. (iii) There have been new types of\\nmethods for GAD, such as semi-supervised settings with\\nsome labeled normal nodes, or open-set supervised GAD.\\nAPPENDIX B\\nDATASETS\\nWe also collected and summarized publicly available GAD\\ndata sets, including node-level, graph-level, and dynamic\\ngraph datasets. Typically, these datasets can be categorized\\ninto synthetic datasets with injected anomalies and real-\\nworld datasets with genuine anomalies. Some studies inject\\nspecific types of exceptional samples into existing graph\\ndatasets, such as contextual and structure-based anomalies\\n[18], [69]. In Table 3 and Table 4, we provide some statistical\\ninformation about the dataset, including the number of\\nnodes, the data volume of edges, the ratio of anomalies,\\nand whether the anomalies are real or injected.\\nAPPENDIX C\\nQUANTITATIVE COMPARISON\\nThe way we compare the performance of different methods\\nis to collect experimental results using the same dataset\\nfrom their original papers. In this subsection, we do such\\nan empirical comparison. Tables 5 and 6 highlight the\\nperformance of several methods on both real and synthetic\\nGAD datasets.\\nAUGUST 2024\\n22\\nTABLE 2: Key characteristics of representative deep GAD methods ordered first by publication time and then the methodology.\\nMethod (Ref.)\\nSupervision\\nGraph Type\\nGraph Instance\\nAnomaly Type\\nMethodology\\nYear\\nCode\\nNetwalk [140]\\nUnsupervised\\nDynamic\\nEdge\\nGenuine\\nProxy Task Design\\n2018\\nLink\\nFraduNE [153]\\nSupervised\\nStatic\\nSubGraph\\nGenuine\\nAnomaly Measures\\n2018\\nLink\\nSemiGNN [119]\\nSupervised\\nStatic\\nNode\\nInjected\\nGNN Backbone\\n2019\\nN/A\\nAddGraph [152]\\nUnsupervised\\nDynamic\\nEdge\\nGenuine\\nProxy Task Design\\n2019\\nLink\\nDOMINANT [18]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2019\\nLink\\nGraphUCB [19]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2019\\nLink\\nGraphConsis [73]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2020\\nLink\\nCARE-GNN [25]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2020\\nLink\\nAnomalyDAE [31]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2020\\nLink\\nGAAN [15]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2020\\nLink\\nALARM [96]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2020\\nLink\\nAdoNE [5]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2020\\nLink\\nAANE [26]\\nUnsupervised\\nStatic\\nEdge\\nGenuine\\nAnomaly Measures\\n2020\\nN/A\\nPC-GNN [66]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2021\\nLink\\nFRAUDRE [142]\\nSupervised\\nStatic\\nNode\\nInjected\\nGNN Backbone\\n2021\\nLink\\nDCI [123]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2021\\nLink\\nRARE-GNN [20]\\nSupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2021\\nN/A\\nCoLA [69]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2021\\nLink\\nANEMONE [51]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2021\\nLink\\nSL-GAD [155]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2021\\nLink\\nAEGIS [17]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2021\\nLink\\nMeta-GDN [21]\\nSupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2021\\nLink\\nOCGNN [122]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nAnomaly Measures\\n2021\\nLink\\nAAGNN [160]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nAnomaly Measures\\n2021\\nLink\\nNGS [100]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2022\\nLink\\nH2-FDetector [108]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2022\\nLink\\niGAD [143]\\nSupervised\\nStatic\\nGraph\\nGenuine\\nGNN Backbone\\n2022\\nN/A\\nBLS [22]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2022\\nN/A\\nAO-GNN [46]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2022\\nN/A\\nDAGAD [60]\\nSupervised\\nStatic\\nNod\\nInjected\\nGNN Backbone\\n2022\\nLink\\nBWGNN [114]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2022\\nLink\\nAMNet [10]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2022\\nLink\\nCONAD [135]\\nUnsupervised\\nStatic\\nNode\\nBoth\\nProxy Task Design\\n2022\\nLink\\nHCM-A [47]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2022\\nLink\\nComGA [77]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2022\\nLink\\nResGCN [95]\\nUnsupervised\\nStatic\\nNode\\nBoth\\nProxy Task Design\\n2022\\nLink\\nGCCAD [13]\\nSupervised\\nStatic\\nGraph\\nGenuine\\nProxy Task Design\\n2022\\nLink\\nGlocaKD [79]\\nUnsupervised\\nStatic\\nGraph\\nGenuine\\nProxy Task Design\\n2022\\nLink\\nSub-CR [145]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2022\\nLink\\nOCGTL [101]\\nUnsupervised\\nStatic\\nGraph\\nGenuine\\nAnomaly Measures\\n2022\\nLink\\nMHGL [158]\\nUnsupervised\\nStatic\\nNode\\nGenuine\\nAnomaly Measures\\n2022\\nLink\\nSDGG [8]\\nSupervised\\nStatic\\nGraph\\nGenuine\\nGNN Backbone\\n2023\\nN/A\\nGDN [35]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2023\\nLink\\nGHRN [36]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2023\\nLink\\nGODM [65]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2023\\nLink\\nDIFFAD [80]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2023\\nN/A\\nGADY [76]\\nUnsupervised\\nDynamic\\nNode\\nInjected\\nGNN Backone\\n2023\\nLink\\nRAND [6]\\nUnsupervised\\nStatic\\nNode\\nBoth\\nGNN Backbone\\n2023\\nLink\\nSplitGNN [125]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2023\\nLink\\nSEC-GFD [133]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2023\\nN/A\\nNSReg [121]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2023\\nN/A\\nGmapAD [82]\\nUnsupervised\\nStatic\\nGraph\\nGenuine\\nGNN Backbone\\n2023\\nLink\\nRQGNN [24]\\nUnsupervised\\nStatic\\nGraph\\nGenunie\\nGNN Backbone\\n2023\\nLink\\nAuGAN [159]\\nSupervised\\nStatic\\nNode\\nBoth\\nGNN Backbone\\n2023\\nLink\\nHimNet [84]\\nUnsupervised\\nStatic\\nGraph\\nGenuine\\nProxy Task Design\\n2023\\nLink\\nGGA [83]\\nSupervised\\nStatic\\nNode\\nGenuine\\nProxy Task Design\\n2023\\nN/A\\nGRADATE [27]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2023\\nLink\\nGAD-NR [104]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2023\\nLink\\nCFAD [131]\\nSupervised\\nStatic\\nNode\\nGenuine\\nProxy Task Design\\n2023\\nLink\\nACT [120]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2023\\nLink\\nWEDGE [157]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nProxy Task Design\\n2023\\nN/A\\nDIF [134]\\nUnsupervised\\nStatic\\nNode\\nGenuine\\nAnomaly Measures\\n2023\\nLink\\nCLAD [53]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nAnomaly Measures\\n2023\\nLink\\nPREM [85]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nAnomaly Measures\\n2023\\nLink\\nHRGCN [56]\\nUnsupervised\\nStatic\\nGraph\\nGenuine\\nAnomaly Measures\\n2023\\nLink\\nTAM [98]\\nUnsupervised\\nStatic\\nNode\\nBoth\\nAnomaly Measures\\n2023\\nLink\\nGCAD [164]\\nUnsupervised\\nStatic\\nNode\\nInjected\\nAnomaly Measures\\n2023\\nLink\\nConsisGAD [14]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2024\\nLink\\nPMP [165]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2024\\nLink\\nHedGe [147]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2024\\nLink\\nBioGNN [34]\\nSupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2024\\nLink\\nMITIGATE [12]\\nSupervised\\nStatic\\nNode\\nInjected\\nGNN Backbone\\n2024\\nLink\\nGGAD [99]\\nSemi-Supervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2024\\nLink\\nSmoothGNN [23]\\nUnsupervised\\nStatic\\nNode\\nGenuine\\nGNN Backbone\\n2024\\nN/A\\nFGAD [9]\\nSupervised\\nStatic\\nGraph\\nGenuine\\nProxy Task Design\\n2024\\nN/A\\nSTRIPE [63]\\nUnsupervised\\nDynamic\\nNode\\nInjected\\nProxy Task design\\n2024\\nN/A\\nDOHSC [148]\\nUnsupervised\\nStatic\\nGraph\\nGenuine\\nAnomaly Measures\\n2024\\nLink\\nARC [68]\\nSupervised\\nStatic\\nNode\\nBoth\\nAnomaly Measures\\n2024\\nN/A\\nAUGUST 2024\\n23\\nTABLE 3: Publicly accessible node-level GAD datasets.\\nDataset\\n# Nodes\\n# Edges\\n# Attributes\\nSize\\nAnomaly\\nAnomaly Type\\nDomain\\nReferences\\nCora\\n2,708\\n5,429\\n1,433\\nSmall\\n5.5%\\nInjected\\nCitation Networks\\n[18], [31], [69], [77]\\nCitersee\\n3,327\\n4,732\\n3,703\\nSmall\\n4.5%\\nInjected\\nCitation Networks\\n[18], [31], [69], [77]\\nACM\\n16,484\\n71,980\\n8,337\\nMedium\\n3.6%\\nInjected\\nCitation Networks\\n[18], [31], [69], [77]\\nBlogCatalog\\n5,196\\n171,743\\n8,189\\nSmall\\n5.8%\\nInjected\\nSocial Networks\\n[18], [31], [69], [77]\\nFlickr\\n7,575\\n239,738\\n12,407\\nMedium\\n5.2%\\nInjected\\nSocial Networks\\n[18], [31], [69], [77]\\nOGB-arXiv\\n169,343\\n1,166,243\\n128\\nLarge\\n3.5%\\nInjected\\nCitation Networks\\n[44], [69]\\nAmazon\\n11,944\\n4,398,392\\n25\\nLarge\\n9.5%\\nGenuine\\nTransaction Record\\n[25], [98], [113], [114]\\nYelpChi\\n45,954\\n3,846,979\\n32\\nLarge\\n14.5%\\nGenuine\\nReviewer Interaction\\n[25], [98], [113], [114]\\nT-Finance\\n39,357\\n21,222,543\\n10\\nLarge\\n4.6%\\nGenuine\\nTransaction Record\\n[36], [113], [114]\\nT-Social\\n5,781,065\\n73,105,508\\n10\\nLarge\\n3.0%\\nGenuine\\nSocial Network\\n[36], [113], [114]\\nWeibo\\n8,405\\n407,963\\n400\\nSmall\\n10.3%\\nGenuine\\nUnder Same Hashtag\\n[113], [114]\\nDGraph\\n3,700,550\\n4,300,999\\n17\\nLarge\\n1.3%\\nGenuine\\nLoan Guarantor\\n[48], [113]\\nElliptic\\n203,769\\n234,355\\n166\\nLarge\\n9.8%\\nGenuine\\nPayment Flow\\n[10], [23], [113], [121]\\nTolokers\\n11,758\\n519,000\\n10\\nMedium\\n21.8%\\nGenuine\\nWork Collaboration\\n[23], [113]\\nQuestions\\n48,921\\n153,540\\n301\\nMedium\\n3.0%\\nGenuine\\nQuestion Answering\\n[23], [113]\\nDisney\\n124\\n335\\n28\\nSmall\\n4.8%\\nGenuine\\nCo-purchase\\n[64], [104]\\nBooks\\n1,418\\n3,695\\n21\\nSmall\\n2.0%\\nGenuine\\nCo-purchase\\n[64], [104]\\nEnron\\n13,533\\n176,987\\n18\\nMedium\\n0.4%\\nGenuine\\nEmail network\\n[64], [104]\\nReddit\\n10,984\\n168,016\\n64\\nMedium\\n3.3%\\nGenuine\\nUser-subreddit\\n[64], [98], [99], [113]\\nTABLE 4: Publicly accessible graph-level GAD datasets. Homo. and Heter. indicate the graph is homogeneous and heterogeneous,\\nrespectively. Graph-level GAD methods are typically trained using anomaly-free data, so the anomaly rate is applied to the test\\ndata only.\\nDataset\\n# Graphs\\n# Avg. Nodes\\n# Edges\\nAnomaly\\nDomain\\nHomo./Heter.\\nReferences\\nKKI\\n83\\n190\\n237.4\\n44.6%\\nBioinformatics\\nHomo.\\n[79], [82], [122]\\nOHSU\\n79\\n82.01\\n199.66\\n44.3%\\nBioinformatics\\nHomo.\\n[79], [82]\\nMUTAG\\n188\\n17.93\\n19.79\\n33.5%\\nMolecules\\nHomo.\\n[67], [79], [82]\\nPROTEINSfull\\n1,113\\n39.06\\n72.82\\n40.4%\\nBioinformatics\\nHomo.\\n[67], [79], [82], [122]\\nENZYMES\\n600\\n32.63\\n62.14\\n16.7%\\nBioinformatics\\nHomo.\\n[79]\\nAIDS\\n2,000\\n15.69\\n16.2\\n20.0%\\nChemical Structure\\nHomo.\\n[67], [79], [82], [122]\\nBZR\\n405\\n35.75\\n38.36\\n21.0%\\nMolecules\\nHomo.\\n[67], [79], [122]\\nCOX2\\n467\\n41.22\\n43.45\\n21.8%\\nMolecules\\nHomo.\\n[67], [79], [122]\\nDD\\n1,178\\n284.32\\n715.66\\n41.3%\\nBioinformatics\\nHomo.\\n[67], [79], [122]\\nNCI1\\n4,110\\n29.87\\n32.3\\n49.9%\\nMolecules\\nHomo.\\n[67], [82], [122]\\nIMDB\\n1,000\\n19.77\\n96.53\\n50.0%\\nSocial Networks\\nHomo.\\n[67], [82]\\nREDDIT\\n2,000\\n429.63\\n497.75\\n50.0%\\nSocial Networks\\nHomo.\\n[67], [79], [82], [122]\\nHSE\\n8,417\\n16.89\\n17.23\\n5.2%\\nMolecules\\nHomo.\\n[79], [122]\\nMMP\\n7,558\\n17.62\\n17.98\\n15.6%\\nMolecules\\nHomo.\\n[79], [122]\\np53\\n8,903\\n17.92\\n18.34\\n6.3%\\nMolecules\\nHomo.\\n[79], [122]\\nPPAR-gamma\\n8,451\\n17.38\\n17.72\\n2.8%\\nMolecules\\nHomo.\\n[79], [122]\\nCOLLAB\\n5,000\\n74.49\\n2,457.78\\n15.5%\\nSocial Networks\\nHomo.\\n[79], [122]\\nMutagenicit\\n4,337\\n30.32\\n30.77\\n44.6%\\nMolecules\\nHomo.\\n[82]\\nDHFR\\n756\\n42.43\\n44.54\\n39.0%\\nMolecules\\nHomo.\\n[67], [79], [122]\\nTraceLog\\n132,485\\n205\\n224\\n17.6%\\nLog Sequences\\nHeter.\\n[56]\\nFlowGraph\\n600\\n8,411\\n12,730\\n16.7%\\nSystem Flow\\nHeter.\\n[56]\\nAUGUST 2024\\n24\\nTABLE 5: Quantitative comparison of node-level anomaly detection on datasets with manually injected (synthetic) anomalies.\\nMetric\\nMethod\\nDataset\\nAUROC\\nCora\\nCiteseer\\nACM\\nBlogCatalog\\nFlicker\\nPubmed\\nFacebook\\nReddit\\nWeibo\\nDOMINANT [18]\\n0.815\\n0.825\\n0.760\\n0.746\\n0.744\\n0.808\\n0.554\\n0.560\\n0.850\\nCoLA [69]\\n0.878\\n0.896\\n0.823\\n0.785\\n0.751\\n0.951\\n/\\n0.603\\n/\\nSL-GAD [155]\\n0.913\\n0.913\\n0.853\\n0.818\\n0.796\\n0.967\\n/\\n0.567\\n/\\nCONAD [135]\\n0.788\\n/\\n/\\n/\\n/\\n/\\n0.863\\n0.561\\n0.854\\nAEGIS [17]\\n/\\n/\\n/\\n0.743\\n0.738\\n0.773\\n/\\n/\\n/\\nOCGNN [122]\\n0.881\\n0.856\\n/\\n/\\n/\\n0.747\\n0.793\\n/\\n/\\nComGA [77]\\n0.884\\n0.916\\n0.849\\n0.814\\n0.799\\n0.922\\n0.659\\n/\\n/\\nAAGNN [160]\\n/\\n/\\n/\\n0.818\\n0.829\\n0.856\\n/\\n/\\n0.925\\nHCM-A [47]\\n/\\n/\\n0.761\\n0.798\\n0.792\\n/\\n/\\n/\\n/\\nGAAN [15]\\n0.742\\n/\\n0.877\\n0.765\\n0.753\\n/\\n/\\n0.554\\n0.925\\nAnomalyDAE [31]\\n0.762\\n0.727\\n0.778\\n0.783\\n0.751\\n0.810\\n/\\n0.557\\n0.915\\nGAD-NR [104]\\n0.835\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n0.623\\nTAM [98]\\n/\\n/\\n0.887\\n0.824\\n/\\n/\\n0.914\\n0.602\\n/\\nAURPC\\nDOMINANT [18]\\n0.200\\n/\\n/\\n0.338\\n0.324\\n0.299\\n/\\n0.037\\n/\\nCoLA [69]\\n/\\n/\\n0.323\\n0.327\\n/\\n/\\n0.211\\n0.044\\n/\\nSL-GAD [155]\\n/\\n/\\n/\\n0.388\\n0.378\\n/\\n0.131\\n0.041\\n/\\nCONAD [135]\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n0.037\\n/\\nAEGIS [17]\\n/\\n/\\n/\\n0.339\\n0.324\\n0.373\\n/\\n/\\n/\\nOCGNN [122]\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\nComGA [77]\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\nAAGNN [160]\\n/\\n/\\n/\\n0.435\\n0.421\\n0.428\\n/\\n/\\n/\\nHCM-A [47]\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\nGAAN [15]\\n/\\n/\\n/\\n0.338\\n0.324\\n0.337\\n/\\n0.037\\n/\\nAnomalyDAE [31]\\n0.183\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\nGAD-NR [104]\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\nTAM [98]\\n/\\n/\\n0.512\\n0.418\\n/\\n/\\n0.223\\n0.044\\n/\\nTABLE 6: Quantitative comparison of node-level anomaly detection on datasets with genuine anomalies. Results of DevNet and\\nPReNet are taken from [121].\\nMetric\\nSetting\\nMethod\\nDataset\\nAmazon YelpChi T-Finance Question Elliptic Reddit Tolokers Weibo DGraph T-Social Photo\\nCS\\nAUROC\\nUnsupervised\\nDOMINANT [18]\\n0.694\\n0.539\\n0.538\\n/\\n0.296\\n0.556\\n/\\n/\\n0.574\\n/\\n0.514 0.402\\nCoLA [69]\\n0.261\\n0.480\\n0.483\\n/\\n/\\n0.603\\n/\\n/\\n/\\n/\\n/\\n0.481\\nCLAD [53]\\n0.203\\n0.476\\n0.139\\n0.621\\n0.419\\n0.578\\n0.406\\n/\\n/\\n/\\n/\\n/\\nGRADATE [27]\\n0.478\\n0.492\\n0.406\\n0.554\\n/\\n0.526\\n0.537\\n/\\n/\\n/\\n/\\n/\\nGAD-NR [104]\\n0.260\\n0.470\\n0.579\\n0.587\\n0.400\\n0.553\\n0.576\\n/\\n/\\n/\\n/\\n/\\nPrem [85]\\n0.278\\n0.490\\n0.448\\n0.603\\n0.497\\n0.551\\n0.565\\n/\\n/\\n/\\n/\\n/\\nTAM [98]\\n0.802\\n0.548\\n0.690\\n0.504\\n/\\n0.572\\n0.469\\n/\\n/\\n/\\n/\\n/\\nSmoothGNN [23]\\n0.840\\n0.575\\n0.755\\n0.644\\n0.572\\n0.594\\n0.687\\n/\\n0.649\\n0.703\\n/\\n/\\nSemi-supervised\\nGGAD [99]\\n0.944\\n/\\n0.823\\n/\\n0.729\\n/\\n/\\n/\\n0.594\\n/\\n0.648\\n/\\nSupervised\\nBWGNN [114]\\n0.980\\n0.849\\n0.961\\n0.718\\n0.852\\n0.654\\n0.804\\n0.973\\n0.763\\n0.920\\n/\\n/\\nDCI [123]\\n0.946\\n0.778\\n0.868\\n0.692\\n0.828\\n0.665\\n0.755\\n0.942\\n0.747\\n0.808\\n/\\n/\\nAMNet [10]\\n0.970\\n0.826\\n0.937\\n0.681\\n0.773\\n0.684\\n0.768\\n0.953\\n0.731\\n0.536\\n/\\n/\\nGHRN [35]\\n0.981\\n0.853\\n0.96\\n0.718\\n0.854\\n0.660\\n0.804\\n0.967\\n0.761\\n0.790\\n/\\n/\\nNGS [100]\\n0.973\\n0.921\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\nPCGNN [66]\\n0.973\\n0.797\\n0.933\\n0.699\\n0.858\\n0.532\\n0.728\\n0.902\\n0.720\\n0.692\\n/\\n/\\nGDN [36]\\n0.971\\n0.903\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\nDevNet [91]\\n/\\n/\\n0.654\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n0.599 0.606\\nPReNet [90]\\n/\\n/\\n0.892\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n0.698 0.632\\nNSReg [121]\\n/\\n/\\n0.929\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n0.908 0.797\\nAUPRC\\nUnsupervised\\nDOMINANT [18]\\n0.102\\n0.165\\n0.047\\n/\\n/\\n0.036\\n/\\n0.008\\n/\\n0.104 0.187\\nCoLA [69]\\n0.052\\n0.136\\n0.041\\n/\\n/\\n0.045\\n/\\n/\\n/\\n/\\n0.246 0.253\\nCLAD [53]\\n0.040\\n0.128\\n0.025\\n0.051\\n0.081\\n0.050\\n0.192\\n/\\n/\\n/\\n/\\n/\\nGRADATE [27]\\n0.063\\n0.145\\n0.038\\n0.035\\n/\\n0.039\\n0.236\\n/\\n/\\n/\\n/\\n/\\nGADNR [104]\\n0.042\\n0.139\\n0.054\\n0.057\\n0.077\\n0.037\\n0.299\\n/\\n/\\n/\\n/\\n/\\nPrem [85]\\n0.074\\n0.137\\n0.039\\n0.043\\n0.090\\n0.041\\n0.259\\n/\\n/\\n/\\n/\\n/\\nTAM [98]\\n0.332\\n0.173\\n0.128\\n0.039\\n/\\n0.042\\n0.196\\n/\\n/\\n/\\n/\\n/\\nSmoothGNN [23]\\n0.395\\n0.182\\n0.140\\n0.059\\n0.116\\n0.043\\n0.351\\n/\\n0.019\\n0.063\\n/\\n/\\nSemi-supervised\\nGGAD [99]\\n0.792\\n/\\n0.183\\n/\\n0.243\\n0.061\\n/\\n/\\n0.008\\n/\\n0.144\\n/\\nSupervised\\nBWGNN [114]\\n0.891\\n0.551\\n0.866\\n0.167\\n0.260\\n0.069\\n0.497\\n0.930\\n0.040\\n0.549\\n/\\n/\\nDCI [123]\\n0.815\\n0.395\\n0.626\\n0.141\\n0.254\\n0.061\\n0.399\\n0.896\\n0.036\\n0.138\\n/\\n/\\nAMNet [10]\\n0.873\\n0.488\\n0.743\\n0.146\\n0.147\\n0.073\\n0.432\\n0.897\\n0.028\\n0.031\\n/\\n/\\nGHRN [36]\\n0.895\\n0.566\\n0.866\\n0.167\\n0.277\\n0.072\\n0.499\\n0.918\\n0.04\\n0.163\\n/\\n/\\nNGS [100]\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\nPCGNN [66]\\n0.878\\n0.437\\n0.698\\n0.144\\n0.356\\n0.042\\n0.381\\n0.819\\n0.028\\n0.087\\n/\\n/\\nDevNet [91]\\n/\\n/\\n0.323\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n0.468 0.537\\nPReNet [90]\\n/\\n/\\n0.571\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n0.460 0.557\\nNSReg [121]\\n/\\n/\\n0.757\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n0.836 0.752\\nAUGUST 2024\\n25\\nTABLE 7: Quantitative comparison of graph-level anomaly detection.\\nMetric\\nMethod\\nDataset\\nPROTEINS-F ENZYMES AIDS DHFR BZR COX2\\nDD\\nNCI1 IMDB COLLAB HSE MMP\\nP53\\nTraceLog FlowGraph\\nAUROC\\nGlocalKD [79]\\n0.773\\n0.613\\n0.932\\n0.567 0.694 0.593 0.801 0.684 0.521\\n0.674\\n0.593 0.675 0.640\\n/\\n/\\nOCGIN [149]\\n0.708\\n0.587\\n0.781\\n0.492 0.659 0.535 0.722 0.719 0.601\\n/\\n/\\n/\\n/\\n/\\n/\\nSIGNET [67]\\n0.752\\n0.629\\n0.972\\n0.740 0.814 0.714 0.727 0.748 0.664\\n/\\n/\\n/\\n/\\n/\\n/\\nOCGTL [101]\\n0.765\\n0.620\\n0.994\\n0.599 0.639 0.552 0.794 0.734 0.640\\n/\\n/\\n/\\n/\\n/\\n/\\nOCGCN [122]\\n0.718\\n0.613\\n0.664\\n0.495 0.658 0.628 0.605 0.627 0.536\\n/\\n0.388 0.457 0.483\\n/\\n/\\nHimNet [84]\\n0.772\\n0.589\\n0.997\\n0.701 0.703 0.637 0.806 0.686 0.553\\n0.683\\n0.613 0.703 0.646\\n/\\n/\\nGLADST [59]\\n/\\n0.694\\n0.976\\n0.773 0.810 0.630\\n/\\n0.681\\n/\\n0.776\\n0.547 0.685 0.688\\n/\\n/\\nDIF [134]\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n0.737 0.715 0.680\\n/\\n/\\nHRGCN [56]\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n/\\n0.864\\n1.000\\n',\n",
       " 'A Comprehensive Survey with Critical Analysis\\nfor Deepfake Speech Detection\\nLam Pham1∗, Phat Lam2∗, Tin Nguyen3∗, Hieu Tang4, Huyen Nguyen5, Alexander Schindler6, Canh Vu7\\nAbstract— Thanks to advancements in deep learning, speech\\ngeneration systems now power a variety of real-world ap-\\nplications, such as text-to-speech for individuals with speech\\ndisorders, voice chatbots in call centers, cross-linguistic speech\\ntranslation, etc. While these systems can autonomously generate\\nhuman-like speech and replicate specific voices, they also pose\\nrisks when misused for malicious purposes. This motivates the\\nresearch community to develop models for detecting synthesized\\nspeech (e.g., fake speech) generated by deep-learning-based\\nmodels, referred to as the Deepfake Speech Detection task.\\nAs the Deepfake Speech Detection task has emerged in recent\\nyears, there are not many survey papers proposed for this\\ntask. Additionally, existing surveys for the Deepfake Speech\\nDetection task tend to summarize techniques used to construct\\na Deepfake Speech Detection system rather than providing\\na thorough analysis. This gap motivated us to conduct a\\ncomprehensive survey, providing a critical analysis of the\\nchallenges and developments in Deepfake Speech Detection.\\nOur survey is innovatively structured, offering an in-depth\\nanalysis of current challenge competitions, public datasets, and\\nthe deep-learning techniques that provide enhanced solutions to\\naddress existing challenges in the field. From our analysis, we\\npropose hypotheses on leveraging and combining specific deep\\nlearning techniques to improve the effectiveness of Deepfake\\nSpeech Detection systems. Beyond conducting a survey, we\\nperform extensive experiments to validate these hypotheses and\\npropose a highly competitive model for the task of Deepfake\\nSpeech Detection. Given the analysis and the experimental\\nresults, we finally indicate potential and promising research\\ndirections for the Deepfake Speech Detection task.\\nItems— Deepfake speech detection (DSD), challenge compe-\\ntition, ensemble, audio embedding, pre-trained model.\\nI. INTRODUCTION\\nIn recent years, remarkable advancements in deep learning\\ntechniques and neural networks have revolutionized the field\\nof generative AI. Today, core communication mediums such\\nas audio, images, video, and text can be automatically\\ngenerated and applied across various domains, including\\nchatbot systems (e.g., ChatGPT), film production [10], code\\ngeneration [11], and audio synthesis [12], [13], etc. However,\\nAI-synthesized data could pose a serious threat to social se-\\ncurity when there is an increasing number of crimes related to\\nleveraging the synthesized data [14]. To address this concern,\\nL. Pham and A. Schindler are with Austrian Institute of Technology,\\nVienna, Austria.\\nP. Lam and T. Nguyen are with HCM University of Technology, Ho Chi\\nMinh city, Vietnam\\nH. Tang is with FPT University, Ho Chi Minh city, Vietnam\\nH. Nguyen is with Tokyo University of Agriculture and Technology,\\nTokyo, Japan\\nC. Vu is with Laboratory for Applied and Industrial Mathematics, Institute\\nfor Computational Science and Artificial Intelligence, Van Lang University,\\nHo Chi Minh City, Viet Nam\\n(*) Main and equal contribution into the paper.\\nthe tasks, which are proposed for detecting synthesized data\\n(e.g. fake data) generated from deep-learning-based methods,\\nreferred to as deepfake detection, have drawn much attention\\nfrom the research community recently.\\nFocusing on human speech, this paper provides a com-\\nprehensive survey for the task of Deepfake Speech De-\\ntection (DSD). To this end, the milestones presenting the\\ndevelopment progress of the DSD task are first presented\\nin Fig. 1. As the figure showns, the earliest public dataset\\nand challenge proposed for the DSD task was introduced in\\n2015, focusing exclusively on the English language. Then,\\nthe first challenge for video deepfake detection (DFDC [15])\\nwas introduced in 2020. In subsequent years, datasets for the\\nDSD task in Japanese [16], Korean [16], and Chinese [17]\\nwere introduced in 2021 and 2022, respectively. Recently,\\nin 2024, multilingual datasets for the DSD task have been\\npublished, including MLAAD [18] for conversational speech\\nand SVDD [19] for singing. Fig. 1 also highlights a growing\\nnumber of papers, datasets, and challenge competitions for\\nthe DSD task from 2021 to the present. This trend indicates\\nthat the DSD task has recently gained prominence and has\\nattracted significant interest from the research community.\\nTo further understand the DSD task, we summarized recent\\nsurvey papers related to the DSD task in Table I. As shown\\nin the table, most of these surveys focus on detecting general\\nfake data (e.g., images, videos, audio, or text), with audio or\\nhuman speech typically being addressed only as a subsection\\nor a part of the broader discussion [8], [2], [3]. Therefore, the\\nmain techniques, existing concerns, and potential research\\nfor the DSD task have not been comprehensively analyzed\\nin these papers. Among the survey papers, only two survey\\npapers of [5] and [9] focus on the DSD task. However,\\nas conventional surveys, these papers primarily summarize\\nthe technologies used to construct a DSD system such as\\ndatasets, feature extraction, classification model, loss func-\\ntions, rather than providing a comprehensive analysis and\\nhighlighting existing concerns. For instance, while challenge\\ncompetitions proposed for the DSD task are very important\\nin advancing the research community, their importance and\\nvarious aspects have not been thoroughly analyzed (i.e., The\\nnumber of research teams participating in these competitions\\nand their results are interesting to analyzed, etc). Although\\nthis information reflects the level of interest in DSD within\\nthe research community, it has not been addressed in any\\nexisting survey papers. The second concern is related to\\npublic datasets proposed for the DSD task. In particular,\\nthe current survey papers do not adequately analyze the\\nimbalance among (1) the number of utterances, (2) the AI-\\narXiv:2409.15180v1  [cs.SD]  23 Sep 2024\\n2015\\n2020\\n2022\\n2023\\n2024\\nFirst challenge for English speech \\n(ASVspoof 2015-LA Task)\\nFirst challenge for English video (DFDC)\\n2021\\nFirst dataset for Japanese\\nFirst dataset for Korean\\nFirst challenge for Chinese\\n26 INTERSPEECH papers;\\n9 ICASSP papers\\nFirst dataset for spatial fake detection;\\n23 INTERSPEECH papers;\\n10 ICASSP papers\\nFirst challenge for singing \\n(SVDD 2024 , 6 languages);\\nFirst  dataset for multiple languages \\n(MLAAD, 23 languages);\\n31 INTERSPEECH papers;\\n18 ICASSP papers\\nFig. 1.\\nThe timeline of Deepfake Speech Detection (DSD) task\\nTABLE I\\nTHE MAIN FACTORS ANALYZED IN SURVEY PAPERS\\nPapers\\nYears\\nAudio/Video\\nChallenge\\nPublic\\nData\\nFeature\\nClassification\\nLoss\\nTraining\\nProposed\\nContinue\\nCompetitions\\nDatasets\\nAugmentation\\nExtraction\\nModels\\nFunctions\\nStrategies\\nModels\\nUpdating\\n[1]\\n2021\\nYes/Yes\\nNo\\nYes\\nNo\\nNo\\nYes\\nNo\\nNo\\nNo\\nNo\\n[2]\\n2023\\nYes/Yes\\nNo\\nNo\\nNo\\nYes\\nYes\\nNo\\nNo\\nNo\\nNo\\n[3]\\n2023\\nYes/Yes\\nNo\\nNo\\nNo\\nYes\\nYes\\nYes\\nNo\\nNo\\nNo\\n[4]\\n2023\\nYes/Yes\\nNo\\nYes\\nNo\\nNo\\nYes\\nYes\\nYes\\nNo\\nNo\\n[5]\\n2023\\nYes/No\\nYes\\nYes\\nNo\\nYes\\nYes\\nYes\\nYes\\nYes\\nNo\\n[6]\\n2023\\nYes/Yes\\nNo\\nYes\\nNo\\nNo\\nYes\\nNo\\nNo\\nNo\\nNo\\n[7]\\n2024\\nYes/Yes\\nNo\\nYes\\nNo\\nNo\\nYes\\nNo\\nNo\\nNo\\nNo\\n[8]\\n2024\\nYes/Yes\\nNo\\nYes\\nNo\\nYes\\nYes\\nNo\\nNo\\nNo\\nNo\\n[9]\\n2024\\nYes/No\\nNo\\nYes\\nYes\\nYes\\nYes\\nYes\\nYes\\nNo\\nNo\\nOur Survey\\n2024\\nYes/No\\nYes\\nYes\\nYes\\nYes\\nYes\\nYes\\nYes\\nYes\\nYes\\nsynthesized speech systems used to generate fake speech; and\\n(3) the original/real human speech resource used to generate\\nfake speech utterances. These key factors are essential in\\ncreating a high-quality DSD dataset for evaluating DSD\\nmodels. Additionally, survey papers are at risk of becoming\\noutdated as new datasets, techniques, and models continue\\nto emerge. However, current surveys do not offer solutions\\nfor regularly updating essential information, such as details\\nabout challenge competitions, public datasets, and the top-\\nperforming models on specific datasets. As regards technolo-\\ngies used to construct a DSD model such as feature extrac-\\ntion, classification model, or loss functions, current survey\\npapers mainly summarize and then present conclusions rather\\nthan conducting experiments to provide strong evidence and\\nvalidation.\\nGiven the existing concerns about the current survey\\npapers for the DSD task, these motivate and inspire us to\\nprovide a much more comprehensive survey in this paper.\\nBy addressing these concerns, we mainly contribute:\\n• We provide a comprehensive analysis and then indicate\\nconcerns related to three main topics: The current chal-\\nlenge competition, the published datasets, and the deep-\\nlearning-based techniques used to develop a DSD sys-\\ntem. We construct each topic by describing three main\\nparts including ‘Analysis’, ‘Discussion’, and ‘Contribu-\\ntion’. The ‘Analysis’ summarizes concrete information\\nabout the topic. Meanwhile, the ‘Discussion’ indicates\\nconcerns in each topic. Finally, the ‘Contribution’ pro-\\nvides our suggestion and solution to further contribute\\nto each topic.\\n• To solve the out-of-date issue of a survey paper, we set\\nup a Github repository to update further challenge com-\\npetitions, public datasets, and top-performance systems.\\n• More than a survey, we conduct extensive experiments\\nto verify assumptions from the comprehensive analysis,\\nachieving a competitive DSD model. Given the analysis\\nand experimental results, we indicate potential research\\ndirections for the DSD task.\\nThe remainder of this paper is structured as follows:\\nSection II discusses challenge competitions for the DSD\\ntask. Section III deeply analyses the public and benchmark\\ndatasets proposed for the DSD task. In Section IV, we\\nsummarize the key techniques for constructing the main\\ncomponents of a DSD system, including data augmentation,\\nfeature extraction, classification models, and loss functions\\nSection V presents extensive experiments that validate the\\ntechniques described in Section IV. Building on the analysis\\nand results from the previous sections, Section VI outlines\\nour proposed research directions in the DSD task. Finally,\\nSection VII concludes the paper.\\nII. CHALLENGE COMPETITIONS PROPOSED FOR\\nDEEPFAKE SPEECH DETECTION\\nAnalysis: Challenge competitions for the DSD task play\\na crucial role in motivating the research community. These\\ncompetitions not only introduce new benchmark datasets\\nbut also host workshops where research teams can discuss\\ntheir ideas and share their motivations. This environment\\nencourages the community to publish more datasets and\\nTABLE II\\nTHE CHALLENGE COMPETITIONS PROPOSED FOR DEEPFAKE SPEECH DETECTION\\nChallenge Competitions\\nYears\\nData Types\\nLanguages\\nPublic Labels\\nAudio\\nVisual\\nTeam No.\\nTop-1\\n(Number)\\n(train&dev/test)\\nSystem\\nASVspoof 2015 [20]\\n2015\\nSpeech\\nEnglish\\nYes/Yes\\nYes\\nNo\\n16\\nEnsemble Model\\nASVspoof 2019 (LA Task) [21]\\n2019\\nSpeech\\nEnglish\\nYes/Yes\\nYes\\nNo\\n48\\nEnsemble Model\\nDFDC [15]\\n2020\\nSpeech\\nEnglish\\nYes/Yes\\nYes\\nYes\\n2114\\nEnsemble Model\\nFTC [22]\\n2020\\nSpeech\\nEnglish\\nNo/No\\nYes\\nNo\\nn/a\\nn/a\\nASVspoof 2021 (LA Task) [23]\\n2021\\nSpeech\\nEnglish\\nYes/Yes\\nYes\\nNo\\n41\\nEnsemble Model\\nASVspoof 2021 (DF Task) [23]\\n2021\\nSpeech\\nEnglish\\nYes/Yes\\nYes\\nNo\\n33\\nEnsemble Model\\nADD 2022 Track 1 [17]\\n2022\\nSpeech\\nChinese\\nYes/Yes\\nYes\\nNo\\n48\\nSingle Model\\nADD 2022 Track 2 [17]\\n2022\\nSpeech\\nChinese\\nYes/Yes\\nYes\\nNo\\n27\\nSingle Model\\nADD 2022 Track 3.2 [17]\\n2022\\nSpeech\\nChinese\\nYes/Yes\\nYes\\nNo\\n33\\nSingle Model\\nADD 2023 Track 1.2 [24]\\n2023\\nSpeech\\nChinese\\nNo/No\\nYes\\nNo\\n49\\nEnsemble Model\\nADD 2023 Track 2 [24]\\n2023\\nSpeech\\nChinese\\nNo/No\\nYes\\nNo\\n16\\nSingle Model\\nAV-Deepfake1M [25], [26]\\n2024\\nSpeech\\nEnglish\\nYes/No\\nYes\\nYes\\nn/a\\nn/a\\nASVspoof 2024 [27]\\n2024\\nSpeech\\nEnglish\\nYes/No\\nYes\\nNo\\n53\\nEnsemble Model\\nSVDD 2024 [28], [19]\\n2024\\nSinging\\nMultilanguages (6)\\nYes/No\\nYes\\nNo\\n47\\nEnsemble Model\\n2015\\n2016\\n2017\\n2018\\n2019\\n2020\\n2021\\n2022\\n2023\\n2024\\nYears\\n1\\n0\\n1\\n2\\n3\\n2\\n3\\nNumber of challenges\\nFig. 2.\\nThe number of competitions proposed for DSD task from 2015\\ndevelop new techniques to address the DSD challenges. To\\nanalyze DSD challenge competitions, we first summarize all\\nchallenges in Table II. Importantly, we will continuously\\nupdate information about future DSD challenge competitions\\nin our GitHub repository1.\\nAs Table II shows, most challenge competitions focus\\non detecting fake speech in a conversation except for the\\nSVDD 2024 challenge [28] for the fake singing detection.\\nAll challenge competitions for fake speech detection in a\\nconversation have been proposed for a single language (i.e.,\\nWhile ADD 2022 and ADD 2023 are for Chinese, the others\\nare proposed for English). Regarding the number of DSD\\nchallenge competitions, Fig. 2 shows that there has been\\nan increase in recent years. This trend indicates that the\\nDSD task has gained attention from the research commu-\\nnity, particularly due to the rise of advanced deep learning\\nsystems capable of generating highly realistic human-like\\nspeech, which poses significant security risks. DSD challenge\\ncompetitions, which explore fake speech in a conversation,\\ncan be separated into two groups. The first group is proposed\\nfor only audio [20], [29], [21], [23], [27], [22], [17], [24].\\nMeanwhile, the second group is for video in which a fake\\nvideo is identified by fake audio, fake image, or both fake\\naudio and image [15], [26]. This indicates that DSD is not\\nonly treated as an individual task independently but also\\n1https://github.com/AI-ResearchGroup/A-Comprehensive-Survey-with-\\nCritical-Analysis-for-Deepfake-Speech-Detection\\nconsidered as a sub-task in multimodal systems. It is also\\nevident that the second group, which focused on fake video\\ndetection, has attracted significantly more research teams\\n(e.g. 2,114 teams in the DFDC challenge [15]) compared\\nto the first group (e.g. the largest team count was 54 in the\\nASVspoof 2021 challenge [23]). This provides an insight\\nthat fake video detection is a more compelling task, draw-\\ning greater interest and participation from research teams.\\nRegarding top-1 systems in these challenge competitions,\\nthey leveraged the ensemble techniques which combine a\\nwide range of input features or multiple models (i.e., most\\nsubmitted systems mainly use deep learning based models).\\nDiscussion: Given the recent analysis of challenge com-\\npetitions proposed for the DSD task, some concerns can be\\nindicated. Firstly, the DSD task has drawn attention from\\nthe research community and is now recognized as one of\\nthe critical components in a complex system of deepfake\\ndetection. However, most current challenge competitions\\nare limited to single languages, such as Chinese or En-\\nglish, and primarily focus on detecting fake speech within\\nconversations. Second, some challenge competitions have\\nnot published datasets for different reasons. For example,\\nFTC [22] was organized by the US government, and the\\ntop-performing systems are used by the US government.\\nSimilarly, ADD 2023 [24] only provides the dataset for the\\nteams that attended during the competition. These limitations\\nhinder research motivation and further development once\\nthe challenges conclude. Third, it is recognized that fake\\nspeech utterances are mainly generated from deep-learning-\\nbased speech generation systems. Therefore, if selected deep-\\nlearning-based speech generators are not general or up-to-\\ndate, this significantly affects the effectiveness and qual-\\nity of the challenge competition. This highlights the need\\nfor collaboration between two tasks of deep-learning-based\\nspeech generation and detection within the same challenge\\ncompetition. Competitions like ASVspoof 2024 [27] and\\nADD 2022 [17] have addressed this by not only published\\ndatasets but also presented a two-phase or two-track chal-\\nlenge in which the first phase/track is for Deepfake Speech\\nGeneration and the second phase/track is for Deepfake\\nSpeech Detection. Finally, regarding techniques used in these\\ncompetitions, ensemble models have become widely used to\\nTABLE III\\nPUBLIC AND BENCHMARK DATASETS PROPOSED FOR DEEPFAKE SPEECH DETECTION\\nDatasets\\nYears\\nLanguages\\nSpeakers\\nUtt. No.\\nFake speech\\nSpeech\\nReal Speech\\nUtt. length (s)\\nEvaluation\\n(Male/Female)\\n(Real/Fake)\\nGenerators\\nCondition\\nResources\\nMetrics\\nASVspoof 2015 [20](audio)\\n2015\\nEnglish\\n45/61\\n16,651/246,500\\n10\\nClean\\nSpeaker Volunteers\\n1 to 2\\nEER\\nFoR [30](audio)\\n2019\\nEnglish\\n140\\n-/195541\\n7\\nClean\\nKaggle [31]\\n2.35\\nAcc\\nASVspoof 2019 (LA task) [21](audio)\\n2019\\nEnglish\\n46/61\\n12,483/108,978\\n19\\nClean\\nSpeaker Volunteers\\nn/a\\nEER\\nDFDC [15](video)\\n2020\\nEnglish\\n3426\\n128,154/104,500\\n1\\nClean & Noisy\\nSpeaker Volunteers\\n68.8\\nPre., Rec.\\nASVspoof 2021 (LA task) [23](audio)\\n2021\\nEnglish\\n21/27\\n18,452/163,114\\n13\\nClean & Noisy\\nSpeaker Volunteers\\nn/a\\nEER\\nASVspoof 2021 (DF task) [23](audio)\\n2021\\nEnglish\\n21/27\\n22,617/589,212\\n100+\\nClean & Noisy\\nSpeaker Volunteers\\nn/a\\nEER\\nWaveFake [16](audio)\\n2021\\nEnglish,\\n0/2\\n-/117,985\\n6\\nClean\\nLJSPEECH [32],\\n6/4.8\\nEER\\nJapanese\\nJSUT [33]\\nKoDF [34](video)\\n2021\\nKorean\\n198/205\\n62,116/175,776\\n2\\nClean\\nSpeaker Volunteers\\n90/15 (real/fake)\\nAcc, AuC\\nADD 2022 [17]\\n2022\\nChinese\\n40/40\\n3012/24072\\n2\\nClean\\nAISHELL-3 [35]\\n1 to 10\\nEER\\nFakeAVCeleb [36](video)\\n2022\\nEnglish\\n250/250\\n570/25,000\\n2\\nClean & Noisy\\nVox-Celeb2 [37]\\n7\\nAuC\\nIn-the-Wild [38](video)\\n2022\\nEnglish\\n58\\n19963/11816\\n0\\nClean & Noisy\\nSelf-collected\\n4.3\\nEER\\nLAV-DF [39](video)\\n2022\\nEnglish\\n153\\n36,431/99,873\\n1\\nClean & Noisy\\nVox-Celeb2 [37]\\n3 to 20\\nAP\\nVoc.v [40](audio)\\n2023\\nEnglish\\n46/61\\n14,250/41,280\\n5\\nClean & Noisy\\nASVspoof 2019\\nn/a\\nEER\\nPartialSpoof [41](audio)\\n2023\\nEnglish\\n46/61\\n12,483/108,978\\n19\\nClean & Noisy\\nASVspoof 2019\\n0.2 to 6.4\\nEER\\nLibriSeVoc [42](audio)\\n2023\\nEnglish\\nn/a\\n13,201/79,206\\n6\\nClean & Noisy\\nLibrispeech\\n5 to 34\\nEER\\nAV-Deepfake1M [25], [26](video)\\n2023\\nEnglish\\n2,068\\n286,721/860,039\\n2\\nClean & Noisy\\nVoxceleb2 [37]\\n5 to 35\\nAcc, AuC\\nCFAD [43](audio)\\n2024\\nChinese\\n1023\\n-/374,000\\n11\\nClean & Noisy\\nAISHELL1-3 [44], [45]\\nn/a\\nEER\\n& Codecs\\nMAGICDATA [46]\\nMLAAD [47](audio)\\n2024\\nMultilanguages (23)\\nn/a\\n-/76,000\\n54\\nClean & Noisy\\nM-AILABS [18]\\nn/a\\nAcc\\nASVspoof 2024 [27](audio)\\n2024\\nEnglish\\nn/a\\n188,819/815,262\\n28\\nClean & Noisy\\nMLS [48]\\nn/a\\nEER\\nSVDD2024 [28](audio)\\n2024\\nMutilanguages (6)\\n59\\n12,169/72,235\\n48\\nClean\\nMandarin,\\nn/a\\nEER\\nJapanese\\nenhance performance in many challenge competitions, often\\nleading research teams to develop top-performing systems.\\nHowever, this approach has several drawbacks, including\\nlimited explainability, increased system complexity, high\\ntraining costs, and concerns related to power consumption\\nand green AI. Therefore, different aspects of using deep-\\nlearning-based models such as using a single model, low\\ncomplexity, or real-time inference can be regarded as main\\nconstraints in challenge competitions for the DSD task in the\\nfuture. For example, the DCASE challenge Task 1 [49] for\\nSound Scene Classification requires the submitted systems to\\nobey two constraints: (1) not larger than 128 K parameters\\nand (2) not larger than 30 MMAC units.\\nOur contribution: Given the analysis and the discussion\\nabout the DSD challenge competitions above, our work\\nfurther motivates the research community by:\\n• We present and highlight the important role of DSD\\nchallenge competitions. We then provide a comprehen-\\nsive analysis and indicate the concerns.\\n• We continue updating new challenge competitions in the\\nfuture by creating a Github project2. The GitHub reposi-\\ntory serves as a reference for up-to-date information on\\nchallenge competitions and current concerns. In other\\nwords, it provides a summary of challenge competitions\\nrelated to the DSD task, ensuring that this survey paper\\nremains current.\\nIII. PUBLIC DATASETS PROPOSED FOR DEEPFAKE\\nSPEECH DETECTION\\nAnalysis: Public datasets proposed for the DSD task,\\nincluding those introduced through challenge competitions,\\nplay a crucial role in motivating the research community\\nto develop and evaluate DSD systems. In this section, we\\npresent a summary of the public and benchmark datasets for\\nthe DSD task, as shown in Table III. These datasets have\\nbeen introduced through various challenge competitions and\\npublished papers.\\n2https://github.com/AI-ResearchGroup/A-Comprehensive-Survey-with-\\nCritical-Analysis-for-Deepfake-Speech-Detection\\n2015\\n2016\\n2017\\n2018\\n2019\\n2020\\n2021\\n2022\\n2023\\n2024\\nYears\\n1\\n0\\n2\\n1\\n4\\n5\\n3\\nNumber of datasets\\nFig. 3.\\nThe number of public datasets proposed for DSD task from 2015\\nAs illustrated in Fig.3, the number of public datasets for\\nthe DSD task has grown significantly in recent years. Most of\\nthese datasets include both clean and noisy speech. Notably,\\nnearly all datasets have been designed for English, with\\nWaveFake [16], KoDF [50], and ADD 2022 [17] being the\\nexceptions, focusing on Japanese, Korean, and Chinese lan-\\nguages, respectively. Recently, the first multilingual datasets\\nfor the DSD task were introduced in [47] and [19]. The\\nMLAAD dataset [18] provides fake speech in conversations\\ngenerated in 23 widely spoken languages. Meanwhile, the\\nSVDDD dataset [19] was proposed for deepfake singing\\ndetection with six different languages (i.e., the Chinese songs\\nare the majority).\\nMost deepfake datasets are generated from one of three\\ngenerator techniques: Text-to-Speech (TTS), Voice Conver-\\nsion (VC), and Adversarial Attacks (AT), as shown in\\nTable IV. Notably, ASVspoof 2024 [27] is the first dataset\\nthat uses AT systems to generate fake speech. While TTS\\nsystems generate fake speech from text, VC systems generate\\nfake speech from real speech (e.g. audio). To mimic the target\\nspeakers, TTS and VC systems attempt to explore the audio\\nembeddings extracted from the target speakers. The audio\\nembeddings extracted from target speakers are treated as a\\npart of the feature map in the entire network architecture in\\nTTS and VC systems. Regarding AC systems, they mainly\\napply Malafide [124] and Malocopula [125] methods to gen-\\nTABLE IV\\nDEEPFAKE SPEECH GENERATION SYSTEMS USED IN PUBLIC DSD DATASETS\\n(TTS: TEXT TO SPEECH, VC: VOICE CONVERSION, AT: ADVERSARIAL ATTACH USING MALAFIDE OR MALOCOPULA)\\nDatasets\\nYear\\nNo. of TTS/VC/AT\\nDeepfake Speech Generation Systems\\nASVspoof 2015 [20]\\n2015\\n7 VC, 3 TTS\\nVC-01 [51], [52], VC-02 [53], TTS-01 [54], TTS-02 [54], VC-03 [55],\\nVC-04 [56], VC-05 [56], VC-06 [57], VC-07 [58], TTS-03 [59]\\nFoR [30]\\n2019\\n7 TTS\\nDeep Voice 3, Amazon AWS Polly, Baidu TTS, Google Traditional TTS,\\nGoogle Cloud TTS, Google Wavenet TTS, Microsoft Azure TTS\\nASVspoof 2019 (LA task) [21]\\n2019\\n8 VC, 11 TTS\\nTTS-01 [60], TTS-02 [60], [61], TTS-03 [62], TTS-04 [63], VC-01 [64], VC-02 [65],\\nTTS-05 [62], [66], TTS-06 [60], [67], TTS-07 [68], [69], TTS-08 [70], [71], TTS-09 [70], [71], [72],\\nTTS-10 [73], VC-03+TTS [74], VC-04+TTS [75], [76], VC-05+TTS [75], [76], TTS-11 [63],\\nVC-06 [77], [78], VC-07 [79], [80], [81], VC-08 [65]\\nDFDC [15]\\n2020\\n1 TTS\\nTTS Skins voice conversion [82]\\nKoDF [34]\\n2021\\n2 TTS\\nATFHP [50] and Wav2Lip [83]\\nASVspoof 2021 (LA task) [23]\\n2021\\n13 TTS/VC\\nReuse ASVspoof 2019\\nASVspoof 2021 (DF task) [23]\\n2021\\n100 TTS/VC\\nVocoders [84]\\nWaveFake [16]\\n2021\\n6 TTS\\nMelGAN [85], FB-MelGAN [85], HiFi-GAN [86], WaveGlow [87], PWG [88], MB-MelGAN [85]\\nFakeAVCeleb [36]\\n2022\\n2 TTS\\nSV2TTS [89], [90]\\nIn-the-Wild [38]\\n2022\\nn/a\\nn/a\\nLAV-DF [39]\\n2022\\n1 TTS\\nSV2TTS [91]\\nVoc.v [40]\\n2023\\n5 TTS\\nHiFi-GAN [86], MB-MelGAN [85], WaveGlow [87], PWG [88], Hn-NSF [92]\\nPartialSpoof [41]\\n2023\\n21 TTS/VC\\nReuse ASVspoof 2019\\nLibriSeVoc [42]\\n2023\\n6 TTS/VC\\nWaveNet [73], WaveRNN [93], MelGAN [85], Parallel WaveGAn [94], WaveGrad [95], DiffWave [96]\\nAV-Deepfake1M [25], [26]\\n2023\\n2 TTS\\nVITS [97], YoursTTS [98]\\nCFAD [43]\\n2024\\n11 TTS\\nSTRAIGHT [99], Griffin-Lim [100], LPCNet [101], WaveNet [73], PWG [88], HiFi-GAN[102],\\nMB-MelGAN [85], MelGAN [85], WORLD [103], FastSpeech [104], Tacotron-HifiGAN [105]\\nMLAAD [47]\\n2024\\n54 TTS\\nBark, Capacitron, FastPitch, GlowTTS, Griffin Lim, Jenny, NeuralHMM, Overflow,\\nParler TTS, Speech5, Tacotron DDC, Tacotron2, Tacotron2 DCA, Tacotron2 DH, Tcotron2-DDC,\\nTortoise, VITS, VITS Neon, VITS-MMS, XTTS v1.1, XTTS v2\\nASVspoof 2024 [27]\\n2024\\n15 TTS, 6 VC, 7 AT\\nTTS-01 [106], TTS-02 [107], TTS-03 [108], TTS-04 [109], TTS-05 [110], TTS-06[111], TTS-07[112],\\nTTS-08(self-develop), VC-01[113], TTS-09[114], VC-02 [115], VC-03(self-develop), TTS-10 [116],\\nAT-01 (Malafide+TTS-10 [116]), TTS-11 [117], AT-02(self-Develop), TTS-12 [118], TTS-13 [119],\\nAT-03(Malafide+TTS [120]), VC-04(self-develop), VC-05 [121][24], VC-06(add noise),\\nAT-04(Malacopula+VC-06), TTS-14 [122], TTS-15 [123], AT-05(Malacopula+AT-01),\\nAT-06(Malacopula+TTS-13 [119]), AT-07(Malacopula+VC-05 [121])\\nerate fake speech. Both Malafide [124] and Malocopula [125]\\nmethods involve leveraging filter banks. Malafide [124] ap-\\nplies multiple techniques of linear time-invariant (LTI), non-\\ncausal filter, and the coefficients (e.g., tap weights) to create\\nTTS/VC-based fake speech that mimics the target speaker.\\nMeanwhile, Malocopula [125] combines both linear filter and\\nnon-linear filter (e.g., one-dimensional convolutional layer)\\nto replicate the target speaker’s voice.\\nTo compare among DSD datasets, we analyze three dif-\\nferent aspects: (1) the number of fake utterances; (2) the AI-\\nsynthesized speech systems used to generate fake speech; and\\n(3) the original/real human speech resource used to generate\\nfake speech utterances. As Table III shows, most datasets\\npresent lower than 300,000 utterances of fake speech, ex-\\npected ASVspoof 2021 (DF Task) [23], ASVspoof 2024 [27],\\nAV-Deepfake1M dataset [25], [26], and DFDC dataset [15]\\nwith 589212, 815262, 860039, and 104500 fake samples,\\nrespectively. Although DFDC [15], [82] and AV-Deepfake1M\\ndataset [25], [26] present a large number of fake data, this\\nwas proposed for video in which audio may not be fake. Ad-\\nditionally, these fake utterances were generated from only a\\nfew deep-learning-based speech-generation systems. Indeed,\\ntwo TTS models of VITS [97], YoursTTS [98] and one TTS\\nmodel [82] were used to generate fake speech in DFDC [15]\\nand AV-Deepfake1M dataset [25], [26] datasets, respectively.\\nOn the other hand, the ASVspoof 2021 (DF Eva) dataset [23]\\ncontains 589212 fake utterances, generated using over 100\\nvoice conversion (VC) and text-to-speech (TTS) systems. To\\ncatch up with state-of-the-art deepfake speech generators,\\nTable IV presents the architectures and resources of deepfake\\nspeech generators. The table indicates that the ASVspoofing\\nseries shows up-to-date and diverse deepfake speech gener-\\nators compared to the others. In terms of the original human\\nspeech resources, most DSD datasets are based on recordings\\nfrom a limited number of speaker volunteers. For example,\\nalthough the ASVspoof 2021 (DF Eva) dataset [23] used\\n100 VC and TTS systems to create fake utterances, the real\\nspeech resource is from 107 speaker volunteers. Some DSD\\ndatasets of AV-Deepfake1M [25], [26], CFAD [43] leveraged\\nthe large and available human speech datasets to generate\\nfake utterances such as Voxceleb2 [37], AISHELLI-3 [35],\\nMAGICDATA [46]. However, these datasets use a limited\\nnumber of speech generators (e.g. 2 TTS and 11 TTS for\\nAV-Deepfake1M [25], [26] and CFAD [43], respectively).\\nRegarding metrics evaluation, all datasets proposed for the\\nDSD task come together with a baseline and metrics for\\nthe evaluation. Regarding the baseline systems, all baselines\\nleveraged convolutional neural network (CNN) based archi-\\ntectures. These baselines are evaluated mainly by the Equal\\nError Rate (EER) metric. Some datasets such as KoDF [34],\\nAV-Deepfake1M [25], [26], MLAAD [47], FoR [30] used\\nAccuracy (Acc.) and Area Under The Curve (AUC) metrics\\ninstead of EER.\\nDiscussion: Given the analysis of benchmark datasets pro-\\nposed for the DSD task, some existing issues can be outlined.\\nThese include the limited number of datasets available for\\nmultiple languages and the imbalance of several aspects\\nwithin existing datasets.\\nFirstly, more public and benchmark datasets have been\\nproposed for the DSD task. However, there is only one mul-\\ntilingual dataset currently. The lack of multilingual datasets\\nfor DSD tasks presents several challenges for current model\\ndevelopment and evaluation such as performance degradation\\non cross-language settings that leads to a limited applicability\\nOriginal\\nUtterance\\nAugmented\\nUtterances\\nspectrograms\\nFeature \\nExtraction\\nClassification \\nModel\\nOffline Data\\nAugmentation\\n.\\n.\\ne1\\ne2\\neC\\nembedding\\npfake\\npreal\\nPredicted \\nProbabilities\\nn-dim Tensors\\nLoss Function\\nFig. 4.\\nThe high-level architecture of Deepfake Speech Detection (DSD) systems\\n \\n Real Speakers\\nFake Utterances \\n \\n \\n \\n Fake Speech Generators\\n \\n Real Speakers\\n106\\n246500\\n10\\n107\\n108978\\n19\\n48\\n163114\\n13\\n48\\n589221\\n100\\n80\\n24072\\n2\\n107\\n41280\\n5\\n2\\n117985\\n6\\n1033\\n347400\\n11\\nASVspoof 2015\\nASVspoof 2019\\nASVspoof 2021 LA\\nASVspoof 2021 DF\\nADD 2022\\nVoC.v\\nWaveFake\\nCFAD\\nFig. 5.\\nThe imbalance among the fake speech utterances, the fake speech\\ngenerators, and the real speaker volunteers in benchmark DSD datasets\\nin real-world applications. This motivates the research com-\\nmunity to propose more datasets for multiple languages to\\nenhance model’s capability in real-life settings. Secondly, we\\nalso highlight an imbalance among DSD datasets regarding\\nthree aspects: (1) the number of fake utterances; (2) the AI-\\nsynthesized speech systems used to generate fake speech;\\nand (3) the original/real human speech resource used to gen-\\nerate fake speech utterances. The imbalance can be clearly\\ndescribed in Fig. 5 regarding DSD datasets using speaker\\nvolunteers.\\n• The number of utterances: The quantity of utter-\\nances within the datasets is not uniform. Some datasets\\nmay contain a large number of samples, while others\\nhave significantly fewer. A small number of real or\\nfake utterances within datasets (e.g. FakeAVCeleb [36],\\nADD [17]) limits the model’s exposure to a wide\\nvariety of speech patterns and scenarios, affecting the\\ndetection robustness and generalization new, unseen\\ndata. Additionally, a controlled ratio between real and\\nfake samples created within datasets (e.g ASVspoof\\n2024 [27], ASVsproof 2021 [23]) also ensure diversity\\nof fake techniques and avoid overfitting on the fake\\ndata, especially if the fake samples are generated using\\nsimilar techniques. Therefore, maintaining a moderately\\ncontrolled ratio between real and fake utterances, along\\nwith a diverse range of these utterances, is essential for\\nfuture dataset development.\\n• Deepfake speech generation systems: The variety of\\ndeep-learning-based systems used to generate deepfake\\nspeech is another area of concern. As Table IV shows,\\nsome of datasets such as MLAAD [47], ASVspoof\\n2021(DF task) [23], ASVspoof 2024 [27] present more\\nthan 20 systems (e.g. TTS, VC, or AT systems). Among\\nthese datasets, ASVspoof 2021 (DF Task) [23] and\\nASVspoof 2024 [27] present diverse TTS, VC, and\\nAT systems. In particular, while more than 100 TTS\\nand VC are for ASVspoof 2021 (DF Task) [23], 28\\nTTS, VC, and AT are used in ASVspoof 2024 [27].\\nAlthough MLAAD [47] has been the unique multiple-\\nlanguage dataset currently, fake speech in this dataset\\nwas only generated from TTS systems (e.g. 54 TTS\\nsystems). Overall, some datasets may predominantly\\nfeature speech synthesized by a few specific deep-\\nlearning-based generators or techniques, while others\\nmight include a broader range. Datasets generated from\\na limited number of deep-learning-based generators pos-\\nsibly lead to over-specialization, reducing the model’s\\nability to detect deepfakes generated by other systems\\nand affecting the performance in real-world scenarios.\\nTherefore, this imbalance motivates the research com-\\nmunity to create more diverse datasets that include a\\nwide range of AI-synthesized speech methods.\\n• Real human speech resource: The source of real voice\\nplays a crucial role in shaping the effectiveness, gen-\\neralizability, and ethical aspects of deepfake detection\\nmodels. As highlighted in Table IV, there are two main\\nsources for building DSD datasets: voice samples from\\nvolunteer speakers or from existing datasets. Voice sam-\\nples from volunteers offer greater control over diversity\\n(if managed thoroughly) and address ethical concerns,\\nas they are collected with explicit informed consent.\\nHowever, this approach can be resource-intensive in\\nterms of time and cost and may not scale efficiently. In\\ncontrast, utilizing existing human speech datasets offers\\nbetter accessibility and scalability. However, it may\\nintroduce biases toward certain groups, such as public\\nfigures, reducing diversity in real-world applications\\nand especially raising significant ethical issues. These\\nproblems suggest other balanced approaches to build\\nDSD datasets that consider both diversity and scalability\\nin the future.\\nBased on the above discussions and statistic informa-\\ntion in Fig. 5, it can be concluded that ASVspoof 2019\\n(LA task) [21], ASVspoof 2021 (LA & DF tasks) [23],\\nASVspoof 2024 [27] are among the most balanced datasets\\nTABLE V\\nINDIVIDUAL DSD SYSTEMS EXPLORING RAW AUDIO\\nSystems\\nYears\\nDatasets\\nFeatures\\nData Augmentation\\nModels\\nLoss Functions\\n(Distoration/Compression)\\n[126]\\n2021\\nASVspoof 2021 (LA Task)\\nRaw Audio\\nComp.: MP3, ACC, OGG\\nRawNet2\\nFocal loss\\n[127]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nRaw Audio\\nComp.: G.723, G.726,\\nRawNet2\\nCross Entropy (CE)\\nGSM, opus, speex, mp2,\\nogg, tta, wma, acc, ra\\n[128]\\n2021\\nASVspoof 2019 (LA Task)\\nRaw Audio\\nDis.: Channel Drop,\\nSinC+CRNN\\nMSE Loss\\nFrequency masking\\n[129]\\n2021\\nASVspoof 2021 (LA Task)\\nRaw Audio\\nComp.: mp3, mp2, m4a, m4r,\\nRawNet2\\nOC-Softmax\\nopus, ogg, mov, PCM µ-law,\\nPCM a-law, speex, ilbc,\\nG.729, GSM, G.722, AMR\\n[130]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nRaw Audio\\nDis.: Time-wise,\\nRawNet2\\nCross Entropy\\nSilence Strimming\\n[131]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nRaw Audio\\nn/a\\nEncoder: SinC+Residual\\nWCE Loss\\nDecoder: Graph Attention Network\\n[132]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nRaw Audio\\nDis.: Mixup, FIR filters\\nSinc+CNN\\nWCE Loss\\n[133]\\n2021\\nASVspoof 2021 (LA Task)\\nRaw Audio\\nComp.: G.711-alaw,G.722,\\nSinC+RawNet2\\nAM-softmax\\nGSM-FR, and G.729\\n[38]\\n2022\\nASVspoof 2019 (LA Task)\\nRaw Audio\\nn/a\\nRawNet2, RawNet-GAT, CRNNSpoof\\nCross Entropy\\nIn The Wild\\n[134]\\n2022\\nASVspoof 2019 (LA Task)\\nRaw Audio\\nn/a\\nEncoder: RawNet2\\nWCE Loss\\nDecoder: Graph Attention Neural Network\\n[135]\\n2022\\nASVspoof 2021 (LA&DF Tasks)\\nRaw Audio\\nDis.: RawBoost [136]\\nEncoder: Sinc+CNN, Wave2Vec2.0+CNN\\nWCE loss\\nDecoder: Graph Attention network\\n[137]\\n2023\\nASVspoof 2019 (LA Task),\\nRaw Audio\\nDis.: Stereo speech\\nEncoder: SinC+ResNet\\nAM-softmax\\nASVspoof 2021 (LA&DF Tasks)\\nDecoder: Graph Attention network\\n[138]\\n2023\\nASVspoof 2019 (LA Task)\\nRaw Audio\\nn/a\\nEncoder: Wav2vec2.0 [139], HuBERT [140]\\nCross Entropy\\nDecoder: LCNN-LSTM-Graph Attention\\n[141]\\n2023\\nADD 2023\\nRaw Audio\\nDis.: Add noise, mix utterance\\nEncoder: Wav2Vec2.0\\nCross Entropy\\nDecoder: ECAPA-TDNN\\n[142]\\n2022\\nASVspoof 2019 (LA Task),\\nRaw Audio\\nn/a\\nEncoder: ECAPA-TDNN, RawNet\\nCross Entropy,\\nDecoder: Linear layers\\nTriplet loss,\\nAM-Softmax\\n[143]\\n2023\\nADD 2023\\nRaw Audio\\nDis.:Add noise, vibration, mixup\\nEncoder: Wav2Vec2.0\\nA-Softmax,\\nDecoder:CNN-Transformer\\nTriplet loss,\\nAdversial loss\\n[144]\\n2023\\nASVspoof 2019 (LA Task),\\nRaw Audio\\nn/a\\nEncoder: Wav2Vec2.0 [139]\\nTriplet, BCE,\\nWaveFake,\\nDecoder: LCNN-Transformer\\nAdversarial loss\\nFakeAVCeleb\\n[145]\\n2024\\nASVspoof 2019 (LA Task),\\nRaw Audio\\nn/a\\nSincNet/LEAF+ResNet\\nCross Entropy\\nASVspoof 2021 (LA&DF Tasks),\\nIn The Wild [38]\\n[145]\\n2024\\nASVspoof 2021 (LA&DF Tasks)\\nRaw Audio\\nn/a\\nEncoder: EnCodec [146], AudioDec [147],\\nCross Entropy\\nAudioMAE [148], HuBERT [140],\\nWavLM [149], Whisper [150]\\nDecoder: ResNet\\n[151]\\n2024\\nASVspoof 2019 (LA Task),\\nRaw Audio\\nDis.: Add noise, overlapping\\nEncoder: WavLM [149],\\nCross Entropy\\nASVspoof 2021 (LA&DF Tasks)\\nDecoder: Multi-Fusion Attentive\\n[152]\\n2024\\nASVspoof 2019 (LA Task),\\nRaw Audio\\nn/a\\nEncoder: Wav2vec2.0 [139], BEATS [153],\\nn/a\\nASVspoof 2021 (LA Task),\\nLationCLAP [154], AudioCLIP [155],\\nIn The Wild\\nDecoder: Similarity Score Measurement\\nat the writing time. Additionally, the MLAAD [47] is the\\nlargest and most suitable DSD dataset for evaluating cross-\\nlanguages. The discussions on existing datasets for the DSD\\ntask underscore the importance of future efforts by the\\nresearch community to release comprehensive, multilingual,\\nand balanced datasets. Also, Fig. 5 emphasizes the significant\\ncosts and workload involved in creating such datasets, while\\nensuring compliance with essential security protocols for\\nspeaker volunteers.\\nOur contribution: Given the analysis and the discussion\\nabove, our work mainly contributes:\\n• We focus on the important role of public datasets\\nproposed for the DSD task, providing a comprehensive\\nanalysis and indicating the existing issues. The analysis\\nshows different aspects that are not mentioned in the\\nother surveys: (1) We report the original resource of\\nreal human speech; (2) We provide an overview of deep\\nlearning-based systems used to generate fake speech; (3)\\nThe survey is not only for fake speech but also for fake\\nvideo; (4) We highlight imbalances and other concerns\\nin current public DSD datasets, along with their impact\\non model performance and practical applicability.\\n• In line with the evolution of challenge competitions,\\nwe will continue to update new DSD datasets via\\nour GitHub repository3 in the future. This ensures the\\nongoing relevance of the survey and provides an up-to-\\ndate resource for DSD datasets.\\nIV. OVERVIEW ON PROPOSED SYSTEMS FOR DEEPFAKE\\nSPEECH DETECTION\\nTo conduct a comprehensive analysis of DSD systems, we\\nfirst review state-of-the-art research papers addressing the\\nDSD task. Notably, a large number of the selected papers\\nare from high-reputation journals and conferences such as\\nINTERSPEECH (48 papers) and ICASSP (29 papers) in\\nrecent years. Then, we categorize these DSD systems into\\n3https://github.com/AI-ResearchGroup/A-Comprehensive-Survey-with-\\nCritical-Analysis-for-Deepfake-Speech-Detection\\nTABLE VI\\nINDIVIDUAL DSD SYSTEMS EXPLORING SPECTROGRAM BASED FEATURES\\nSystems\\nYears\\nDatasets\\nData Augmentation\\nFeatures\\nModels\\nLoss Functions\\n(Distoration/Compression)\\n[156]\\n2020\\nASVspoof 2019 (LA Task)\\nDis.: Add noise, reverberation,\\nLFCC\\nResNet\\nLMC loss,\\nFreqAugment\\nCross Entropy\\n[126]\\n2021\\nASVspoof 2021 (LA Task)\\nComp.: MP3, ACC, OGG\\nLFCC\\nLCNN\\nFocal loss,\\nMEL\\nTDNN\\nFocal, Cross Entropy\\n[157]\\n2021\\nASVspoof 2021 (LA Task)\\nn/a\\nLFB, SPEC, LFCC\\nLCNN, LCNN-LSTM\\nCross Entropy, MSE\\n[158]\\n2021\\nASVspoof 2021 (LA Task)\\nComp.: MP3, ACC,\\nLFCC\\nECAPA-TDNN\\nFocal loss\\nlandlie, cellular, VoiP\\n[127]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nComp.: G.723, G.726, GSM,\\nCQT\\nLCNN\\nCross Entropy\\nopus, speex, mp2, ogg,\\nCQCC, LFCC\\nGMM\\ntta, wma, acc, ra\\nLFCC\\nGMM, LCNN\\n[129]\\n2021\\nASVspoof 2021 (LA Task)\\nComp.: G.723, G.726, GSM\\nPSCC, LFCC,\\nResnet18, TDNN\\nOC-Softmax\\nopus, speex, mp2, ogg,\\nDCT-DFT, LLFB\\ntta, wma, acc, ra\\n[130]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nDis.: Time-wise,\\nCQT\\nResNet, CNN, LSTM\\nCross Entropy\\nSilence Strimming\\n[132]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nDis.: Mixup, FIR filters\\nMSTFT\\nResNet, LCNN\\nCentral loss\\n[159]\\n2021\\nASVspoof 2019, 2021 (LA Task)\\nn/a\\nLFCCs, logLFBs,\\nSqueeze CNN\\nCross Entropy,\\nGM-LFBs,\\nA-Softmax loss\\nTextrograms\\nMLC loss\\n[160]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nComp.: MP3, AAC,\\nLFCCs\\nECAPA-TDNN, ResNet\\nOC-Softmax,\\nLandlie, cellular;\\nP2SGrad losses\\nDis.: device impulse\\n[133]\\n2021\\nASVspoof 2021 (LA Task)\\nComp.: G.711-alaw, G.722,\\nLFCCs\\nLCNN\\nAM-softmax\\nGSM-FR, and G.729\\n[161]\\n2021\\nASVspoof 2019 (LA Tasks)\\nn/a\\nLFCC\\nResNet\\nOC-Softmax\\n[162]\\n2021\\nASVspoof 2019 (LA Tasks)\\nn/a\\nLFCC\\nLSTM-SECNN\\nMSE loss\\n[163]\\n2021\\nASVspoof 2019 (LA Tasks)\\nDis.: SpecAug\\nlog-Mel\\nResNet\\nn/a\\n[38]\\n2022\\nASVspoof 2019 (LA Task),\\nn/a\\nCQT, log-STFT\\nLCNN, CNN-LSTM, Inception,\\nCross Entropy\\nIn the Wild\\nMEL\\nResNet, Transformer\\n[164]\\n2022\\nADD 2022\\nDis.: Add noise/music/babele,\\nLFCC\\nResNet\\nFocal loss\\nReverb, Modify Volume, SpecAug;\\nComp.: MP3, OGG, AAC, OPUS\\n[165]\\n2023\\nASVspoof 2019 (LA Task),\\nn/a\\nLFCC\\nLCNN-LSTM\\nCross Entropy,\\nWaveFake, FakeAVCeleb\\nAdversarial loss,\\nTriplet loss\\n[166]\\n2023\\nASVspoof 2019 (LA Task)\\nComp.: FLAC\\nMEL\\nFinetune SSAT Transformer\\nCross Entropy\\n[143]\\n2023\\nASVspoof 2019 (LA Task)\\nn/a\\nSTFT+F0 sub-bands\\nSENet34\\nA-Softmax,\\nKL loss\\n[167]\\n2023\\nASVspoof 2019 (LA Task)\\nn/a\\nLFCC, CQT\\nTeacher-Student\\nOC-Softmax,\\n(ResNet, LCNN)\\nMSE loss\\n[145]\\n2024\\nASVspoof 2019 (LA Task),\\nn/a\\nCQT, MEL,\\nResNet\\nCross Entropy\\nlogSpec, LFCC\\n[168]\\n2024\\nASVspoof 2019 (LA Task),\\nDis.: SpecAugment\\nFBank\\nECAPA-TDNN\\nAM-Softmax\\nASVspoof 2021 (LA&DF Tasks)\\n[169]\\n2024\\nASVspoof 2019 (LA Task),\\nDis.: RawBoost [136]\\nlog-MEL\\nEncoder: CNN, ResNet,\\nCross Entropy,\\nASVspoof 2021 (LA&DF Tasks)\\nSE-ResNet\\nContrastive loss\\nDecoder: GAN networks [170]\\n[171]\\n2024\\nASVspoof 2019 (LA Task)\\nDis.: Oversampling\\nSTFT\\nEncoder: Transformer\\nCross Entropy\\nDecoder: Transformer\\n[172]\\n2024\\nASVspoof 2019 (LA Task),\\nDis.: RawBoost [136]\\nMEL\\nFinetune Wav2Vec2.0\\nCross Entropy,\\nASVspoof 2021 (LA&DF Tasks),\\n(XLSR-53 [139])\\nContrastive loss\\nFakeAVCeleb, WaveFake\\n[173]\\n2024\\nASVspoof 2019 (LA Task)\\nComp.: aac, flac, mp3, m4a\\nLFCC\\nEncoder: Transformer\\nOC-Softmax\\nASVspoof 2021 (DF Task)\\nwma, ogg, wa\\nDecoder: Transformer\\nDis.: Speed perturbation, SpecAug\\nthree groups based on input type, as detailed in Tables V, VI,\\nand VII. The first group, shown in Table V, consists of DSD\\nsystems that directly process audio utterances using single\\nmodels. These models are based on a single machine learning\\nalgorithm or one specific network architecture. In the second\\ngroup (Table VI), audio utterances are first transformed\\ninto spectrograms, representing temporal-frequency features.\\nAfter this transformation, a single model is applied to analyze\\nthe data. The final group, shown in Table VII, features a\\ndiverse range of ensemble models that utilize various input\\nfeatures and combine multiple models. Given the summary\\nof DSD systems in Table V, VI, VII, we describe the high-\\nlevel architecture of DSD systems as shown in Fig. 4. From\\nFig 4, we then identify and analyze four main components\\nthat directly impact the DSD system performance: (1) Offline\\ndata augmentation, (2) feature extraction, (3) classification\\nmodel, and (4) loss function and training strategy.\\nA. Offline data augmentation\\nAnalysis: Data augmentation involves generating vari-\\nations of the original data to increase the size of DSD\\ndatasets, which enhances the robustness and generalization\\ncapabilities of machine learning models. Since this step\\nis applied to original audio utterances before the training\\nprocess, it can be referred to as offline data augmentation. As\\nshown in Tables V, VI, and VII, offline data augmentation\\nmethods can be separated into two main groups, referred\\nto as compression and distortion. The compression methods\\ninvolve compress and decompress algorithms, mainly using\\naudio codec techniques. A codec, short for ‘coder-decoder’,\\nis software used to compress and decompress digital audio.\\nTABLE VII\\nDSD SYSTEMS LEVERAGING ENSEMBLE TECHNIQUES TO ENHANCE THE PERFORMANCE\\nSystems\\nYears\\nDatasets\\nFeatures\\nData Augmentation\\nModels\\nLoss Functions\\nEnsemble Methods\\n(Distoration/Compression)\\n[174]\\n2019\\nASVspoof 2019 (LA Task),\\nLFCC, CQT, FFT\\nn/a\\nLCNN\\nA-Softmax\\nMultiple inputs\\n[175]\\n2021\\nASVspoof 2019 (LA Task)\\nRaw Audio\\nDis.: Mixup\\nResNet\\nCross Entropy\\nMultiple branches\\n[176]\\n2021\\nASVspoof 2019 (LA Task)\\nLSB, SPEC, LFCC\\nn/a\\nLCNN, LCNN-LSTM\\nCross Entropy,\\nMultiple inputs, models\\nMSE for P2SGrad\\n[158]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nLFCC\\nComp.: MP3, ACC, landlie,\\nVariants of ECAPA-TDNN\\nOC-Softmax\\nMultiple models\\ncellular, VoiP\\n[177]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nLFCC\\nDis.: Reverberation, add noise,\\nResNet, MLP, SWA[18]\\nlarge margin cosine,\\nMultiple models\\nComp.: mp3, mp4\\nCross Entropy\\n[126]\\n2021\\nASVspoof 2021 (LA Task)\\nLFCC, MFCC, draw\\nComp.: MP3, ACC, OGG\\nTDNN, RawNet2\\nFocal loss\\nMultiple inputs, models\\n[127]\\n2021\\nASVspoof 2021 (LA&DF Tasks)\\nDraw, CQCC, LFCC\\nComp.: G.723, G.726,\\nGMM, LCNN\\nCross Entropy\\nMultiple inputs, models\\nGSM, opus, speex, mp2, ogg,\\ntta, wma, acc, ra\\n[129]\\n2021\\nASVspoof 2021 (LA Task)\\nRaw, PSCC, LFCC,\\nComp.: TODO set 1+2\\nResNet18, GMM,\\nOC-Softmax\\nMultiple inputs, models\\nDCT-DFT, LLFB\\nTDNN, RawNet2\\n[132]\\n2021\\nASVspoof 2021 (LA Task)\\nMSTFT\\nDis.: Mixup, FIR filters\\nResnet18, LCNN, Sinc+CNN\\nCentral loss\\nMultiple inputs, models\\n[161]\\n2021\\nASVspoof 2019 (LA Tasks)\\nLFCC\\nn/a\\nResNet\\nOC-Softmax\\nMultiple branches\\n[178]\\n2022\\nASVspoof 2021 (LA&DF Tasks)\\nLFCC\\nComp.: G.711-alaw, G.711-µlaw\\nGMM-MobileNet\\nCross Entropy\\nMultiple branches\\n[179]\\n2022\\nASVspoof 2021 (LA Task)\\nCQT, MEL\\nDis.: Mixup, Frequency Masking\\nBC-ResNet, FreqCNN\\nn/a\\nMultiple inputs, models\\n[180]\\n2022\\nASVspoof 2019 (LA Tasks)\\nLFCC\\nn/a\\nResNet, LSTM\\nOC-Softmax loss\\nMultiple branches\\n[181]\\n2022\\nASVspoof 2019, 2021 (LA Task)\\nLog-Mel\\nDis.: Add music, noise, speech\\nResNet\\nA-Softmax\\nMultiple models\\nReverb, pitch shift, SpecAug\\n[182]\\n2023\\nASVspoof 2019, 2021 (LA Task)\\nRaw Audio\\nDis.: Mixup, SpecAug\\nResNet\\nCross Entropy\\nMultiple branches\\n[183]\\n2023\\nADD 2023\\nRaw Audio, Log-Mel\\nDis.: Add noise, room inpulse,\\nResNet\\nCross Entropy,\\nMultiple branches\\nmixup, speed shifting,\\nKL loss\\nfrequency masking\\n[138]\\n2023\\nASVspoof 2019 (LA Task)\\nWav2vec, Duration,\\nn/a\\nLCNN-LSTM-GAP\\nCross Entropy\\nMultiple inputs\\nPronunciation\\nCross Entropy\\n[171]\\n2024\\nASVspoof 2019 (LA Task)\\nSTFT phase, magnitude\\nDis.: Oversampling\\nTransformer\\nEntropy\\nMultiple inputs\\n[184]\\n2024\\nASVspoof 2019 (LA Task),\\nLFCC, MPE\\nn/a\\nLCNN\\nCross Entropy\\nMultiple inputs\\nIn The Wild\\n[185]\\n2024\\nASVspoof 2019 (LA Tasks)\\nRaw Audio\\nDis.: Noise, Reverb, SpecAug,\\nEncoders:\\nCross Entropy,\\nMultiple models\\nASVspoof 2021 (LA Task)\\nDrop Frequencies\\nWav2vec-XLSR-ASR,\\nMSE for P2SGrad\\nIn-the-wild, MLAAD-EN\\nWav2vec-XLSR-SER\\n[145]\\n2024\\nASVspoof 2019 (LA Task),\\nRaw Audio\\nn/a\\nEncoders: XLS-R,\\nCross Entropy\\nMultiple inputs, models\\nASVspoof 2021 (LA&DF Tasks)\\nHubert, WavLM\\nDecoder: ResNet\\nAmong these methods, MP3, AAC, OGG, G.7XX, and Opus\\nformats are commonly applied. Codec data augmentation\\nhelps simulate these real-world conditions through various\\ncompression schemes (e.g., phone calls, music streaming,\\nor online video playback on applications such as Facebook,\\nWhatsApp, etc.). Since different codecs use various com-\\npression and decompression algorithms, they impact audio-\\nrelated factors such as signal-to-noise ratio (SNR), high-\\nfrequency formants, energy loss, sample rate, bit depth, and\\nbitrate in distinct ways. This suggests that if there are subtle\\ndifferences between real and fake speech in these aspects,\\ngenerating diverse audio utterances using different codecs\\ncan be an effective approach for distinguishing between\\nthem.\\nCodec methods can be divided into three main categories\\nbased on the quality of audio data: uncompressed format,\\nlossless compressed format, and lossy compressed format.\\nAudio files with uncompressed formats such as WAV, AIFF,\\nor PCM are large and contain all audio information recorded\\nfrom an audio device. The lossless compressed formats such\\nas FLAC, WMA, or ALAC only reduce unnecessary features\\nof audio data and retain the almost original audio data.\\nMeanwhile, lossy compressed formats such as MP3 or AAC\\nsignificantly reduce audio features such as sample rate or bit\\ndepth to achieve low-volume audio files, which is suitable for\\nstreaming-based applications with real-time requirements.\\nThe second distortion method tends to modify the raw au-\\ndio by adding reverberation, background, and music in [177],\\n[185], [181] or using techniques of time-wise, silence stream-\\ning in [130] without affecting the audio quality such as sam-\\nple rate, bit depth, or bit rate. The distortion method enforces\\nclassification models to learn distinct features between fake\\nand real speech while these features are mixed by different\\nnoise resources. Notably, conventional data augmentation\\nmethods, such as pitch shifting and time stretching, which are\\ncommonly applied to raw audio in tasks like Acoustic Scene\\nClassification [186], Speech Emotion Detection [187], and\\nSpeech Separation [188], have not been applied popularly to\\nthe DSD task [183], [181].\\nDiscussion: Although compression methods and distortion\\nmethods present different approaches to generate more au-\\ndio data, none of the papers has compared, analyzed, and\\nindicated if one of the approaches is superior in the DSD\\ntask. Indeed, the statistical information in Fig 6 indicates\\nthat the state-of-the-art DSD systems using offline distor-\\ntion augmentation and offline compression augmentation are\\nequal.\\nRegarding codec-based data augmentation, little research\\nhas examined the differences among codec methods to iden-\\ntify which are most suitable for the DSD task in certain real-\\nlife scenarios. Indeed, social networks such as Facebook,\\nInstagram, or YouTube and Internet-based communication\\ntools such as WhatsApp, and WeChat (VoIP call) utilize\\nspecific and relevant codec methods. For example, YouTube\\nshares audio with MP3 formats, while VoIP calls normally\\nuse G.722 audio format as the standard. However, many\\nproposed DSD systems have been evaluated on current and\\nbenchmark datasets with WAV files, which do not accurately\\nreflect the codec-specific conditions of real-life DSD appli-\\ncations.\\nIn speech-relevant tasks such as speaker recognition,\\nspeaker emotion detection, etc., some distortion data aug-\\nCompression \\n (using codecs)\\n39.4%\\nDistortion \\n (on raw audio)\\n39.4%\\nDistortion \\n (on spectrogram)\\n21.2%\\nFig. 6.\\nThe statistics of data augmentation methods obtained from\\nTable V, VI, VII\\nmentations of Mixup [189] or SpecAugment [190], which are\\ninspired from the computer vision domain, are widely used.\\nThese data augmentation methods focus on synthesizing new\\nspectrograms in various manners (e.g., merging, masking),\\nwhich might not accurately reflect artifacts of the audio\\nsignal. Additionally, these data augmentation methods are\\napplied to batches of spectrograms, referred to as online\\ndata augmentation. As shown in Fig. 6, Mixup [189] or\\nSpecAugment [190] are also used in a wide range of DSD\\nsystems. However, none of the papers has analyzed or\\ncompared the efficiency between offline data augmentation\\nand online data augmentation.\\nOur contribution: Given the analysis and the existing\\nconcerns above, our work mainly contributes:\\n• To evaluate the role and the effect of the online and\\noffline data augmentation methods, we conducted ex-\\ntensive experiments in this paper. Based on our find-\\nings, we identify data augmentation techniques that\\nare compatible with DSD systems. In particular, we\\ncompare the performance of codec-based methods with\\nthe Mixup [189] and SpecAugment [190] in this paper.\\n• On our GitHub repository, we regularly update codec-\\nbased methods and other data augmentation techniques\\nfeatured in the latest research. We also released code\\nfor implementing codec-based methods and other data\\naugmentation methods in this GitHub repository, which\\nare used to conduct our experiments in this paper.\\nB. Feature extraction\\nAnalysis: As shown in Fig. 4, feature extraction methods\\ncan be categorized into two main groups: non-parameter and\\ntrainable-parameter methods.\\nIn non-parameter feature extraction, a raw audio ut-\\nterance (e.g., a 1-D tensor) is first transformed into a time-\\nfrequency spectral features (e.g., a 2-D tensor) using var-\\nious transformation ranging from spectral coefficients (e.g.,\\nMFCC [191], [126], LFCC [129], [180], [161], CQCC [127],\\netc) to spectrogram-based representations such as STFT-\\nspectrogram [171], [132], CQT-spectrogram [127], [130],\\netc. Once the time-frequency spectrograms are generated,\\nsome DSD systems directly use them for training with\\nclassification models [130], while other systems use several\\napproaches to enhance feature quality before applying a\\nclassification model. The first approach involves applying\\nauditory filter banks such as Mel [158], [145], Linear Fil-\\nter [126], [160], [133] (LF), etc, to capture the relation-\\nships between frequency bands. Then a Discrete Fourier\\nTransform (DFT) is applied to analyze the relationship\\nacross temporal dimension before the features are fed into\\na model for the training process [126], [158], [160], [133].\\nNotably, the output of Mel, LF, or DFT operations remains\\na 2-D tensor (similar to a spectrogram), representing both\\ntemporal and spectral features. In the second approach,\\nspectrograms are fed into pre-trained models, such as XLS-\\nR [192], Hubert [140], WavLM [149], or Whisper [150], to\\nextract embeddings. These embeddings are the output feature\\nmaps from a specific layer of the pre-trained model [145].\\nTypically, the embeddings form a 1-D tensor, similar to\\na vector, where each dimension of the vector is treated\\nas an independent value. In this approach, the choice of\\nspectrogram depends on the one used to train the pre-trained\\nmodels. Typically, the Mel-spectrogram is preferred, as most\\npre-trained models use it as input for training upstream\\ntasks [149], [140], [150]. In general, non-parameter feature\\nextraction leverages various spectrogram transformations,\\nauditory filters, auditory statistics, and pre-trained models to\\ngenerate distinct features (e.g., 1-D audio embeddings, 2-D\\nspectrograms) of audio input.\\nTrainable-parameter feature extraction involves ex-\\ntracting audio features by applying trainable network layers.\\nIn particular, systems proposed in [145], [128], [131] applied\\nSincNet layers [193], LEAF layers [194], FBanks [168] to\\nlearn and extract features from raw audio. These techniques\\nconstruct learnable filterbanks or approximate the standard\\nfiltering process. For example, SincNet and LEAF layers\\nkeep the role of adaptive and bandpass filters to capture fre-\\nquency features between two pre-defined cut-off frequencies.\\nThe outputs of these trainable layers are the feature maps\\nthat are then fed into the next parts of detection systems. In\\nother words, trainable feature extraction includes trainable\\nnetwork layers as a part of entire network architectures that\\ndirectly train and learn features from raw audio without the\\nspectrogram transformation steps.\\nDiscussion: By allowing learnable temporal-spatial fea-\\ntures during the training process, trainable-parameter feature\\nextraction is compatible with end-to-end systems and shows\\neffectiveness in distinguishing artifacts in fake speech. How-\\never, as most proposed systems using trainable features were\\nevaluated on single datasets rather than cross-dataset settings,\\nthis possibly leads to challenges in generalization since\\nlearned feature sets perform well under specific conditions\\nbut fail in unseen fake speech in real-world environments.\\nRegarding feature extraction using audio embeddings from\\npre-trained models, although these pre-trained models are\\neffective for many audio tasks, using them for deepfake\\ndetection presents several challenges. Firstly, as pre-trained\\nmodels are initially trained for upstream tasks such as\\nspeech-to-text, speaker identification, emotion detection, etc,\\nthat focus on different aspects (i.e., speech-to-text or emotion\\nCross Entropy\\n41.3%\\nSoftmax loss\\n20.6%\\nFocal loss\\n7.9%\\nMSE loss\\n7.9%\\nTriplet loss\\n6.3%\\nAdversarial loss\\n4.8%\\nContrastive loss\\n4.8%\\nOthers\\n6.3%\\nFig. 7.\\nThe statistics of loss functions obtained from Table V, VI, VII\\ndetection), the audio melody and harmony (i.e. emotion de-\\ntection), or distinct frequencies (i.e., speaker identification),\\nembeddings can fail to capture subtle artifacts specific to\\nsynthesized speech. Secondly, audio deepfakes are generated\\nto closely mimic real speech, they often have the same\\nformants, pitch, and rhythm as real audio, especially when\\ngenerated by advanced deep-learning-based speech genera-\\ntion systems. Additionally, the use of pre-trained models can\\nadd complexity due to their large network architectures.\\nFor systems using spectrograms such as CQT, MEL,\\nGAM, etc., each spectrogram is designed to capture specific\\nfrequency ranges. These spectrograms focus on different\\ncentral frequencies, which allows them to highlight distinct\\nfeatures of an audio signal. However, human speech contains\\na wide range of formants - characteristics of sound deter-\\nmined by factors such as language, accent, vocal tract shape,\\nand vocal fold behavior. Therefore, relying on only one\\ntype of spectrogram may miss important features, leading\\nto incomplete or insufficient representations of the speech\\nsignal that are useful for deepfake detection. To address\\nthis, DSD systems have begun to use ensembles of mul-\\ntiple spectrogram inputs [126], [158], [127], [129], [132].\\nBy leveraging the unique strengths of each spectrogram\\ntype, this approach aims to enhance detection accuracy\\nand has shown significant improvements in model perfor-\\nmance. Many top-performing systems in recent competitions\\nhave demonstrated the effectiveness of using ensembles to\\nboost overall system robustness. However, ensemble models\\npresent several limitations, including reduced interpretability,\\nincreased system complexity, and higher training costs.\\nOur contribution: Given the analysis and the discussion\\nabove, our work mainly contributes:\\n• We presented the commonly used feature extraction\\nmethods in DSD systems, highlighting their charac-\\nteristics and potential challenges associated with each\\napproach.\\n• In the next section, we conduct extensive experiments\\nof various feature extraction methods to evaluate the\\nMultiple inputs\\n19.0%\\nMultiple \\n branches \\n or models\\n47.6%\\nMultiple inputs \\n and models\\n33.3%\\nFig. 8.\\nThe statistics of ensemble methods obtained from Table V, VI, VII\\nmost effective approach for the DSD task. Additionally,\\nwe explore different feature ensembles to determine the\\noptimal combinations for enhancing performance.\\n• In our GitHub, we release code for different spectro-\\ngram transformations using Librosa toolbox [195].\\nC. Classification models\\nAnalysis: Early models proposed for DSD task ap-\\nproached conventional machine learning algorithms. For ex-\\nample, 9 over 16 submitted systems in ASVspoofing 2015\\nchallenge [191] extract MFCC feature (i.e. Systems A, B,\\nE, G, H, I, N, O, and P in [191]). Then, various ma-\\nchine learning-based models such as Mahalanobis distance\\nmeasurement, Gaussian-based model (GMM), support vector\\nmachine-based models (SVM, SVM-RBF), or fusion models\\n(GMM and SVM) are used to explore MFCC features.\\nHowever, recent DSD systems as shown in Table V, VI, VII\\npresent a wide range of neural network architectures due to\\nthe powerful deep learning techniques. Recently proposed\\ndeep neural networks for the DSD task can be separated\\ninto four main approaches. The first approach, which fo-\\ncuses on exploring spatial features, leverages convolutional-\\nbased network architectures (CNN). Among the CNN-based\\nnetworks, Resnet, LCNN, and RawNet architectures are\\nwidely approached. ResNet and LCNN are used to explore\\nspectrogram-based features such as LFCC [127], CQT [132],\\nand MEL [145]. Meanwhile, RawNet architectures are nor-\\nmally combined with SincNet layer [193] to learn raw\\naudio [126], [127], [129], [130], [133], [145]. The second\\napproach, which focuses on exploring the temporal features,\\npresents recurrent neural network (RNN) based architectures.\\nFor example, LSTM-based networks, TDNN, or ECAPA-\\nTDNN are proposed in [130], [126], [158], [129] and [168],\\nrespectively. As shown in Table V, VI, VII, RNN-based\\nnetworks have not been popularly applied for the DSD\\ntask compared to the CNN-based architectures. The third\\napproach involves combining both convolutional layers and\\nrecurrent layers to explore both temporal and spatial features,\\nreferred to as hybrid network architectures. In particular,\\nrecurrent network-based layers such as LSTM, GRU are\\ncombined with CNN-based layers to perform convolutional-\\nrecurrent neural network (CRNN) architectures [126], [168],\\n[165].\\nRecently, encoder-decoder based network architectures\\nhave been popularly used for the DSD task. Indeed, along\\nwith conventional encoder and decoder in transformer-based\\narchitectures [171], [173], various encoder architectures such\\nas XLSR-53 [172], WavLM [151], CNN or ResNet [169]\\nare explored. Decoder architectures also show diverse using\\nGAN-based architecture [169], Multi-feature attention [151],\\nGraph Attention Network [131], [135], [134], etc.\\nTo further enhance the DSD performance, the DSD re-\\nsearch community leverages a wide range of ensemble\\nmodels. These ensemble models can be separated into three\\nmain approaches which are marked in the final column in\\nTable VII. In the first approach (Multiple inputs), multi-\\nple input features are explored [174], [138], [171]. This\\napproach is inspired by the idea that multiple features\\ncontain different and distinct features between fake and real\\nutterances. Given different features, each feature is trained\\nby the same classification model (i.e., the individual model\\nshares the same network architecture but presents different\\ntraining parameters after the training process). For example,\\nwhile [171] explores the magnitude and phase features of\\nSTFT spectrogram, different features of Wav2Vec embed-\\ndings, duration, and pronunciation are explored in [138].\\nSimilarly, multiple spectrograms such as LFCC, CQT, and\\nSTFT are trained by one classification model of CNN [196].\\nFinally, the scores obtained from individual models are fused\\nto achieve the final and best result. The second approach\\n(Multiple branches or models) leverages different network\\narchitectures that explore one type of input feature [158],\\n[177], [178], [161], [175], [182], [183], [181], [185]. This\\napproach is inspired by the idea that different network archi-\\ntectures are likely to capture distinct properties from the input\\nfeature. For example, [177] proposed multiple branches of\\nGMM-DNN and ResNet to explore the LFCC spectrogram.\\nSimilarly, [158] explores the raw audio by different variants\\nof ECAPA-TDNN. The final approach (Multiple inputs,\\nmodels) leverages both multiple input features and different\\nnetwork architectures. For example, [126] explore raw audio\\nby RawNet2. Meanwhile, TDNN and LFCC spectrogram are\\nexplored by LCNN. Then, the authors fused three results\\nobtained from three individual models. Similarly, multiple\\ninput features of raw audio, CQCC, and LFCC are ex-\\nplored by different models of LCNN, GMM, and RawNet2\\nin [127]. Ensemble methods are widely adopted in many\\ntop-performing systems in DSD challenge competitions.\\nDiscussion: Although many deep neural network archi-\\ntectures have been proposed for the DSD task and evaluated\\non various benchmark datasets, the best results have been\\nobtained from ensemble methods with multiple inputs or/and\\ndifferent network architectures. The statistics of ensemble\\nmodels, as shown in Fig 8, indicate that multiple branches or\\nmodels are the majority. However, ensemble models present\\nthe concern of large trainable parameters. Moreover, none\\nof the research has been analyzed to indicate the individual\\nroles of input features or types of network architectures used\\nin ensemble methods. To demonstrate a robust and general\\nDSD model, the proposed model needs to be evaluated\\nwith multiple datasets, cross-datasets, or cross-languages.\\nHowever, only some recent research [172], [38], [152], [144]\\nevaluated the proposed models with multiple datasets such as\\nASVspoof 2019 (LA Task), ASVspoof 2021 (LA&DF Task),\\nIn The Wild, etc. To the best of our knowledge, none of the\\nresearch has proposed the evaluation on cross-languages.\\nOur contribution: Given the analysis and the discussion\\nabove, our work mainly contributes:\\n• We evaluate various input features, indicating the effec-\\ntive input feature for DSD system performance.\\n• We also evaluate a wide range of network architectures\\nleveraging the transfer learning technique, end-to-end\\ntraining approach, and audio embeddings extracted from\\nstate-of-the-art pre-trained models.\\n• Given extensive experiments on different input features\\nand various network architectures, we propose an en-\\nsemble model that is competitive to the state-of-the-art\\nDSD systems\\nD. Loss function and training strategy\\nFrom Table V, VI, VII, it can be seen that most proposed\\nmodels use a single loss function. Statistics of the individual\\nloss functions are also presented in Fig. 7. As shown in\\nFig. 7, the cross entropy (CE) based losses (e.g. Binary\\nCross Entropy (BCE), Weight Cross Entropy (WCE), etc.)\\nand Softmax-based losses (e.g., Additive-Margin-Based Soft-\\nmax (AM-Softmax), Angular-Margin-Based Softmax (A-\\nSoftmax), etc.) present the most popular loss functions. Some\\nmodels combine different loss functions. For example, CE\\nand Contrastive loss were used in [169]. Similarly, authors\\nin [165] combined three loss functions of Cross Entropy,\\nTriplet loss, and Adversarial loss. Some papers such as [159]\\nand [160] compared the DSD performance between large\\nmargin cosine loss (LMC loss), and A-Softmax loss functions\\nor between OC-Softmax, MSE for P2SGrad loss functions,\\nrespectively.\\nGenerally, a single loss function is used in end-to-end\\nbased systems. Meanwhile, the combination of multiple loss\\nfunctions is related to different training strategies. For exam-\\nple, [172] proposed a teacher-student scheme in which the\\nteacher was trained with contrastive loss and the student was\\ntrained by a combination of contrastive loss, Cross Entropy,\\nand MSE loss. Similarly, the student network in [197],\\n[167] was trained by a combination of Cosine Similarity/OC-\\nSoftmax and MSE loss functions. It can be seen that muliple-\\nloss functions used for teacher-student schemes help achieve\\na low-complexity model for the DSD task [172], [197], [167].\\nAdditionally, using multiple-loss function in [142] aims for\\nmultiple-task learning strategy. Rather than focusing on loss\\nfunctions, some researchers improve the DSD system by\\nexploring the training strategy. For example, authors in [198]\\nsuggested to mix three datasets for the training process.\\nThis enhances the generalization and stabilization of the\\nauthors’ proposed DSD system. Meanwhile, authors in [199]\\ngenerated more fake utterances by leveraging four types of\\nVocoders: HiFiGAN, MB-MelGAN, PWG, and WaveGlow,\\nwhich helps to improve their DSD system performance.\\nV. OUR PROPOSED DEEPFAKE SPEECH DETECTION\\nSYSTEM AND EXTENSIVE EVALUATION\\nA. Our motivation\\nGiven the comprehensive analysis of the DSD systems in\\nSection IV, we are motivated to conduct extensive experi-\\nments that address and evaluate the main concerns below.\\n• We evaluate the role of offline data augmentation\\n(codec) and compare this method with the conventional\\nonline data augmentation methods of Mixup [189] and\\nSpecAugment [190]. We also indicate if a combination\\nof offline and online data augmentation methods is\\neffective in enhancing the DSD system performance.\\n• We conduct extensive experiments to evaluate different\\ninputs and various network architectures. Given the\\ncomparison, we indicate which input features, network\\narchitectures, combination of input features, and net-\\nwork architectures have the potential to be further ex-\\nplored. We then propose the best DSD ensemble system\\nwhich is competitive to the state-of-the-art systems.\\n• To address the real-time ability, our proposed models\\nare evaluated on two-second utterances and present low-\\ncomplexity architectures.\\nB. Selected datasets and evaluating metrics\\nAs the trade-off among the number of utterances, the\\ndeep-learning-based fake speech generation systems, the\\noriginal/real human speech resource shown in Fig. 2 and\\nthe comprehensive analysis in Section III, we decide to use\\nASVspoof 2019 (LA Task) to evaluate the effect of data\\naugmentations, different types of input features, and various\\nnetwork architectures.\\nWe obey the ASVspoof 2019 (LA Task) challenge, then\\nuse the Equal Error Rate (ERR) as the main metric for\\nevaluating proposed models. We also report the Accuracy, F1\\nscore, and AUC score to compare the performance among\\nevaluating models.\\nC. Proposed systems and experimental settings\\nData augmentations: We evaluate the role of two data\\naugmentation methods: offline data augmentation (codecs)\\nand online data augmentation (Mixup and SpecAugment).\\nRegarding offline data augmentation using codec-based\\nmethods, we use six popular codec formats MP3, OPUS,\\nOGG, GSM, G722, and M4A. While the codec-based meth-\\nods compress and decompress raw audio before the training\\nprocess, the online data augmentation methods of Mixup\\nand SpecAugment work on batches of spectrograms during\\nthe training process. By evaluating these two groups of\\ndata augmentation individually, we indicate if each of them\\npresents a significant contribution and a combination of two\\ndata augmentation methods can help to enhance DSD task\\nperformance.\\n2-second segment\\nMel filter\\nLinear filter\\nGamma filter\\nWavelet\\nSTFT\\nCQT\\nFig. 9.\\nGenerate spectrograms using different spectrogram transformation\\nmethods and auditory filter models\\nTABLE VIII\\nTHE CNN, RNN, AND C-RNN NETWORK ARCHITECTURES\\nModels\\nConfiguration\\nCNN-based model\\n3 × {Conv(32/64/128)-ReLU-AP-Dropout(0.2)}\\n1 × {Dense(256)-ReLU-Dropout(0.2)}\\n1 × {Dense(2)-Softmax}\\nRNN-based model\\n2 × {BiLSTM(128/64)-ReLU-Dropout(0.2)}\\n1 × {Dense(256)-ReLU-Dropout(0.2)}\\n1 × {Dense(2)-Softmax}\\nC-RNN-based model\\n3 × {Conv(32/64/128)-ReLU-AP-Dropout(0.2)}\\n2 × {BiLSTM(128/64)-ReLU-Dropout(0.2)}\\n1 × {Dense(256)-ReLU-Dropout(0.2)}\\n1 × {Dense(2)-Softmax}\\nMultiple input features: Fig. 9 presents seven types of\\ninput features: raw audio and six different spectrograms,\\nwhich are evaluated in this paper. In particular, we use\\nthree transformation methods of Short-time Fourier Trans-\\nform (STFT), Constant-Q Transform (CQT), and Wavelet\\nTransform. Presumably, each type of spectrogram focuses on\\ndifferent perspectives on frequency content and might catch\\ndifferent inconsistencies in the audio signal. We then leverage\\ndifferent auditory-based filters: Mel and Gammatone filters\\nfocus on subtle variations relevant to human auditory per-\\nception and the linear filter (LF) isolates specific frequency\\nbands.\\nAs we set the window length, the hop length, and the filter\\nnumber with 1024, 512, and 64, we achieve the same spectro-\\ngram shape of 64×64. Then, we apply Discrete Cosine Trans-\\nform (DCT) to spectrograms across the temporal dimension.\\nFinally, the first and the second-order derivatives are applied\\nto these spectrograms, generating a three-dimensional tensor\\nof 64×64×3 (i.e., the original spectrogram, the first-order\\nderivative, and the second-order derivative are concatenated\\nacross the third dimension).\\nBack-end classification models: This paper proposes\\nthree main approaches for back-end classification models:\\nthe end-to-end deep learning approach, the transfer learning\\napproach, and the audio-embedding deep learning approach.\\nRegarding the end-to-end deep learning approach, four mod-\\nels of CNN-based model, SinC-CNN model (CNN architec-\\nture in SinC-CNN model reused from CNN-based model),\\nRNN-based model, and C-RNN-based model are evaluated\\nwith the detailed configuration in Table VIII. The Sinc-CNN\\nmodel proves powerful for raw audio input and has been\\nwidely used as the survey in Section IV Meanwhile, CNN-\\nbased models are commonly used and effectively capture\\nand learn spectral features. We also use RNNs to focus on\\ndetecting natural sequential patterns that can be disrupted in\\nsynthetic audio [200] (e.g., temporal coherence, prosodic fea-\\ntures such as rhythm, stress, and intonation). Consequently,\\nbased on the idea of combining both spectral features and\\ntemporal features, we use C-RNN-based model to distinguish\\ncharacteristics of real and fake audio utterances.\\nWith the transfer learning approach, a wide range of\\nbenchmark network architectures in the computer vision\\ndomain are evaluated. These networks are ResNet-18,\\nMobileNet-V3, EfficientNet-B0, DenseNet-121, SuffleNet-\\nV2, Swint, Convnext-Tiny, GoogLeNet, MNASnet, RegNet,\\nwhich were trained on the ImageNet1K dataset [201] in\\nadvance. Given the pre-trained networks, trainable weights,\\nwhich capture rich and generalized features of pattern recog-\\nnition in images,have the potential to adapt patterns in\\nspectrograms by the fine-tuning process. To adapt the DSD\\ntask, we modify the final dense layer of these mentioned\\nnetworks to be compatible with the binary classification task.\\nFor the audio-embedding deep learning approach, the\\nstate-of-the-art audio pre-trained models of Whisper [150],\\nSeamless [202], Speechbrain [203], and Pyanote [204], [205]\\nare leveraged.\\nIn particular, we feed the spectrogram inputs into these\\npre-trained models to obtain audio embeddings. Given the\\naudio embeddings, We then propose a Multilayer Perceptron\\n(MLP) to classify the audio embeddings into fake or real\\nclasses. The proposed MLP is shown in Table IX, to detect\\nreal or fake audio.\\nEnsemble method: As we train individual model works\\nwith two-second audio segment, the result on an entire audio\\nrecording is computed by averaging of results over all two-\\nsecond segments. Let consider p(n) = [p(n)\\n1 , p(n)\\n2 , ..., p(n)\\nC ],\\nwhere C is the category number of the n-th out of N two-\\nsecond segments, as the predicted probability of one two-\\nsecond segment. The predicted probability of an entire audio\\nrecording, as described by ¯p = [¯p1, ¯p2, ..., ¯pC], is computed\\nby:\\n¯pc = 1\\nN\\nN\\nX\\nn=1\\np(n)\\nc\\nfor 1 ≤c ≤C\\n(1)\\nGiven the predicted probabilities from individual models,\\nwe propose a MEAN fusion for an ensemble of multiple\\nmodels. Let consider the predicted probability of one model\\nas ˆps = (¯ps1, ¯ps2, ..., ¯psC), where C is the category number\\nand the s-th out of S individual models. Next, the predicted\\nprobability after MEAN fusion (ˆp1, ˆp2, ..., ˆpC) is obtained\\nby:\\nˆpc = 1\\nS\\nS\\nX\\ns=1\\nˆpsc\\nfor 1 ≤c ≤C\\n(2)\\nFinally, the predicted label ˆy for an entire audio sample is\\ncomputed by:\\nTABLE IX\\nTHE AUDIO PRE-TRAINED MODELS AND THE MULTILAYER PERCEPTRON\\nModels\\nUsing License\\nEmbedding size/\\nConfiguration\\nWhisper [150]\\nMIT\\n512\\nSpeechBrain [203]\\nApache2-0\\n192\\nSeamLess [202]\\nMIT\\n1024\\nPyannote [204], [205]\\nMIT\\n512\\nMLP\\nOur proposal\\n1 × {Dense(128)-ReLU }\\n1 × {Dense(2)-Softmax }\\nˆy = argmax(ˆp1, ˆp2, ..., ˆpC)\\n(3)\\nD. Experimental results and discussion\\nEvaluation of data augmentation methods: Considering\\nthe performance of online and offline data augmentation\\nmethods as shown in systems A1 (no data augmentation),\\nA2 (online data augmentation with codec), A3 (offline data\\naugmentation with Mixup and SpecAugment), and A4 (both\\nonline and offline data augmentation), it can be seen that the\\noffline data augmentations of Mixup and SpecAugment are\\nappropriate for DSD task. Notably, the combination of online\\nand offline data augmentations does not help to enhance the\\nDSD task performance compared with only using online data\\naugmentation.\\nEvaluation of input features: Considering the efficacy of\\nraw audio and six types of spectrograms in systems from B1\\nto B7, STFT outperforms the raw audio and other spectro-\\ngrams. Models B2, B5, and B7 achieve the best ERR score\\nof 0.08 while the combination of STFT & LF obtains slightly\\nbetter accuracy and F1 score of 0.88 and 0.9, respectively.\\nThis indicates that STFT and applying filters such as Linear\\nFilter or Gammatone filter are suitable for isolating specific\\nfrequency bands in classification algorithms.\\nMultiple deep learning approaches: Regarding the end-\\nto-end deep learning approach from A1 to C2, CNN systems\\noutperform RNN or C-RNN systems. Indeed, using the same\\ninput feature of STFT+LFCC, RNN and C-RNN approaches\\n(C1 and C2 systems) obtain ERR scores of 0.14 and 0.17,\\nwhich is significantly worse than CNN system (A3 or B2\\nor B7) with the best score of 0.08. This indicates that the\\nspecific patterns indicative of deepfake audio might not be\\nprimarily temporal but rather frequency in the spectrogram\\nrepresentation. Regarding the finetuning approach (D1 to\\nD10), Convnext-Tiny stands out as the best system with com-\\npetitive EER scores of 0.075. Meanwhile, the embedding-\\nbased approach (E1 to E4) achieves the best EER scores of\\n0.10 from the pre-trained Whisper model. This suggests the\\npotential of these approaches when choosing the appropriate\\nnetworks for enhancement.\\nEnsembles: Given the performance of individual input\\nfeatures and network architecture, we conduct extensive\\nexperiments to evaluate a wide range of ensemble models.\\nFirst, ensembles of STFT, CQT, and WT spectrograms are\\nevaluated, indicating the best EER score of 0.06 from the\\ncombination of STFT and CQT (B2+B3). Then, ensembles\\nof spectrogram with different filter banks (MEL, LF, GAM)\\nare also evaluated, resulting in the best score of 0.065\\nTABLE X\\nPERFORMANCE COMPARISON AMONG DEEP LEARNING MODELS AND ENSEMBLE OF HIGH-PERFORMANCE MODELS\\nON LOGIC ACCESS EVALUATION SUBSET IN ASVSPOOFING 2019\\nSystems\\nInputs\\nAugmentations\\nModels\\nAcc\\nF1\\nAUC\\nERR\\nA1\\nSTFT & LF\\nNone\\nCNN\\n0.82\\n0.84\\n0.91\\n0.15\\nA2\\nSTFT & LF\\nCodec\\nCNN\\n0.81\\n0.84\\n0.93\\n0.13\\nA3\\nSTFT & LF\\nMixup, Spec.\\nCNN\\n0.88\\n0.90\\n0.96\\n0.08\\nA4\\nSTFT & LF\\nCodec, Mixup, Spec.\\nCNN\\n0.81\\n0.84\\n0.93\\n0.13\\nB1\\nRaw Audio\\nNone\\nSinC-CNN\\n0.84\\n0.87\\n0.96\\n0.10\\nB2\\nSTFT\\nMixup, Spec.\\nCNN\\n0.87\\n0.89\\n0.96\\n0.08\\nB3\\nCQT\\nMixup, Spec.\\nCNN\\n0.89\\n0.90\\n0.92\\n0.14\\nB4\\nWT\\nMixup, Spec.\\nCNN\\n0.84\\n0.86\\n0.89\\n0.17\\nB5\\nSTFT & LF\\nMixup, Spec.\\nCNN\\n0.88\\n0.90\\n0.96\\n0.08\\nB6\\nSTFT & MEL\\nMixup, Spec.\\nCNN\\n0.86\\n0.88\\n0.95\\n0.11\\nB7\\nSTFT & GAM\\nMixup, Spec.\\nCNN\\n0.85\\n0.87\\n0.96\\n0.08\\nC1\\nSTFT & LF\\nMixup, Spec.\\nRNN\\n0.92\\n0.91\\n0.88\\n0.17\\nC2\\nSTFT & LF\\nMixup, Spec.\\nCRNN\\n0.88\\n0.90\\n0.96\\n0.14\\nD1\\nSTFT & LF\\nMixup, Spec.\\nResNet-18\\n0.49\\n0.58\\n0.51\\n0.47\\nD2\\nSTFT & LF\\nMixup, Spec.\\nMobileNet-V3\\n0.59\\n0.67\\n0.52\\n0.48\\nD3\\nSTFT & LF\\nMixup, Spec.\\nEfficientNet-B0\\n0.52\\n0.61\\n0.51\\n0.48\\nD4\\nSTFT & LF\\nMixup, Spec.\\nDenseNet-121\\n0.58\\n0.66\\n0.51\\n0.48\\nD5\\nSTFT & LF\\nMixup, Spec.\\nShuffleNet-V2\\n0.64\\n0.71\\n0.53\\n0.48\\nD6\\nSTFT & LF\\nMixup, Spec.\\nSwin T\\n0.84\\n0.87\\n0.94\\n0.09\\nD7\\nSTFT & LF\\nMixup, Spec.\\nConvNeXt-Tiny\\n0.88\\n0.90\\n0.96\\n0.075\\nD8\\nSTFT & LF\\nMixup, Spec.\\nGoogLeNet\\n0.53\\n0.62\\n0.51\\n0.47\\nD9\\nSTFT & LF\\nMixup, Spec.\\nMNASNet\\n0.62\\n0.70\\n0.54\\n0.47\\nD10\\nSTFT & LF\\nMixup, Spec.\\nRegNet\\n0.50\\n0.60\\n0.50\\n0.48\\nE1\\nRaw Audio\\nNone\\nWhisper+MLP\\n0.85\\n0.88\\n0.95\\n0.10\\nE2\\nRaw Audio\\nNone\\nSpeechbrain+MLP\\n0.77\\n0.81\\n0.81\\n0.25\\nE3\\nRaw Audio\\nNone\\nSeamless+MLP\\n0.86\\n0.88\\n0.87\\n0.20\\nE4\\nRaw Audio\\nNone\\nPyannote+MLP\\n0.64\\n0.71\\n0.78\\n0.27\\nB2 + B3\\nSTFT, CQT\\nMixup, Spec.\\nCNN\\n0.91\\n0.92\\n0.98\\n0.06\\nB2 + B4\\nSTFT, WT\\nMixup, Spec.\\nCNN\\n0.88\\n0.90\\n0.96\\n0.09\\nB2 + B3 + B4\\nSTFT, CQT, WT\\nMixup, Spec.\\nCNN\\n0.90\\n0.92\\n0.98\\n0.07\\nB5 + B6\\nSTFT&LF, STFT&MEL\\nMixup, Spec.\\nCNN\\n0.88\\n0.90\\n0.97\\n0.08\\nB5 + B7\\nSTFT&LF, STFT&GAM\\nMixup, Spec.\\nCNN\\n0.87\\n0.89\\n0.98\\n0.065\\nB5 + B6 + B7\\nSTFT& LF, STFT&MEL, STFT&GAM\\nMixup, Spec.\\nCNN\\n0.88\\n0.90\\n0.98\\n0.069\\nB5 + D6\\nSTFT&LF\\nMixup, Spec.\\nCNN, Swint T\\n0.87\\n0.89\\n0.96\\n0.078\\nB5 + D7\\nSTFT&LF\\nMixup, Spec.\\nCNN, ConvNeXt-Tiny\\n0.88\\n0.90\\n0.97\\n0.07\\nB5 + D6 + D7\\nSTFT&LF\\nMixup, Spec.\\nCNN, ConvNeXt-Tiny, Swint T\\n0.88\\n0.89\\n0.97\\n0.072\\nB3 + B5 + B7\\nCQT, STFT&LF, STFT&GAM\\nMixup, Spec.\\nCNN\\n0.88\\n0.90\\n0.98\\n0.05\\nD7 + E1\\nRaw Audio, STFT&LF\\nMixup, Spec.\\nWhisper, ConvNeXt-Tiny\\n0.86\\n0.88\\n0.99\\n0.03\\nfrom STFT+LF and STFT+GAM (B5+B7). As a result,\\nwhen an ensemble of CQT, STFT+LF, and STFT+GAM is\\nconducted (B3+B5+B7), we can achieve the EER score of\\n0.05. Regarding the ensemble of network architecture, CNN\\nand ConvNeXt-Tiny (B5+D7) help obtain the EER score\\nof 0.07. Meanwhile, the combination of Whisper+MLP and\\nConvNeXt-Tiny (E1+D7) achieves the best EER score of\\n0.03. These results obtained from ensemble models lead to\\nsome conclusions:\\n• Ensembling different input features or network archi-\\ntectures can significantly help to enhance the DSD task\\nperformance.\\n• Not all network architectures are appropriate for the\\nDSD task. As the good performance obtained from\\nConvNeXt-Tiny, the depthwise convolution layer in this\\nnetwork architecture needs to be further investigated.\\n• Leveraging pre-trained models such as Whisper shows\\neffectiveness.\\nThis\\nagain\\nproves\\nwhy\\nthe\\nrecent\\nEncoder-Decoder\\nnetwork\\narchitectures\\nusing\\npre-\\ntrained models for the Encoder have been proposed\\npopularly.\\nVI. OPEN CHALLENGES AND POTENTIAL RESEARCH\\nDIRECTIONS\\nA. Datasets for Deepfake Speech Detection\\n1) Open challenges: Building better datasets for audio\\ndeepfake detection is essential for improving the accuracy\\nand robustness of detection systems. However, the current\\ndiversity of available datasets for audio deepfake detection\\nremains limited, especially in terms of speaker identity,\\nlanguage, and deepfake generation methods.\\nA large number of published datasets feature a narrow\\nrange of speaker identities, often focusing on a small group\\nof speakers with limited gender, age, and accent diversity.\\nFor instance, datasets of ASVspoof and FakeAVCeleb in-\\nclude mainly English-speaking voices from certain groups\\nof speakers (e.g., celebrity, predominantly synthesized voice)\\nwith a small number of speakers from different language\\nbackgrounds, resulting in biased models when applied to\\ndiverse populations.\\nMany existing datasets are domain-specific, focusing\\non particular types of audio or speakers. For example,\\nFakeAVCeleb primarily includes celebrity interviews, while\\nLibriSpeech focuses on read recordings. These datasets often\\nhave limited variability in terms of recording conditions,\\nspeaker interactions, and speech styles, making it difficult\\nto generalize detection models to new domains or unseen\\nenvironments, such as detecting deepfakes in real-world\\nscenarios with noisy or degraded audio, such as phone calls,\\npublic spaces, or online content.\\nThe lack of language diversity is also a significant issue\\nthat limits the robustness of detection models. As shown at\\nTable III, most existing datasets support single languages\\n(primarily English or Chinese). This imbalance raises chal-\\nlenges that hinder the development of robust, audio deepfake\\ndetection systems in multilingual settings.\\nAs deepfake generation techniques have been evolving\\nrapidly, they produce fake audio that is increasingly difficult\\nto detect. This makes it difficult for existing datasets to stay\\nup to date as they may be vulnerable to newer methods of\\naudio synthesis. Therefore, datasets must be continuously\\nupdated to include samples produced by new techniques to\\nensure the robustness and adaptability of detection models.\\n2) Future directions: Given the open challenges discussed\\nin the previous subsection, we highlight some potential\\nfuture directions in dataset development for Deepfake Speech\\nDetection:\\nMultilingual and Multimodal Datasets: To address the\\nissue of language diversity, future datasets should include\\na broader range of languages, accents, and dialects. This\\nvariety will enable detection models to better handle diverse\\nlinguistic and phonetic features across different languages,\\nensuring their stability in multilingual contexts and their\\neffectiveness in developing global solutions.\\nMoreover, deepfake content in real-world scenarios often\\nincludes both audio and video elements, rather than just au-\\ndio. Therefore, integrating multimodal datasets that combine\\nboth audio and video deepfakes is a crucial direction for\\nfuture research. This integration enhances detection capabil-\\nities by allowing models to identify anomalies across mul-\\ntiple data types, improving their effectiveness in combating\\nincreasingly sophisticated forgeries\\nContinuous Dataset Updates: To stay updated, there\\nneeds to be ongoing collaboration between researchers de-\\nveloping deepfake generation methods and those working on\\nthe DSD task. Regular updates to datasets should include\\ndeepfake samples created by the latest synthesized generation\\ntechniques, allowing detection models to adapt to emerging\\nthreats.\\nCross-Domain and Real-World Dataset Adaptation:\\nOne of the biggest challenges for DSD models is domain\\nadaptation — the ability to generalize across different types\\nof audio environments, speakers, and use cases. Future\\ndatasets should prioritize cross-domain generalization, in-\\ncluding diverse data from various contexts (e.g., podcasts,\\nphone calls, interviews, public speeches, and social media\\ncontent). In addition, besides varied deepfake generation\\nmethods, future dataset development should include data\\nfrom diverse online platforms (e.g., YouTube, TikTok, pod-\\ncasts) and various speaker demographics that stimulate in-\\nclusive real-life scenarios.\\nB. The generalization and robustness of Deepfake Speech\\nDetection models\\n1) Open challenges: A major challenge in developing\\ndeepfake detection systems is ensuring they can generalize\\nto new samples that are not presented in the training data.\\nWhile models may perform well on known attacks, they\\noften struggle with novel manipulations and across different\\ndomains, such as varying languages, accents, or speaking\\nstyles. The limited size and diversity of training datasets\\nhinder DSD models’ ability to handle real-world variability\\nwithout degraded performance. Some approaches have been\\nadopted to address these challenges. For example, ensemble\\nmodels, as discussed in Sections II and IV, have been\\neffectively utilized to enhance DSD performance and gener-\\nalization ability, often achieving top results in competition\\nsettings. They are also frequently employed in research\\npapers to deliver competitive outcomes [129], [145], [127].\\nWhile ensemble models are powerful and versatile, they\\noften require significant computational costs during train-\\ning. Additionally, detection systems leveraging pre-trained\\nmodels have gained popularity [172]. By fine-tuning models\\npre-trained on upstream audio tasks like speech-to-text [139],\\n[150], the training cost for DSD downstream tasks is greatly\\nreduced. However, proving the generalization of these fine-\\ntuned single models remains challenging. For instance, ex-\\nperiments on ASVspoof 2021 (DF Task) in [172] achieved\\nremarkable results, with an EER of 5.67 compared to 15.64\\nfrom the top-performing system in the challenge. In contrast,\\nthe performance on the ASVspoof 2021 (LA Task) was much\\nlower, with an EER of 15.92, compared to 1.32 from the top-\\nperforming system.\\nIn terms of improving the model’s robustness to adver-\\nsarial attacks, the majority of current methods for defending\\nagainst adversarial attacks rely on adversarial training [9],\\nwhich involves generating adversarial examples from known\\nattacks to retrain the model. However, this approach incurs\\nhigh computational costs.\\n2) Future directions: To improve the generalization and\\nrobustness of detection systems, there has been much room\\nfor improving existing approaches as well as proposing\\nnew methods. For example, future directions can address\\nchallenges in ensemble methods by balancing the trade-off\\nbetween cost and effectiveness using techniques such as\\npruning, quantization, and knowledge distillation or other\\nefficient ensembling strategies to reduce model size. In the\\napproach using transfer learning or fine-tuning, employing\\nseveral strategies such as cross-dataset validation or an\\nensemble of fine-tuned models could address the challenges\\nof proving generalization. Applying mechanisms to learn in-\\nformation from domain-invariant attacks could also enhance\\nthe robustness of models against different adversarial attacks.\\nC. Interpretability and Explainable AI (XAI) for Deepfake\\nSpeech Detection\\n1) Open challenges: Improving interpretability and ex-\\nplainability in Deepfake Speech Detection remains a complex\\ntask due to the unique challenges posed by audio data and\\nthe black-box nature of deep learning methods. Although\\nvarious explainable AI (XAI) techniques prove effectiveness\\nin interpreting deep-learning-based models, applying XAI\\nto DSD systems has not drawn much attention from the\\nresearch community. Indeed, only some recently published\\npapers [206], [207], [208], [209], [210] address the role of\\nXAI, which mainly focus on the visualization-based XAI\\nmethods. For example, the conventional SHapley Additive\\nexPlanations (SHAP) [211] and Local Interpretable Model-\\nagnostic Explanations (LIME) [212] methods were used to\\ninterpret the feature contribution in [207], [209] and in [208],\\nrespectively. Authors in [206] applied Saliency Map [213]\\nand Smooth Grad [214] techniques to visualize how their\\nmodel processes audio in the frequency domain. Similarly,\\nlayer-wise relevance propagation (LRP), a visualization-\\nbased XAI method, was leveraged in [210] to indicate the\\ndifference of formants among fake and real audio utterances.\\nWhile more deep-learning-based models have been proposed\\nto solve the DSD task, not many research papers focus on\\nexploring XAI methods to interpret DSD systems.\\n2) Future directions: Based on the above discussion, there\\nis much room for applying XAI to improve transparency\\nand trustworthiness within detection systems. Additionally,\\nleveraging visualization tools for visualizing audio features\\nor feature maps could also provide user-friendly platforms\\nand valuable insights into the underlying decision-making\\nprocess of detection models.\\nD. Real-time deepfake speech detection\\n1) Open challenges: Integrating DSD systems into real-\\nworld applications still presents several challenges. Key fac-\\ntors include the length of the audio utterance, the complexity\\nof the model (e.g., the number of trainable parameters), com-\\nputational costs (e.g., FLOPs), and the target edge devices\\n(e.g., mobile phones, embedded systems, high-performance\\ncomputers). These factors directly affect inference time and\\nare carefully analyzed to ensure effective implementation.\\nFor example, the trade-off between the performance and the\\nmodel complexity was comprehensively analyzed in [196]\\nand [215] concerning Acoustic Scene Classification (ASC)\\ntask and Acoustic Event Detection (AED) task, respectively.\\nCurrently, most proposed DSD systems have been currently\\nevaluated on high-performance computers with the advance\\nof powerful GPUs without any computational constraints,\\nwhile there is little research on real-time deepfake detection.\\nSeveral studies, such as [216] and [217], have proposed\\nreal-time deepfake audio detection systems. However, these\\nsystems often face significant limitations, such as being\\napplicable to only a limited range of deepfake creation\\ntechniques (voice conversion) or domains (communication).\\nThese challenges highlight the need for further exploration\\nand analysis of real-time DSD systems in future research.\\n2) Future directions: Future directions in developing real-\\ntime audio deepfake detection systems could rely on better\\nhandling the trade-off between model complexity and per-\\nformance, facilitating model implementation in low-latency\\nconditions. Some techniques such as quantization and prun-\\ning can be used to reduce model size, while other methods\\nleverage edge computing or distributed computing to reduce\\ninference time and handle large-scale data more efficiently.\\nE. Ethical and legal considerations\\n1) Open challenges: Training audio deepfake detection\\nmodels requires large datasets, which may involve the collec-\\ntion and the use of personal voice recordings. For example,\\nVoxCeleb and FakeAVCeleb corpora contain speech from\\nthousands of celebrities in various environments. Personal\\ndata handling raises threats of privacy and consent. Further-\\nmore, there is also a risk of dual-use dilemma when some bad\\nactors could manipulate detection technology and available\\nindividuals’s speech for harmful purposes such as reinforcing\\ndisinformation narratives, defamation, and fraud, infringing\\non individuals’ privacy rights.\\n2) Future directions: Future directions in addressing eth-\\nical and legal considerations for developing audio deepfake\\ntechnologies focus on enhancing data privacy protection, fair-\\nness, and facilitating global regulatory frameworks. Develop-\\ners will increasingly incorporate privacy-by-design principles\\nin developing detection systems, ensuring that personal voice\\ndata is handled securely and with consent, minimizing the\\nrisk of misuse. Within DSD applications, access control\\nmechanisms should be implemented to limit certain groups\\nof people and the frequency of using detection technologies,\\nreducing the potential risk of misuse by malicious actors.\\nIn terms of legal perspectives, legal frameworks may also\\nevolve to introduce stricter penalties for misuse of both\\ndeepfake creation and detection technology.\\nF. The race between Deepfake Speech Generation and De-\\ntection\\n1) Open challenges:: As mentioned and discussed in\\nSection III, there is a tight relationship between Deepfake\\nSpeech Generation and Deepfake Speech Detection tasks.\\nDeepfake Speech Generation systems (e.g., VC, TTS, and AT\\nmodels) have been becoming more powerful and accessible,\\nenabling the creation of hyper-realistic fake utterances that\\nmimic normal speech patterns and produce fewer detectable\\nflaws. This makes it hard for DSD systems to distinguish\\nbetween real and manipulated content, presenting challenges\\nto keep pace with these deepfake creation advancements.\\n2) Future directions:: As deepfakes have evolved rapidly,\\ndetection models must also adapt by learning from increas-\\ningly realistic fakes. By facilitating collaborative environ-\\nments, researchers in both Deepfake Speech Generation and\\nDetection can further explore and push boundaries of what\\nis technically possible and ensure that detection methods\\nkeep pace with advances in deepfake generators. For ex-\\nample, ADD 2022 [17], ADD 2023 [24], and ASVspoof\\n2024 [27] challenge competitions were established to en-\\ngage researchers in both Deepfake Speech Generation and\\nDetection. This promotes innovations in addressing the race\\nbetween creating and detecting deepfake, improving the\\nrobustness of detection systems in combating increasingly\\ncomplicated deepfakes.\\nG. The availability of Deepfake Speech Detection tools\\n1) Open challenges: Deepfake speech detection tools still\\nface challenges in increasing their quantity and quality due\\nto the rapid development of deepfake speech generation\\ntechniques. Although DSD systems act as a critical func-\\ntion in Voice over Internet Protocol (VoIP) based platforms\\nsuch as WhatsApp, Facebook, etc. or social media such as\\nYouTube, Twister, etc. for a thread warning, very few VoIP\\nplatforms or social media have announced an available and\\nindependent DSD tool. Regarding non-commercial or com-\\nmercial solutions, only some DSD tools or platforms such\\nas Deepware, WeVerify, TrueMedia, and DeepFake-O-Meter\\nare available as highlighted in the survey [218]. However,\\ninformation on DSD models used in these tools has been\\nnot described in detail except TrueMeida and DeepFake-O-\\nMeter with 3 and 5 systems replicated from published papers.\\nOverall, the sufficiency of deepfake detection applications\\nis primarily due to technical complexity in developing and\\nupdating models, resource demands such as computational\\ncosts and scalability, accuracy concerns, and privacy issues.\\n2) Future directions:: To address the mentioned chal-\\nlenges, future improvements in developing deepfake speech\\ndetection tools could rely on some approaches such as\\nlightweight detection models that can operate on consumer\\ndevices such as smartphones, laptops, or cloud-based ser-\\nvices. To ensure broader adaption, the development of open-\\nsource deepfake detection tools or libraries and established\\nstandards for their use could also be promoted by the collab-\\noration between tech companies and academic institutions,\\nmaking detection tools more accessible and reliable.\\nVII. CONCLUSION\\nThis paper has provided a comprehensive survey for\\nDeepfake Speech Detection (DSD) task by deeply analyz-\\ning the challenge competitions, the public and benchmark\\ndatasets, the main components in a deep-learning-based DSD\\nsystem. From the survey, we indicate exiting concerns and\\nprovide enhance solutions to motivate the research commu-\\nnity for further contribution on this research topic. More\\nthan a survey, we verified the role and the effect of data\\naugmentation, feature extraction, and network architectures\\nGiven the comprehensive survey and extensive experiments,\\nwe indicate potential and promising research directions for\\nDeepfake Speech Detection task.\\nREFERENCES\\n[1] Zahra Khanjani, Gabrielle Watson, and Vandana P Janeja,\\n“How\\ndeep are the fakes? focusing on audio deepfake: A survey,” arXiv\\npreprint arXiv:2111.14203, 2021.\\n[2] Momina Masood, Mariam Nawaz, Khalid Mahmood Malik, Ali\\nJaved, Aun Irtaza, and Hafiz Malik,\\n“Deepfakes generation and\\ndetection: State-of-the-art, open challenges, countermeasures, and\\nway forward,” Applied intelligence, vol. 53, no. 4, pp. 3974–4026,\\n2023.\\n[3] Rami Mubarak, Tariq Alsboui, Omar Alshaikh, Isa Inuwa-Dutse,\\nSaad Khan, and Simon Parkinson, “A survey on the detection and\\nimpacts of deepfakes in visual, audio, and textual formats,” IEEE\\nAccess, vol. 11, pp. 144497–144529, 2023.\\n[4] Yogesh Patel, Sudeep Tanwar, Rajesh Gupta, Pronaya Bhattacharya,\\nInnocent Ewean Davidson, Royi Nyameko, Srinivas Aluvala, and\\nVrince Vimal, “Deepfake generation and detection: Case study and\\nchallenges,” IEEE Access, vol. 11, pp. 143296–143323, 2023.\\n[5] Jiangyan Yi, Chenglong Wang, Jianhua Tao, Xiaohui Zhang,\\nChu Yuan Zhang, and Yan Zhao,\\n“Audio deepfake detection: A\\nsurvey,” arXiv preprint arXiv:2308.14970, 2023.\\n[6] Zahra Khanjani, Gabrielle Watson, and Vandana P Janeja, “Audio\\ndeepfakes: A survey,” Frontiers in Big Data, vol. 5, pp. 1001063,\\n2023.\\n[7] Zahid Akhtar, Thanvi Lahari Pendyala, and Virinchi Sai Athmakuri,\\n“Video and audio deepfake datasets and open issues in deepfake\\ntechnology: Being ahead of the curve,” Forensic Sciences, vol. 4,\\nno. 3, pp. 289–377, 2024.\\n[8] Enes Altuncu, Virginia NL Franqueira, and Shujun Li, “Deepfake:\\ndefinitions, performance metrics and standards, datasets, and a meta-\\nreview,” Frontiers in Big Data, vol. 7, pp. 1400024, 2024.\\n[9] Menglu Li, Yasaman Ahmadiadli, and Xiao-Ping Zhang,\\n“Audio\\nanti-spoofing detection: A survey,” arXiv preprint arXiv:2404.13914,\\n2024.\\n[10] Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, and\\nHong Lin, “Ai-generated content (aigc): A survey,” arXiv preprint\\narXiv:2304.06632, 2023.\\n[11] Burak Yetis¸tiren, Is¸ık ¨Ozsoy, Miray Ayerdem, and Eray T¨uz¨un,\\n“Evaluating the code quality of ai-assisted code generation tools:\\nAn empirical study on github copilot, amazon codewhisperer, and\\nchatgpt,” arXiv preprint arXiv:2304.10778, 2023.\\n[12] Xu Tan, Tao Qin, Frank Soong, and Tie-Yan Liu, “A survey on neural\\nspeech synthesis,” arXiv preprint arXiv:2106.15561, 2021.\\n[13] Berrak Sisman, Junichi Yamagishi, Simon King, and Haizhou Li,\\n“An overview of voice conversion and its challenges: From statistical\\nmodeling to deep learning,”\\nIEEE/ACM Transactions on Audio,\\nSpeech, and Language Processing, vol. 29, pp. 132–157, 2021.\\n[14] Fatima Dakalbab, Manar Abu Talib, Omnia Abu Waraga, Ali Bou\\nNassif, Sohail Abbas, and Qassim Nasir, “Artificial intelligence &\\ncrime prediction: A systematic literature review,” Social Sciences &\\nHumanities Open, vol. 6, no. 1, pp. 100342, 2022.\\n[15] Brian Dolhansky, Joanna Bitton, Ben Pflaum, Jikuo Lu, Russ Howes,\\nMenglin Wang, and Cristian Canton Ferrer, “The deepfake detection\\nchallenge (DFDC) dataset,” arXiv preprint arXiv:2006.07397, 2020.\\n[16] Joel Frank and Lea Sch¨onherr, “Wavefake: A data set to facilitate\\naudio deepfake detection,” NeurIPS, 2024.\\n[17] “Audio deep synthesis detection challenge (ADD 2022),” http://\\naddchallenge.cn/add2022, 2022.\\n[18] “M-ailabs\\nspeech\\ndataset,”\\nhttps://github.com/\\nimdatceleste/m-ailabs-dataset, 2024.\\n[19] You Zhang, Yongyi Zang, Jiatong Shi, Ryuichi Yamamoto, Tomoki\\nToda, and Zhiyao Duan, “SVDD 2024: The inaugural singing voice\\ndeepfake detection challenge,”\\narXiv preprint arXiv:2408.16132,\\n2024.\\n[20] Zhizheng Wu, Tomi Kinnunen, Nicholas Evans, Junichi Yamagishi,\\nCemal Hanilc¸i, Md. Sahidullah, and Aleksandr Sizov,\\n“Asvspoof\\n2015: the first automatic speaker verification spoofing and counter-\\nmeasures challenge,” in Proc. INTERSPEECH, 2015, pp. 2037–2041.\\n[21] Xin Wang, Junichi Yamagishi, Massimiliano Todisco, H´ector Del-\\ngado, Andreas Nautsch, Nicholas Evans, Md Sahidullah, Ville Vest-\\nman, Tomi Kinnunen, Kong Aik Lee, et al.,\\n“Asvspoof 2019: A\\nlarge-scale public database of synthesized, converted and replayed\\nspeech,” Computer Speech & Language, vol. 64, pp. 101114, 2020.\\n[22] “The\\nftc\\nvoice\\ncloning\\nchallenge,”\\nhttps:\\n//www.ftc.gov/news-events/contests/\\nftc-voice-cloning-challenge, 2023.\\n[23] Junichi Yamagishi, Xin Wang, Massimiliano Todisco, Md Sahidullah,\\nJose Patino, Andreas Nautsch, Xuechen Liu, Kong Aik Lee, Tomi\\nKinnunen, Nicholas Evans, et al.,\\n“Asvspoof 2021: accelerating\\nprogress in spoofed and deepfake speech detection,” in Workshop-\\nAutomatic Speaker Verification and Spoofing Coutermeasures Chal-\\nlenge (ASVspoof), 2021.\\n[24] “Audio deep synthesis detection challenge (ADD 2023),” http://\\naddchallenge.cn/add2023, 2023.\\n[25] Zhixi Cai, Shreya Ghosh, Aman Pankaj Adatia, Munawar Hayat,\\nAbhinav Dhall, and Kalin Stefanov,\\n“Av-deepfake1m: A large-\\nscale llm-driven audio-visual deepfake dataset,”\\narXiv preprint\\narXiv:2311.15308, 2023.\\n[26] “1m-deepfakes detection challenge,” https://deepfakes1m.\\ngithub.io/, 2023.\\n[27] “The\\nasvspoof\\n2024\\nchallenge,”\\nhttps://www.asvspoof.\\norg/, 2024.\\n[28] “The singing voice deepfake detection challenge (svdd),” https:\\n//challenge.singfake.org/, 2024.\\n[29] H´ector Delgado, Massimiliano Todisco, Md Sahidullah, Nicholas\\nEvans, Tomi Kinnunen, Kong Aik Lee, and Junichi Yamagishi,\\n“Asvspoof 2017 version 2.0: meta-data analysis and baseline en-\\nhancements,” in The Speaker and Language Recognition Workshop,\\n2018, pp. 296–303.\\n[30] Ricardo Reimao and Vassilios Tzerpos, “For: A dataset for synthetic\\nspeech detection,” in International Conference on Speech Technology\\nand Human-Computer Dialogue, 2019, pp. 1–10.\\n[31] “Audio\\nsource\\nused\\nto\\ngenerate\\nfor\\ndataset,”\\nhttps:\\n//www.kaggle.com/datasets/percevalw/\\nenglishfrench-translations, 2018.\\n[32] Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Nor-\\nman Casagrande, Edward Lockhart, Florian Stimberg, Aaron Oord,\\nSander Dieleman, and Koray Kavukcuoglu, “Efficient neural audio\\nsynthesis,” in Proc. ICML, 2018, pp. 2410–2419.\\n[33] Ryosuke Sonobe, Shinnosuke Takamichi, and Hiroshi Saruwatari,\\n“Jsut corpus: free large-scale japanese speech corpus for end-to-end\\nspeech synthesis,” arXiv preprint arXiv:1711.00354, 2017.\\n[34] Patrick Kwon, Jaeseong You, Gyuhyeon Nam, Sungwoo Park, and\\nGyeongsu Chae,\\n“Kodf: A large-scale korean deepfake detection\\ndataset,” in Proc. IEEE/CVF International Conference on Computer\\nVision, 2021, pp. 10744–10753.\\n[35] Yao Shi, Hui Bu, Xin Xu, Shaoji Zhang, and Ming Li, “Aishell-3: A\\nmulti-speaker mandarin tts corpus,” in Proc. INTERSPEECH, 2021,\\npp. 2756–2760.\\n[36] Hasam Khalid, Shahroz Tariq, Minha Kim, and Simon S Woo,\\n“Fakeavceleb: A novel audio-video multimodal deepfake dataset,”\\nin Thirty-fifth Conference on Neural Information Processing Systems\\nDatasets and Benchmarks Track (Round 2), 2021.\\n[37] Joon Son Chung, Arsha Nagrani, and Andrew Zisserman,\\n“Vox-\\nCeleb2: Deep Speaker Recognition,” in Proc. INTERSPEECH, 2018,\\npp. 1086–1090.\\n[38] Nicolas M¨uller, Pavel Czempin, Franziska Diekmann, Adam Frogh-\\nyar, and Konstantin B¨ottinger,\\n“Does Audio Deepfake Detection\\nGeneralize?,” in Proc. INTERSPEECH, 2022, pp. 2783–2787.\\n[39] Zhixi Cai, Kalin Stefanov, Abhinav Dhall, and Munawar Hayat,\\n“Do you really mean that? content driven audio-visual deepfake\\ndataset and multimodal method for temporal forgery localization,” in\\nInternational Conference on Digital Image Computing: Techniques\\nand Applications, 2022, pp. 1–10.\\n[40] Xin Wang and Junichi Yamagishi, “Spoofed training data for speech\\nspoofing countermeasure can be efficiently created using neural\\nvocoders,” in Proc. ICASSP, 2023, pp. 1–5.\\n[41] Lin Zhang, Xin Wang, Erica Cooper, Nicholas Evans, and Junichi\\nYamagishi, “The partialspoof database and countermeasures for the\\ndetection of short fake speech segments embedded in an utterance,”\\nIEEE/ACM Transactions on Audio, Speech, and Language Process-\\ning, vol. 31, pp. 813–825, 2022.\\n[42] Chengzhe Sun, Shan Jia, Shuwei Hou, and Siwei Lyu,\\n“Ai-\\nsynthesized voice detection using neural vocoder artifacts,” in Proc.\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\\n2023, pp. 904–912.\\n[43] Haoxin Ma, Jiangyan Yi, Chenglong Wang, Xinrui Yan, Jianhua Tao,\\nTao Wang, Shiming Wang, and Ruibo Fu, “CFAD: A chinese dataset\\nfor fake audio detection,”\\nSpeech Communication, vol. 164, pp.\\n103122, 2024.\\n[44] Hui Bu, Jiayu Du, Xingyu Na, Bengu Wu, and Hao Zheng,\\n“AISHELL-1: An open-source mandarin speech corpus and a speech\\nrecognition baseline.,” in Proc. O-COCOSDA, 2017, pp. 1–5.\\n[45] Yao Shi, Hui Bu, Xin Xu, Shaoji Zhang, and Ming Li, “Aishell-3: A\\nmulti-speaker mandarin tts corpus,” in Proc. INTERSPEECH, 2021,\\npp. 2756–2760.\\n[46] Zehui Yang, Yifan Chen, Lei Luo, Runyan Yang, Lingxuan Ye,\\nGaofeng Cheng, Ji Xu, Yaohui Jin, Qingqing Zhang, Pengyuan\\nZhang, Lei Xie, and Yonghong Yan,\\n“Open source MagicData-\\nRAMC: A rich annotated mandarin conversational(RAMC) speech\\ndataset,” in Proc. INTERSPEECH, 2022, pp. 1736–1740.\\n[47] Nicolas M M¨uller, Piotr Kawa, Wei Herng Choong, Edresson\\nCasanova, Eren G¨olge, Thorsten M¨uller, Piotr Syga, Philip Sperl,\\nand Konstantin B¨ottinger, “Mlaad: The multi-language audio anti-\\nspoofing dataset,” International Joint Conference on Neural Networks\\n(IJCNN), 2024.\\n[48] Vineel Pratap, Qiantong Xu, Anuroop Sriram, Gabriel Synnaeve, and\\nRonan Collobert,\\n“MLS: A Large-Scale Multilingual Dataset for\\nSpeech Research,” in Proc. INTERSPEECH, 2020, pp. 2757–2761.\\n[49] “DCASE\\n2022\\nchallenge\\ncompetition\\nTask\\n1A,”\\nhttps://dcase.community/challenge2022/\\ntask-low-complexity-acoustic-scene-classification,\\n2022.\\n[50] Ran Yi, Zipeng Ye, Juyong Zhang, Hujun Bao, and Yong-Jin Liu,\\n“Audio-driven talking face video generation with learning-based\\npersonalized head pose,” arXiv preprint arXiv:2002.10137, 2020.\\n[51] Thierry Dutoit, Andre Holzapfel, Matthieu Jottrand, Alexis Moinet,\\nJavier Perez, and Yannis Stylianou,\\n“Towards a voice conversion\\nsystem based on frame selection,” in Proc. ICASSP, 2007, vol. 4,\\npp. IV–513.\\n[52] Zhizheng Wu, Tuomas Virtanen, Tomi Kinnunen, Engsiong Chng,\\nand Haizhou Li, “Exemplar-based unit selection for voice conversion\\nutilizing temporal information.,” in Proc. INTERSPEECH, 2013, pp.\\n3057–3061.\\n[53] Toshiaki Fukuda, “An adaptive algorithm for mel-cepstral analysis\\nof speech,” in Proc. ICASSP, 1992, pp. 137–140.\\n[54] Junichi Yamagishi, Takao Kobayashi, Yuji Nakano, Katsumi Ogata,\\nand Juri Isogai,\\n“Analysis of speaker adaptation algorithms for\\nhmm-based speech synthesis and a constrained smaplr adaptation\\nalgorithm,”\\nIEEE Transactions on Audio, Speech, and Language\\nProcessing, vol. 17, no. 1, pp. 66–83, 2009.\\n[55] “Festvox voice conversion system,” http://www.festvox.org,\\n2024.\\n[56] Tomoki Toda, Alan W Black, and Keiichi Tokuda, “Voice conver-\\nsion based on maximum-likelihood estimation of spectral parameter\\ntrajectory,”\\nIEEE Transactions on Audio, Speech, and Language\\nProcessing, vol. 15, no. 8, pp. 2222–2235, 2007.\\n[57] Daisuke Saito, Keisuke Yamamoto, Nobuaki Minematsu, and Kei-\\nkichi Hirose,\\n“One-to-many voice conversion based on tensor\\nrepresentation of speaker space,”\\nin Proc. INTERSPEECH, 2011,\\npp. 653–656.\\n[58] Elina Helander, Hanna Sil´en, Tuomas Virtanen, and Moncef Gabbouj,\\n“Voice conversion using dynamic kernel partial least squares regres-\\nsion,” IEEE transactions on audio, speech, and language processing,\\nvol. 20, no. 3, pp. 806–817, 2011.\\n[59] “Marytts speech synthesis system,” http://mary.dfki.de,\\n2024.\\n[60] “Hts working group, the english tts system flite+hts engine,” http:\\n//hts-engine.sourceforge.net/, 2014.\\n[61] Masanori Morise, Fumiya Yokomori, and Kenji Ozawa,\\n“World:\\na vocoder-based high-quality speech synthesis system for real-time\\napplications,” IEICE Transactions on Information and Systems, vol.\\n99, no. 7, pp. 1877–1884, 2016.\\n[62] Zhizheng Wu, Oliver Watts, and Simon King,\\n“Merlin: An open\\nsource neural network speech synthesis system,” in Speech Synthesis\\nWorkshop, 2016, pp. 202–207.\\n[63] Marc Schr¨oder, Marcela Charfuelan, Sathish Pammi, and Ingmar\\nSteiner,\\n“Open source voice creation toolkit for the mary tts\\nplatform,” in Proc. INTERSPEECH, 2011, pp. 3253–3256.\\n[64] Chin-Cheng Hsu, Hsin-Te Hwang, Yi-Chiao Wu, Yu Tsao, and Hsin-\\nMin Wang,\\n“Voice conversion from non-parallel corpora using\\nvariational auto-encoder,” in Proc. APSIPA, 2016, pp. 1–6.\\n[65] Driss Matrouf, J-F Bonastre, and Corinne Fredouille,\\n“Effect of\\nspeech transformation on impostor acceptance,” in Proc. ICASSP,\\n2006, vol. 1, pp. I–I.\\n[66] Kou Tanaka, Hirokazu Kameoka, Takuhiro Kaneko, and Nobukatsu\\nHojo, “Wavecyclegan2: Time-domain neural post-filter for speech\\nwaveform generation,” arXiv preprint arXiv:1904.02892, 2019.\\n[67] Xin Wang, Shinji Takaki, and Junichi Yamagishi, “Neural source-\\nfilter-based waveform model for statistical parametric speech synthe-\\nsis,” in Proc. ICASSP, 2019, pp. 5916–5920.\\n[68] Heiga Zen, Yannis Agiomyrgiannakis, Niels Egberts, Fergus Hender-\\nson, and Przemysław Szczepaniak, “Fast, compact, and high quality\\nlstm-rnn based statistical parametric speech synthesizers for mobile\\ndevices,” in Proc. INTERSPEECH, 2016, pp. 2273–2277.\\n[69] Yannis Agiomyrgiannakis, “Vocaine the vocoder and applications in\\nspeech synthesis,” in Proc. ICASSP, 2015, pp. 4230–4234.\\n[70] Li Wan, Quan Wang, Alan Papir, and Ignacio Lopez Moreno,\\n“Generalized end-to-end loss for speaker verification,”\\nin Proc.\\nICASSP, 2018, pp. 4879–4883.\\n[71] Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Nor-\\nman Casagrande, Edward Lockhart, Florian Stimberg, Aaron Oord,\\nSander Dieleman, and Koray Kavukcuoglu, “Efficient neural audio\\nsynthesis,” in Proc. ICML, 2018, pp. 2410–2419.\\n[72] Daniel Griffin and Jae Lim, “Signal estimation from modified short-\\ntime fourier transform,” IEEE Transactions on acoustics, speech, and\\nsignal processing, vol. 32, no. 2, pp. 236–243, 1984.\\n[73] A¨aron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan,\\nOriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and\\nKoray Kavukcuoglu,\\n“WaveNet: A Generative Model for Raw\\nAudio,” in Proc. Workshop on Speech Synthesis, 2016, p. 125.\\n[74] “Voicetext,”\\nhttp://dws2.voicetext.jp/tomcat/\\ndemonstration/top.html, 2024.\\n[75] Li-Juan Liu, Zhen-Hua Ling, Yuan Jiang, Ming Zhou, and Li-\\nRong Dai, “Wavenet vocoder with limited training data for voice\\nconversion.,” in Proc. INTERSPEECH, 2018, pp. 1983–1987.\\n[76] Hideki Kawahara, Ikuyo Masuda-Katsuse, and Alain De Cheveigne,\\n“Restructuring speech representations using a pitch-adaptive time–\\nfrequency smoothing and an instantaneous-frequency-based f0 ex-\\ntraction: Possible role of a repetitive structure in sounds,” Speech\\ncommunication, vol. 27, no. 3-4, pp. 187–207, 1999.\\n[77] Kazuhiro Kobayashi, Tomoki Toda, and Satoshi Nakamura, “Intra-\\ngender statistical singing voice conversion with direct waveform\\nmodification using log-spectral differential,” Speech communication,\\nvol. 99, pp. 211–220, 2018.\\n[78] Wen-Chin Huang, Yi-Chiao Wu, Kazuhiro Kobayashi, Yu-Huai Peng,\\nHsin-Te Hwang, Patrick Lumban Tobing, Yu Tsao, Hsin-Min Wang,\\nand Tomoki Toda, “Generalization of spectrum differential based di-\\nrect waveform modification for voice conversion,” in Proc. Workshop\\non Speech Synthesis, 2019, pp. 57–62.\\n[79] Najim Dehak, Patrick J Kenny, R´eda Dehak, Pierre Dumouchel, and\\nPierre Ouellet, “Front-end factor analysis for speaker verification,”\\nIEEE Transactions on Audio, Speech, and Language Processing, vol.\\n19, no. 4, pp. 788–798, 2010.\\n[80] Patrick Kenny, “A small footprint i-vector extractor.,” in Odyssey,\\n2012, vol. 2012, pp. 1–6.\\n[81] Simon JD Prince and James H Elder,\\n“Probabilistic linear dis-\\ncriminant analysis for inferences about identity,”\\nin Proc. IEEE\\ninternational conference on computer vision, 2007, pp. 1–8.\\n[82] Adam Polyak, Lior Wolf, and Yaniv Taigman, “TTS Skins: Speaker\\nConversion via ASR,” in Proc. INTERSPEECH, 2020, pp. 786–790.\\n[83] KR Prajwal, Rudrabha Mukhopadhyay, Vinay P Namboodiri, and\\nCV Jawahar, “A lip sync expert is all you need for speech to lip\\ngeneration in the wild,” in Proceedings of the 28th ACM international\\nconference on multimedia, 2020, pp. 484–492.\\n[84] Xuechen Liu, Xin Wang, Md Sahidullah, Jose Patino, H´ector Del-\\ngado, Tomi Kinnunen, Massimiliano Todisco, Junichi Yamagishi,\\nNicholas Evans, Andreas Nautsch, and Kong Aik Lee, “Asvspoof\\n2021: Towards spoofed and deepfake speech detection in the wild,”\\nIEEE/ACM Transactions on Audio, Speech, and Language Process-\\ning, vol. 31, pp. 2507–2522, 2023.\\n[85] Kundan Kumar, Rithesh Kumar, Thibault De Boissiere, Lucas Gestin,\\nWei Zhen Teoh, Jose Sotelo, Alexandre De Brebisson, Yoshua\\nBengio, and Aaron C Courville,\\n“Melgan: Generative adversarial\\nnetworks for conditional waveform synthesis,” Advances in neural\\ninformation processing systems, vol. 32, 2019.\\n[86] Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae, “Hifi-gan: Gen-\\nerative adversarial networks for efficient and high fidelity speech\\nsynthesis,” Advances in neural information processing systems, vol.\\n33, pp. 17022–17033, 2020.\\n[87] Durk P Kingma and Prafulla Dhariwal,\\n“Glow: Generative flow\\nwith invertible 1x1 convolutions,” Advances in neural information\\nprocessing systems, vol. 31, 2018.\\n[88] Ryuichi Yamamoto, Eunwoo Song, and Jae-Min Kim,\\n“Parallel\\nwavegan: A fast waveform generation model based on generative\\nadversarial networks with multi-resolution spectrogram,”\\nin Proc.\\nICASSP, 2020, pp. 6199–6203.\\n[89] Ye Jia, Yu Zhang, Ron Weiss, Quan Wang, Jonathan Shen, Fei Ren,\\nPatrick Nguyen, Ruoming Pang, Ignacio Lopez Moreno, Yonghui\\nWu, et al.,\\n“Transfer learning from speaker verification to multi-\\nspeaker text-to-speech synthesis,” Advances in neural information\\nprocessing systems, vol. 31, 2018.\\n[90] KR Prajwal, Rudrabha Mukhopadhyay, Vinay P Namboodiri, and\\nCV Jawahar, “A lip sync expert is all you need for speech to lip\\ngeneration in the wild,” in Proc. ACM international conference on\\nmultimedia, 2020, pp. 484–492.\\n[91] Ye Jia, Yu Zhang, Ron Weiss, Quan Wang, Jonathan Shen, Fei Ren,\\nPatrick Nguyen, Ruoming Pang, Ignacio Lopez Moreno, Yonghui\\nWu, et al.,\\n“Transfer learning from speaker verification to multi-\\nspeaker text-to-speech synthesis,” Advances in neural information\\nprocessing systems, vol. 31, 2018.\\n[92] Xin Wang, Shinji Takaki, and Junichi Yamagishi, “Neural source-\\nfilter waveform models for statistical parametric speech synthesis,”\\nIEEE/ACM Transactions on Audio, Speech, and Language Process-\\ning, vol. 28, pp. 402–415, 2019.\\n[93] Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman\\nCasagrande, Edward Lockhart, Florian Stimberg, Aaron van den\\nOord, Sander Dieleman, and Koray Kavukcuoglu, “Efficient neural\\naudio synthesis,” in Proc. ICML, 2018, pp. 2410–2419.\\n[94] Ryuichi Yamamoto, Eunwoo Song, and Jae-Min Kim,\\n“Parallel\\nwavegan: A fast waveform generation model based on generative\\nadversarial networks with multi-resolution spectrogram,”\\nin Proc.\\nICASSP, 2020, pp. 6199–6203.\\n[95] Nanxin Chen, Yu Zhang, Heiga Zen, Ron J. Weiss, Mohammad\\nNorouzi, and William Chan, “Wavegrad: Estimating gradients for\\nwaveform generation,” in Proc. ICLR, 2021.\\n[96] Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catan-\\nzaro, “Diffwave: A versatile diffusion model for audio synthesis,” in\\nProc. ICLR, 2021.\\n[97] Jaehyeon Kim, Jungil Kong, and Juhee Son, “Conditional variational\\nautoencoder with adversarial learning for end-to-end text-to-speech,”\\nin Proc. ICML, 2021, pp. 5530–5540.\\n[98] Edresson Casanova, Julian Weber, Christopher D Shulby, Ar-\\nnaldo Candido Junior, Eren G¨olge, and Moacir A Ponti, “Yourtts:\\nTowards zero-shot multi-speaker tts and zero-shot voice conversion\\nfor everyone,” in Proc. ICML, 2022, pp. 2709–2720.\\n[99] Hideki Kawahara,\\n“Straight, exploitation of the other aspect of\\nvocoder: Perceptually isomorphic decomposition of speech sounds,”\\nAcoustical Science and Technology, vol. 27, no. 6, pp. 349–353, 2006.\\n[100] Nathana¨el Perraudin, Peter Balazs, and Peter L. Søndergaard, “A fast\\ngriffin-lim algorithm,” in IEEE Workshop on Applications of Signal\\nProcessing to Audio and Acoustics, 2013, pp. 1–4.\\n[101] Jean-Marc Valin and Jan Skoglund,\\n“Lpcnet: Improving neural\\nspeech synthesis through linear prediction,” in Proc. ICASSP, 2019,\\npp. 5891–5895.\\n[102] Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae, “Hifi-gan: gen-\\nerative adversarial networks for efficient and high fidelity speech\\nsynthesis,” in Proc. NeurIPS, 2020.\\n[103] Masanori MORISE, Fumiya YOKOMORI, and Kenji OZAWA,\\n“World: A vocoder-based high-quality speech synthesis system for\\nreal-time applications,”\\nIEICE Transactions on Information and\\nSystems, vol. E99.D, no. 7, pp. 1877–1884, 2016.\\n[104] Yi Ren, Chenxu Hu, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and\\nTie-Yan Liu, “Fastspeech 2: Fast and high-quality end-to-end text to\\nspeech,” arXiv preprint arXiv:2006.04558, 2020.\\n[105] Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J.\\nWeiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen,\\nSamy Bengio, Quoc Le, Yannis Agiomyrgiannakis, Rob Clark, and\\nRif A. Saurous, “Tacotron: Towards end-to-end speech synthesis,”\\nin Proc. INTERSPEECH, 2017, pp. 4006–4010.\\n[106] Jaehyeon Kim, Sungwon Kim, Jungil Kong, and Sungroh Yoon,\\n“Glow-tts: A generative flow for text-to-speech via monotonic align-\\nment search,” Advances in Neural Information Processing Systems,\\nvol. 33, pp. 8067–8077, 2020.\\n[107] Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova,\\nand Mikhail Kudinov, “Grad-tts: A diffusion probabilistic model for\\ntext-to-speech,” in Proc. ICML, 2021, pp. 8599–8608.\\n[108] Adrian Ła´ncucki,\\n“Fastpitch: Parallel text-to-speech with pitch\\nprediction,” in Proc. ICASSP, 2021, pp. 6588–6592.\\n[109] Jaehyeon Kim, Jungil Kong, and Juhee Son, “Conditional variational\\nautoencoder with adversarial learning for end-to-end text-to-speech,”\\nin Proc. ICML, 2021, pp. 5530–5540.\\n[110] Florian Lux, Julia Koch, and Ngoc Thang Vu,\\n“Low-resource\\nmultilingual and zero-shot multispeaker tts,” in Proc. AACL, 2022,\\npp. 741–751.\\n[111] Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae, “Hifi-gan: Gen-\\nerative adversarial networks for efficient and high fidelity speech\\nsynthesis,” Advances in neural information processing systems, vol.\\n33, pp. 17022–17033, 2020.\\n[112] Jonathan Shen, Ruoming Pang, Ron J Weiss, Mike Schuster, Navdeep\\nJaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang,\\nRj Skerrv-Ryan, et al., “Natural tts synthesis by conditioning wavenet\\non mel spectrogram predictions,” in Proc. ICASSP, 2018, pp. 4779–\\n4783.\\n[113] Yinghao Aaron Li, Ali Zare, and Nima Mesgarani, “Starganv2-vc: A\\ndiverse, unsupervised, non-parallel framework for natural-sounding\\nvoice conversion,” in Proc. INTERSPEECH, 2021, pp. 1349–1353.\\n[114] Edresson Casanova, Julian Weber, Christopher D Shulby, Ar-\\nnaldo Candido Junior, Eren G¨olge, and Moacir A Ponti, “Yourtts:\\nTowards zero-shot multi-speaker tts and zero-shot voice conversion\\nfor everyone,” in Proc. ICML, 2022, pp. 2709–2720.\\n[115] Ehab A AlBadawy and Siwei Lyu, “Voice conversion using speech-\\nto-speech neuro-style transfer.,” in Proc. INTERSPEECH, 2020, pp.\\n4726–4730.\\n[116] Cheng Gong, Xin Wang, Erica Cooper, Dan Wells, Longbiao Wang,\\nJianwu Dang, Korin Richmond, and Junichi Yamagishi, “Zmm-tts:\\nZero-shot multilingual and multispeaker speech synthesis conditioned\\non self-supervised discrete speech representations,”\\nIEEE/ACM\\nTransactions on Audio, Speech, and Language Processing, 2024.\\n[117] Ingmar Steiner and S´ebastien Le Maguer, “Creating new language\\nand voice components for the updated marytts text-to-speech synthe-\\nsis platform,” in Proc. LREC, 2018, pp. 1371–1375.\\n[118] Sang-gil Lee, Wei Ping, Boris Ginsburg, Bryan Catanzaro, and\\nSungroh Yoon, “Bigvgan: A universal neural vocoder with large-\\nscale training,” in Proc. ICLR, 2022.\\n[119] Florian Lux, Julia Koch, and Ngoc Thang Vu, “Exact prosody cloning\\nin zero-shot multispeaker text-to-speech,” in Proc. SLT, 2023, pp.\\n962–969.\\n[120] Florian Lux, Julia Koch, and Ngoc Thang Vu,\\n“Low-resource\\nmultilingual and zero-shot multispeaker tts,” in Proc. AACL, 2022.\\n[121] Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova,\\nMikhail Kudinov, and Jiansheng Wei, “Diffusion-based voice con-\\nversion with fast maximum likelihood sampling scheme,” in Proc.\\nICLR, 2022.\\n[122] Edresson Casanova, Julian Weber, Christopher D Shulby, Ar-\\nnaldo Candido Junior, Eren G¨olge, and Moacir A Ponti, “Yourtts:\\nTowards zero-shot multi-speaker tts and zero-shot voice conversion\\nfor everyone,” in Proc. ICML, 2022, pp. 2709–2720.\\n[123] Edresson Casanova, Kelly Davis, Eren G¨olge, G¨orkem G¨oknar, Iulian\\nGulea, Logan Hart, Aya Aljafari, Joshua Meyer, Reuben Morais,\\nSamuel Olayemi, et al., “Xtts: a massively multilingual zero-shot\\ntext-to-speech model,” in Proc. INTERSPEECH, 2024, pp. 4978–\\n4982.\\n[124] Michele\\nPanariello,\\nWanying\\nGe,\\nHemlata\\nTak,\\nMassimiliano\\nTodisco, and Nicholas Evans, “Malafide: a novel adversarial convo-\\nlutive noise attack against deepfake and spoofing detection systems,”\\nin Proc. INTERSPEECH, 2023, pp. 2868–2872.\\n[125] Massimiliano Todisco, Michele Panariello, Xin Wang, Hector Del-\\ngado, Kong Aik Lee, and Nicholas Evans, “Malacopula: adversarial\\nautomatic speaker verification attacks using a neural-based gener-\\nalised hammerstein model,” arXiv preprint arXiv:2408.09300, 2024.\\n[126] Joaquın C´aceres, Roberto Font, Teresa Grau, Javier Molina, and\\nBiometric Vox SL,\\n“The biometric vox system for the asvspoof\\n2021 challenge,” in Edition of the Automatic Speaker Verification\\nand Spoofing Countermeasures Challenge, 2021, pp. 68–74.\\n[127] Rohan Kumar Das, “Known-unknown data augmentation strategies\\nfor detection of logical access, physical access and speech deepfake\\nattacks: Asvspoof 2021,”\\nin Edition of the Automatic Speaker\\nVerification and Spoofing Countermeasures Challenge, 2021, pp. 29–\\n36.\\n[128] Wanying Ge, Jose Patino, Massimiliano Todisco, and Nicholas Evans,\\n“Raw differentiable architecture search for speech deepfake and\\nspoofing detection,” in Edition of the Automatic Speaker Verification\\nand Spoofing Countermeasures Challenge, 2021, pp. 22–28.\\n[129] Woo Hyun Kang, Jahangir Alam, and Abderrahim Fathan, “Crim’s\\nsystem description for the asvspoof2021 challenge,” in Edition of\\nthe Automatic Speaker Verification and Spoofing Countermeasures\\nChallenge, 2021, pp. 100–106.\\n[130] Nicolas M M¨uller, Franziska Dieckmann, Pavel Czempin, Roman\\nCanals, Konstantin B¨ottinger, and Jennifer Williams,\\n“Speech is\\nsilver, silence is golden: What do asvspoof-trained models really\\nlearn?,” in Edition of the Automatic Speaker Verification and Spoofing\\nCountermeasures Challenge, 2021, pp. 55–60.\\n[131] Hemlata Tak, Jee-weon Jung, Jose Patino, Madhu Kamble, Massi-\\nmiliano Todisco, and Nicholas Evans, “End-to-end spectro-temporal\\ngraph attention networks for speaker verification anti-spoofing and\\nspeech deepfake detection,”\\nin Edition of the Automatic Speaker\\nVerification and Spoofing Countermeasures Challenge, 2021, pp. 1–\\n8.\\n[132] Anton\\nTomilov,\\nAleksei\\nSvishchev,\\nMarina\\nVolkova,\\nArtem\\nChirkovskiy, Alexander Kondratev, and Galina Lavrentyeva,\\n“Stc\\nantispoofing systems for the asvspoof2021 challenge,” in Edition of\\nthe Automatic Speaker Verification and Spoofing Countermeasures\\nChallenge, 2021, pp. 61–67.\\n[133] Xingming Wang, Xiaoyi Qin, Tinglong Zhu, Chao Wang, Shilei\\nZhang, and Ming Li, “The dku-cmri system for the asvspoof 2021\\nchallenge: vocoder based replay channel response estimation,”\\nin\\nEdition of the Automatic Speaker Verification and Spoofing Counter-\\nmeasures Challenge, 2021, pp. 16–21.\\n[134] Jee-weon Jung, Hee-Soo Heo, Hemlata Tak, Hye-jin Shim, Joon Son\\nChung, Bong-Jin Lee, Ha-Jin Yu, and Nicholas Evans,\\n“Aasist:\\nAudio anti-spoofing using integrated spectro-temporal graph attention\\nnetworks,” in Proc. ICASSP, 2022, pp. 6367–6371.\\n[135] Hemlata Tak, Massimiliano Todisco, Xin Wang, Jee-weon Jung,\\nJunichi Yamagishi, and Nicholas Evans, “Automatic speaker veri-\\nfication spoofing and deepfake detection using wav2vec 2.0 and data\\naugmentation,” in The Speaker and Language Recognition Workshop,\\n2022.\\n[136] Hemlata Tak, Madhu Kamble, Jose Patino, Massimiliano Todisco,\\nand Nicholas Evans, “Rawboost: A raw data boosting and augmenta-\\ntion method applied to automatic speaker verification anti-spoofing,”\\nin Proc. ICASSP, 2022, pp. 6382–6386.\\n[137] Rui Liu, Jinhua Zhang, Guanglai Gao, and Haizhou Li,\\n“Betray\\nOneself: A Novel Audio DeepFake Detection Model via Mono-to-\\nStereo Conversion,” in Proc. INTERSPEECH, 2023, pp. 3999–4003.\\n[138] Chenglong Wang, Jiangyan Yi, Jianhua Tao, Chu Yuan Zhang,\\nShuai Zhang, and Xun Chen,\\n“Detection of Cross-Dataset Fake\\nAudio Based on Prosodic and Pronunciation Features,”\\nin Proc.\\nINTERSPEECH, 2023, pp. 3844–3848.\\n[139] Alexis Conneau, Alexei Baevski, Ronan Collobert, Abdelrahman Mo-\\nhamed, and Michael Auli, “Unsupervised Cross-Lingual Represen-\\ntation Learning for Speech Recognition,” in Proc. INTERSPEECH,\\n2021, pp. 2426–2430.\\n[140] Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal\\nLakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed, “Hu-\\nbert: Self-supervised speech representation learning by masked pre-\\ndiction of hidden units,” IEEE/ACM transactions on audio, speech,\\nand language processing, vol. 29, pp. 3451–3460, 2021.\\n[141] Xiao-Min Zeng, Jian-Tao Zhang, Kang Li, Zhuo-Li Liu, Wei-Lin\\nXie, and Yan Song, “Deepfake algorithm recognition system with\\naugmented data for add 2023 challenge.,” in Proc. IJCAI, 2023, pp.\\n31–36.\\n[142] Zhongwei Teng, Quchen Fu, Jules White, Maria E Powell, and Dou-\\nglas C Schmidt, “Sa-sasv: An end-to-end spoof-aggregated spoofing-\\naware speaker verification system,” in Proc. INTERSPEECH, 2022,\\npp. 4391–4395.\\n[143] Jun Xue, Cunhang Fan, Jiangyan Yi, Chenglong Wang, Zhengqi Wen,\\nDan Zhang, and Zhao Lv, “Learning from yourself: A self-distillation\\nmethod for fake speech detection,” in Proc. ICASSP, 2023, pp. 1–5.\\n[144] Yuankun Xie, Haonan Cheng, Yutian Wang, and Long Ye, “Learning\\na self-supervised domain-invariant feature representation for general-\\nized audio deepfake detection,” in Proc. INTERSPEECH, 2023, pp.\\n2808–2812.\\n[145] Yujie Yang, Haochen Qin, Hang Zhou, Chengcheng Wang, Tianyu\\nGuo, Kai Han, and Yunhe Wang, “A robust audio deepfake detection\\nsystem via multi-view feature,” in Proc. ICASSP, 2024, pp. 13131–\\n13135.\\n[146] Alexandre D´efossez, Jade Copet, Gabriel Synnaeve, and Yossi Adi,\\n“High fidelity neural audio compression,” Transactions on Machine\\nLearning Research, 2023.\\n[147] Yi-Chiao Wu, Israel D Gebru, Dejan Markovi´c, and Alexander\\nRichard, “Audiodec: An open-source streaming high-fidelity neural\\naudio codec,” in Proc. ICASSP, 2023, pp. 1–5.\\n[148] Po-Yao Huang, Hu Xu, Juncheng Li, Alexei Baevski, Michael\\nAuli, Wojciech Galuba, Florian Metze, and Christoph Feichtenhofer,\\n“Masked autoencoders that listen,” Advances in Neural Information\\nProcessing Systems, vol. 35, pp. 28708–28720, 2022.\\n[149] Sanyuan Chen, Chengyi Wang, Zhengyang Chen, Yu Wu, Shujie\\nLiu, Zhuo Chen, Jinyu Li, Naoyuki Kanda, Takuya Yoshioka, Xiong\\nXiao, et al., “Wavlm: Large-scale self-supervised pre-training for full\\nstack speech processing,” IEEE Journal of Selected Topics in Signal\\nProcessing, vol. 16, no. 6, pp. 1505–1518, 2022.\\n[150] Alec Radford et al., “Robust speech recognition via large-scale weak\\nsupervision,” in Proc. ICML, 2023, pp. 28492–28518.\\n[151] Yinlin Guo, Haofan Huang, Xi Chen, He Zhao, and Yuehai Wang,\\n“Audio deepfake detection with self-supervised wavlm and multi-\\nfusion attentive classifier,” in Proc. ICASSP, 2024, pp. 12702–12706.\\n[152] Alessandro Pianese, Davide Cozzolino, Giovanni Poggi, and Luisa\\nVerdoliva, “Training-free deepfake voice recognition by leveraging\\nlarge-scale pre-trained models,” in Proc. ACM Workshop on Infor-\\nmation Hiding and Multimedia Security, 2024, pp. 289–294.\\n[153] Sanyuan Chen, Yu Wu, Chengyi Wang, Shujie Liu, Daniel Tompkins,\\nZhuo Chen, Wanxiang Che, Xiangzhan Yu, and Furu Wei, “Beats:\\naudio pre-training with acoustic tokenizers,” in Proc. ICML, 2023,\\npp. 5178–5193.\\n[154] Yusong Wu, Ke Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-\\nKirkpatrick, and Shlomo Dubnov, “Large-scale contrastive language-\\naudio pretraining with feature fusion and keyword-to-caption aug-\\nmentation,” in Proc. ICASSP, 2023, pp. 1–5.\\n[155] Andrey Guzhov, Federico Raue, J¨orn Hees, and Andreas Dengel,\\n“Audioclip: Extending clip to image, text and audio,”\\nin Proc.\\nICASSP, 2022, pp. 976–980.\\n[156] Tianxiang Chen, Avrosh Kumar, Parav Nagarsheth, Ganesh Sivara-\\nman, and Elie Khoury, “Generalization of audio deepfake detection.,”\\nin Odyssey, 2020, pp. 132–137.\\n[157] Yuankun Xie, Haonan Cheng, Yutian Wang, and Long Ye, “Single\\ndomain generalization for audio deepfake detection.,” in Proc. IJCAI,\\n2023, pp. 58–63.\\n[158] Xinhui Chen, You Zhang, Ge Zhu, and Zhiyao Duan, “Ur channel-\\nrobust synthetic speech detection system for asvspoof 2021,”\\nin\\nEdition of the Automatic Speaker Verification and Spoofing Coun-\\ntermeasures Challenge, 2021, pp. 75–82.\\n[159] Zhor Benhafid, Sid Ahmed Selouani, Mohammed Sidi Yakoub, and\\nAbderrahmane Amrouche,\\n“Larihs assert reassessment for logical\\naccess asvspoof 2021 challenge,” in Edition of the Automatic Speaker\\nVerification and Spoofing Countermeasures Challenge, 2021, pp. 94–\\n99.\\n[160] You Zhang, Fei Jiang, and Zhiyao Duan, “One-class learning towards\\nsynthetic voice spoofing detection,” IEEE Signal Processing Letters,\\nvol. 28, pp. 937–941, 2021.\\n[161] Woo Hyun Kang, Jahangir Alam, and Abderrahim Fathan, “Investi-\\ngation on activation functions for robust end-to-end spoofing attack\\ndetection system,” in Proc. INTERSPEECH, 2021, pp. 83–88.\\n[162] Lin Zhang, Xin Wang, Erica Cooper, and Junichi Yamagishi, “Multi-\\ntask learning in utterance-level and segmental-level spoof detection,”\\nin Edition of the Automatic Speaker Verification and Spoofing Coun-\\ntermeasures Challenge, 2021.\\n[163] Yang Gao, Tyler Vuong, Mahsa Elyasi, Gaurav Bharaj, and Rita\\nSingh,\\n“Generalized spoofing detection inspired from audio gen-\\neration artifacts,” in Proc. INTERSPEECH, 2021, pp. 4184–4188.\\n[164] Rui Yan, Cheng Wen, Shuran Zhou, Tingwei Guo, Wei Zou, and\\nXiangang Li, “Audio deepfake detection system with neural stitching\\nfor add 2022,” in Proc. ICASSP, 2022, pp. 9226–9230.\\n[165] Yuankun Xie, Haonan Cheng, Yutian Wang, and Long Ye, “Domain\\ngeneralization via aggregation and separation for audio deepfake\\ndetection,” IEEE Transactions on Information Forensics and Security,\\nvol. 19, pp. 344–358, 2024.\\n[166] Amit Kumar Singh Yadav, Emily R Bartusiak, Kratika Bhagtani, and\\nEdward J Delp, “Synthetic speech attribution using self supervised\\naudio spectrogram transformer,”\\nElectronic Imaging, vol. 35, pp.\\n1–11, 2023.\\n[167] Yeqing\\nRen,\\nHaipeng\\nPeng,\\nLixiang\\nLi,\\nand\\nYixian\\nYang,\\n“Lightweight voice spoofing detection using improved one-class\\nlearning and knowledge distillation,”\\nIEEE Transactions on Mul-\\ntimedia, 2023.\\n[168] Yuxiang Zhang, Zhuo Li, Jingze Lu, Wenchao Wang, and Pengyuan\\nZhang, “Synthetic speech detection based on the temporal consis-\\ntency of speaker features,” IEEE Signal Processing Letters, vol. 31,\\npp. 944–948, 2024.\\n[169] Junlong Deng, Yanzhen Ren, Tong Zhang, Hongcheng Zhu, and\\nZongkun Sun,\\n“Vfd-net: Vocoder fingerprints detection for fake\\naudio,” in Proc. ICASSP, 2024, pp. 12151–12155.\\n[170] “Gan-based\\nnetwork\\ndecoders,”\\nhttps://github.com/\\nkan-bayashi/ParallelWaveGAN, 2023.\\n[171] Luca Cuccovillo, Milica Gerhardt, and Patrick Aichroth,\\n“Audio\\ntransformer for synthetic speech detection via formant magnitude\\nand phase analysis,” in Proc. ICASSP, 2024, pp. 4805–4809.\\n[172] Xin Wang and Junichi Yamagishi, “Can large-scale vocoded spoofed\\ndata improve speech spoofing countermeasure with a self-supervised\\nfront end?,” in Proc. ICASSP, 2024, pp. 10311–10315.\\n[173] Hyun-seo Shin, Jungwoo Heo, Ju-ho Kim, Chan-yeong Lim, Wonbin\\nKim, and Ha-Jin Yu,\\n“Hm-conformer: A conformer-based audio\\ndeepfake detection system with hierarchical pooling and multi-level\\nclassification token aggregation methods,” in Proc. ICASSP, 2024,\\npp. 10581–10585.\\n[174] Galina Lavrentyeva, Sergey Novoselov, Andzhukaev Tseren, Marina\\nVolkova, Artem Gorlanov, and Alexandr Kozlov, “Stc antispoofing\\nsystems for the asvspoof2019 challenge,” in Proc. INTERSPEECH,\\n2019, pp. 1033–1037.\\n[175] Guang Hua, Andrew Beng Jin Teoh, and Haijian Zhang, “Towards\\nend-to-end synthetic speech detection,”\\nIEEE Signal Processing\\nLetters, vol. 28, pp. 1265–1269, 2021.\\n[176] Xin Wang and Junich Yamagishi, “A comparative study on recent\\nneural spoofing countermeasures for synthetic speech detection,” in\\nProc. INTERSPEECH, 2021, pp. 4259–4263.\\n[177] Tianxiang Chen, Elie Khoury, Kedar Phatak, and Ganesh Sivaraman,\\n“Pindrop labs’ submission to the asvspoof 2021 challenge,” in Edition\\nof the Automatic Speaker Verification and Spoofing Countermeasures\\nChallenge, 2021, pp. 89–93.\\n[178] Yan Wen, Zhenchun Lei, Yingen Yang, Changhong Liu, and Minglei\\nMa,\\n“Multi-path gmm-mobilenet based on attack algorithms and\\ncodecs for synthetic speech and deepfake detection.,”\\nin Proc.\\nINTERSPEECH, 2022, pp. 4795–4799.\\n[179] Il-Youp Kwak, Sunmook Choi, Jonghoon Yang, Yerin Lee, Soyul\\nHan, and Seungsang Oh, “Low-quality fake audio detection through\\nfrequency feature masking,” in Proceedings of the 1st International\\nWorkshop on Deepfake Detection for Audio Multimedia, 2022, pp.\\n9–17.\\n[180] Jiahui Pan, Shuai Nie, Hui Zhang, Shulin He, Kanghao Zhang, Shan\\nLiang, Xueliang Zhang, and Jianhua Tao,\\n“Speaker recognition-\\nassisted robust audio deepfake detection.,” in Proc. INTERSPEECH,\\n2022, pp. 4202–4206.\\n[181] Alexander Alenin, Nikita Torgashov, Anton Okhotnikov, Rostislav\\nMakarov, and Ivan Yakovlev, “A subnetwork approach for spoofing\\naware speaker verification.,”\\nin Proc. INTERSPEECH, 2022, pp.\\n2888–2892.\\n[182] Shunbo Dong, Jun Xue, Cunhang Fan, Kang Zhu, Yujie Chen,\\nand Zhao Lv,\\n“Multi-perspective information fusion res2net with\\nrandomspecmix for fake speech detection,” in Proc. IJCAI, 2023.\\n[183] Ziqian Wang, Qing Wang, Jixun Yao, and Lei Xie, “The npu-aslp\\nsystem for deepfake algorithm recognition in add 2023 challenge.,”\\nin Proc. IJCAI, 2023, pp. 64–69.\\n[184] Chenglong Wang, Jiayi He, Jiangyan Yi, Jianhua Tao, Chu Yuan\\nZhang, and Xiaohui Zhang,\\n“Multi-scale permutation entropy for\\naudio deepfake detection,” in Proc. ICASSP, 2024, pp. 1406–1410.\\n[185] Yi Zhu, Surya Koppisetti, Trang Tran, and Gaurav Bharaj, “Slim:\\nStyle-linguistics mismatch model for generalized audio deepfake\\ndetection,” arXiv preprint arXiv:2407.18517, 2024.\\n[186] Hu Hu, Chao-Han Huck Yang, Xianjun Xia, Xue Bai, Xin Tang,\\nYajian Wang, Shutong Niu, Li Chai, Juanjuan Li, Hongning Zhu,\\net al.,\\n“Device-robust acoustic scene classification based on two-\\nstage categorization and data augmentation,” in Proc. DCASE, 2020.\\n[187] Nhat Truong Pham et al.,\\n“Hybrid data augmentation and deep\\nattention-based dilated convolutional-recurrent neural networks for\\nspeech emotion recognition,” Expert Systems with Applications, vol.\\n230, pp. 120608, 2023.\\n[188] Ashish Alex, Lin Wang, Paolo Gastaldo, and Andrea Cavallaro, “Data\\naugmentation for speech separation,” Speech Communication, vol.\\n152, pp. 102949, 2023.\\n[189] Y. Tokozume, Y. Ushiku, and T. Harada, “Learning from between-\\nclass examples for deep sound recognition,” in ICLR, 2018.\\n[190] Daniel S Park, William Chan, Yu Zhang, Chung-Cheng Chiu, Barret\\nZoph, Ekin D Cubuk, and Quoc V Le, “Specaugment: A simple data\\naugmentation method for automatic speech recognition,”\\nin Proc.\\nINTERSPEECH, 2019, pp. 2613–2617.\\n[191] Zhizheng Wu, Junichi Yamagishi, Tomi Kinnunen, Cemal Hanilc¸i,\\nMohammed Sahidullah, Aleksandr Sizov, Nicholas Evans, Massimil-\\niano Todisco, and Hector Delgado, “Asvspoof: the automatic speaker\\nverification spoofing and countermeasures challenge,” IEEE Journal\\nof Selected Topics in Signal Processing, vol. 11, no. 4, pp. 588–604,\\n2017.\\n[192] Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia,\\nQiantong Xu, Naman Goyal, Kritika Singh, Patrick von Platen,\\nYatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, and\\nMichael Auli, “XLS-R: Self-supervised Cross-lingual Speech Rep-\\nresentation Learning at Scale,” in Proc. INTERSPEECH, 2022, pp.\\n2278–2282.\\n[193] Mirco Ravanelli and Yoshua Bengio,\\n“Speaker recognition from\\nraw waveform with sincnet,” in IEEE spoken language technology\\nworkshop, 2018, pp. 1021–1028.\\n[194] Neil Zeghidour, Olivier Teboul, F´elix de Chaumont Quitry, and\\nMarco Tagliasacchi, “LEAF: A learnable frontend for audio clas-\\nsification,” in Proc. ICLR, 2021.\\n[195] McFee, Brian, R. Colin, L. Dawen, Daniel P., M. Matt, B. Eric, and\\nN. Oriol, “librosa: Audio and music signal analysis in python,” in\\nProc. Python in Science Conference, 2015, pp. 18–25.\\n[196] Lam Pham, Dat Ngo, Dusan Salovic, Anahid Jalali, Alexan-\\nder Schindler, Phu X. Nguyen, Khoa Tran, and Hai Canh Vu,\\n“Lightweight deep neural networks for acoustic scene classification\\nand an effective visualization for presenting sound scene contexts,”\\nApplied Acoustics, vol. 211, pp. 109489, 2023.\\n[197] Jingze Lu, Yuxiang Zhang, Wenchao Wang, Zengqiang Shang, and\\nPengyuan Zhang,\\n“One-class knowledge distillation for spoofing\\nspeech detection,” in Proc. ICASSP, 2024, pp. 11251–11255.\\n[198] Piotr Kawa, Marcin Plata, and Piotr Syga, “Attack Agnostic Dataset:\\nTowards Generalization and Stabilization of Audio DeepFake Detec-\\ntion,” in Proc. INTERSPEECH, 2022, pp. 4023–4027.\\n[199] Xin Wang and Junichi Yamagishi, “Spoofed training data for speech\\nspoofing countermeasure can be efficiently created using neural\\nvocoders,” in Proc. ICASSP, 2023, pp. 1–5.\\n[200] Akash Chintha et al., “Recurrent convolutional structures for audio\\nspoof and video deepfake detection,” IEEE Journal of Selected Topics\\nin Signal Processing, vol. 14, no. 5, pp. 1024–1037, 2020.\\n[201] Jia Deng et al.,\\n“Imagenet: A large-scale hierarchical image\\ndatabase,” in Proc. CVPR, 2009, pp. 248–255.\\n[202] Barrault Lo¨ıc et al., “Seamless: Multilingual expressive and stream-\\ning speech translation,” arXiv preprint arXiv:2312.05187, 2023.\\n[203] Mirco Ravanelli et al.,\\n“SpeechBrain: A general-purpose speech\\ntoolkit,” 2021, arXiv:2106.04624.\\n[204] Alexis Plaquet and Herv´e Bredin, “Powerset multi-class cross entropy\\nloss for neural speaker diarization,” in Proc. INTERSPEECH, 2023,\\npp. 3222–3226.\\n[205] Herv´e Bredin,\\n“pyannote.audio 2.1 speaker diarization pipeline:\\nprinciple, benchmark, and recipe,” in Proc. INTERSPEECH, 2023,\\npp. 1983–1987.\\n[206] Nicolas\\nM.\\nM¨uller,\\nPhilip\\nSperl,\\nand\\nKonstantin\\nB¨ottinger,\\n“Complex-valued neural networks for voice anti-spoofing,” in Proc.\\nINTERSPEECH, 2023, pp. 3814–3818.\\n[207] Wanying Ge, Jose Patino, Massimiliano Todisco, and Nicholas Evans,\\n“Explaining deep learning models for spoofing and deepfake detec-\\ntion with shapley additive explanations,” in Proc. ICASSP, 2022, pp.\\n6387–6391.\\n[208] Davide Salvi, Paolo Bestagini, and Stefano Tubaro,\\n“Towards\\nfrequency band explainability in synthetic speech detection,” in Proc.\\nEUSIPCO, 2023, pp. 620–624.\\n[209] Ning Yu, Long Chen, Tao Leng, Zigang Chen, and Xiaoyin Yi, “An\\nexplainable deepfake of speech detection method with spectrograms\\nand waveforms,” Journal of Information Security and Applications,\\nvol. 81, pp. 103720, 2024.\\n[210] Suk-Young Lim, Dong-Kyu Chae, and Sang-Chul Lee, “Detecting\\ndeepfake voice using explainable deep learning techniques,” Applied\\nSciences, vol. 12, no. 8, pp. 3926, 2022.\\n[211] Scott M. Lundberg and Su-In Lee, “A unified approach to interpreting\\nmodel predictions,”\\nin Proc. International Conference on Neural\\nInformation Processing Systems, 2017, p. 4768–4777.\\n[212] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin,\\n“”why\\nshould i trust you?”: Explaining the predictions of any classifier,” in\\nProceedings of the 22nd ACM SIGKDD International Conference on\\nKnowledge Discovery and Data Mining, 2016, p. 1135–1144.\\n[213] Karen Simonyan and Andrew Zisserman, “Very deep convolutional\\nnetworks for large-scale image recognition,” in Proc. ICLR, 2015.\\n[214] Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda B. Vi´egas, and\\nMartin Wattenberg, “Smoothgrad: removing noise by adding noise,”\\nCoRR, vol. abs/1706.03825, 2017.\\n[215] Reza Amini Gougeh, Zhang Nu, and Zeljko Zilic,\\n“Optimizing\\nAuditory Immersion Safety on Edge Devices: An On-Device Sound\\nEvent Detection System,”\\nin Proc. The Speaker and Language\\nRecognition Workshop, 2024, pp. 225–231.\\n[216] Jordan J Bird and Ahmad Lotfi,\\n“Real-time detection of ai-\\ngenerated speech for deepfake voice conversion,”\\narXiv preprint\\narXiv:2308.12734, 2023.\\n[217] Jonat John Mathew, Rakin Ahsan, Sae Furukawa, Jagdish Gau-\\ntham Krishna Kumar, Huzaifa Pallan, Agamjeet Singh Padda, Sara\\nAdamski, Madhu Reddiboina, and Arjun Pankajakshan, “Towards\\nthe development of a real-time deepfake audio detection system in\\ncommunication platforms,” arXiv preprint arXiv:2403.11778, 2024.\\n[218] Shuwei Hou, Yan Ju, Chengzhe Sun, Shan Jia, Lipeng Ke, Riky Zhou,\\nAnita Nikolich, and Siwei Lyu, “Deepfake-o-meter v2. 0: An open\\nplatform for deepfake detection,” arXiv preprint arXiv:2404.13146,\\n2024.\\n',\n",
       " 'IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n1\\nDiffusion Models for Intelligent Transportation\\nSystems: A Survey\\nMingxing Peng, Kehua Chen, Xusen Guo, Qiming Zhang, Hongliang Lu, Hui Zhong, Di Chen, Meixin Zhu*, and\\nHai Yang\\nAbstract—Intelligent Transportation Systems (ITS) are vital\\nin modern traffic management and optimization, significantly\\nenhancing traffic efficiency and safety. Recently, diffusion models\\nhave emerged as transformative tools for addressing complex\\nchallenges within ITS. In this paper, we present a comprehensive\\nsurvey of diffusion models for ITS, covering both theoretical and\\npractical aspects. First, we introduce the theoretical foundations\\nof diffusion models and their key variants, including conditional\\ndiffusion models and latent diffusion models, highlighting their\\nsuitability for modeling complex, multi-modal traffic data and\\nenabling controllable generation. Second, we outline the primary\\nchallenges in ITS and the corresponding advantages of diffusion\\nmodels, providing readers with a deeper understanding of the\\nintersection between ITS and diffusion models. Third, we offer\\na multi-perspective investigation of current applications of diffu-\\nsion models in ITS domains, including autonomous driving, traf-\\nfic simulation, trajectory prediction, and traffic safety. Finally, we\\ndiscuss state-of-the-art diffusion model techniques and highlight\\nkey ITS research directions that warrant further investigation.\\nThrough this structured overview, we aim to provide researchers\\nwith a comprehensive understanding of diffusion models for ITS,\\nthereby advancing their future applications in the transportation\\ndomain.\\nIndex Terms—Intelligent Transportation Systems, Diffusion\\nModels, Autonomous Driving, Traffic Simulation, Traffic Fore-\\ncasting, Traffic Safety.\\nI. INTRODUCTION\\nA\\nS urbanization accelerates and populations grow, the de-\\nmand for public transportation services increases along-\\nside a steep rise in vehicle numbers. These trends have\\ngradually revealed several issues in current transportation sys-\\ntems, such as traffic congestion and accidents. With advance-\\nments in computer technologies and transportation systems,\\nmany cities are increasingly focused on developing intelligent\\ntransportation systems (ITS) [1], which leverage cutting-edge\\ntechnologies and extensive traffic data to enable efficient, high-\\nquality, and safe traffic management. ITS encompasses sev-\\nManuscript received XX September, 2024.\\nCorresponding author is Meixin Zhu (E-mail: meixin@ust.hk).\\nMingxing Peng, Xusen Guo, Qiming Zhang, Hongliang Lu, and Hui Zhong\\nare with the Systems Hub, The Hong Kong University of Science and\\nTechnology (Guangzhou). Meixin Zhu is with the Systems Hub, The Hong\\nKong University of Science and Technology (Guangzhou) and Guangdong\\nProvincial Key Lab of Integrated Communication, Sensing and Computation\\nfor Ubiquitous Internet of Thing. Kehua Chen is with the Division of Emerging\\nInterdisciplinary Areas (EMIA), Academy of Interdisciplinary Studies, The\\nHong Kong University of Science and Technology, Hong Kong, China. Di\\nChen is with the Department of Electrical and Electronic Engineering of The\\nHong Kong Polytechnic University, Hong Kong, China. Hai Yang is with\\nthe Department of Civil and Environmental Engineering, the Hong Kong\\nUniversity of Science and Technology, Clear Water Bay, Kowloon, Hong\\nKong, China.\\neral domains, including autonomous driving, which enhances\\ntraffic safety and efficiency; traffic simulation, which enables\\nmodeling, analysis, and testing of various strategies; traffic\\nforecasting, which aims to reduce congestion and optimize\\nservices; and traffic safety, which seeks to minimize accidents\\nand improve overall safety.\\nTraffic data are inherently heterogeneous and multi-modal,\\nincluding vehicle and pedestrian trajectories, driving images or\\nvideos, spatial-temporal graphs derived from GPS positions,\\nand textual data such as traffic rules and accident reports.\\nThese data often exhibit complex spatial-temporal dependen-\\ncies and uncertainties. Additionally, the data may be noisy,\\nincomplete, or difficult to obtain, with privacy concerns par-\\nticularly affecting personal GPS data collection. Consequently,\\nprocessing these multi-modal, complex, and often imperfect\\ndatasets presents a significant challenge for ITS.\\nIn the past few decades, researchers have employed various\\napproaches to address the challenges of ITS. For example,\\nRecurrent Neural Networks (RNNs) are often used to model\\ntemporal relationships, while Convolutional neural networks\\n(CNNs) are commonly utilized to capture spatial structure\\n[2]. And graph-based approaches have demonstrated superior\\ncapabilities in extracting spatial correlations within traffic\\nnetworks [3], [4]. However, these approaches often exhibit lim-\\nitations when handling noisy or incomplete data. In contrast,\\ngenerative models such as Generative Adversarial Networks\\n(GANs) and Variational Autoencoders (VAEs) have proven\\neffective for traffic data generation and imputation tasks [5],\\n[6]. However, GANs suffer from unstable training, and VAE\\nhas the limitation of low-quality output. Diffusion models,\\nas a powerful class of generative models, offer advantages\\nsuch as ease of training, enhanced generative performance,\\ncontrollable generation, and multi-modal capabilities. To date,\\ndiffusion models have been applied across a wide range of\\nvision tasks [7], with promising applications such as Sora\\n[8]. Inspired by these developments, an increasing number of\\nresearchers in the ITS domain have begun to adopt diffusion\\nmodels to address various challenges in ITS. Therefore, orig-\\ninating in image processing and computer vision, diffusion\\nmodels are now being applied across various traffic tasks, from\\nautonomous driving and traffic simulation to traffic forecasting\\nand traffic safety. As illustrated in Fig. 1, diffusion models are\\nsuitable for processing various traffic data, and are capable\\nof addressing a wide range of various traffic tasks based on\\ntask-specific conditions or unconditional methods.\\nThere have been numerous surveys on ITS [2], [9], as\\nwell as specific technologies within the ITS domain [3], [4],\\narXiv:2409.15816v1  [eess.SY]  24 Sep 2024\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n2\\nTraffic Data\\nTraffic Tasks\\n…\\nVarious conditions or unconditional\\n…\\nDiffusion Model\\n…\\nForward Process   𝐪(𝒙𝒕|𝒙𝒕−𝟏)\\nAdd Noise\\n𝑥0\\n𝑥2\\n𝑥1\\n𝑥𝑇\\nReverse Process   𝒑𝜽(𝒙𝒕−𝟏|𝒙𝒕)\\nTrajectories\\nTraffic Images \\nSpatial-Temporal Graphs\\nTraffic Texts\\nAutonomous Driving\\nTraffic Simulation \\nTraffic Forecasting\\nTraffic Safety\\nDomain Knowledge\\nTraffic Rules\\nAccident Documents\\n…\\nDenoise\\nFig. 1: Overview of applying diffusion models to traffic tasks using various traffic data types, including trajectories, traffic\\nimages, spatial-temporal graphs, and traffic-related texts.\\n[10]. Similarly, several reviews have focused on diffusion\\nmodels [11], [12], [13] and their applications in areas such\\nas computer vision [7] and medical imaging [14]. However,\\nthere is currently no comprehensive review of diffusion models\\nwithin the ITS domain.\\nTo address this gap, this paper presents a detailed literature\\nreview on diffusion models in ITS. First, we outline how diffu-\\nsion models have emerged as powerful tools for various traffic\\ntasks. Specifically, we introduce the theoretical foundations\\nof diffusion models, along with conditional diffusion models\\nand latent diffusion models, which extend their applicability\\nto more specific tasks within ITS. Second, we examine the\\nkey challenges in ITS and the corresponding advantages of\\ndiffusion models. Third, we investigate the applications of\\ndiffusion models in areas such as autonomous driving, traffic\\nsimulation, traffic forecasting, and traffic safety within ITS, as\\nshown in Fig. 6. In particular, we review these applications\\nbased on criteria such as task, denoising condition, or model\\narchitecture, as illustrated in Table. I. Finally, we provide an\\noutlook on potential future directions for diffusion models\\nin ITS. Our goal is to bridge the gap between the diffusion\\nmodel and transportation research communities, fostering in-\\nterdisciplinary collaboration and advancing the application of\\ndiffusion models in transportation.\\nIn summary, the main contributions of this paper include:\\n• To the best of our knowledge, this is the first compre-\\nhensive literature review focused on the application of\\ndiffusion models in ITS.\\n• We systematically introduce how diffusion models have\\nbecome powerful approaches for various traffic tasks by\\nprocessing multi-modal and complex traffic data. Addi-\\ntionally, we explore the key challenges in ITS and the\\ncorresponding advantages of diffusion models. This anal-\\nysis offers readers deeper insights into the intersection of\\nITS and diffusion models.\\n• We present a comprehensive and up-to-date literature\\nreview of diffusion models in the ITS domain, focusing\\non applications in autonomous driving, traffic simulation,\\ntraffic forecasting, and traffic safety. By analyzing these\\napplications through multiple perspectives, we aim to\\noffer researchers from various ITS subfields a clear and\\nefficient overview of the latest advancements in diffusion\\nmodels.\\n• We discuss the cutting-edge techniques in diffusion mod-\\nels, and highlight key research directions for diffusion\\nmodels in ITS that are worthy of further exploration.\\nThe remainder of the paper is organized as follows: Sec. II\\npresents theoretical foundations of diffusion models and their\\nkey variants. Sec. III outline the key challenges in ITS and\\nthe corresponding advantages of diffusion models. Sec. IV-\\nSec. VII explores the diverse applications of diffusion models\\nwithin ITS, including autonomous driving, traffic simulation,\\ntraffic forecasting, and traffic safety. Sec. VIII discusses\\nseveral promising directions for future research. Finally, the\\nconclusions are drawn in Sec. IX.\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n3\\nII. THEORY\\nDiffusion models have emerged as transformative tools in\\nthe field of ITS. This section outlines how diffusion models\\nhave become powerful and flexible methods for addressing\\nvarious traffic-related challenges. First, we explore the the-\\noretical foundations of diffusion models, which lies in their\\nability to learn the underlying data distribution through a\\nprocess of noise injection and subsequent denoising. This\\nmakes them highly effective for modeling complex traffic\\ndynamics. Next, we introduce key variants of diffusion models,\\nparticularly conditional diffusion models and latent diffusion\\nmodels, which extend their applicability to more specific\\nand challenging tasks within ITS. By incorporating domain-\\nspecific conditions and leveraging latent spaces, diffusion\\nmodels can be applied to multi-modal traffic data, offering\\nsolutions to a wide range of traffic-related tasks.\\nA. Foundations of Diffusion Models\\nDiffusion models are a powerful class of probabilistic gen-\\nerative models that gradually perturb data by adding Guassian\\nnoise to data, and then learn to reverse this process to generate\\nnew data. During training, the model learns to denoise the\\ndata at each step, effectively transforming random noise into\\ncoherent and realistic outputs.\\nThis section provides an overview of three predominant\\nformulations in diffusion models: Denoising Diffusion Prob-\\nabilistic Models (DDPMs), which utilize discrete steps to\\nincrementally add and remove noise; Noise Conditioned Score\\nNetworks (NCSNs), which estimate the gradient of the log-\\ndensity of the data distribution to guide sample generation;\\nand Stochastic Differential Equations (SDEs), which offer\\na continuous-time perspective that unifies and generalizes\\nboth DDPMs and NCSNs under a common mathematical\\nframework.\\n1) Denoising Diffusion Probabilistic Models (DDPMs):\\nDDPMs [15], [16] utilize two Markov chains: a forward\\n(diffusion) process that gradually adds Gaussian noise to\\ndata, transforming it into pure noise over multiple steps,\\nand a reverse (denoising) process, learned through neural\\nnetworks—typically based on a U-Net architecture [17]—that\\nprogressively removes the noise to reconstruct the original\\ndata.\\nForward (Diffusion) Process. The forward (diffusion) pro-\\ncess incrementally corrupts the data by adding Gaussian noise\\nin a series of T steps. Given a data distribution x0 ∼q(x0), the\\nforward process starts with the original data x0 and generates a\\nsequence of latent variables x1, x2, . . . , xT through different\\ndiffusion steps. The process is defined by a Markov chain\\nwhere each state xt depends only on the previous state xt−1:\\nq(xt|xt−1) = N(xt;\\np\\n1 −βtxt−1, βtI), ∀t ∈{1, . . . , T}\\n(1)\\nwhere βt ∈(0, 1) is a hyperparameter representing the noise\\nvariance schedule that controls the amount of noise added\\nat each step. I denotes the identity matrix, and N(x; µ, σ)\\nrepresents a normal distribution with mean µ and covariance\\nσ.\\nThe entire forward process can be expressed directly in\\nterms of the original data x0 using the reparameterization trick:\\nxt = √¯αtx0 +\\n√\\n1 −¯αtϵ,\\nϵ ∼N(0, I)\\n(2)\\nwhere αt = 1 −βt and ¯αt = Qt\\ns=1 αs.\\nReverse (Denoising) Process. The goal of DDPMs is to\\nlearn the reverse of this diffusion process, where the model\\nstarts with Gaussian noise and progressively removes the noise\\nto generate new data. The reverse process is also modeled as\\na Markov chain, but it is parameterized by a neural network\\npθ(xt−1|xt) that generates pθ(x0) in a step-by-step manner:\\npθ(xt−1|xt) = N(xt−1; µθ(xt, t), σ2I)\\n(3)\\nIn the DDPM [16], the covariance σ2 is fixed to a constant\\nvalue, and the mean µθ(xt, t) is reformulated as:\\nµθ(xt, t) =\\n1\\n√αt\\n\\x12\\nxt −\\nβt\\n√1 −¯αt\\nϵθ(xt, t)\\n\\x13\\n(4)\\nwhere ϵθ(xt, t) represents the neural network’s prediction\\nof the noise component at step t.\\nThe objective of training a DDPM is to minimize the\\nvariational bound on the negative log-likelihood, which can be\\nsimplified to a mean squared error loss between the predicted\\nnoise and the actual noise [16]:\\nL(θ) = Et,x0,ϵ\\n\\x02\\n∥ϵ −ϵθ(xt, t)∥2\\x03\\n(5)\\nwhere ϵ ∼N(0, I) is the Gaussian noise, and xt is the noisy\\ndata generated during the forward process.\\n2) Noise Conditioned Score Networks (NCSNs):\\nNCSNs [18] are a class of score-based generative models\\nthat focus on estimating the score function of the data dis-\\ntribution. Instead of explicitly modeling the reverse diffusion\\nprocess, NCSNs learn the gradient of the log-density of the\\ndata distribution at various noise levels via score matching\\n[19], and subsequently generate samples via Langevin dynam-\\nics [20], [21].\\nScore Matching. Given an unknown data distribution\\npdata(x), the score function of the data density p(x) is defined\\nas ∇x log p(x). The score network sθ, a neural network\\nparameterized by θ, is trained to estimate the score function\\n∇x log p(x). When the data distribution is unknown, score\\nestimation can be performed using sliced score matching [22]\\nor denoising score matching [23]. In NCSNs [18], denoising\\nscore matching is adopted, wherein data are perturbed with\\nmultiple levels of Gaussian noise. Specifically, the noise\\ndistribution is pre-specified as qσ(˜x|x) = N(˜x|x, σ2I), and\\nthe gradient of the log-likelihood with respect to the noisy\\ndata is given by ∇˜x log qσ(˜x|x) = −(˜x −x)/σ2. Given a\\nsequence noise scales σ1 < σ2 < ... < σL, the denoising\\nscore matching objective for all σ ∈{σi}L\\ni=1 is defined as:\\nL = 1\\nL\\nL\\nX\\ni=1\\nλ(σi)Ep(x)E˜x∼qσi(˜x|x)\\n\"\\r\\r\\r\\rsθ(˜x, σi) + ˜x −x\\nσ2\\ni\\n\\r\\r\\r\\r\\n2\\n2\\n#\\n(6)\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n4\\nwhere ˜x is a noised version of x, and λ(σi) is a weighting\\nfunction depending on σi.\\nLangevin Dynamics. To generate samples, NCSNs employ\\nannealed Langevin dynamics, starting with large noise levels\\nand gradually annealing down to lower noise levels. At each\\nnoise level, Langevin dynamics is iteratively applied using the\\nlearned score function to recover the original data distribution\\nprogressively. The update rule for Langevin dynamics is given\\nby:\\n˜xt = ˜xt−1 + αi\\n2 sθ(˜xt−1, σi) + √αiN(0, I)\\n(7)\\nwhere αi = ϵ · σ2\\ni /σ2\\nL, and t ∈[1, T]. When αi →0 and\\nT →∞, the final generated sample converges to the original\\ndata distribution pdata(x).\\n3) Stochastic Differential Equations (SDEs):\\nSDEs [24] provide a continuous-time framework that unifies\\nthe concepts of DDPMs and NCSNs. Specifically, both the for-\\nward and reverse processes in these models are formulated as\\nsolutions to stochastic differential equations, with the reverse\\nprocess requiring the estimation of score functions for noisy\\ndata distributions.\\nForward Process. In the SDEs [24], the forward process\\ncan be represented as the solution to an Itˆo SDE [25]:\\ndx = f(x, t)dt + g(t)dw\\n(8)\\nwhere f(·, t) denotes the drift coefficient of x(t), g(·) repre-\\nsents the diffusion coefficient of x(t), and w is a Brownian\\nmotion.\\nThe forward processes in DDPMs and NCSNs can be\\nregarded as discretizations of two different SDEs [24]. For\\nDDPMs, the corresponding SDE is:\\ndx = −1\\n2β(t)xdt +\\np\\nβtdw\\n(9)\\nwhereas for NCSNs, the corresponding SDE is expressed\\nas:\\ndx =\\nr\\nd[σ2(t)]\\ndt\\ndw\\n(10)\\nReverse Process. To generate samples, starting from sam-\\nples of the standard Gaussian distribution x(T) and reversing\\nthe process, the reverse-time SDE is solved [26]:\\ndx = [f(x, t) −g(t)2∇x log pt(x)]dt + g(t)d¯w\\n(11)\\nwhere ¯w is a Brownian motion with time flows backwards\\nfrom T to 0, and dt is an infinitesimal negative timestep.\\nSimilar\\nto\\nNCSNs,\\nto\\nestimate\\nthe\\nscore\\nfunction\\n∇x log pt(x), we train a time-dependent score model sθ(xt, t)\\nby generalizing the score matching objective to continuous\\ntime. The objective function is given by:\\nL=Et\\nn\\nλ(t)Ex(0)Ex(t)|x(0)\\nh\\r\\rsθ(x(t), t)−∇x(t)log p(x(t)|x(0))\\n\\r\\r2\\n2\\nio\\n(12)\\nwhere t is uniformly sampled over the interval [0, T], and λ(t)\\nis a positive weighting function.\\nB. Variants of Diffusion Models\\nIn this section, we introduce key variants of diffusion\\nmodels, including conditional diffusion models and latent\\ndiffusion models (LDMs), which have significantly advanced\\nthe field of intelligent transportation systems. These mod-\\nels not only enhance the ability to generate realistic traffic\\ndata but also offer flexibility and controllability in model-\\ning complex traffic environments. By incorporating domain-\\nspecific information, such as historical data, traffic layouts,\\nor external semantic features, conditional diffusion models\\nenable the generation of more accurate and diverse traffic\\nscenarios that reflect real-world conditions. Meanwhile, LDMs\\noperate in a lower-dimensional latent space, facilitating faster\\ntraining and inference times while maintaining the fidelity\\nof generated outputs. Additionally, LDMs allows multi-modal\\nconditions within the latent space. These capabilities make\\nLDMs particularly useful for image-based, video-based, or\\ntext-involved traffic tasks. Collectively, these advanced models\\ndemonstrate the potential of diffusion models to revolutionize\\nintelligent transportation systems, providing powerful tools for\\ntraffic simulating, forecasting, and optimization in increasingly\\ndynamic urban environments.\\n1) Conditional Diffusion Models:\\nThe three types of standard diffusion models introduced\\nabove are unconditional, where the inputs are limited to\\nthe perturbed data xt and the diffusion step t. Conditional\\ndiffusion models, on the other hand, incorporate conditional\\ninformation as an extra input, allowing for control over the\\ngeneration process according to specific requirements. This ca-\\npability makes them highly adaptable for various applications\\nin intelligent transportation systems. Below, we focus on four\\nprimary conditioning mechanisms: concatenation-based, cross-\\nattention-based, classifier-based, and classifier-free-based ap-\\nproaches. Concatenation-based methods are simple to im-\\nplement but may struggle to capture complex relationships\\nbetween the data and conditions. Cross-attention-based meth-\\nods excel at modeling long-range dependencies and complex\\ninteractions, and enable multi-modal conditioning, but they do\\nnot offer control over the strength of the conditions. Classifier-\\nbased approaches provide adjustable guidance through external\\nclassifiers but can be limited by the accuracy and generaliza-\\ntion capability of the classifier. Classifier-free-based methods\\nare flexible and do not require additional classifiers, but they\\noften come with increased training costs. The visualization of\\nthese four conditioning mechanisms is shown in Fig. 2.\\nConcatenation-based. In concatenation-based mechanisms,\\nthe conditioning information is directly concatenated with the\\nperturbed data xt or the diffusion step t, and then fed into\\nthe model for sample generation. This method is simple and\\neffective, allowing the model to leverage the conditioning\\ninformation throughout the denoising process. For example,\\nin the field of intelligent transportation systems, conditioning\\non historical data [27], [28], [29] or map feature [30] has been\\nemployed for generating traffic trajectories. Similarly, image\\nfeatures [31], [32] or traffic layout [33] have been directly\\nconcatenated with the noise data vector for generating traffic\\nscenarios. Additionally, conditioning on trip regions [34], road\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n5\\n𝑥𝑡\\n𝑡\\nConditions\\nHistorical info\\nMap\\n…\\nc\\n𝑥𝑡−1\\nDenoising Network\\n1) Concatenation-based Condition Mechanism.\\n𝑥𝑡\\n𝑡\\nConditions\\nText\\nExternal features\\n…\\n𝑥𝑡−1\\nDenoising Network\\n2) Cross-attention-based Condition Mechanism.\\n𝑄\\n𝐾𝑉\\n𝑄\\n𝐾𝑉\\n𝑄\\n𝐾𝑉\\n𝑄\\n𝐾𝑉\\n𝑥𝑡−1\\n3) Classifier-based Condition Mechanism.\\nClassifier\\nReinforcement learning\\nLanguage guidance\\n…\\n∇\\n𝑥𝑡\\n𝑡\\nDenoising Network\\nCost function\\n𝑥𝑡−1\\n𝑥𝑡\\n𝑡\\nDenoising Network\\nDenoising Network\\n∅\\n𝑥𝑡\\n𝑡\\nConditions\\n𝑤\\n1 −𝑤\\n4) Classifier-free-based Condition Mechanism.\\nShared Parameters\\nFig. 2: Different condition mechanisms for diffusion models. (1) Concatenation-based mechanism incorporates conditions such\\nas historical data and maps directly into the input. (2) Cross-attention-based mechanism integrates conditions like text and\\nexternal features through cross-attention layers. (3) Classifier-based mechanism uses an external classifier to guide denoising\\nbased on conditions such as reinforcement learning or cost functions. (4) Classifier-free mechanism combines conditional and\\nunconditional denoising models, balancing both with a weight parameter.\\nnetwork [35], or graph structure [36] has been applied in traffic\\nflow generation. These examples emphasize the effectiveness\\nof concatenation-based mechanisms in diverse transportation\\napplications.\\nCross-attention-based. Cross-attention-based conditional\\ndiffusion models integrate the cross-attention layers [37] into\\nthe denoising networks, enabling effective fusion of condition-\\ning information during the denoising process and guiding the\\nnetwork to generate outputs aligned with the conditions. The\\ncross-attention mechanism plays an important role in facilitat-\\ning the interaction between the conditioning information and\\nthe noisy data, especially in scenarios where their relationship\\nis complex or involves different modalities, such as text and\\nimages. Stable Diffusion [38] introduced a general-purpose\\nconditioning mechanism based on cross-attention, enabling\\nmulti-modal conditional inputs, making diffusion models into\\npowerful and flexible generators. Building on this foundational\\nwork, numerous studies have applied this cross-attention-based\\nconditioning mechanism in the field of intelligent transporta-\\ntion systems. For example, conditioning on text [39], [40],\\n[32], [33], [41], [42], drive actions [30], external features\\nand semantic features [43], origin-destination-departure time\\n(ODT) feature [44], or bounding boxes [42] has been used for\\nvarious traffic-related tasks.\\nClassifier-based. The classifier-based mechanism incorpo-\\nrates conditions by using a task-related classifier to guide the\\ndiffusion sampling process, enabling controllable generation.\\nDhariwal and Nicho [45] proposed a classifier-guidance ap-\\nproach, where an additional classifier pϕ(y|xt, t) is trained\\non noisy data xt and the diffusion step t. The gradients of\\nthe guidance ∇xt log pϕ(y|xt, t) are then used to guide the\\ndiffusion sampling process towards a specified class label\\ny. Given a pre-trained diffusion model pθ(xt, t) and a pre-\\ntrained classifier pϕ(y|xt, t), the diffusion sampling process is\\nas follows:\\nxt−1 = N(µθ(xt, t) + w∇xt log pϕ(y|xt, t), σ2I)\\n(13)\\nwhere w is a hyperparameter controlling the strength of the\\nguidance; as w increases, the generated samples more closely\\nadhere to the specified conditions.\\nFollowing this work, many studies related to traffic trajec-\\ntory generation and motion planning have designed various\\nclassifiers to controllably generate traffic scenarios that comply\\nwith traffic rules and ensure trajectory smoothness. For ex-\\nample, the cumulative rewards learned through reinforcement\\nlearning [46], motion planning cost function [47], STL formu-\\nlas based on traffic rules [48], language-based loss function\\n[49], and driving behavior classes [50] have been designed as\\nclassifier to generate task-conditioned samples.\\nClassifier-free-based. The classifier-free mechanism com-\\nbines unconditional and conditional diffusion models, achiev-\\ning a balance between fidelity and diversity without the need\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n6\\n𝑥\\nҧ𝑥\\nLatent Space\\nForward Process \\n𝜀\\n𝒟\\n…\\nReverse Process \\n𝑋0\\nAdd Noise \\nDenoise \\n𝑋𝑇\\n𝑋𝑇\\n𝑋0\\n𝑋1\\n𝑋𝑇−1\\nFig. 3: Illustration of latent diffusion models. Compared\\nto standard diffusion models, they incorporate a pre-trained\\nencoder E and decoder D, with the diffusion and denoising\\nprocesses operating in latent space rather than pixel or data\\nspace.\\nto train a separate classifier. Additionally, it should be noted\\nthat the conditional diffusion model can employ either a\\nconcatenation mechanism or a cross-attention mechanism. In\\nclassifier-free diffusion guidance [51], the authors jointly train\\na conditional and an unconditional diffusion model, setting the\\ncondition c to ∅for the unconditional model. Then, a weighted\\naverage of the conditional and unconditional scores is used to\\nestimate the score function:\\n˜ϵt = w ϵθ(xt, t, c) + (1 −w) ϵθ(xt, t, ∅)\\n(14)\\nwhere w is also a guidance scale.\\nFor many traffic-related generation tasks, researchers have\\nemployed the classifier-free guidance mechanism to regulate\\nthe diversity of the generated outputs [52], [50], [53], [54],\\n[55], [34]. This approach prevents the outputs from following\\nthe conditional guidance too closely or being constrained too\\ntightly.\\n2) Latent Diffusion Models:\\nThe latent diffusion models (LDMs) [38] incorporate pre-\\ntrained perceptual compression models, VQGAN [56], which\\nconsist of an encoder E and a decoder D, as illustrated\\nin the Fig. 3. This approach enables diffusion models to\\nleverage a lower-dimensional latent space, thereby reducing\\nthe computational burden during training and speeding up\\ninference while maintaining high fidelity in generated outputs.\\nFollowing this work, Blattmann et al. [57] extended LDM\\nto the video latent diffusion model (VLDM) by introducing\\ntemporal layers and finetuning the autoencoder of pre-trained\\nLDM using video data.\\nLDMs have gained attention in intelligent transportation\\nsystems due to their ability to model complex traffic patterns\\nand generate realistic traffic scenarios. This approach has\\nproven particularly useful in simulating traffic flows [41], pre-\\ndicting vehicle trajectories [28], [58], [59], [30], and enhancing\\nautonomous driving systems through the generation of diverse\\nand realistic traffic scenario data [60], [61], [62], [32], [63],\\n[64].\\nChallenges in ITS\\nAbsence of Quality \\nData\\nPrivacy Issues\\nLack of Rare Events\\nDifficult to Model Complex \\nTraffic Dynamics\\nWeak Scalability and \\nGeneralization\\nLack of User-friendly \\nInteraction\\nFig. 4: The challenges in intelligent transportation systems.\\nIII. CHALLENGES AND TECHNIQUES\\nThis section discusses key challenges in ITS and high-\\nlights why diffusion models, as a state-of-the-art generative\\napproach, offer innovative solutions to these challenges. The\\ncomplexity of traffic systems, combined with the inherent\\nuncertainty and variability in traffic data, presents signifi-\\ncant challenges for the development of robust models. These\\nchallenges are further compounded by issues such as poor\\ndata quality, privacy concerns, and the need for scalable\\nsolutions that generalize effectively across different regions\\nand traffic conditions. While various techniques have been\\ndeveloped to address these challenges, diffusion models have\\nemerged as a promising approach due to their advantages:\\nhigh-fidelity generation, controllable generation, strong flex-\\nibility, probabilistic modeling, and multi-modal capabilities.\\nThese strengths enhance the accuracy and robustness of ITS\\nmodels, improving their applicability across diverse scenarios\\nwithin the ITS field. As illustrated in Fig. 4 and Fig. 5, the\\nkey challenges in ITS and the corresponding advantages of\\ndiffusion models are highlighted.\\nA. Challenges in Intelligent Transportation Systems\\nITS is a sophisticated system that integrates advanced tech-\\nnologies and data analytics into transportation infrastructure\\nand management to enhance the efficiency and safety of\\ntransportation networks [2], [9]. ITS encompasses a broad\\nrange of applications, including traffic prediction, autonomous\\ndriving, traffic simulation, and so on, all aimed at improving\\ntransportation services by using large-scale traffic data and\\nautomated systems. However, several challenges affect the\\neffectiveness and implementation of ITS:\\n• Absence of Quality Data. High-quality data are crucial\\nfor training reliable models, particularly in supervised\\nlearning approaches. However, real-world traffic data\\ncollected from traffic sensors, vehicle sensors, or GPS\\ndevices are often noisy, incomplete, or insufficient, lim-\\niting the ability to accurately predict and simulate traffic\\nconditions.\\n• Privacy Issues. The collection of real-world traffic data\\nfrom various sources, such as vehicle sensors, GPS de-\\nvices, and surveillance cameras, raises significant privacy\\nconcerns. In particular, obtaining GPS data for traffic\\nflow-related tasks is often challenging due to the need\\nto protect personal and location information.\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n7\\nAdvantages \\nof DMs\\nHigh-fidelity \\nGeneration\\nControllable \\nGeneration\\nMulti-modal \\nCapabilities\\nStrong \\nFlexibility\\nProbabilistic \\nModeling\\nFig. 5: The advantages of diffusion models.\\n• Lack of Rare Events. Rare but critical events, such as\\naccidents, sudden weather changes, or unexpected road\\nblockages, are difficult to model due to their infrequency.\\nThis scarcity of data on such events makes it challeng-\\ning to develop systems that can effectively handle and\\nrespond to these situations.\\n• Difficult to Model Complex Traffic Dynamics. Traffic\\nsystems are inherently complex, involving spatial and\\ntemporal dynamics at various scales, along with various\\nexternal factors such as holidays, weathers conditions,\\nand local events. Accurately modeling these dynamics\\nand capturing the intricate relationships between different\\nelements in the transportation network remains a chal-\\nlenge.\\n• Weak Scalability and Generalization. Many ITS so-\\nlutions struggle to scale effectively or generalize across\\ndifferent regions and traffic conditions. Solutions that\\nwork well in one location may not perform as effectively\\nin another due to variations in traffic patterns, and other\\nlocal factors.\\n• Lack of User-friendly Interaction. Many current ITS\\ninterfaces and tools are difficult for users to navigate\\nand use effectively. Improving user-friendly interaction is\\nessential to ensure that users can easily understand and\\nutilize the benefits of ITS technologies.\\nB. Advantages of Diffusion Models\\nIn ITS, various deep learning methods have been employed\\nto address key challenges in various traffic tasks. For ex-\\nample, RNNs [65], [66] have proven effective in modeling\\ntemporal relationships in traffic data, and Transformers [37]\\nare widely employed for multi-timestep traffic forecasting.\\nAdditionally, graph-based techniques such as Graph Neural\\nNetworks (GNNs) [67] and Graph Convolutional Networks\\n(GCNs) [68] have emerged as powerful tools for modeling\\ntraffic as graph structures, effectively capturing spatial inter-\\nactions in transportation networks. However, these approaches\\noften require large amounts of labeled data and tend to perform\\npoorly with noise or incomplete data.\\nIn contrast, generative models serve as flexible frameworks\\nthat can not only incorporate architectures such as CNNs,\\nRNNs, and GNNs, enhancing their representational capacity,\\nbut are also effective at traffic data generation and imputation.\\nHowever, generative models such as GANs [69], [70] often\\nsuffer from issues like mode collapse and unstable training,\\nwhile another type of generative models, VAEs [71], [72],\\nfrequently produces lower-quality outputs and exhibits limited\\nexpressiveness in their latent spaces.\\nRecently, diffusion models have emerged as a promising\\nclass of generative models, offering several unique advantages\\nthat make them particularly well-suited for ITS applications:\\n• High-fidelity\\nGeneration.\\nDiffusion\\nmodels\\nhave\\ndemonstrated the ability to generate high-quality and\\ndiverse outputs in traffic-related tasks. Compared to\\nGANs and VAEs, diffusion models exhibit greater ease\\nof training and superior generative capabilities. [45].\\n• Controllable Generation. By incorporating task-related\\nconditions, such as traffic layout, external factors, or task-\\nrequirements text, conditional diffusion models enable\\ncontrollable outputs. This capability is particularly useful\\nfor a wide range of traffic-related applications, such\\nas generating accident data for safety-critical testing or\\ntraining accident detection models.\\n• Strong Flexibility. Diffusion models can be flexibly\\ncombined with other methods, including GNNs, rein-\\nforcement learning, and even other generative models\\nsuch as GANs and VAEs. This adaptability allows them\\nto handle complex spatial-temporal dependency in traffic\\ndata, improve overall model performance, or improve\\nsampling efficiency.\\n• Probabilistic Modeling. The inherent probabilistic nature\\nof diffusion models provides a robust framework for\\nhandling uncertainties and variations in traffic data, which\\nis essential for predicting real-world, variable traffic sit-\\nuations.\\n• Multi-modal Capabilities. Traffic data is inherently\\nmulti-modal,\\nincluding\\ntrajectories,\\nimages,\\nspatial-\\ntemporal graphs, and textual information. LDMs enable\\nmulti-modal input training, making them highly suitable\\nfor various traffic tasks. Moreover, LDMs conditioned on\\nuser-specific text can provide a user-friendly, language-\\nbased interface.\\nIn the following sections, we will explore specific applica-\\ntions of diffusion models in the field of intelligent transporta-\\ntion systems, including autonomous driving, traffic simulation,\\ntraffic forecasting, and traffic safety. These applications will\\ndemonstrate how the advantages of diffusion models support\\ntheir practical implementation in real-world traffic scenarios.\\nIV. DIFFUSION MODELS FOR AUTONOMOUS DRIVING\\nAutonomous driving represents one of the most transfor-\\nmative aspects of ITS. The integration of autonomous ve-\\nhicles (AVs) into ITS can drastically reduce traffic conges-\\ntion, enhance safety, and improve the overall efficiency of\\ntransportation networks. However, achieving full autonomy in\\ndriving poses significant challenges due to the complex and\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n8\\nPerception\\n- Object detection\\n- Semantic segmentation\\n- Object tracking\\n- Data generation\\nPlanning and Decision Making\\n- Robotics\\n- Autonomous vehicle\\nTrajectory Prediction\\n- Human trajectory prediction\\n- Vehicle trajectory prediction\\nAutonomous Driving\\nTrajectory Generation\\nScenario Generation\\n- Image-based generation\\n- Point cloud-based generation\\nTraffic Flow Generation\\nTraffic Simulation\\nDiffusion Model\\nDDPM, DDIM,\\nLDM, ADM, VLDM\\nFDM, VDM\\nTraffic Flow Forecasting\\nTravel Time Estimation\\nTraffic Forecasting\\nTraffic Anomaly Detection\\nTraffic Accident Prevention\\nTraffic Safety\\nFig. 6: Overview of the application of diffusion models in various domains of intelligent transportation systems.\\ndynamic nature of real-world driving environments, which are\\ncharacterized by unpredictable events, diverse road conditions,\\nand varying traffic behaviors [130], [131], [132]. Addressing\\nthese challenges requires advanced models capable of handling\\nuncertainty, learning from vast amounts of data, and making\\nreal-time decisions in a safe and reliable manner. Diffusion\\nmodels, with their ability to model complex distributions,\\nrefine data, and generate high-quality predictions, play a cru-\\ncial role in advancing the capabilities of autonomous driving.\\nHowever, their computational inefficiency poses challenges.\\nThus, many research works focus on accelerating these models\\nto meet real-time requirements.\\nThis section explores the application of diffusion models to\\nvarious aspects of autonomous driving, including perception,\\ntrajectory prediction, and planning. By leveraging the strengths\\nof diffusion models, researchers aim to improve the overall\\nperformance and safety of AVs, making them more adept at\\nnavigating the complexities of modern roadways.\\nA. Perception\\nPerception in autonomous driving systems refers to the\\ntechnologies that enable self-driving vehicles to sense and\\nunderstand their environment [133]. However, sensor data are\\noften affected by intemperate weather, light conditions, and\\nother factors, which introduce noises and pose challenges for\\nperception [134]. With the rapid development of diffusion\\nmodels in the field of computer vision [7], [38], [135],\\nmany researchers are now focusing on their applications in\\nautonomous driving perception. The increasing interest in\\ndiffusion models is attributed to their ability to enhance the\\nclarity and quality of sensor data under diverse conditions\\n[83], [136], [137], as well as their proficiency in modeling\\nuncertainty in perception [138], [31]. By leveraging these\\nstrengths, researchers aim to enhance perception tasks such as\\nobject detection, semantic segmentation, and object tracking,\\nthereby contributing to safer and more reliable autonomous\\nvehicles. In the following part, we present a review of the\\ncurrent advancements in the application of diffusion models\\nfor these perception tasks.\\n1) Object Detection:\\nObject detection involves locating and sizing objects within\\nan image[134]. Specifically, it entails determining the presence\\nof objects and their positions by drawing bounding boxes\\naround them. Recent advancements have introduced diffusion\\nmodels to enhance detection accuracy. For example, Chen et\\nal. [79] first redefined 2D object detection as a denoising\\ndiffusion process conditioned on the corresponding image,\\ntransforming noisy bounding boxes into precise object boxes.\\nNotably, their model demonstrates superior flexibility, enabling\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n9\\nTABLE I: Applications of diffusion models in intelligent transportation systems. To classify existing models, three key criteria\\nare considered: the task, the denoising condition, and the architecture. Additionally, the datasets and open source are provided.\\nThe following abbreviations are used to denote the architectures: DDPM (Denoising Diffusion Probabilistic Model) [16], DDIM\\n(Denoising Diffusion Implicit Model) [73], ADM (Ablated Diffusion Model) [45], LDM (Latent Diffusion Model) [38], LED\\n(LEapfrog Diffusion Model) [74], VLDM (Video Latent Diffusion Model) [57], EDM (Elucidating Diffusion Model) [75],\\nFDM (Flexible Diffusion Model) [76], D3PM (Discrete Denoising Diffusion Probabilistic Model) [77], CARD (Classification\\nand Regression Diffusion Model) [78].\\nPaper\\nTask\\nDenoising Condition\\nArchitecture Datasets\\nYear\\nOpen Source\\nDiffusionDet [79]\\n2D object detection\\nconditioned on image feature\\nDDIM\\nCrowdHuman [80]\\nCOCO [81]\\n2023 ICCV\\nDiffusionDet\\nDetDiffusion [82]\\n2D object detection\\nconditioned\\non\\nperception-\\naware attributes\\nLDM\\nCOCO [81]\\n2024 CVPR\\n——\\nDiffBEV [83]\\nBEV semantic segmentation\\n3D object detection\\nconditioned on BEV feature\\nDDPM\\nnuScenes [84]\\n2024 AAAI\\nDiffBEV\\nDDP [31]\\nBEV map segmentation\\nsemantic segmentation\\ndepth estimation\\nconditioned on image feature\\nDDIM\\nADE20K [85]\\nNYU-DepthV2 [86]\\nKITTI [87] et al.\\n2023 ICCV\\nDDP\\nVPD [88]\\nsemantic segmentation\\nimage segmentation\\ndepth estimation\\nconditioned on text\\nLDM\\nADE20K [85]\\nRefCOCO [89]\\nNYU-DepthV2 [86]\\n2023 ICCV\\nVPD\\nChen et al. [90]\\nmulti-object tracking\\nconditioned on text\\nLDM\\nMOT20 [91] et al.\\n2024 CVPR\\nLtD-MOT\\nLuo et al. [92]\\nmulti-object tracking\\nconditioned on two adjacent\\nraw images\\nDDPM\\nMOT20 [91] et al.\\n2024 AAAI\\nDiffusionTrack\\nXie et al. [93]\\nobject tracking\\nunconditional\\nDDIM\\nGOT-10k [94]\\nLaSOT [95]\\n2024 CVPR\\nDiffusionTrack\\nLuo et al. [96]\\n3D point cloud generation\\nconditioned on shape latent\\n[97]\\nDDPM\\nShapeNet\\n2021 CVPR\\nDPC\\nDiffuMask [39]\\nsemantic segmentation\\nperception data augmentation\\nconditioned on text\\nLDM\\nVOC [98]\\nADE20K [85]\\nCityscapes [99]\\n2023 ICCV\\nDiffuMask\\nDatasetDM [40]\\nperception data augmentation\\nconditioned on text\\nLDM\\nCOCO [81] et al.\\n2023 NIPS\\nDatasetDM\\nMID [27]\\nhuman trajectory prediction\\nconditioned on observed tra-\\njectories\\nDDPM\\nSDD [100]\\nETH [101]\\nUCY [102]\\n2022 CVPR\\nMID\\nLED [74]\\nhuman trajectory prediction\\nspeed up\\nconditioned on observed tra-\\njectories\\nLED\\nSDD [100] et al.\\n2023 CVPR\\nLED\\nSingularTrajectory\\n[103]\\nhuman trajectory prediction\\nspeed up\\nconditioned on observed scene DDIM\\nETH [101] et al.\\n2024 CVPR\\nSingularTrajectory\\nIDM [104]\\nhuman trajectory prediction\\nspeed up\\nconditioned on observed tra-\\njectories\\nconditioned on endpoint\\nDDPM\\nSDD [100] et al.\\n2024 arxiv\\n——\\nLADM [105]\\nhuman trajectory prediction\\nspeed up\\nconditioned on coarse future\\ntrajectory\\nVAE\\nDDPM\\nETH [101] et al.\\n2024 TIM\\n——\\nBCDiff [106]\\nhuman trajectory prediction\\ninstantaneous trajectory pre-\\ndiction\\nconditioned on gate\\nDDPM\\nSDD [100] et al.\\n2024 NIPS\\n——\\nMotionDiffuser\\n[28]\\nmulti-agent prediction\\nconditioned on observed scene\\n, constraints\\nclassifier guidance\\nLDM\\nWOMD [107]\\n2023 CVPR\\n——\\nSceneDiffusion\\n[58]\\nmulti-agent prediction\\nconditioned\\non\\nobserved\\nscene, interval time\\nunconditional\\nLDM\\nArgoverse [108]\\n2023 ITSC\\n——\\nEquidiff [29]\\nvehicle trajectory prediction\\nconditioned on observed tra-\\njectories, interactions\\nDDPM\\nNGSIM [109]\\n2023 ITSC\\n——\\nYao et al. [110]\\nvehicle trajectory prediction\\nconditioned on observed tra-\\njectories, map\\nDDPM\\nArgoverse2 [111]\\n2023 CSIS-IAC ——\\nDiffuser [46]\\nbehavior planning\\nunconditional\\nclassifier guidance\\nADM\\nD4RL [112]\\n2022 ICML\\ndiffuser\\nDecision\\nDiffuser\\n[52]\\ndecision making\\nbehavior planning\\nconditioned on rewards, con-\\nstraints, skills\\nclassifier-free guidance\\nADM\\nD4RL [112]\\n2023 ICLR\\n——\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n10\\nMPD [47]\\nmotion planning\\nunconditional\\nclassifier guidance\\nDDPM\\nPointMass2D\\n2023 IROS\\nmpd\\nDiffusion-ES [113] motion planning\\nunconditional\\ntruncated\\nDDPM\\nnuPlan [114]\\n2024 CVPR\\ndiffusion-es\\nDrive-WM [60]\\nmotion planning\\nmultiview video generation\\nconditioned on adjacent views VLDM\\nnuScenes [84]\\n2024 CVPR\\nDrive-WM\\nGenAD [61]\\nmotion planning\\nmultiview video generation\\nconditioned on past frame, text VLDM\\nWOMD [107] et al.\\n2024 CVPR\\nDriveAGI\\nCTG [48]\\nvehicle trajectory generation\\nconditioned on observed scene\\nSTL-based guidance\\nADM\\nnuScenes [84]\\n2023 ICRA\\nCTG\\nCTG++ [49]\\nmulti-agent trajectory genera-\\ntion\\nconditioned on observed scene\\nlanguage-based guidance\\nADM\\nnuScenes [84]\\n2023 CoRL\\nCTG++\\nDragtraffic [59]\\nmulti-agent trajectory genera-\\ntion\\nconditioned on initial scene,\\ntext\\nLED\\nWOMD [107]\\n2024 IROS\\nDragtraffic\\nDJINN [50]\\nmulti-agent trajectory genera-\\ntion\\nconditioned on arbitrary state\\nclassifier-free guidance\\nbehavior classes guidance\\nEDM\\nArgoverse [108]\\nINTERACTION\\n[115]\\n2024 NIPS\\n——\\nPronovost\\net\\nal.\\n[30]\\nmulti-agent trajectory genera-\\ntion\\nconditioned on map, tokens\\nEDM\\nLDM\\nArgoverse2 [111]\\n2023 NIPS\\n——\\nRempe et al. [53]\\nhuman trajectory generation\\nconditioned on observed scene\\nclassifier-free guidance\\nADM\\nETH [101] et al.\\nnuScenes [84]\\n2023 CVPR\\ntrace pacer\\nFDM [76]\\nimage-based driving scenario\\ngeneration\\nconditioned\\non\\npreviously\\nsampled frames\\nFDM\\nCarla [116]\\n2022 NIPS\\n——\\nGAIA-1 [54]\\nimage-based driving scenario\\ngeneration\\nconditioned\\non\\npast\\nimage,\\ntext, action tokens\\nclassifier-free guidance\\nVDM\\nFDM\\nreal-world dataset\\n2023 arxiv\\n——\\nDriveDreamer [62] image-based driving scenario\\ngeneration\\nconditioned on image, road\\nstructure, text\\nLDM\\nVLDM\\nnuScenes\\n2023 arxiv\\nDriveDreamer\\nDriveDreamer-2\\n[117]\\nimage-based driving scenario\\ngeneration\\nconditioned on structured info\\nby LLMs, text\\nEDM\\nnuScenes [84]\\n2024 arxiv\\nDriveDreamer2\\nPanacea [32]\\nimage-based driving scenario\\ngeneration\\nconditioned on image, text,\\nBEV sequence\\nLDM\\nDDIM\\nnuScenes [84]\\n2024 CVPR\\npanacea\\nDrivingDiffusion\\n[33]\\nimage-based driving scenario\\ngeneration\\nconditioned on key-frame, op-\\ntical flow prior, text, 3D layout\\nVDM\\nLDM\\nnuScenes [84]\\n2023 arxiv\\nDrivingDiffusion\\nWoVoGen [63]\\nimage-based driving scenario\\ngeneration\\nconditioned on past world vol-\\numes, actions, text, 2D image\\nfeature\\nLDM\\nnuScenes [84]\\n2023 arxiv\\nWoVoGen\\nLiDMs [64]\\npoint cloud-based driving sce-\\nnario generation\\nunconditional\\nconditioned on arbitrary data\\nLDM\\nnuScenes [84]\\nKITTI-360 [118]\\n2024 CVPR\\nLiDAR-Diffusion\\nCopilot4D [55]\\npoint cloud-based driving sce-\\nnario generation\\nconditioned on past observa-\\ntions, actions\\nclassifier-free guidance\\nD3PM\\nADM\\nnuScenes [84] et al.\\n2024 ICLR\\n——\\nKSTDiff [119]\\ntraffic flow generation\\nconditioned on urban knowl-\\nedge\\ngraph,\\nregion\\nfeature,\\nvolume estimator\\nCARD\\nreal-world dataset\\n2023 SIGSPA-\\nTIAL\\nKSTDiff\\nDiffTraj [34]\\nGPS trajectory generation\\nconditioned on trip region, de-\\nparture time et al.\\nclassifier-free guidance\\nDDIM,\\nADM\\nreal-world dataset\\n2023 NIPS\\nDiffTraj\\nDiff-RNTraj [35]\\nGPS trajectory generation\\nconditioned on road network\\nDDPM\\nreal-world dataset\\n2024 arxiv\\n——\\nChatTraffic [41]\\ntraffic flow generation\\nconditioned on text\\nLDM\\ntext-traffic\\npairs\\ndataset\\n2024 arxiv\\nChatTraffic\\nRong et al. [120]\\norigin-destination flow genera-\\ntion\\nconditioned on node feature,\\nedge feature\\nDDPM,\\nADM\\nreal-world dataset\\n2023 arxiv\\n——\\nDiffSTG [36]\\ntraffic flow forecasting\\nConditioned on past graph sig-\\nnals, graph structure\\nDDIM\\nPEMS [121] et al.\\n2023 GIS\\nDiffSTG\\nSpecSTG [122]\\ntraffic flow forecasting\\ntraffic speed forecasting\\nconditioned on past graph sig-\\nnals feature, adjacency matrix\\nDDPM\\nPEMS [121] et al.\\n2024 arxiv\\nSpecSTG\\nDiffUFlow [43]\\ntraffic flow forecasting\\nconditioned on pass feature\\nmap, coarse-grained flow map,\\nsemantic features\\nDDPM\\nreal-world dataset\\n2023 CIKM\\n——\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n11\\nXu et al. [123]\\ntraffic flow forecasting\\nunconditional\\nDDPM\\nreal-world dataset\\n2023 ICASSP\\n——\\nST-SSPD [124]\\ntraffic flow forecasting\\nconditioned\\non\\npast\\ndata\\npoints,\\ntemporal\\nencoding,\\nnode identifier\\nDDPM\\nMETR-LA [125] et\\nal.\\n2023 MobiArch ——\\nDifforecast [126]\\ntraffic flow forecasting\\nimage generation\\nconditioned on past S-T image DDPM\\nreal-world dataset\\n2023 BigData\\n——\\nLin et al. [44]\\norigin-destination travel time\\nestimation\\nconditioned on origin, destina-\\ntion, departure time\\nDDPM\\nreal-world dataset\\n2023 MOD\\n——\\nDiffTAD [127]\\ntrajectory anomaly detection\\nunconditional\\nDDIM\\nNGSIM [109]\\n2024 KBS\\n——\\nVAD [128]\\nvideo anomaly detection\\nunconditional\\nconditioned on original fea-\\ntures\\nLDM,\\nDDIM\\nCUHK Avenue [129]\\net al.\\n2023 ICCV\\n——\\nAdVersa-SD [42]\\naccident video understanding\\naccident preventing\\nconditioned on text, bounding\\nboxes\\nLDM\\nMM-AU [42]\\n2024 CVPR\\nMM-AU\\na dynamic number of boxes and iterative evaluation during\\ninference. Additionally, Wang et al. [82] presented a pioneer-\\ning framework that integrates diffusion models and perceptive\\nmodels to enhance data generation quality and perception\\ncapabilities. The framework leverages perception-aware at-\\ntributes as conditions and employs perception-aware loss as\\na form of supervision during the image generation process.\\nThis conditional approach enables the generation of images\\ntailored to specific perceptual criteria, thereby improving the\\nperformance of downstream tasks such as object detection.\\n2) Semantic Segmentation:\\nSemantic segmentation involves classifying each pixel in\\nan image into a predefined category [134]. Bird’s Eye View\\n(BEV) perception holds significant importance in the domain\\nof autonomous driving perception, especially for semantic\\nsegmentation. Recent works have utilized the diffusion model\\nto enhance BEV perception [83], [138], [136]. Notably, Zhou\\net al. [83] first applied conditional diffusion models to denoise\\nand refine BEV features, addressing noise and distortions from\\ncamera parameters and LiDAR scans, significantly improving\\nBEV semantic segmentation and 3D object detection. In detail,\\nthree BEV features serve as conditions for the diffusion model,\\nenabling progressive denoising and enhancing fine-granularity\\ndetails such as object boundaries and shapes.\\nBeyond BEV feature conditioning [83], image features\\n[31] and text [88] have also been employed as conditions\\nin semantic segmentation tasks. Ji et al. [31] introduced\\nDDP, a noise-to-map method that progressively removes noise\\nfrom a Gaussian distribution, guided by image features, to\\nproduce visual perception. DDP stands out for its dynamic\\ninference capabilities, and natural awareness of the perception\\nuncertainty. Additionally, DDP is easy to generalize to most\\ndense visual perception tasks without needing task-specific\\ndesigns. Motivated by the compelling generative semantic\\nof a text-to-image diffusion model [38], Zhao et al. [88]\\nproposed VPD, a framework utilizing pre-trained text-to-image\\ndiffusion models for visual perception tasks. By prompting\\nthe denoising decoder with textual inputs and refining text\\nfeatures with an adapter, VPD aligns visual content with text\\nprompts and leverages cross-attention maps for guidance. This\\nwork suggests that pre-trained text-to-image diffusion models\\ncan efficiently adapt to downstream visual perception tasks,\\nbridging generative models and visual perception.\\n3) Object Tracking:\\nObject tracking involves locating an object or multiple\\nobjects in a video, maintaining their identities, and tracking\\ntheir trajectories over time [139]. Chen et al. [90] addressed\\nthe challenge of trajectory length imbalance in multiple object\\ntracking (MOT) datasets by proposing Stationary and Dynamic\\nCamera View Data Augmentation (SVA and DVA) and a\\nGroup Softmax module. Specifically, the DVA employs a con-\\nditional diffusion model to alter scene backgrounds, helping\\nthe network focus more on pedestrian features. This approach\\neffectively alleviate the impact of long-tail distribution, en-\\nhancing tracking system effectiveness. Additionally, Luo et al.\\n[92] proposed a noise-to-tracking framework, which formu-\\nlates object detection and association jointly as a consistent\\ndenoising diffusion process from paired noise boxes to paired\\nground-truth boxes, enabling consistency between detection\\nand tracking. In contrast, Xie et al. [93] introduced a novel\\nnoise-to-target tracking paradigm, employing a point set-based\\ndenoising diffusion process for dynamic and precise target\\nlocalization, offering superior self-correction and appearance\\nvariation handling capabilities. This method also simplifies the\\npost-processing, enabling real-time tracking capabilities.\\n4) Perception Data Generation:\\nRecent advancements [39], [40] have highlighted the ef-\\nficacy of diffusion models in synthesizing images and their\\ncorresponding annotations. Specifically, Wu et al. [39] have\\nconcentrated on semantic segmentation, utilizing a text-guided\\npre-trained diffusion model to generate synthetic images with\\npixel-level semantic mask annotations. Building upon this\\nwork, Wu et al. [40] presented a dataset generation model\\nthat also leverages the knowledge learned by pre-trained\\ndiffusion models to produce diverse perception annotations. It\\nemphasizes a unified perception decoder, which can be trained\\nwith minimal human-labeled data, to generate extensive high-\\nfidelity images paired with various perception annotations\\nincluding depth, segmentation, and human pose estimation.\\n3D point cloud data, another form of perception data, has\\nalso seen significant progress in generative modeling. Several\\nstudies have applied diffusion models for the generation of\\n3D point clouds. Luo et al. [96] introduced a novel generative\\nmodel by treating 3D point cloud generation as a reverse\\ndiffusion process. The model conditions on a shape latent,\\nand demonstrates flexibility and robustness in generating high-\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n12\\nquality, realistic 3D point clouds. Following this work, Sun\\net al. [140] addressed the vulnerability of 3D point cloud\\nrecognition models to adversarial attacks by leveraging the\\ndiffusion model designed in [96] as the base model for the\\nadversarial point cloud purification.\\nB. Trajectory Prediction\\nTrajectory prediction in autonomous driving systems in-\\nvolves using past states of traffic participants in a given scene\\nto forecast their future states [141]. The primary challenges\\ninclude the uncertainty and multi-modality of future behavior,\\nthe complex interactions between traffic participants, and\\nenvironmental influences like road geometry [141], [142]. In\\nrecent years, diffusion models have emerged as a promising\\napproach for trajectory prediction due to their ability to\\ncapture the inherent uncertainty and multi-modality of human\\nbehavior and driving behavior. Additionally, diffusion models\\ncan flexibly integrate map information, constraints, and other\\nrelevant factors.\\n1) Human Trajectory Prediction:\\nTo address the challenges of unstable training and unnatural\\ntrajectories in human trajectory prediction, Gu et al. [27]\\nproposed Motion Indeterminacy Diffusion (MID). This method\\nfirst leverages a diffusion model to transform trajectory pre-\\ndiction into a reverse diffusion process, achieving a balance\\nbetween prediction diversity and determinacy by adjusting the\\nlength of a parameterized Markov chain. However, despite\\nits promising performance, MID’s 17-second runtime for 100\\ndiffusion steps is impractical for real-time applications in\\nautonomous driving systems. Following this pioneering work,\\nmany subsequent studies have focused on the application of\\ndiffusion models in trajectory prediction [74], [103], [104],\\n[105], [143], [144]. Notably, to address the time-consuming\\nproblem, Mao et al. [74] introduced a trainable leapfrog ini-\\ntializer to bypass multiple denoising steps, enabling real-time\\nprediction. Specifically, they employed a two-stage training\\nstrategy: the first stage trains a denoising module similar to\\nMID [27], while the second stage optimizes the leapfrog ini-\\ntializer using the frozen denoising module. During inference,\\nthe leapfrog initializer allows denoising to start directly from\\nthe last few steps, significantly reducing computational time.\\nLater, Bae et al. [103] proposed a unified model, Singular-\\nTrajectory, introducing an adaptive anchor mechanism and\\nleveraging a diffusion-based predictor to enhance prototype\\npaths through a cascaded denoising process. Moreover, the\\nadaptive anchor functions as a good initializer similar to\\n[74], to speed up the denoising process. Additionally, Liu\\net al. [104] decoupled trajectory prediction uncertainty into\\nintention uncertainty and action uncertainties through two\\ndiffusion processes. They also introduced a PriorNet mod-\\nule for estimating prior noise distribution, reducing diffusion\\nsteps and consequently cutting inference time by two-thirds.\\nAnother study is LADM [105], which integrates the VAEs\\nwith diffusion models. This combination enables the diffusion\\nmodels to refine future trajectories generated by the VAE in\\na low-dimensional space, enhancing prediction accuracy and\\nsupporting real-time inference.\\nInstantaneous trajectory prediction presents another chal-\\nlenge in human trajectory prediction due to the need for\\naccurate predictions based on very limited observational data\\n[145]. Li et al. [106] addressed this challenge by utilizing\\nbidirectional diffusion models to generate unobserved his-\\ntorical trajectories and future trajectories step-by-step, effec-\\ntively leveraging complementary information between them.\\nFurthermore, they proposed a gate mechanism to balance the\\ncontributions between the observed and future trajectories.\\n2) Vehicle Trajectory Prediction:\\nVehicle trajectories are often governed by physical rules and\\nconstraints. Several works have incorporated these constraints\\nas classifiers [28] or conditions [58] into diffusion models,\\nthereby enabling physically feasible trajectory predictions.\\nJiang et al. [28] utilized a compressed trajectory representation\\nusing PCA-base latent diffusion models for multi-agent joint\\nmotion prediction. Additionally, they introduced constrained\\nsampling, enabling controlled predictions based on differ-\\nentiable cost functions as a classifier. Similarly, Westny et\\nal. [146] integrated differential motion constraints into the\\ndiffusion model output, generating realistic future trajectories.\\nAnother work by Balasubramanian et al. [58] employed con-\\nditional latent diffusion models with temporal constraints to\\npredict the motion of vehicles in a traffic scenario, while also\\nproviding an unconditional mode as a scene initializer.\\nIn addition to these advancements, other works have com-\\nbined diffusion models with other network architectures. For\\nexample, Chen et al. [29] noticed that previous works did\\nnot fully exploit the geometric properties of trajectory. They\\ncombined the diffusion models and equivariant transformer\\nas an SO(2)-equivariant diffusion model for vehicle trajectory\\nprediction, thereby fully utilizing the geometric properties of\\nlocation coordinates. Moreover, they utilized Recurrent Neural\\nNetworks and Graph Attention Networks to capture social\\ninteractions among vehicles. Additionally, Yao et al. [110] ex-\\ntended the MID model [27] for vehicle trajectory prediction by\\nusing Graph Neural Networks to capture interactions between\\nagents and road elements.\\nC. Planning and Decision-making\\nIn autonomous driving systems, planning and decision-\\nmaking are crucial components. Planning entails generating a\\nsafe and comfortable trajectory based on the vehicle’s current\\nstate, and environmental information [132]. Decision-making\\ninvolves selecting the optimal high-level action by considering\\nthe final goal, the environment, traffic rules, and ensuring\\nsafety [147]. Diffusion models have shown promise potential\\nin enhancing these components, particularly in improving\\ngeneralization and flexibly integrating with other algorithms.\\nDiffusion models exhibit robust generalization to new envi-\\nronments with unseen obstacles [47], [60], which is essential\\nfor dynamic environments. Additionally, diffusion models can\\nflexibly integrate with other algorithms, enhancing their effec-\\ntiveness. Since the autonomous vehicle is a specialized form\\nof robotics, we examine the topic within both the robotics and\\nautonomous driving fields.\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n13\\n1) Planning and Decision-making in Robotics:\\nDiffusion models can flexibly combine with motion-\\nplanning approaches, such as reinforcement learning (RL) [46]\\nor trajectory optimization algorithms [47]. Specifically, Janner\\net al. [46] proposed the Diffuser model, which combines\\nRL with classifier-guided diffusion models [45] to improve\\nplanning and decision-making processes. The Diffuser itera-\\ntively denoises trajectories to generate plans, with the sam-\\npling process guided by gradients of the cumulative rewards\\nlearned through RL. In contrast, the follow-up work, Decision\\nDiffuser [52], employed classifier-free diffusion guidance [51]\\nto generate a sequence of future states, conditioning on re-\\nwards, various constraints, and behavior skills. This approach\\ndoesn’t require a separately trained classifier but learns both a\\nconditional and an unconditional model for the noise. While\\nthe Decision Diffuser [52] demonstrates that classifier-free\\nguidance performs better than classifier guidance in practice,\\nthe Diffuser [46] enables planning for new rewards without\\nretraining. A different approach was presented by Carvalho\\net al. [47], who utilized learned diffusion priors to initialize\\nan optimization-based motion planner. This method not only\\nimproves and accelerates the planning process but also fosters\\ngreater diversity in trajectory planning.\\n2) Planning and Decision-making in AVs:\\nDiffusion models have been employed to optimize the\\nplanning process in autonomous driving. Yang et al. [113]\\nfirst combined gradient-free evolutionary search with diffusion\\nmodels to enhance planning for autonomous driving. Unlike\\nconventional methods that use naive Gaussian perturbations,\\nthis approach leverages a truncated diffusion-denoising process\\nto mutate trajectories in the evolutionary search process,\\nensuring that the resulting mutations remain within the data\\nmanifold.\\nAdditionally, several studies have leveraged diffusion mod-\\nels to generate out-of-distribution driving scenarios, thereby\\nimproving planning performance. For example, Wang et al.\\n[60] leveraged diffusion models to generate multi-view future\\nstate videos, enabling the prediction of future events and\\nrisk assessment through these videos, thereby enhancing the\\nsafety of end-to-end planning. Furthermore, evaluations on\\ncounterfactual events demonstrate that their model improves\\ngeneralization capabilities in out-of-distribution scenarios. An-\\nother video generative model for motion planning is GenAD\\n[61], which has the ability to generalize across diverse and\\nunseen driving datasets in a zero-shot manner. Moreover,\\nGenAD can be adapted for various tasks, including language-\\nconditioned prediction, action-conditioned prediction, and mo-\\ntion planning.\\nRL has seen widespread application in planning and\\ndecision-making for autonomous driving [148], [149]. Recent\\nadvancements have incorporated diffusion models to improve\\nthe performance and sampling efficiency of RL algorithms\\n[150]. For example, Wang et al. [151] introduced Diffusion-\\nQL, which integrates a conditional diffusion model as the\\npolicy and combines it with Q-learning. Subsequently, Liu et\\nal. [152] employed conditional diffusion models as the actor in\\nan Actor-Critic decision-making framework, facilitating policy\\nexploration and learning.\\nV. DIFFUSION MODELS FOR TRAFFIC SIMULATION\\nTraffic simulation is a critical tool for developing and\\ntesting intelligent transportation systems, allowing researchers\\nand engineers to model, analyze, and simulate the behav-\\nior, interactions or movement of traffic participants within a\\ntransportation network [153], [10]. Universal methods, such\\nas rule-based or data-driven models often struggle to capture\\nthe complexity and variability of real-world traffic dynamics\\n[154]. These methods also lack the controllability to generate\\ndiverse and customizable scenarios, which are essential for\\nsafety-critical testing [155]. Furthermore, traffic data are often\\nunavailable or suffer from privacy concerns, posing additional\\nchallenges for data-driven traffic simulations.\\nDiffusion models, a type of generative model, have recently\\nemerged as a promising solution for overcoming these chal-\\nlenges in traffic simulation. They are particularly effective\\nat learning the distributions of traffic patterns, enabling the\\ngeneration of high-fidelity simulations that closely mimic real-\\nworld situations. Moreover, diffusion models offer signifi-\\ncant advantages in terms of controllability, allowing users to\\ncustomize generated traffic scenarios, trajectories, and flows\\naccording to specific conditions or guidance.\\nThis section explores the applications of diffusion models\\nin traffic simulation, with a focus on their roles in traffic\\ntrajectory generation, traffic scenario generation, and traffic\\nflow generation. We also examine recent advancements in this\\nfield and discuss how diffusion models are being integrated\\nwith other technologies to enhance their effectiveness and\\napplicability in intelligent transportation systems.\\nA. Traffic Trajectory Generation\\nTraffic trajectory generation, which focuses on creating\\nrealistic and compliant paths for vehicles and pedestrians in\\ntraffic simulations, is essential for the development and testing\\nof intelligent transportation systems. Traditional heuristic-\\nbased models [156] enable vehicles to adhere to specific\\ntrajectories and traffic rules, but they often struggle to capture\\nthe complexity of real-world driving behaviors. In contrast,\\ndata-driven approaches can produce more realistic and human-\\nlike behaviors [154], but they often lack the controllability to\\ngenerate user-defined trajectories. Diffusion models stand out\\nfor their ability to model real-world traffic data effectively\\nby capturing the complexity and variability of traffic patterns.\\nAdditionally, guidance-based diffusion models enhance con-\\ntrollability and flexibility during the inference stage. These\\nstrengths of diffusion models make them highly suitable for\\ngenerating both realistic and controllable trajectories. Recent\\nresearch has increasingly utilized these advanced diffusion\\nmodels to improve the realism and controllability of agent\\ntrajectory generation, offering significant advancements in\\ntraffic simulation.\\nSeveral studies have utilized classifiers to enhance con-\\ntrollability during sampling, such as using Signal Temporal\\nLogic (STL) rules classifiers [48] or language-based classifiers\\n[49]. Zhong et al. [48] proposed a classifier-guided conditional\\ndiffusion model to produce realism and controllable driving\\ntrajectories. Unlike the approach of training a reward function\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n14\\nas guidance [46], they utilized STL [157] to guide sampling\\nto generate trajectories that are both physically feasible and\\ncompliant with rules. Building on this, Zhong et al. [49] further\\nadvanced their model by incorporating language instructions\\nto guide the trajectory sampling process, thereby enhancing\\nuser-friendliness. Specifically, they employed a large language\\nmodel (LLM) to convert user language instructions into a\\nguidance loss, replacing the STL-based guidance loss used\\nin their earlier work [48]. In contrast, wang et al. [59]\\nenhanced user-friendliness and controllability by introducing\\nuser-defined context through the cross-attention mechanism.\\nAdditionally, they utilized a regression model for initial scene\\ncreation to enhance realism.\\nMeanwhile, recent research has increasingly focused on\\nmulti-agent joint trajectories generation, aiming to generate\\nmore interactive trajectories [48], [59], [50], [30], [158], [159].\\nNotably, Niedoba et al. [50] employed both classifier guidance\\nand classifier-free guidance diffusion models to generate joint\\ntrajectories for all agents in a traffic scene. They trained a\\nbehavior classifier as guidance for conditional sampling, and\\ncontrolled the strength of conditioning through classifier-free\\nguidance, thereby enabling the flexible sampling of diverse\\nbehavior modes. Additionally, Pronovost et al. [30] integrated\\nlatent diffusion with object detection and trajectory regression\\nto simultaneously generate poses and trajectories for all agents,\\nconditioned on a map and scenario tokens.\\nSome research has focused on human trajectory simulation.\\nFor example, Rempe et al. [53] introduced a controllable\\npedestrian simulation system that integrates a trajectory dif-\\nfusion model (TRACE) for generating pedestrian paths and\\na physics-based humanoid controller (PACER) to establish a\\nclosed-loop system. Furthermore, the guided TRACE model\\nallows users to constrain trajectories based on target way-\\npoints, desired speeds, specified social groups, and other\\nfactors.\\nB. Traffic Scenario Generation\\nTraffic scenario generation involves creating a temporal\\nsequence of traffic scene elements that simulate the actions,\\ninteractions, and events of the participating agents within a\\ndriving environment [160], [155]. It plays a significant role\\nin enhancing the efficiency and safety of intelligent trans-\\nportation systems, as it enables the creation of diverse and\\nsafety-critical scenarios. However, traffic scenario generation\\nfaces two critical challenges: Consistency and Controllability\\n[161], [32]. Consistency ensures that the generated scenarios\\nare temporally and multi-view coherent, maintaining logical\\nrelationships across time and from different viewpoints within\\nthe scene. Controllability refers to the ability to guide the gen-\\nerated scenarios to align with specific annotations, conditions,\\nor objectives. Diffusion models have emerged as a powerful\\ntool to address these challenges. Fundamentally, they can\\neffectively model complex data distributions, achieving high\\nlevels of realism. Additionally, diffusion models can be flexi-\\nbly combined with various approaches, such as cross-view and\\ncross-frame attention mechanisms, post-processing techniques,\\nand multi-stage generation processes, to ensure both temporal\\nand multi-view consistency. Moreover, controllable diffusion\\nmodels, like ControlNet [162], can incorporate multimodal\\nconditioning controls, including layout, text, segmentation, and\\nother inputs, to fine-tune large diffusion models like Stable\\nDiffusion [38], thereby enhancing the controllability of driving\\nscenario generation.\\nWith the rapid development of diffusion models in image\\n[38] generation, video generation [57], [163], [164], and\\nworld models [165], [161], diffusion models offer a powerful\\nframework for generating high-quality, consistent, and control-\\nlable traffic scenarios. In the following part, we will explore\\nthe current advancements in traffic scenario generation from\\ntwo different perspectives: image-based and point cloud-based\\napproaches.\\n1) Image-based Driving Scenario Generation:\\nRecent advancements in diffusion models have led to signif-\\nicant progress in generating realistic and controllable image-\\nbased driving scenarios. For example, Harvey et al. [76]\\nproposed a Flexible Diffusion Model (FDM), that enables\\nthe model to sample any arbitrary subset of video frames\\nconditioned on others, thereby optimizing frame sampling\\nschedules and effectively handling long-range temporal de-\\npendencies. Building on this foundational work in temporal\\nsequence modeling, Hu et al. [54] integrated a video diffusion\\ndecoder with a world model to create high-fidelity and long-\\nterm driving scenarios. The world model [165] facilitates the\\nunderstanding of the environment and the prediction of reason-\\nable object interactions, while the diffusion decoder translates\\nlatent representations into high-quality videos with realistic\\ndetail. Additionally, it offers fine-grained control over the sim-\\nulation environment through action and language conditioning.\\nSimilarly, DriveDreamer [62] focused on generating high-\\nquality, controllable driving videos and policies that align with\\nreal-world traffic structures. Building upon the DriveDreamer\\nfoundation, Zhao et al. [117] proposed the DriveDreamer-\\n2 framework, which leverages the power of finetuned-LLMs\\n[166], [167] to translate user descriptions into agent trajecto-\\nries. Additionally, it employs an HDMap generator to produce\\nhigh-definition (HD) maps. These trajectories and HD maps\\nare then used as structured conditions to ultimately generate\\nmulti-view driving scenes.\\nNext, we discuss the multi-view driving video generation.\\nWen et al. [32] integrated a pre-trained diffusion model and\\na decomposed 4D attention mechanism within a two-stage\\ngeneration pipeline to generate multi-view driving scenario\\nvideos with temporal consistency. The first stage trains a multi-\\nview image generator, while the second stage expands these\\nimages along the temporal axis to create video sequences. Li\\net al. [33] proposed DrivingDiffusion for generating spatially\\nand temporally consistent multi-view videos of complex urban\\ndriving scenes. Another important work is WoVoGen [63],\\nwhich leverages 4D world volumes as foundational elements\\nfor multi-camera street-view video generation, addressing key\\nchallenges in ensuring intra-world consistency and inter-sensor\\ncoherence. Furthermore, these approaches [32], [33], [63]\\nemployed the ControlNet [162] framework to achieve Fine-\\ngrained control, conditioned on the BEV sequences or 3D\\nlayout or world volume-aware 2D image feature.\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n15\\n2) Point Cloud-based Driving Scenario Generation:\\nMeanwhile, the generation of realistic driving scenarios\\nfrom point cloud data has gained significant attention due to its\\nimportance in traffic simulation [64], [55], [168]. Notably, Ran\\net al. [64] concentrated on generating realistic LiDAR driving\\nscenes from a latent space that incorporates geometric priors to\\ncapture realism, enhancing pattern realism, geometry realism,\\nand object realism. Furthermore, their approach leverages a\\npre-trained model, CLIP [169], to enable controllability under\\narbitrary conditions, including text prompts, semantic maps,\\nand camera views. Zhang et al. [55] proposed Copilot4D for\\nbuilding unsupervised world models. This approach leverages\\nVQVAE [170] to tokenize point cloud observations, and com-\\nbines MaskGIT [171] with discrete diffusion models [77] to\\nefficiently decode and denoise tokens in parallel, enhancing\\npoint cloud-based driving scene forecasting.\\nC. Traffic Flow Generation\\nTraffic flow generation involves creating synthetic data that\\nmodels the movement of vehicles or pedestrians across specific\\nregions within a transportation network [10]. These synthetic\\ndata are crucial for macroscopic simulations [153], as model-\\ning real-world human mobility trajectories often suffers from\\nprivacy concerns. However, traffic flow generation presents\\nseveral challenges. Firstly, the non-independent and identically\\ndistributed nature of trajectories between different areas and\\nthe inherent stochasticity of human behavior make traffic pat-\\ntern modeling complicated. Secondly, traffic flow influenced\\nby external factors such as traffic conditions, departure times,\\nand local events, adds further complexity. Diffusion models are\\nadept at handling stochasticity and uncertainty, making them\\nparticularly well-suited for traffic flow generation. Further-\\nmore, diffusion models can be flexibly combined with various\\napproaches, such as GCNs, RNNs, and attention mechanisms,\\nto model the spatiotemporal dependencies of traffic data.\\nAdditionally, diffusion models enable conditional generation\\nbased on text, road networks, external factors, and other inputs,\\nallowing for the generation of customized traffic flow patterns.\\nTo explore how diffusion models have been applied in traffic\\nflow generation, we review several notable advancements in\\nthe field.\\nEffectively capturing spatiotemporal dependencies is crucial\\nin traffic flow generation, given that traffic flow data typi-\\ncally involves spatiotemporal information. Recently, DiffSTG\\n[36] and ChatTraffic [41] introduced a GCN-based architec-\\nture to effectively model spatiotemporal dependencies, while\\nTimeGrad [172] employs an RNN, and both CSDI [173] and\\nSTPP [174] utilize attention mechanisms for this purpose. In\\ncontrast, Zhou et al. [119] proposed the KSTDiff model, which\\nleverages an urban knowledge graph (UKG) to capture the\\nspatiotemporal dependencies of urban flow. Additionally, they\\ndeveloped a volume estimator that integrates region-specific\\nfeatures to guide the diffusion model’s sampling process,\\nenabling the accurate generation of urban flow across different\\nregions. Notably, ChatTraffic [41] also presented the first text-\\nto-traffic generation framework. This approach incorporates\\nBERT [175], a pre-trained text encoder, to extract text em-\\nbedding, which serves as conditions to guide the generation\\nof traffic flow.\\nMany researchers have focused on GPS trajectory gener-\\nation [34], [35] due to the ability of GPS trajectory data to\\nreflect traffic flow, which is crucial in ITS. Specifically, Zhu et\\nal. [34] proposed a Traj-UNet structure within diffusion mod-\\nels for spatial-temporal modeling and embedding conditional\\ninformation such as the trip region and departure time, thereby\\nenabling controlled GPS trajectory generation. Subsequently,\\nDiff-RNTraj [35] generates trajectories conditioned on the\\nroad network, with these trajectories represented in a hybrid\\nformat where each point is defined by a discrete road segment\\nand a continuous moving rate.\\nAdditionally, Rong et al. [120] proposed a cascaded graph\\ndenoising diffusion method to capture the joint distribution of\\nnodes and edges within the origin-destination (OD) network.\\nThis method generates region-level OD flow for a new city\\nby first generating the topology structure and then the corre-\\nsponding mobility flows.\\nVI. DIFFUSION MODELS FOR TRAFFIC FORECASTING\\nTraffic forecasting is a critical component of intelligent\\ntransportation systems, facilitating the optimization of traffic\\nflow, the reduction of congestion, and the enhancement of\\noverall transportation efficiency. It involves predicting future\\ntraffic conditions, such as traffic flow rates and travel times, by\\nanalyzing historical data. However, traffic forecasting presents\\nsignificant challenges due to the inherent complexities of\\ntransportation networks and concerns regarding the quality of\\ntraffic data [176].\\nRecent advancements in traffic forecasting have increas-\\ningly focused on leveraging diffusion models to address these\\nchallenges. Diffusion models have demonstrated significant\\npromise in capturing the complex and dynamic nature of\\ntraffic systems. By incorporating diffusion processes, these\\nmodels effectively account for the uncertainties and noise\\npresent in traffic data, making them particularly well-suited for\\nhandling incomplete or imperfect traffic datasets. As a result,\\nthe application of diffusion models in traffic forecasting is\\ngaining momentum, especially in tasks such as traffic flow\\nprediction and travel time estimation.\\nA. Traffic Flow Forecasting\\nTraffic flow forecasting entails predicting the future state of\\ntraffic on transportation networks, including vehicle speeds,\\ntraffic density, and flow rates, based on historical data and\\nother relevant factors [176]. While significant progress has\\nbeen made in this field, accurately forecasting traffic flow\\nremains challenging due to the inherent uncertainties in flow\\ndistributions and the complex external factors that impact\\nforecasting performance. Additionally, the collected urban\\nflow data is often unreliable, noisy, and sometimes incomplete,\\nfurther complicating the prediction task. Recent advancements\\nhave focused on addressing these challenges by leveraging\\ndiffusion models, which have shown promise in recovering\\ntraffic data [177], capturing the intricate spatial-temporal de-\\npendencies and handling the uncertainties associated with\\ntraffic flow data [36].\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n16\\nGraph-based approaches have proven effective in extracting\\nspatial correlations in traffic networks [3], [4]. Naturally,\\nintegrating graph-based networks with diffusion models can\\nenhance the modeling of intricate spatial-temporal depen-\\ndencies. Wen et al. [36] proposed a GCN-based network\\ncalled UGnet, which effectively captures multi-scale tempo-\\nral dependencies and spatial correlations, thus significantly\\nadvancing traffic flow prediction tasks. However, GCN-based\\nmethods are computationally expensive, particularly for large-\\nscale traffic networks. To address this issue, Lin et al. [122]\\nincorporated a fast spectral graph convolution, which alleviates\\nthe computational inefficiencies of existing models.\\nDiffusion models have also been leveraged for fine-grained\\ntraffic flow inference from noisy and incomplete data. For\\nexample, Zheng et al. [43] and Xu et al. [123] focused on\\nleveraging diffusion models for fine-grained traffic flow in-\\nference from noisy and incomplete coarse-grained traffic flow\\nmaps. Specifically, Zheng et al. [43] developed a transformer-\\nbased spatial-temporal feature extraction network along with\\na semantic feature extraction network designed to capture\\nexternal factors and land features. These two types of features,\\nserving as conditions for conditional diffusion models, facil-\\nitate the robust modeling of dynamic and long-range spatial-\\ntemporal dependencies. In contrast, Xu et al. [123] employed\\na relaxed structural constraint and a disentangled scheme for\\nflow map and external factor learning. Additionally, Lablack\\net al. [124] proposed a vectorized state space module to\\ndecompose the historical signal of an ego-graph into the\\nfrequency domain, thereby reducing the impact of noise and\\ndata imperfections present in real-world traffic data.\\nLastly, recent research has introduced novel approaches\\nthat transform the traffic flow forecasting task into a new\\ndomain. Chi et al. [126] introduced a novel concept of a space-\\ntime image to incorporate physical meanings of traffic state\\nvariables. They transformed the traffic flow forecasting task\\ninto a conditional image generation problem by leveraging\\ndiffusion models.\\nB. Travel Time Estimation\\nOrigin-Destination (OD) travel time estimation aims to\\npredict the time required to travel between a specific start-\\ning point (origin) and a destination within a transportation\\nnetwork. This task is complex due to the variability in travel\\ntimes for the same OD pair, influenced by factors such as\\ntraffic conditions and route choices [178]. Multiple historical\\ntrajectories with different travel times may connect an OD pair,\\nand these trajectories can differ significantly, making accurate\\nprediction challenging. To address this, it is crucial to mitigate\\nthe impact of outlier trajectories. The conditional diffusion\\nmodel provides a promising solution to this challenge. For\\nexample, Lin et al. [44] proposed a conditional diffusion-based\\nmodel for OD travel time estimation, which leverages his-\\ntorical trajectories. The model employs a pixelated trajectory\\nrepresentation and is conditioned on origin, destination, and\\ndeparture time (ODT) queries to capture correlations between\\nOD pairs and historical travel patterns, thereby aiding in the\\nfiltering of outlier trajectories.\\nVII. DIFFUSION MODELS FOR TRAFFIC SAFETY\\nTraffic safety is a critical area of research within intelli-\\ngent transportation systems, focusing on minimizing the risks\\nassociated with vehicular travel and reducing the frequency\\nand severity of traffic accidents [179]. Recent advancements\\nin diffusion models have opened new avenues for enhancing\\ntraffic safety. These models excel in generating high-quality\\nsamples from complex distributions and producing customiz-\\nable samples conditioned on text descriptions, addressing the\\nchallenge of limited traffic accident or anomaly data. They\\nhave been effectively applied to various aspects of traffic\\nsafety, including traffic anomaly detection and accident pre-\\nvention. The successful detection of traffic anomalies and the\\nprevention of accidents are crucial for maintaining safe and\\nefficient transportation systems.\\nA. Traffic Anomaly Detection\\nTraffic anomaly detection aims to identify irregular patterns\\nin traffic data that deviate from normal behavior, such as\\nunusual vehicle activity, accidents, or irregular traffic flow\\npatterns. Detecting these anomalies is important for traffic\\nmanagement and safety. However, this task faces significant\\nchallenges due to the lack of large-scale labeled anomaly\\ndata and the difficulty in precisely defining the boundary\\nbetween normal and abnormal patterns [180], [181]. Diffusion\\nmodels, known for their powerful generative capacity, offer a\\npromising solution. These models are well-suited for traffic\\nanomaly detection, as anomalous events often exhibit a level\\nof randomness and uncertainty that are inherently similar to\\nthe diffusion process. By leveraging diffusion models to recon-\\nstruct normal traffic patterns from Gaussian noise, researchers\\ncan effectively identify samples that deviate from these normal\\npatterns, thereby flagging them as anomalies.\\nBuilding on this idea, Li et al. [127] formalized the ve-\\nhicle trajectory anomaly detection problem as a noisy-to-\\nnormal paradigm, which leverages the generative capabilities\\nof diffusion models to reconstruct near-normal trajectories and\\neffectively identifies anomalies by comparing the difference\\nbetween a query trajectory and its reconstruction. Similarly,\\nYan et al. [128] utilized diffusion models to learn the dis-\\ntribution of normal samples for video anomaly detection.\\nSpecifically, they employed two denoising diffusion modules\\nto learn motion and appearance features from normal samples,\\nensuring the generative quality of the produced features.\\nB. Traffic Accident Prevention\\nTraffic accident prevention requires a deep understanding of\\naccident causality and then designing strategies to reduce their\\nlikelihood. A significant challenge in this field is the lack of a\\nlarge-scale and long-tailed accident dataset [182], which limits\\nthe ability to develop comprehensive and effective accident\\nprevention. Diffusion models, with their powerful controllable\\ngeneration capabilities, have emerged as a promising tool to\\novercome these challenges.\\nRecent advancements in diffusion models have enabled\\nmore innovative applications in traffic accident analysis and\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n17\\nprevention. For example, Fang et al. [42] leveraged an ab-\\nductive CLIP model within an Object-Centric Video Diffu-\\nsion (OAVD) method to discern accident cause-effect chains,\\nthereby enhancing the understanding of accident causality\\nand improving accident prevention strategies. Specifically, this\\napproach leverages diffusion models to generate new video\\nframes conditioned on text descriptions, such as accident rea-\\nsons and prevention advice. This allows for the visualization of\\nhow accidents might unfold based on these descriptions, aiding\\nin understanding and potentially predicting accident outcomes,\\nand contributing to better accident prevention.\\nFuture Directions\\nIntegrating LLMs with \\nDiffusion Models\\nTraffic Guidance with \\nPrior Knowledge\\nNetwork Architectures \\nImprovements\\nFine-Tuning \\nDiffusion Models\\nEnhancing Speed \\nand Efficiency\\nFig. 7: Future research directions for diffusion models in\\nintelligent transportation systems.\\nVIII. FUTURE DIRECTIONS\\nAs diffusion models continue to evolve, their potential to ad-\\ndress complex challenges in ITS becomes increasingly evident.\\nHowever, several critical areas require further investigation\\nand innovation to fully realize their capabilities. This section\\noutlines key research directions for diffusion models in ITS\\nthat are worthy of further exploration, as shown in Fig. 7.\\nA. Integrating LLMs with Diffusion Models\\nThe integration of large language models (LLMs) and\\ndiffusion models represents a promising new direction in ITS.\\nPrevious works, such as [32], [33], [64], have primarily relied\\non pre-trained CLIP [169] to encode textual information and\\ngenerate outputs conditioned on these text feature representa-\\ntions. However, CLIP exhibits inherent limitations in process-\\ning long and complex sentences, which can negatively impact\\nthe quality of generated outputs. LLMs, with their strong\\ncapabilities in language understanding and knowledge-based\\nreasoning, combined with the generative power of diffusion\\nmodels, offer a compelling opportunity for enhanced perfor-\\nmance. Recent studies, including MiniGPT-5 [183], which\\nutilizes “generative vokens” to bridge LLMs and diffusion\\nmodels, and EasyGen [184], which integrates these models\\nvia a projection layer, have demonstrated the potential for\\nproducing more realistic and reasonable outputs. Building on\\nthese advancements, integrating LLMs and diffusion models\\nfor various ITS tasks holds significant promise. In particular,\\nin the field of traffic simulation, the use of LLMs for semantic\\ncomprehension, reasoning, and automated decision-making\\ncould lead to the generation of more realistic and contextually\\naccurate driving images and videos. Moreover, another benefit\\nof combining LLMs with diffusion models is their potential\\nas a user interface. The natural language capabilities of LLMs\\ncan provide a more intuitive means for users to interact with\\nthese systems, enabling users to describe complex scenarios\\nand receive tailored outputs without needing deep technical\\nknowledge. This enhances the accessibility and usability of\\ndiffusion models in ITS applications.\\nB. Traffic Guidance with Prior Knowledge\\nTraffic-related tasks often require reasoning that integrates\\nboth scenario-specific features and domain-specific knowl-\\nedge. Rather than relying on a large, and computationally\\nexpensive diffusion model, the development of more efficient\\ntraffic guidance that incorporate prior knowledge about traffic\\nsystems can significantly enhance the generative process.\\nExisting research has primarily focused on designing guidance\\nto guide sampling in autonomous driving contexts, particularly\\nin planning and decision-making. These guidance are often\\nbased on reinforcement learning techniques or cost functions\\ngrounded in traffic rules [46], [47]. Beyond autonomous driv-\\ning, other domains within ITS, such as traffic flow predic-\\ntion and traffic safety analysis, also rely heavily on domain\\nknowledge. For instance, factors like the relationship between\\ntraffic flow, urban population density, public holidays, weather\\nconditions, and landmark locations are critical for accurate\\ntraffic forecasting. By leveraging this extensive domain knowl-\\nedge, task-specific guidance can be developed to improve the\\nprediction of traffic patterns and congestion levels. Future\\nresearch could focus on creating guidance that more effectively\\nmine and utilize relevant prior knowledge for specific traffic-\\nrelated tasks, thereby advancing the performance of diffusion\\nmodels in these domains.\\nC. Network Architectures Improvements\\nThe architectures of diffusion models present substantial\\nopportunities for improvement. U-Net [17], while demonstrat-\\ning remarkable performance as a denoising network backbone\\nacross various traffic-related tasks and being combinable with\\nmethods such as GCNs to model spatial-temporal dependen-\\ncies [36], still has considerable potential for further optimiza-\\ntion. Recent advancements in transformer-based denoising net-\\nworks, such as DiT [185], U-ViT [186], and their applications\\nin diffusion models like Sora [8] and Stable Diffusion 3\\n[187], have gained significant attention. Transformer-based\\narchitectures excel in capturing long-range spatial-temporal\\nrelationships and offer greater scalability. Therefore, leverag-\\ning or refining transformer-based denoising networks holds\\nsignificant potential for enhancing spatial-temporal-related\\ntraffic applications, such as traffic flow forecasting and traffic\\ntrajectory prediction. Furthermore, designing novel network\\narchitectures specifically tailored to particular tasks within\\nintelligent transportation systems, as backbones for diffusion\\nmodels, presents a promising direction for future research.\\nD. Fine-Tuning Diffusion Models\\nLarge diffusion models, such as Stable Diffusion [38], pre-\\ntrained on extensive image datasets, have demonstrated con-\\nsiderable promise across various domains. Fine-tuning these\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n18\\nmodels on traffic-specific data or for traffic-related condition\\ncontrol can further enhance their applicability within ITS.\\nRecent research has explored methods to fine-tune large pre-\\ntrained diffusion models for more fine-grained control. For\\nexample, ControlNet [162] adds spatial conditioning controls\\nto large and pre-trained diffusion models through efficient fine-\\ntuning techniques. Similarly, T2I-Adapter [188] learns simple\\nand lightweight adapters to align internal knowledge in large\\ndiffusion models with external control signals. Building on\\nthese advancements, developing effective fine-tuning methods\\ntailored to traffic data or traffic scenes holds the potential\\nto significantly enhance the flexibility and control of these\\nmodels in generating traffic-related outputs. These approaches\\npromise to improve the models’ utility in various ITS applica-\\ntions, particularly in traffic simulation and incident detection.\\nE. Enhancing Speed and Efficiency\\nAlthough diffusion models have demonstrated significant\\npotential in generating high-quality results, their computational\\ncost and slow inference speeds remain major bottlenecks.\\nTo enable real-time applications in ITS, such as autonomous\\ndriving, future research should improve the efficiency of these\\nmodels. Although recent advancements, including sampling\\nacceleration [73], [189], [190], network architecture opti-\\nmization [74], [38], and approach improvements [191], have\\ncontributed to mitigating these challenges, further innovation is\\nnecessary. Future research should explore the development of\\nmore adaptive and lightweight network architectures, as well\\nas parallel sampling techniques. Additionally, hybrid models\\nthat integrate the strengths of diffusion models with faster,\\nmore deterministic approaches might also prove valuable for\\nreal-time applications in ITS.\\nIX. CONCLUSION\\nIn this paper, we provide a comprehensive review of dif-\\nfusion models in ITS. We outline the theoretical founda-\\ntions of diffusion models, discuss their key variants, and\\ndemonstrate how they can effectively address the complex\\nchallenges of ITS. Our review also highlights the advantages\\nof diffusion models, especially in handling multi-modal, noisy,\\nand incomplete traffic data. By investigating their current\\napplications in ITS domains, including autonomous driving,\\ntraffic simulation, traffic forecasting, and traffic safety, we\\nhighlight the versatility and potential of diffusion models in\\nenhancing various aspects of ITS. Additionally, we summarize\\nseveral key research directions that warrant further investi-\\ngation, including the integration of other approaches and the\\ndevelopment of more efficient and scalable diffusion models\\ntailored to various traffic-related tasks. We hope this review\\nencourages further interdisciplinary collaboration, paving the\\nway for the continued evolution of diffusion models as a\\npivotal tool in future ITS.\\nACKNOWLEDGMENTS\\nThis study is supported by the National Natural Sci-\\nence Foundation of China under Grant 52302379, Guang-\\ndong Provincial Natural Science Foundation-General Project\\nwith Grant 2024A1515011790, Guangzhou Basic and Ap-\\nplied Basic Research Projects under Grants 2023A03J0106\\nand\\n2024A04J4290,\\nGuangdong\\nProvince\\nGeneral\\nUni-\\nversities\\nYouth\\nInnovative\\nTalents\\nProject\\nunder\\nGrant\\n2023KQNCX100, Guangzhou Municipal Science and Tech-\\nnology Project 2023A03J0011, Nansha District Key R&D\\nProject 2023ZD006.\\nREFERENCES\\n[1] J. Wootton, A. Garcia-Ortiz, and S. Amin, “Intelligent transportation\\nsystems: a global perspective,” Mathematical and computer modelling,\\nvol. 22, no. 4-7, pp. 259–268, 1995.\\n[2] M. Veres and M. Moussa, “Deep learning for intelligent transportation\\nsystems: A survey of emerging trends,” IEEE Transactions on Intelli-\\ngent transportation systems, vol. 21, no. 8, pp. 3152–3168, 2019.\\n[3] J. Ye, J. Zhao, K. Ye, and C. Xu, “How to build a graph-based deep\\nlearning architecture in traffic domain: A survey,” IEEE Transactions\\non Intelligent Transportation Systems, vol. 23, no. 5, pp. 3904–3924,\\n2020.\\n[4] H. Li, Y. Zhao, Z. Mao, Y. Qin, Z. Xiao, J. Feng, Y. Gu, W. Ju, X. Luo,\\nand M. Zhang, “A survey on graph neural networks in intelligent\\ntransportation systems,” arXiv preprint arXiv:2401.00713, 2024.\\n[5] H. Lin, Y. Liu, S. Li, and X. Qu, “How generative adversarial networks\\npromote the development of intelligent transportation systems: A\\nsurvey,” IEEE/CAA journal of automatica sinica, 2023.\\n[6] G. Boquet, A. Morell, J. Serrano, and J. L. Vicario, “A variational\\nautoencoder solution for road traffic forecasting systems: Missing\\ndata imputation, dimension reduction, model selection and anomaly\\ndetection,” Transportation Research Part C: Emerging Technologies,\\nvol. 115, p. 102622, 2020.\\n[7] F.-A. Croitoru, V. Hondru, R. T. Ionescu, and M. Shah, “Diffusion\\nmodels in vision: A survey,” IEEE Transactions on Pattern Analysis\\nand Machine Intelligence, 2023.\\n[8] T.\\nBrooks,\\nB.\\nPeebles,\\nC.\\nHolmes,\\nW.\\nDePue,\\nY.\\nGuo,\\nL.\\nJing,\\nD.\\nSchnurr,\\nJ.\\nTaylor,\\nT.\\nLuhman,\\nE.\\nLuhman,\\nC.\\nNg,\\nR.\\nWang,\\nand\\nA.\\nRamesh,\\n“Video\\ngeneration\\nmodels\\nas\\nworld\\nsimulators,”\\n2024.\\n[Online].\\nAvailable:\\nhttps:\\n//openai.com/research/video-generation-models-as-world-simulators\\n[9] R. A. Khalil, Z. Safelnasr, N. Yemane, M. Kedir, A. Shafiqurrahman,\\nand N. Saeed, “Advanced learning technologies for intelligent trans-\\nportation systems: Prospects and challenges,” IEEE Open Journal of\\nVehicular Technology, 2024.\\n[10] H. Yan and Y. Li, “A survey of generative ai for intelligent transporta-\\ntion systems,” arXiv preprint arXiv:2312.08248, 2023.\\n[11] L. Yang, Z. Zhang, Y. Song, S. Hong, R. Xu, Y. Zhao, W. Zhang,\\nB. Cui, and M.-H. Yang, “Diffusion models: A comprehensive survey\\nof methods and applications,” ACM Computing Surveys, vol. 56, no. 4,\\npp. 1–39, 2023.\\n[12] R. Jiang, G.-C. Zheng, T. Li, T.-R. Yang, J.-D. Wang, and X. Li,\\n“A survey of multimodal controllable diffusion models,” Journal of\\nComputer Science and Technology, vol. 39, no. 3, pp. 509–541, 2024.\\n[13] Y. Yang, M. Jin, H. Wen, C. Zhang, Y. Liang, L. Ma, Y. Wang, C. Liu,\\nB. Yang, Z. Xu et al., “A survey on diffusion models for time series\\nand spatio-temporal data,” arXiv preprint arXiv:2404.18886, 2024.\\n[14] A. Kazerouni, E. K. Aghdam, M. Heidari, R. Azad, M. Fayyaz,\\nI. Hacihaliloglu, and D. Merhof, “Diffusion models in medical imaging:\\nA comprehensive survey,” Medical Image Analysis, vol. 88, p. 102846,\\n2023.\\n[15] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli,\\n“Deep unsupervised learning using nonequilibrium thermodynamics,”\\nin International conference on machine learning.\\nPMLR, 2015, pp.\\n2256–2265.\\n[16] J. Ho, A. Jain, and P. Abbeel, “Denoising diffusion probabilistic\\nmodels,” Advances in neural information processing systems, vol. 33,\\npp. 6840–6851, 2020.\\n[17] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional net-\\nworks for biomedical image segmentation,” in Medical image comput-\\ning and computer-assisted intervention–MICCAI 2015: 18th interna-\\ntional conference, Munich, Germany, October 5-9, 2015, proceedings,\\npart III 18.\\nSpringer, 2015, pp. 234–241.\\n[18] Y. Song and S. Ermon, “Generative modeling by estimating gradients\\nof the data distribution,” Advances in neural information processing\\nsystems, vol. 32, 2019.\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n19\\n[19] A. Hyv¨arinen and P. Dayan, “Estimation of non-normalized statistical\\nmodels by score matching.” Journal of Machine Learning Research,\\nvol. 6, no. 4, 2005.\\n[20] R. M. Neal, “Mcmc using hamiltonian dynamics,” arXiv preprint\\narXiv:1206.1901, 2012.\\n[21] G. O. Roberts and R. L. Tweedie, “Exponential convergence of langevin\\ndistributions and their discrete approximations,” 1996.\\n[22] Y. Song, S. Garg, J. Shi, and S. Ermon, “Sliced score matching: A\\nscalable approach to density and score estimation,” in Uncertainty in\\nArtificial Intelligence.\\nPMLR, 2020, pp. 574–584.\\n[23] P. Vincent, “A connection between score matching and denoising\\nautoencoders,” Neural computation, vol. 23, no. 7, pp. 1661–1674,\\n2011.\\n[24] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon,\\nand B. Poole, “Score-based generative modeling through stochastic\\ndifferential equations,” arXiv preprint arXiv:2011.13456, 2020.\\n[25] K. Itˆo, On stochastic differential equations.\\nAmerican Mathematical\\nSoc., 1951, no. 4.\\n[26] B. D. Anderson, “Reverse-time diffusion equation models,” Stochastic\\nProcesses and their Applications, vol. 12, no. 3, pp. 313–326, 1982.\\n[27] T. Gu, G. Chen, J. Li, C. Lin, Y. Rao, J. Zhou, and J. Lu, “Stochastic\\ntrajectory prediction via motion indeterminacy diffusion,” in Proceed-\\nings of the IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition, 2022, pp. 17 113–17 122.\\n[28] C. Jiang, A. Cornman, C. Park, B. Sapp, Y. Zhou, D. Anguelov\\net al., “Motiondiffuser: Controllable multi-agent motion prediction\\nusing diffusion,” in Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition, 2023, pp. 9644–9653.\\n[29] K. Chen, X. Chen, Z. Yu, M. Zhu, and H. Yang, “Equidiff: A\\nconditional equivariant diffusion model for trajectory prediction,” in\\n2023 IEEE 26th International Conference on Intelligent Transportation\\nSystems (ITSC).\\nIEEE, 2023, pp. 746–751.\\n[30] E. Pronovost, M. R. Ganesina, N. Hendy, Z. Wang, A. Morales,\\nK. Wang, and N. Roy, “Scenario diffusion: Controllable driving\\nscenario generation with diffusion,” Advances in Neural Information\\nProcessing Systems, vol. 36, pp. 68 873–68 894, 2023.\\n[31] Y. Ji, Z. Chen, E. Xie, L. Hong, X. Liu, Z. Liu, T. Lu, Z. Li, and P. Luo,\\n“Ddp: Diffusion model for dense visual prediction,” in Proceedings of\\nthe IEEE/CVF International Conference on Computer Vision, 2023, pp.\\n21 741–21 752.\\n[32] Y. Wen, Y. Zhao, Y. Liu, F. Jia, Y. Wang, C. Luo, C. Zhang, T. Wang,\\nX. Sun, and X. Zhang, “Panacea: Panoramic and controllable video\\ngeneration for autonomous driving,” in Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition, 2024, pp.\\n6902–6912.\\n[33] X. Li, Y. Zhang, and X. Ye, “Drivingdiffusion: Layout-guided multi-\\nview driving scene video generation with latent diffusion model,” arXiv\\npreprint arXiv:2310.07771, 2023.\\n[34] Y. Zhu, Y. Ye, S. Zhang, X. Zhao, and J. Yu, “Difftraj: Generating\\ngps trajectory with diffusion probabilistic model,” Advances in Neural\\nInformation Processing Systems, vol. 36, pp. 65 168–65 188, 2023.\\n[35] T. Wei, Y. Lin, S. Guo, Y. Lin, Y. Huang, C. Xiang, Y. Bai,\\nM. Ya, and H. Wan, “Diff-rntraj: A structure-aware diffusion model\\nfor road network-constrained trajectory generation,” arXiv preprint\\narXiv:2402.07369, 2024.\\n[36] H. Wen, Y. Lin, Y. Xia, H. Wan, Q. Wen, R. Zimmermann, and\\nY. Liang, “Diffstg: Probabilistic spatio-temporal graph forecasting with\\ndenoising diffusion models,” in Proceedings of the 31st ACM Interna-\\ntional Conference on Advances in Geographic Information Systems,\\n2023, pp. 1–12.\\n[37] A. Vaswani, “Attention is all you need,” Advances in Neural Informa-\\ntion Processing Systems, 2017.\\n[38] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer,\\n“High-resolution image synthesis with latent diffusion models,” in\\nProceedings of the IEEE/CVF conference on computer vision and\\npattern recognition, 2022, pp. 10 684–10 695.\\n[39] W. Wu, Y. Zhao, M. Z. Shou, H. Zhou, and C. Shen, “Diffumask: Syn-\\nthesizing images with pixel-level annotations for semantic segmentation\\nusing diffusion models,” in Proceedings of the IEEE/CVF International\\nConference on Computer Vision, 2023, pp. 1206–1217.\\n[40] W. Wu, Y. Zhao, H. Chen, Y. Gu, R. Zhao, Y. He, H. Zhou, M. Z.\\nShou, and C. Shen, “Datasetdm: Synthesizing data with perception\\nannotations using diffusion models,” Advances in Neural Information\\nProcessing Systems, vol. 36, pp. 54 683–54 695, 2023.\\n[41] C. Zhang, Y. Zhang, Q. Shao, B. Li, Y. Lv, X. Piao, and B. Yin, “Chat-\\ntraffc: Text-to-traffic generation via diffusion model,” arXiv preprint\\narXiv:2311.16203, 2023.\\n[42] J. Fang, L.-l. Li, J. Zhou, J. Xiao, H. Yu, C. Lv, J. Xue, and T.-\\nS. Chua, “Abductive ego-view accident video understanding for safe\\ndriving perception,” in Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition, 2024, pp. 22 030–22 040.\\n[43] Y. Zheng, L. Zhong, S. Wang, Y. Yang, W. Gu, J. Zhang, and J. Wang,\\n“Diffuflow: Robust fine-grained urban flow inference with denoising\\ndiffusion model,” in Proceedings of the 32nd ACM International\\nConference on Information and Knowledge Management, 2023, pp.\\n3505–3513.\\n[44] Y. Lin, H. Wan, J. Hu, S. Guo, B. Yang, Y. Lin, and C. S. Jensen,\\n“Origin-destination travel time oracle for map-based services,” Pro-\\nceedings of the ACM on Management of Data, vol. 1, no. 3, pp. 1–27,\\n2023.\\n[45] P. Dhariwal and A. Nichol, “Diffusion models beat gans on image\\nsynthesis,” Advances in neural information processing systems, vol. 34,\\npp. 8780–8794, 2021.\\n[46] M.\\nJanner,\\nY.\\nDu,\\nJ.\\nB.\\nTenenbaum,\\nand\\nS.\\nLevine,\\n“Plan-\\nning with diffusion for flexible behavior synthesis,” arXiv preprint\\narXiv:2205.09991, 2022.\\n[47] J. Carvalho, A. T. Le, M. Baierl, D. Koert, and J. Peters, “Motion\\nplanning diffusion: Learning and planning of robot motions with\\ndiffusion models,” in 2023 IEEE/RSJ International Conference on\\nIntelligent Robots and Systems (IROS).\\nIEEE, 2023, pp. 1916–1923.\\n[48] Z. Zhong, D. Rempe, D. Xu, Y. Chen, S. Veer, T. Che, B. Ray,\\nand M. Pavone, “Guided conditional diffusion for controllable traffic\\nsimulation,” in 2023 IEEE International Conference on Robotics and\\nAutomation (ICRA).\\nIEEE, 2023, pp. 3560–3566.\\n[49] Z. Zhong, D. Rempe, Y. Chen, B. Ivanovic, Y. Cao, D. Xu, M. Pavone,\\nand B. Ray, “Language-guided traffic simulation via scene-level diffu-\\nsion,” in Conference on Robot Learning.\\nPMLR, 2023, pp. 144–177.\\n[50] M. Niedoba, J. Lavington, Y. Liu, V. Lioutas, J. Sefas, X. Liang,\\nD. Green, S. Dabiri, B. Zwartsenberg, A. Scibior et al., “A diffusion-\\nmodel of joint interactive navigation,” Advances in Neural Information\\nProcessing Systems, vol. 36, 2024.\\n[51] J. Ho and T. Salimans, “Classifier-free diffusion guidance,” arXiv\\npreprint arXiv:2207.12598, 2022.\\n[52] A. Ajay, Y. Du, A. Gupta, J. Tenenbaum, T. Jaakkola, and P. Agrawal,\\n“Is conditional generative modeling all you need for decision-making?”\\narXiv preprint arXiv:2211.15657, 2022.\\n[53] D. Rempe, Z. Luo, X. Bin Peng, Y. Yuan, K. Kitani, K. Kreis, S. Fidler,\\nand O. Litany, “Trace and pace: Controllable pedestrian animation\\nvia guided trajectory diffusion,” in Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition, 2023, pp.\\n13 756–13 766.\\n[54] A. Hu, L. Russell, H. Yeo, Z. Murez, G. Fedoseev, A. Kendall,\\nJ. Shotton, and G. Corrado, “Gaia-1: A generative world model for\\nautonomous driving,” arXiv preprint arXiv:2309.17080, 2023.\\n[55] L. Zhang, Y. Xiong, Z. Yang, S. Casas, R. Hu, and R. Urtasun,\\n“Learning unsupervised world models for autonomous driving via\\ndiscrete diffusion,” arXiv preprint arXiv:2311.01017, 2023.\\n[56] P. Esser, R. Rombach, and B. Ommer, “Taming transformers for\\nhigh-resolution image synthesis,” in Proceedings of the IEEE/CVF\\nconference on computer vision and pattern recognition, 2021, pp.\\n12 873–12 883.\\n[57] A. Blattmann, R. Rombach, H. Ling, T. Dockhorn, S. W. Kim, S. Fidler,\\nand K. Kreis, “Align your latents: High-resolution video synthesis with\\nlatent diffusion models,” in Proceedings of the IEEE/CVF Conference\\non Computer Vision and Pattern Recognition, 2023, pp. 22 563–22 575.\\n[58] L. Balasubramanian, J. Wurst, R. Egolf, M. Botsch, W. Utschick, and\\nK. Deng, “Scenediffusion: Conditioned latent diffusion models for\\ntraffic scene prediction,” in 2023 IEEE 26th International Conference\\non Intelligent Transportation Systems (ITSC).\\nIEEE, 2023, pp. 3914–\\n3921.\\n[59] S. Wang, G. Sun, F. Ma, T. Hu, Y. Song, L. Zhu, and M. Liu,\\n“Dragtraffic: A non-expert interactive and point-based controllable\\ntraffic scene generation framework,” arXiv preprint arXiv:2404.12624,\\n2024.\\n[60] Y. Wang, J. He, L. Fan, H. Li, Y. Chen, and Z. Zhang, “Driving into the\\nfuture: Multiview visual forecasting and planning with world model for\\nautonomous driving,” in Proceedings of the IEEE/CVF Conference on\\nComputer Vision and Pattern Recognition, 2024, pp. 14 749–14 759.\\n[61] J. Yang, S. Gao, Y. Qiu, L. Chen, T. Li, B. Dai, K. Chitta, P. Wu,\\nJ. Zeng, P. Luo et al., “Generalized predictive model for autonomous\\ndriving,” in Proceedings of the IEEE/CVF Conference on Computer\\nVision and Pattern Recognition, 2024, pp. 14 662–14 672.\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n20\\n[62] X. Wang, Z. Zhu, G. Huang, X. Chen, and J. Lu, “Drivedreamer:\\nTowards real-world-driven world models for autonomous driving,”\\narXiv preprint arXiv:2309.09777, 2023.\\n[63] J. Lu, Z. Huang, J. Zhang, Z. Yang, and L. Zhang, “Wovogen: World\\nvolume-aware diffusion for controllable multi-camera driving scene\\ngeneration,” arXiv preprint arXiv:2312.02934, 2023.\\n[64] H. Ran, V. Guizilini, and Y. Wang, “Towards realistic scene gener-\\nation with lidar diffusion models,” in Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition, 2024, pp.\\n14 738–14 748.\\n[65] J. L. Elman, “Finding structure in time,” Cognitive science, vol. 14,\\nno. 2, pp. 179–211, 1990.\\n[66] S. Hochreiter, “Long short-term memory,” Neural Computation MIT-\\nPress, 1997.\\n[67] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini,\\n“The graph neural network model,” IEEE transactions on neural\\nnetworks, vol. 20, no. 1, pp. 61–80, 2008.\\n[68] T. N. Kipf and M. Welling, “Semi-supervised classification with graph\\nconvolutional networks,” arXiv preprint arXiv:1609.02907, 2016.\\n[69] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,\\nS. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,”\\nAdvances in neural information processing systems, vol. 27, 2014.\\n[70] A. Creswell, T. White, V. Dumoulin, K. Arulkumaran, B. Sengupta,\\nand A. A. Bharath, “Generative adversarial networks: An overview,”\\nIEEE signal processing magazine, vol. 35, no. 1, pp. 53–65, 2018.\\n[71] D. P. Kingma, “Auto-encoding variational bayes,” arXiv preprint\\narXiv:1312.6114, 2013.\\n[72] D. J. Rezende, S. Mohamed, and D. Wierstra, “Stochastic backprop-\\nagation and approximate inference in deep generative models,” in\\nInternational conference on machine learning.\\nPMLR, 2014, pp.\\n1278–1286.\\n[73] J. Song, C. Meng, and S. Ermon, “Denoising diffusion implicit mod-\\nels,” arXiv preprint arXiv:2010.02502, 2020.\\n[74] W. Mao, C. Xu, Q. Zhu, S. Chen, and Y. Wang, “Leapfrog diffusion\\nmodel for stochastic trajectory prediction,” in Proceedings of the\\nIEEE/CVF conference on computer vision and pattern recognition,\\n2023, pp. 5517–5526.\\n[75] T. Karras, M. Aittala, T. Aila, and S. Laine, “Elucidating the design\\nspace of diffusion-based generative models,” Advances in neural infor-\\nmation processing systems, vol. 35, pp. 26 565–26 577, 2022.\\n[76] W. Harvey, S. Naderiparizi, V. Masrani, C. Weilbach, and F. Wood,\\n“Flexible diffusion modeling of long videos,” Advances in Neural\\nInformation Processing Systems, vol. 35, pp. 27 953–27 965, 2022.\\n[77] J. Austin, D. D. Johnson, J. Ho, D. Tarlow, and R. Van Den Berg,\\n“Structured denoising diffusion models in discrete state-spaces,” Ad-\\nvances in Neural Information Processing Systems, vol. 34, pp. 17 981–\\n17 993, 2021.\\n[78] X. Han, H. Zheng, and M. Zhou, “Card: Classification and regression\\ndiffusion models,” Advances in Neural Information Processing Systems,\\nvol. 35, pp. 18 100–18 115, 2022.\\n[79] S. Chen, P. Sun, Y. Song, and P. Luo, “Diffusiondet: Diffusion model\\nfor object detection,” in Proceedings of the IEEE/CVF international\\nconference on computer vision, 2023, pp. 19 830–19 843.\\n[80] S. Shao, Z. Zhao, B. Li, T. Xiao, G. Yu, X. Zhang, and J. Sun,\\n“Crowdhuman: A benchmark for detecting human in a crowd,” arXiv\\npreprint arXiv:1805.00123, 2018.\\n[81] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,\\nP. Doll´ar, and C. L. Zitnick, “Microsoft coco: Common objects in\\ncontext,” in Computer Vision–ECCV 2014: 13th European Conference,\\nZurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13.\\nSpringer, 2014, pp. 740–755.\\n[82] Y. Wang, R. Gao, K. Chen, K. Zhou, Y. Cai, L. Hong, Z. Li, L. Jiang,\\nD.-Y. Yeung, Q. Xu et al., “Detdiffusion: Synergizing generative and\\nperceptive models for enhanced data generation and perception,” in\\nProceedings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition, 2024, pp. 7246–7255.\\n[83] J. Zou, K. Tian, Z. Zhu, Y. Ye, and X. Wang, “Diffbev: Conditional\\ndiffusion model for bird’s eye view perception,” in Proceedings of the\\nAAAI Conference on Artificial Intelligence, vol. 38, no. 7, 2024, pp.\\n7846–7854.\\n[84] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu,\\nA. Krishnan, Y. Pan, G. Baldan, and O. Beijbom, “nuscenes: A\\nmultimodal dataset for autonomous driving,” in Proceedings of the\\nIEEE/CVF conference on computer vision and pattern recognition,\\n2020, pp. 11 621–11 631.\\n[85] B. Zhou, H. Zhao, X. Puig, S. Fidler, A. Barriuso, and A. Torralba,\\n“Scene parsing through ade20k dataset,” in Proceedings of the IEEE\\nconference on computer vision and pattern recognition, 2017, pp. 633–\\n641.\\n[86] N. Silberman, D. Hoiem, P. Kohli, and R. Fergus, “Indoor segmentation\\nand support inference from rgbd images,” in Computer Vision–ECCV\\n2012: 12th European Conference on Computer Vision, Florence, Italy,\\nOctober 7-13, 2012, Proceedings, Part V 12.\\nSpringer, 2012, pp.\\n746–760.\\n[87] A. Geiger, P. Lenz, C. Stiller, and R. Urtasun, “Vision meets robotics:\\nThe kitti dataset,” The International Journal of Robotics Research,\\nvol. 32, no. 11, pp. 1231–1237, 2013.\\n[88] W. Zhao, Y. Rao, Z. Liu, B. Liu, J. Zhou, and J. Lu, “Unleashing\\ntext-to-image diffusion models for visual perception,” in Proceedings\\nof the IEEE/CVF International Conference on Computer Vision, 2023,\\npp. 5729–5739.\\n[89] L. Yu, P. Poirson, S. Yang, A. C. Berg, and T. L. Berg, “Modeling\\ncontext in referring expressions,” in Computer Vision–ECCV 2016:\\n14th European Conference, Amsterdam, The Netherlands, October 11-\\n14, 2016, Proceedings, Part II 14.\\nSpringer, 2016, pp. 69–85.\\n[90] S. Chen, E. Yu, J. Li, and W. Tao, “Delving into the trajectory long-tail\\ndistribution for muti-object tracking,” in Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition, 2024, pp.\\n19 341–19 351.\\n[91] P. Dendorfer, “Mot20: A benchmark for multi object tracking in\\ncrowded scenes,” arXiv preprint arXiv:2003.09003, 2020.\\n[92] R. Luo, Z. Song, L. Ma, J. Wei, W. Yang, and M. Yang, “Diffusiontrack:\\nDiffusion model for multi-object tracking,” in Proceedings of the AAAI\\nConference on Artificial Intelligence, vol. 38, no. 5, 2024, pp. 3991–\\n3999.\\n[93] F. Xie, Z. Wang, and C. Ma, “Diffusiontrack: Point set diffusion model\\nfor visual object tracking,” in Proceedings of the IEEE/CVF Conference\\non Computer Vision and Pattern Recognition, 2024, pp. 19 113–19 124.\\n[94] L. Huang, X. Zhao, and K. Huang, “Got-10k: A large high-diversity\\nbenchmark for generic object tracking in the wild,” IEEE transactions\\non pattern analysis and machine intelligence, vol. 43, no. 5, pp. 1562–\\n1577, 2019.\\n[95] H. Fan, L. Lin, F. Yang, P. Chu, G. Deng, S. Yu, H. Bai, Y. Xu,\\nC. Liao, and H. Ling, “Lasot: A high-quality benchmark for large-scale\\nsingle object tracking,” in Proceedings of the IEEE/CVF conference on\\ncomputer vision and pattern recognition, 2019, pp. 5374–5383.\\n[96] S. Luo and W. Hu, “Diffusion probabilistic models for 3d point cloud\\ngeneration,” in Proceedings of the IEEE/CVF conference on computer\\nvision and pattern recognition, 2021, pp. 2837–2845.\\n[97] A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang,\\nZ. Li, S. Savarese, M. Savva, S. Song, H. Su et al., “Shapenet:\\nAn\\ninformation-rich\\n3d\\nmodel\\nrepository,”\\narXiv\\npreprint\\narXiv:1512.03012, 2015.\\n[98] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisser-\\nman, “The pascal visual object classes (voc) challenge,” International\\njournal of computer vision, vol. 88, pp. 303–338, 2010.\\n[99] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Be-\\nnenson, U. Franke, S. Roth, and B. Schiele, “The cityscapes dataset\\nfor semantic urban scene understanding,” in Proceedings of the IEEE\\nconference on computer vision and pattern recognition, 2016, pp.\\n3213–3223.\\n[100] A. Robicquet, A. Sadeghian, A. Alahi, and S. Savarese, “Learning\\nsocial etiquette: Human trajectory understanding in crowded scenes,” in\\nComputer Vision–ECCV 2016: 14th European Conference, Amsterdam,\\nThe Netherlands, October 11-14, 2016, Proceedings, Part VIII 14.\\nSpringer, 2016, pp. 549–565.\\n[101] S. Pellegrini, A. Ess, and L. Van Gool, “Improving data association by\\njoint modeling of pedestrian trajectories and groupings,” in Computer\\nVision–ECCV 2010: 11th European Conference on Computer Vision,\\nHeraklion, Crete, Greece, September 5-11, 2010, Proceedings, Part I\\n11.\\nSpringer, 2010, pp. 452–465.\\n[102] A. Lerner, Y. Chrysanthou, and D. Lischinski, “Crowds by example,”\\nin Computer graphics forum, vol. 26, no. 3.\\nWiley Online Library,\\n2007, pp. 655–664.\\n[103] I. Bae, Y.-J. Park, and H.-G. Jeon, “Singulartrajectory: Universal\\ntrajectory predictor using diffusion model,” in Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\\n2024, pp. 17 890–17 901.\\n[104] C. Liu, S. He, H. Liu, and J. Chen, “Intention-aware denoising diffusion\\nmodel for trajectory prediction,” arXiv preprint arXiv:2403.09190,\\n2024.\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n21\\n[105] K. Lv, L. Yuan, and X. Ni, “Learning autoencoder diffusion models\\nof pedestrian group relationships for multimodal trajectory prediction,”\\nIEEE Transactions on Instrumentation and Measurement, 2024.\\n[106] R. Li, C. Li, D. Ren, G. Chen, Y. Yuan, and G. Wang, “Bcdiff: Bidi-\\nrectional consistent diffusion for instantaneous trajectory prediction,”\\nAdvances in Neural Information Processing Systems, vol. 36, 2024.\\n[107] S. Ettinger, S. Cheng, B. Caine, C. Liu, H. Zhao, S. Pradhan, Y. Chai,\\nB. Sapp, C. R. Qi, Y. Zhou et al., “Large scale interactive motion fore-\\ncasting for autonomous driving: The waymo open motion dataset,” in\\nProceedings of the IEEE/CVF International Conference on Computer\\nVision, 2021, pp. 9710–9719.\\n[108] M.-F. Chang, J. Lambert, P. Sangkloy, J. Singh, S. Bak, A. Hartnett,\\nD. Wang, P. Carr, S. Lucey, D. Ramanan et al., “Argoverse: 3d tracking\\nand forecasting with rich maps,” in Proceedings of the IEEE/CVF\\nconference on computer vision and pattern recognition, 2019, pp.\\n8748–8757.\\n[109] U.S. Department of Transportation Federal Highway Administration,\\n“Next Generation Simulation (NGSIM) Vehicle Trajectories and Sup-\\nporting Data,” 2016, [Dataset]. Provided by ITS DataHub through\\nData.transportation.gov. Accessed: 2024-05-21.\\n[110] Y. Yao, Y. Liu, X. Dai, S. Chen, and Y. Lv, “A graph-based scene\\nencoder for vehicle trajectory prediction using the diffusion model,”\\nin 2023 International Annual Conference on Complex Systems and\\nIntelligent Science (CSIS-IAC).\\nIEEE, 2023, pp. 981–986.\\n[111] B. Wilson, W. Qi, T. Agarwal, J. Lambert, J. Singh, S. Khandelwal,\\nB. Pan, R. Kumar, A. Hartnett, J. K. Pontes et al., “Argoverse 2: Next\\ngeneration datasets for self-driving perception and forecasting,” arXiv\\npreprint arXiv:2301.00493, 2023.\\n[112] J. Fu, A. Kumar, O. Nachum, G. Tucker, and S. Levine, “D4rl:\\nDatasets for deep data-driven reinforcement learning,” arXiv preprint\\narXiv:2004.07219, 2020.\\n[113] B. Yang, H. Su, N. Gkanatsios, T.-W. Ke, A. Jain, J. Schneider, and\\nK. Fragkiadaki, “Diffusion-es: Gradient-free planning with diffusion\\nfor autonomous and instruction-guided driving,” in Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\\n2024, pp. 15 342–15 353.\\n[114] H. Caesar, J. Kabzan, K. S. Tan, W. K. Fong, E. Wolff, A. Lang,\\nL. Fletcher, O. Beijbom, and S. Omari, “nuplan: A closed-loop ml-\\nbased planning benchmark for autonomous vehicles,” arXiv preprint\\narXiv:2106.11810, 2021.\\n[115] W. Zhan, L. Sun, D. Wang, H. Shi, A. Clausse, M. Naumann, J. Kum-\\nmerle, H. Konigshof, C. Stiller, A. de La Fortelle et al., “Interaction\\ndataset: An international, adversarial and cooperative motion dataset\\nin interactive driving scenarios with semantic maps,” arXiv preprint\\narXiv:1910.03088, 2019.\\n[116] A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V. Koltun, “Carla:\\nAn open urban driving simulator,” in Conference on robot learning.\\nPMLR, 2017, pp. 1–16.\\n[117] G. Zhao, X. Wang, Z. Zhu, X. Chen, G. Huang, X. Bao, and X. Wang,\\n“Drivedreamer-2: Llm-enhanced world models for diverse driving\\nvideo generation,” arXiv preprint arXiv:2403.06845, 2024.\\n[118] Y. Liao, J. Xie, and A. Geiger, “Kitti-360: A novel dataset and\\nbenchmarks for urban scene understanding in 2d and 3d,” IEEE\\nTransactions on Pattern Analysis and Machine Intelligence, vol. 45,\\nno. 3, pp. 3292–3310, 2022.\\n[119] Z. Zhou, J. Ding, Y. Liu, D. Jin, and Y. Li, “Towards generative mod-\\neling of urban flow through knowledge-enhanced denoising diffusion,”\\nin Proceedings of the 31st ACM International Conference on Advances\\nin Geographic Information Systems, 2023, pp. 1–12.\\n[120] C. Rong, J. Ding, Z. Liu, and Y. Li, “Complexity-aware large scale\\norigin-destination network generation via diffusion model,” arXiv\\npreprint arXiv:2306.04873, 2023.\\n[121] C. Chen, K. Petty, A. Skabardonis, P. Varaiya, and Z. Jia, “Freeway\\nperformance measurement system: mining loop detector data,” Trans-\\nportation research record, vol. 1748, no. 1, pp. 96–102, 2001.\\n[122] L. Lin, D. Shi, A. Han, and J. Gao, “Specstg: A fast spectral diffusion\\nframework for probabilistic spatio-temporal traffic forecasting,” arXiv\\npreprint arXiv:2401.08119, 2024.\\n[123] X. Xu, Y. Wei, P. Wang, X. Luo, F. Zhou, and G. Trajcevski, “Diffusion\\nprobabilistic modeling for fine-grained urban traffic flow inference with\\nrelaxed structural constraint,” in ICASSP 2023-2023 IEEE International\\nConference on Acoustics, Speech and Signal Processing (ICASSP).\\nIEEE, 2023, pp. 1–5.\\n[124] M. Lablack, S. Yu, S. Xu, and Y. Shen, “Long-sequence model for\\ntraffic forecasting in suboptimal situation,” in Proceedings of the 18th\\nWorkshop on Mobility in the Evolving Internet Architecture, 2023, pp.\\n25–30.\\n[125] R. Jiang, D. Yin, Z. Wang, Y. Wang, J. Deng, H. Liu, Z. Cai,\\nJ. Deng, X. Song, and R. Shibasaki, “Dl-traff: Survey and benchmark\\nof deep learning models for urban traffic prediction,” in Proceedings of\\nthe 30th ACM international conference on information & knowledge\\nmanagement, 2021, pp. 4515–4525.\\n[126] P. Chi and X. Ma, “Difforecast: Image generation based highway\\ntraffic forecasting with diffusion model,” in 2023 IEEE International\\nConference on Big Data (BigData).\\nIEEE, 2023, pp. 608–615.\\n[127] C. Li, G. Feng, Y. Li, R. Liu, Q. Miao, and L. Chang, “Difftad:\\nDenoising diffusion probabilistic models for vehicle trajectory anomaly\\ndetection,” Knowledge-Based Systems, vol. 286, p. 111387, 2024.\\n[128] C. Yan, S. Zhang, Y. Liu, G. Pang, and W. Wang, “Feature prediction\\ndiffusion model for video anomaly detection,” in Proceedings of the\\nIEEE/CVF International Conference on Computer Vision, 2023, pp.\\n5527–5537.\\n[129] C. Lu, J. Shi, and J. Jia, “Abnormal event detection at 150 fps\\nin matlab,” in Proceedings of the IEEE international conference on\\ncomputer vision, 2013, pp. 2720–2727.\\n[130] J. Zhao, W. Zhao, B. Deng, Z. Wang, F. Zhang, W. Zheng, W. Cao,\\nJ. Nan, Y. Lian, and A. F. Burke, “Autonomous driving system: A\\ncomprehensive survey,” Expert Systems with Applications, p. 122836,\\n2023.\\n[131] L. Chen, P. Wu, K. Chitta, B. Jaeger, A. Geiger, and H. Li, “End-\\nto-end autonomous driving: Challenges and frontiers,” arXiv preprint\\narXiv:2306.16927, 2023.\\n[132] S. Teng, X. Hu, P. Deng, B. Li, Y. Li, Y. Ai, D. Yang, L. Li,\\nZ. Xuanyuan, F. Zhu et al., “Motion planning for autonomous driving:\\nThe state of the art and future perspectives,” IEEE Transactions on\\nIntelligent Vehicles, vol. 8, no. 6, pp. 3692–3711, 2023.\\n[133] S. Grigorescu, B. Trasnea, T. Cocias, and G. Macesanu, “A survey\\nof deep learning techniques for autonomous driving,” Journal of field\\nrobotics, vol. 37, no. 3, pp. 362–386, 2020.\\n[134] E. Yurtsever, J. Lambert, A. Carballo, and K. Takeda, “A survey of\\nautonomous driving: Common practices and emerging technologies,”\\nIEEE access, vol. 8, pp. 58 443–58 469, 2020.\\n[135] D. Baranchuk, I. Rubachev, A. Voynov, V. Khrulkov, and A. Babenko,\\n“Label-efficient semantic segmentation with diffusion models,” arXiv\\npreprint arXiv:2112.03126, 2021.\\n[136] D.-T. Le, H. Shi, J. Cai, and H. Rezatofighi, “Diffuser: Diffusion\\nmodel for robust multi-sensor fusion in 3d object detection and bev\\nsegmentation,” arXiv preprint arXiv:2404.04629, 2024.\\n[137] J. Li, B. Li, Z. Tu, X. Liu, Q. Guo, F. Juefei-Xu, R. Xu, and H. Yu,\\n“Light the night: A multi-condition diffusion framework for unpaired\\nlow-light enhancement in autonomous driving,” in Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\\n2024, pp. 15 205–15 215.\\n[138] A. Nachkov, M. Danelljan, D. P. Paudel, and L. Van Gool,\\n“Diffusion-based particle-detr for bev perception,” arXiv preprint\\narXiv:2312.11578, 2023.\\n[139] W. Luo, J. Xing, A. Milan, X. Zhang, W. Liu, and T.-K. Kim, “Multiple\\nobject tracking: A literature review,” Artificial intelligence, vol. 293, p.\\n103448, 2021.\\n[140] J. Sun, W. Nie, Z. Yu, Z. M. Mao, and C. Xiao, “Pointdp: Diffusion-\\ndriven purification against adversarial attacks on 3d point cloud recog-\\nnition,” arXiv preprint arXiv:2208.09801, 2022.\\n[141] Y. Huang, J. Du, Z. Yang, Z. Zhou, L. Zhang, and H. Chen, “A\\nsurvey on trajectory-prediction methods for autonomous driving,” IEEE\\nTransactions on Intelligent Vehicles, vol. 7, no. 3, pp. 652–674, 2022.\\n[142] R. Huang, H. Xue, M. Pagnucco, F. Salim, and Y. Song, “Multimodal\\ntrajectory prediction: A survey,” arXiv preprint arXiv:2302.10463,\\n2023.\\n[143] Y. Tang, H. He, Y. Wang, and Y. Wu, “Utilizing a diffusion model\\nfor pedestrian trajectory prediction in semi-open autonomous driving\\nenvironments,” IEEE Sensors Journal, 2024.\\n[144] Y. Yang, P. Zhu, M. Qi, and H. Ma, “Uncovering the human motion\\npattern: Pattern memory-based diffusion model for trajectory predic-\\ntion,” arXiv preprint arXiv:2401.02916, 2024.\\n[145] J. Sun, Y. Li, L. Chai, H.-S. Fang, Y.-L. Li, and C. Lu, “Human tra-\\njectory prediction with momentary observation,” in Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\\n2022, pp. 6467–6476.\\n[146] T. Westny, B. Olofsson, and E. Frisk, “Diffusion-based environment-\\naware trajectory prediction,” arXiv preprint arXiv:2403.11643, 2024.\\n[147] C. Badue, R. Guidolini, R. V. Carneiro, P. Azevedo, V. B. Cardoso,\\nA. Forechi, L. Jesus, R. Berriel, T. M. Paixao, F. Mutz et al., “Self-\\ndriving cars: A survey,” Expert systems with applications, vol. 165, p.\\n113816, 2021.\\nIEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. XX, NO. X, XXX 2024\\n22\\n[148] B. R. Kiran, I. Sobh, V. Talpaert, P. Mannion, A. A. Al Sallab, S. Yo-\\ngamani, and P. P´erez, “Deep reinforcement learning for autonomous\\ndriving: A survey,” IEEE Transactions on Intelligent Transportation\\nSystems, vol. 23, no. 6, pp. 4909–4926, 2021.\\n[149] S. Aradi, “Survey of deep reinforcement learning for motion planning\\nof autonomous vehicles,” IEEE Transactions on Intelligent Transporta-\\ntion Systems, vol. 23, no. 2, pp. 740–759, 2020.\\n[150] Z. Zhu, H. Zhao, H. He, Y. Zhong, S. Zhang, Y. Yu, and W. Zhang,\\n“Diffusion models for reinforcement learning: A survey,” arXiv preprint\\narXiv:2311.01223, 2023.\\n[151] Z. Wang, J. J. Hunt, and M. Zhou, “Diffusion policies as an expres-\\nsive policy class for offline reinforcement learning,” arXiv preprint\\narXiv:2208.06193, 2022.\\n[152] J. Liu, P. Hang, X. Zhao, J. Wang, and J. Sun, “Ddm-lag: A diffusion-\\nbased decision-making model for autonomous vehicles with lagrangian\\nsafety enhancement,” arXiv preprint arXiv:2401.03629, 2024.\\n[153] J. Nguyen, S. T. Powers, N. Urquhart, T. Farrenkopf, and M. Guck-\\nert, “An overview of agent-based traffic simulators,” Transportation\\nresearch interdisciplinary perspectives, vol. 12, p. 100486, 2021.\\n[154] D. Chen, M. Zhu, H. Yang, X. Wang, and Y. Wang, “Data-driven traffic\\nsimulation: A comprehensive review,” IEEE Transactions on Intelligent\\nVehicles, 2024.\\n[155] W. Ding, C. Xu, M. Arief, H. Lin, B. Li, and D. Zhao, “A survey on\\nsafety-critical driving scenario generation—a methodological perspec-\\ntive,” IEEE Transactions on Intelligent Transportation Systems, vol. 24,\\nno. 7, pp. 6971–6988, 2023.\\n[156] P. A. Lopez, M. Behrisch, L. Bieker-Walz, J. Erdmann, Y.-P. Fl¨otter¨od,\\nR. Hilbrich, L. L¨ucken, J. Rummel, P. Wagner, and E. Wießner,\\n“Microscopic traffic simulation using sumo,” in 2018 21st international\\nconference on intelligent transportation systems (ITSC).\\nIEEE, 2018,\\npp. 2575–2582.\\n[157] O. Maler and D. Nickovic, “Monitoring temporal properties of con-\\ntinuous signals,” in International symposium on formal techniques in\\nreal-time and fault-tolerant systems.\\nSpringer, 2004, pp. 152–166.\\n[158] Z. Huang, Z. Zhang, A. Vaidya, Y. Chen, C. Lv, and J. F. Fisac,\\n“Versatile scene-consistent traffic scenario generation as optimization\\nwith diffusion,” arXiv preprint arXiv:2404.02524, 2024.\\n[159] C. Yang, A. X. Tian, D. Chen, T. Shi, and A. Heydarian, “Wcdt:\\nWorld-centric diffusion transformer for traffic scene generation,” arXiv\\npreprint arXiv:2404.02082, 2024.\\n[160] S. Riedmaier, T. Ponn, D. Ludwig, B. Schick, and F. Diermeyer,\\n“Survey on scenario-based safety assessment of automated vehicles,”\\nIEEE access, vol. 8, pp. 87 456–87 477, 2020.\\n[161] Z. Zhu, X. Wang, W. Zhao, C. Min, N. Deng, M. Dou, Y. Wang,\\nB. Shi, K. Wang, C. Zhang et al., “Is sora a world simulator? a\\ncomprehensive survey on general world models and beyond,” arXiv\\npreprint arXiv:2405.03520, 2024.\\n[162] L. Zhang, A. Rao, and M. Agrawala, “Adding conditional control\\nto text-to-image diffusion models,” in Proceedings of the IEEE/CVF\\nInternational Conference on Computer Vision, 2023, pp. 3836–3847.\\n[163] J. Ho, T. Salimans, A. Gritsenko, W. Chan, M. Norouzi, and D. J. Fleet,\\n“Video diffusion models,” Advances in Neural Information Processing\\nSystems, vol. 35, pp. 8633–8646, 2022.\\n[164] J. Ho, W. Chan, C. Saharia, J. Whang, R. Gao, A. Gritsenko, D. P.\\nKingma, B. Poole, M. Norouzi, D. J. Fleet et al., “Imagen video:\\nHigh definition video generation with diffusion models,” arXiv preprint\\narXiv:2210.02303, 2022.\\n[165] D. Ha and J. Schmidhuber, “Recurrent world models facilitate policy\\nevolution,” Advances in neural information processing systems, vol. 31,\\n2018.\\n[166] J. Mao, Y. Qian, H. Zhao, and Y. Wang, “Gpt-driver: Learning to drive\\nwith gpt,” arXiv preprint arXiv:2310.01415, 2023.\\n[167] M. Peng, X. Guo, X. Chen, M. Zhu, K. Chen, X. Wang, Y. Wang et al.,\\n“Lc-llm: Explainable lane-change intention and trajectory predictions\\nwith large language models,” arXiv preprint arXiv:2403.18344, 2024.\\n[168] V. Zyrianov, H. Che, Z. Liu, and S. Wang, “Lidardm: Generative lidar\\nsimulation in a generated world,” arXiv preprint arXiv:2404.02903,\\n2024.\\n[169] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal,\\nG. Sastry, A. Askell, P. Mishkin, J. Clark et al., “Learning transferable\\nvisual models from natural language supervision,” in International\\nconference on machine learning.\\nPMLR, 2021, pp. 8748–8763.\\n[170] A. Van Den Oord, O. Vinyals et al., “Neural discrete representation\\nlearning,” Advances in neural information processing systems, vol. 30,\\n2017.\\n[171] H. Chang, H. Zhang, L. Jiang, C. Liu, and W. T. Freeman,\\n“Maskgit: Masked generative image transformer,” in Proceedings of the\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition,\\n2022, pp. 11 315–11 325.\\n[172] K. Rasul, C. Seward, I. Schuster, and R. Vollgraf, “Autoregressive\\ndenoising diffusion models for multivariate probabilistic time se-\\nries forecasting,” in International Conference on Machine Learning.\\nPMLR, 2021, pp. 8857–8868.\\n[173] Y. Tashiro, J. Song, Y. Song, and S. Ermon, “Csdi: Conditional\\nscore-based diffusion models for probabilistic time series imputation,”\\nAdvances in Neural Information Processing Systems, vol. 34, pp.\\n24 804–24 816, 2021.\\n[174] Y. Yuan, J. Ding, C. Shao, D. Jin, and Y. Li, “Spatio-temporal diffusion\\npoint processes,” in Proceedings of the 29th ACM SIGKDD Conference\\non Knowledge Discovery and Data Mining, 2023, pp. 3173–3184.\\n[175] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training\\nof deep bidirectional transformers for language understanding,” arXiv\\npreprint arXiv:1810.04805, 2018.\\n[176] W. Jiang and J. Luo, “Graph neural network for traffic forecasting: A\\nsurvey,” Expert systems with applications, vol. 207, p. 117921, 2022.\\n[177] Z. Zheng, Z. Wang, Z. Hu, Z. Wan, and W. Ma, “Recovering traffic\\ndata from the corrupted noise: A doubly physics-regularized denoising\\ndiffusion model,” Transportation Research Part C: Emerging Technolo-\\ngies, vol. 160, p. 104513, 2024.\\n[178] U. Mori, A. Mendiburu, M. ´Alvarez, and J. A. Lozano, “A review of\\ntravel time estimation and forecasting for advanced traveller informa-\\ntion systems,” Transportmetrica A: Transport Science, vol. 11, no. 2,\\npp. 119–157, 2015.\\n[179] K. Goniewicz, M. Goniewicz, W. Pawłowski, and P. Fiedor, “Road\\naccident rates: strategies and programmes for improving road traffic\\nsafety,” European journal of trauma and emergency surgery, vol. 42,\\npp. 433–438, 2016.\\n[180] K. K. Santhosh, D. P. Dogra, and P. P. Roy, “Anomaly detection in road\\ntraffic using visual surveillance: A survey,” ACM Computing Surveys\\n(CSUR), vol. 53, no. 6, pp. 1–26, 2020.\\n[181] X. Kong, J. Wang, Z. Hu, Y. He, X. Zhao, and G. Shen, “Mobile\\ntrajectory anomaly detection: Taxonomy, methodology, challenges, and\\ndirections,” IEEE Internet of Things Journal, 2024.\\n[182] J. Fang, J. Qiao, J. Xue, and Z. Li, “Vision-based traffic accident\\ndetection and anticipation: A survey,” IEEE Transactions on Circuits\\nand Systems for Video Technology, 2023.\\n[183] K. Zheng, X. He, and X. E. Wang, “Minigpt-5: Interleaved vision-\\nand-language\\ngeneration\\nvia\\ngenerative\\nvokens,”\\narXiv\\npreprint\\narXiv:2310.02239, 2023.\\n[184] X. Zhao, B. Liu, Q. Liu, G. Shi, and X.-M. Wu, “Making multimodal\\ngeneration easier: When diffusion models meet llms,” arXiv preprint\\narXiv:2310.08949, 2023.\\n[185] W. Peebles and S. Xie, “Scalable diffusion models with transformers,”\\nin Proceedings of the IEEE/CVF International Conference on Com-\\nputer Vision, 2023, pp. 4195–4205.\\n[186] F. Bao, S. Nie, K. Xue, Y. Cao, C. Li, H. Su, and J. Zhu, “All are\\nworth words: A vit backbone for diffusion models,” in Proceedings of\\nthe IEEE/CVF conference on computer vision and pattern recognition,\\n2023, pp. 22 669–22 679.\\n[187] P. Esser, S. Kulal, A. Blattmann, R. Entezari, J. M¨uller, H. Saini,\\nY. Levi, D. Lorenz, A. Sauer, F. Boesel et al., “Scaling rectified\\nflow transformers for high-resolution image synthesis,” in Forty-first\\nInternational Conference on Machine Learning, 2024.\\n[188] C. Mou, X. Wang, L. Xie, Y. Wu, J. Zhang, Z. Qi, and Y. Shan, “T2i-\\nadapter: Learning adapters to dig out more controllable ability for text-\\nto-image diffusion models,” in Proceedings of the AAAI Conference on\\nArtificial Intelligence, vol. 38, no. 5, 2024, pp. 4296–4304.\\n[189] T. Salimans and J. Ho, “Progressive distillation for fast sampling of\\ndiffusion models,” arXiv preprint arXiv:2202.00512, 2022.\\n[190] Y. Song, P. Dhariwal, M. Chen, and I. Sutskever, “Consistency models,”\\narXiv preprint arXiv:2303.01469, 2023.\\n[191] S. Xue, Z. Liu, F. Chen, S. Zhang, T. Hu, E. Xie, and Z. Li,\\n“Accelerating diffusion sampling with optimized time steps,” in Pro-\\nceedings of the IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition, 2024, pp. 8292–8301.\\n',\n",
       " 'Unleashing the Power of Data Tsunami: A Comprehensive Survey on\\nData Assessment and Selection for Instruction Tuning of Language Models\\nYulei Qin1, Yuncheng Yang1,2, Pengcheng Guo1, Gang Li1, Hang Shao1,\\nYuchen Shi1, Zihan Xu1, Yun Gu2, Ke Li1, Xing Sun1,\\n1Tencent YouTu Lab, 2Shanghai Jiao Tong University\\nCorrespondence: yuleiqin@tencent.com\\nAbstract\\nInstruction tuning plays a critical role in align-\\ning large language models (LLMs) with human\\npreference. Despite the vast amount of open\\ninstruction datasets, naively training a LLM\\non all existing instructions may not be opti-\\nmal and practical. To pinpoint the most benefi-\\ncial datapoints, data assessment and selection\\nmethods have been proposed in the fields of\\nnatural language processing (NLP) and deep\\nlearning. However, under the context of instruc-\\ntion tuning, there still exists a gap in knowl-\\nedge on what kind of data evaluation metrics\\ncan be employed and how they can be inte-\\ngrated into the selection mechanism. To bridge\\nthis gap, we present a comprehensive review\\non existing literature of data assessment and\\nselection especially for instruction tuning of\\nLLMs. We systematically categorize all ap-\\nplicable methods into quality-based, diversity-\\nbased, and importance-based ones where a uni-\\nfied, fine-grained taxonomy is structured. For\\neach category, representative methods are elab-\\norated to describe the landscape of relevant re-\\nsearch. In addition, comparison between lat-\\nest methods is conducted on their officially re-\\nported results to provide in-depth discussions\\non their limitations. Finally, we summarize the\\nopen challenges and propose the promosing av-\\nenues for future studies. All related contents are\\navailable at https://github.com/yuleiqin/\\nfantastic-data-engineering.\\n1\\nIntroduction\\nOne of the ultimate goal of developing large\\nlnguage models (LLMs) is to unlock their poten-\\ntials of generalization to unseen natural language\\nprocessing (NLP) tasks. Towards this goal, a se-\\nries of LLMs such as GPTs (Brown et al., 2020;\\nAchiam et al., 2023), LLaMAs (Touvron et al.,\\n2023a,b; AI@Meta, 2024), and Mistrals (Jiang\\net al., 2023a, 2024a) have delivered high-level text\\nunderstanding and generation capabilities via uti-\\nlizing vast amount of high-quality web and human-\\nannotated datasets for pre-training and preference\\nalignment (Liu et al., 2023a, 2024c; Sun et al.,\\n2024b; Edunov et al., 2019; Dong et al., 2019). Dur-\\ning preference alignment, instruction tuning plays\\nan important role in refining pre-trained LLMs to\\nprovide accurate, pertinent, and harmless responses\\non a collection of downstream tasks (Wei et al.,\\n2021; Sanh et al., 2021; Zhang et al., 2023c; Peng\\net al., 2023; Longpre et al., 2023; Shu et al., 2023;\\nJang et al., 2023; Ghosh et al., 2024; Kung and\\nPeng, 2023). For efficient and effective instruction\\ntuning, existing studies (Ouyang et al., 2022; Taori\\net al., 2023; Zhou et al., 2024a; Xia et al., 2024a)\\nhave noticed that improving quality of instruction\\ntuning data (e.g., formulation of well-defined and\\ncomplete contexts), rather than simply piling up\\ninstructions without analysis (e.g., exhaustive col-\\nlection of open datasets), is of prioritized concerns.\\nIn this work, we aim to unify a wide array of\\ndata assessment and selection methods under the\\ncontext of instruction tuning of LLMs. As revealed\\nfrom the probabilistic view (John and Draper, 1975;\\nMurphy, 2012; Albalak et al., 2024), the statistical\\npatterns inherent in datasets determines the model-\\ning performance. The overall evaluation of instruc-\\ntion datapoints not only deciphers the distribution\\nin various aspects (e.g., composition, task, and do-\\nmain) and also help cherry-pick the most beneficial\\nsubsets for higher performance with less training\\ncost. Through this survey, we demonstrate that:\\n1) existing resourceful data assessment methods\\ncan be categorized into three main perspectives:\\nquality, diversity, and importance (see Fig. 1). 2) a\\nsystematic view of selection methods can be uni-\\nfied even they more or less exhibit coupling with\\nthe assessment techniques (see Fig. 2). It is noted\\nthat quality, diversity, and importance might be\\nused interchangeably without strict discrimination\\nin previous studies. But here we provide a ratio-\\nnalized organization taxonomy for structured elab-\\noration. Despite the goal of being comprehensive,\\narXiv:2408.02085v3  [cs.CV]  7 Aug 2024\\nFigure 1: Categorization of data assessment and selection methods for efficient LLM instruction tuning.\\nthe present survey only provides details of certain\\ntypical, representative methods to avoid being te-\\ndiously long. We hope the in-depth explanations\\nand discussions on the selected methods provide\\ninsights into developing robust data assessment and\\nselection pipelines for further studies.\\n1.1\\nRelated Surveys\\n(Liu et al., 2024d) studies the mainstream datasets\\nfor building LLMs, including the pre-training\\ncorpora, instruction tuning datasets, preference\\ndatasets, evaluation benchmarks, and traditional\\nNLP datasets. (Albalak et al., 2024) presents a sys-\\ntematic overview of constructing the data pipeline\\nfor language models. Any selection method, ei-\\nther via distribution matching or diversification,\\ncan be composed of: 1) utility function; 2) selec-\\ntion mechanism. During different stages of the\\npipeline (e.g., language filtering, data quality, do-\\nmain knowledge, deduplication, toxic and explicit\\ncontent removal, and data mixing), the selection\\nmethod should be adjusted according to different\\nselection objectives. (Wang et al., 2024a) focuses\\non the data preparation for instruction tuning. Exist-\\ning methods on building instruction tuning datasets\\ninclude: 1) reformulating the discriminative NLP\\ndatasets into generative ones; 2) self-instruct with\\nseed prompts; 3) prompt mapping and evol-instruct.\\nPopular methods on dataset selection can be simply\\nclassified as: 1) system of indicators; 2) trainable\\nLLMs; 3) powerful LLMs; and 4) small models.\\n(Guo et al., 2022) starts from the general core-\\nset selection method in the field of deep learn-\\ning and categorize all selection manners into: 1)\\ngeometry-based methods (e.g., herding, kcenter-\\ngreedy); 2) uncertainty-based methods (e.g., least\\nconfidence/entropy/margin); 3) error/loss-based\\nmethods (forgetting; GraND/EL2N; importance re-\\nsampling); 4) decision boundary-based (adversarial\\ndeepfool; contrastive active learning); 5) gradient\\nmatching-based (gradient approximation towards\\nfull set); 6) bi-level optimization-based (inner loop\\nof model optimization and outer loop of datapoint\\nselection); 7) sub-modularity-based (e.g., graph\\ncut; facility location); 8) proxy-based (preference\\nof a small model on data selection). (Zhou et al.,\\n2024b) investigates the potential metrics and as-\\npects for data quality measurement and provides\\na list of available tools for data evaluation. Apart\\nfrom data assessment and selection methods that\\nspecifically designed for NLP or LLM applica-\\ntions (Moore and Lewis, 2010; Chen et al., 2024a;\\nDodge et al., 2020; Kandpal et al., 2022; Li et al.,\\n2022; Feng et al., 2021; Lee et al., 2021; Malho-\\ntra and Bakal, 2015; Liu et al., 2024e), there ex-\\nist many survey studies that tackle general quality\\nmeasurement in machine learning (Gupta et al.,\\n2021; Zha et al., 2023; Ehrlinger and Wöß, 2022;\\nMohammed et al., 2024; Li et al., 2024c; Lu et al.,\\n2023b; Dix et al., 2023; Priestley et al., 2023;\\nByabazaire et al., 2020; Roh et al., 2019; Sidi et al.,\\n2012; Batini et al., 2009) for constructing safe, un-\\nbiased, and accurate datasets.\\n1.2\\nSurvey Scope\\nAlthough “data evaluation\" has been so frequently\\nmentioned that it appears as a cliché problem in\\ndeveloping machine learning algorithms, the opti-\\nmal solution to establishing an overall data assess-\\nment and selection pipeline still remains an open\\nquestion. Especially under the context of instruc-\\ntion tuning of LLMs, existing studies propose vari-\\nous measurement and cleaning strategies to select\\nthe “high-quality\" instructions from all datapoints.\\nFigure 2: A high-level overview of comprehensive data assessment and selection. Most analysis aspects that evaluate\\neach datapoint and the overall dataset are categorized into three groups marked in blue italic.\\nHowever, very few studies notice that there ex-\\nists no unified dimensions or aspects in measuring\\ndata “quality\" where previous works tend to put em-\\nphasis on the domain-specific and task-dependent\\ncharacteristics. In addition, the inherent, system-\\natic coupling between data assessment and subset\\nselection methods is not well demonstrated.\\nUnder such circumstance, the present study\\nstrives to provide a comprehensive review on evalu-\\nating and decomposing massive instruction tuning\\ndatasets. We categorize the main aspects of data\\nassessment in terms of quality, diversity, and im-\\nportance. In each aspect, we provide a detailed\\nsurvey on both traditional (e.g., hand-crafted indi-\\ncators) and machine learning (e.g., model-based\\nindicators) methods. Besides, the coreset sampling\\nmethods that fuses evaluation and selection are in-\\ntroduced separately in diversity and importance\\noriented subset construction. In consideration of\\nthe properties of instruction tuning, we focus on the\\ntext modality and start from classical text analysis\\nmetrics. Metrics that are either specific to instruc-\\ntion tuning or compatible with pre-training and\\npreference alignment datasets are included since\\nthey all share general rules in data assessment.\\nThe survey is organized as follows. First, we\\npresent the preliminaries for assessment and se-\\nlection of instruction tuning datasets (Sec. §2).\\nNext, we present the surveying methods of data\\nassessment and selection methods in terms of qual-\\nity (Sec. §3), diversity (Sec. §4), and importance\\n(Sec. §5). Then, discussions on the existing meth-\\nods are provided in (Sec. §6), followed by the\\npromising directions for future research (Sec. §7).\\nThe final conclusion is given in (Sec. §8).\\n2\\nPreliminaries\\nIn this section, we briefly introduce the instruction\\ntuning of LLMs and the problem statement for\\ndataset assessment and selection.\\nInstruction Dataset Preparation\\nIn instruction\\ntuning, each text sample Ii is usually composed of\\nthree parts: 1) instruction (either with or without\\nsystem prompt), 2) input, and 3) response. For\\nan off-the-shelf pre-trained LLM parameterized as\\nθ, a pre-determined instruction template is used\\nto wrap Ii into the prompt pi with special tokens\\nlike “<|im_start|>\" and “<|im_end|>\" for sep-\\naration of roles (e.g., system, user, assistant,\\nfunction, and observation) and their contents.\\nThen, a LLM-associated tokenizer performs to-\\nkenization on the instruction prompt pi for a se-\\nquence of xi = {xi(1), xi(2), ..., xi(n)}, where xi(j)\\ndenotes the j-th token of xi and n is the total num-\\nber of tokens. Out of simplicity, the token sequence\\nxi can be simply split into two parts by the index t\\nwhere the content from the role assistant starts:\\n1) the instruction (input) part (xi(<t)), and 2) the\\nground-truth response part (xi(≥t)).\\nInstruction Supervision\\nGiven the tokenized in-\\nstruction tuning dataset S = {xi}N\\ni=1, the super-\\nvised tuning is performed via cross-entropy loss:\\nL =\\nX\\nxi∈S\\nLi,\\nLi = −\\n|xi|\\nX\\nj=t\\nlogP(xi(j)|xi(<j); θ).\\n(1)\\nFor each xi, the model iteratively predicts the next\\ntoken given xi(j) all previous tokens including the\\ninstruction context and the response completions\\nup to the current token xi(< j).\\nData Assessment and Selection\\nWe aim at find-\\ning the most informative subset Sb ⊂S from the\\nentire set S under the given budget |Sb| ≤b. Math-\\nematically, the selection of Sb requires the quanti-\\ntative evaluation q(·) on each datapoint xi and an\\nelaborated sampling mechanism π:\\nS∗\\nb = π(arg max\\nxi∈S q(xi), b),\\n(2)\\nwhere π(·, b) denotes the sampling process with a\\nmaximum b datapoints. With respect to the detailed\\nimplementation of π, either an iterative, greedy\\nalgorithm or a batch-wise heuristic rule can be\\nadopted for compatibility with q(·). The expected\\nbenefits of such selection include: 1) the reduction\\nof noise by ignoring those mislabeled, mismatched\\ninstruction-response pairs, 2) the re-balance of data\\ndistributions by down-sampling those easy, com-\\nmon, and similar examples while up-sampling hard,\\nrare ones, and 3) the expedition of training in return\\nfor efficient iterations of LLMs.\\n3\\nQuality-based Selection\\nIn this section, we present methods on quality as-\\nsessment and selection. Without lose of general-\\nity, the term “quality\" here primarily refers to the\\nintegrity, accuracy, and rationality of instruction-\\nresponse datapoints.\\nFor integrity, it measures\\nwhether the instruction and response are under-\\nstandable and complete in both format and content.\\nFor accuracy, it estimates whether the “ground-\\ntruth\" response truly corresponds to the instruction.\\nFor rationality, we focus on the consistency and co-\\nherency of the instruction context. Although these\\nthree dimensions all contribute to the overall qual-\\nity, in general, existing methods often formulate a\\nunified scoring mechanism to implicitly consider\\nthem partially or comprehensively.\\n3.1\\nHand-crafted Indicators\\nOverview\\nTraditional methods develop hand-\\ncrafted indicators to evaluate the data quality in\\nterms of linguistic analysis such as vocabulary, syn-\\ntax, and inter-sample semantic similarity. Each\\nindicator is manually, empirically designed with\\nprior knowledge on the language, domain, and task\\nof the corpus under investigation. The calculation\\nof each indicator is explicitly defined and does not\\nrequire training and inference of proxy models or\\nlanguage models. Although the indicators are hand-\\ncrafted, deep learning models such as sentence en-\\ncoders might be leveraged to extract embedding\\nrepresentations for each instruction text. For the\\ndatapoint xi, its indicator INDi can be typically\\ndefined as:\\nINDi = f(IND1(xi), IND2(xi),\\nIND3(xi), ...INDM(xi)),\\n(3)\\nwhere M denotes the total number of indicators\\nand f is the aggregation function which depends\\non both the instruction task and dataset. One can\\nsimply use linear combination with pre-defined\\nor dynamically adjusted weights while meticulous\\ntuning might be needed for the ultimate f. Given\\nthe indicators INDi for each xi, two intuitive se-\\nlection methods can be adopted: 1) to filter out\\ndatapoints whose indicator scores are below a pre-\\ndefined threshold; 2) to keep only the samples\\nwhose indicator scores rank within a certain range\\nof percentiles. Mathematically, these two selection\\nmechanism can be respectively represented as:\\nSπ = {xi|τmin < f(xi) < τmax, 1 ≤i ≤N},\\n(4)\\nSπ = {xi|Pmin ≤ˆFf(f(xi)) ≤Pmax, 1 ≤i ≤N},\\n(5)\\nwhere τmin and τmax respectively denote the left\\nand right threshold boundaries. The estimated ˆFf\\nis the empirical cumulative distribution function of\\nall indicators f. Pmin and Pmax respectively refer\\nto the minimum and maximum percentile for en-\\nclosing the selection range. In practice, both the\\nthreshold and percentiles are hyper-parameters that\\nrequire task-specific fine-tuning.\\nTechnical Details\\n(Mishra et al., 2020b) and\\n(Mishra et al., 2020a) introduce a data quality met-\\nric, namely the DQI, to quantify the differences\\nbetween successive benchmarks by giving high\\nscores to generalizable samples and low scores to\\nbiased samples. Such a metric implies whether\\na well-trained model truly learns the underlying\\ntask rather than overfitting the spurious bias of\\nspecific benchmarks. Specifically, DQI has seven\\ncomponents including vocabulary, inter-sample N-\\ngram frequency and relation, inter-sample semantic\\ntextual similarities (STS), intra-sample word sim-\\nilarity, intra-sample STS, N-Gram frequency per\\nlabel, and inter-split STS. Based on the proposed\\nDQI, (Mishra and Sachdeva, 2020) proposes to\\nprune existing huge NLP datasets and demonstrates\\nthat the model trained on only 2% of the SNLI\\ndataset achieves near-equal performance with that\\non the entire set. It first performs AFLite (Le Bras\\net al., 2020), which is detailed in , to keep sam-\\nples with predictability scores over a pre-defined\\nthreshold and then delete bottom k samples with\\nlowest DQI scores. (Dang and Verma, 2024) fur-\\nther split DQI components into linguistic indicators\\nand semantic indicators, and validate their respec-\\ntive roles in detecting outliers, noises, and duplica-\\ntions. Apart from training-oriented data selection,\\nquality indicators can also be employed to identify\\nthe most discriminative samples in the evaluation\\nset to expedite evaluation of LLMs. (Saranathan\\net al.) investigates key indicators such as spelling\\nerrors (Yannakoudakis and Fawthrop, 1983), av-\\nerage word length, excessive word repetition, and\\nthe compound probability distribution. These in-\\ndicators stem from the traditional studies on text\\nreadability (i.e., readability formulas and sophis-\\nticated features) (Klare et al., 1963, 1984; Dubay,\\n2004; Kintsch and Vipond, 2014; Kemper, 1983).\\nRecent studies on readability leverage NLP sys-\\ntems to extract more advanced and informative fea-\\ntures for readability measures (Si and Callan, 2001;\\nCollins-Thompson and Callan, 2005; Schwarm and\\nOstendorf, 2005; Feng et al., 2010). (François,\\n2010, 2011; François and Fairon, 2012) systemati-\\ncally analyze the lexical features, syntactic features,\\nsemantic features, and language-specific features\\nwith up to 46 indicators. (François and Miltsakaki,\\n2012) validates these manually-designed (classical)\\nand NLP-enabled (non-classical) readability formu-\\nlas, implying that high-quality text corpus can be\\npinpointed by such carefully designed metrics. (Fe-\\nlice and Specia, 2012) finds that the hand-crafted\\nlinguistic features should be combined with other\\nshallow features for better quality estimation.\\nRemark\\nThe hand-crafted indicators often stem\\nfrom studies on linguistic analysis and readabil-\\nity measurement. Although these indicators help\\nfilter out instruction samples that are unreadable,\\nnonsensical, and incoherent, they cannot detect mis-\\nmatched instruction-response pairs and therefore\\nfail to guarantee the instruction-following capabil-\\nity of LLMs trained on highly-scored datasets.\\n3.2\\nModel-based Indicators\\nOverview\\nThe model-based indicators, on the\\nother hand, leverage trainable models to predict\\nthe indicators for each instruction datapoint. The\\ntrainable models used for data quality measure-\\nment can either share the same or similar architec-\\nture with the language model under development,\\nor possesses completely different implementation\\nchoices. Accordingly, these indicators can be sim-\\nply defined as:\\nINDi = f(IND1\\nθ(xi), IND2\\nθ(xi),\\nIND3\\nθ(xi), ...INDM\\nθ (xi)),\\n(6)\\nwhere the learnable parameters θ highlight the dif-\\nference between model-based and hand-crafted in-\\ndicators. Based on the computed indicators, similar\\nselection mechanisms (Eqs. 45) can be adopted to\\nselect favorable datapoints.\\nTechnical Details\\nOne of the most intuitive\\nmodel-based indicators is perplexity (Shannon,\\n2001; Jelinek et al., 1977; Jelinek, 1980). It is\\nfrequently mentioned as the evaluation metric for\\npre-trained language models (Penedo et al., 2023;\\nRadford et al., 2018, 2019; Brown et al., 2020;\\nAchiam et al., 2023) but can also be employed as\\na data quality indicator. (Ankner et al., 2024) pro-\\nposes to use a small GPT-style reference model\\nsuch as MPT 125M (Team, 2023) to prune dataset\\nvia perplexity-based sampling for training a 3B\\nmodel. Specifically, for any datapoint xi, the per-\\nplexity is defined as the exponential of negative\\nlikelihood with base of 2:\\nNLLi =\\n1\\n|xi|\\n|xi|\\nX\\nj=1\\n−logP(xi(j)|xi(<j); θ)\\nPPLXi = 2NLLi\\n(7)\\nBased on the perplexity inferred from a small\\nmodel, samples at the high and medium per-\\ncentiles are chosen by Eq. 5 for downstream fine-\\ntuning.\\n(Deng et al., 2021) develops a unified\\nevaluator framework to score the generated out-\\nputs for natural language generation tasks.\\nA\\nRoBERTa-based (Liu et al., 2019) discriminator\\nlearns to score responses in terms of consistency,\\nrelevance, preservation, engagingness, and ground-\\nedness. One could simply adopt such a discrim-\\ninator for evaluation of the instruction-response\\npairs. (Zhong et al., 2022) further proposes a multi-\\ndimensional scoring evaluator. For each evaluation\\ndimension, the original ground-truth instruction-\\nresponse pairs are converted into positive samples\\nin the form of boolean question-answer problems.\\nThe negative samples are respectively constructed\\nvia rule-based transformation. The evaluator itself\\nis implemented as T5 model (Raffel et al., 2020)\\nand trained on these positive and negative samples\\nfor scoring in the range from 0 to 1. (Jiang et al.,\\n2024c) prunes the UltraChat (Ding et al., 2023)\\ndataset by scoring each datapoint by learning com-\\nplexity of a pre-trained Qwen-1.8B model (Bai\\net al., 2023). Specifically, the learning complexity\\nis calculated as the averaged prediction confidence\\nof different subnets:\\n˜S(xi) = 1\\nI\\nI\\nX\\nj=1\\nPPLX−1\\ni;Θj,\\n(8)\\nwhere I is the number of subnets. Each subnet\\nΘj is obtained by adjusting the dropout rate from\\n10% to 90% on the original Θ of any pre-trained\\nlanguage model. Instruction datapoints with small\\n˜S(xi) are easy ones and should be kept first during\\npruning. Both (Bukharin and Zhao, 2023) and (Du\\net al., 2023) employ reward models to assess the\\nquality of each instruction pairs. They respectively\\nutilize the raft model (Dong et al., 2023) and the\\ndeberta-v3-large-v2 1 for reward scoring:\\nRi = rθ(xi(<t), xi(≥t)),\\n(9)\\nwhere rθ denotes the reward model. t is the in-\\ndex where xi(<t) and xi(≥t) respectively denote\\nthe instruction Q and response A. (Marion et al.,\\n2023) investigates three classic metrics in clean\\nset selection (Guo et al., 2022; Song et al., 2022;\\nNatarajan et al., 2013; Qin et al., 2024): perplexity\\n(Eq. 7), error l2-Norm (EL2N) (Paul et al., 2021),\\nand memorization ranking (Biderman et al., 2024).\\nSpecifically, EL2N is defined as:\\nEL2Ni =\\n1\\n|xi|\\n|xi|\\nX\\nj=1\\n∥P(xi(<j); θ)−yi(j)∥2, (10)\\n1https://huggingface.co/OpenAssistant/reward-model-\\ndeberta-v3-large-v2\\nwhere yi(j) ∈RNvocab denotes the one-hot vector\\nof the vocabulary size Nvocab, where its element\\nindexed at xi(j) equals one. The memorization\\nranking is represented as:\\nMEMi =\\n1\\nNwin\\nNwin\\nX\\nj=1\\n1(ˆxi(Moffset+j) = xi(Moffset+j)),\\n(11)\\nwhere Nwin denotes the length of a consecutive\\nsequence and Moffset is an offset of the starting\\nindex. The ˆxi(Moffset+j) refers to the generated to-\\nken given input xi(<Moffset+j), and xi(Moffset+j) is its\\nground-truth. (Cao et al., 2023) combines both\\nhand-crafted indicators (e.g., input length, output\\nlength, MTLD (McCarthy and Jarvis, 2010), and\\nkNN-i (Dong et al., 2011)) and model-based in-\\ndicators (e.g., reward score, perplexity, and Uni-\\nEval metrics (Zhong et al., 2022)) for fitting the\\nloss of a LLM on the evaluation set. The linear\\nregression model is optimized via least squares\\nmethod (Bjork, 1988) and the optimal selection of\\ninstruction data is achieved via BlendSearch (Wang\\net al., 2021a,b) for minimizing the estimated eval-\\nuation loss. (Li et al., 2023a) is one of the most\\npioneering works that leverages the target language\\nmodel itself to perform self-guided data selection.\\nThe language model is first “warmed-up\" with very\\nfew samples randomly chosen from the pool to\\nlearn from brief experience. Then, such an expe-\\nrienced model evaluates each instruction-response\\npair via the instruction-following difficulty (IFD)\\nscore. The IFD score measures how much guid-\\nance or assistance the instruction provides to the\\ngeneration of ground-truth response, by compar-\\ning the loss of causal language modeling on the\\nresponse with and without instruction:\\nIFDi = NLLA|Q\\ni\\nNLLA\\ni\\n,\\nNLLA|Q\\ni\\n=\\n1\\n|xi(≥t)|\\n|xi|\\nX\\nj=t\\n−logP(xi(j)|xi(<j); θ),\\nNLLA\\ni =\\n1\\n|xi(≥t)|\\n|xi|\\nX\\nj=t\\n−logP(xi(j)|xi(t≤,<j); θ),\\n(12)\\nwhere the index t splits apart the instruction Q and\\nthe response A. Samples whose IFD scores over\\nτmax = 1 are invalid datapoints with misaligned,\\nmismatched instruction-response pairs. The empir-\\nical setting of τmin affects the trade-off between\\nquality and diversity of the selected datapoints.\\n(Zhao and Fang, 2024) comprehensively employs\\nhand-crafted indicators for low-level quality filter-\\ning, and uses perplexity and IFD score for high-\\nlevel filtering. A voting mechanism is addition-\\nally introduced with IFD scores from one pre-\\ntrained base model and one fine-tuned experience\\nmodel. (Li et al., 2024b) corroborates that both the\\nperplexity and IFD scores inferred from a rather\\nsmall GPT2-125M (Radford et al., 2019) are in-\\ndicative in selecting high-quality datapoints for\\ntraining LLaMA2-7B and LLaMA2-13B (Touvron\\net al., 2023b), which greatly improves selection\\nefficiency.\\nAnother popular model-based quality filtering\\nmethod is AF-Lite (Le Bras et al., 2020), which\\nhas been applied and validated in recent NLP stud-\\nies (Mishra and Sachdeva, 2020; Sakaguchi et al.,\\n2021). It randomly partition all available datapoints\\ninto training set and validation set. Then, a model\\n(e.g., linear classifier or language model) is trained\\non the training set and inferred on the validation\\nset. Such process iterates m times for calculation\\nof the predictability score, which is defined as the\\nratio of the number of correctly predicted response\\nover the number of total predictions:\\nPREDi = |{ˆxi ∈Ei, s.t. ˆxi = xi}|\\nEi\\n,\\nEi = {ˆxθ1\\ni , ˆxθ1\\ni , ..., ˆxθj\\ni , ..., ˆxθm\\ni },\\n(13)\\nwhere ˆxθj\\ni denotes the generated response from the\\nmodel parameterized as θj. It is noted that xi is not\\ninvolved for optimizing θj, and therefore a higher\\nPREDi suggests better quality.\\n(Bhatt et al., 2024) presents uncertainty-based\\nquality indicators such as mean entropy (Settles,\\n2011; Kremer et al., 2014), least confidence (Set-\\ntles, 1995, 2011), mean margin (Tong and Koller,\\n2001; Balcan et al., 2006; Settles, 2011), and min\\nmargin (Nguyen et al., 2022). Mathematically, such\\nuncertainty indicators are defined as:\\nU entropy\\ni\\n=\\n1\\n|xi|\\n|xi|\\nX\\nj=1\\nP(xi(j)|xi(<j); θ)·\\nlogP(xi(j)|xi(<j); θ).\\n(14)\\nU confidence\\ni\\n= −\\n|xi|\\nY\\nj=1\\nP(xi(j)|xi(<j); θ).\\n(15)\\nU margin\\ni\\n= −1\\n|xi|\\n|xi|\\nX\\nj=1\\n(β1(P(xi(<j); θ))−\\nβ2(P(xi(<j); θ))),\\n(16)\\nU min-margin\\ni\\n= −\\nmin\\nj∈{1,2,...,|xi|}(β1(P(xi(<j); θ))−\\nβ2(P(xi(<j); θ))),\\n(17)\\nwhere β1 and β2 denote the largest and second\\nlargest element of the probability P(xi(<j); θ) ∈\\nRNvocab for the newly generated j-th token. How-\\never, (Wu et al., 2023) finds that such uncertainty-\\nbased data sampling methods perform worse than\\nrandom sampling on Databricks-Dolly (Conover\\net al., 2023), SelfInstruct-Davinci (Taori et al.,\\n2023), and SelfInstruct-GPT4 (Peng et al., 2023).\\nRemark\\nHybrid techniques that simultaneously\\ncombines perplexity, uncertainty, reward scores,\\nand other training-aware metrics are promising in\\nselecting unbiased high quality samples. In con-\\nsideration of the training and inference cost, it is\\nfeasible to employ small proxy models as alterna-\\ntives for computing model-based indicators.\\n3.3\\nGPT Score\\nOverview\\nThe invoking of OpenAI APIs (Tin-\\ngiris\\nand\\nKinsella,\\n2021;\\nLappalainen\\nand\\nNarayanan, 2023; Sun et al., 2023; Kublik and Sa-\\nboo, 2023) for ChatGPT services (e.g., GPT3.5,\\nGPT4) allows automatic scoring of instruction tun-\\ning datasets. Recent studies on bringing LLMs as\\njudges (Zheng et al., 2024; Wang et al., 2023a; Zhu\\net al., 2023; Huang et al., 2024; Zeng et al., 2023;\\nChan et al., 2023) reveal that powerful language\\nmodels like ChatGPT highly align with human pref-\\nerence on judging the quality of instructions and re-\\nsponses. Given a well-designed prompt with clear\\ndefinition on grading criteria, ChatGPT produces\\njustified quality scorings with explanations:\\nGPTScorei = G(xi, pG),\\n(18)\\nwhere pG denotes the prompt template that de-\\nfines the task and grading scheme with format con-\\nstraints on outputs. G represents the quality score\\nparsed from the GPT response. Samples with high\\nGPTScorei can be selected using Eqs. 4 and 5.\\nPrompt pG for scoring xi with instruction\\n(input) and response in the <dimension>\\nWe would like to request your feedback on the\\nperformance of AI assistant in response to the\\ninstruction and the given input displayed following.\\nInstruction: <instruction>\\nInput: <input>\\nResponse: <response>\\nPlease rate according to the <dimension> of\\nthe response to the instruction and the input. Each\\nassistant receives a score on a scale of 0 to 5,\\nwhere a higher score indicates higher level of the\\n<dimension>.\\nPlease first output a single line containing the\\nvalue indicating the scores. In the subsequent line,\\nplease provide a comprehensive explanation of your\\nevaluation, avoiding any potential bias.\\nTechnical Details\\n(Chen et al., 2023b) proposes\\na surprisingly easy-yet-effective method that di-\\nrectly uses GPT3.5 to score datapoints in terms\\nof helpfulness and accuracy (see the detailed\\nprompt 3.3). Both instructions and responses are\\nscored on a scale from 0 to 5 and experimental\\nresults show that general instruction datasets, ex-\\ncept coding-related samples, can be distilled into\\nsmaller subsets for better downstream performance.\\n(Bukharin and Zhao, 2023) follows (Chen et al.,\\n2023b) for filtering Alpaca (Taori et al., 2023).\\n(Chen and Mueller, 2024) employs the BSDetec-\\ntor (Chen and Mueller, 2023) to estimate the con-\\nfidence of GPT3.5/GPT4 on the give instruction-\\nresponse pair. It takes both the self-consistency\\nand direct scoring into consideration. Only highly\\nconfident samples are kept for fine-tuning domain-\\nspecific LLMs and those less confident ones are\\ncorrected automatically by these LLMs. (Xu et al.,\\n2023b) directly evaluates instruction datasets in\\nterms of accuracy, explanation, clarity, and diffi-\\nculty for weighted scorings from GPT4. Then, both\\nhand-crafted indicators (i.e., lengthwise semantic\\nevaluation) and GPT4 scorings are employed for\\nfinal ranking. (Liu et al., 2023b) argues that the\\ndirect scoring of GPT4 on one single instruction\\nsample is not well-calibrated and instead gives rela-\\ntive ranking of multiple instruction variants at once.\\nThe complexity of instructions (Xu et al., 2023a)\\nand the quality of instruction-response pairs are\\nsequentially obtained from GPT3.5. (Zhang et al.,\\n2024c) uses GPT scorings to judge: 1) whether\\nthe given text contains mathematical contents; 2)\\nand if yes, whether these maths contents are of\\nhigh quality for education purpose. Such scores\\nare proved more effective than traditional “mathe-\\nmatical\" classifiers (Paster et al., 2023). (Lu et al.,\\n2023a) proposes to use ChatGPT for annotating\\nopen-ended, fine-grained intention tags on open\\ndatasets. Then, the quality of the tag dataset is\\nevaluated by humans and GPT4 in terms of tagging\\nprecision and consistency. Instead of fully relying\\non the GPT4, (Li et al., 2023c) exploits the model\\nunder investigation itself (e.g., LLaMA 65B) to\\niteratively derive quality scores on each augmented\\nexample on a 5-point scale. Then a curated clean\\nset is chosen via Eq. 4.\\nQuRator (Wettig et al., 2024) manually defines\\nquality criterion such as writing style, facts and\\ntrivia, educational value, and required expertise.\\nThen, quality comparison is conducted on two\\ninstruction-response samples via GPT3.5 scoring.\\nSuch pairwise scorings are used to fine-tune a\\nsheared-LLaMA 1.3B model (Xia et al., 2023) in\\na manner similar to DPO (Ouyang et al., 2022;\\nRafailov et al., 2024). It is noted that pairwise scor-\\ning (Ouyang et al., 2022; Dubois et al., 2024; Zeng\\net al., 2023; Liu et al., 2023b) have been found\\nmore reliable, consistent, and unbiased than indi-\\nvidual scoring (Gunasekar et al., 2023; Chen et al.,\\n2023b) during GPT-based quality analysis.\\nRemark\\nClosed-source LLMs such as ChatGPT\\nenjoy a high level of alignment with human prefer-\\nence and therefore can be utilized to score data\\nquality. It would be more cost-efficient to col-\\nlect few (e.g., <100K) GPT-scored samples first\\nand then fine-tune an open-source LLM for quality\\nmeasurement on massive instruction corpus.\\n3.4\\nHuman Evaluation\\nOverview\\nHuman annotation and evaluation is\\nindispensable in constructing preference alignment\\ndatasets (Wang et al., 2023b; Ouyang et al., 2022)\\nfor helpfulness, honesty, and harmlessness. Specif-\\nically, human annotators deliver grading results\\nfollowing specific criteria in multiple dimensions:\\nLabelScorei = f(LabelScore1(xi),\\nLabelScore2(xi), ..., LabelScoreM(xi)),\\n(19)\\nwhere LabelScorem(xi) can be both bool or in-\\nteger (e.g., range from 0 to 5) for the m-th fine-\\ngrained aspect. The aggregation function f is com-\\nmonly chosen as summation or averaging.\\nGuidelines (excerpts) for human annota-\\ntions\\n# Guidelines\\nBelow is a list of guidelines that should be adhered\\nto for each possible task available when building the\\ndataset. To see some examples of how the guidelines\\ncan be applied, visit the examples document.\\n## 1. General rules\\n- Always make sure to read and understand the\\nguidelines to each task before fulfilling it. - Try to\\nfollow the guidelines as closely as possible. - If you\\nare unsure whether a message violates a guidelines,\\ncontact us at our Discord.\\n- Use the thumbs-up/thumbs-down system to further\\nmark messages that are of high or low quality.\\n## 2.\\nProviding an assistant reply #assistant-\\nreply\\n### Do:\\n- Remain polite and treat the user with respect, even\\nwhen not given the same courtesy.\\n...\\nTechnical Details\\nThe OpenAssistant (Köpf\\net al., 2024) dataset is featured by its high-quality\\nhuman-generated, human-annotated multi-lingual\\nconversations for both instruction tuning and re-\\ninforcement learning from human feedback (see\\nthe guidelines excerpts 3.4). For each instruction-\\nresponse pair along the conversation tree, the hu-\\nman annotators are asked to categorize them ac-\\ncording to three dimensions: spam detection, guide-\\nline adherence, and quality. The quality score is\\nrated on a five-point Likert scale across aspects\\nincluding quality, creativity, humorousness, polite-\\nness, and harmlessness. These scores are used to\\nsort instructions for analysis and preference op-\\ntimization of LLMs.\\n(Lu et al., 2023a) enrolls\\nhuman annotators to provide judgements on the\\ntagging of each instruction. To verify the quality\\nscores provided by humans, counterfactual cases\\nare prepared respectively for precision and consis-\\ntency tasks. Results show that human annotators\\nhave low false positive rates at tagging precision,\\nbut lack proof of confidence on their original qual-\\nity judgements. (Zhou et al., 2024a) proposes to\\nuse human annotators for creation of small-yet-\\neffective instruction datasets. To collect questions\\nand answers from various sources, simple hand-\\ncrafted indicators such as text length are used to\\nfilter low-quality datapoints. Then, high quality\\ninstruction-response pairs are manually selected\\n(750) and written (250) via subjective quality con-\\ntrol. The databricks-dolly dataset (Conover et al.,\\n2023) contains 15K human-generated instruction-\\nresponse pairs. Although quality is emphasized dur-\\ning large-scale annotation, imperfect samples still\\nexist where low-quality and inaccurate responses,\\nincomplete and vague instructions, problematic\\ntexts with toxic language and grammar errors are\\nfound (He et al., 2024).\\nRemark\\nHuman evaluation play a irreplaceable\\nrole in quality control of preference alignment. To\\nreduce the inter-annotator inconsistency, detailed\\nguidelines should be prepared for quality measure-\\nment. In addition, supplementary quality measures\\nsuch as GPT-Scores can be provided for manually\\nevaluating and selecting high-quality datasets.\\n4\\nDiversity-based Selection\\nIn this section, we introduce methods that empha-\\nsize the diversity of instruction datasets. When it\\ncomes to diversity, existing researches either mea-\\nsure the individual diversity of each sample (e.g.,\\nlexical and semantic richness) or the overall diver-\\nsity of the entire dataset (e.g., the volume of the\\nenclosed embedding space). Instruction datapoints\\nwhose tasks and domains are of minority classes in\\na long-tailed distribution are preferred during sub-\\nset selection. Such sampling philosophy strikes to\\nmaintain or approximate the spread of the original\\nembedding clusters but with much less sparsity.\\n4.1\\nHand-crafted Indicators\\nOverview\\nThe diversity of datasets is the key to\\ndevelop less biased, more generalizable machine\\nlearning models. However, recent studies (Zhao\\net al., 2024c,b) show that existing vision and lan-\\nguage datasets do not share a unified and concrete\\ndefinition of diversity in terms of dataset composi-\\ntion, source, domain, subject, annotator, and pro-\\nmote (fairness). With respect to the diversity mea-\\nsures specific in instruction tuning datasets, hand-\\ncrafted indicators, similar to Eq. 3 in traditional\\nNLP studies, can be used as a good starting point.\\nTechnical Details\\nOne of the most popular diver-\\nsity measure is lexical diversity, which refers to the\\nrange of different words occurring in one text. The\\ngreater range implies greater diversity and quality.\\nType-token ratio (TTR) (Templin, 1957; Richards,\\n1987) is originally proposed as:\\nTTRi = |Unique(xi)|\\n|xi|\\n,\\n(20)\\nwhere Unique(xi) denotes the set of unique tokens\\npresent in xi. To reduce the sensitivity of TTR to\\nthe variation of text length, several studies (Cov-\\nington and McFall, 2008, 2010; Kettunen, 2014;\\nMatlach et al., 2021) standardized the length by in-\\ntroducing logarithms or n-grams into the formula.\\nLater, computational approaches to measure lex-\\nical diversity have been developed such as vocab-\\nulary diversity (vocd-D) (Malvern and Richards,\\n1997; Malvern et al., 2004; Silverman and Ratner,\\n2002; deBoer, 2014), the measure of textual lexi-\\ncal diversity (MTLD) (McCarthy and Jarvis, 2010;\\nJarvis and Daller, 2013), and hypergeometric distri-\\nbution diversity (HD-D) (Jarvis, 2013; McCarthy,\\n2005). All these metrics require multi-step compu-\\ntation for approximation. Specifically for vocd-D,\\nrandom sampling is first performed on xi for a se-\\nries of sub-sequences with varying lengths k (e.g.,\\n10, 20, 30 tokens). Then, TTRk is:\\nTTRk\\ni = |Unique(xi(j≤,<j+k))|\\n|xi(j≤,<j+k)|\\n, 1 ≤j ≤|xi|−k,\\n(21)\\nwhere xi(j≤,<j+k)) denotes the sub-sequence of\\nxi starting from the randomly chosen index j and\\nending at the index j+k. Then, the curve of TTRk\\ni\\nversus the lengths k is plotted and a mathematical\\nmodel is built for fitting the curve:\\nˆ\\nTTR\\nk\\ni = D\\nk [(1 + 2 k\\nD)\\n1\\n2 −1],\\n(22)\\nwhere D is the only parameter required to be esti-\\nmated. By approximating\\nˆ\\nTTR\\nk\\ni towards TTRk\\ni\\nwith the least squares, we have Dbest fit = D:\\nvocd-Di = D.\\n(23)\\nA larger D reflects the higher diversity of xi. The\\ncomputation of MTLD, on the other hand, first\\ndetermines the TTRi as a pre-defined threshold,\\nand then partitions xi into M different contiguous\\nsubsequences {x1\\ni , x2\\ni , ..., xm\\ni , ..., xM\\ni }. Each sub-\\nsequence xm\\ni\\n= xi(j≤,<j+k), ∀k > 0, ∀1 ≤j ≤\\n|xi| −k maintains a TTRk\\ni above the threshold\\nTTRi. The MTLD is defined as:\\nMTLDi = 1\\nM\\nM\\nX\\ni=1\\n|xm\\ni |.\\n(24)\\nThe HD-D shares the same idea behind vocd-D but\\nstems from the hypergeometric distribution (Mc-\\nCarthy and Jarvis, 2010). With M-times sampling,\\nthe HD-D represents the probability of drawing a\\ncertain number of tokens of the given type from the\\nsubsequence of xi with a particular size k:\\nHD-Di =\\n|Unique(xi)|\\nX\\nt=1\\n1\\nM\\nM\\nX\\nm=1\\n1(xm\\ni(n) = ut,\\n∃1 ≤n ≤|xm\\ni |), ut ∈Unique(xi),\\nxm\\ni =xi(j≤,<j+k), ∀k > 0, ∀1 ≤j ≤|xi| −k.\\n(25)\\nOther variants of TTR indicators such as MT-\\nTRSS (Malvern et al., 2004), MSTTR (Malvern\\net al., 2004), MATTR (Covington and McFall,\\n2010), and MTLD-W (Vidal and Jarvis, 2020; Kyle\\net al., 2021) all target at improving the solutions\\nto two fundamental problems (Bestgen, 2023): 1)\\nthe sensitivity of indicators to text length, and 2)\\nthe impact of the indicator parameters. (Li et al.,\\n2015) proposes two rather simplified TTR scores\\nas distinct-1 and distinct-2, where the number of\\ndistinct unigrams and bigrams of xi are respectively\\ndevided by the total number of words. Many other\\nstudies (Cao and Clark, 2017; Zhu et al., 2018; Shu\\net al., 2019; Tevet and Berant, 2020) extend the\\napplication of n-gram-based diversity measures for\\nmodel-generated responses.\\nApart from lexical diversity, there exists many\\nefficient diversity indicators that are built upon the\\nsemantics of each example. (Dong et al., 2011)\\nproposes to approximate k-nearest neighbor (k-NN)\\ngraph (Peterson, 2009) with arbitrary similarity\\nmeasures on semantic embeddings of large-scale\\ndatasets. Such efficient construction of a k-NN\\ngraph allows the distance of xi to its j-th nearest\\nneighbors to be a feasible diversity measure:\\nkNNj\\ni = d(g(xi), g(Nj(xi))),\\n(26)\\nwhere Nj(xi) denotes the j-th closest neighbor of\\nxi in the embedding space projected by g(·). The\\ncommon choices of the distance function d(·, ·)\\ninclude the Euclidean distance, cosine distance,\\nand Jaccard coefficient distance (Huang et al.,\\n2008). The projection from text (e.g., instruction-\\nresponse pairs) into the embedding space can be\\nachieved with pre-trained sentence BERT (Reimers\\nand Gurevych, 2019; Feng et al., 2020), where\\nan additional pooling operation is performed on\\nthe final output of BERT (Devlin et al., 2018) for\\nsentence embeddings. Note that a higher kNNi im-\\nplies that the sample xi is more unique and should\\nbe kept in subset selection for higher diversity.\\nDue to the fine-grained representation capability of\\nBERT, existing hand-crafted indicators often rely\\non BERT embeddings for similarity or diversity\\nmeasurement (Tevet and Berant, 2020; Zhang et al.,\\n2019; Larson et al., 2019; Yauney et al., 2023).\\nTo improve the generalization of diversity mea-\\nsure, (Xu et al., 2023b) argues that the statistics\\nof feature embedding of each sample itself should\\nbe considered. It does not require additional prior\\nknowledge on the structure of embeddings. Given\\nall datapoints xi ∈S, their semantic embeddings\\nfrom any sentence encoder can be represented as\\nX = [g(x1), g(x2), ..., g(xN)] ∈R|S|×H. The\\nrow variance V ari of each embedding g(xi) in\\nthe reduced dimensional space R|S|×k by principal\\ncomponents analysis (PCA) (Wold et al., 1987) is\\nused as the diversity indicator:\\nV ari =\\n1\\nk −1\\nX\\n(j = 1)k(Yij −µi)2,\\nµi = 1\\nk\\nk\\nX\\nj=1\\nYij\\n(27)\\nwhere the PCA chooses the top-k eigenvectors\\n(V\\n= [v1, v2, ..., vk] with λ1 ≥λ2 ≥... ≥\\nλk) of the covariance matrix Cov = QΛQT =\\n1\\n|S|−1(X −µX)T (X −µX), µX =\\n1\\n|S|\\nP|S|\\ni=1 Xi to\\nproject the original embeddings into more compact\\nand reduced ones via Y = (X −µX)V . Samples\\nwith the highest 20% V ari (via Eq. 5) are selected\\nas the variety-curated dataset.\\nWhen it comes to the overall diversity of a\\ndataset S, the average distance of any sample xi to\\nits closest neighbor in the dataset, namely kNNi,\\ncan be leveraged intuitively:\\nDkNN(S) = 1\\n|S|\\n|S|\\nX\\ni=1\\nkNN1\\ni , xi ∈S.\\n(28)\\nSuch a diversity measure has been widely used in\\ndataset construction and content retrieval (Stasaski\\net al., 2020; Stasaski and Hearst, 2022; Mithun\\net al., 2019; Spyromitros-Xioufis et al., 2015; Sun\\net al., 2024a; Ionescu et al., 2018). (Du and Black,\\n2019) simply performs clustering on all samples\\nwith k-means (Ikotun et al., 2023) into K clusters\\n(C1,C2,...,CK) in the embedding space, and then\\nuses the cluster inertia as diversity indicators:\\nDinertia(S) =\\nK\\nX\\nj=1\\nX\\nxi∈Cj\\n∥g(xi) −µj∥2,\\nµj =\\n1\\n|Cj|\\nX\\nxi∈Cj\\ng(xi).\\n(29)\\n(Lai et al., 2020) develops a diversity metric on the\\ndispersion of a cluster induced by embeddings of\\nall samples, where the cluster is approximated by a\\nmulti-variate Gaussian distribution:\\nDradius(S) =\\nH\\nv\\nu\\nu\\nt\\nH\\nY\\nj=1\\nσj,\\n(30)\\nwhere H is the dimension of the projected embed-\\ndings g(xi) ∈RH and σj denotes the radius of the\\nellipsoid along the j-th axis of the dataset S. The\\ninter-cluster (class) distance can also be used for\\ndiversity measure (Dang and Verma, 2024):\\nDICD(S) = 1\\nK\\nK\\nX\\nj=1\\ndivJS(Pj||P̸=j),\\n(31)\\nwhere Pj denotes the inverse-document frequency\\n(IDF) distribution (Sparck Jones, 1972) of the clus-\\nter Cj and divJS is the Jensen-Shannon divergence.\\nRemark\\nBoth lexical and semantic diversity\\nshould be considered with hand-crafted indicators.\\nThe optimization of individual diversity would con-\\ntribute to the overall diversity of the entire dataset.\\n4.2\\nModel-based Indicators\\nOverview\\nSimilar to Eq. 6, model-based indica-\\ntors on diversity also rely on the target or proxy\\nlanguage model for computing the indices.\\nTechnical Details\\nThe diversity of a dataset S\\ncan be intuitively defined as the sum of rarity mea-\\nsures of each constituting element xi. Accord-\\ningly, entropy-related methods are proposed to es-\\ntimate such rarity. The more uncommon, various\\nsamples exist, the higher diversity the dataset be-\\ncomes. Mathematically, the vanilla entropy (Shan-\\nnon, 1948) is proposed for diversity measures:\\nDentropy(S) = −\\nX\\nxi∈S\\nP(xi|θ) · log2(P(xi|θ)),\\n(32)\\nwhere P(xi) denotes the probability of xi occur-\\nring in the dataset. Later, Rényi entropy (Rényi,\\n1961) introduces an additional parameter α >\\n0, α ̸= 1 for a generalized entropy definition:\\nDRE\\nα (S) =\\n1\\n1 −α log2(\\nX\\nxi∈S\\nP(xi|θ)α).\\n(33)\\nThe parameter α adjusts the element-wise emphasis\\non rare or frequent events.\\nStudies on biology and ecology (Mouillot and\\nLepretre, 1999; Peet, 1974; He and Hu, 2005; Gre-\\ngorius and Gillet, 2008) investigate Simpson’s In-\\ndex (SI) (Simpson, 1949; Wu et al., 2024, 2022)\\nfor measuring the biodiversity of species and ge-\\nnetics. (Zhou et al., 2020) proposes a variant of the\\noriginal SI with a more flexible statistic metric:\\nDSI(S) = 2\\nP\\nxi,xj∈S,i≤j 1(xi = xj|θ)\\n|S|(|S| + 1)\\n,\\n(34)\\nwhere the equivalence of xi and xj is judged by an\\nindicator function parameterized as θ.\\nVendi Score (VS) (Dan Friedman and Dieng,\\n2023; Pasarkar and Dieng, 2023; Nguyen and\\nDieng, 2024) is rencently proposed for diversity\\nmeasurement in machine learning researches. In-\\nspired by the Rényi entropy, a generalized VS met-\\nric (Pasarkar and Dieng, 2023) is defined as below:\\nDV S\\nα (S) = exp(\\n1\\n1 −α log2(\\n|S|\\nX\\ni=1,i∈supp(¯λ)\\n¯λα\\ni|θ)),\\n(35)\\nwhere ¯λi|θ denotes the normalized eigenvalues of\\nthe similarity kernel matrix KS|θ, and supp(¯λ) is\\nthe set of indices of all non-zero eigenvalues. The\\nsmaller α < 1 makes the scoring more sensitive to\\nrare classes and therefore allows accurate diversity\\nmeasurement even under severe class imbalance.\\nOne simple implementation of the similarity kernel\\nKS|θ is to use the Gaussian Radial Basis function k\\nwith feature embeddings as k(g(xi|θ), g(xj|θ)) =\\nexp(−1\\n2∥g(xi|θ) −g(xj|θ)∥2). (Nguyen and Di-\\neng, 2024) further introduces quality scoring into\\nEq. 35 where for each subset Sb ⊂S, its average\\nquality score Q(Sb) =\\n1\\n|Sb|\\nP\\nxi∈Sb INDi is multi-\\nplied with DV S\\nα (Sb) for comprehensive evaluation\\nin terms of quality and diversity.\\n(Miranda et al., 2022) proposes an intrinsic diver-\\nsity coefficient to measure the diversity of a dataset\\nwith Task2Vec embeddings (Achille et al., 2019;\\nNguyen et al., 2019) for distance computation be-\\ntween different tasks. The Task2Vec encodes data\\nfrom different tasks by the diagonal entries of the\\nFisher Information Matrix (FIM). The FIM results\\nfrom fine-tuning only the final (e.g., token classi-\\nfication) layer of a pre-trained model, namely a\\nprobe model (e.g., GPT2 (Radford et al., 2019)),\\nto solve the task. Given a batch of samples B, the\\nmathematical representation of FIM is defined as:\\nˆFB = Exi,j,ˆxi(j)∇θ log P(ˆxi(j)|xi(<j); θ)·\\n∇θ log P(ˆxi(j)|xi(<j); θ)T ,\\n(36)\\nwhere ˆxi(j) denotes the j-th token predicted from\\nthe model parameterized as θ given the real se-\\nquence input xi(<j). The expectation Exi,j,ˆxi(j)\\ntakes an average over the sequence length |xi| for\\neach xi sampled randomly from the batch xi ∈B.\\nThe Task2Vec embedding\\n→\\nfB = diag(FB), where\\ndiag(·) denotes the diagonal entries of FB. Based\\non the Task2Vec embeddings, (Lee et al., 2023)\\nproposes to compute the diversity coefficients ˆdiv\\nspecifically for NLP datasets:\\nD\\nˆdiv(S) = EB1,B2∼Sd(\\n→\\nfB1,\\n→\\nfB2),\\nD\\nˆdiv(S1, S2) = EB1∼S1,B2∼S2d(\\n→\\nfB1,\\n→\\nfB2),\\n(37)\\nwhere d denotes distance measurement (e.g., cosine\\ndistance). Both B1 and B2 are two batches sampled\\nrespectively from the same or different datasets\\nfor diversity measures within or across datasets.\\nExperiments confirm that hand-crafted indicators\\nsuch as the number of latent concepts (Xie et al.,\\n2021) and the richness of vocabulary are positively\\nassociated with the proposed ˆdiv coefficients.\\n(Lu et al., 2023a) develops a diversity measure\\nby open-ended tagging. Specifically, a tagging\\nmodel parameterized by θ is trained with GPT4-\\nlabeled tagging pairs to describe each instruction\\ntuning datapoint xi by its fine-grained, atomic in-\\ntentions and semantics (e.g., tasks and domains).\\nCorrespondingly, the number of tags can be viewed\\nas a diversity indicator for sampling a instruction\\nsubset Sb from the whole set S (see Alg. 1).\\nRemark\\nThe model-based indicators are high-\\nlighted by their flexibility in handling various as-\\npects of diversity either implicitly or explicitly.\\n4.3\\nGeometry-based Coreset Sampling\\nOverview\\nInstead of explicitly calculating the\\ndiversity-aware indicators, recent studies on se-\\nlecting instruction datasets tend to introduce core-\\nset sampling methods for a systematic considera-\\ntion (Guo et al., 2022). Specifically, coreset sam-\\npling aims to find the most informative-and-diverse\\nsubset that represents the entire dataset the most,\\nso that close or even surpassing performance can\\nbe achieved on the language model trained on the\\nsubset with respect to that on the entire set.\\nTechnical Details\\nAmong different categories\\nof coreset sampling methods, geometry-based\\nmethods are the most intuitive and widely-used\\nones (Chen et al., 2012; Agarwal et al., 2020; Sener\\nAlgorithm 1 TagLM-based Diverse Sampling (Lu\\net al., 2023a)\\nRequire: data xi ∈S, a tagging LLM Tθ, a vis-\\nited tag set DB\\nb , and a budget b\\n1: Initialize Sb = ∅\\n2: for each xi ∈S do\\n3:\\nObtain tags Dxi = Tθ(xi)\\n4: end for\\n5: repeat\\n6:\\nInitialize DB\\nb = ∅\\n7:\\nfor each xi = arg maxxi∈S Dxi do\\n8:\\nif |DB\\nb ∪Dxi| > |DB\\nb | then\\n9:\\nSb = Sb ∪{xi}\\n10:\\nDB\\nb = DB\\nb ∪Dxi\\n11:\\nS = S\\\\{xi}\\n12:\\nend if\\n13:\\nend for\\n14: until |Sb| = b\\n15: return Sb\\nand Savarese, 2017; Sinha et al., 2020; Kamalov,\\n2020; Rezazadegan Tavakoli et al., 2011; Kirchen-\\nbauer et al., 2024; Zhou et al., 2023). The intu-\\nition behind is that close samples in the embedding\\nspace often share similar properties with low diver-\\nsity. Therefore, redundant information can be effec-\\ntively suppressed by controlling the minimum dis-\\ntance between any two samples for subset selection.\\nSpecifically, k-center greedy is a typical diversity-\\noriented sampling method for massive pretraining\\nand instruction-tuning corpus (Chen et al., 2023a;\\nBhatt et al., 2024; Wu et al., 2023; Zhao and Fang,\\n2024; Du et al., 2023). It solves the minimax facil-\\nity location (FL) problem (Cornuéjols et al., 1983;\\nFarahani and Hekmatfar, 2009), i.e., selecting the\\nsubset Sb under the given size budget b from the\\nfull set S so that the largest distance between an\\nexample in S\\\\Sb and its closest example in Sb is\\nminimized:\\nmin\\nSb⊂S, |Sb|=b max\\nxi∈S\\\\Sb\\nmin\\nxj∈Sb d(g(xi), g(xj)).\\n(38)\\nThe direct solution to Eq. 38 is NP-hard (Cook\\net al., 1994) and a greedy approximation is pro-\\nposed (Sener and Savarese, 2017) (see Alg. 2). For\\ninitialization of S0\\nb , one can either choose randomly\\nsampled datapoints from S, or use the cluster cen-\\nter points from K clusters (C1, C2, ..., CK) of S\\nvia k-means clustering. Similarly, the farthest point\\nsampling method (Eldar et al., 1997) shares the\\nsame principle that each iteration time only the\\nAlgorithm\\n2\\nK-Center\\nGreedy\\n(Sener\\nand\\nSavarese, 2017)\\nRequire: data xi ∈S, existing pool S0\\nb and a\\nbudget b\\n1: Initialize Sb = S0\\nb\\n2: repeat\\n3:\\nu = arg maxxi∈S\\\\Sb\\nminxj∈Sb d(g(xi), g(xj))\\n4:\\nSb = Sb ∪{u}\\n5: until |Sb| = b + |S0\\nb |\\n6: return Sb\\\\S0\\nb\\nfarthest datapoint relative to the already selected\\ncoreset is chosen from the candidates.\\nIn addition to the k-center greedy, the herding\\nmethod (Chen et al., 2012; Welling, 2009; Huszár\\nand Duvenaud, 2012; Adhikary and Boots, 2022)\\nselects datapoints xi so that the distance between\\nthe coreset center and the full set center is min-\\nimized in the embedding space. For efficiency,\\nit is also approximated via greedy implementa-\\ntion (Chen et al., 2016; Harvey and Samadi, 2014)\\nby adding one sample each time into the Sb to mini-\\nmize the distance between two centers (see Alg. 3).\\nAlgorithm 3 Herding Greedy (Harvey and Samadi,\\n2014)\\nRequire: data xi ∈S, a budget b\\n1: Initialize µ = 1\\nn\\nPn\\ni=1 g(xi)\\n2: Initialize Sb = ∅\\n3: for t = 1 to b do\\n4:\\nu = arg minxi∈S\\\\Sb ∥µ−\\n1\\n|Sb|+1\\nP\\nxj∈Sb∪{xi} g(xj)∥2\\n5:\\nSb = Sb ∪{u}\\n6: end for\\n7: return Sb\\nFurthermore, recent studies tend to develop\\ncomplex heuristic sampling methods that takes\\ngeometry-based diversity into consideration (Jiang\\net al., 2023c; Chan et al., 2021; Xia et al., 2022).\\nSpecifically, the inter-sample similarity of the se-\\nlected coreset is minimized in return for an overall\\nhigh diversity. (Jiang et al., 2024c) proposes to\\npreserve informative subset with the learning com-\\nplexity (see Eq. 8) and implicitly puts constraints\\non its diversity via sampling on the k-means clus-\\nters:\\nDdist(S) = 1\\n|S|\\nX\\nxi∈S\\nmin\\nj̸=i d(xi, xj) ≥C,\\n(39)\\nwhere C denotes the constant that controls the de-\\ngree of diversity. A larger C represents the larger\\ndiversity of the dataset. The detailed procedure can\\nbe found in Alg. 4.\\nAlgorithm 4 Easy and Diverse First Sam-\\npling (Jiang et al., 2024c)\\nRequire: data xi ∈S, existing pool S0\\nb , a budget\\nb, and the number of clusters K\\n1: Initialize Sb = S0\\nb\\n2: arg minC\\nPK\\nj=1\\nP\\nxi∈Cj⊂S ∥g(xi)\\n∥g(xi)∥−µj∥2,\\nµj =\\n1\\n|Cj|\\nP\\nxi∈Cj\\ng(xi)\\n∥g(xi)∥.\\n3: for j = 1 to K do\\n4:\\nSj\\nb = {xi| ˆF ˜S( ˜S(xi)) ≤b\\nK , xi ∈Cj}\\n5:\\nSb = Sb ∪Sj\\nb\\n6: end for\\n7: return Sb\\n(Bukharin and Zhao, 2023) proposes the quality-\\ndiversity instruction tuning (QDIT). It also uses FL\\nfunctions for diversity measure of the subset Sb:\\nDFL(Sb) =\\nX\\nxj∈S\\nmax\\nxi∈Sb sim(g(xi), g(xj)), (40)\\nwhere sim(·, ·) denotes the similarity function\\n(e.g., cosine similarity). If the selected Sb can be\\nwell-representative of the entire set S, then Sb is\\nassumed of high diversity. Given quality scores de-\\nfined by Eq. 18, the detailed mechanism of QDIT\\nis described in Alg. 5 with greedy approximation.\\nAlgorithm 5 QDIT sampling (Bukharin and Zhao,\\n2023)\\nRequire: data xi ∈S, a budget b, and the trade-\\noff hyper-parameter α\\n1: Initialize Sb = ∅\\n2: for t = 1 to b do\\n3:\\nu = arg maxxi∈S\\\\Sb(1 −α) · DFL(Sb ∪\\n{xi}) + α · GPTScorei\\n4:\\nSb = Sb ∪{u}\\n5: end for\\n6: return Sb\\n(Liu et al., 2023b) adopts the quality score-\\nfirst and diversity-aware data selection method\\n(DEITA), where all datapoints are first scored and\\nsorted by quality measurement, and then selected\\nby a geometry-based heuristic criterion (i.e., Repr\\nFilter). Specifically, it considers that for each cho-\\nsen datapoint in Sb, its kNN1\\ni (Eq. 26) should be\\nabove a certain threshold τ so that the overall di-\\nversity DkNN(Sb) (Eq. 28) can be improved. As\\nshown in Alg. 6, the quality and complexity of each\\nsample xi is respectively measured by the trained\\ncomplexity scoring model θC and the quality scor-\\ning model θQ with prompts pC and pQ. Then, sam-\\nples with high GCQ are prioritized but only those\\ndissimilar ones can be kept for the diversity of Sb.\\nAlgorithm 6 DEITA Sampling (Liu et al., 2023b)\\nRequire: data xi ∈S and a budget b\\n1: Compute the combined complexity and qual-\\nity score\\nGCQ(xi)\\n=\\nG(xi, pC|θC) ·\\nG(xi, pQ|θQ)\\n2: u = arg maxxi∈S GCQ(xi|θ)\\n3: Initialize Sb = {u}\\n4: S = S\\\\{u}\\n5: while |Sb| < b do\\n6:\\nu = arg maxxi∈S GCQ(xi|θ)\\n7:\\nif d(g(u), g(N0(u)) > τ, N0(u) ∈Sb\\nthen\\n8:\\nSb = Sb ∪{u}\\n9:\\nend if\\n10:\\nS = S\\\\{u}\\n11: end while\\n12: return Sb\\nAnother series of geometry-based methods\\nfocus on the organization of data structures\\nvia developing clustering-based sampling tech-\\nniques (Citovsky et al., 2021; Tirumala et al., 2024;\\nAxiotis et al., 2024; Shao et al., 2024; Alcoforado\\net al., 2024; Saranathan et al.). With respect to\\nthe clustering criterion, traditional methods em-\\nploy topic modeling with LDA (Blei et al., 2003;\\nRaghuveer et al., 2012; Bui et al., 2017), NMF (Lee\\nand Seung, 2000; Wang and Zhang, 2012; Shen\\nand Si, 2010; Lazar and Doncescu, 2009), TF-\\nIDF (Sparck Jones, 1972; Bafna et al., 2016; Patil\\nand Atique, 2013; Roul et al., 2014), and latent con-\\ncepts (Xie et al., 2021) to assign text corpus into\\nthematic clusters. Most recent studies exploit sen-\\ntence encoding methods (Reimers and Gurevych,\\n2019; Feng et al., 2020) to perform clustering in the\\nembedding space, where the vanilla k-means clus-\\ntering and its variants (Sinaga and Yang, 2020; Ka-\\nnungo et al., 2000; Bandyapadhyay and Varadara-\\njan, 2015), DBSCAN (Deng, 2020; Khan et al.,\\n2014; Cre¸tulescu et al., 2019), and spectral cluster-\\ning (Bach and Jordan, 2003; Von Luxburg, 2007;\\nJia et al., 2014) are widely used. Specifically, (Tiru-\\nmala et al., 2024) proposes to use SemDeDup (Ab-\\nbas et al., 2023) to remove semantically similar\\nexamples for deduplication, which provides a basis\\nof diversity sampling. Then, k-means clustering is\\nperformed in the embedding space and prototype-\\nbased sampling technique (Sorscher et al., 2022) is\\nused. The “prototypical\" samples, whose distance\\nto their assigned cluster centers are small, should\\nbe discarded first to allow more “outliers\" to be\\nkept in Sb during iterative sampling (see Alg. 7).\\nAlgorithm 7 D4 Sampling (Liu et al., 2023b)\\nRequire: data xi ∈S, a budget b, the number of\\nclusters for SemDeDup K1 and the number of\\nclusters for prototypicality K2\\n1: Initialize Sd = ∅, Sb = ∅\\n2: arg minC\\nPK1\\nj=1\\nP\\nxi∈Cj⊂S ∥g(xi)\\n∥g(xi)∥−µj∥2,\\nµj =\\n1\\n|Cj|\\nP\\nxi∈Cj\\ng(xi)\\n∥g(xi)∥.\\n3: for j = 1 to K1 do\\n4:\\nCv\\nj = ∅\\n5:\\nwhile |Cv\\nj | < |Cj| do\\n6:\\nu = arg minxi∈Cj\\\\Cv\\nj sim(g(xi), µj)\\n7:\\nif maxxi∈Cj sim(g(u), g(xi))\\n<\\nτ\\nthen\\n8:\\nSd = Sd ∪{u}\\n9:\\nend if\\n10:\\nCv\\nj = Cv\\nj ∪{u}\\n11:\\nend while\\n12: end for\\n13: arg minC\\nPK2\\nj=1\\nP\\nxi∈Cj⊂Sd ∥g(xi)\\n∥g(xi)∥−µj∥2,\\nµj =\\n1\\n|Cj|\\nP\\nxi∈Cj\\ng(xi)\\n∥g(xi)∥.\\n14: for j = 1 to K2 do\\n15:\\nSj\\nb = {xi| ˆFd(d(xi, µj) >\\nb\\nK2 , xi ∈Cj}\\n16:\\nSb = Sb ∪Sj\\nb\\n17: end for\\n18: return Sb\\n(Axiotis et al., 2024) proposed a k-means cluster-\\nbased sensitivity sampling technique. For each\\nsample in one cluster, its distance to the cluster\\ncenter and the proxy evaluation loss (Feldman and\\nLangberg, 2011) of the center datapoint are both\\nproportional to the probability of being chosed.\\n(Shao et al., 2024) proposes the balanced Cluster-\\nClip sampling. It first performs k-means clustering\\nand then sample datapoints uniformly from each\\ncluster. Different from the uniform sampling, the\\nproposed ClusterClip puts constraints on the max-\\nimum number of each cluster being sampled, and\\ntherefore avoids overfitting of small clusters.\\n(Alcoforado et al., 2024) comprehensively com-\\npare different geometry-based diversity sampling\\ntechniques such as similarity or distance-based\\ngreedy sampling and clustering-based sampling.\\nIt proposes three approaches to select subsets Sb\\nfor human annotation: 1) reverse semantic search,\\n2) ordered clustering, and 3) limited lexical similar-\\nity. For the reverse semantic search, two datapoints\\n(xi, xj) that share the least semantic similarity are\\nfirst sampled as S0\\nb and then iterative selection of\\nthe next most dissimilar element from S is added\\ninto S0\\nb . Its implementation is quite similar to the\\nk-center greedy algorithm (see Alg. 2) except for\\nthe initialization of S0\\nb . For the limited lexical\\nsimilarity approach, the first sample x0 is chosen\\nrandomly for initialization of S0\\nb . For the remain-\\ning b −1 quota, each sample xi is also randomly\\nchosen from S\\\\Sb as long as sim(xi, xi−1) ≤τ,\\nwhere sim(·, ·) here denotes the lexical similarity\\nsuch as BLEU (Papineni et al., 2002) and ROUGE\\nscores (Lin, 2004). The ordered clustering applies\\na hierarchical and density-based clustering algo-\\nrithm like HDBSCAN (Campello et al., 2013) on\\nall samples and sequentially (i.e., from large to\\nsmall clusters) choose the samples of the lowest\\nmembership in each cluster into the subset Sb. Ex-\\nperimental results show that the reverse semantic\\nsearch performs most consistently and competi-\\ntively, while the limited lexical similarity is sen-\\nsitive to the hyper-parameter threshold τ. The or-\\ndered clustering is not robust across datasets and\\nfails to select high-quality samples.\\nRemark\\nGeometry-based sampling is intuitive\\nand effective in diversity control. Most solutions\\nto optimizing the overall diversity can be refor-\\nmulated as variants of an iterative similarity or\\ndistance-based greedy sampling technique. Cluster-\\ning does play an explanatory role in deciphering the\\nembedding structures, making it easier and preciser\\nto control the proportion of selection.\\n4.4\\nBilevel Optimization-based Coreset\\nSampling\\nOverview\\nThe selection of coreset can also be\\nviewede as a bilevel optimization problem (Colson\\net al., 2007; Zhang, 2024; Sinha et al., 2017; Bor-\\nsos et al., 2020; Killamsetty et al., 2021b,c; Zhang\\net al., 2022; Borsos et al., 2024; Pan et al., 2024)\\nthat consists of two loops: 1) the outer loop of opti-\\nmizing the hard masks or soft weights for selecting\\nthe subset Sb from S; 2) the inner loop of optimiz-\\ning the model parameters θ on Sb. Without lose\\nof generalizability, the bilevel optimization with\\nthe self-supervised language modeling loss can be\\nwritten as follows:\\nS∗\\nb = arg min\\nSb⊂S\\nX\\nxi∈Sb,θ=θ∗\\nNLLA|Q\\ni\\n,\\ns.t. θ∗= arg min\\nθ\\nX\\nxi∈Sb\\nNLLA|Q\\ni\\n.\\n(41)\\nTechnical Details\\nThe retrieve method proposed\\nby (Killamsetty et al., 2021c) takes both labeled\\nand unlabeled datasets into consideration, where\\nthe self-supervised loss from the unlabeled set (e.g.,\\nconsistency regularization (Xie et al., 2020; Wang\\net al., 2021c) and entropy regularization (Zhao\\net al., 2020b; Grandvalet and Bengio, 2004; Erkan\\nand Altun, 2010)) contributes to the inter-level and\\nouter-level optimization as well. To improve the\\nrobustness, Glister (Killamsetty et al., 2021b) opti-\\nmizes the outer-level coreset selection on the addi-\\ntionally prepared validation set for the minimized\\nvalidation loss. (Li et al., 2023d) further empha-\\nsizes the role of the validation set in bilevel op-\\ntimization. It not only computes the loss on the\\nvalidation set for adversarial training, but also intro-\\nduces gradient matching (Killamsetty et al., 2021a)\\nwhere the gradient of the model on the selected\\nsubset Sb should be close to that on the entire S.\\n(Borsos et al., 2024) reformulates the coreset\\nsampling as a cardinality-constrained bilevel op-\\ntimization problem. It proposes greedy forward\\nselection and first-order methods that apply to any\\ntwice differentiable models. Variants of the so-\\nlution for acceleration are extended: 1) binary\\nweights, inverse-hessian-vector product approxi-\\nmations, and batch-wise selection; 2) small proxy\\nmodels for fast estimation; 3) enforced sparsity-\\ninducing penalty in the outer loop.\\nThe ScaleBiO (Pan et al., 2024) specifically ad-\\ndresses the data reweighting problem for large-\\nscale LLM instruction tuning. It also prepares an\\nextra validation set Sval for the minimization of\\nthe outer loop. ScaleBio transforms the bilevel op-\\ntimization into the single loop framework with an\\nouter-level problem plus a constraint of the inner-\\nlevel problem. A multiplier α > 0 and a proxy u\\nfor optimizing the original inner loop (i.e., model\\nweights θ) are introduced into the minimax formu-\\nlation (Kwon et al., 2023; Lu and Mei, 2024).\\nIn contrast to a fixed budget b, (Xia et al., 2024b)\\nproposes a lexicographic bilevel-optimization\\nmethod (Borsos et al., 2020; Killamsetty et al.,\\n2021b,c) where the inner loop optimizes model\\nparameters and the outer loop optimizes data se-\\nlection. When optimizing the selection mask, the\\nminimization of loss terms is relaxed to allow the\\nsize of the final coreset smaller than b.\\nRemark\\nThe bilevel optimization methods of-\\nten involve optimization regularization tricks as a\\nrelaxation to the original problem with nested outer-\\ninner loops. Compared with the hard masks, the\\nsoft weights-based objective guarantees a higher\\nlevel of diversity as each sample contributes more\\nor less to the overall optimization.\\n5\\nImportance-based Selection\\nThis section provides the review of methods on\\nimportance measurement and selection. By im-\\nportance we mean the necessity of adding one\\ninstruction-response sample into the training set.\\nDue to the pre-training nature of LLMs, a wide\\nrange of materials have been “parameterized\" as\\ninternal knowledge and therefore several common\\ntasks can be correctly solved without additional\\nfine-tuning. In this case, alignment is not required\\nfor easy samples but becomes indispensable for\\ndifficult ones. The selected datapoints provide sup-\\nplementary knowledge to activate the pre-trained\\nLLMs on following complex instructions.\\n5.1\\nHand-crafted Indicators\\nOverview\\nExisting researches on importance\\nmeasurement of datapoints often stem from two as-\\npects: 1) from the perspective of a datapoint itself,\\ni.e., the difficulty or complexity of each datapoint\\nand the amount of information it provides; 2) from\\nthe perspective of the model under development,\\ni.e., the necessity of learning from such a datapoint\\nbased on the current performance and confidence\\n(uncertainty), Most hand-crafted indicators are pro-\\nposed to analyze the text difficulty.\\nTechnical\\nDetails\\nThe\\nreadability\\nin-\\ndices (Young\\nand Shishido, 2023) can\\nbe\\nused to assess both quality (see Sec. §3.1) and\\ndifficulty of text samples. Specifically, samples\\nwith intricate grammar, advanced vocabulary, and\\ninference dependency are deemed as difficult\\nones and can be used to evaluate robustness of\\nmodels across benchmarks of various difficulty\\nlevels (Smith and Johnson, 2020; Kiela et al.,\\n2021; Ethayarajh et al., 2022; Belinkov and Glass,\\n2019; Nie et al., 2019; Ribeiro et al., 2020). For\\nspecialized domains such as solving maths prob-\\nlems, the education level (e.g., elementary-level,\\nhigh school-level, and university-level) determines\\nthe difficulty of samples (Patel et al., 2021; Huang\\net al., 2016; Koncel-Kedziorski et al., 2016).\\nOne of the pioneering studies on readability\\nscores for difficulty assessment is to compute the\\npercentage of difficult or easy words in one sen-\\ntence (Klare, 1974; Begeny and Greene, 2014).\\nThe words on a pre-defined list are counted as\\nfamiliar words, and those not listed are unfamil-\\niar, advanced words. Besides, the average num-\\nber of syllables per word, the number of single-\\nsyllable words, and the number of multi-syllable\\nwords are also indicative in assessing the text mate-\\nrials (Connatser, 1999; Carrell, 1987; Zakaluk and\\nSamuels, 1988; Dale and Chall, 1949). Notably,\\nthere exist three representative readability metrics:\\n1) the Dale Chall formula (Chall and Dale, 1995),\\n2) the flesch reading ease (Flesch, 1948), and 3) the\\ngunning fog index (Gunning, 1952). Given these\\nmetrics, (Saranathan et al.) conducts a thorough\\nanalysis on existing NLP datasets S to select the\\nmost challenging subsets for efficient evaluation of\\nLLMs. The easiest and hardest samples from the\\nTruthfulQA (Lin et al., 2021) via these indicators\\nare confirmed positively correlated with the actual\\ncomplexity. The selection of difficult instruction-\\nresponse pairs via Eq. 5 allows the wider perfor-\\nmance distribution of models under investigation,\\nmaking it accurate to keep the relative rank of dif-\\nferent models unchanged on subsets Sb.\\nRemark\\nThe computing of difficulty indices\\nhelps comprehensively analyze the robustness of\\nmodels across samples and datasets. In addition, it\\nalso presents guidelines in curating and construct-\\ning discriminating NLP benchmarks.\\n5.2\\nModel-based Indicators\\nOverview\\nTo avoid potential confusion, the\\nmodel-based importance indicators discussed in\\nthis section are mainly categorized as three kinds:\\n1) uncertainty-based; 2) reward score-based; and\\n3) data model-based. Methods that employ train-\\ning/inference losses, errors (metrics), and gradients,\\ndespite their involvement of the language model\\nfor importance sampling, are not included.\\nTechnical Details\\nInspired from uncertainty in-\\ndicators (Siddhant and Lipton, 2018; Kung et al.,\\n2023; Nieth et al., 2024) proposes the prompt uncer-\\ntainty, which measures the disagreement of model\\nresponses on different perturbed versions of the\\nsame instruction:\\nU prompt\\ni\\n= −1\\nK\\nK\\nX\\nk=1\\n|xi|\\nX\\nj=t\\n|P(xi(j)|xi(<j); θ)−\\nP(xi(j)|˜xk\\ni(<j); θ)|,\\n(42)\\nwhere K denotes the number of perturbations and\\n˜xk\\ni is the k-th perturbed prompt. Note that only the\\ninstruction part xi(<t) is perturbed and sent to the\\nmodel for the following likelihood measurement\\non the original response xi(j), j = t, t + 1, ..., |xi|.\\nSamples with high prompt uncertainty should be\\nchosen for fine-tuning since the model does not\\nperform consistently on such instructions.\\n(Jiang et al., 2023b) targets at the over-\\nconfidence problem of LLMs after instruction tun-\\ning (Kadavath et al., 2022), and proposes to cali-\\nbrate the uncertainty with augmented prompt en-\\nsembles.\\nIt casts the uncertainty estimation of\\neither discriminative or generative tasks into a\\nmultiple-choice selection problem. Specifically\\nfor open-generation tasks, different candidate re-\\nsponses are designed to be as diverse as possible\\nby: 1) prompting explicitly to encourage seman-\\ntically distinct answers, or 2) clustering sampled\\nresponses (with a high temperature) into groups\\nand choosing the prototype response from each\\ngroup. Such calibrated uncertainty can be used to\\nprecisely choose important samples.\\nApart from the uncertainty, the reward model\\ncan also be used beyond quality scorer. Since most\\nof the knowledge and capabilities are acquired dur-\\ning pre-training (Zhou et al., 2024a), the instruction\\ntuning datasets are aimed at aligning the behavior\\nof models with human preference and expectations.\\nTherefore, for any given instruction xi, if the gener-\\nated response is of high quality, then the necessity\\nof fine-tuning on this instruction is low. Accord-\\ningly, xi is deemed as “unimportant\" and will not\\nbe chosen into the subset. In that case, the lan-\\nguage model parameterized as θ is first prompted\\nwith xi(<t) to generate the response ˆxθ\\ni(≥t). Then, a\\nreward model parameterized as ϕ acts as a necessity\\nevaluation model:\\nˆRi = rϕ(xi(<t), ˆxθ\\ni(≥t)),\\n(43)\\nSamples whose necessity score ˆRi below a pre-\\ndetermined threshold are selected via Eq. 4, imply-\\ning that the model θ does not own the capabilities\\nto handle xi and requires fine-tuning.\\nAnother series of model-based importance es-\\ntimation methods are based on datamodels (Ilyas\\net al., 2022; Park et al., 2023; Jain et al., 2023;\\nKang et al., 2024; Chhabra et al., 2024; Saunshi\\net al., 2022; Ye et al., 2024), where the contribution\\nof each datapoint to the model’s behavior is esti-\\nmated. The datamodels can be implemented in any\\nmachine learning model which targets at predicting\\nthe influence of each datapoint on the performance\\nof the trained model (Koh and Liang, 2017; Jain\\net al., 2022; Liu et al., 2024b; Picard et al., 2024;\\nBae et al., 2024; Covert et al., 2024).\\n(Engstrom et al., 2024) proposes to use data-\\nmodels to select subsets that maximize the overall\\nperformance. Specifically, it chooses the subset\\nSb ⊂S, S = {x1, x2, ..., x|S|} by estimating the\\nloss of the model trained on it. Out of simplicity,\\nthe datamodel τθx can be implemented as a linear\\nmodel and it learns to approximate the actual loss\\nvia the TARK estimator (Park et al., 2023):\\nθxj = arg min\\nθ\\nˆE(m)\\nSi∼Sb⊂S[Lreg(τθ(1Si)), Lxj(Si)],\\n1Sb ∈{0, 1}|S|, (1Sb)i =\\n(\\n1,\\nif xi ∈Sb,\\n0,\\notherwise. ,\\nτθx(1Sb) = θT\\nx 1Sb,\\n(44)\\nwhere Lxj(Si) denotes the loss of the model\\n(trained on Si) on the sample xj. The ˆE(m) is\\na m-sample empirical expectation and Lreg(·, ·) is\\na regression loss function (e.g., mean squared er-\\nror). Intuitively, what the datamodel τθx does is\\nto approximate the real loss Lxj(Si) under vari-\\nous compositions of subset Si ∼Sb. Given any\\nsubset Sb, the averaged loss approximated by the\\ndatamodel on all xj ∈Seval is calculated on the\\nevaluation set Seval and minimized to find the opti-\\nmal Sb, |Sb| = b:\\nS∗\\nb = arg min\\nSb⊂S\\nˆLSeval(Sb),\\nˆLSeval(Sb) = ˆE(n)\\nxj∼Seval[τθxj (1Sb)]\\n=\\n1\\n|Seval|\\nX\\nxj∈Seval\\nθT\\nxj1Sb\\n= 1T\\nSb(\\n1\\n|Seval|\\nX\\nxj∈Seval\\nθxj).\\n(45)\\nThe importance of xi ∈S is therefore measured\\nby\\n1\\n|Seval|\\nP\\nxj∈Seval θxj and its smallest b elements\\nare chosen for the minimum loss ˆLSeval.\\n(Liu et al., 2024b) also proposes a simulence-\\nbased (Guu et al., 2023) linear datamodel that cor-\\nrelates the training samples with the validation or\\ntest set loss. A featurized simulator, namely GPT-\\nfluence, models the training dynamics (e.g., loss,\\nBLEU and ROUGE scores) across time via an n-th\\norder Markov process. It extracts representations\\ng(xi), xi ∈S from BERT or GPT, and generates\\nboth multiplicative and additive factors to reflect\\nthe influence of any training example on the test-\\ning set. The testing performance ϕt at any time t\\nis affected by: 1) its performance at preceding n\\ntimes and 2) the current training batch ct:\\nϕt(xk) =\\nn\\nX\\nj=1\\nαj(ct)ϕt−j(xk) + β(ct), ∀xk ∈Seval,\\nαj(ct) =\\n|ct|\\nX\\ni=1\\nAi,j, β(ct) =\\n|ct|\\nX\\ni=1\\nBi, ∀xi ∈ct ⊂S,\\nAij = ⟨WT\\n(j)g(xi)j, UT\\n(j)g(xk)⟩F ,\\nBi = ⟨W′T g(xi)j, U′g(xk)⟩F ,\\n(46)\\nwhere WT\\n(j), UT\\n(j), W′, U′ are learnable weights\\nwhich are optimized by minimizing PT\\nt=1(yt −\\nϕt(xk))2 with yt being the ground-truth metric\\nscore monitored during training at step t. The\\n⟨·, ·⟩F denotes the Frobenius inner product. Based\\non the datamodel, samples that reduce evaluation\\nloss the most are selected as influential data.\\nInstead of performing off-line data selection, (Yu\\net al., 2024) proposes MATES where a small data-\\nmodel continuously selects the most effective sub-\\nset for the current training of the LLM. The data-\\nmodel is updated alternatively, like a partner, to\\nadapt to the constantly changing data preferences\\nof the model under development.\\nUnlike previous datamodels that predict the in-\\nfluence of datapoints on the testing performance\\nof the model, (Xie et al., 2023) proposes the DSIR\\nwith importance scores estimated by the distribu-\\ntional resemblance. It simply assumes that training\\nsamples that resemble the evaluation set are impor-\\ntant, and these datapoints should be selected with\\nhigher probability. Given the hashed n-grams fea-\\ntures h(xi) ∈Nm of xi, its importance score wi is\\ncalculated as:\\nwi =\\nˆwi\\nP|S|\\ni=1 ˆwi\\n,\\nˆwi = ˆpfeat(h(xi))\\nˆqfeat(h(xi)),\\nˆpfeat(h(xi)) =\\nm\\nY\\nj=1\\nγh(xi)j\\nj\\n,\\nˆqfeat(h(xi)) =\\nm\\nY\\nj=1\\nβh(xi)j\\nj\\n,\\nˆγ =\\n1\\nP\\nxi∈Seval 1T h(xi)\\nX\\nxj∈Seval\\nh(xj),\\nˆβ =\\n1\\nP\\nxi∈S 1T h(xi)\\nX\\nxj∈S\\nh(xj),\\n(47)\\nwhere S and Seval respectively denote the training\\nset and the evaluation set. Given the budget b, the\\nsubset Sb is obtained by importance-weighted sam-\\npling without replacement b times. (Zhang et al.,\\n2023b) also proposes to use a independent-cascade\\ndiffusion model (Li et al., 2018; Du et al., 2014)\\nto mimic the information diffusion process upon a\\ndirected graph on embeddings of datapoints. The\\nmost influential datapoint are selected for annota-\\ntion and serve as in-context learning examples for\\nLLMs.\\nRemark\\nCompared with uncertainty and reward\\nscore, datamodel-based importance indicators are\\nmore correlated with the downstream performance\\nsince the task-specific evaluation set is introduced\\nto provide feedback for the selection scheme.\\n5.3\\nLoss and Error-based Coreset Sampling\\nOverview\\nDuring training, samples that con-\\ntribute more to the loss or cause worse performance\\nare considered more important. Compared with\\nthe datamodels, the influence of each datapoint is\\nalso measured in the loss and error-based coreset\\nsampling but differs in that such measurement is\\nperformed with the same LLM under development\\nrather than a specifically designed datamodel.\\nTechnical Details\\nOne kind of methods that\\nrecord the errors of each sample during training\\nto estimate importance is forgetting score or for-\\ngetting event (Toneva et al., 2018). It counts how\\nmany times the forgetting happens with the itera-\\ntion of training step t. For any given sample xi\\nin a batch B (xi ∈B ⊂S), if the previous ac-\\ncuracy acct−1\\ni\\nsurpasses the current accuracy acct\\ni\\n(acct\\ni > acct+1\\ni\\n), then the example xi undergoes\\na forgetting event. Conversely, a learning event\\noccurs if acct\\ni < acct+1\\ni\\n. The number of forget-\\nting events implies whether the sample is difficult\\nand indispensable for training. An example xi is\\ndefined as unforgettable if it satisfies:\\nUnforgeti =\\n\\uf8f1\\n\\uf8f4\\n\\uf8f2\\n\\uf8f4\\n\\uf8f3\\n1,\\n∃t∗< ∞, s.t. acct\\ni < acct+1\\ni\\nand ∀k ≥t∗, acck\\ni > acck−1\\ni\\n,\\n0,\\notherwise.\\n(48)\\nThe easy samples with Unforgeti = 1 can be\\nsimply discarded and the important subset Sb =\\n{xi|Unforgeti = 0, xi ∈S} is selected for train-\\ning. Recent studies on both pre-training and in-\\nstruction tuning have investigated the effectiveness\\nof using the forgetting score for efficient data prun-\\ning (Sorscher et al., 2022; Paul et al., 2021; Zhang\\net al., 2023a; Jin and Ren, 2024a; Maini et al.,\\n2022).\\nIn contrast to the term “forgetting\", researchers\\nintroduce the concept “memorization\" (Feldman,\\n2020; Tirumala et al., 2022; Antoniades et al.,\\n2024) for analysis on the generalization of deep\\nmodels (Zhang et al., 2021). The memorization of\\ntraining samples is necessary for reducing close-\\nto-optimal generalization error especially when a\\nlong-tailed disttribution is observed for the training\\nset (Feldman, 2020). Specifically, the amount of la-\\nbel memorization on the instruction-response pair\\n(xi(<t), xi(≥t)) is defined as follows:\\nMemoi =\\n1\\n|xi| −t\\n|xi|\\nX\\nj=t\\n(P(xi(j)|xi(<j); θS)−\\nP(xi(j)|xi(<j); θS\\\\xi)),\\n(49)\\nwhere θS and θS\\\\xi respectively refer to the lan-\\nguage model parameters optimized with the entire\\nset with and without xi. Accordingly, the influ-\\nence (Feldman and Zhang, 2020) of the sample xi\\non other samples xk, xk ̸= xi can be defined as:\\nInflik =\\n1\\n|xk| −t\\n|xk|\\nX\\nj=t\\n(P(xk(j)|xk(<j); θS)−\\nP(xk(j)|xk(<j); θS\\\\xi)),\\n(50)\\nwhere xk(<t) and xk(≥t)) respectively denote the\\ninstruction and response part of xk. In practice,\\nthe memorization and influence scores are approxi-\\nmated via batch-wise sampling where N batches\\nB1, B2, ..., BN are sampled from S with |Bi| = n.\\nFor each batch Bi, a language model parameter-\\nized as θBi is trained to compute the memoriza-\\ntion and influence scores of each sample xi. It is\\nnoted that some batches contain xi and the others\\ndo not. Therefore, the two probability terms in\\nEqs. 49 and 50 are respectively averaged over mul-\\ntiple probability outputs of the models trained on\\nbatches with and without xi. (Sorscher et al., 2022)\\nconfirms that memorization scores (Eq. 49) demon-\\nstrate stronger performance on pruning the dataset\\ninto a significantly smaller subset Sb than random\\nsampling, EL2N (Eq. 10), and influence scores\\n(Eq. 50). (Suzuki et al., 2023) and (Schoch et al.,\\n2023) also follow (Feldman and Zhang, 2020) to\\nselect the high-quality influential subset for LLM\\ntraining.\\nFurthermore, (Chen et al., 2024b) uses the evalu-\\nation loss to check whether the current task requires\\ncertain skills or capabilities that can be obtained by\\nlearning from the prerequisite tasks. For each task,\\nit selects the skill-dependent datapoints that reduce\\nevaluation loss. (Mishra and Sachdeva, 2020) pro-\\nposes a rather simple method that adopts a proxy\\nmodel (e.g., logistic regression and SVM) to train\\non the randomly selected subset Sb and evaluate\\non the remaining set S\\\\Sb. Such process iterates\\nover multiple times to ensure that each sample is\\nat least validated once. The probability of each\\nsample being correctly predicted is used as impor-\\ntance measurement. Likewise, (Lin et al., 2022)\\nalso quantifies the average marginal effect (AME)\\nas influence of xi. It can be viewed as a variant of\\nshapley value (Jia et al., 2019; Ghorbani and Zou,\\n2019; Schoch et al., 2023; Kwon and Zou, 2021).\\nDifferent subsets are randomly sampled to train\\nmultiple submodels and each submodel is evalu-\\nated for jointly estimating the AME via LASSO\\nregression (Lecué and Mendelson, 2018).\\nRemark\\nThe loss and error-based selection meth-\\nods are intuitive and effective to select the data-\\npoints with high difficulty and influence. To ac-\\ncelerate the computation of marginal effect (gain)\\nof each datapoint, iterative approximations can be\\nadopted with small proxy models.\\n5.4\\nGradient-based Coreset Sampling\\nOverview\\nSince gradients directly affect the opti-\\nmization of language models, two kinds of intuitive\\nmethods for data selection are presented: 1) gradi-\\nent matching (Zhao et al., 2020a; Killamsetty et al.,\\n2021a; Jiang et al., 2023d; Zhao and Bilen, 2023;\\nDu et al., 2024; Balles et al., 2022; Zhang et al.,\\n2024a), i.e., the gradients of the entire set S being\\napproximated by the weighted gradients of the sub-\\nset Sb, and 2) gradient-based influence (Pruthi et al.,\\n2020; Brophy et al., 2023; Koh and Liang, 2017;\\nBasu et al., 2020; Picard et al., 2024; Alaa and Van\\nDer Schaar, 2020), i.e., the influence of each sam-\\nple xi on a testing datapoint xt being measured by\\nupweighted gradient multiplication. Specifically,\\nthe gradient matching aims to minimize the differ-\\nence below:\\nθ∗, S∗\\nb = arg min\\nθ,S d( 1\\n|S|\\nX\\nxi∈S\\n∇θNLLA|Q\\ni\\n,\\n1\\nP\\ni wi\\nX\\nxi∈Sb\\nwi∇θNLLA|Q\\ni\\n), Sb ∈S, wi > 0,\\n(51)\\nwhere d(·, ·) denotes the distance measurement and\\nwi is the weight for the gradient of xi.\\nThe gradient-based influence methods, on the\\nother hand, aim at selecting the most influential\\ndatapoints in terms of the variation of model pa-\\nrameters θ. Given the optimal parameters θ∗, the\\nupdated parameters θϵ\\n{xi} by up-weighting the loss\\nof xi with ϵ can be derived as the first-order Taylor\\nseries expansion as follows:\\nθϵ\\nxi = arg min\\nθ\\n1\\n|S|\\nX\\nxj∈S\\nNLLA|Q\\nj\\n+ ϵNLLA|Q\\ni\\n,\\nθϵ\\nxi ≈θ∗−ϵH−1\\nθ∗∇θNLLA|Q\\ni\\n,\\n(52)\\nwhere Hθ∗represents the Hessian with respect to\\nthe model parameters θ∗. Accordingly, the influ-\\nence function of a sample xi on the model parame-\\nters and its effect on the performance of a particular\\nsample xj can be respectively denoted as:\\nInflFi = dθϵ\\nxi\\ndϵ |ϵ=0 = −H−1\\nθ∗∇θNLLA|Q\\ni\\n,\\nInflFij = −∇θNLLA|Q\\nj\\nT H−1\\nθ∗∇θNLLA|Q\\ni\\n.\\n(53)\\nThe importance indicator InflFij approximately\\nmeasures the change of the loss on xj when xi\\nis removed from the training set. To expedite the\\ncomputation of Hessian matrix for large models,\\na combination of Hessian-vector product and opti-\\nmization techniques are developed (Pearlmutter,\\n1994; Nilsen et al., 2019; Mathieu and LeCun,\\n2014; Agarwal et al., 2016; Shewchuk et al., 1994).\\nAnother kind of influence score is defined as the\\nexpected gradient norm (GraNd score) (Paul et al.,\\n2021; Kirsch, 2023; Böther et al., 2023), where the\\nGraNd score controls the contribution of a training\\nsample to the change of the loss.\\nGraNdi = Eθ∥∇θNLLA|Q\\ni\\n∥2\\n(54)\\nExperiments (Paul et al., 2021) suggest that the\\nGraNd score (Eq. 54) can be well approximated by\\nEL2N score (Eq. 10) for efficient data pruning.\\nTechnical Details\\n(Xia et al., 2024a) proposes to\\nfind the most influential training data that resem-\\nble the testing set the most via low-rank gradient\\nsimilarity search. (Tan et al., 2024a) introduces the\\nmoving-one-sample-out (MoSo) by pinpointing the\\nleast informative samples via gradient-based influ-\\nence assessment. To avoid the costly retraining\\nprocedure by iteratively moving one sample out, a\\ngradient-based approximator is proposed to select\\nsamples whose gradients are consistently aligned\\nwith the average gradients of the entire training set\\nFor the detailed definition of distance measure\\nof Eq. 51, (Everaert and Potts, 2023) exploits the\\nKL-divergence to measure the difference between\\nthe selected subset and the testing set. Note that\\nhere the objective is to approach the distribution\\nof the testing set rather than the entire training\\nset.\\n(Killamsetty et al., 2021a) speeds up the\\ngradient matching between the selected dataset\\nand the validation set via an orthogonal match-\\ning pursuit algorithm. (Lin et al., 2024) applies\\ngradient-based influence scores on recommenda-\\ntion datasets for effective LLM instruction tun-\\ning. (Schioppa et al., 2021) chooses a different\\nway (Arnoldi, 1951) to accelerate the computation\\nof the inverse Hessian matrix in Eq. 52 and suc-\\ncessfully scales up the influence scoring for LLMs\\nwith several hundreds of millions of parameters.\\n(Grosse et al., 2023) uses the influence functions\\nto study the generalization properties of LLMs To\\nscale up influence functions for LLMs up to 52 bil-\\nlions, an approximation technique via Eigenvalue-\\ncorrected Kronecker-Factored Approximate Curva-\\nture (EK-FAC) (George et al., 2021) to efficiently\\nfind the most influential samples to the pre-trained\\nLLMs over maths and programming abilities, cross-\\nlingual generalization, and role-playing behavior.\\n(Zhao et al., 2021) condenses the datasets into small\\ninformative synthetic samples where the gradients\\nof the model on the synthetic data are matching\\nthose on the real data of the entire training set.\\nRemark\\nThe gradient-based coreset sampling\\ntechniques are highly dependent on the LLMs un-\\nder development, where the gradients describe the\\nmodel’s inherent knowledge and uncertainty about\\neach training sample. Despite the precision of\\ngradient-based selection methods, it is noted that\\napproximation is unavoidable for application on\\nLLMs. The efficiency and accuracy of various ap-\\nproximation techniques should be considered.\\n6\\nResults and Discussions\\nIn this chapter, we classify different methods ac-\\ncording to their different emphases, and then sum-\\nmarize and present the experimental results. First,\\nwe classify the methods according to their different\\nemphases (quality, diversity, importance) and sum-\\nmarize them in Tab. 1 as well as the datasets/data\\nvolume used.\\nQuality\\nThe quality of data directly impacts the\\neffectiveness of model training. Quality control\\nmeasures include data scoring, quality assessment,\\nand more. In Tab. 2, we have summarized the re-\\nsults of different methods focusing on data quality.\\nIn the table, we list the data used by different meth-\\nods and the proportion/size of the data selected. It\\ncan be seen that the method of selecting data based\\non quality can match the results of training with\\nfull data even when using less data, and is also su-\\nperior to the results of randomly selecting part of\\nthe data. In the table, WK stands for World Knowl-\\nedge, CR stands for Commonsense Reasoning, LU\\nstands for Language Understanding, SPS stands\\nfor Symbolic Problem Solving, and RC stands for\\nReading Comprehension.\\nDiversity\\nData engineers enhance the general-\\nization ability of models by introducing diverse\\ndatasets. This diversity may encompass data from\\ndifferent sources, with varying features, and dis-\\ntinct distributions. Research indicates that merely\\nselecting datasets that are similar to downstream\\ntasks is insufficient. Diversity is important for data\\nselection, and this is reflected in the experiments.\\nTab. 3 demonstrates the importance of diversity in\\ndata selection. Compared to random selection and\\nuniform selection of data, the scheme of selecting\\ndata with diversity criteria is superior. In addi-\\ntion, compared to only selecting high-quality data,\\nthe criteria that combine quality and diversity can\\nachieve better performance than simply selecting\\nhigh-quality data.\\nImportance\\nIdentifying and utilizing key data\\nthat significantly impacts model performance is\\nMethods\\nQuality\\nDiversity\\nImportance\\nTraining Set\\nTraining Set Size\\nIFD (Li et al., 2023a)\\n!\\n%\\n%\\nAlpaca\\n52K\\nWizardLM\\n70K\\nLIFT (Xu et al., 2023b)\\n!\\n!\\n%\\nOpen-Platypus\\n25K\\nCodeAlpaca\\n20K\\nDQ (Zhou et al., 2023)\\n%\\n!\\n%\\nAlpaca\\n52K\\nPPL (Ankner et al., 2024)\\n!\\n%\\n%\\nThe Pile\\nNA\\nDolma\\nNA\\nInstructionMining (Cao et al., 2023)\\n!\\n%\\n%\\nOpenOrca\\n50K\\nDolly\\n15K\\nFL (Bhatt et al., 2024)\\n!\\n!\\n%\\nFLAN v2\\n99K\\nAlpagasus (Chen et al., 2023b)\\n!\\n%\\n%\\nAlpaca\\n52K\\nBSDetector (Chen and Mueller, 2024)\\n!\\n%\\n%\\nSQuAD-N\\nNA\\nEmails-N\\nNA\\nDROP-N\\nNA\\nDEITA (Liu et al., 2023b)\\n!\\n!\\n%\\nMixed(ShareGPT+UltraChat+WizardLM)\\n206K\\nAutoDS (Zhang et al., 2024c)\\n!\\n%\\n%\\nOpenWebMath\\nNA\\nQurator (Wettig et al., 2024)\\n!\\n%\\n%\\nQuRatedPajama\\n260B tokens\\nClusterClip (Shao et al., 2024)\\n%\\n!\\n%\\nOpenOrca\\n4.2M\\nProof-Pile-2\\n2.7M\\nQDIT (Bukharin and Zhao, 2023)\\n!\\n!\\n%\\nUltraChat\\n1.3M\\nLMSYS\\n1M\\nAlpaca\\n52K\\nMixed (Alpaca+OIG+Dolly)\\n270K\\nDolly\\n15K\\nDsDm (Engstrom et al., 2024)\\n%\\n%\\n!\\nC4\\nNA\\nMATES (Yu et al., 2024)\\n%\\n%\\n!\\nC4\\nNA\\nDSIR (Xie et al., 2023)\\n%\\n%\\n!\\nThe Pile\\n1.6B\\nSkill-it (Chen et al., 2024b)\\n%\\n%\\n!\\nRedPajama\\n1.2T tokens\\nLESS (Xia et al., 2024a)\\n%\\n%\\n!\\nMixed(FLAN v2+Dolly+OpenAssistant+COT)\\n270K\\nTable 1: Statistics of datasets in existing representative data assessment and selection methods.\\ncrucial. As shown in Tab. 4, the importance-based\\ndata selection approach combines data selection\\nand model training, aiming to maximize the final\\nperformance. It addresses the challenges in the im-\\nplementation framework by using point-wise data\\nimpact and data impact parameterization. More-\\nover, by performing importance resampling in the\\nfeature space that provides structure, it selects ex-\\namples similar to the target distribution, thereby\\nenhancing the performance of the target task. Ex-\\nisting work has found that the importance sampling-\\nbased approach can effectively improve the perfor-\\nmance of the target task and enhance the model’s\\ncapabilities.\\n7\\nFuture Directions: Challenges and\\nOpportunities\\nIn this section, we present the existing challenges\\nand potential solutions to developing advanced data\\nassessment and selection methods.\\n7.1\\nBenchmarking Instruction-Tuned LLMs\\nThere exists a gap between the effectiveness of\\ndata selection and the reported performance on\\nbenchmarks.\\nIn existing researches, the ablation\\nstudies on the effectiveness of assessment and selec-\\ntion methods are often carried out by comparing the\\nperformance of LLMs fine-tuned with the selected\\nand the full dataset. However, for coreset sampling\\nmethods that use losses and gradients as proxies\\nfor data quality, the downstream performance may\\nnot be positively correlated with the selection effec-\\ntiveness. The reason behind is that the evaluation\\nloss itself (Yang et al., 2022; Hoffmann et al., 2022;\\nKaplan et al., 2020) is not informative enough for\\nuniversal estimation of benchmark performance.\\n(AI@Meta, 2024) demonstrates that the correlation\\nbetween the negative log-likelihood loss on down-\\nstream tasks and the accuracy metrics should be\\nmodeled task-by-task and model-by-model. In the\\nlight of this statement, it is impractical to simply\\ncount on losses or gradients to pinpoint the most\\nbeneficial data for improving the downstream per-\\nformance, let alone methods that try to predict the\\nloss based on various indicators (Cao et al., 2023).\\nFurthermore, even if the metrics are exhaustively\\ncomputed for the selection of each sample, the\\ngains brought by one sample might be limited in\\nMethods\\nTraining Set\\nModel\\nSelection Ratio/Size\\nReported Results on Testing Sets\\nIFD\\n(Li et al., 2023a)\\nARC\\nHellaSwag\\nMMLU\\nTruthfulQA\\nAlpacaEval\\nAlpaca\\nLLaMA-7B\\nFull\\n0.427\\n0.769\\n0.417\\n0.396\\n0.265\\n5%\\n0.539\\n0.795\\n0.365\\n0.383\\n0.347\\nWizardLM\\nFull\\n0.531\\n0.774\\n0.378\\n0.429\\n0.620\\n10%\\n0.529\\n0.790\\n0.331\\n0.414\\n0.614\\nAlpaca\\nLLaMA2-7B\\nFull\\n0.544\\n0.787\\n0.470\\n0.410\\n0.278\\n5%\\n0.558\\n0.579\\n0.804\\n0.442\\n0.368\\n10%\\n0.580\\n0.804\\n0.466\\n0.402\\nNA\\n15%\\n0.564\\n0.574\\n0.807\\n0.464\\nNA\\nWizardLM\\nFull\\n0.576\\n0.820\\n0.541\\n0.415\\n0.350\\n5%\\n0.624\\n0.840\\n0.557\\n0.428\\n0.468\\n10%\\n0.630\\n0.839\\n0.553\\n0.419\\nNA\\n15%\\n0.624\\n0.835\\n0.556\\n0.434\\nNA\\nARC\\nHellaSwag\\nMMLU\\nTruthfulQA\\nLIFT\\n(Xu et al., 2023b)\\nOpen-\\nMistral-7B\\nRandom 15K\\n0.607\\n0.820\\n0.625\\n0.438\\nPlatypus\\nLIFT 15K\\n0.643\\n0.844\\n0.645\\n0.490\\nHumanEval\\nMBPP\\nCode-\\nStarCoder-15B\\nRandom 10K\\n0.381\\n0.431\\nAlpaca\\nLIFT 10K\\n0.550\\n0.495\\nWK\\nCR\\nLU\\nSPS\\nRC\\nPPL\\n(Ankner et al., 2024)\\nThe Pile\\nMPT-1B\\nFull\\n0.155\\n0.103\\n0.281\\n0.035\\n0.112\\nLow 50%\\n0.111\\n0.058\\n0.187\\n0.035\\n0.087\\nMid 50%\\n0.161\\n0.090\\n0.281\\n0.034\\n0.109\\nHigh 50%\\n0.182\\n0.128\\n0.332\\n0.034\\n0.106\\nDolma\\nFull\\n0.165\\n0.123\\n0.289\\n0.036\\n0.080\\nLow 50%\\n0.161\\n0.101\\n0.273\\n0.345\\n0.079\\nMid 50%\\n0.180\\n0.130\\n0.319\\n0.034\\n0.104\\nHigh 50%\\n0.167\\n0.131\\n0.311\\n0.032\\n0.086\\nARC\\nHellaSwag\\nMMLU\\nTruthfulQA\\nInstructionMining\\n(Cao et al., 2023)\\nOpenOrca &\\nDolly\\nLLaMA2-7B\\nSelseted 10K\\n0.567\\n0.798\\n0.499\\n0.483\\nSelected 40K\\n0.544\\n0.801\\n0.526\\n0.498\\nRandom 10K\\n0.548\\n0.796\\n0.490\\n0.516\\nRandom 40K\\n0.548\\n0.799\\n0.512\\n0.500\\nMMLU\\nBBH\\nFL\\n(Bhatt et al., 2024)\\nFLAN v2\\nLLaMA2-7B\\nRandom 20K\\n0.443\\n0.390\\nFL 20K\\n0.451\\n0.383\\nRandom 30K\\n0.449\\n0.394\\nFL 30K\\n0.471\\n0.411\\nRandom 45K\\n0.460\\n0.394\\nFL 45K\\n0.476\\n0.413\\nBBH\\nDROP\\nHumanEval\\nMMLU\\nAlpagasus\\n(Chen et al., 2023b)\\nAlpaca\\nLLaMA2-7B\\nRandom 9K\\n0.319\\n0.259\\n0.116\\n0.369\\nFull 52K\\n0.330\\n0.259\\n0.117\\n0.409\\nAlpagasus 9K\\n0.338\\n0.260\\n0.122\\n0.388\\nLLaMA2-13B\\nRandom 9K\\n0.386\\n0.334\\n0.152\\n0.450\\nFull 52k\\n0.387\\n0.338\\n0.157\\n0.479\\nAlpagasus 9K\\n0.389\\n0.344\\n0.159\\n0.461\\nSQuQA-N\\nEmails-N\\nDROP-N\\nBSDetector\\n(Chen and Mueller, 2024)\\nSQuAD-N\\nLLaMA2-7B-\\nChat\\nFull\\n0.499\\nNA\\nNA\\nAuto-filter\\n0.599\\nNA\\nNA\\nAuto-correct\\n0.714\\nNA\\nNA\\nEmails-N\\nFull\\nNA\\n0.507\\nNA\\nAuto-filter\\nNA\\n0.497\\nNA\\nAuto-correct\\nNA\\n0.523\\nNA\\nDROP-N\\nFull\\nNA\\nNA\\n0.447\\nAuto-filter\\nNA\\nNA\\n0.474\\nAuto-correct\\nNA\\nNA\\n0.505\\nMATH\\nGSM8K\\nBBH\\nARC-E\\nARC-C\\nAutoDS\\n(Zhang et al., 2024c)\\nOpenWebMath\\nMistral-7B\\nRandom 2.5B tokens\\n0.143\\n0.441\\n0.565\\n0.842\\n0.567\\nAutoDS 2.5B tokens\\n0.161\\n0.454\\n0.586\\n0.842\\n0.552\\nLogiQ\\nBoolQ\\nNQ\\nMMLU\\nHellaSwag\\nRandom 2.5B tokens\\n0.310\\n0.838\\n0.292\\n0.522\\n0.622\\nAutoDS 2.5B tokens\\n0.310\\n0.831\\n0.291\\n0.523\\n0.627\\nPIQA\\nWinogrande\\nSciQ\\nRandom 2.5B tokens\\n0.822\\n0.802\\n0.972\\nAutoDS 2.5B tokens\\n0.822\\n0.800\\n0.968\\nRC\\nCR\\nWK\\nQuRator\\nQuRated-\\nSheared-\\nRandom 30B tokens\\n0.509\\n0.55\\n0.149\\n(Wettig et al., 2024)\\nPajama\\nLLaMA-1.3B\\nQurator 30B tokens\\n0.521\\n0.555\\n0.152\\nTable 2: Experimental results of quality-based selection methods. Results are directly cited from their papers. WK,\\nCR, LU, SPS, and RC respectively stand for compound datasets of World Knowledge, Commonsense Reasoning,\\nLanguage Understanding, Symbolic Problem Solving, and Reading Comprehension.\\nMethods\\nTraining Set\\nModel\\nSelection Ratio/Size\\nReported Results on Testing Sets\\nARC\\nHellaSwag\\nMMLU\\nTruthfulQA\\nDEITA\\n(Liu et al., 2023b)\\nMixed\\nLLaMA-13B\\nRandom 10K\\n0.558\\n0.800\\n0.474\\n0.574\\nDEITA 10K\\n0.595\\n0.820\\n0.606\\n0.550\\nLLaMA2-13B\\nRandom 10K\\n0.615\\n0.837\\n0.552\\n0.448\\nDEITA 10K\\n0.589\\n0.821\\n0.553\\n0.546\\nMistral-7B\\nRandom 10K\\n0.554\\n0.792\\n0.587\\n0.536\\nDEITA 6K\\n0.578\\n0.803\\n0.619\\n0.598\\nSuperGLUE\\nGSM8k\\nOBQA\\nMT-Bench\\nClusterClip\\n(Shao et al., 2024)\\nOpenOrca\\nMistral-7B\\nRandom 5B tokens\\n0.621\\n0.615\\n0.798\\n6.600\\nUniform 5B tokens\\n0.630\\n0.588\\n0.782\\n6.750\\nClusterClip\\n0.643\\n0.587\\n0.814\\n6.900\\nMATH\\nGSM8K\\nMMLU\\nBBH\\nProof-Pile-2\\nLLaMA2-7B\\nRandom 20B tokens\\n0.065\\n0.256\\n0.488\\n0.418\\nUniform 20B tokens\\n0.076\\n0.260\\n0.500\\n0.429\\nClusterClip\\n0.079\\n0.248\\n0.511\\n0.428\\nMMLU\\nBBH\\nARC\\nQDIT\\n(Bukharin and Zhao, 2023)\\nUltraChat\\nLLaMA-7B\\nRandom 10K\\n0.321\\n0.332\\n0.583\\nQDIT 10K\\n0.361\\n0.321\\n0.607\\nLMSYS\\nRandom 10K\\n0.331\\n0.326\\n0.602\\nQDIT 10K\\n0.373\\n0.325\\n0.614\\nAlpaca\\nRandom 3K\\n0.362\\n0.303\\n0.617\\nQDIT 3K\\n0.355\\n0.304\\n0.620\\nMixed\\nRandom 10K\\n0.329\\n0.309\\n0.583\\nQDIT 10K\\n0.343\\n0.312\\n0.607\\nDolly\\nRandom 1K\\n0.281\\n0.273\\n0.594\\nQDIT 1K\\n0.338\\n0.303\\n0.598\\nDROP\\nLAMBADA\\nSciQ\\nUltraChat\\nRandom 10K\\n0.262\\n0.698\\n0.854\\nQDIT 10K\\n0.267\\n0.698\\n0.868\\nLMSYS\\nRandom 10K\\n0.251\\n0.685\\n0.867\\nQDIT 10K\\n0.264\\n0.693\\n0.850\\nAlpaca\\nRandom 3K\\n0.263\\n0.716\\n0.870\\nQDIT 3K\\n0.270\\n0.697\\n0.841\\nMixed\\nRandom 10K\\n0.203\\n0.681\\n0.841\\nQDIT 10K\\n0.260\\n0.697\\n0.898\\nDolly\\nRandom 1K\\n0.173\\n0.717\\n0.807\\nQDIT 1K\\n0.226\\n0.723\\n0.806\\nBBH\\nDROP\\nMMLU\\nHumanEval\\nDQ\\n(Zhou et al., 2023)\\nAlpaca\\nLLaMA-7B\\nFull\\n0.329\\n0.263\\n0.416\\n0.100\\n20%\\n0.327\\n0.267\\n0.398\\n0.092\\n2%\\n0.329\\n0.276\\n0.366\\n0.085\\nTable 3: Experimental results of diversity-based selection methods. Results are directly cited from their papers.\\nfew tasks. Therefore, to comprehensively reflect\\nthe effectiveness of sample selection, the evalua-\\ntion of instruction-tuned models should be accom-\\npanied by the specialised evaluation of the selected\\ndatapoints. For the former, all sorts of evaluation\\nstrategies have been proposed to precisely evaluate\\nthe LLMs (Melis et al., 2017; Chang et al., 2024;\\nXu et al., 2022; Liang et al., 2022). The multiple-\\nchoice QA tasks are not enlightening in judging if\\nthe instruction-tuned model truly understands the\\nproblem rather than simply memorizing the answer\\nchoices given the instruction context. For the later,\\na benchmark for documenting and comparing the\\nstatistics of the selected instruction-response pairs\\nin terms of quality, diversity, and importance needs\\nto be constructed in the future. It would benefit the\\ntask-wise customized data selection according to\\nthe statistical indicators on such a benchmark.\\nTest set contamination should be considered dur-\\ning instruction data selection.\\nFor instruction\\ntuning on publicly released pre-trained LLMs, it\\ncannot be too careful to check the potential data\\nleakage where the testing instructions are already\\nmodeled during pre-training (Rae et al., 2021; Li\\net al., 2023b; Magar and Schwartz, 2022; Carlini\\net al., 2019; Marone and Van Durme, 2024; Deng\\net al., 2023; Cao et al., 2024; Jiang et al., 2024b;\\nMagar and Schwartz, 2022). To improve the perfor-\\nmance of pre-trained models on downstream tasks,\\ninstruction datapoints (i.e., instruction-like conver-\\nsations) are already added into the annealing phase\\nof pre-training (AI@Meta, 2024; Bilibili, 2024;\\nYang et al., 2024; Bai et al., 2023). Therefore, po-\\ntential risks of data contamination are raised for\\nbenchmarking the fine-tuned LLMs. To avoid the\\nnegative effect of data leakage on evaluation of the\\ndata assessment and selection, it is encouraged to\\nfollow (Li et al., 2023a) to adopt the pre-trained\\nmodel for experiencing the instruction datapoints\\nbefore fine-tuning. If the model exhibits overfit-\\nting behaviors (i.e., accurately generating the in-\\nstruction part or producing the same answer choice\\neven with permutation on the choice letters), data\\ncontamination is likely to exist and thereafter the\\ntesting set should be replaced. For future studies,\\nMethods\\nTraining Set\\nModel\\nSelection Ratio/Size\\nReported Results on Testing Set\\nCOPA\\nOBQA\\nPIQA\\nCBT\\nHellaswag\\nDsDm\\n(Engstrom et al., 2024)\\nC4\\nChinchilla-\\noptimal-1.3B\\nRandom\\n0.620\\n0.334\\n0.689\\n0.864\\n0.449\\nDsDm\\n0.630\\n0.312\\n0.690\\n0.882\\n0.423\\nWinogrande\\nBoolQ\\nCOQA\\nARC-E\\nTriviaQA\\nRandom\\n0.522\\n0.549\\n0.188\\n0.448\\n0.037\\nDsDm\\n0.511\\n0.580\\n0.255\\n0.476\\n0.071\\nSciQ\\nARC-E\\nARC-C\\nLogiQA\\nMATES\\n(Yu et al., 2024)\\nC4\\nPythia-410M\\nRandom 20%\\n0.641\\n0.402\\n0.256\\n0.247\\nMATES 20%\\n0.660\\n0.418\\n0.250\\n0.257\\nPythia-1B\\nRandom 20%\\n0.658\\n0.437\\n0.256\\n0.275\\nMATES 20%\\n0.673\\n0.449\\n0.259\\n0.287\\nOBQA\\nBoolQ\\nHellaSwag\\nPIQA\\nWinogrande\\nPythia-410M\\nRandom 20%\\n0.294\\n0.589\\n0.397\\n0.671\\n0.506\\nMATES 20%\\n0.308\\n0.606\\n0.410\\n0.687\\n0.527\\nPythia-1B\\nRandom 20%\\n0.318\\n0.602\\n0.438\\n0.689\\n0.507\\nMATES 20%\\n0.322\\n0.609\\n0.453\\n0.695\\n0.524\\nMNLI\\nQNLI\\nQQP\\nRTE\\nDSIR\\n(Xie et al., 2023)\\nThe Pile\\nRoBERTa-\\nBase (125M)\\nRandom 51.2M\\n0.826\\n0.869\\n0.896\\n0.674\\nDSIR 51.2M\\n0.831\\n0.891\\n0.898\\n0.751\\nSST-2\\nMRPC\\nCoLA\\nSTS-B\\nRandom 51.2M\\n0.901\\n0.874\\n0.494\\n0.886\\nDSIR 51.2M\\n0.905\\n0.877\\n0.540\\n0.892\\nARC-C\\nARC-E\\nBoolQ\\nCOPA\\nSkill-it\\n(Chen et al., 2024b)\\nRedPajama\\nGPT-Neo-3B\\nSkill-it 1B\\n0.346\\n0.612\\n0.682\\n0.820\\nUniform 1B\\n0.354\\n0.652\\n0.689\\n0.810\\nSkill-it 1B\\n0.349\\n0.617\\n0.686\\n0.810\\nUniform 1B\\n0.353\\n0.624\\n0.677\\n0.800\\nSkill-it 1B\\n0.348\\n0.620\\n0.687\\n0.810\\nUniform 1B\\n0.346\\n0.625\\n0.672\\n0.810\\nHellaSwag\\nLAMBADA\\nPIQA\\nWinogrande\\nSkill-it 1B\\n0.637\\n0.670\\n0.750\\n0.639\\nUniform 1B\\n0.639\\n0.644\\n0.748\\n0.628\\nSkill-it 1B\\n0.639\\n0.667\\n0.752\\n0.632\\nUniform 1B\\n0.638\\n0.659\\n0.755\\n0.639\\nSkill-it 1B\\n0.639\\n0.660\\n0.757\\n0.631\\nUniform 1B\\n0.640\\n0.668\\n0.750\\n0.634\\nMMLU\\nTYDIQA\\nBBH\\nLESS\\n(Xia et al., 2024a)\\nMixed\\nLLaMA2-7B\\nFull\\n0.516\\n0.540\\n0.432\\nRandom 5%\\n0.465\\n0.527\\n0.389\\nLESS 5%\\n0.502\\n0.562\\n0.415\\nLLaMA2-13B\\nFull\\n0.545\\n0.543\\n0.508\\nRandom 5%\\n0.534\\n0.530\\n0.470\\nLESS 5%\\n0.540\\n0.546\\n0.506\\nMistral-7B\\nFull\\n0.604\\n0.577\\n0.530\\nRandom 5%\\n0.600\\n0.569\\n0.545\\nLESS 5%\\n0.618\\n0.603\\n0.560\\nTable 4: Experimental results of importance-based selection methods. Results are directly cited from their papers.\\nit would be more reliable to decouple the evalua-\\ntion of data selection and that of fine-tuned LLMs,\\nwhere the performance consistency between these\\ntwo evaluation results can be analyzed to rule out\\nthe possibility of contamination.\\n7.2\\nUnveiling the Definitions of Good Data\\nWhat signifies the most a good instruction data-\\npoint remains an open question.\\nUnfortunately,\\nthere exists no unified criteria on discriminating\\n“good\" instructions from “bad\" ones. Essentially,\\nthe definitions on the general data “quality\" differ\\nfrom task to task and domain to domain (Evans\\nand Murshudov, 2013; Flach, 2012; Albalak et al.,\\n2024). Although existing quality measurement\\nmethods can be categorized in terms of quality,\\ndiversity, and importance under the present study,\\nthey all exhibit more or less ad-hoc properties in\\nmethodology. First, studies on instruction tuning\\nare often targeted at improving the performance\\nof LLMs on downstream task. No matter whether\\nthese tasks are of general-purpose (e.g., common\\nNLP tasks on leaderboard (Myrzakhan et al., 2024;\\nWolf et al., 2019)) or domain-specific applications,\\nsuch task-orientated data selection itself is only a\\n“proxy\" for exploring the underlying “quality\" mea-\\nsurement. Especially for coreset sampling methods\\nthat directly employ the evaluation set or testing set\\nfor distribution matching or importance estimation,\\ninstructions that resemble the most to the testing\\nset or bring about performance gains are judged as\\n“good\" data. However, such “good\" data cannot be\\neasily transferred to another LLM of completely\\ndifferent architecture and parameters. Each time\\nthe entire pipeline has to be enforced for a novel\\ntask, making it difficult to accumulate universally-\\nacknowledged high-quality data for archiving. Sec-\\nond, each method has an individual quality eval-\\nuation system and very few of them ever tried to\\njustify their design and interpret the philosophy be-\\nhind. It is difficult to validate whether certain com-\\nponent of the selection pipeline can be replaced or\\nremoved for better serving a new task-of-interest.\\nAccordingly, further academic explorations in-\\nclude: 1) to present a more unified, generally appli-\\ncable definitions on “good\" instruction datapoints\\nin terms of fine-grained aspects, and 2) to improve\\ninterpretability and explanability of the selection\\npipeline beyond empirical design.\\nThe expected model behavior retrospectively de-\\ntermines the trade-off between quality, diversity,\\nand importance for data selection.\\nThe three\\naspects we used to categorize data assessment meth-\\nods are actually overlapping with each other, where\\nthe “boundary\" between two measuring dimension\\nis often hard to explicitly defined. Under such\\ncircumstance, the definition of good data can be\\nperceived as the weighted, biased mixture of qual-\\nity, diversity, and importance. Existing methods\\nare not flexible in dynamically adjusting the mix-\\ning weights to adapt to different downstream tasks.\\nInstead, their priority order of the three dimensions\\nis implicitly encoded into the selection of instruc-\\ntions. For instance, (Liu et al., 2023b) emphasizes\\nquality and importance equally by first establishing\\nthe relative ranking of all samples in both quality\\nand complexity. The subset is formed by consecu-\\ntively selecting the top-ranked samples in sequence,\\nwith diversity intervened via ruling out heavily ho-\\nmogenized examples. Such hard-coded, greedy\\ntreatment to quality, diversity, and importance is\\nnot applicable to scenarios where the behavior of\\nLLMs is expected to cater to varied preference.\\nIn general, the data assessment and selection\\nmethods that can adapt to the model requirement\\nunder different application scenarios are yet to be\\nsystematically developed. For generation tasks like\\nrole playing and creative writing, the preferred in-\\nstruction tuning datapoints should be distinct from\\nthose for discriminative tasks like named entity\\nrecognition and sentiment analysis.\\n7.3\\nScaling Up Datasets\\nThe optimal scale of the selected subset becomes\\nless explicit with the expansion of datasets.\\nIn\\nthe analysis of the disadvantages in exploiting the\\nentire instruction dataset for alignment, putting\\naside the issue of long training time, we notice that\\nthe performance of fine-tuning the entire dataset\\nmight not be the optimal. There often exists a criti-\\ncal point of the best selection proportion, and such\\nproportion varies from dataset to dataset. When\\nmore instruction datasets from diverse domains\\nand tasks are incorporated, it becomes more dif-\\nficult to nail down the best selection proportion\\nfor three main reasons. First, a large proportion\\nof noise exists in the open datasets and few noisy\\nsamples can already cause tremendous negative im-\\npact on performance (Song et al., 2022). During\\nthe pre-processing of instruction dataset, noise can\\nbe unintentionally introduced in instruction prepa-\\nration (e.g., missing context or system prompt), re-\\nsponse generation (e.g., unverified or mismatched\\nanswers), format wrapping (e.g., invalid JSON and\\nunresolved code), and text augmentation (e.g., syn-\\nonym replacement and reorder of words). Second,\\nfor specialized tasks in “vertical\" domains, the over-\\nfitting of specific prompts occurs (Ma et al., 2023)\\nwhen the diversity of input instructions is rather\\nlimited. Despite the accuracy and rationality of the\\ninstruction-response pairs, LLMs tend to overfit\\ncertain patterns of the input instruction rather than\\ntruly comprehend the task. Therefore, the increase\\nof dataset size instead reduces the generalization\\nof trained LLMs with lower instruction following\\ncapabilities. Third, the forgetting (Zhang and Wu,\\n2024; Jin and Ren, 2024b; Wang et al., 2024b)\\nbecomes a severe problem when more instruction\\ndatasets are introduced without setting a proper\\nre-playing schedule of pre-training or previously\\nvisited instruction tuning datapoints (Parmar et al.,\\n2024; Jin et al., 2021; Ibrahim et al., 2024). The\\nskill cultivation of a LLM on any new instruction\\ntask heavily relies on its preceding skills acquired\\nduring pre-training or previous fine-tuning. Con-\\nsequently, the expansion of samples for high-level\\nskills would “dilute\" those for low-level skills and\\ndegrade performance.\\nTo sum up, with the dataset scaling up, fine-\\ntuning with the selected subset instead of the entire\\nset becomes a must-have strategy. To help deter-\\nmine the optimal selection ratio, we suggest the\\nfollowing three guidelines: 1) One may first de-\\nvelop a complex quality measure scheme that uses\\nboth indicators and human verification to estimate\\nthe noise percentage of each constituting dataset.\\nWithout lose of generality, random sampling can\\nbe performed to accelerate quality measurement.\\nTo combat noise, a lower ratio (i.e., smaller Sb)\\nshould be considered for data selection from the\\nnoisy S. 2) To combat overfitting, both the di-\\nversity of instruction datapoints within and across\\ndatasets should be emphasized. A higher keep-\\ning proportion should be established for datasets\\nwith diverse instruction styles, prompt formations,\\nand response patterns, which helps improve the\\nmodel’s instruction following capabilities. 3) For\\ncontinual fine-tuning, datasets that share similar\\ndistributions with pre-training and previous fine-\\ntuning datapoints should be kept to fight against\\nforgetting. The optimal selection ratio and propor-\\ntion for each dataset is built upon the meticulous\\nand thorough analysis on each instruction dataset,\\nand therefore case-by-case adjustment is needed.\\nFor future studies, one may investigate the automa-\\ntion of assessment and selection recipe to minimize\\nthe human intervention.\\nThe optimization of a scalable pipeline for data\\nassessment and selection is of urgent need.\\nIn\\nconsideration of the cost of building human-labeled\\nand human-verified instruction tuning datasets,\\nmethods that employ powerful LLMs like GPT4\\nfor instruction synthesis (Bradley et al., 2023; Li\\net al., 2023e; Xu et al., 2023a; Li et al., 2024a;\\nZhao et al., 2024a; Dong et al., 2024) have gained\\nincreasing attention. The synthetic instructions pro-\\nliferate cost-effectively with fine-grained control of\\ncharacteristics such as difficulty and style. There-\\nfore, it is expected to witness a surge of instruction\\ndatapoints (e.g., tens or even hundreds millions)\\nin the short future. In that case, datasets of such\\nquantity pose a significant challenge to the robust-\\nness, efficiency, and precision of the selection meth-\\nods. Previous studies like DSIM (Xie et al., 2023)\\ndemonstrated that cheap approximation of features\\nby bag-of-n-grams achieves similar performance\\nbut requires much less computing resources. For\\nfuture research, one may draw inspiration from the\\ndata deduplication and filtering techniques in han-\\ndling billions of pre-training tokens. Especially\\nfor the measurement of diversity, the computing\\nof embedding-based pairwise similarity and clus-\\ntering can be greatly reduced with simplified rep-\\nresentations. In addition, the hierarchical philoso-\\nphy (Hmida et al., 2016; Talavera, 1999; Cabezas\\net al., 2023; Ran et al., 2023) might be a promis-\\ning approach to select data from coarse-grained to\\nfine-grained structures. One may apply the devide-\\nand-conquer strategy to recursively handle each\\nsubset of the instruction dataset, limiting the peak\\nresource consumption under budget.\\n7.4\\nScaling Up LLMs\\nThe cost-efficiency of data assessment and se-\\nlection diminishes with larger LLMs involved\\nin the pipeline.\\nThe model-based indicators and\\ncoreset sampling methods often require the lan-\\nguage model itself to be involved for computation\\nof metrics (Li et al., 2023a), losses (Chen et al.,\\n2024b), and gradients (Xia et al., 2024a). With\\nthe increase of model sizes, it becomes more and\\nmore cumbersome to implement the entire pipeline\\nfor quality measurement and selection. To expe-\\ndite the process, one important direction for future\\nstudy is to develop proper efficient proxy mod-\\nels. Small proxy models have been successfully\\napplied in accelerated fine-tuning of language mod-\\nels (Hoffmann et al., 2022; Liu et al., 2024a), filter-\\ning datasets by perplexity (Ankner et al., 2024), in-\\ntervention on retrieval-augmented generation (Tan\\net al., 2024b), and performance prediction (Anu-\\ngraha et al., 2024; Ngu et al., 2024). Such proxy\\nmodels often share the same architecture design\\nwith the LLMs under development but own much\\nless parameters. The scaling law (Kaplan et al.,\\n2020) confirms the expected consistent behavior\\nbetween data quantity and model scale, providing\\npractical guidelines on the development of such\\nproxy LLMs.\\nOn the other hand, under the context of data\\nevaluation, it calls upon on rethinking of tradi-\\ntional machine learning techniques such as effi-\\ncient optimization tricks and dimensionality re-\\nduction approaches. For example, in the assess-\\nment of loss-based datapoint influence (Feldman\\nand Zhang, 2020), the exhaustive measurement on\\nthe marginal performance by moving-each-sample-\\nout and model re-training can be simply approxi-\\nmated by iterative batch-wise sampling tricks with\\na greedy principle behind. For efficient assessment,\\nPCA (Xu et al., 2023b) and random projection (Xia\\net al., 2024a; Park et al., 2023) are popular choices\\nfor obtaining low-rank representations of embed-\\ndings and gradients, which facilitates not only met-\\nric computation but also storing of datapoints.\\nThe marginal benefits of instruction tuning\\ndiminishes with increasing size of LLMs for\\nknowledge supplement.\\nRecent studies on the\\neffectiveness of instruction tuning in injecting\\ntask-specific or domain-specific knowledge into\\nLLMs (Shi and Lipani, 2023; Goyal et al., 2023;\\nZhang et al., 2024b; Yıldız et al., 2024) show that\\nthe stand-alone instruction tuning might not be the\\nmost appropriate method. Compared with strate-\\ngies like continual pre-training (Cossu et al., 2024;\\nKe, 2024; Cossu et al., 2024) and instruction mod-\\neling (Lou et al., 2024; Cheng et al., 2024; Wang\\net al., 2022; Xu et al., 2024; Shi et al., 2024),\\ninstruction tuning counts the response sequences\\nfor loss computation without sufficient perception\\nof instruction context. For specialized domains\\nlike medicine, finance, and laws, if the pre-trained\\nLLMs are in lack of the prerequisite knowledge,\\nthe instruction tuning cannot properly activates the\\nparameterized “memory\" for alignment but only\\ncauses overfitting of the given prompt. In that case,\\nthe benefits of data selection are limited with poor\\ngeneralizability.\\nAnother noteworthy phenomenon in data assess-\\nment and selection studies is that due to limited\\nbudgets of computing resources, most of the exper-\\niments are performed on LLMs of small and moder-\\nate size (e.g., less than 7B) to validate the effective-\\nness of the quality measurement and the selection\\nstrategy. Small pre-trained LLMs, by their nature\\nof small parameter size, are more sensitive to the\\ninstruction datasets during fine-tuning or continual\\nlearning (Schick and Schütze, 2020; Yıldız et al.,\\n2024). They exhibit the most significant rates of\\nboth forggeting (old knowledge) and learning (new\\nknowledge). In the light of such statement, small\\nLLMs tend to sacrifice the task-irrelevant knowl-\\nedge in return for rapid adaptation towards novel\\ndomains and tasks. The selected datasets by vari-\\nous quality measures can impose immediate effect\\non the parameters of small LLMs, but may weaken\\non those of huge ones. It remains unknown whether\\nthe same quality measurement and data selection\\npipeline can achieve similar performance gains on\\nboth small and large LLMs. For future research\\nof data assessment and selection, extensive exper-\\niments are required to validate their efficiency on\\nhuge LLMs (e.g., 70B and 405B) (AI@Meta, 2024)\\nand LLMs of mixture-of-experts (MoE) architec-\\ntures (e.g., Mixtral 8x22B) (Jiang et al., 2024a).\\nIn consideration of the pre-training corpus, ex-\\ntremely large LLMs already experienced a vast\\namount of multi-lingual, multi-domain web texts\\nduring pre-training, and therefore the priority of\\nthe dimensions in data assessment (i.e., quality, di-\\nversity, and importance) differs from small LLMs.\\nThe association between the model scale and the\\ndata selection criteria is yet to be studied.\\n8\\nConclusion\\nIn this study, we have thoroughly examined the\\nstate-of-the-art data assessment and selection meth-\\nods for instruction tuning of LLMs. The present\\nreview presents a unified organization and catego-\\nrizes these methods in terms of measuring dimen-\\nsionality: quality, diversity, and importance. In\\neach dimensionality, we outline the representative\\nstrategies in details and describe the factors to con-\\nsider when selecting data for instruction tuning.\\nFurthermore, we report the performance of typical\\ndata selection methods and provide discussions on\\nthe comparison between these methods. Last but\\nnot least, the existing challenges and potential so-\\nlutions for future studies are summarized in hope\\nfor benefitting the research community.\\nReferences\\nAmro Abbas, Kushal Tirumala, Dániel Simig, Surya\\nGanguli, and Ari S Morcos. 2023. Semdedup: Data-\\nefficient learning at web-scale through semantic dedu-\\nplication. arXiv preprint arXiv:2303.09540.\\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama\\nAhmad, Ilge Akkaya, Florencia Leoni Aleman,\\nDiogo Almeida, Janko Altenschmidt, Sam Altman,\\nShyamal Anadkat, et al. 2023. Gpt-4 technical report.\\narXiv preprint arXiv:2303.08774.\\nAlessandro Achille, Michael Lam, Rahul Tewari,\\nAvinash Ravichandran, Subhransu Maji, Charless C\\nFowlkes, Stefano Soatto, and Pietro Perona. 2019.\\nTask2vec: Task embedding for meta-learning. In\\nProceedings of the IEEE/CVF international confer-\\nence on computer vision, pages 6430–6439.\\nSandesh Adhikary and Byron Boots. 2022. Sampling\\nover riemannian manifolds using kernel herding. In\\n2022 International Conference on Robotics and Au-\\ntomation (ICRA), pages 3646–3653. IEEE.\\nNaman Agarwal, Brian Bullins, and Elad Hazan. 2016.\\nSecond-order stochastic optimization in linear time.\\nstat, 1050:15.\\nSharat Agarwal, Himanshu Arora, Saket Anand, and\\nChetan Arora. 2020. Contextual diversity for active\\nlearning. In Computer Vision–ECCV 2020: 16th\\nEuropean Conference, Glasgow, UK, August 23–28,\\n2020, Proceedings, Part XVI 16, pages 137–153.\\nSpringer.\\nAI@Meta. 2024. Llama 3 model card.\\nAhmed Alaa and Mihaela Van Der Schaar. 2020. Dis-\\ncriminative jackknife: Quantifying uncertainty in\\ndeep learning via higher-order influence functions.\\nIn International Conference on Machine Learning,\\npages 165–174. PMLR.\\nAlon Albalak, Yanai Elazar, Sang Michael Xie, Shayne\\nLongpre, Nathan Lambert, Xinyi Wang, Niklas\\nMuennighoff, Bairu Hou, Liangming Pan, Haewon\\nJeong, et al. 2024. A survey on data selection for\\nlanguage models. arXiv preprint arXiv:2402.16827.\\nAlexandre Alcoforado,\\nThomas Palmeira Ferraz,\\nLucas Hideki Okamura, Israel Campos Fama,\\nArnold Moya Lavado, Bárbara Dias Bueno, Bruno\\nVeloso, and Anna Helena Reali Costa. 2024. From\\nrandom to informed data selection: A diversity-based\\napproach to optimize human annotation and few-shot\\nlearning. arXiv preprint arXiv:2401.13229.\\nZachary Ankner, Cody Blakeney, Kartik Sreenivasan,\\nMax Marion, Matthew L Leavitt, and Mansheej Paul.\\n2024. Perplexed by perplexity: Perplexity-based data\\npruning with small reference models. arXiv preprint\\narXiv:2405.20541.\\nAntonis Antoniades, Xinyi Wang, Yanai Elazar, Al-\\nfonso Amayuelas, Alon Albalak, Kexun Zhang,\\nand William Yang Wang. 2024.\\nGeneralization\\nvs memorization: Tracing language models’ capa-\\nbilities back to pretraining data.\\narXiv preprint\\narXiv:2407.14985.\\nDavid Anugraha, Genta Indra Winata, Chenyue Li,\\nPatrick Amadeus Irawan, and En-Shiun Annie Lee.\\n2024. Proxylm: Predicting language model perfor-\\nmance on multilingual tasks via proxy models. arXiv\\npreprint arXiv:2406.09334.\\nWalter E. Arnoldi. 1951. The principle of minimized\\niterations in the solution of the matrix eigenvalue\\nproblem. Quarterly of Applied Mathematics, 9:17–\\n29.\\nKyriakos Axiotis, Vincent Cohen-Addad, Monika Hen-\\nzinger, Sammy Jerome, Vahab Mirrokni, David\\nSaulpic, David Woodruff, and Michael Wunder. 2024.\\nData-efficient learning via clustering-based sensitiv-\\nity sampling: Foundation models and beyond. arXiv\\npreprint arXiv:2402.17327.\\nFrancis Bach and Michael Jordan. 2003. Learning spec-\\ntral clustering. Advances in neural information pro-\\ncessing systems, 16.\\nJuhan Bae, Wu Lin, Jonathan Lorraine, and Roger\\nGrosse. 2024.\\nTraining data attribution via ap-\\nproximate unrolled differentation. arXiv preprint\\narXiv:2405.12186.\\nPrafulla Bafna, Dhanya Pramod, and Anagha Vaidya.\\n2016. Document clustering: Tf-idf approach. In\\n2016 International Conference on Electrical, Elec-\\ntronics, and Optimization Techniques (ICEEOT),\\npages 61–66. IEEE.\\nJinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang,\\nXiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei\\nHuang, et al. 2023. Qwen technical report. arXiv\\npreprint arXiv:2309.16609.\\nMaria-Florina Balcan, Alina Beygelzimer, and John\\nLangford. 2006. Agnostic active learning. In Pro-\\nceedings of the 23rd international conference on Ma-\\nchine learning, pages 65–72.\\nLukas Balles, Giovanni Zappella, and Cédric Ar-\\nchambeau. 2022. Gradient-matching coresets for\\nrehearsal-based continual learning. arXiv preprint\\narXiv:2203.14544.\\nSayan Bandyapadhyay and Kasturi Varadarajan. 2015.\\nOn variants of k-means clustering. arXiv preprint\\narXiv:1512.02985.\\nSamyadeep Basu, Philip Pope, and Soheil Feizi. 2020.\\nInfluence functions in deep learning are fragile. arXiv\\npreprint arXiv:2006.14651.\\nCarlo Batini, Cinzia Cappiello, Chiara Francalanci, and\\nAndrea Maurino. 2009. Methodologies for data qual-\\nity assessment and improvement. ACM computing\\nsurveys (CSUR), 41(3):1–52.\\nJohn C Begeny and Diana J Greene. 2014. Can readabil-\\nity formulas be used to successfully gauge difficulty\\nof reading materials?\\nPsychology in the Schools,\\n51(2):198–215.\\nYonatan Belinkov and James Glass. 2019. Analysis\\nmethods in neural language processing: A survey.\\nTransactions of the Association for Computational\\nLinguistics, 7:49–72.\\nYves Bestgen. 2023. Measuring lexical diversity in\\ntexts: The twofold length problem. Language Learn-\\ning.\\nGantavya Bhatt, Yifang Chen, Arnav M Das, Jifan\\nZhang, Sang T Truong, Stephen Mussmann, Yinglun\\nZhu, Jeffrey Bilmes, Simon S Du, Kevin Jamieson,\\net al. 2024.\\nAn experimental design framework\\nfor label-efficient supervised finetuning of large lan-\\nguage models. arXiv preprint arXiv:2401.06692.\\nStella Biderman, Usvsn Prashanth, Lintang Sutawika,\\nHailey Schoelkopf, Quentin Anthony, Shivanshu\\nPurohit, and Edward Raff. 2024. Emergent and pre-\\ndictable memorization in large language models. Ad-\\nvances in Neural Information Processing Systems,\\n36.\\nBilibili. 2024. Index1.9b technical report.\\nA Bjork. 1988. Least squares methods: Handbook of\\nnumerical analysis. Finite Difference Methods Solu-\\ntions of Equations in Rn, 1.\\nDavid M Blei, Andrew Y Ng, and Michael I Jordan.\\n2003. Latent dirichlet allocation. Journal of machine\\nLearning research, 3(Jan):993–1022.\\nZalán Borsos, Mojmir Mutny, and Andreas Krause.\\n2020. Coresets via bilevel optimization for continual\\nlearning and streaming. Advances in neural informa-\\ntion processing systems, 33:14879–14890.\\nZalán Borsos, Mojmír Mutn`y, Marco Tagliasacchi, and\\nAndreas Krause. 2024.\\nData summarization via\\nbilevel optimization. Journal of Machine Learning\\nResearch, 25(73):1–53.\\nMaximilian Böther, Viktor Gsteiger, Ties Robroek, and\\nAna Klimovic. 2023. Modyn: A platform for model\\ntraining on dynamic datasets with sample-level data\\nselection. arXiv preprint arXiv:2312.06254.\\nHerbie Bradley, Andrew Dai, Hannah Teufel, Jenny\\nZhang, Koen Oostermeijer, Marco Bellagente, Jeff\\nClune, Kenneth Stanley, Grégory Schott, and Joel\\nLehman. 2023. Quality-diversity through ai feedback.\\narXiv preprint arXiv:2310.13032.\\nJonathan Brophy, Zayd Hammoudeh, and Daniel Lowd.\\n2023. Adapting and evaluating influence-estimation\\nmethods for gradient-boosted decision trees. Journal\\nof Machine Learning Research, 24(154):1–48.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie\\nSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\\nAskell, et al. 2020. Language models are few-shot\\nlearners. Advances in neural information processing\\nsystems, 33:1877–1901.\\nQuang Vu Bui, Karim Sayadi, Soufian Ben Amor, and\\nMarc Bui. 2017. Combining latent dirichlet alloca-\\ntion and k-means for documents clustering: effect\\nof probabilistic based distance measures. In Intelli-\\ngent Information and Database Systems: 9th Asian\\nConference, ACIIDS 2017, Kanazawa, Japan, April\\n3-5, 2017, Proceedings, Part I 9, pages 248–257.\\nSpringer.\\nAlexander Bukharin and Tuo Zhao. 2023. Data diversity\\nmatters for robust instruction tuning. arXiv preprint\\narXiv:2311.14736.\\nJohn Byabazaire, Gregory O’Hare, and Declan Delaney.\\n2020. Data quality and trust: A perception from\\nshared data in iot. In 2020 IEEE International Con-\\nference on Communications Workshops (ICC Work-\\nshops), pages 1–6. IEEE.\\nLuben MC Cabezas, Rafael Izbicki, and Rafael B Stern.\\n2023. Hierarchical clustering: Visualization, feature\\nimportance and model selection. Applied Soft Com-\\nputing, 141:110303.\\nRicardo JGB Campello, Davoud Moulavi, and Jörg\\nSander. 2013. Density-based clustering based on\\nhierarchical density estimates. In Pacific-Asia confer-\\nence on knowledge discovery and data mining, pages\\n160–172. Springer.\\nJialun Cao, Wuqi Zhang, and Shing-Chi Cheung. 2024.\\nConcerned with data contamination? assessing coun-\\ntermeasures in code language model. arXiv preprint\\narXiv:2403.16898.\\nKris Cao and Stephen Clark. 2017. Latent variable\\ndialogue models and their diversity. arXiv preprint\\narXiv:1702.05962.\\nYihan Cao, Yanbin Kang, and Lichao Sun. 2023. In-\\nstruction mining: High-quality instruction data se-\\nlection for large language models. arXiv preprint\\narXiv:2307.06290.\\nNicholas Carlini, Chang Liu, Úlfar Erlingsson, Jernej\\nKos, and Dawn Song. 2019. The secret sharer: Eval-\\nuating and testing unintended memorization in neu-\\nral networks. In 28th USENIX security symposium\\n(USENIX security 19), pages 267–284.\\nPatricia L Carrell. 1987. Readability in esl.\\nJeanne Sternlicht Chall and Edgar Dale. 1995. Readabil-\\nity revisited: The new dale-chall readability formula.\\nEdgar Brookline Books.\\nChi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu,\\nWei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan\\nLiu. 2023. Chateval: Towards better llm-based eval-\\nuators through multi-agent debate. arXiv preprint\\narXiv:2308.07201.\\nKHR Chan, Y Yu, C You, H Qi, J Wright, and YR Ma.\\n2021. a white-box deep network from the principle\\nof maximizing rate reduction. arxiv. 2021. arXiv\\npreprint arXiv:2105.10446.\\nYupeng Chang, Xu Wang, Jindong Wang, Yuan Wu,\\nLinyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi,\\nCunxiang Wang, Yidong Wang, et al. 2024. A sur-\\nvey on evaluation of large language models. ACM\\nTransactions on Intelligent Systems and Technology,\\n15(3):1–45.\\nDaoyuan Chen, Yilun Huang, Zhijian Ma, Hesen Chen,\\nXuchen Pan, Ce Ge, Dawei Gao, Yuexiang Xie,\\nZhaoyang Liu, Jinyang Gao, et al. 2024a. Data-juicer:\\nA one-stop data processing system for large language\\nmodels. In Companion of the 2024 International\\nConference on Management of Data, pages 120–134.\\nHao Chen, Yiming Zhang, Qi Zhang, Hantao Yang, Xi-\\naomeng Hu, Xuetao Ma, Yifan Yanggong, and Junbo\\nZhao. 2023a. Maybe only 0.5% data is needed: A\\npreliminary exploration of low training data instruc-\\ntion tuning. arXiv preprint arXiv:2305.09246.\\nJiuhai Chen and Jonas Mueller. 2023. Quantifying un-\\ncertainty in answers from any language model and\\nenhancing their trustworthiness.\\nJiuhai Chen and Jonas Mueller. 2024.\\nAutomated\\ndata curation for robust language model fine-tuning.\\narXiv preprint arXiv:2403.12776.\\nLichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa\\nGunaratna, Vikas Yadav, Zheng Tang, Vijay Srini-\\nvasan, Tianyi Zhou, Heng Huang, et al. 2023b. Al-\\npagasus: Training a better alpaca with fewer data.\\narXiv preprint arXiv:2307.08701.\\nMayee Chen, Nicholas Roberts, Kush Bhatia, Jue Wang,\\nCe Zhang, Frederic Sala, and Christopher Ré. 2024b.\\nSkill-it! a data-driven skills framework for under-\\nstanding and training language models. Advances in\\nNeural Information Processing Systems, 36.\\nYutian Chen, Luke Bornn, Nando De Freitas, Mareija\\nEskelin, Jing Fang, and Max Welling. 2016. Herded\\ngibbs sampling. The Journal of Machine Learning\\nResearch, 17(1):263–291.\\nYutian Chen, Max Welling, and Alex Smola. 2012.\\nSuper-samples from kernel herding. arXiv preprint\\narXiv:1203.3472.\\nDaixuan Cheng, Yuxian Gu, Shaohan Huang, Junyu Bi,\\nMinlie Huang, and Furu Wei. 2024. Instruction pre-\\ntraining: Language models are supervised multitask\\nlearners. arXiv preprint arXiv:2406.14491.\\nAnshuman Chhabra, Peizhao Li, Prasant Mohapatra,\\nand Hongfu Liu. 2024.\\n\" what data benefits my\\nclassifier?\" enhancing model performance and inter-\\npretability through influence-based data selection. In\\nThe Twelfth International Conference on Learning\\nRepresentations.\\nGui Citovsky, Giulia DeSalvo, Claudio Gentile, Lazaros\\nKarydas, Anand Rajagopalan, Afshin Rostamizadeh,\\nand Sanjiv Kumar. 2021. Batch active learning at\\nscale. Advances in Neural Information Processing\\nSystems, 34:11933–11944.\\nKevyn Collins-Thompson and Jamie Callan. 2005. Pre-\\ndicting reading difficulty with statistical language\\nmodels. Journal of the american society for informa-\\ntion science and technology, 56(13):1448–1462.\\nBenoît Colson, Patrice Marcotte, and Gilles Savard.\\n2007. An overview of bilevel optimization. Annals\\nof operations research, 153:235–256.\\nBradford R Connatser. 1999. Last rites for readabil-\\nity formulas in technical communication. Journal\\nof technical writing and communication, 29(3):271–\\n287.\\nMike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie,\\nJun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell,\\nMatei Zaharia, and Reynold Xin. 2023. Free dolly:\\nIntroducing the world’s first truly open instruction-\\ntuned llm. Company Blog of Databricks.\\nWilliam J Cook, William H Cunningham, William R\\nPulleyblank, and Alexander Schrijver. 1994. Com-\\nbinatorial optimization. Unpublished manuscript,\\n10:75–93.\\nGérard Cornuéjols, George Nemhauser, and Laurence\\nWolsey. 1983. The uncapicitated facility location\\nproblem. Technical report, Cornell University Opera-\\ntions Research and Industrial Engineering.\\nAndrea Cossu, Antonio Carta, Lucia Passaro, Vincenzo\\nLomonaco, Tinne Tuytelaars, and Davide Bacciu.\\n2024. Continual pre-training mitigates forgetting in\\nlanguage and vision. Neural Networks, page 106492.\\nIan Covert, Wenlong Ji, Tatsunori Hashimoto, and\\nJames Zou. 2024.\\nScaling laws for the value of\\nindividual data points in machine learning. arXiv\\npreprint arXiv:2405.20456.\\nM Covington and Joe D McFall. 2008. The moving-\\naverage type-token ratio. Linguistics Society of Amer-\\nica, Chicago, IL.\\nMichael A Covington and Joe D McFall. 2010. Cutting\\nthe gordian knot: The moving-average type–token\\nratio (mattr).\\nJournal of quantitative linguistics,\\n17(2):94–100.\\nRadu G Cre¸tulescu, Daniel I Morariu, Macarie Breazu,\\nand Daniel Volovici. 2019. Dbscan algorithm for\\ndocument clustering. International Journal of Ad-\\nvanced Statistics and IT&C for Economics and Life\\nSciences, 9(1):58–66.\\nEdgar Dale and Jeanne S Chall. 1949. The concept of\\nreadability. Elementary English, 26(1):19–26.\\nDan Dan Friedman and Adji Bousso Dieng. 2023. The\\nvendi score: A diversity evaluation metric for ma-\\nchine learning. Transactions on machine learning\\nresearch.\\nVu Minh Hoang Dang and Rakesh M Verma. 2024.\\nData quality in nlp: Metrics and a comprehensive\\ntaxonomy. In International Symposium on Intelligent\\nData Analysis, pages 217–229. Springer.\\nFredrik deBoer. 2014. Evaluating the comparability of\\ntwo measures of lexical diversity. System, 47:139–\\n145.\\nChunyuan Deng, Yilun Zhao, Xiangru Tang, Mark Ger-\\nstein, and Arman Cohan. 2023. Investigating data\\ncontamination in modern benchmarks for large lan-\\nguage models. arXiv preprint arXiv:2311.09783.\\nDingsheng Deng. 2020. Dbscan clustering algorithm\\nbased on density. In 2020 7th international forum\\non electrical engineering and automation (IFEEA),\\npages 949–953. IEEE.\\nMingkai Deng, Bowen Tan, Zhengzhong Liu, Eric P\\nXing, and Zhiting Hu. 2021. Compression, trans-\\nduction, and creation: A unified framework for eval-\\nuating natural language generation. arXiv preprint\\narXiv:2109.06379.\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\\nKristina Toutanova. 2018. Bert: Pre-training of deep\\nbidirectional transformers for language understand-\\ning. arXiv preprint arXiv:1810.04805.\\nNing Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi\\nZheng, Shengding Hu, Zhiyuan Liu, Maosong Sun,\\nand Bowen Zhou. 2023. Enhancing chat language\\nmodels by scaling high-quality instructional conver-\\nsations. arXiv preprint arXiv:2305.14233.\\nMarcel Dix, Gianluca Manca, Kenneth Chigozie Okafor,\\nReuben Borrison, Konstantin Kirchheim, Divyasheel\\nSharma, Kr Chandrika, Deepti Maduskar, and Frank\\nOrtmeier. 2023. Measuring the robustness of ml mod-\\nels against data quality issues in industrial time series\\ndata. In 2023 IEEE 21st International Conference on\\nIndustrial Informatics (INDIN), pages 1–8. IEEE.\\nJesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali\\nFarhadi, Hannaneh Hajishirzi, and Noah Smith. 2020.\\nFine-tuning pretrained language models: Weight ini-\\ntializations, data orders, and early stopping. arXiv\\npreprint arXiv:2002.06305.\\nGuanting Dong, Keming Lu, Chengpeng Li, Tingyu\\nXia, Bowen Yu, Chang Zhou, and Jingren Zhou.\\n2024. Self-play with execution feedback: Improving\\ninstruction-following capabilities of large language\\nmodels. arXiv preprint arXiv:2406.13542.\\nHanze Dong, Wei Xiong, Deepanshu Goyal, Yihan\\nZhang, Winnie Chow, Rui Pan, Shizhe Diao, Jipeng\\nZhang, Kashun Shum, and Tong Zhang. 2023. Raft:\\nReward ranked finetuning for generative foundation\\nmodel alignment. arXiv preprint arXiv:2304.06767.\\nLi Dong, Nan Yang, Wenhui Wang, Furu Wei, Xi-\\naodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou,\\nand Hsiao-Wuen Hon. 2019. Unified language model\\npre-training for natural language understanding and\\ngeneration. Advances in neural information process-\\ning systems, 32.\\nWei Dong, Charikar Moses, and Kai Li. 2011. Efficient\\nk-nearest neighbor graph construction for generic\\nsimilarity measures. In Proceedings of the 20th in-\\nternational conference on World wide web, pages\\n577–586.\\nJiawei Du, Qin Shi, and Joey Tianyi Zhou. 2024. Se-\\nquential subset matching for dataset distillation. Ad-\\nvances in Neural Information Processing Systems,\\n36.\\nNan Du, Yingyu Liang, Maria Balcan, and Le Song.\\n2014.\\nInfluence function learning in information\\ndiffusion networks. In International Conference on\\nMachine Learning, pages 2016–2024. PMLR.\\nQianlong Du, Chengqing Zong, and Jiajun Zhang. 2023.\\nMods: Model-oriented data selection for instruction\\ntuning. arXiv preprint arXiv:2311.15653.\\nWenchao Du and Alan W Black. 2019. Boosting dialog\\nresponse generation. In Proceedings of the 57th An-\\nnual Meeting of the Association for Computational\\nLinguistics.\\nWilliam H Dubay. 2004. The principles of readability.\\nimpact information. Costa Mesa, CA.\\nYann Dubois, Chen Xuechen Li, Rohan Taori, Tianyi\\nZhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin,\\nPercy S Liang, and Tatsunori B Hashimoto. 2024.\\nAlpacafarm: A simulation framework for methods\\nthat learn from human feedback. Advances in Neural\\nInformation Processing Systems, 36.\\nSergey Edunov, Alexei Baevski, and Michael Auli. 2019.\\nPre-trained language model representations for lan-\\nguage generation. arXiv preprint arXiv:1903.09722.\\nLisa Ehrlinger and Wolfram Wöß. 2022.\\nA survey\\nof data quality measurement and monitoring tools.\\nFrontiers in big data, 5:850611.\\nYuval Eldar, Michael Lindenbaum, Moshe Porat, and\\nYehoshua Y Zeevi. 1997. The farthest point strategy\\nfor progressive image sampling. IEEE transactions\\non image processing, 6(9):1305–1315.\\nLogan Engstrom, Axel Feldmann, and Aleksander\\nMadry. 2024. Dsdm: Model-aware dataset selection\\nwith datamodels. arXiv preprint arXiv:2401.12926.\\nAyse Erkan and Yasemin Altun. 2010. Semi-supervised\\nlearning via generalized maximum entropy. In Pro-\\nceedings of the Thirteenth International Conference\\non Artificial Intelligence and Statistics, pages 209–\\n216. JMLR Workshop and Conference Proceedings.\\nKawin\\nEthayarajh,\\nYejin\\nChoi,\\nand\\nSwabha\\nSwayamdipta.\\n2022.\\nUnderstanding\\ndataset\\ndifficulty with V-usable information.\\nIn Interna-\\ntional Conference on Machine Learning, pages\\n5988–6008. PMLR.\\nPhilip R Evans and Garib N Murshudov. 2013. How\\ngood are my data and what is the resolution? Acta\\nCrystallographica Section D: Biological Crystallog-\\nraphy, 69(7):1204–1214.\\nDante Everaert and Christopher Potts. 2023. Gio: Gra-\\ndient information optimization for training dataset\\nselection. arXiv preprint arXiv:2306.11670.\\nReza Zanjirani Farahani and Masoud Hekmatfar. 2009.\\nFacility location: concepts, models, algorithms and\\ncase studies. Springer Science & Business Media.\\nDan Feldman and Michael Langberg. 2011. A unified\\nframework for approximating and clustering data. In\\nProceedings of the forty-third annual ACM sympo-\\nsium on Theory of computing, pages 569–578.\\nVitaly Feldman. 2020. Does learning require memoriza-\\ntion? a short tale about a long tail. In Proceedings\\nof the 52nd Annual ACM SIGACT Symposium on\\nTheory of Computing, pages 954–959.\\nVitaly Feldman and Chiyuan Zhang. 2020. What neural\\nnetworks memorize and why: Discovering the long\\ntail via influence estimation. Advances in Neural\\nInformation Processing Systems, 33:2881–2891.\\nMariano Felice and Lucia Specia. 2012. Linguistic\\nfeatures for quality estimation. In Proceedings of the\\nSeventh Workshop on Statistical Machine Translation,\\npages 96–103.\\nFangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen\\nArivazhagan, and Wei Wang. 2020.\\nLanguage-\\nagnostic bert sentence embedding. arXiv preprint\\narXiv:2007.01852.\\nLijun Feng, Martin Jansche, Matt Huenerfauth, and\\nNoémie Elhadad. 2010. A comparison of features for\\nautomatic readability assessment. In Coling 2010:\\nPosters, pages 276–284.\\nSteven Y Feng, Varun Gangal, Jason Wei, Sarath Chan-\\ndar, Soroush Vosoughi, Teruko Mitamura, and Ed-\\nuard Hovy. 2021. A survey of data augmentation ap-\\nproaches for nlp. arXiv preprint arXiv:2105.03075.\\nPeter Flach. 2012. Machine learning: the art and sci-\\nence of algorithms that make sense of data. Cam-\\nbridge university press.\\nRudolph Flesch. 1948. A new readability yardstick.\\nJournal of applied psychology, 32(3):221.\\nThomas François. 2010. La lisibilité computationnelle:\\nun renouveau pour la lisibilité du français langue\\npremière et seconde? ITL-International Journal of\\nApplied Linguistics, 160(1):75–99.\\nThomas François. 2011.\\nLes apports du traitement\\nautomatique du langage à la lisibilité du français\\nlangue étrangère. Ph.D. thesis, Ph. D. thesis, Uni-\\nversité Catholique de Louvain. Thesis Supervisors:\\nCédrick . . . .\\nThomas François and Cédrick Fairon. 2012. An “ai\\nreadability” formula for french as a foreign language.\\nIn Proceedings of the 2012 joint conference on em-\\npirical methods in Natural Language Processing and\\ncomputational natural language learning, pages 466–\\n477.\\nThomas François and Eleni Miltsakaki. 2012. Do nlp\\nand machine learning improve traditional readability\\nformulas? In Proceedings of the First Workshop on\\nPredicting and Improving Text Readability for target\\nreader populations, pages 49–57.\\nThomas George, César Laurent, Xavier Bouthillier,\\nNicolas Ballas, and Pascal Vincent. 2021. Fast ap-\\nproximate natural gradient descent in a kronecker-\\nfactored eigenbasis. Preprint, arXiv:1806.03884.\\nAmirata Ghorbani and James Zou. 2019. Data shapley:\\nEquitable valuation of data for machine learning. In\\nInternational conference on machine learning, pages\\n2242–2251. PMLR.\\nSreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Ku-\\nmar, Deepali Aneja, Zeyu Jin, Ramani Duraiswami,\\nDinesh Manocha, et al. 2024.\\nA closer look at\\nthe limitations of instruction tuning. arXiv preprint\\narXiv:2402.05119.\\nSachin Goyal, Ananya Kumar, Sankalp Garg, Zico\\nKolter, and Aditi Raghunathan. 2023. Finetune like\\nyou pretrain: Improved finetuning of zero-shot vision\\nmodels. In Proceedings of the IEEE/CVF Confer-\\nence on Computer Vision and Pattern Recognition,\\npages 19338–19347.\\nYves Grandvalet and Yoshua Bengio. 2004.\\nSemi-\\nsupervised learning by entropy minimization. Ad-\\nvances in neural information processing systems, 17.\\nHans-Rolf Gregorius and Elizabeth M Gillet. 2008.\\nGeneralized simpson-diversity.\\nEcological Mod-\\nelling, 211(1-2):90–96.\\nRoger Grosse, Juhan Bae, Cem Anil, Nelson Elhage,\\nAlex Tamkin, Amirhossein Tajdini, Benoit Steiner,\\nDustin Li, Esin Durmus, Ethan Perez, Evan Hubinger,\\nKamil˙e Lukoši¯ut˙e, Karina Nguyen, Nicholas Joseph,\\nSam McCandlish, Jared Kaplan, and Samuel R.\\nBowman. 2023.\\nStudying large language model\\ngeneralization with influence functions. Preprint,\\narXiv:2308.03296.\\nSuriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio\\nCésar Teodoro Mendes, Allie Del Giorno, Sivakanth\\nGopi, Mojan Javaheripi, Piero Kauffmann, Gustavo\\nde Rosa, Olli Saarikivi, et al. 2023. Textbooks are all\\nyou need. arXiv preprint arXiv:2306.11644.\\nRobert Gunning. 1952. The technique of clear writing.\\n(No Title).\\nChengcheng Guo, Bo Zhao, and Yanbing Bai. 2022.\\nDeepcore: A comprehensive library for coreset selec-\\ntion in deep learning. In International Conference\\non Database and Expert Systems Applications, pages\\n181–195. Springer.\\nNitin Gupta, Shashank Mujumdar, Hima Patel, Satoshi\\nMasuda, Naveen Panwar, Sambaran Bandyopadhyay,\\nSameep Mehta, Shanmukha Guttula, Shazia Afzal,\\nRuhi Sharma Mittal, et al. 2021. Data quality for\\nmachine learning tasks. In Proceedings of the 27th\\nACM SIGKDD conference on knowledge discovery\\n& data mining, pages 4040–4041.\\nKelvin Guu, Albert Webson, Ellie Pavlick, Lucas Dixon,\\nIan Tenney, and Tolga Bolukbasi. 2023.\\nSimflu-\\nence: Modeling the influence of individual training\\nexamples by simulating training runs. arXiv preprint\\narXiv:2303.08114.\\nNick Harvey and Samira Samadi. 2014. Near-optimal\\nherding. In Conference on Learning Theory, pages\\n1165–1182. PMLR.\\nFangliang He and Xin-Sheng Hu. 2005. Hubbell’s fun-\\ndamental biodiversity parameter and the simpson di-\\nversity index. Ecology Letters, 8(4):386–390.\\nJimming He, Sanjana Garg, and Jonas Mueller. 2024.\\nHow to detect bad data in your instruction tuning\\ndataset (for better llm fine-tuning).\\nHmida Hmida, Sana Ben Hamida, Amel Borgi, and\\nMarta Rukoz. 2016.\\nHierarchical data topol-\\nogy based selection for large scale learning.\\nIn\\n2016 Intl IEEE Conferences on Ubiquitous In-\\ntelligence & Computing, Advanced and Trusted\\nComputing,\\nScalable Computing and Commu-\\nnications,\\nCloud\\nand\\nBig\\nData\\nComputing,\\nInternet of People, and Smart World Congress\\n(UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld),\\npages 1221–1226. IEEE.\\nJordan Hoffmann, Sebastian Borgeaud, Arthur Men-\\nsch, Elena Buchatskaya, Trevor Cai, Eliza Ruther-\\nford, Diego de Las Casas, Lisa Anne Hendricks,\\nJohannes Welbl, Aidan Clark, et al. 2022. Train-\\ning compute-optimal large language models. arXiv\\npreprint arXiv:2203.15556.\\nAnna Huang et al. 2008. Similarity measures for text\\ndocument clustering. In Proceedings of the sixth new\\nzealand computer science research student confer-\\nence (NZCSRSC2008), Christchurch, New Zealand,\\nvolume 4, pages 9–56.\\nDanqing Huang, Shuming Shi, Chin-Yew Lin, Jian Yin,\\nand Wei-Ying Ma. 2016. How well do computers\\nsolve math word problems? large-scale dataset con-\\nstruction and evaluation. In Proceedings of the 54th\\nAnnual Meeting of the Association for Computational\\nLinguistics (Volume 1: Long Papers), pages 887–896.\\nHui Huang, Yingqi Qu, Jing Liu, Muyun Yang, and\\nTiejun Zhao. 2024.\\nAn empirical study of llm-\\nas-a-judge for llm evaluation:\\nFine-tuned judge\\nmodels are task-specific classifiers. arXiv preprint\\narXiv:2403.02839.\\nFerenc Huszár and David Duvenaud. 2012. Optimally-\\nweighted herding is bayesian quadrature.\\narXiv\\npreprint arXiv:1204.1664.\\nAdam Ibrahim, Benjamin Thérien, Kshitij Gupta,\\nMats L Richter, Quentin Anthony, Timothée Lesort,\\nEugene Belilovsky, and Irina Rish. 2024. Simple\\nand scalable strategies to continually pre-train large\\nlanguage models. arXiv preprint arXiv:2403.08763.\\nAbiodun M Ikotun, Absalom E Ezugwu, Laith Abuali-\\ngah, Belal Abuhaija, and Jia Heming. 2023. K-means\\nclustering algorithms: A comprehensive review, vari-\\nants analysis, and advances in the era of big data.\\nInformation Sciences, 622:178–210.\\nAndrew Ilyas, Sung Min Park, Logan Engstrom, Guil-\\nlaume Leclerc, and Aleksander Madry. 2022. Data-\\nmodels: Predicting predictions from training data.\\narXiv preprint arXiv:2202.00622.\\nBogdan Ionescu, Mihai Lupu, Maia Rohm, Alexan-\\ndru Lucian Gînsca, and Henning Müller. 2018.\\nDatasets column: diversity and credibility for social\\nimages and image retrieval. ACM SIGMultimedia\\nRecords, 9(3):7–7.\\nSaachi Jain, Hadi Salman, Alaa Khaddaj, Eric Wong,\\nSung Min Park, and Aleksander M ˛adry. 2023. A\\ndata-based perspective on transfer learning. In Pro-\\nceedings of the IEEE/CVF Conference on Computer\\nVision and Pattern Recognition, pages 3613–3622.\\nSarthak Jain, Varun Manjunatha, Byron C Wallace, and\\nAni Nenkova. 2022. Influence functions for sequence\\ntagging models. arXiv preprint arXiv:2210.14177.\\nJoel Jang, Seungone Kim, Seonghyeon Ye, Doyoung\\nKim, Lajanugen Logeswaran, Moontae Lee, Kyung-\\njae Lee, and Minjoon Seo. 2023. Exploring the bene-\\nfits of training expert language models over instruc-\\ntion tuning. In International Conference on Machine\\nLearning, pages 14702–14729. PMLR.\\nScott Jarvis. 2013. Capturing the diversity in lexical\\ndiversity. Language learning, 63:87–106.\\nScott Jarvis and M Daller. 2013. Defining and measur-\\ning lexical diversity. Vocabulary knowledge: Human\\nratings and automated measures. Amsterdam, The\\nNetherlands.\\nFred Jelinek, Robert L Mercer, Lalit R Bahl, and\\nJames K Baker. 1977. Perplexity—a measure of the\\ndifficulty of speech recognition tasks. The Journal of\\nthe Acoustical Society of America, 62(S1):S63–S63.\\nFrederick Jelinek. 1980.\\nInterpolated estimation of\\nmarkov source parameters from sparse data. In Proc.\\nWorkshop on Pattern Recognition in Practice, 1980.\\nHongjie Jia, Shifei Ding, Xinzheng Xu, and Ru Nie.\\n2014. The latest research progress on spectral clus-\\ntering. Neural Computing and Applications, 24:1477–\\n1486.\\nRuoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis,\\nNick Hynes, Nezihe Merve Gürel, Bo Li, Ce Zhang,\\nDawn Song, and Costas J Spanos. 2019. Towards\\nefficient data valuation based on the shapley value.\\nIn The 22nd International Conference on Artificial\\nIntelligence and Statistics, pages 1167–1176. PMLR.\\nAlbert Q Jiang, Alexandre Sablayrolles, Arthur Men-\\nsch, Chris Bamford, Devendra Singh Chaplot, Diego\\nde las Casas, Florian Bressand, Gianna Lengyel, Guil-\\nlaume Lample, Lucile Saulnier, et al. 2023a. Mistral\\n7b. arXiv preprint arXiv:2310.06825.\\nAlbert Q Jiang, Alexandre Sablayrolles, Antoine\\nRoux, Arthur Mensch, Blanche Savary, Chris Bam-\\nford, Devendra Singh Chaplot, Diego de las Casas,\\nEmma Bou Hanna, Florian Bressand, et al. 2024a.\\nMixtral of experts. arXiv preprint arXiv:2401.04088.\\nMingjian Jiang, Yangjun Ruan, Sicong Huang, Saifei\\nLiao, Silviu Pitis, Roger Baker Grosse, and Jimmy\\nBa. 2023b. Calibrating language models via aug-\\nmented prompt ensembles. Workshop on Challenges\\nin Deployable Generative AI at International Confer-\\nence on Machine Learning.\\nMinhao Jiang, Ken Ziyu Liu, Ming Zhong, Rylan\\nSchaeffer, Siru Ouyang, Jiawei Han, and Sanmi\\nKoyejo. 2024b.\\nInvestigating data contamination\\nfor pre-training language models. arXiv preprint\\narXiv:2401.06059.\\nWenyu Jiang, Hao Cheng, Mingcai Chen, Chongjun\\nWang, and Hongxin Wei. 2023c. Dos: Diverse out-\\nlier sampling for out-of-distribution detection. arXiv\\npreprint arXiv:2306.02031.\\nWenyu Jiang, Zhenlong Liu, Zejian Xie, Songxin Zhang,\\nBingyi Jing, and Hongxin Wei. 2024c. Exploring\\nlearning complexity for downstream data pruning.\\narXiv preprint arXiv:2402.05356.\\nZixuan Jiang, Jiaqi Gu, Mingjie Liu, and David Z Pan.\\n2023d.\\nDelving into effective gradient matching\\nfor dataset condensation.\\nIn 2023 IEEE Interna-\\ntional Conference on Omni-layer Intelligent Systems\\n(COINS), pages 1–6. IEEE.\\nXisen Jin and Xiang Ren. 2024a. Demystifying for-\\ngetting in language model fine-tuning with statisti-\\ncal analysis of example associations. arXiv preprint\\narXiv:2406.14026.\\nXisen Jin and Xiang Ren. 2024b. What will my model\\nforget? forecasting forgotten examples in language\\nmodel refinement. arXiv preprint arXiv:2402.01865.\\nXisen Jin, Dejiao Zhang, Henghui Zhu, Wei Xiao,\\nShang-Wen Li, Xiaokai Wei, Andrew Arnold, and\\nXiang Ren. 2021. Lifelong pretraining: Continu-\\nally adapting language models to emerging corpora.\\narXiv preprint arXiv:2110.08534.\\nRC St John and Norman R Draper. 1975. D-optimality\\nfor regression designs: a review.\\nTechnometrics,\\n17(1):15–23.\\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom\\nHenighan, Dawn Drain, Ethan Perez, Nicholas\\nSchiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli\\nTran-Johnson, et al. 2022.\\nLanguage models\\n(mostly) know what they know.\\narXiv preprint\\narXiv:2207.05221.\\nFiruz Kamalov. 2020. Kernel density estimation based\\nsampling for imbalanced class distribution. Informa-\\ntion Sciences, 512:1192–1201.\\nNikhil Kandpal, Eric Wallace, and Colin Raffel. 2022.\\nDeduplicating training data mitigates privacy risks\\nin language models. In International Conference on\\nMachine Learning, pages 10697–10707. PMLR.\\nFeiyang Kang, Hoang Anh Just, Anit Kumar Sahu, and\\nRuoxi Jia. 2024. Performance scaling via optimal\\ntransport: Enabling data selection from partially re-\\nvealed sources. Advances in Neural Information Pro-\\ncessing Systems, 36.\\nTapas Kanungo, David M Mount, Nathan S Netanyahu,\\nChristine Piatko, Ruth Silverman, and Angela Y Wu.\\n2000. The analysis of a simple k-means clustering\\nalgorithm. In Proceedings of the sixteenth annual\\nsymposium on Computational geometry, pages 100–\\n109.\\nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B\\nBrown, Benjamin Chess, Rewon Child, Scott Gray,\\nAlec Radford, Jeffrey Wu, and Dario Amodei. 2020.\\nScaling laws for neural language models.\\narXiv\\npreprint arXiv:2001.08361.\\nZixuan Ke. 2024. Continual Learning with Language\\nModels.\\nPh.D. thesis, University of Illinois at\\nChicago.\\nSusan Kemper. 1983. Measuring the inference load of a\\ntext. Journal of educational psychology, 75(3):391.\\nKimmo Kettunen. 2014. Can type-token ratio be used to\\nshow morphological complexity of languages? Jour-\\nnal of Quantitative Linguistics, 21(3):223–245.\\nKamran Khan, Saif Ur Rehman, Kamran Aziz, Simon\\nFong, and Sababady Sarasvady. 2014. Dbscan: Past,\\npresent and future. In The fifth international confer-\\nence on the applications of digital information and\\nweb technologies (ICADIWT 2014), pages 232–238.\\nIEEE.\\nDouwe Kiela, Max Bartolo, Yixin Nie, Divyansh\\nKaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vid-\\ngen, Grusha Prasad, Amanpreet Singh, Pratik Ring-\\nshia, et al. 2021. Dynabench: Rethinking benchmark-\\ning in nlp. arXiv preprint arXiv:2104.14337.\\nKrishnateja\\nKillamsetty,\\nSivasubramanian\\nDurga,\\nGanesh Ramakrishnan, Abir De, and Rishabh Iyer.\\n2021a. Grad-match: Gradient matching based data\\nsubset selection for efficient deep model training.\\nIn International Conference on Machine Learning,\\npages 5464–5474. PMLR.\\nKrishnateja\\nKillamsetty,\\nDurga\\nSivasubramanian,\\nGanesh Ramakrishnan, and Rishabh Iyer. 2021b.\\nGlister: Generalization based data subset selection\\nfor efficient and robust learning. In Proceedings of\\nthe AAAI Conference on Artificial Intelligence, vol-\\nume 35, pages 8110–8118.\\nKrishnateja Killamsetty, Xujiang Zhao, Feng Chen, and\\nRishabh Iyer. 2021c. Retrieve: Coreset selection for\\nefficient and robust semi-supervised learning. Ad-\\nvances in neural information processing systems,\\n34:14488–14501.\\nWalter Kintsch and Douglas Vipond. 2014. Reading\\ncomprehension and readability in educational prac-\\ntice and psychological theory. In Perspectives on\\nmemory research, pages 329–365. Psychology Press.\\nJohn\\nKirchenbauer,\\nGarrett\\nHonke,\\nGowthami\\nSomepalli, Jonas Geiping, Daphne Ippolito, Kather-\\nine Lee, Tom Goldstein, and David Andre. 2024.\\nLmd3: Language model data density dependence.\\narXiv preprint arXiv:2405.06331.\\nAndreas Kirsch. 2023. Does\" deep learning on a data\\ndiet\" reproduce? overall yes, but grand at initializa-\\ntion does not. arXiv preprint arXiv:2303.14753.\\nGeorge R Klare. 1974. Assessing readability. Reading\\nresearch quarterly, pages 62–102.\\nGeorge R Klare et al. 1963. The measurement of read-\\nability. Iowa State University Press Ames.\\nGeorge R Klare et al. 1984. Readability. Handbook of\\nreading research, 1:681–744.\\nPang Wei Koh and Percy Liang. 2017. Understanding\\nblack-box predictions via influence functions. In\\nInternational conference on machine learning, pages\\n1885–1894. PMLR.\\nRik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate\\nKushman, and Hannaneh Hajishirzi. 2016. Mawps:\\nA math word problem repository. In Proceedings of\\nthe 2016 conference of the north american chapter of\\nthe association for computational linguistics: human\\nlanguage technologies, pages 1152–1157.\\nAndreas Köpf, Yannic Kilcher, Dimitri von Rütte,\\nSotiris Anagnostidis, Zhi Rui Tam, Keith Stevens,\\nAbdullah Barhoum, Duc Nguyen, Oliver Stan-\\nley, Richárd Nagyfi, et al. 2024.\\nOpenassistant\\nconversations-democratizing large language model\\nalignment. Advances in Neural Information Process-\\ning Systems, 36.\\nJan Kremer, Kim Steenstrup Pedersen, and Christian\\nIgel. 2014. Active learning with support vector ma-\\nchines. Wiley Interdisciplinary Reviews: Data Min-\\ning and Knowledge Discovery, 4(4):313–326.\\nSandra Kublik and Shubham Saboo. 2023. GPT-3: The\\nUltimate Guide to Building NLP Products with Ope-\\nnAI API. Packt Publishing Ltd.\\nPo-Nien Kung and Nanyun Peng. 2023.\\nDo mod-\\nels really learn to follow instructions? an empir-\\nical study of instruction tuning.\\narXiv preprint\\narXiv:2305.11383.\\nPo-Nien Kung, Fan Yin, Di Wu, Kai-Wei Chang,\\nand Nanyun Peng. 2023.\\nActive instruction tun-\\ning: Improving cross-task generalization by train-\\ning on prompt sensitive tasks.\\narXiv preprint\\narXiv:2311.00288.\\nJeongyeol Kwon, Dohyun Kwon, Stephen Wright, and\\nRobert D Nowak. 2023. A fully first-order method\\nfor stochastic bilevel optimization. In International\\nConference on Machine Learning, pages 18083–\\n18113. PMLR.\\nYongchan Kwon and James Zou. 2021.\\nBeta shap-\\nley:\\na unified and noise-reduced data valuation\\nframework for machine learning.\\narXiv preprint\\narXiv:2110.14049.\\nKristopher Kyle, Scott A Crossley, and Scott Jarvis.\\n2021. Assessing the validity of lexical diversity in-\\ndices using direct judgements. Language Assessment\\nQuarterly, 18(2):154–170.\\nYi-An Lai, Xuan Zhu, Yi Zhang, and Mona Diab. 2020.\\nDiversity, density, and homogeneity: Quantitative\\ncharacteristic metrics for text collections.\\narXiv\\npreprint arXiv:2003.08529.\\nYrjo Lappalainen and Nikesh Narayanan. 2023. Aisha:\\nA custom ai library chatbot using the chatgpt api.\\nJournal of Web Librarianship, 17(3):37–58.\\nStefan Larson,\\nAnish Mahendran,\\nAndrew Lee,\\nJonathan K Kummerfeld, Parker Hill, Michael A\\nLaurenzano, Johann Hauswald, Lingjia Tang, and\\nJason Mars. 2019. Outlier detection for improved\\ndata quality and diversity in dialog systems. arXiv\\npreprint arXiv:1904.03122.\\nCosmin Lazar and Andrei Doncescu. 2009. Non nega-\\ntive matrix factorization clustering capabilities; appli-\\ncation on multivariate image segmentation. In 2009\\nInternational Conference on Complex, Intelligent and\\nSoftware Intensive Systems, pages 924–929. IEEE.\\nRonan Le Bras, Swabha Swayamdipta, Chandra Bha-\\ngavatula, Rowan Zellers, Matthew Peters, Ashish\\nSabharwal, and Yejin Choi. 2020. Adversarial fil-\\nters of dataset biases. In International conference on\\nmachine learning, pages 1078–1088. Pmlr.\\nGuillaume Lecué and Shahar Mendelson. 2018. Regu-\\nlarization and the small-ball method i: sparse recov-\\nery.\\nAlycia Lee, Brando Miranda, Sudharsan Sundar, and\\nSanmi Koyejo. 2023. Beyond scale: the diversity\\ncoefficient as a data quality metric demonstrates\\nllms are pre-trained on formally diverse data. arXiv\\npreprint arXiv:2306.13840.\\nDaniel Lee and H Sebastian Seung. 2000. Algorithms\\nfor non-negative matrix factorization. Advances in\\nneural information processing systems, 13.\\nKatherine Lee, Daphne Ippolito, Andrew Nystrom,\\nChiyuan Zhang, Douglas Eck, Chris Callison-Burch,\\nand Nicholas Carlini. 2021. Deduplicating training\\ndata makes language models better. arXiv preprint\\narXiv:2107.06499.\\nBohan Li, Yutai Hou, and Wanxiang Che. 2022. Data\\naugmentation approaches in natural language pro-\\ncessing: A survey. Ai Open, 3:71–90.\\nHaoran Li, Qingxiu Dong, Zhengyang Tang, Chaojun\\nWang, Xingxing Zhang, Haoyang Huang, Shaohan\\nHuang, Xiaolong Huang, Zeqiang Huang, Dongdong\\nZhang, et al. 2024a. Synthetic data (almost) from\\nscratch: Generalized instruction tuning for language\\nmodels. arXiv preprint arXiv:2402.13064.\\nJiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,\\nand Bill Dolan. 2015. A diversity-promoting objec-\\ntive function for neural conversation models. arXiv\\npreprint arXiv:1510.03055.\\nMing Li, Yong Zhang, Shwai He, Zhitao Li, Hongyu\\nZhao, Jianzong Wang, Ning Cheng, and Tianyi\\nZhou. 2024b. Superfiltering: Weak-to-strong data\\nfiltering for fast instruction-tuning. arXiv preprint\\narXiv:2402.00530.\\nMing Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang\\nChen, Ning Cheng, Jianzong Wang, Tianyi Zhou, and\\nJing Xiao. 2023a. From quantity to quality: Boosting\\nllm performance with self-guided data selection for\\ninstruction tuning. arXiv preprint arXiv:2308.12032.\\nNa Li, Yiyang Qi, Chaoran Li, and Zhiming Zhao.\\n2024c. Active learning for data quality control: A\\nsurvey. ACM Journal of Data and Information Qual-\\nity.\\nRaymond Li, Loubna Ben Allal, Yangtian Zi, Niklas\\nMuennighoff, Denis Kocetkov, Chenghao Mou, Marc\\nMarone, Christopher Akiki, Jia Li, Jenny Chim, et al.\\n2023b.\\nStarcoder: may the source be with you!\\narXiv preprint arXiv:2305.06161.\\nXian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke\\nZettlemoyer, Omer Levy, Jason Weston, and Mike\\nLewis. 2023c. Self-alignment with instruction back-\\ntranslation. arXiv preprint arXiv:2308.06259.\\nYize Li, Pu Zhao, Xue Lin, Bhavya Kailkhura, and\\nRyan Goldhahn. 2023d. Less is more: Data prun-\\ning for faster adversarial training. arXiv preprint\\narXiv:2302.12366.\\nYuchen Li, Ju Fan, Yanhao Wang, and Kian-Lee Tan.\\n2018. Influence maximization on social graphs: A\\nsurvey. IEEE Transactions on Knowledge and Data\\nEngineering, 30(10):1852–1872.\\nZhuoyan Li, Hangxiao Zhu, Zhuoran Lu, and Ming\\nYin. 2023e. Synthetic data generation with large\\nlanguage models for text classification: Potential and\\nlimitations. arXiv preprint arXiv:2310.07849.\\nPercy Liang, Rishi Bommasani, Tony Lee, Dimitris\\nTsipras, Dilara Soylu, Michihiro Yasunaga, Yian\\nZhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-\\nmar, et al. 2022. Holistic evaluation of language\\nmodels. arXiv preprint arXiv:2211.09110.\\nChin-Yew Lin. 2004. Rouge: A package for automatic\\nevaluation of summaries.\\nIn Text summarization\\nbranches out, pages 74–81.\\nJinkun Lin, Anqi Zhang, Mathias Lécuyer, Jinyang\\nLi, Aurojit Panda, and Siddhartha Sen. 2022. Mea-\\nsuring the effect of training data on deep learning\\npredictions via randomized experiments. In Inter-\\nnational Conference on Machine Learning, pages\\n13468–13504. PMLR.\\nStephanie Lin, Jacob Hilton, and Owain Evans. 2021.\\nTruthfulqa: Measuring how models mimic human\\nfalsehoods. arXiv preprint arXiv:2109.07958.\\nXinyu Lin, Wenjie Wang, Yongqi Li, Shuo Yang, Fuli\\nFeng, Yinwei Wei, and Tat-Seng Chua. 2024. Data-\\nefficient fine-tuning for llm-based recommendation.\\nPreprint, arXiv:2401.17197.\\nAlisa Liu, Xiaochuang Han, Yizhong Wang, Yulia\\nTsvetkov, Yejin Choi, and Noah A Smith. 2024a.\\nTuning language models by proxy. arXiv preprint\\narXiv:2401.08565.\\nFuxiao Liu, Xiaoyang Wang, Wenlin Yao, Jianshu Chen,\\nKaiqiang Song, Sangwoo Cho, Yaser Yacoob, and\\nDong Yu. 2023a.\\nMmc: Advancing multimodal\\nchart understanding with large-scale instruction tun-\\ning. arXiv preprint arXiv:2311.10774.\\nQingyi Liu, Yekun Chai, Shuohuan Wang, Yu Sun,\\nKeze Wang, and Hua Wu. 2024b.\\nOn training\\ndata influence of gpt models.\\narXiv preprint\\narXiv:2404.07840.\\nWei Liu, Weihao Zeng, Keqing He, Yong Jiang, and\\nJunxian He. 2023b.\\nWhat makes good data for\\nalignment?\\na comprehensive study of automatic\\ndata selection in instruction tuning. arXiv preprint\\narXiv:2312.15685.\\nXiaoyu Liu, Paiheng Xu, Junda Wu, Jiaxin Yuan, Yifan\\nYang, Yuhang Zhou, Fuxiao Liu, Tianrui Guan, Hao-\\nliang Wang, Tong Yu, et al. 2024c. Large language\\nmodels and causal inference in collaboration: A com-\\nprehensive survey. arXiv preprint arXiv:2403.09606.\\nYang Liu, Jiahuan Cao, Chongyu Liu, Kai Ding, and\\nLianwen Jin. 2024d. Datasets for large language\\nmodels: A comprehensive survey. arXiv preprint\\narXiv:2402.18041.\\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\\nRoberta: A robustly optimized bert pretraining ap-\\nproach. arXiv preprint arXiv:1907.11692.\\nZiche Liu, Rui Ke, Feng Jiang, and Haizhou Li. 2024e.\\nTake the essence and discard the dross: A rethink-\\ning on data selection for fine-tuning large language\\nmodels. arXiv preprint arXiv:2406.14115.\\nShayne Longpre, Le Hou, Tu Vu, Albert Webson,\\nHyung Won Chung, Yi Tay, Denny Zhou, Quoc V\\nLe, Barret Zoph, Jason Wei, et al. 2023. The flan\\ncollection: Designing data and methods for effective\\ninstruction tuning. In International Conference on\\nMachine Learning, pages 22631–22648. PMLR.\\nRenze Lou, Kai Zhang, and Wenpeng Yin. 2024. Large\\nlanguage model instruction following: A survey of\\nprogresses and challenges. Computational Linguis-\\ntics, pages 1–10.\\nKeming Lu, Hongyi Yuan, Zheng Yuan, Runji Lin, Jun-\\nyang Lin, Chuanqi Tan, Chang Zhou, and Jingren\\nZhou. 2023a. # instag: Instruction tagging for analyz-\\ning supervised fine-tuning of large language models.\\nIn The Twelfth International Conference on Learning\\nRepresentations.\\nYingzhou Lu, Minjie Shen, Huazheng Wang, Xiao\\nWang, Capucine van Rechem, and Wenqi Wei. 2023b.\\nMachine learning for synthetic data generation: a re-\\nview. arXiv preprint arXiv:2302.04062.\\nZhaosong Lu and Sanyou Mei. 2024. First-order penalty\\nmethods for bilevel optimization. SIAM Journal on\\nOptimization, 34(2):1937–1969.\\nChengcheng Ma, Yang Liu, Jiankang Deng, Lingxi\\nXie, Weiming Dong, and Changsheng Xu. 2023.\\nUnderstanding and mitigating overfitting in prompt\\ntuning for vision-language models. IEEE Transac-\\ntions on Circuits and Systems for Video Technology,\\n33(9):4616–4629.\\nInbal Magar and Roy Schwartz. 2022. Data contami-\\nnation: From memorization to exploitation. arXiv\\npreprint arXiv:2203.08242.\\nPratyush Maini, Saurabh Garg, Zachary Lipton, and\\nJ Zico Kolter. 2022. Characterizing datapoints via\\nsecond-split forgetting. Advances in Neural Informa-\\ntion Processing Systems, 35:30044–30057.\\nJyoti Malhotra and Jagdish Bakal. 2015. A survey and\\ncomparative study of data deduplication techniques.\\nIn 2015 International Conference on Pervasive Com-\\nputing (ICPC), pages 1–5. IEEE.\\nDavid Malvern, Brian Richards, Ngoni Chipere, and\\nPilar Durán. 2004. Lexical diversity and language\\ndevelopment. Springer.\\nDavid D Malvern and Brian J Richards. 1997. A new\\nmeasure of lexical diversity. British Studies in Ap-\\nplied Linguistics, 12:58–71.\\nMax Marion, Ahmet Üstün, Luiza Pozzobon, Alex\\nWang, Marzieh Fadaee, and Sara Hooker. 2023.\\nWhen less is more:\\nInvestigating data pruning\\nfor pretraining llms at scale.\\narXiv preprint\\narXiv:2309.04564.\\nMarc Marone and Benjamin Van Durme. 2024. Data\\nportraits: Recording foundation model training data.\\nAdvances in Neural Information Processing Systems,\\n36.\\nMichael Mathieu and Yann LeCun. 2014. Fast approx-\\nimation of rotations and hessians matrices. arXiv\\npreprint arXiv:1404.7195.\\nVladimir Matlach, Diego Krivochen, and Jiri Miliˇcka.\\n2021. A method for comparison of general sequences\\nvia type-token ratio. Language and Text: Data, mod-\\nels, information and applications. Amsterdam: John\\nBenjamins, pages 37–54.\\nPhilip M McCarthy. 2005. An assessment of the range\\nand usefulness of lexical diversity measures and the\\npotential of the measure of textual, lexical diversity\\n(MTLD). Ph.D. thesis, The University of Memphis.\\nPhilip M McCarthy and Scott Jarvis. 2010. Mtld, vocd-\\nd, and hd-d: A validation study of sophisticated ap-\\nproaches to lexical diversity assessment. Behavior\\nresearch methods, 42(2):381–392.\\nGábor Melis, Chris Dyer, and Phil Blunsom. 2017. On\\nthe state of the art of evaluation in neural language\\nmodels. arXiv preprint arXiv:1707.05589.\\nBrando Miranda, Patrick Yu, Yu-Xiong Wang, and\\nSanmi Koyejo. 2022. The curse of low task diver-\\nsity: On the failure of transfer learning to outperform\\nmaml and their empirical equivalence. arXiv preprint\\narXiv:2208.01545.\\nSwaroop Mishra,\\nAnjana Arunkumar,\\nBhavdeep\\nSachdeva, Chris Bryan, and Chitta Baral. 2020a. Dqi:\\nA guide to benchmark evaluation. arXiv preprint\\narXiv:2008.03964.\\nSwaroop Mishra,\\nAnjana Arunkumar,\\nBhavdeep\\nSachdeva, Chris Bryan, and Chitta Baral. 2020b.\\nDqi: Measuring data quality in nlp. arXiv preprint\\narXiv:2005.00816.\\nSwaroop Mishra and Bhavdeep Singh Sachdeva. 2020.\\nDo we need to create big datasets to learn a task?\\nIn Proceedings of SustaiNLP: Workshop on Simple\\nand Efficient Natural Language Processing, pages\\n169–173.\\nNiluthpol Chowdhury Mithun, Rameswar Panda, and\\nAmit K Roy-Chowdhury. 2019. Construction of di-\\nverse image datasets from web collections with lim-\\nited labeling. IEEE Transactions on Circuits and\\nSystems for Video Technology, 30(4):1147–1161.\\nSedir Mohammed, Hazar Harmouch, Felix Naumann,\\nand Divesh Srivastava. 2024. Data quality assess-\\nment: Challenges and opportunities. arXiv preprint\\narXiv:2403.00526.\\nRobert C Moore and William Lewis. 2010. Intelligent\\nselection of language model training data. In Pro-\\nceedings of the ACL 2010 conference short papers,\\npages 220–224.\\nDavid Mouillot and Alain Lepretre. 1999. A compar-\\nison of species diversity estimators. Researches on\\nPopulation Ecology, 41:203–215.\\nKevin P Murphy. 2012. Machine learning: a probabilis-\\ntic perspective. MIT press.\\nAidar Myrzakhan, Sondos Mahmoud Bsharat, and\\nZhiqiang Shen. 2024. Open-llm-leaderboard: From\\nmulti-choice to open-style questions for llms eval-\\nuation, benchmark, and arena.\\narXiv preprint\\narXiv:2406.07545.\\nNagarajan Natarajan, Inderjit S Dhillon, Pradeep K\\nRavikumar, and Ambuj Tewari. 2013. Learning with\\nnoisy labels. Advances in neural information pro-\\ncessing systems, 26.\\nNoel Ngu, Nathaniel Lee, and Paulo Shakarian. 2024.\\nDiversity measures: Domain-independent proxies for\\nfailure in language model queries. In 2024 IEEE 18th\\nInternational Conference on Semantic Computing\\n(ICSC), pages 176–182. IEEE.\\nCuong V Nguyen, Alessandro Achille, Michael Lam,\\nTal Hassner, Vijay Mahadevan, and Stefano Soatto.\\n2019.\\nToward understanding catastrophic for-\\ngetting in continual learning.\\narXiv preprint\\narXiv:1908.01091.\\nQuan Nguyen and Adji Bousso Dieng. 2024. Quality-\\nweighted vendi scores and their application to\\ndiverse experimental design.\\narXiv preprint\\narXiv:2405.02449.\\nVu-Linh Nguyen, Mohammad Hossein Shaker, and\\nEyke Hüllermeier. 2022. How to measure uncertainty\\nin uncertainty sampling for active learning. Machine\\nLearning, 111(1):89–122.\\nYixin Nie, Adina Williams, Emily Dinan, Mohit Bansal,\\nJason Weston, and Douwe Kiela. 2019. Adversarial\\nnli: A new benchmark for natural language under-\\nstanding. arXiv preprint arXiv:1910.14599.\\nBjörn Nieth, Thomas Altstidl, Leo Schwinn, and Björn\\nEskofier. 2024. Large-scale dataset pruning in adver-\\nsarial training through data importance extrapolation.\\narXiv preprint arXiv:2406.13283.\\nGeir K Nilsen, Antonella Z Munthe-Kaas, Hans J\\nSkaug, and Morten Brun. 2019. Efficient computa-\\ntion of hessian matrices in tensorflow. arXiv preprint\\narXiv:1905.05559.\\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\\n2022. Training language models to follow instruc-\\ntions with human feedback. Advances in neural in-\\nformation processing systems, 35:27730–27744.\\nRui Pan, Jipeng Zhang, Xingyuan Pan, Renjie Pi, Xi-\\naoyu Wang, and Tong Zhang. 2024. Scalebio: Scal-\\nable bilevel optimization for llm data reweighting.\\narXiv preprint arXiv:2406.19976.\\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\\nJing Zhu. 2002. Bleu: a method for automatic evalu-\\nation of machine translation. In Proceedings of the\\n40th annual meeting of the Association for Computa-\\ntional Linguistics, pages 311–318.\\nSung Min Park, Kristian Georgiev, Andrew Ilyas, Guil-\\nlaume Leclerc, and Aleksander Madry. 2023. Trak:\\nAttributing model behavior at scale. arXiv preprint\\narXiv:2303.14186.\\nJupinder Parmar, Sanjev Satheesh, Mostofa Patwary,\\nMohammad Shoeybi, and Bryan Catanzaro. 2024.\\nReuse, don’t retrain: A recipe for continued pre-\\ntraining of language models.\\narXiv preprint\\narXiv:2407.07263.\\nAmey Pasarkar and Adji Bousso Dieng. 2023. Cousins\\nof the vendi score: A family of similarity-based diver-\\nsity metrics for science and machine learning. arXiv\\npreprint arXiv:2310.12952.\\nKeiran Paster, Marco Dos Santos, Zhangir Azerbayev,\\nand Jimmy Ba. 2023.\\nOpenwebmath: An open\\ndataset of high-quality mathematical web text. arXiv\\npreprint arXiv:2310.06786.\\nArkil Patel, Satwik Bhattamishra, and Navin Goyal.\\n2021.\\nAre nlp models really able to solve\\nsimple math word problems?\\narXiv preprint\\narXiv:2103.07191.\\nLeena H Patil and Mohammed Atique. 2013. A novel\\napproach for feature selection method tf-idf in doc-\\nument clustering. In 2013 3rd IEEE international\\nadvance computing conference (IACC), pages 858–\\n862. IEEE.\\nMansheej Paul, Surya Ganguli, and Gintare Karolina\\nDziugaite. 2021. Deep learning on a data diet: Find-\\ning important examples early in training. Advances\\nin neural information processing systems, 34:20596–\\n20607.\\nBarak A. Pearlmutter. 1994. Fast exact multiplication\\nby the hessian. Neural Computation, 6(1):147–160.\\nRobert K Peet. 1974. The measurement of species di-\\nversity. Annual review of ecology and systematics,\\npages 285–307.\\nGuilherme Penedo, Quentin Malartic, Daniel Hesslow,\\nRuxandra Cojocaru, Alessandro Cappelli, Hamza\\nAlobeidli, Baptiste Pannier, Ebtesam Almazrouei,\\nand Julien Launay. 2023. The refinedweb dataset\\nfor falcon llm: outperforming curated corpora with\\nweb data, and web data only.\\narXiv preprint\\narXiv:2306.01116.\\nBaolin Peng, Chunyuan Li, Pengcheng He, Michel Gal-\\nley, and Jianfeng Gao. 2023. Instruction tuning with\\ngpt-4. arXiv preprint arXiv:2304.03277.\\nLeif E Peterson. 2009. K-nearest neighbor. Scholarpe-\\ndia, 4(2):1883.\\nAgustin Picard, Lucas Hervier, Thomas Fel, and David\\nVigouroux. 2024. Influenciæ: A library for tracing\\nthe influence back to the data-points. In World Con-\\nference on Explainable Artificial Intelligence, pages\\n193–204. Springer.\\nMaria Priestley, Fionntán O’donnell, and Elena Simperl.\\n2023. A survey of data quality requirements that\\nmatter in ml development pipelines. ACM Journal of\\nData and Information Quality, 15(2):1–39.\\nGarima Pruthi, Frederick Liu, Satyen Kale, and Mukund\\nSundararajan. 2020. Estimating training data influ-\\nence by tracing gradient descent. Advances in Neural\\nInformation Processing Systems, 33:19920–19930.\\nYulei Qin, Xingyu Chen, Yunhang Shen, Chaoyou\\nFu, Yun Gu, Ke Li, Xing Sun, and Rongrong Ji.\\n2024. Capro: webly supervised learning with cross-\\nmodality aligned prototypes. Advances in Neural\\nInformation Processing Systems, 36.\\nAlec Radford, Karthik Narasimhan, Tim Salimans, Ilya\\nSutskever, et al. 2018. Improving language under-\\nstanding by generative pre-training.\\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\\nDario Amodei, Ilya Sutskever, et al. 2019. Language\\nmodels are unsupervised multitask learners. OpenAI\\nblog, 1(8):9.\\nJack W Rae, Sebastian Borgeaud, Trevor Cai, Katie\\nMillican, Jordan Hoffmann, Francis Song, John\\nAslanides, Sarah Henderson, Roman Ring, Susan-\\nnah Young, et al. 2021. Scaling language models:\\nMethods, analysis & insights from training gopher.\\narXiv preprint arXiv:2112.11446.\\nRafael Rafailov, Archit Sharma, Eric Mitchell, Christo-\\npher D Manning, Stefano Ermon, and Chelsea Finn.\\n2024. Direct preference optimization: Your language\\nmodel is secretly a reward model. Advances in Neu-\\nral Information Processing Systems, 36.\\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\\nWei Li, and Peter J Liu. 2020. Exploring the lim-\\nits of transfer learning with a unified text-to-text\\ntransformer. Journal of machine learning research,\\n21(140):1–67.\\nK Raghuveer et al. 2012. Legal documents clustering\\nusing latent dirichlet allocation. IAES Int. J. Artif.\\nIntell, 2(1):34–37.\\nXingcheng Ran, Yue Xi, Yonggang Lu, Xiangwen\\nWang, and Zhenyu Lu. 2023. Comprehensive sur-\\nvey on hierarchical clustering algorithms and the re-\\ncent developments. Artificial Intelligence Review,\\n56(8):8219–8264.\\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\\nSentence embeddings using siamese bert-networks.\\narXiv preprint arXiv:1908.10084.\\nAlfréd Rényi. 1961. On measures of entropy and in-\\nformation. In Proceedings of the fourth Berkeley\\nsymposium on mathematical statistics and probabil-\\nity, volume 1: contributions to the theory of statistics,\\nvolume 4, pages 547–562. University of California\\nPress.\\nHamed Rezazadegan Tavakoli, Esa Rahtu, and Janne\\nHeikkilä. 2011. Fast and efficient saliency detection\\nusing sparse sampling and kernel density estimation.\\nIn Image Analysis: 17th Scandinavian Conference,\\nSCIA 2011, Ystad, Sweden, May 2011. Proceedings\\n17, pages 666–675. Springer.\\nMarco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin,\\nand Sameer Singh. 2020. Beyond accuracy: Behav-\\nioral testing of nlp models with checklist.\\narXiv\\npreprint arXiv:2005.04118.\\nBrian Richards. 1987. Type/token ratios: What do they\\nreally tell us? Journal of child language, 14(2):201–\\n209.\\nYuji Roh, Geon Heo, and Steven Euijong Whang.\\n2019. A survey on data collection for machine learn-\\ning: a big data-ai integration perspective.\\nIEEE\\nTransactions on Knowledge and Data Engineering,\\n33(4):1328–1347.\\nRajendra Kumar Roul, Omanwar Rohit Devanand, and\\nSanjay Kumar Sahay. 2014. Web document cluster-\\ning and ranking using tf-idf based apriori approach.\\narXiv preprint arXiv:1406.5617.\\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavat-\\nula, and Yejin Choi. 2021. Winogrande: An adver-\\nsarial winograd schema challenge at scale. Commu-\\nnications of the ACM, 64(9):99–106.\\nVictor Sanh, Albert Webson, Colin Raffel, Stephen H\\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\\nChaffin, Arnaud Stiegler, Teven Le Scao, Arun\\nRaja, et al. 2021. Multitask prompted training en-\\nables zero-shot task generalization. arXiv preprint\\narXiv:2110.08207.\\nGayathri Saranathan, Mahammad Parwez Alam, James\\nLim, Suparna Bhattacharya, Soon Yee Wong, Martin\\nFoltin, and Cong Xu. Dele: Data efficient llm eval-\\nuation. In ICLR 2024 Workshop on Navigating and\\nAddressing Data Problems for Foundation Models.\\nNikunj Saunshi, Arushi Gupta, Mark Braverman, and\\nSanjeev Arora. 2022. Understanding influence func-\\ntions and datamodels via harmonic analysis. In The\\nEleventh International Conference on Learning Rep-\\nresentations.\\nTimo Schick and Hinrich Schütze. 2020. It’s not just\\nsize that matters: Small language models are also\\nfew-shot learners. arXiv preprint arXiv:2009.07118.\\nAndrea Schioppa, Polina Zablotskaia, David Vilar, and\\nArtem Sokolov. 2021. Scaling up influence functions.\\nPreprint, arXiv:2112.03052.\\nStephanie Schoch, Ritwick Mishra, and Yangfeng Ji.\\n2023. Data selection for fine-tuning large language\\nmodels using transferred shapley values.\\narXiv\\npreprint arXiv:2306.10165.\\nSarah E Schwarm and Mari Ostendorf. 2005. Reading\\nlevel assessment using support vector machines and\\nstatistical language models. In Proceedings of the\\n43rd annual meeting of the Association for Computa-\\ntional Linguistics (ACL’05), pages 523–530.\\nOzan Sener and Silvio Savarese. 2017. Active learn-\\ning for convolutional neural networks: A core-set\\napproach. arXiv preprint arXiv:1708.00489.\\nBurr Settles. 1995. Active learning literature survey.\\nScience, 10(3):237–304.\\nBurr Settles. 2011. From theories to queries: Active\\nlearning in practice. In Active learning and experi-\\nmental design workshop in conjunction with AISTATS\\n2010, pages 1–18. JMLR Workshop and Conference\\nProceedings.\\nClaude Elwood Shannon. 1948. A mathematical theory\\nof communication. The Bell system technical journal,\\n27(3):379–423.\\nClaude Elwood Shannon. 2001. A mathematical the-\\nory of communication. ACM SIGMOBILE mobile\\ncomputing and communications review, 5(1):3–55.\\nYunfan Shao, Linyang Li, Zhaoye Fei, Hang Yan, Dahua\\nLin, and Xipeng Qiu. 2024. Balanced data sampling\\nfor language model training with clustering. arXiv\\npreprint arXiv:2402.14526.\\nBin Shen and Luo Si. 2010. Non-negative matrix factor-\\nization clustering on multiple manifolds. In Proceed-\\nings of the AAAI Conference on Artificial Intelligence,\\nvolume 24, pages 575–580.\\nJonathan Richard Shewchuk et al. 1994. An introduc-\\ntion to the conjugate gradient method without the\\nagonizing pain.\\nZhengxiang Shi and Aldo Lipani. 2023. Don’t stop pre-\\ntraining? make prompt-based fine-tuning powerful\\nlearner. Advances in Neural Information Processing\\nSystems, 36:5827–5849.\\nZhengyan Shi, Adam X Yang, Bin Wu, Laurence Aitchi-\\nson, Emine Yilmaz, and Aldo Lipani. 2024. Instruc-\\ntion tuning with loss over instructions. arXiv preprint\\narXiv:2405.14394.\\nManli Shu, Jiongxiao Wang, Chen Zhu, Jonas Geiping,\\nChaowei Xiao, and Tom Goldstein. 2023. On the ex-\\nploitability of instruction tuning. Advances in Neural\\nInformation Processing Systems, 36:61836–61856.\\nRaphael Shu, Hideki Nakayama, and Kyunghyun Cho.\\n2019. Generating diverse translations with sentence\\ncodes. In Proceedings of the 57th annual meeting of\\nthe association for computational linguistics, pages\\n1823–1827.\\nLuo Si and Jamie Callan. 2001. A statistical model\\nfor scientific readability. In Proceedings of the tenth\\ninternational conference on Information and knowl-\\nedge management, pages 574–576.\\nAditya Siddhant and Zachary C Lipton. 2018. Deep\\nbayesian active learning for natural language process-\\ning: Results of a large-scale empirical study. arXiv\\npreprint arXiv:1808.05697.\\nFatimah Sidi, Payam Hassany Shariat Panahy, Lilly Suri-\\nani Affendey, Marzanah A Jabar, Hamidah Ibrahim,\\nand Aida Mustapha. 2012. Data quality: A survey\\nof data quality dimensions. In 2012 International\\nConference on Information Retrieval & Knowledge\\nManagement, pages 300–304. IEEE.\\nStacy Silverman and Nan Bernstein Ratner. 2002. Mea-\\nsuring lexical diversity in children who stutter: Ap-\\nplication of vocd.\\nJournal of fluency disorders,\\n27(4):289–304.\\nEdward H Simpson. 1949. Measurement of diversity.\\nnature, 163(4148):688–688.\\nKristina P Sinaga and Miin-Shen Yang. 2020. Unsu-\\npervised k-means clustering algorithm. IEEE access,\\n8:80716–80727.\\nAnkur Sinha, Pekka Malo, and Kalyanmoy Deb. 2017.\\nA review on bilevel optimization: From classical\\nto evolutionary approaches and applications. IEEE\\ntransactions on evolutionary computation, 22(2):276–\\n295.\\nSamarth Sinha, Han Zhang, Anirudh Goyal, Yoshua\\nBengio, Hugo Larochelle, and Augustus Odena. 2020.\\nSmall-gan: Speeding up gan training using core-sets.\\nIn International Conference on Machine Learning,\\npages 9005–9015. PMLR.\\nJohn Smith and Lisa Johnson. 2020.\\nStrategies for\\ndifficulty sampling providing diversity in datasets.\\nJournal of Machine Learning Research, 10:100–120.\\nHwanjun Song, Minseok Kim, Dongmin Park, Yooju\\nShin, and Jae-Gil Lee. 2022. Learning from noisy\\nlabels with deep neural networks: A survey. IEEE\\ntransactions on neural networks and learning sys-\\ntems, 34(11):8135–8153.\\nBen Sorscher, Robert Geirhos, Shashank Shekhar, Surya\\nGanguli, and Ari Morcos. 2022. Beyond neural scal-\\ning laws: beating power law scaling via data pruning.\\nAdvances in Neural Information Processing Systems,\\n35:19523–19536.\\nKaren Sparck Jones. 1972. A statistical interpretation\\nof term specificity and its application in retrieval.\\nJournal of documentation, 28(1):11–21.\\nEleftherios Spyromitros-Xioufis, Symeon Papadopou-\\nlos, Alexandru Lucian Ginsca, Adrian Popescu, Yian-\\nnis Kompatsiaris, and Ioannis Vlahavas. 2015. Im-\\nproving diversity in image search via supervised rel-\\nevance scoring. In Proceedings of the 5th ACM on\\nInternational Conference on Multimedia Retrieval,\\npages 323–330.\\nKatherine Stasaski and Marti A Hearst. 2022. Semantic\\ndiversity in dialogue with natural language inference.\\narXiv preprint arXiv:2205.01497.\\nKatherine Stasaski, Grace Hui Yang, and Marti A Hearst.\\n2020. More diverse dialogue datasets via diversity-\\ninformed data collection. In Proceedings of the 58th\\nannual meeting of the association for computational\\nlinguistics, pages 4958–4968.\\nAlbert Yu Sun, Eliott Zemour, Arushi Saxena, Udith\\nVaidyanathan, Eric Lin, Christian Lau, and Vaikkunth\\nMugunthan. 2023. Does fine-tuning gpt-3 with the\\nopenai api leak personally-identifiable information?\\narXiv preprint arXiv:2307.16382.\\nPeng Sun, Bei Shi, Daiwei Yu, and Tao Lin. 2024a. On\\nthe diversity and realism of distilled dataset: An effi-\\ncient dataset distillation paradigm. In Proceedings of\\nthe IEEE/CVF Conference on Computer Vision and\\nPattern Recognition, pages 9390–9399.\\nWangtao Sun, Haotian Xu, Xuanqing Yu, Pei Chen,\\nShizhu He, Jun Zhao, and Kang Liu. 2024b.\\nItd:\\nLarge language models can teach them-\\nselves induction through deduction. arXiv preprint\\narXiv:2403.05789.\\nJun Suzuki, Heiga Zen, and Hideto Kazawa. 2023. Ex-\\ntracting representative subset from extensive text data\\nfor training pre-trained language models. Informa-\\ntion Processing & Management, 60(3):103249.\\nLuis Talavera. 1999. Feature selection as a preprocess-\\ning step for hierarchical clustering. In ICML, vol-\\nume 99, pages 389–397.\\nHaoru Tan, Sitong Wu, Fei Du, Yukang Chen, Zhibin\\nWang, Fan Wang, and Xiaojuan Qi. 2024a. Data\\npruning via moving-one-sample-out. Advances in\\nNeural Information Processing Systems, 36.\\nJiejun Tan, Zhicheng Dou, Yutao Zhu, Peidong Guo,\\nKun Fang, and Ji-Rong Wen. 2024b. Small models,\\nbig insights: Leveraging slim proxy models to decide\\nwhen and what to retrieve for llms. arXiv preprint\\narXiv:2402.12052.\\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\\nDubois, Xuechen Li, Carlos Guestrin, Percy Liang,\\nand Tatsunori B Hashimoto. 2023.\\nAlpaca: A\\nstrong, replicable instruction-following model. Stan-\\nford Center for Research on Foundation Models.\\nhttps://crfm. stanford. edu/2023/03/13/alpaca. html,\\n3(6):7.\\nMosaicML NLP Team. 2023. Introducing mpt-7b: A\\nnew standard for open-source, commercially usable\\nllms. Accessed: 2023-05-05.\\nMildred C Templin. 1957. Certain language skills in\\nchildren; their development and interrelationships.\\nUniversity of Minnesota Press.\\nGuy Tevet and Jonathan Berant. 2020. Evaluating the\\nevaluation of diversity in natural language generation.\\narXiv preprint arXiv:2004.02990.\\nSteve Tingiris and Bret Kinsella. 2021. Exploring GPT-\\n3: An unofficial first look at the general-purpose\\nlanguage processing API from OpenAI. Packt Pub-\\nlishing Ltd.\\nKushal Tirumala, Aram Markosyan, Luke Zettlemoyer,\\nand Armen Aghajanyan. 2022. Memorization with-\\nout overfitting: Analyzing the training dynamics of\\nlarge language models. Advances in Neural Informa-\\ntion Processing Systems, 35:38274–38290.\\nKushal Tirumala, Daniel Simig, Armen Aghajanyan,\\nand Ari Morcos. 2024. D4: Improving llm pretrain-\\ning via document de-duplication and diversification.\\nAdvances in Neural Information Processing Systems,\\n36.\\nMariya Toneva, Alessandro Sordoni, Remi Tachet des\\nCombes, Adam Trischler, Yoshua Bengio, and Geof-\\nfrey J Gordon. 2018. An empirical study of exam-\\nple forgetting during deep neural network learning.\\narXiv preprint arXiv:1812.05159.\\nSimon Tong and Daphne Koller. 2001. Support vec-\\ntor machine active learning with applications to text\\nclassification. Journal of machine learning research,\\n2(Nov):45–66.\\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\\nMartinet, Marie-Anne Lachaux, Timothée Lacroix,\\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal\\nAzhar, et al. 2023a.\\nLlama:\\nOpen and effi-\\ncient foundation language models. arXiv preprint\\narXiv:2302.13971.\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\\nBhosale, et al. 2023b.\\nLlama 2: Open founda-\\ntion and fine-tuned chat models.\\narXiv preprint\\narXiv:2307.09288.\\nKarina Vidal and Scott Jarvis. 2020. Effects of english-\\nmedium instruction on spanish students’ proficiency\\nand lexical diversity in english. Language Teaching\\nResearch, 24(5):568–587.\\nUlrike Von Luxburg. 2007. A tutorial on spectral clus-\\ntering. Statistics and computing, 17:395–416.\\nChi Wang, Qingyun Wu, Silu Huang, and Amin Saied.\\n2021a. Economic hyperparameter optimization with\\nblended search strategy. In International Conference\\non Learning Representations.\\nChi Wang, Qingyun Wu, Markus Weimer, and Erkang\\nZhu. 2021b. Flaml: A fast and lightweight automl\\nlibrary. Proceedings of Machine Learning and Sys-\\ntems, 3:434–447.\\nJiahao Wang, Bolin Zhang, Qianlong Du, Jiajun Zhang,\\nand Dianhui Chu. 2024a.\\nA survey on data se-\\nlection for llm instruction tuning. arXiv preprint\\narXiv:2402.05123.\\nLingzhi Wang, Xingshan Zeng, Jinsong Guo, Kam-Fai\\nWong, and Georg Gottlob. 2024b.\\nSelective for-\\ngetting: Advancing machine unlearning techniques\\nand evaluation in language models. arXiv preprint\\narXiv:2402.05813.\\nYidong Wang, Zhuohao Yu, Zhengran Zeng, Linyi\\nYang, Cunxiang Wang, Hao Chen, Chaoya Jiang,\\nRui Xie, Jindong Wang, Xing Xie, et al. 2023a.\\nPandalm: An automatic evaluation benchmark for\\nllm instruction tuning optimization. arXiv preprint\\narXiv:2306.05087.\\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Al-\\nisa Liu, Noah A Smith, Daniel Khashabi, and Han-\\nnaneh Hajishirzi. 2022. Self-instruct: Aligning lan-\\nguage models with self-generated instructions. arXiv\\npreprint arXiv:2212.10560.\\nYu-Xiong Wang and Yu-Jin Zhang. 2012. Nonnegative\\nmatrix factorization: A comprehensive review. IEEE\\nTransactions on knowledge and data engineering,\\n25(6):1336–1353.\\nYufei Wang, Wanjun Zhong, Liangyou Li, Fei Mi, Xing-\\nshan Zeng, Wenyong Huang, Lifeng Shang, Xin\\nJiang, and Qun Liu. 2023b.\\nAligning large lan-\\nguage models with human: A survey. arXiv preprint\\narXiv:2307.12966.\\nYulin Wang, Gao Huang, Shiji Song, Xuran Pan, Yi-\\ntong Xia, and Cheng Wu. 2021c. Regularizing deep\\nnetworks with semantic data augmentation. IEEE\\nTransactions on Pattern Analysis and Machine Intel-\\nligence, 44(7):3733–3748.\\nJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin\\nGuu, Adams Wei Yu, Brian Lester, Nan Du, An-\\ndrew M Dai, and Quoc V Le. 2021. Finetuned lan-\\nguage models are zero-shot learners. arXiv preprint\\narXiv:2109.01652.\\nMax Welling. 2009. Herding dynamical weights to\\nlearn. In Proceedings of the 26th annual interna-\\ntional conference on machine learning, pages 1121–\\n1128.\\nAlexander Wettig, Aatmik Gupta, Saumya Malik, and\\nDanqi Chen. 2024. Qurating: Selecting high-quality\\ndata for training language models. arXiv preprint\\narXiv:2402.09739.\\nSvante Wold, Kim Esbensen, and Paul Geladi. 1987.\\nPrincipal component analysis. Chemometrics and\\nintelligent laboratory systems, 2(1-3):37–52.\\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\\nChaumond, Clement Delangue, Anthony Moi, Pier-\\nric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,\\net al. 2019. Huggingface’s transformers: State-of-\\nthe-art natural language processing. arXiv preprint\\narXiv:1910.03771.\\nHaolun Wu, Yansen Zhang, Chen Ma, Fuyuan Lyu, Fer-\\nnando Diaz, and Xue Liu. 2022. A survey of diver-\\nsification techniques in search and recommendation.\\nCoRR arXiv, 2212.\\nHaolun Wu, Yansen Zhang, Chen Ma, Fuyuan Lyu,\\nBowei He, Bhaskar Mitra, and Xue Liu. 2024. Re-\\nsult diversification in search and recommendation: A\\nsurvey. IEEE Transactions on Knowledge and Data\\nEngineering.\\nShengguang Wu, Keming Lu, Benfeng Xu, Junyang Lin,\\nQi Su, and Chang Zhou. 2023. Self-evolved diverse\\ndata sampling for efficient instruction tuning. arXiv\\npreprint arXiv:2311.08182.\\nMengzhou Xia, Tianyu Gao, Zhiyuan Zeng, and Danqi\\nChen. 2023. Sheared llama: Accelerating language\\nmodel pre-training via structured pruning.\\narXiv\\npreprint arXiv:2310.06694.\\nMengzhou Xia, Sadhika Malladi, Suchin Gururangan,\\nSanjeev Arora, and Danqi Chen. 2024a. Less: Se-\\nlecting influential data for targeted instruction tuning.\\narXiv preprint arXiv:2402.04333.\\nXiaobo Xia, Jiale Liu, Jun Yu, Xu Shen, Bo Han, and\\nTongliang Liu. 2022. Moderate coreset: A universal\\nmethod of data selection for real-world data-efficient\\ndeep learning. In The Eleventh International Confer-\\nence on Learning Representations.\\nXiaobo Xia, Jiale Liu, Shaokun Zhang, Qingyun Wu,\\nHongxin Wei, and Tongliang Liu. 2024b. Refined\\ncoreset selection: Towards minimal coreset size un-\\nder model performance constraints. In Forty-first\\nInternational Conference on Machine Learning.\\nQizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, and\\nQuoc Le. 2020. Unsupervised data augmentation for\\nconsistency training. Advances in neural information\\nprocessing systems, 33:6256–6268.\\nSang Michael Xie, Aditi Raghunathan, Percy Liang, and\\nTengyu Ma. 2021. An explanation of in-context learn-\\ning as implicit bayesian inference. arXiv preprint\\narXiv:2111.02080.\\nSang Michael Xie, Shibani Santurkar, Tengyu Ma, and\\nPercy S Liang. 2023. Data selection for language\\nmodels via importance resampling.\\nAdvances in\\nNeural Information Processing Systems, 36:34201–\\n34227.\\nCan Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,\\nPu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin\\nJiang. 2023a.\\nWizardlm: Empowering large lan-\\nguage models to follow complex instructions. arXiv\\npreprint arXiv:2304.12244.\\nFrank F Xu, Uri Alon, Graham Neubig, and Vincent Jo-\\nsua Hellendoorn. 2022. A systematic evaluation of\\nlarge language models of code. In Proceedings of\\nthe 6th ACM SIGPLAN International Symposium on\\nMachine Programming, pages 1–10.\\nYang Xu, Yongqiang Yao, Yufan Huang, Mengnan\\nQi, Maoquan Wang, Bin Gu, and Neel Sundaresan.\\n2023b. Rethinking the instruction quality: Lift is\\nwhat you need. arXiv preprint arXiv:2312.11508.\\nZhangchen Xu, Fengqing Jiang, Luyao Niu, Yun-\\ntian Deng, Radha Poovendran, Yejin Choi, and\\nBill Yuchen Lin. 2024. Magpie: Alignment data\\nsynthesis from scratch by prompting aligned llms\\nwith nothing. arXiv preprint arXiv:2406.08464.\\nAn Yang, Baosong Yang, Binyuan Hui, Bo Zheng,\\nBowen Yu, Chang Zhou, Chengpeng Li, Chengyuan\\nLi, Dayiheng Liu, Fei Huang, et al. 2024. Qwen2\\ntechnical report. arXiv preprint arXiv:2407.10671.\\nYaoqing Yang, Ryan Theisen, Liam Hodgkinson,\\nJoseph E Gonzalez, Kannan Ramchandran, Charles H\\nMartin, and Michael W Mahoney. 2022. Evaluating\\nnatural language processing models with generaliza-\\ntion metrics that do not need access to any training\\nor testing data. arXiv preprint arXiv:2202.02842.\\nEmmanuel J Yannakoudakis and David Fawthrop. 1983.\\nThe rules of spelling errors. Information Processing\\n& Management, 19(2):87–99.\\nGregory Yauney, Emily Reif, and David Mimno.\\n2023.\\nData similarity is not enough to explain\\nlanguage model performance.\\narXiv preprint\\narXiv:2311.09006.\\nJingwen Ye, Ruonan Yu, Songhua Liu, and Xinchao\\nWang. 2024. Distilled datamodel with reverse gra-\\ndient matching. In Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recog-\\nnition, pages 11954–11963.\\nÇa˘gatay Yıldız, Nishaanth Kanna Ravichandran, Pr-\\nishruit Punia, Matthias Bethge, and Beyza Ermis.\\n2024. Investigating continual pretraining in large\\nlanguage models: Insights and implications. arXiv\\npreprint arXiv:2402.17400.\\nJulio Christian Young and Makoto Shishido. 2023. In-\\nvestigating openai’s chatgpt potentials in generating\\nchatbot’s dialogue for english as a foreign language\\nlearning. International journal of advanced com-\\nputer science and applications, 14(6).\\nZichun Yu, Spandan Das, and Chenyan Xiong. 2024.\\nMates: Model-aware data selection for efficient pre-\\ntraining with data influence models. arXiv preprint\\narXiv:2406.06046.\\nBeverly L Zakaluk and S Jay Samuels. 1988. Readabil-\\nity: Its Past, Present, and Future. ERIC.\\nZhiyuan Zeng, Jiatong Yu, Tianyu Gao, Yu Meng, Tanya\\nGoyal, and Danqi Chen. 2023.\\nEvaluating large\\nlanguage models at evaluating instruction following.\\narXiv preprint arXiv:2310.07641.\\nDaochen Zha, Zaid Pervaiz Bhat, Kwei-Herng Lai, Fan\\nYang, Zhimeng Jiang, Shaochen Zhong, and Xia Hu.\\n2023. Data-centric artificial intelligence: A survey.\\narXiv preprint arXiv:2303.10158.\\nChiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin\\nRecht, and Oriol Vinyals. 2021.\\nUnderstanding\\ndeep learning (still) requires rethinking generaliza-\\ntion. Communications of the ACM, 64(3):107–115.\\nChiyuan Zhang, Daphne Ippolito, Katherine Lee,\\nMatthew Jagielski, Florian Tramèr, and Nicholas Car-\\nlini. 2023a. Counterfactual memorization in neural\\nlanguage models. Advances in Neural Information\\nProcessing Systems, 36:39321–39362.\\nJipeng Zhang, Yaxuan Qin, Renjie Pi, Weizhong\\nZhang, Rui Pan, and Tong Zhang. 2024a.\\nTag-\\ncos: Task-agnostic gradient clustered coreset se-\\nlection for instruction tuning data. arXiv preprint\\narXiv:2407.15235.\\nLei Zhang. 2024. Bilevel optimization in the deep learn-\\ning era: Methods and applications.\\nShaokun Zhang, Xiaobo Xia, Zhaoqing Wang, Ling-\\nHao Chen, Jiale Liu, Qingyun Wu, and Tongliang\\nLiu. 2023b. Ideal: Influence-driven selective annota-\\ntions empower in-context learners in large language\\nmodels. arXiv preprint arXiv:2310.10873.\\nShengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang,\\nXiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tian-\\nwei Zhang, Fei Wu, et al. 2023c. Instruction tuning\\nfor large language models: A survey. arXiv preprint\\narXiv:2308.10792.\\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q\\nWeinberger, and Yoav Artzi. 2019. Bertscore: Eval-\\nuating text generation with bert.\\narXiv preprint\\narXiv:1904.09675.\\nXiao Zhang and Ji Wu. 2024. Dissecting learning and\\nforgetting in language model finetuning.\\nIn The\\nTwelfth International Conference on Learning Repre-\\nsentations.\\nXiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou,\\nYipeng Zhang, Haitao Mi, and Helen Meng. 2024b.\\nSelf-tuning: Instructing llms to effectively acquire\\nnew knowledge through self-teaching. arXiv preprint\\narXiv:2406.06326.\\nYifan Zhang, Yifan Luo, Yang Yuan, and Andrew C\\nYao. 2024c. Autonomous data selection with lan-\\nguage models for mathematical texts. In ICLR 2024\\nWorkshop on Navigating and Addressing Data Prob-\\nlems for Foundation Models.\\nYihua Zhang, Yuguang Yao, Parikshit Ram, Pu Zhao,\\nTianlong Chen, Mingyi Hong, Yanzhi Wang, and\\nSijia Liu. 2022. Advancing model pruning via bi-\\nlevel optimization. Advances in Neural Information\\nProcessing Systems, 35:18309–18326.\\nBo Zhao and Hakan Bilen. 2023. Dataset condensa-\\ntion with distribution matching. In Proceedings of\\nthe IEEE/CVF Winter Conference on Applications of\\nComputer Vision, pages 6514–6523.\\nBo Zhao, Konda Reddy Mopuri, and Hakan Bilen.\\n2020a. Dataset condensation with gradient matching.\\narXiv preprint arXiv:2006.05929.\\nBo Zhao, Konda Reddy Mopuri, and Hakan Bilen.\\n2021. Dataset condensation with gradient matching.\\nPreprint, arXiv:2006.05929.\\nChenyang Zhao, Xueying Jia, Vijay Viswanathan,\\nTongshuang Wu,\\nand Graham Neubig. 2024a.\\nSelf-guide: Better task-specific instruction follow-\\ning via self-synthetic finetuning.\\narXiv preprint\\narXiv:2407.12874.\\nDora Zhao, Jerone TA Andrews, Orestis Papakyri-\\nakopoulos, and Alice Xiang. 2024b. Position: Mea-\\nsure dataset diversity, don’t just claim it.\\narXiv\\npreprint arXiv:2407.08188.\\nDorothy Zhao,\\nJerone TA Andrews,\\nAI Sony,\\nTokyo Orestis Papakyriakopoulos, and Alice Xiang.\\n2024c. Measuring diversity in datasets. Interna-\\ntional Conference on Learning Representations.\\nShanshan Zhao, Mingming Gong, Tongliang Liu, Huan\\nFu, and Dacheng Tao. 2020b. Domain generaliza-\\ntion via entropy regularization. Advances in neural\\ninformation processing systems, 33:16096–16107.\\nShuaijiang Zhao and Xiaoquan Fang. 2024. Technical\\nreport: Competition solution for bettermixture. arXiv\\npreprint arXiv:2403.13233.\\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\\nZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\\nZhuohan Li, Dacheng Li, Eric Xing, et al. 2024.\\nJudging llm-as-a-judge with mt-bench and chatbot\\narena. Advances in Neural Information Processing\\nSystems, 36.\\nMing Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu\\nJiao, Pengfei Liu, Chenguang Zhu, Heng Ji, and\\nJiawei Han. 2022.\\nTowards a unified multi-\\ndimensional evaluator for text generation.\\narXiv\\npreprint arXiv:2210.07197.\\nChunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer,\\nJiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping\\nYu, Lili Yu, et al. 2024a. Lima: Less is more for\\nalignment. Advances in Neural Information Process-\\ning Systems, 36.\\nDaquan Zhou, Kai Wang, Jianyang Gu, Xiangyu Peng,\\nDongze Lian, Yifan Zhang, Yang You, and Jiashi\\nFeng. 2023. Dataset quantization. In Proceedings\\nof the IEEE/CVF International Conference on Com-\\nputer Vision, pages 17205–17216.\\nJianghong Zhou,\\nEugene Agichtein,\\nand Surya\\nKallumadi. 2020. Diversifying multi-aspect search\\nresults using simpson’s diversity index. In Proceed-\\nings of the 29th ACM International conference on\\ninformation & knowledge management, pages 2345–\\n2348.\\nYuhan Zhou, Fengjiao Tu, Kewei Sha, Junhua Ding,\\nand Haihua Chen. 2024b. A survey on data quality\\ndimensions and tools for machine learning. arXiv\\npreprint arXiv:2406.19614.\\nLianghui Zhu, Xinggang Wang, and Xinlong Wang.\\n2023.\\nJudgelm:\\nFine-tuned large language\\nmodels are scalable judges.\\narXiv preprint\\narXiv:2310.17631.\\nYaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan\\nZhang, Jun Wang, and Yong Yu. 2018. Texygen: A\\nbenchmarking platform for text generation models.\\nIn The 41st international ACM SIGIR conference\\non research & development in information retrieval,\\npages 1097–1100.\\n',\n",
       " '1\\nA Survey of Blockchain, Artificial Intelligence, and\\nEdge Computing for Web 3.0\\nJianjun Zhu, Fan Li, and Jinyuan Chen\\nAbstract—Web 3.0, as the third generation of the World\\nWide Web, aims to solve contemporary problems of trust,\\ncentralization, and data ownership. Driven by the latest advances\\nin cutting-edge technologies, Web 3.0 is moving towards a more\\nopen, decentralized, intelligent, and interconnected network.\\nHowever, increasingly widespread data breaches have raised\\nawareness of online privacy and security of personal data.\\nAdditionally, since Web 3.0 is a sophisticated and complex\\nconvergence, the technical details behind it are not as clear as\\nthe characteristics it presents. In this survey, we conduct an in-\\ndepth exploration of Web 3.0 from the perspectives of blockchain,\\nartificial intelligence, and edge computing. Specifically, we begin\\nwith summarizing the evolution of the Internet and providing\\nan overview of these three key technological factors. Afterward,\\nwe provide a thorough analysis of each technology separately,\\nincluding its relevance to Web 3.0, key technology components,\\nand practical applications. We also propose decentralized stor-\\nage and computing solutions by exploring the integration of\\ntechnologies. Finally, we highlight the key challenges alongside\\npotential research directions. Through the combination and\\nmutual complementation of multiple technologies, Web 3.0 is\\nexpected to return more control and ownership of data and digital\\nassets back to users.\\nIndex\\nTerms—Web\\n3.0,\\nDecentralization,\\nOwnership,\\nBlockchain, Artificial Intelligence, Edge Computing.\\nI. INTRODUCTION\\nS\\nINCE the second half of 2021, Web 3.0 has become\\nubiquitous and gained widespread attention across various\\nindustries. Web 3.0 is a new version of the World Wide Web\\n(also known as the Web), which is the world’s dominant\\nsoftware platform. According to the well-known statistical site\\nStatista, as of October 2023, there were 5.3 billion web users\\nworldwide, which accounts for 65.7% of the global population.\\nNotably, social media users account for 93.4% of web users\\n[1]. However, the vast online world is controlled by tech giants\\nwho have absolute power compared to the general public. The\\ncentralized platforms developed by tech giants gather personal\\ndata from users and serve as both gatekeepers and arbiters\\nin the delivery of their services, allowing them to shape\\nand control what is available on the Web. Those platforms\\ndrive most traffic to online news and hence have a significant\\ninfluence on the sources of information that the general public\\nconsumes on a regular basis. The primary beneficiaries are a\\nsmall group of stakeholders. These platforms are unelected\\nand difficult to audit. For the current dilemma, there is an\\nurgent need for solutions to improve web environment while\\nreturning control to users. This has laid a solid foundation for\\nJianjun Zhu, Fan Li, and Jinyuan Chen are with Louisiana Tech University,\\nDepartment of Electrical Engineering, Ruston, LA 71272 USA (e-mail:\\njzh013@latech.edu; fanli@latech.edu; jinyuan@latech.edu).\\nthe emergence of Web 3.0. Web 3.0 is a counter-proposal to\\nthe current technological monopoly, providing a more holistic\\nview of how society should use technologies [2].\\nA. Motivations and contributions\\nWhile Web 3.0 is still in its infancy, it has made significant\\nadvances in creating an open, trustless, and permissionless web\\nwhere users can share and exchange data without relying on\\ncentralized organizations. However, there are still some major\\nproblems that need to be addressed.\\n1) True decentralization: The emerging industries support-\\ning decentralized web are highly consolidated, which may un-\\ndermine the realization of the decentralized vision of Web 3.0.\\n2) Mass adoption: Technical barriers for using Web 3.0\\nremain high, making it challenging for users to migrate to Web\\n3.0 platforms. In addition, the differences between developing\\nenvironments also pose challenges to Web 3.0 adoption.\\n3) Storage/computation: Web 3.0 requires decentralized\\nstorage and computation. However, building efficient decen-\\ntralized solutions is challenging.\\nWe are motivated by these problems to explore mitigation\\nstrategies from a technical perspective. Fundamentally, Web\\n3.0 is a convergence of emerging technologies. Among them,\\nblockchain, artificial intelligence (AI), and edge computing\\nare essential in this revolution, enabling users to use the Web\\nsecurely and intelligently. Blockchain will allow individuals,\\ncompanies, and computers to exchange data in a decentralized\\nmanner. AI will empower computers with the ability to learn\\nand reason to provide user-centered interactions. Edge com-\\nputing allows faster processing and decision-making with low\\nlatency by bringing computing and storage closer to where\\nusers actually consume the data.\\nBased on the concept that the architecture of Web 3.0 is\\ntypically constructed using technology stacks [3], we propose\\nan alternative stack architecture with varying emphases as\\nillustrated in Fig. 1. In this paper, we will explore Web 3.0\\nin-depth from the perspectives of blockchain, AI, and edge\\ncomputing. The corresponding technology enablers will be dis-\\ncussed in depth in each chapter. To the best of our knowledge,\\nthere has been no comprehensive survey on Web 3.0 from\\nthe perspective of these three technologies simultaneously. To\\nsummarize, the main contributions of our work are discussed\\nas follows:\\n1) We discuss in detail the technical building blocks of Web\\n3.0 and their necessity from the perspectives of blockchain, AI,\\nand edge computing.\\narXiv:2311.13731v1  [cs.CR]  22 Nov 2023\\n2\\nTABLE I\\nA COMPARISON BETWEEN OUR SURVEY AND OTHER WORKS ON WEB 3.0.\\nReference\\nDescription\\n[4]\\nProviding an integrative literature review on the development of the Web.\\n[5]\\nConducting a review of decentralized Internet with a focus on consensus and other emerging technologies.\\n[6]\\nExploring blockchain-based Web 3.0 from an architecture identification and evaluation perspective.\\n[7]\\nAnalyzing key advances and potential impacts to emphasize the importance of Web 3.0.\\n[8]\\nIntroducing the evolution, technologies, and challenges of Web 3.0.\\n[9]\\nSurveying the impact of quantum technology on the development of blockchain-based Web 3.0.\\n[10]\\nInvestigating Web 3.0 application categories, popularity, challenges, and opportunities.\\n[11]\\nConducting a comprehensive overview of the latest advances of AI in Web 3.0.\\nThis work\\nProviding an in-depth analysis of Web 3.0 from the perspectives of blockchain, AI, and edge computing,\\ndiscussing practical applications through a significant amount of concrete research works, and proposing\\nsolutions for decentralized storage and computation through technological integration.\\nInfrastructure \\nlayer\\nPeer-to-Peer\\nEdge computing\\nNetwork \\nlayer\\nProtocol \\nlayer\\nUse-case \\nlayer\\nEthereum\\nSolana\\nAvalanche\\nCardano\\nPolkadot\\nAstar\\nConsensus\\nOff-chain\\nCross-chain\\nLayer-2\\nsolutions\\nNFTs\\nDeFi\\nDAO\\nCognitive\\nlayer\\nAutoregression\\nTransformer\\nNLP\\nCV\\nGAN\\nVAE\\nFig. 1. Web 3.0 stack architecture.\\n2) We survey state-of-the-art Web 3.0 practical applications\\nto explore more convergence possibilities to improve the Web\\n3.0 ecosystem.\\n3) We propose and illustrate storage and computing solu-\\ntions in decentralized scenarios by exploring the integration of\\nblockchain, AI, and edge computing.\\n4) We highlight critical challenges encountered in the de-\\nvelopment of Web 3.0 with concrete data and discuss future\\nresearch directions accordingly.\\nB. Comparison with other surveys\\nTo date, there have been several survey papers on different\\naspects of Web 3.0. Our survey is distinctive from all the other\\nsurveys as we conducted an in-depth analysis of the impact\\nof blockchain, AI, and edge computing on the development\\nof the Web 3.0 ecosystem. A comparison of our survey with\\nother works on Web 3.0 is provided in Table I.\\nComparatively, Voj´ıˇr et al. in [4] provided an integrative\\nliterature review examining the development of the Web by\\nanalyzing its evolution from centralization to decentralization\\nand the reactions it provoked. Zarrin et al. in [5] showed\\nthe potential of blockchain technology to provide a robust\\nand secure decentralized Internet by exploring consensus al-\\ngorithms and how blockchain can be combined with emerg-\\ning technologies. Wang et al. in [6] conducted an in-depth\\nexploration of Web 3.0 from the perspective of blockchain,\\nidentifying twelve types of architecture by decoupling exist-\\ning systems into core components. Ray in [7] emphasized\\nthe importance of Web 3.0 in shaping a decentralized and\\ndemocratized Internet by analyzing the key advances and\\nimpacts of Web 3.0 applications and their integration with\\nemerging technologies. Gan et al. in [8] provided an overview\\nof Web 3.0 in terms of technologies, challenges, potential,\\nand prospects. Ren et al. in [9] explored the fusion of various\\nquantum information technologies with blockchain to develop\\na resilient digital ecosystem based on blockchain. Huang et\\nal. in [10] empirically investigated the categories of Web 3.0\\napplications and their popularity, as well as the potential of this\\nemerging field. Shen et al. in [11] provided a comprehensive\\noverview of the latest advances of AI in Web 3.0, proposing\\nand investigating the main challenges at each layer of the Web\\n3.0 architecture.\\nThe rest of this paper is organized as follows. Section II\\nprovides relevant preliminaries such as the evolution of the\\nWeb, current web issues, and background on blockchain,\\nAI, and edge computing. Sections III-V provide an in-depth\\nanalysis of each technology (i.e., blockchain, AI, and edge\\ncomputing) for Web 3.0 in terms of relevance, fundamental\\ncomponents, practical applications, and further insights. Sec-\\ntion VI delves into the primary use cases of Web 3.0 and their\\n3\\npractical applications. Additionally, major issues from both\\ntechnical and non-technical aspects are discussed. Section VII\\ndiscusses the key challenges and further research directions.\\nFinally, the work is concluded in Section VIII. An illustrative\\norganizational structure of this survey is presented in Fig. 2.\\nSection I: Introduction\\nMotivations and contributions\\nComparison with other surveys\\nSection II: Preliminaries\\xa0\\nWhat is blockchain?\\nMain issues of the current Web\\nWhat is AI?\\nWhat is edge computing?\\nSection III:\\xa0Blockchain for Web 3.0: a decentralized and trusted web\\xa0\\nOff-chain technology\\nRelevance to Web 3.0\\nCross-chain technology\\nLayer 2 scaling solutions\\nPractical applications of\\xa0 blockchain in Web 3.0\\nSection IV:\\xa0AI for Web 3.0: an intelligent and semantic web\\xa0\\nGenerative AI\\nRelevance to Web 3.0\\nGenerative AI for Web 3.0\\nWeb 3.0 for generative AI\\nPractical\\xa0 applications of\\xa0 AI in Web 3.0\\nSection V: Edge computing\\xa0for Web 3.0: an\\xa0interconnected and ubiquitous\\xa0web\\xa0\\nIntegration of edge computing and blockchain: a storage solution\\nRelevance to Web 3.0\\nIntegration of edge computing and AI: a computing solution\\nPractical applications of\\xa0 edge computing in Web 3.0\\nSection VI: Use cases for Web 3.0\\nNFTs\\nDeFi\\nDAOs\\nSection VII:\\xa0Challenges and future research directions\\xa0\\nKey challenge and future direction in the context of blockchain\\nKey challenge and future direction in the context of AI\\nKey challenge and future direction in the context of edge computing\\nSection VIII: Conclusion\\nEvolution of the Web\\nSummary and insights\\nSummary and insights\\nSummary and insights\\nFig. 2. An illustrative organizational structure of this paper.\\nII. PRELIMINARIES\\nIn this section, we introduce the fundamentals of Web 3.0\\nfrom the following aspects: evolution of the Web, main issues\\nof current Web, and enabling technologies (i.e., blockchain,\\nAI, and edge computing).\\nA. Evolution of the current Web\\nThe Web is a hypertext document management system\\naccessible via the Internet. People can use a web browser to\\naccess web pages hosted on web servers. In March 1989, Sir\\nTim Berners-Lee proposed a system for managing information\\nfor what would become the Web. He envisioned an intelligent,\\nconnected, and data-driven network in which computers could\\nanalyze all network data, including content, connections, and\\ntransactions between users and computers. He advocated for\\nthe European Council for Nuclear Research to provide the\\nunderlying code for free in April 1993. This decision led to\\ntoday’s Web [12], [13].\\nWeb 1.0, also called the Static Web, is described as a web\\nof interconnected information. Tim Berners-Lee coined it as\\n“read-only” Web (see Fig. 3-a) since a massive majority of\\nparticipants were content consumers. Content creators were\\nbasically reporters, writers, and developers. Web 1.0 was not\\ninteractive as it did not provide the features to browse the Web,\\nwhich made it extremely difficult for content users to find\\nthe needed information. The web pages were also proprietary,\\nas many web browsers tried to attract users and stand out\\nby providing proprietary content. This led to a series of\\nincompatibility issues between web pages and web browsers.\\nWeb 2.0, also called the Social Web, is the most familiar and\\nwidely used Web today. The term “Web 2.0” was first proposed\\nby Darcy Dinucci in 1999 and later promoted by Tim O’Reilly\\nand Dale Dougherty as a “read-write” Web in late 2004 (see\\nFig. 3-b) [14]. The focus of Web 2.0 is on enabling users to\\ninteract with web content. Users are becoming more engaged\\nin generating and sharing web content in addition to browsing.\\nUsers can communicate with each other over the Web through\\nsocial media platforms. They can create content in their own\\nblogs that other users can access and interact with in discussion\\nforums. The Web 2.0 period is also a time when mobile web\\naccess has boomed. People can utilize their phones, tablets,\\nand almost any other web-connected devices to access web\\ncontent at any time. Overall, Web 2.0 applications demonstrate\\na powerful front-end revolution with more opportunities to\\ninteract with end users.\\nWeb 3.0 was first coined by Gavin Wood, co-founder of\\nEthereum, in 2014 as a way to minimize trust in a handful of\\nprivate companies [3], [15]. It is a decentralized and fair In-\\nternet reconstructed using distributed technology, where users\\ncan control their own data and identity. Up until 2021, Web\\n3.0 gradually entered the public consciousness and became\\nmainstream. It is described as a “read-write-own” Web (see\\nFig. 3-c) that enables users to acquire, create, and execute. Web\\n3.0 does not rely on any third parties but rather allows users\\nto interact directly with each other and with the web content\\nthey are accessing through a peer-to-peer (P2P) network. This\\nmakes privacy and security more assured because information\\nis not stored in a data center that could be compromised.\\nAdditionally, power will be handed back to the end users,\\nwho no longer need permission from the tech giants to create,\\n4\\na) Web 1.0: read-only\\nb) Web 2.0: read-write\\nc) Web 3.0: read-write-own\\nFig. 3. Evolution of the Web.\\ntrade, and collaborate. A typical example is Solid proposed\\nby Tim Berners-Lee in late 2020 [16]. The purpose is to\\npropose a specification that allows users to securely store data\\nin a decentralized manner to achieve true data ownership and\\nimprove privacy. Notably, Web 3.0 is more than just a new\\nwave of innovation. It is an opportunity to reset and enable new\\nbenefits for ordinary users while solving some of the toughest\\nchallenges posed by disruptive technologies of the past.\\nB. Main issues of the current Web\\nThe Web is among the most crucial innovations in the\\nprogression of human technologies. It aims to serve as an open\\nplatform that facilitates interaction, access, and information\\nsharing across regional and cultural boundaries. From this\\nviewpoint, the current Web has partially realized this vision\\nsince it has brought many revolutionary changes to the Inter-\\nnet. However, it has also raised some major issues [17].\\n• Lack of ownership: The current business strategy of\\nmany data-driven companies is to provide free services in\\nexchange for personal data. The collected data is invisible\\nto users. In addition, users lack ways to inform third\\nparties that they do not want their data to be disclosed.\\nAccording to a survey on personal information by Pew\\nResearch Center [18], 62% of Americans believe that it is\\nimpossible for their data not to be collected in their daily\\nlives; 79% of Americans are very concerned about how\\ncompanies use their personal data; 81% of Americans\\nbelieve that they have little control over their personal\\ndata. To make matters worse, the government is working\\nwith tech companies to track online behavior and create\\nsevere regulations that violate people’s privacy.\\n• Centralization: Despite the decades-long history of the\\nWeb, the network architecture is still based on the concept\\nof stand-alone computers. Companies with significant\\ncontrol over large data platforms are progressively con-\\ncentrating data in their hands. These tech giants provide\\nusers with online identities by holding their personal data\\nand acting as gatekeepers of information. At the same\\ntime, they likely have control over who is able to use\\ntheir digital products. All activities on the platform need\\nto be carried out with the permission of the platform. This\\nbecomes a problem when people are denied the choices\\nthat should be rightfully theirs. Whenever people interact\\nover the Web, data will be sent to the central server. It\\nshould be clear that the users will lose control over the\\ndata when that happens which will also cause a serious\\ncrisis of trust.\\n• Privacy: Web 2.0 applications collect vast amounts of\\npersonal and sensitive data by extensively tracking an\\nindividual’s digital activities, social media posts, physical\\nlocation, purchasing habits, and more to build highly\\ndetailed digital profiles. However, individuals have little\\nknowledge or control over what information is collected\\nand how it is used. This data may be accessed or\\ndisclosed by unauthorized parties, or misused by the\\nservice provider itself. According to Statista, the number\\nof exposed data records detected since 2020 has exceeded\\n473 million data records [19]. This points to serious\\nissues with this pervasive data collection under opaque\\nusage policies, which can lead to unfounded behavioral\\nprofiling, intrusive advertising practices, and inadvertent\\ntargeting of vulnerable audiences.\\n• Spread of misinformation: Data quality issues include\\ndata inaccuracy, data inconsistency, and data duplication.\\nIn Web 1.0, data quality was primarily determined by\\nthe reputations of publishers. However, Web 2.0 reduces\\ndata quality and leads to the spread of misinformation.\\nThe majority of individuals acquire news and information\\nfrom a handful of social media platforms and search\\nengines. These companies determine what to display\\nbased on the recommendation algorithms that learn from\\npersonal data so that more profit can be achieved when\\nusers click on links. This leads to these sites showing\\nsome poor-quality data or even fake news that may\\nsurprise and shock people and can spread like wildfire.\\nAdditionally, those with malicious intent may exploit the\\nsystem to disseminate false information for monetary or\\npolitical gain.\\n• Unfair reward system: The reward system in Web 2.0\\nis unfair, with platforms reaping the vast majority of\\nprofits from the content created by content creators. Only\\na small percentage of the profits go to the individuals who\\n5\\nTABLE II\\nBLOCKCHAIN CONSENSUS PROTOCOLS.\\nTypes\\nReference\\nDescription\\nBFT\\nconsensus\\nBEAT [20]\\nA set of five asynchronous protocols focusing on practicality and efficiency\\nHotStuff [21]\\nA partially synchronous and leader-based protocol for linearity and responsiveness\\nHoneyBager [22]\\nAn asynchronous protocol constructed from an asynchronous common subset\\nProteus [23]\\nA protocol that achieves consistent performance by applying a root committee strategy\\nSBFT [24]\\nA protocol combining collectors, threshold signatures, a fast path, and redundant servers\\nGosig [25]\\nA protocol applying transmission pipelining and aggregated signature gossip\\nPoX\\nconsensus\\nProof of Work [26]\\nParticipants compete to solve computational puzzles to validate transaction blocks\\nProof of Stake [27]–[29] Validators are selected to validate transaction blocks based on their stake\\nProof of Activity [30]\\nParticipants first solve cryptographic puzzles and then transit to a staking mechanism\\nProof of History [31]\\nVerifiers collectively creat a ledger with verifiable passage of time between events\\nProof of Burn [32]\\nParticipants burn some of their own tokens to gain the right to validate transactions\\nProof of Importance [33] Participants harvest new blocks depending on their importance to the network\\nProof of Replication [34] Prover provides evidence that a unique copy of the data is stored\\nProofs of Space [35]\\nParticipants prove their commitment by allocating significant amounts of storage space\\nactually create the content. There are two main reasons\\nfor this situation: The first reason is high concentration.\\nAll network resources are owned and controlled by the\\nplatform. The second reason is the unconsciousness of\\ndata value. Most users are not aware of data value\\nthey generate. The platform is also subtly telling people\\nthe uselessness of data. In addition, centralized recom-\\nmendation algorithms prefer data that can be widely\\ndisseminated regardless of whether the data content itself\\nhas positive value. This type of content recommendation\\nis unbalanced, which greatly enriches the interests of a\\nsmall group of top influencers.\\nC. What is blockchain?\\nA blockchain is essentially a global network of intercon-\\nnected nodes that serves as a distributed database or ledger. It\\ncontains blocks of transaction records that are shared by all\\nparticipants in the network. Each block carries the digest of the\\nprevious block, which is the output of the cryptographic hash\\nfunction. This digest can be used to verify the validity of the\\nprevious block, such that it connects the blocks into a growing\\nchain. Blocks cannot be changed backward without affecting\\nall the following blocks. This assures data confidentiality and\\nintegrity, as well as the ability for blockchain participants to\\nverify and audit transactions.\\nThe consensus protocol is the fundamental building block\\nof blockchain networks as well as the Web 3.0 ecosystem.\\nAccording to the latest research on the priority of Web 3.0\\ndevelopment factors, the most important factor in the develop-\\nment of Web 3.0 is the consensus mechanism, with a weight\\nof 20.0% [36]. Fundamentally, a consensus protocol was a\\nfault-tolerant mechanism used between distributed processes\\nto achieve a common agreement on a single data value. From\\nthe perspective of blockchain, the consensus protocol is used\\nby each participant to agree on the state of a distributed ledger.\\nConsensus protocols ensure the reliability of blockchain net-\\nworks by fostering trust among anonymous peers in a decen-\\ntralized setting and enacting regulatory economic incentives\\nin this way. There are many consensus mechanisms powering\\nthe blockchain systems. Fundamentally, they can be broadly\\ngrouped into two categories: Byzantine fault-tolerant (BFT)\\nconsensus and Proof of Something (PoX) consensus (see\\nTable II). A comparison between some of the most commonly\\nused consensus protocols can also be found in [37]–[39].\\nD. What is AI?\\nAI is an interdisciplinary science that uses computers and\\ndata to mimic the problem-solving and decision-making abil-\\nities of the human brain. It includes machine learning (ML)\\nand deep learning (DL), which are creating a paradigm shift\\nand making breakthroughs in all different fields. Typically,\\nhumans will play a role in supervised learning, providing pos-\\nitive feedback for good decisions while preventing bad ones.\\nHowever, certain AI systems are designed for unsupervised\\nlearning, where they eventually figure out the rules through\\npattern recognition and learning using large amounts of data.\\n6\\n2016\\nAlphaGo\\n2022\\nChatGPT\\n?\\nperform intellectual tasks\\nthat are beyond human\\nabilities\\nArtificial Super\\nIntelligence\\nMachine Consciousness\\naim to replicate\\nhuman-level\\nintelligence\\nArtificial General\\nIntelligence\\nMachine Intelligence\\nfocus on specific\\ntasks or domains\\xa0\\nArtificial Narrow\\nIntelligence\\nMachine Learning\\nFig. 4. Levels of AI sophistication.\\nEdge node\\nEdge server\\nEdge devices\\nEdge\\ndatabases\\nEdge node\\nNetwork edge\\nEdge server\\nEdge devices\\nEdge\\ndatabases\\nFig. 5. Edge computing.\\nIn terms of technical capabilities, there are three types of\\nAI as shown in Fig. 4 [40]. One type is known as Artificial\\nNarrow Intelligence (ANI), which has been integrated to\\nimprove people’s daily lives. Both voice-controlled personal\\nassistants and self-driving cars have benefited greatly from this\\ntype of AI. In particular, breakthroughs in healthcare are also\\ndependent on it, as it can greatly reduce repetitive tasks that\\ncan lead to human errors, enhance the process of developing\\nmedical materials, and improve treatment outcomes. Another\\ntype of AI is called Artificial General Intelligence (AGI),\\nin which the computer has greatly improved in intelligence\\ncompared to the level of Web 2.0. It would be self-aware,\\ncapable of problem-solving, learning, and long-term planning.\\nIf development continues, it will reach the third type of AI, i.e.,\\nArtificial Super Intelligence (ASI). With the advent of Web\\n3.0, the booming development of various edge technologies\\nwill propel AI into a more advanced stage.\\nE. What is edge computing?\\nEdge computing refers to the offloading of data storage and\\ndata processing that were previously handled by centralized\\nservers to the edge of the network close to end-user devices.\\nThis technique helps reduce data transfer times and device\\nresponse latency while easing bandwidth congestion on the\\nnetwork. Costs associated with data transmission can be de-\\ncreased by localizing processing at the edge. Decentralization\\nis accomplished by dispersing computing away from central\\nhubs. Additionally, shifting workloads to edge nodes with\\nprocessing and storage capabilities helps effectively optimize\\nresource usage.\\nThe key components enabling edge computing are edge\\ndevices, edge servers, edge databases, edge nodes, and network\\nedge as shown in Fig. 5 [41]. Edge devices refer to the\\ndevices that process data near the data source. For example,\\nsmartphones, laptops, sensors, and industrial robots. Edge\\nservers are information technology (IT) computing devices\\nlocated near edge devices for computing IT workloads and\\nresource management. Edge databases are database systems\\nthat are deployed at the edge of the network. They are used to\\nstore the data generated by the edge devices locally instead of\\nsending to a centralized data server. Edge nodes are nodes\\nthat hold edge devices, edge servers, and edge databases.\\nThey are connected to the network and each other, acting as\\nintermediaries to facilitate data exchange and resource sharing.\\nThe network edge is the network infrastructure such as 5G\\nand high-speed satellite Internet that connects edge devices\\nand edge servers with low latency.\\n7\\nIII. BLOCKCHAIN FOR WEB 3.0: A DECENTRALIZED AND\\nTRUSTED WEB\\nWeb 3.0 is a decentralized network based on blockchain\\ntechnology, collectively maintained by nodes scattered around\\nthe globe. Blockchain redefines the way data is stored and\\nmanaged. It uses cryptographic techniques to provide a unique\\nset of states that can enable true P2P transactions without third\\nparties. With blockchain, data will be stored on a decentralized\\nnetwork rather than on a centralized server so that privacy\\nand ownership will be given back to individuals [42]. Notably,\\nblockchain combined with privacy-preserving technologies has\\nthe potential to further enhance the protection of user privacy.\\nTypically, website fingerprinting is a technique widely used in\\nweb browser analysis to infer sensitive information about users\\nby examining traffic patterns. In response to such attacks, some\\nsignificant improvements have been proposed for website\\nfingerprinting-based methods. For example, a TCP/IP traffic-\\nbased defense mechanism was proposed in [43]. It is an\\nefficient and low-overhead defense mechanism against attacks\\nthat can filter out the injected noise. A traffic splitting-based\\ndefense mechanism was proposed to limit the data that can be\\nobserved by a single entry node in [44]. By embedding these\\ndefense technologies, blockchain can provide additional layers\\nof security on top of its inherent cryptographic protections and\\ndecentralized framework.\\nDue to its ability to store data in P2P networks, blockchain\\nlays the foundation for Web 3.0. The protocol specifies the\\nmanagement rules, which are guaranteed by a majority vote\\nof all members of the network. Participants are rewarded for\\ntheir contributions to network security and maintenance. It\\nenables the individuals to reach a consensus while the network\\nBlock\\nBlock\\nBlock\\nDecentralized\\nstorage\\nConsensus\\nDecentralized\\ncomputation\\nSmart contract\\nEthereum Virtual Machine\\n(Ethereum, Solana, etc.)\\nPrivate Key-based Authentication\\n(Wallet)\\nFrontend\\nBlockchain platform\\nSmart contract\\nSmart contract\\ndApp\\ndApp\\ndApp\\nFig. 6. Web 3.0 infrastructure from the perspective of blockchain.\\nKey aspects of Blockchain\\nin Web 3.0\\n\\xa0 Decentralization:\\xa0to delegate power through decentralized networks.\\xa0\\n\\xa0 Tokenization:\\xa0 to\\xa0revolutionize ownership, value, and exchange in Web 3.0.\\n\\xa0 Democratization:\\xa0to democratize Web 3.0 via decentralized governance.\\n\\xa0 Digital Identity:\\xa0to manage Web 3.0 interactions with unique digital identity.\\n\\xa0 Security&Privacy:\\xa0to mitigate network attacks in Web 3.0 via consensus technique\\nFig. 7. Relevance of blockchain to Web 3.0.\\ncollectively records previous user interactions or events. As a\\nresult, blockchain technology is certainly a powerful force that\\ncan make the network more decentralized [45]. Web 3.0 is a\\nbackend revolution with a network architecture as shown in\\nFig. 6 [46], [47]. For average users, there will be no change\\nto the interface of the Web. From a technical perspective, it is\\na set of blockchain-based protocols designed to transform the\\nbackend of the Web.\\nIn this section, we will first show how blockchain tech-\\nnology is closely related to Web 3.0. Then, we will explain\\nthe criticality of blockchain for Web 3.0 from the perspective\\nof specific technologies, i.e., off-chain technology, cross-chain\\ntechnology, and layer 2 solutions. Afterward, we will introduce\\nthe practical applications of blockchain in Web 3.0. Finally,\\nthe summary and insights are provided.\\nA. Relevance to Web 3.0\\nWeb 3.0 is a decentralized and trustworthy Web, aiming to\\ntransform a centralized network platform into a decentralized,\\nsecure, and user-centric platform. Blockchain technology plays\\na crucial role in realizing the vision of Web 3.0. This can be\\ndemonstrated in several key aspects as shown in Fig. 7.\\n1) Decentralization: One of Web 3.0’s visions is to build\\na decentralized system that does not depend on a single\\nentity but operates on a distributed network of nodes. The\\ncore principle of decentralization is the delegation of power\\nwhich requires the distribution of power and control outside\\nof the central authority. The technological support comes from\\nblockchain and its underlying P2P networks. Web 3.0 can\\nhelp create more sustainable networks by decentralizing the\\nenergy consumption associated with centralized data centers.\\nBy distributing data and computing power among multiple\\nnodes, blockchain-based systems can be more energy-efficient\\nand environmentally friendly. For example, according to mea-\\nsurements [48]–[51], the energy consumption per Algorand\\ntransaction is approximately 0.000008 kWh, whereas each\\nVisa transaction consumes around 0.0015 kWh. In terms of\\ncarbon footprint, each Algorand transaction generates 0.0004\\ngCO2 compared to the 0.45 gCO2 of each Visa transaction.\\n8\\nDecentralized Oracle\\nNetwork\\nOff-chain \\ndata sources\\n<101011000110>\\nMain chain\\n<101011000110, sig>\\nMinority reports\\nManage\\nData-source\\nauthentication\\nDON trust\\nminimization\\nGuardrails\\nTrust-minimized\\ngovernance\\nPublic-key\\ninfrastructure\\n(DON)\\nFig. 8. Interactions between off-chain and on-chain resources via DON.\\n2) Tokenization: Token is a digital scarcity in Web 3.0,\\nwhich refers to the representation of real-world assets by\\na string of numbers on the blockchain network. The im-\\nmutability and public verifiability of the blockchain network\\nguarantee the uniqueness, scarcity, and security of this digital\\nstring. Tokens can be used to represent access rights, voting\\nrights, or other types of ownership in applications. It also\\nenables fractional ownership, which means assets can be\\ndivided into smaller parts that can be easily bought, sold,\\nor traded, enabling more people to participate in investment\\nopportunities. Tokenization has great potential to revolutionize\\nownership, value, and exchange in the Web 3.0 ecosystem.\\n3) Democratization: One of the main features of Web 3.0\\nis the democratization enabled by blockchain technology. Web\\n3.0 promises to allow users to be rewarded based on their\\ncontributions to the Web. However, democratizing in an error-\\nfree and fair manner is a major challenge. Essentially, the\\nmain problem that the blockchain solves is how to transfer\\nvalue and control from the platform to the community, while\\nmaintaining the prosperity of the platform. Decentralization\\nand tokenization are two key aspects that are at the heart\\nof the democratization of Web 3.0. Specifically, the decen-\\ntralized nature of blockchain technology allows for trustless\\ncooperation between stakeholders within the platform; then the\\ntokenization of blockchain provides a fair way to incentivize\\ndifferent stakeholders to participate in the governance and use\\nof the platform.\\n4) Digital universal identity: Digital identity is one of\\nthe core elements of Web 3.0. It plays a key role in man-\\naging Web 3.0 interactions. However, as data breaches and\\nhacks expose the vulnerability of personal data, the utility\\nand relevance of digital identities are becoming increasingly\\napparent. In particular, the proliferation of social media has\\nresulted in individuals having different digital identities on\\ndifferent platforms. Online identity management faces serious\\nchallenges. Blockchain technology can provide a decentralized\\nand interoperable identity system for Web 3.0 users. This\\nensures that each user has a secure, unique digital universal\\nidentity across multiple platforms, eliminating the need for\\nmultiple usernames and passwords.\\n5) Security and privacy: Ensuring the security and pri-\\nvacy of data and transactions is a crucial part of the rapid\\ndevelopment of Web 3.0. Blockchain-based Web 3.0 can\\nfundamentally eliminate the need for central institutions to\\nmanage data. Moreover, the integration of blockchain in Web\\n3.0 will greatly mitigate network attacks. Every data stream on\\nthe blockchain network has to be verified by different nodes. A\\nsuccessful network attack requires controlling the majority of\\nnodes on the blockchain network in order to reach a consensus\\non its proposals. At the same time, it has to compete with\\npotential new blocks that are added. This is impractical for\\nhackers, as they would be trapped in an endless computational\\nloop, making it harder for them to compromise the network\\nand access users’ personal information and transaction records.\\nB. Off-chain technology\\nOff-chain technologies play a critical role in augmenting\\nblockchains in the Web 3.0 ecosystem. When blockchains are\\nconnected to off-chain resources, their capabilities are greatly\\nenhanced, from incorporating real-world information into on-\\nchain execution to reducing costs and increasing through-\\nput by shifting computation off-chain. However, to securely\\nand immutably connect blockchain to external resources, the\\noracle problem needs to be overcome. This problem refers\\nto the inherent limitation of blockchains being unable to\\ndirectly access or use external data resources due to their\\nisolated nature. A blockchain oracle is an entity that connects\\nblockchain to external systems, allowing smart contract (SCs)\\nto execute based on real-world inputs and outputs in the Web\\n3.0 ecosystem.\\nThe decentralized oracle network (DON), proposed by\\nChainlink in [52], acts as a secure middleware to facilitate\\ncommunication between on-chain and off-chain resources as\\nshown in Fig. 8. The DON obtains data from off-chain\\nresources and then forwards the data to the SC deployed on the\\nmain chain. Additionally, the DON incorporates a separate SC\\nfor node management. Notably, one of the goals of Web 3.0\\nis to minimize trust. The implementation of a DON involves\\nintegrating a variety of trust-minimized technologies.\\n9\\nDecentralized account\\nwith public address\\xa0\\xa0\\nCreate account (2)\\nDeposit (3)\\nLock (4)\\nTriggering (6)\\nGenerate and Manage (5)\\nBTC\\nETH\\nLTC\\nMint (7)\\nwBTC wETH\\nwLTC\\nWithdraw (5)\\nUnlock (4)\\nTriggering (2)\\nBTC\\nETH\\nLTC\\nBurn (3)\\nwBTC wETH\\nwLTC\\nDeposit request (1)\\nWithdraw request (1)\\nSmart contract\\nDecentralized account\\nwith public address\\xa0\\xa0\\nSmart contract\\na) Deposit process\\nb) Withdraw process\\nFig. 9. Cross-chain assets deposit/withdraw flowchart.\\n1) Data-source authentication: An important component of\\ntrust minimization involves strengthening data-source authenti-\\ncation through support for data signing tools and standards. By\\ncryptographically signing the data they provide to SCs, a DON\\nenables users to identify which nodes sent data and track the\\nbehaviors to determine the quality of their performance. In this\\nway, the end-to-end integrity of the data can be guaranteed.\\n2) DON trust minimization: To minimize trust in DON,\\nthere are two main methods. The first is the failover clients,\\nwhich are backup clients for nodes in case of unexpected\\nevents. They do not increase the number of potential attacks\\nand can reduce reliance on individual client security as they\\nare not deployed on the mainline. The second is the minority\\nreport, which is a parallel report that is forwarded to SCs on\\nthe main chain. This is an important mechanism that operates\\nin a threshold manner to maintain the integrity and reliability\\nof the data sources provided by the DON.\\n3) Guardrails: Guardrails are a collection of trust mini-\\nmization mechanisms involving the implementation of moni-\\ntoring and fail-safety in SCs. A circuit breaker is a guardrail\\nwhere a SC may control state updates based on inputs. For\\nexample, it might be triggered if minority reports change\\nsignificantly over time. Escape hatches are emergency facilities\\nthat SCs can invoke to terminate pending transactions and\\nfuture transactions in adverse circumstances. Failover means\\nthat SCs can provide a failover mechanism to ensure the\\ncontinuity of services even in the event of DON failure.\\n4) Trust-minimized governance: Evolutionary governance\\nand emergent governance are two types of trust-minimizing\\ngovernance mechanisms. Evolutionary governance is about\\ndeploying changes gradually, ensuring the community has\\nthe opportunity to respond. Emergency governance refers\\nto vulnerabilities in SC that require immediate intervention\\nto avoid catastrophic consequences. Specifically, emergency\\ngovernance uses a multi-signature intervention mechanism to\\nensure that signers dispersed across organizations are always\\navailable to authorize emergency changes.\\n5) Public-key infrastructure: As decentralization contin-\\nues to advance, a strong public key infrastructure (PKI) is\\nrequired to reliably identify network participants, including\\nDON nodes. The foundation of PKI in DON is the Ethereum\\nName Service (ENS). ENS allows human-readable Ethereum\\nnames to be mapped to blockchain addresses. Tampering with\\nthe name is inherently as difficult as tampering with the SC\\nthat governs it unless the keys are compromised.\\nC. Cross-chain technology\\nA blockchain is a decentralized system powered by dis-\\ntributed ledger technology. However, it is not a cumulative\\necosystem since each blockchain is designed for a particular\\nuse. They have specific advantages, limitations, and varying\\nlevels of decentralization. For example, if a blockchain aims to\\nachieve high transaction throughput, it may be less decentral-\\nized and less secure. Since each blockchain is isolated from the\\nothers, leveraging the functionality of one blockchain cannot\\ncompensate for another. To fully take advantage of blockchain\\ntechnology, cross-chain technology was developed to address\\ninteroperability, which can greatly boost productivity in the\\nWeb 3.0 ecosystem [53]–[55]. Everyone involved will benefit\\nfrom the increased flexibility, as users will be able to easily\\ntransfer assets and data between blockchains [56]. Given the\\nwide variety of bridge designs, the most widely adopted bridge\\ndesign is based on the lock-mint-burn method as shown in\\nFig. 9 [57]. Basically, this type of bridge designates a public\\n10\\nLayer 2 \\nsolutions\\nRollups\\nState channels\\nSidechains\\nOptimistic\\nrollups\\nZero-\\nknowledge\\nrollups\\nBitcoin’s\\nLightning\\nnetwork\\nEthereum’s\\nRaiden\\nnetwork\\nLiquid\\nnetwork\\nPolygon \\nPoS\\nFig. 10. Layer 2 solutions with typical projects.\\naddress on the source chain for users to deposit their tokens.\\nOn the destination chain, a SC will mint the wrapped tokens\\n1:1 with the tokens held in the decentralized managed account\\nand send them to the user’s wallet.\\nCross-chain technology enables trade-offs between two or\\nmore blockchains in terms of efficiency, decentralization, and\\nsecurity. Additionally, cross-chain technology can improve\\nchain efficiency, reduce fragmentation, and enable a free flow\\nof users and features between multiple blockchains. In recent\\nyears, cross-chain platforms with different goals have been\\ndeveloped. For example, tBTC is an Ethereum-like token that\\nis linked to the value of Bitcoin [58]. It enables Bitcoin holders\\nto gain access to the Ethereum ecosystem and decentralized\\nfinance (DeFi) applications. Parity Bridge is a cross-chain\\nsolution to connect fast and cheap Proof of Authority chains\\nwith the Ethereum public network and any other Ethereum-\\nlike PoW chain [59]. Wormhole is a communication bridge\\nbetween Solana and other mainstream blockchain networks\\n[60]. Existing projects, platforms, and communities are able\\nto seamlessly transfer digital assets across blockchains by\\nutilizing Solana’s high-speed and low-cost features.\\nD. Layer 2 scaling solutions\\nBlockchain-based Web 3.0 will revolutionize the way people\\ntransact and transfer value with each other. However, with\\nits rapid development, scalability has become a bottleneck.\\nTo solve this problem, scaling solutions developed on top of\\nLayer 1 blockchain networks, also called Layer 2 solutions,\\nare widely adopted. The purpose is to improve the scalability,\\nefficiency, privacy, and other characteristics of the underlying\\nblockchain network. There are several types of Layer 2 so-\\nlutions. For example, rollups, state channels, and sidechains.\\nBelow is an overview of Layer 2 solutions as shown in Fig. 10.\\n1) Rollups: Rollups allow transactions to be executed out-\\nside the Layer 1 blockchain. When consensus is reached on\\nthe transaction data, the data will be posted back to the\\nmain chain and secured by the security mechanism of the\\nunderlying blockchain. Specifically, there are two types of\\nrollups in terms of security models: optimistic rollups and\\nzero-knowledge (ZK) rollups [61]. An optimistic rollup is\\nan approach used to scale the Ethereum network by moving\\nsome computations and state storage off-chain. In ZK rollups,\\ntransactions are bundled into batches and executed outside\\nthe Layer 1 blockchain. The summary of changes will be\\nsubmitted to the main blockchain, rather than submitting each\\ntransaction individually. To guarantee the correctness of the\\nchanges, they provide proof of validity by utilizing zero-\\nknowledge proofs. The rollup paradigm is based on a final\\nsettlement on the Layer 1 blockchain. It requires rollups to post\\na copy of every transaction to the Layer 1 blockchain. In order\\nto address the data availability bottleneck, it is necessary to\\ncreate dedicated space for rollups. For example, Danksharding\\nscales Ethereum for high throughput by scaling the number of\\nbinary large objects (a.k.a. blobs) attached to blocks from 1\\nto 64 [62].\\n2) State channels: State channels enable participants to\\nsecurely transact off-chain by utilizing multi-signature con-\\ntracts. Then, two on-chain transactions that can open and close\\nthe channel are submitted for final settlement with the main\\nnetwork [61]. State channels represent a more generalized\\nform of payment channels. They can be utilized not only for\\npayments but also for any state updates on the blockchain, such\\nas changes within a SC. The most well-known examples are\\nBitcoin’s Lightning network and Ethereum’s Raiden network.\\nThe Lightning Network is a decentralized payments network\\nthat runs on top of the Bitcoin blockchain. It greatly improves\\nthe scalability of the Bitcoin blockchain by allowing users\\nto make multiple transactions off-chain without broadcasting\\neach transaction to the entire network. Near-instant and low-\\ncost Bitcoin settlements can be achieved between participants.\\nThe Lightning Network uses a two-party, multi-signature Bit-\\ncoin address (channel) to store funds. It requires both parties\\nto agree on the new balance to spend funds from the channel.\\nIn this case, the network allows dynamic participation so\\nthat payments can be made through a network of channels\\n[63]. Similarly, the Raiden network is Ethereum’s version\\nof Bitcoin’s Lightning Network. It enables the transfer of\\ntokens that are compliant with the ERC20 standard on the\\nEthereum blockchain. This is achieved through the use of\\ndigital signatures and hash-lock (i.e., balance proof). Digital\\nsignatures ensure that neither party can exit any value transfers\\ncontained therein, as long as at least one participant decides\\nto submit it to the blockchain. The Raiden balance proof is a\\nprotocol executed by the Ethereum blockchain. Since no one\\nother than these two participants can access the tokens stored\\nin the payment channel SC, the Raiden balance proof is as\\nbinding as on-chain transactions [64].\\n3) Sidechains: A sidechain is an independent blockchain\\nthat is linked to the main blockchain. It allows assets to move\\nbetween the sidechain and the main chain. The purpose is to\\nsolve scalability issues by offloading some of the validation\\nand transaction processing to the sidechain [61]. Sidechains\\ninteract with Layer 1 blockchains in two primary ways: the\\nfirst way is to provide a mechanism (i.e., a cross-chain bridge)\\nfor bridging assets from Layer 1 blockchain to their respective\\nsidechain; the second method involves periodically publishing\\nits state snapshots (i.e., highly compressed summaries of the\\nbalances of all accounts on its network) to Layer 1 blockchain\\nnetwork [65]. Examples of sidechains include the Liquid net-\\nwork and Polygon Proof of Stake (PoS). The Liquid Network\\nis a sidechain of the Bitcoin blockchain. It facilitates fast,\\n11\\nApplications of\\nBlockchain in \\nWeb 3.0\\nShared \\nDatabase [69]\\nInteroperability\\nPlatform\\xa0[70]\\n\\xa0Power Transaction\\nPlatform\\xa0[71]\\nBlockchain-Semantic\\nFramework [72]\\nData Sharing\\nPlatform [75]\\nSemantic\\nExchange [76]\\nPrivacy-Preserving\\nComputing [77]\\nDecentralized \\nStorage [68]\\nSocial \\nNetwork [73]\\nAuthentication\\nMechanism [74]\\nRadio Access\\nNetwork [78]\\nTransition \\nFramework [79]\\nFig. 11. Applications of blockchain in Web 3.0.\\nsecure, and private settlement of digital assets. The Liquid-\\nversion Bitcoins are backed by an equal amount of Bitcoins\\non the main chain, ensuring verifiable 1:1 backing. This allows\\nusers to trade using the speed and confidentiality of the Liquid\\nnetwork [66]. Polygon PoS is a 3-layer architecture sidechain\\nof the Ethereum blockchain to connect Ethereum-compatible\\nblockchain networks. The Ethereum layer consists of a set of\\nstaking SCs on the main chain, allowing users to stake tokens\\nto join the system. The Heimdall layer is a validation layer,\\nconsisting of PoS Heimdall nodes that run in parallel to the\\nmain chain. These nodes monitor the staking SCs and commit\\ncheckpoints from Polygon to the Ethereum main chain. The\\nBor layer is a layer for producing sidechain blocks. It is used\\nto aggregate transactions into blocks for periodic verification\\nby Heimdall nodes [67].\\nE. Practical applications of blockchain in Web 3.0\\nIn this section, we further explore the applications of\\nblockchain in Web 3.0, as shown in Fig. 11, to provide\\nintuitions on how to leverage blockchain in the Web 3.0\\necosystem. Benet in [68] designed a P2P distributed file\\nstorage system called InterPlanetary File System (IPFS). It\\nis a modular suite of protocols for storing and sharing data,\\naiming to store files by connecting computing devices around\\nthe world to the same file system. It plays a crucial role as\\nthe file storage solution underlying the decentralized vision of\\nWeb 3.0. Compared to traditional centralized storage solutions,\\nIPFS uses a global P2P network, allowing for permanent\\nand immutable data storage without single points of failure.\\nIts content addressing and distributed hash table technology\\nensure fast and reliable file retrieval. Drakato et al. in [69]\\nproposed Triastore, a blockchain database system that can\\nstore and retrieve ML models from the blockchain. To this\\nend, Triastore introduced Proof of Federated Learning for a\\nglobal model, and Blockchain Consensus for committing the\\ngenerated model data to a blockchain database. In the context\\nof Web 3.0, the authors claimed that Triastore has the potential\\nfor big data analytics in telecommunications and smart city\\napplications. Liu et al. in [70] proposed an interoperability\\nplatform, HyperService, that provides interoperability and\\nprogrammability between blockchains in order to make the\\nWeb 3.0 ecosystem connected. In particular, HyperService is\\npowered by a unified programming framework for developers\\nand a secure cryptographic protocol for blockchain. A Web\\n3.0-based P2P platform, VA3, was developed by Chopra et\\nal. in [71] for electricity settlement at an individual level.\\nSpecifically, VA3 automates the measurement of power con-\\nsumption and production by feeding this data into a SC to\\nmodify the home router. Then, the SC could automatically\\nmanage electricity settlements. Lin et al. in [72] proposed\\na blockchain-semantic framework for Web 3.0, aiming to\\naddress the problem of unsustainable resource consumption\\nfor computation and storage due to the explosive growth of\\non-chain content and the growing user base. Specifically, an\\nOracle-based proof of semantic mechanism was introduced to\\nfacilitate on-chain and off-chain interactions while maintaining\\nsystem security. Additionally, a DL-based sharding mechanism\\nwas designed to improve interaction efficiency. Palanikkumar\\net al. in [73] proposed a decentralized social network system\\nimplemented using the Web 3.0 Library, which is a collection\\nof Ethereum JavaScript application programming interfaces\\n(APIs). This library provides functionalities to interact with the\\nEthereum blockchain. In this way, an Online Social Network\\n(OSN) service was created in a decentralized manner for\\ndemocratic self-management. Petcu et al. [74] proposed a\\nnovel authentication mechanism utilizing Ethereum blockchain\\ntechnologies, enabling the browser to interact with the user’s\\nsoftware and hardware wallets to implement user authen-\\ntication. With this approach, Web 3.0 authentication could\\nprovide enhanced security, privacy, and ownership of user\\ndata compared to existing authentication methods that rely\\non third-party authentication service providers. Razzaq et al.\\nin [75] proposed a Web 3.0 Internet of Things (IoT) data\\nsharing framework based on IPFS. Specifically, blockchain\\nand SCs are used to provide data security. Hybrid storage\\nis used to achieve secure data exchange. Additionally, access\\ncontrol policies are stored on-chain to ensure policy integrity\\nand allow for public auditing of any policy changes. Lin\\net al. in [76] proposed a blockchain-based framework for\\nsemantic exchange in Web 3.0, which aims to achieve fair and\\nefficient interactions. Specifically, it first tokenized semantic\\ndata as non-fungible tokens (NFTs). Trading strategies were\\nthen optimized via the Stackelberg game. Afterward, ZK proof\\nwas leveraged to allow the sharing of authentic semantic\\ninformation. Guo et al. in [77] proposed a privacy-preserving\\ncomputing architecture in Web 3.0. The main building blocks\\nare state channel and computing sandbox, used to ensure\\nsecure and reliable computation. In addition, the onion routing\\ntechnology was used to preserve user privacy. Qiu et al. in\\n[78] proposed a framework, called FogBC-RAN, to establish\\na secure and decentralized communication system in Web 3.0.\\nTo this end, a cross-chain information transmission process\\nwas introduced for efficient cost-sharing. Additionally, a com-\\n12\\nputational offloading strategy using matching game theory was\\nused to minimize the system cost of computationally intensive\\nWeb 3.0 applications. Yu et al. in [79] proposed a framework\\ncalled WebttCom that allows for a transition from Web 2.0\\nto Web 3.0. The proposed framework can build a connection\\nbetween traditional Web 2.0 applications and Web 3.0 plat-\\nforms, ensuring data privacy and governance while improving\\ndevelopment efficiency. Specifically, an interpreter mechanism\\nwas used to aggregate and process requests between the Web\\n2.0 and Web 3.0 domains.\\nF. Summary and insights\\nOff-chain, cross-chain, and layer 2 solutions play a vital role\\nin the blockchain-based Web 3.0 system. Off-chain technology\\ngreatly expands Web 3.0’s ability to provide solutions to the\\nreal world by connecting on-chain and off-chain resources.\\nCross-chain technology provides interoperability for isolated\\nblockchain platforms, jointly promoting the development of\\nthe Web 3.0 ecosystem. Layer 2 solutions improve the scalabil-\\nity of blockchain-based Web 3.0 by offloading computationally\\nintensive operations. These technologies demonstrate effec-\\ntiveness in their respective focuses while taking into account\\nother aspects, such as decentralization, security, and privacy.\\nHowever, it is challenging to make effective tradeoffs. It is\\nimportant to first identify key concerns and then develop a\\nlogical strategy. For example, scalability may take precedence\\nover decentralization and security in DeFi, whereas security\\nand decentralization are more important than scalability in the\\nNFT market.\\nIV. AI FOR WEB 3.0: AN INTELLIGENT AND SEMANTIC\\nWEB\\nAI plays a crucial role in realizing a more decentralized,\\nsecure, and user-centered Web 3.0. By effectively integrating\\nAI technology into various areas of the Web 3.0 ecosystem, it\\nis promising to bring about an era of more intelligent, efficient,\\nand personalized digital experiences. However, the dominance\\nof centralization has been a longstanding characteristic of AI-\\nbased solutions due to their heavy reliance on centralized\\nmassive datasets and computing resources. Traditional AI\\ntechniques typically require aggregating large amounts of data\\nand performing computationally intensive training processes.\\nThis has inevitably led to a centralization of both the data and\\ninfrastructure that AI advances have been built upon up to this\\npoint. In contrast, Web 3.0 aims to build a decentralized archi-\\ntecture with no single point of control, raising novel challenges\\nfor integrating AI in a manner that is distributed, privacy-\\npreserving, and aligned with the vision of decentralization.\\nAs we explore the decentralized landscape of Web 3.0, it\\nis necessary to consider how AI can adapt its centralization\\ntendencies in order to flourish in this emerging environment.\\nIn this section, we first show the relevance of AI and\\nWeb 3.0. Then we illustrate how generative AI and Web 3.0\\ncomplement each other through an in-depth study of generative\\nAI. Afterward, we will introduce the practical applications of\\nAI in Web 3.0. Finally, the summary and insights are provided.\\n1\\nHighly Targeted Content\\nAI is used in Web 3.0 to deliver personalized and targeted\\ncontent and reduce irrelevant advertising.\\n2\\nAutomation, personalization, and content creation through\\nAI will significantly reduce manual tasks in Web 3.0.\\nAutomated Content Creation\\n3\\nWeb 3.0 facilitates online community building by\\nanalyzing user interests via AI to enable collaboration.\\nIncreased Community Building\\n4\\nAI powers personalized Web 3.0 by optimizing user interfaces\\nand delivering targeted results for an enhanced experience.\\nBetter User Experience\\n5\\nSmart contracts enabled by AI can simplify data management\\nby facilitating a consistent, high-quality decentralized database.\\n\"Smarter\" Contract\\nFig. 12. Relevance of AI to Web 3.0.\\nA. Relevance to Web 3.0\\nWeb 3.0 represents an intelligent and personalized Web with\\nthe goal of providing users with a more seamless experience.\\nAI can drive the applications of Web 3.0 to handle more\\ncomplex tasks due to its ability to process and analyze large\\namounts of data. The high correlation between AI and Web\\n3.0 can be seen from the following key aspects as shown in\\nFig. 12.\\n1) Highly targeted content: Web 3.0 is powered by AI\\ntechnology to provide consumers with more personalized\\nand targeted advertising. With the ability to understand user\\nintent and preferences, Web 3.0 allows for more effective\\nand efficient marketing campaigns. As a result, annoying and\\nirrelevant advertisements can be eliminated. Only the most\\nrelevant content is available to customers. For example, in\\ne-commerce, recommender systems make personalized prod-\\nuct recommendations by analyzing users’ browsing behavior,\\nsearch history, and purchase history.\\n2) Automated content creation: Web 3.0 allows for the\\ncreation of smarter, connected, and interactive web experiences\\nthat automate more complex tasks and reduce the need for\\nhuman intervention. In Web 3.0, automated content creation\\nwill become more prevalent through the use of AI technolo-\\ngies. High-quality and dynamic content can be generated based\\non user queries and preferences. For example, ChatGPT not\\nonly helps users generate personalized product descriptions\\nand marketing materials but also optimizes them in a real-\\ntime interactive manner.\\n3) Increased community building: Web 3.0 is expected to\\nfoster community building through the utilization of AI tech-\\nnologies. AI helps connect people with similar interests, skills,\\nand goals by analyzing user behavior and preferences, thereby\\ncreating more meaningful discussions and collaborations in\\n13\\nGPT-4\\nGPT-3\\nLaMDA\\nChinchilla\\nTongyi Qianwen\\nErnie 3.0 Titan\\nLLaMA\\nBloom\\nDialoGPT\\nNeural Networks\\nColab/Telegram\\nBloomBot\\nVicuna\\nErine\\nDingTalk\\nSparrow\\nBARD\\nBing\\nChatGPT\\nText Generation\\nAudio Generation\\nImage Generation\\nVideo Generation\\nCode Generation\\nArtwork\\nGeneration\\nTranslation\\nData Analysis\\nData Visualization\\nVirtual Assistant\\nMultimodal data\\nLLMs\\nChatBots\\nApplications\\nAudio\\nText\\nImage\\nVideo\\nAudio\\nText\\nImage\\nVideo\\nTransformer-based\\nModels\\nGAN-based Models\\nVAE-based Models\\nAutoregressive-based\\nmodels\\nFig. 13. Generative AI.\\nonline communities to increase engagement and build a sense\\nof community. In this way, the Web will be more interactive,\\nintelligent, and connected.\\n4) Better user experiences: The convergence of Web 3.0\\nand AI holds significant potential in enhancing the user\\nexperience. AI can deliver more precise and relevant results\\nto Web 3.0 users, as well as personalize their interfaces\\nto improve the usability and accessibility of Web 3.0. In\\norder to accomplish this goal, AI-enabled websites need to\\nclassify data and present information that is deemed useful\\nto individual users, providing a personalized and improved\\nnavigation experience. Users will search and find what they\\nneed more easily and precisely, making Web 3.0 applications\\nmore user-friendly. From this point of view, prioritizing user\\nexperience throughout the entire development of Web 3.0\\napplications will be more important than ever.\\n5) “Smarter” contract: In the era of Web 3.0, data man-\\nagement will be more important than ever as data becomes\\nmore complex and time-consuming to manage. Additionally,\\nthe nature of data ownership means that data will not be\\nmanaged on a central server. As a decentralized solution, SCs\\ncan produce a clean version of data by connecting multiple\\ndata sources. In particular, when combined with AI, SCs have\\ngreat potential to improve and simplify data management and\\navoid duplicate aggregation. If the underlying P2P network\\nof Web 3.0 is regarded as a unified database, AI-powered\\nSCs will facilitate the establishment of a consistent and high-\\nquality database.\\nB. Generative AI\\nGenerative AI has emerged as the most exciting technology\\nof AI advancement within two years. It empowers various\\napplications by creating new data that is similar to human-\\ngenerated data as shown in Fig. 13. Notably, generative AI\\nhas gained significant interest in semantic communication\\n[80]–[84] and edge network [85]–[89]. The rapid growth is\\nattributed to the creation of large language models (LLMs)\\nthat may have billions or even trillions of parameters [90],\\n[91]. Unlike traditional AI, which focuses on analyzing and\\nprocessing existing data to accomplish tasks such as classifica-\\ntion and clustering, generative AI creates new and original data\\nby learning patterns and features from existing datasets. With\\ngenerative AI, Web 3.0 will be more creative and engaging\\nthan ever before. The development cycle of decentralized\\napplications (dApps) will be dramatically shortened to help\\ncompanies stay ahead of the competition. In addition, gen-\\nerative AI has the potential to fundamentally change the\\nway a wide range of traditional industries operates due to\\nthe highly automated creative process. In the entertainment\\nindustry, generative AI has brought huge disruption to the film\\nindustry.\\n1) Underlying technologies: Natural Language Processing\\n(NLP) and Computer Vision (CV) are two distinct subfields\\nof AI. The former focuses on the interaction between com-\\nputers and human language. The latter focuses on enabling\\nmachines to interpret and understand visual information. Both\\nare important components of generative AI.\\n14\\n• NLP: NLP is dedicated to empowering computers to\\ncomprehend and react to text or speech input in the\\nsame manner that humans respond to their own text or\\nspeech. NLP makes it possible for computer algorithms\\nto effectively summarize massive volumes of information\\nand translate text across languages and spoken commands\\n[92]. This is critical in Web 3.0 as natural language is\\nambiguous, making it difficult for algorithms to accu-\\nrately recognize and process text or audio data. With\\nthe increase in computing power and a large amount\\nof decentralized data available in Web 3.0, computers\\nwill be intelligent enough to interpret information to\\nprovide faster and more precise results, which makes\\nmachines virtually indistinguishable from human users.\\nImagine that a voice assistant in Web 3.0 is able to\\nprocess all the unstructured data on the network. They\\nwill comprehend the meaning of anything on the web\\nand deliver a thorough answer rather than merely replying\\nwith Wikipedia information and reading Web 2.0 articles\\n[93]–[95].\\n• CV: CV aims to use computers to extract features from\\na large number of visual inputs and then provide rec-\\nommendations. The computer will develop the ability to\\ndistinguish between images if enough data is supplied\\ninto the model. This will be greatly met in Web 3.0\\nwith the explosive growth of decentralized data volume.\\nConvolutional neural networks (CNN)-type algorithms\\nand recurrent neural networks (RNN)-type algorithms are\\nthe pillars of computer vision [96], [97]. A CNN aids\\na computer’s vision by breaking down an image into\\nlabeled pixels which will be further used to perform\\nconvolutional operations. Similarly, RNN techniques are\\napplied in video applications to assist computers in\\nunderstanding the connections between images within a\\nsequence of frames. The development of self-driving cars\\nrelies on computer vision to interpret visual inputs from\\ncar cameras and other sensors, in order to understand the\\nenvironment. It is crucial for distinguishing other objects\\non the road, such as various automobiles, traffic signs,\\npedestrians, and all other visual information.\\n2) Types of generative AI: Generative AI is a form of\\nunsupervised learning, which means that the model learns to\\ngenerate new data samples without being explicitly told what\\nthe correct output should be. Instead, the model is trained on a\\nlarge dataset of examples and learns to capture the underlying\\npatterns and structures in the data. There are four main types\\nof generative models as shown in Fig. 13, including trans-\\nformers, generative adversarial networks (GANs), variational\\nautoencoders (VAEs), and autoregressive models.\\n• Transformers: A transformer model is a neural network\\nthat understands contextual meaning by analyzing re-\\nlationships and patterns in sequential data [98]. It is\\nbased on an attention mechanism to selectively prioritize\\ndifferent parts of the input sequence to produce relevant\\noutputs. It consists of an encoder and a decoder. The\\nencoder processes input sequences to generate latent\\nrepresentations that capture semantic information. One of\\nthe key advantages is its ability to process input sequences\\nin parallel, which makes it much faster than traditional\\nRNNs for long sequences. This, together with its effec-\\ntiveness in capturing long-range dependencies (a subtle\\nway of detecting the interactions and interdependencies\\nof even distant data elements in a series of data), makes\\nthe transformer model a fundamental model driving a\\nparadigm shift in AI.\\n• GANs: One of the key breakthroughs in the development\\nof generative AI was the introduction of GANs [99]. A\\nGAN involves a generator and a discriminator. These two\\nnetworks oppose each other, using a two-player game-like\\napproach to generate new data. The generator generates\\nnew data based on patterns it learns from the training\\ndataset while the discriminator evaluates the authenticity\\nof the generated data. This adversarial training approach\\nallows the generator to generate data that is indistinguish-\\nable from real data, while the discriminator has enhanced\\ncapabilities in identifying the generated data.\\n• VAEs: A VAE is a neural network for unsupervised\\nlearning of complex data distributions [100]. It involves\\ntwo sub-processes: the encoder maps input data into\\na latent space; the decoder then draws samples from\\nthe data distribution in this latent space to generate the\\noutput. Unlike traditional autoencoders, VAEs introduce\\nrandomness into the encoding process, which allows them\\nto be used in generative AI for generating new data with\\nsimilar patterns to the input data. Furthermore, they could\\nbe combined with other generative models to create more\\nadvanced and powerful generative models.\\n• Autoregressive models: An autoregressive model is a type\\nof statistical model used for forecasting future values in\\ntime series data based on prior observations [101]. It\\nis assumed that there is an auto-correlated structure in\\nthe data where the current value of a time series can\\nbe modeled as a linear combination of prior values in\\nthe series. The term “autoregressive” comes from the\\nfact that these models involve regressing a time series\\ndata to its own past values. However, autoregressive\\nmodels are primarily used for stationary time series with\\nconstant mean and variance over time. Non-stationary\\ntime series may require transformation before applying\\nan autoregressive model.\\nC. Generative AI for Web 3.0\\nWeb 3.0 is envisioned to transform the Internet into a\\nsemantic, intelligent, and user-centric platform where informa-\\ntion is interconnected through semantic understanding. Gener-\\native AI plays a crucial role in realizing this vision. There are\\nfour key drivers for integrating generative AI into Web 3.0,\\ni.e., truly bringing semantics to Semantic Web 3.0, efficiently\\ndeveloping Web 3.0, easily performing data analysis, and\\nproactively providing security assistance.\\n1) Semantic understanding: Web 3.0 proposes a digital\\nrealm where machines can interact and communicate with\\nboth other machines and human users. However, in order for\\nmachines to precisely and effectively communicate, they must\\n15\\nfirst understand the meaning and subtle differences of digital\\ninformation. This is why generative AI will be the cognitive\\nlayer of Web 3.0 as illustrated in Fig. 1, driving machines to\\ncomprehend various types of content through DL algorithms.\\nFor instance, text, audio, images, and video as shown in\\nFig. 13. An increasing number of practical applications also\\nhighlight the advantages of incorporating semantic capabilities\\ninto the Web 3.0 ecosystem. For example, Alice is the first\\nintelligent non-fungible token powered by GPT-3, allowing\\nit to adjust how it interacts with people based on each new\\ninteraction [102]. Pregelj in [103] introduces a ChatGPT-based\\nWeb 3.0 plugin that enables wallet creation, on-chain queries,\\nand on-chain operations directly from prompts. SuperCool AI\\nis a digital marketplace based on generative AI that generates\\nand trades NFTs via prompts [104].\\n2) Efficient development: To realize the decentralized and\\nintelligent vision of Web 3.0, SCs are indispensable because\\nmost of the core applications and services in Web 3.0 are built\\non SCs. These include the creation and trading of NFTs, the\\ndevelopment of dApps in the DeFi field, and the formulation of\\nDAO rules, etc. Generative AI can revolutionize the way SCs\\nare created as they are essentially self-executing contracts with\\nterms and conditions programmed directly into the codes. By\\nunderstanding context and expected outcomes, generative AI\\ncan advance the Web 3.0 ecosystem by efficiently developing\\nSC code that ensures compliance with predefined rules. For\\nexample, Web3-GPT is a chat assistant based on GPT4 that\\ncombines LLMs and AI agents, aiming to revolutionize the\\ndevelopment and deployment process of SCs [105]. ETHGPT\\nis a development toolkit that supports semantic search to\\nprovide professional tools and assistance to support the rapid\\ndevelopment of the Web 3.0 ecosystem [106]. FlashGPT can\\nefficiently generate and deploy secure and reliable Solidity SCs\\nto a variety of Layer 1 and Layer 2 solutions through simple\\ninteractions [107].\\n3) Data analysis: In the user-centric Web 3.0 ecosystem,\\ngenerative AI will play an important role in simplifying data\\nanalysis. Through natural language interfaces, generative AI\\ncan quickly and accurately analyze complex datasets based\\non simple prompts from users, providing users with valuable\\ninsights. In this way, generative AI eliminates the need for Web\\n3.0 users to master relevant programming languages or ad-\\nvanced data analysis knowledge by automating data processing\\nbehind the scenes, lowering the barrier to participating in the\\nWeb 3.0 economic ecosystem. For example, TokenGPT aims\\nto simplify complex Web 3.0 investing by using generative\\nAI to review SCs to conduct a comprehensive analysis of the\\nmarket [108]. CoinGPT is a generative AI-driven data analysis\\ntool that allows users to connect their crypto wallets to analyze\\nthe transaction history of NFTs and other cryptocurrencies to\\nimprove transaction performance [109]. Defi-Companion is a\\nChatGPT-based bot that assists Web 3.0 users in querying data\\nfrom endpoints, performing data analysis, and identifying DeFi\\nopportunities [110].\\n4) Security assistance: Security is critical to the Web 3.0\\necosystem. The P2P architecture, consensus mechanism, and\\ncryptographic protocol of blockchain technology provide the\\nfirst level of security, preventing 51% attacks, double spends,\\nSybil attacks, etc. However, these guarantees are not sufficient\\nfor complex Web 3.0 systems. Various security and reliability\\nissues may still arise. Generative AI is a promising solution\\nthat provides additional protection for Web 3.0 users and their\\ndata through continuous monitoring of SCs. For example,\\nQuantstamp can secure transactions and build user trust by\\nautomatically auditing SCs through generative AI to uncover\\nvulnerabilities that may be missed by traditional methods\\n[111]. ChainSecurity uses a combination of generative AI and\\nformal verification methods to detect vulnerabilities in SCs\\n[112]. Secure Semantic Snap, a ChatGPT-based MetaMask\\nSnap, can semantically understand the target contract to protect\\nusers from malicious SCs [113].\\nD. Web 3.0 for generative AI\\n1) Current solution of generative AI: Data and computing\\npower are considered to be the two major elements that\\npromote the development of AI. The development of these\\ntwo elements has also become a booster for the explosion of\\nAI technology. Based on the generative models, generative AI\\ntypically requires a significant amount of computing power\\nand data. This is due to the fact that generative AI models\\nare built on intricate mathematical algorithms, which need to\\nanalyze enormous datasets to recognize patterns and generate\\nnew content. In addition, training these models is compu-\\ntationally intensive, particularly for models that deal with\\nhigh-resolution images or real-time processing. Today, LLMs\\nare booming. However, the scale of LLMs has dramatically\\nincreased which could be a major obstacle for the majority of\\norganizations. The high computational demands also restrict\\nits use in computing environments with constrained resources,\\nsuch as mobile devices or edge computing systems.\\nThe current solution is cloud computing, as it provides the\\nnecessary computing resources and infrastructure required to\\ndevelop and deploy chatbots at scale. Different chatbots can be\\ndeployed on different cloud computing platforms, depending\\non their specific needs and requirements. For example, Chat-\\nGPT is running on Microsoft Azure while Bard is executing\\non the Google Cloud platform. The cost of training such\\nmodels is growing exponentially, which is unacceptable for\\nmany organizations. Ultimately, the tech giants will continue\\nto dominate the market for generative AI, meaning that the\\nvalue generated by this phenomenal field will be drawn by\\nthese large companies. This is still the typical way of operating\\nin the Web 2.0 era, which is large-scale and highly centralized.\\n2) Web 3.0 as a solution: In the trend of decentralization,\\ncloud computing solutions represent a compromise for the\\nemerging industry. Web 3.0 provides a decentralized coordi-\\nnation platform that will facilitate unprecedented innovation\\nand the adoption of generative AI. The enormous amount\\nof data available for research, development, and industrial\\nuse is one of the key factors enabling the rapid development\\nof generative AI. Accordingly, relevant solutions in this area\\nhave also received wide attention. For example, MedDAO is\\nan innovative decentralized autonomous organization (DAO)\\ndedicated to addressing the critical issue of the shortage\\nof medical images in training AI models within the global\\n16\\nData Source\\nData Sharing\\nDecentralized\\nComputing\\nToken-based\\nIncentives\\nInterpretability\\nWeb 3.0\\nGenerative AI\\nComputational \\nPower\\nWeb 3.0 Ecosystem\\nDecentralized\\xa0\\nStorage\\nData\\nFig. 14. Web 3.0 reduces the requirements for generative AI development.\\nhealthcare field. Specifically, MedDAO creates aggregated and\\ndecentralized datasets by providing an anonymous, encrypted,\\nand secure healthcare platform that incentivizes patients to\\ncontribute personal data [114]. A data-driven economy makes\\ndata the new gold. Correspondingly, computing power will\\nbe an important tool for contemporary “gold diggers”. Under\\nthe status quo of the technological monopoly of tech giants,\\nthe Web 3.0 ecosystem will effectively promote the broader\\ndevelopment of generative AI. Data-driven industries are no\\nlonger just limited to large technology companies. Small-scale\\ninstitutions and individuals will also benefit greatly, which is\\nconsistent with the vision of Web 3.0. Generally, how Web 3.0\\ncan solve the dual challenges of data and computing power\\nfaced by generative AI can be elaborated from several main\\naspects as shown in Fig. 14.\\n• Decentralized storage: Web 3.0 infrastructure can provide\\na more effective data storage solution. Instead of central-\\nized servers, data can be stored on computer networks. In\\naddition, there are technologies that allow for decentral-\\nized data storage such as the IPFS. In this way, generative\\nAI models can access data from various sources, reducing\\nthe burden on individual computers and thereby assisting\\nin solving the issues of data accessibility and availability\\nfor generative AI that the existing system confronts.\\n• Data provenance: Data provenance is a fundamental\\nconsideration in generative AI as it creates new data from\\nexisting data. Therefore, understanding the provenance of\\nthe training data is critical to assessing the quality and\\ntrustworthiness of the generated data. Web 3.0 enables the\\ncreation of a tamper-proof record of data provenance and\\ndata integrity. By ensuring that the data used to train AI\\nmodels is trustworthy and comes from a reliable source,\\nthe accuracy and quality of generative language models\\ncan be improved.\\n• Data sharing: Web 3.0 can effectively facilitate data\\nsharing as it provides accountability and transparency\\nregarding data access. Users will have absolute control\\nover their data, as they possess ownership of their per-\\nsonal data and digital identity through private keys that\\nare exclusively under their control. Through protocols\\nlike IPFS, users can choose which data to share and\\nwith whom. Additionally, the network allows for secure\\ndata sharing through technologies such as threshold secret\\nsharing [115]–[117] and revocable data sharing [118]–\\n[121]. This means individuals and organizations can\\nshare data to jointly train generative AI models through\\ncollaborative learning and secure multi-party computing\\nschemes without compromising their privacy.\\n• Decentralized computing: Web 3.0 enables decentralized\\ncomputing through the use of blockchain networks. By\\nleveraging the computing power of a network of decen-\\ntralized computers, Web 3.0 can provide a more efficient\\nand scalable computing environment for generative AI.\\nIn this case, instead of relying on a single, centralized\\nserver or data center to perform computational tasks,\\nblockchain-based networks can distribute computational\\ntasks across decentralized nodes coordinated by the Web\\n3.0 platform.\\n• Token-based incentives: Web 3.0 allows users to monetize\\ntheir data using SCs. This is a key feature of Web\\n3.0, where users can sell their data directly for profit\\nwithout the involvement of third parties. Small companies\\nand individuals will benefit from such a marketplace\\nplatform as it removes barriers, levels the playing field,\\nand promotes innovation. Additionally, idle computing\\npower could also be sold. GPUs used for gaming are\\ntypically utilized only a fraction of the time. Gamers can\\nbid and receive payment for their idle computing power\\nusing SCs. In this case, AI developers can utilize this\\ncomputing power to train and deploy their models.\\n• Interpretability: The interpretability of deep learning has\\nlong been a bottleneck. Deep learning-based generative\\nAI inherits this. Due to the dramatic increase in the size\\nof language models, interpretability has become more\\nimportant than ever. Web 3.0 allows all data processing\\nand decisions to be tracked via blockchain. In turn, the\\ngenerative paradigm of the data is analyzed in depth to\\nachieve a constant understanding of generative AI and\\nachieve effective control over it.\\n17\\nApplications\\n\\xa0of AI in \\nWeb 3.0\\nAnti-money Laundering [123]-[126]\\nReputation System [122]\\nFake News Detector [127]\\nAnomaly Detection [128]\\nOptimal Auction [129]\\nAssets Recommendation [130]\\nSocial Recommendation [131]\\nFig. 15. Applications of AI in Web 3.0.\\nE. Practical applications of AI in Web 3.0\\nIn this section, we further explore the applications of AI in\\nWeb 3.0 as shown in Fig. 15, to provide intuitions on how to\\nleverage AI in the Web 3.0 ecosystem. Keizer et al. in [122]\\nintroduced the need for a decentralized trust and reputation\\nsystem on the Web 3.0 platform by discussing the trust issues\\ncaused by Web 3.0’s distributed shared services. Specifically,\\nthe paper proposed a framework based on deep reinforcement\\nlearning that allows reputation scores to be calculated in a\\ndecentralized manner while still being personalized for each\\nuser. Lorenz et al. in [123] proposed an active learning so-\\nlution to address the challenging problem of detecting money\\nlaundering activities in cryptocurrency transactions when there\\nis minimal labeled data available. Specifically, active learning\\nwas applied to develop an efficient classifier to reduce the\\nnumber of labels required. This is achieved through an iterative\\nsampling strategy of the most informative, yet unlabeled\\nexamples from the pool of data points. Weber et al. in [124]\\nexplored the potential of using ML for the anti-money laun-\\ndering of cryptocurrencies. The goal was to enable financial\\nforensics by analyzing open data on blockchains despite the\\nchallenges posed by the anonymity of cryptocurrencies. The\\nmain contribution of this article was to open source the Elliptic\\ndataset and provide benchmark methods to predict the binary\\nclassification of illegal transactions. Alarab and Prakoonwit\\nin [125] developed a classification model that utilizes a\\ncombination of long-short-term memory (LSTM) and graph\\nconvolutional network (GNN) to classify illicit transactions in\\nthe Elliptic Bitcoin dataset based only on transaction features.\\nBy studying different acquisition functions under the same\\nexperimental settings, the proposed model could achieve an\\naccuracy of 97.77%. Lo et al. in [126] proposed Inspection-\\nL, a novel GNN framework for detecting money laundering\\nactivities in the Bitcoin network. At its core, Inspection-\\nL combined a self-supervised Deep Graph Infomax and a\\nsupervised Random Forest to learn topological information\\nand node characteristics within the transaction graph for the\\npurpose of identifying illegal transactions. The framework\\nshowed the potential for identifying suspicious financial activ-\\nities. Unzeelah et al. in [127] proposed an AI-powered method\\nto build a secure, reliable, and efficient platform in Web 3.0\\nto address the issues of misleading content and fake news\\nspreading on current platforms. To this end, NLP technologies\\nand ML models were implemented. For example, LSTM\\nwith Word2Vec and GloVe were used for word embeddings.\\nAdditionally, the combination of the Ethereum blockchain with\\nthe IPFS technique was utilized to decentralize the system and\\nenable off-chain storage. Kim et al. in [128] presented a novel\\nsecurity mechanism using blockchain network traffic statistics\\nas a metric for identifying malicious events. Specifically, a data\\ncollection engine periodically generated multi-dimensional,\\nreal-time data streams by monitoring underlying blockchain\\nactivities. Afterward, an anomaly detection engine was used\\nto detect anomalies from the generated data instances based\\non One-class Support Vector Machine or AutoEncoder. Xu et\\nal. in [129] introduced a quantum blockchain-powered Web\\n3.0 framework to provide information-theoretic security for\\ndecentralized data transmission and payment to cope with the\\nsituation that quantum computing subverts the conventional\\ncryptosystems. In particular, an optimal auction for NFT\\ntransactions based on quantum deep learning is proposed to\\nmaximize revenue with sufficient liquidity in Web 3.0. Yu et al.\\nin [130] proposed a framework for classifying referable non-\\nfungible tokens (rNFTs) using GNN. The goal was to provide\\nan effective recommendation system for Web 3.0 assets. First,\\nthe authors converted rNFT reference relationships into direct\\nacyclic graphs (DAGs). Then, the node and edge charac-\\nteristics were modeled based on rNFT metadata and token\\ntransactions. Afterward, GraphSage was modeled to contain\\nthe characteristics collected during the learning process. In this\\nway, the model combined considerations of graph topology\\nand attribute characteristics to enable supervised classification\\nof existing and incoming NFT nodes. Madhwal and Pouwelse\\nin [131] implemented a decentralized social recommendation\\nsystem, Web3Recommend, that aimed to generate balanced\\nrecommendations for trust and relevance on Web 3.0 plat-\\nforms. It addressed the challenges of generating recommen-\\ndations in decentralized networks that lacked a central author-\\nity and were vulnerable to Sybil attacks. Web3Recommend\\ncombined MeritRank (a decentralized reputation scheme that\\nprovides Sybil resistance) and SALSA (a personalized graph\\nalgorithm). Specifically, MeritRank added decay parameters\\nto SALSA to theoretically guarantee protection against Sybil\\nattacks. By integrating with Music-DAO, an open-source Web\\n3.0 music-sharing platform, the proposed system was shown\\nto generate personalized real-time recommendations.\\nF. Summary and insights\\nWeb 3.0 is a user-centric web where users can create and\\ntrade their digital assets. Generative AI and Web 3.0 have great\\npotential to reinforce each other. On one hand, Generative\\nAI lowers the barriers for ordinary users to enter the Web\\n3.0 world through its powerful API. Its semantic understand-\\ning capabilities allow users to easily create exclusive NFTs,\\nproviding a solid foundation for participating in the digital\\n18\\neconomy. On the other hand, Web 3.0 can alleviate Generative\\nAI’s huge demand for data and computing power. In this way,\\nlightweight, personalized, and even decentralized generative\\nAI will become possible. Despite these promising aspects, for\\ngenerative AI to be effectively and securely integrated into\\nWeb 3.0 environments, challenges around bias and lack of\\nexplainability need to be addressed. Moreover, there is an\\nurgent need for effective storage and computing solutions to\\nsupport the sustainable development of Web 3.0.\\nV. EDGE COMPUTING FOR WEB 3.0: AN\\nINTERCONNECTED AND UBIQUITOUS WEB\\nWeb 3.0 is expected to be an interconnected and ubiquitous\\nweb that is accessible to everyone and anywhere at any time.\\nWith the rise of IoT devices and the increasing need for low-\\nlatency and real-time data processing, edge computing has\\nbecome an important part of the Web 3.0 ecosystem. Edge\\ncomputing is essentially a distributed computing paradigm in\\nwhich computing services occur at the edge of the network\\nas opposed to being performed in centralized data servers.\\nUsers can benefit from faster service via edge computing by\\nbringing computing resources and data storage closer to where\\nusers actually consume the data.\\nIn this section, we will first illustrate the close correlation\\nbetween edge computing and Web 3.0. Then we will explore\\nthe integration of edge computing and other cutting-edge tech-\\nnologies to promote the development of Web 3.0. Specifically,\\nwe proposed two solutions for decentralized storage and com-\\nputing. Afterward, we will introduce the practical applications\\nof edge computing in Web 3.0. Finally, the summary and\\ninsights are provided.\\nA. Relevance to Web 3.0\\nWeb 3.0 is a network of ubiquitous connectivity that aims\\nto create a collaborative platform that is accessible to anyone,\\nanywhere, and anytime. The decentralized infrastructure of\\nedge computing is highly compatible with this vision of Web\\n3.0. Specifically, edge computing can support Web 3.0 in the\\nfollowing aspects as shown in Fig. 16.\\n1) Decentralized storage and computing: Edge computing\\nplays a crucial role in facilitating decentralized storage and\\ncomputing in the Web 3.0 ecosystem. Users are able to\\nstore and process data in edge devices without relying on\\ncentralized servers. This increases users’ control over their\\ndata. In addition, edge computing can distribute storage and\\ncomputing tasks across edge devices, making Web 3.0 more\\nscalable and more resilient [132]. In this way, users can also\\nshare or monetize their idle storage space and computing\\npower on the Web 3.0 platform, which contributes to the\\nrealization of data ownership and fair incentives in Web 3.0.\\n2) Reduced latency: Edge computing can significantly re-\\nduce the latency of Web 3.0 applications, improving the overall\\nperformance of the Web 3.0 ecosystem. Edge devices can pro-\\ncess data and perform tasks close to the data source, reducing\\nthe need for network transmissions [133]. This is important\\nfor Web 3.0 applications as they typically require real-time\\ninteractions. With the proliferation of 5G, fast communication\\nto distribute data and computing power across edge\\ndevices, enhancing scalability and resilience\\nDecentralized storage and computing:\\xa0\\nReduced latency:\\nto process data and perform tasks close to the data\\nsource, reducing the need for network transmissions\\nEnhanced security and privacy:\\xa0\\nto minimize the need to interact with centralized\\nservers by locally\\xa0storing and processing data\\nGreater availability:\\nto enable resilient and accessible Web 3.0 via reduced\\ntransmission distance, local data processing, etc.\\nto reduce the usage of bandwidth and network\\nresources, lowering the network costs\\nHighly cost-effective:\\xa0\\nFig. 16. Relevance of edge computing to Web 3.0.\\nwith edge devices has been greatly improved. Users can get\\nfast responses from Web 3.0 applications running on edge\\ndevices. Therefore, with the help of edge computing, the user\\nexperience can be greatly enhanced, driving the widespread\\nadoption of Web 3.0.\\n3) Enhanced security and privacy: In the architecture of\\nedge computing, the natural isolation of edge devices improves\\nthe overall security and privacy of the Web 3.0 ecosystem. In\\nedge computing, data is stored and processed locally on edge\\ndevices, minimizing the need for data to travel to and from\\ncentralized data servers. This reduces the risk of data being\\ncompromised during transmission. In addition, distributed data\\nstorage and processing across a wide range of edge devices\\nprotects data from a single point of failure. As data is frag-\\nmented and stored on multiple edge devices, an attacker would\\nneed to simultaneously compromise a significant number of\\ndevices to access or tamper with the information, which\\nis challenging. For example, in the well-designed Web 3.0\\necosystem with Byzantine fault tolerance, an adversary might\\nneed to corrupt more than 33% of the devices to attack the\\nsystem. Otherwise the Web 3.0 ecosystem can continuously\\nprovide services. Moreover, since data is stored and processed\\non edge devices, without being collected by the centralized\\ndata servers, data privacy can be enhanced.\\n4) Greater availability: The Web 3.0 ecosystem needs to\\nfunction regardless of connectivity. The architecture of edge\\ncomputing can provide the resilience to prevent a single point\\nof system failure. In addition, edge computing allows data\\nto be stored and processed locally on edge devices close to\\nwhere the data is generated. This can significantly shorten the\\ndistance of data transfer. Moreover, edge computing allows\\nlocal edge devices to perform data preprocessing, content\\ncaching, and load balancing. This reduces the amount of\\ndata that needs to be transferred over a constrained network.\\nThese three aspects improve the availability of the Web 3.0\\necosystem as well as the accessibility of its applications.\\n5) Highly cost-effective: Mass adoption of Web 3.0 will\\nbenefit from a variety of applications. Edge computing pro-\\n19\\nvides a more cost-effective solution for application develop-\\nment and deployment by allowing businesses or individuals to\\nutilize edge devices. Specifically, edge computing enables the\\nutilization of existing client devices, thereby eliminating the\\nrequirement for costly infrastructure. As such, the development\\nof edge applications requires less upfront equipment invest-\\nments and deployment time. Moreover, with edge computing,\\nbusinesses can optimize their IT costs by processing data\\nlocally rather than in the cloud or large data centers [134],\\n[135]. In the Web 3.0 ecosystem, enterprises will benefit from\\nutilizing edge computing infrastructure to reduce dependence\\non cloud providers, resulting in lower workloads and faster\\ncontent delivery. For example, MadeiraMadeira, a leading\\nBrazilian retailtech, has significantly reduced its operating\\ncosts by offloading up to 90% of transmitted data to edge\\ncomputing resources [136].\\nB. Integration of edge computing and blockchain: a storage\\nsolution for Web 3.0\\nEdge computing and blockchain are separate but inter-\\ndependent technologies in Web 3.0. Edge computing can\\nprovide the infrastructure for blockchain nodes to store and\\nverify transactions. Blockchain, on the other hand, can be\\ntruly decentralized by creating an open and secure computing\\nenvironment. Since both edge computing and blockchain are\\ndeveloped based on the concept of decentralized and dis-\\ntributed networks, they can become a powerful combination\\nby complementing each other [137], [138]. The main benefit\\nof this combination is that it enables secure communication\\nand data processing, including data storage and computation,\\nwithout the need for centralized servers. In this section, we\\nwill discuss in-depth how the integration of edge computing\\nand blockchain can provide a decentralized storage solution\\nfor Web 3.0 applications that require high performance, low\\nlatency, secure, and decentralized storage. Specifically, we will\\nfirst introduce the main building blocks. Then, we will parse\\ntheir functionalities to propose an edge storage solution.\\n1) Building blocks: The proposed decentralized storage\\nsolution consists of four main functional modules: network\\narchitecture, incentive mechanism, data integrity, and access\\ncontrol. These modules play a vital role in ensuring the\\neffectiveness and security of the storage system.\\n• Network architecture: Edge nodes act as storage nodes\\nwhile edge devices act as data centers. These edge nodes\\nare registered on the blockchain network in a specific\\nway to provide excess storage space that can be used by\\nthe storage network. For example, a deposit is required\\nto complete registration on the Ethereum network. When\\ndata needs to be stored, the data is distributed to avail-\\nable edge nodes for redundant storage. The reliability\\nof storage is guaranteed by the blockchain-based token\\nsystem. Blockchain networks run in parallel to act as\\nadministrators. Data is hash-mapped to corresponding\\nedge node locations for tracking and maintenance. In\\naddition, the blockchain strictly enforces the access con-\\ntrol mechanism and verifies the integrity of the data.\\nIncentives are made by tracking and monitoring the\\namount of storage provided by each edge node and the\\nintegrity of the data. Users and dApps interact with the\\nstorage network through APIs that communicate with\\nthe blockchain network. Specifically, edge nodes provide\\na decentralized storage layer. Blockchain manages the\\nstorage network and enforces policies. The API acts as\\nthe interface between users and dApps. The key is that\\nthis architecture combines the advantages of blockchain\\nwith the distributed resources of edge computing.\\n• Incentive mechanism: An important component of this\\nstorage solution is the incentive mechanism that rewards\\nedge nodes for providing storage. An effective incentive\\nmechanism can solve the information asymmetry problem\\nbetween users and the network [139]. When an edge node\\ninitially registers to join the network, it needs to deposit a\\ncertain amount of tokens. The deposited amount depends\\non the amount of storage that the edge node wishes to\\nprovide. This ensures that edge nodes are committed to\\nproviding reliable and accessible storage. If an edge node\\ndoes not do as promised, it will lose the deposited tokens.\\nOn the other hand, edge nodes can obtain corresponding\\nrewards by meeting certain conditions. For example, they\\nprovide the amount of storage promised at registration\\nand keep that storage accessible. They also need to\\nregularly verify data integrity.\\n• Data integrity: Blockchain verifies the integrity of data\\nby maintaining hash values. When data is uploaded to\\nthe storage network, SC is responsible for distributing\\nit to available edge nodes. Specifically, edge nodes first\\nhash the data to generate a unique hash value. Then, the\\nhash value and corresponding metadata will be recorded\\non the blockchain. Notably, edge nodes must periodically\\nprovide hash values of the data to prove that they have the\\ncorrect version of the data. In this way, it can be ensured\\nthat the data stored on the edge nodes matches the original\\ndata uploaded to the storage network. If an edge node\\nfails to provide the correct hash value, it will be tagged\\nas an invalid storage node. Users can choose whether to\\ndownload the required data according to the latest tag.\\nThe downloaded data is hashed locally using the same\\nalgorithm (i.e., SHA256). This local hash value is then\\ncompared to the hash value stored on the blockchain. If\\nthe hashes do not match, the data has been corrupted or\\nmodified. Users will need to re-download the required\\ndata from other edge nodes. In this way, even if some\\nedge nodes are offline, users can obtain the correct data\\nwith the help of the original hash value stored on the\\nblockchain.\\n• Access control: As a Web 3.0 storage solution, the\\nblockchain does not exist as a database but is used as\\na decentralized and immutable ledger. Data ownership,\\naccess rights, and decryption keys are all recorded on\\nthe blockchain. A large number of edge devices serve as\\nactual storage units. At this point, the encrypted data is\\nstored on the edge device, while the decryption key is\\nmanaged by the blockchain. When a user requests access\\nto the data, the blockchain is first responsible for checking\\nwhether the user has the appropriate permissions. Access\\n20\\ndApp\\nAPI\\nEdge nodes\\nSmart contract\\nLedger\\nEdge\\nstorage\\n1. register\\n2. require deposit\\nBlockchain\\n3. provide storage\\n4. hash data\\n5. verify data\\nEdge\\nstorage\\nEdge\\nstorage\\n6. provide hash\\n7. request data\\n8. lookup access rights\\n9. check access rights\\n10. provide decryption key\\n11. request data\\n12. return encrypted data\\n13. decrypt data\\n14. record access log\\nFig. 17. A decentralized storage solution in Web 3.0.\\nrights can also be further divided and enforced by the\\nblockchain. For example, a small number of designated\\nusers can read and write data, while other users can only\\nread data. In addition, access rights can be restricted to\\naccess only specific parts of the data, rather than the entire\\ndataset. Authenticated users will be given the appropriate\\ndecryption key to access the data. The blockchain dis-\\ntributes the decryption keys only to users with appropriate\\naccess rights. In this case, only authorized users with\\nthe correct decryption key can access the data. This\\nensures that even if an edge node is compromised, data\\nremains secure without proper keys. Moreover, activity\\nlogs of access attempts, key distribution, and successful\\naccess are recorded in the immutable ledger so that any\\nunauthorized access attempts can be detected.\\n2) A decentralized storage solution: The proposed frame-\\nwork (see Fig. 17) aims to provide decentralized, secure,\\nreliable, and low-latency storage by utilizing the integration of\\ndistributed edge resources with blockchain technology. Edge\\nnodes first register on the blockchain network. As part of\\nthe registration process, edge nodes must post a deposit of a\\ncertain value to signify their commitment to providing storage\\nresource services. A blockchain-based token incentive system\\nis used to reward edge nodes for reliably contributing their\\nstorage. When storing data, edge nodes initially hash the data\\nthrough a cryptographic hash function, such as SHA256, to\\ngenerate a unique identifier. Edge nodes are then responsible\\nfor periodically verifying data integrity by comparing hash\\nvalues. The latest hash is submitted to the blockchain network\\nfor review and modification, in order to ensure only valid\\ndata hashes are maintained. This allows data reliability and\\nintegrity to be guaranteed even if some edge nodes become\\nunavailable. Additionally, the blockchain network is used to\\nmanage access control, decryption keys, and access logging\\nin a decentralized manner. Specifically, when a dApp requests\\ndata through the API, the blockchain uses predefined SCs to\\ncheck whether it has the appropriate access right. If authorized,\\nthe blockchain will provide the decryption key to the API. The\\nAPI then requests data from the specified edge node which will\\nreturn encrypted data. At this point, the API can use the key\\nto decrypt the encrypted data and provide the plaintext to the\\nuser. Afterward, the blockchain records an immutable log of\\nthe access.\\nC. Integration of edge computing and AI: a computing solu-\\ntion for Web 3.0\\nThe convergence of edge computing and AI is known as\\nedge AI, where AI models are deployed and executed at the\\nedge of the network, close to where the data is generated\\n[140]–[142]. Edge AI is a promising combination for enhanc-\\ning the functionalities of Web 3.0. With edge AI, edge devices\\ncan perform data analysis locally, without relying on tradi-\\ntional centralized servers. In this way, Web 3.0 applications\\nthat require high-speed data processing can give fast responses\\nto complex environments. For example, edge AI can power\\nedge devices such as robots, drones, and self-driving cars that\\nrequire real-time analysis of sensor data. Edge AI can also\\nimprove the privacy and security of Web 3.0 applications by\\nprocessing data at the edge device. In addition, the architecture\\nof edge computing is distributed and redundant, the Web 3.0\\nsystem can continue to operate even if some edge nodes are\\ndamaged or offline. All of these characteristics are highly\\ncompatible with the Web 3.0 vision. In this section, we will\\nproceed to explain how edge AI can provide a decentralized\\ncomputing solution for the Web 3.0 ecosystem. Specifically,\\nwe will first introduce the main building blocks. Then, we will\\nuse a sequence diagram to demonstrate the proposed edge AI-\\nbased decentralized computing solution.\\n1) Building blocks: The proposed decentralized computing\\nsolution consists of five core components: network deploy-\\nment, model deployment, incentive mechanism, collaborative\\nlearning, and communication-efficient protocol. They are de-\\nsigned to function in an integrated manner to facilitate efficient\\nand effective edge operations.\\n• Network deployment: The first step is to deploy an edge\\nnetwork consisting of a large number of edge devices.\\nEdge devices refer to any machines at the edge of the\\nnetwork that can perform specific tasks. For example,\\nvarious types of IoT sensors, edge servers, smart devices,\\nand so on. Specifically, IoT sensors are responsible for\\ncollecting data from the surrounding environment. Edge\\nservers are designed to aggregate data from multiple\\nIoT sensors and perform computations accordingly. Smart\\ndevices can both collect and process data.\\n• Model deployment: Through the edge network, AI mod-\\nels can be deployed to edge devices as needed by Web 3.0\\n21\\nEdge devices\\n1. collect/process data\\nEdge AI \\nmodels\\nComputing \\ntasks\\nGlobal model\\nWeb 3.0\\ndApps\\nCommunication\\nIncentives\\n2. deploy models\\n3. perform computing tasks\\n4. train local models\\n5. exchange parameters\\n6. update global model\\n7. continuous learning\\n8. optimize protocols\\n9. establish rewards\\n10. participate\\n11. provide updates\\nEdge devices\\nEdge AI \\nmodels\\nComputing \\ntasks\\nGlobal model\\nWeb 3.0\\ndApps\\nIncentives\\nCommunication\\nFig. 18. Workflow of a decentralized computing solution in Web 3.0.\\napplications. These AI models can perform various tasks\\nsuch as CV, NLP, and predictive analytics. Specifically,\\nCV models can be deployed on edge devices such as cam-\\neras and IoT sensors for object detection and recognition.\\nNLP models can be used to perform language-related\\ntasks on smart devices. Predictive models can analyze\\nreal-time data streams from IoT sensors for anomaly\\ndetection and predictive maintenance.\\n• Incentive mechanism: A proper incentive mechanism is\\nsignificant for developing decentralized computing solu-\\ntions in the Web 3.0 ecosystem. Owners of edge devices\\nwill have an incentive to participate and share their data\\nand computing resources, driving more effective edge AI-\\nbased computing solutions. Rewards can be offered in a\\nvariety of ways. For example, owners of edge devices and\\ndata contributors can be rewarded with tokens for sharing\\ndata and resources. In the decentralized community, they\\ncan also gain a higher reputation, such as badges and\\nrankings, for the quantity and quality of data and re-\\nsources they provide, thereby unlocking more community\\nservices.\\n• Collaborative learning: Collaborative learning is funda-\\nmentally a decentralized form of learning, which matches\\nthe decentralized nature of Web 3.0. In the context of\\nedge AI, each edge device can train a local model based\\non the local data. Then honest edge devices within the\\nedge network collaborate and share parameters to create\\na more general global model. Since there is no central\\nauthority, edge nodes can exchange learning parame-\\nters through peer-to-peer communication to optimize the\\nglobal model. Furthermore, collaborative learning can\\nhelp improve the global model by combining data from\\nmultiple data resources without sharing the original data.\\n• Communication-efficient protocol: Communication over-\\nhead is often the bottleneck in distributed systems. The\\nperformance of a distributed system is usually measured\\nby the communication complexity. Communication com-\\nplexity refers to the amount of data that needs to be com-\\nmunicated in the form of bits or messages between edge\\nnodes in the network. Reducing communication complex-\\nity is critical to the scalability, bandwidth requirements,\\nand network latency of the Web 3.0 ecosystem. There\\nare several ways to significantly reduce communication\\noverhead. First, the most fundamental way is to de-\\nvelop communication-efficient decentralized algorithms.\\nSecond, priorities can be assessed based on the incentive\\nmechanism. In this way, the model parameters provided\\nby edge nodes or devices with high priority will be\\nadopted. Finally, limiting the frequency of model updates\\nis also a straightforward way to reduce communication\\noverhead. For example, changes in model parameters of\\nedge nodes or devices only trigger communication when\\na certain threshold is reached.\\n2) A decentralized computing solution:\\nAs shown in\\nFig. 18, deploying edge AI models can process data efficiently\\nand effectively. This eliminates the need for extensive data\\nexchange with centralized servers and provides real-time feed-\\nback to perform tasks such as object detection using computer\\nvision or malware analysis using LLMs. Edge devices train\\nlocal models using their own data and share parameters with\\nthe global model. This sharing enables the global model\\nto be continuously improved through collaboration, creating\\n22\\nApplications \\nof Edge\\nComputing in\\nWeb 3.0\\nResource\\nManagement\\n[143]\\nSurveillance\\nSystem\\n[144]\\nHealthcare\\nSystem\\n[133]\\nFig. 19. Applications of edge computing in Web 3.0.\\na positive loop ecosystem. Optimization of communication\\nprotocols is critical to creating decentralized ecosystems where\\ndata and resources may be limited, as they allow efficient shar-\\ning of parameters between edge devices and global models.\\nBy optimizing communication, the communication overhead\\nof edge devices is mitigated, making it easier for them to\\nparticipate and contribute to the growth and improvement of\\nthe global model. The incentive mechanism creates a mutually\\nbeneficial relationship that can further encourage edge devices\\nto share resources and strengthen the global model to support\\nvarious applications in the Web 3.0 ecosystem.\\nD. Practical applications of edge computing in Web 3.0\\nIn this section, we further explore the applications of edge\\ncomputing in Web 3.0, as shown in Fig. 19, to provide\\nintuitions on how edge computing can be used in the Web\\n3.0 ecosystem. Singh and Chatterjee in [133] proposed a\\nsmart healthcare system based on edge computing, aiming\\nto address the challenges posed by the growing number of\\nsensitive patient data faced by modern healthcare systems. The\\nproposed system incorporated an intermediary edge comput-\\ning layer tasked with preserving low latency and protecting\\npatient privacy. This edge computing layer was used to en-\\ncrypt and handle patient data privacy by applying Privacy-\\nPreserving-Searchable-Encryption techniques. Additionally, an\\naccess control mechanism was also implemented by the layer\\nto restrict unauthorized access to patient data stored remotely.\\nCompared with traditional methods, the proposed approach\\nshows improvements in performance, security, lower latency,\\ntransmission time, power consumption, and energy consump-\\ntion. In the Web 3.0 ecosystem, no single entity can control\\nlarge volumes of resources. Therefore, resource collaboration\\nand management have become particularly important. As a\\npromising solution, edge computing has the potential to max-\\nimize individual benefits through resource allocation mecha-\\nnisms. Luong et al. in [143] presented a DL-based approach\\nfor deriving an optimal auction mechanism to coordinate\\nedge resources in a decentralized environment. Specifically,\\nminers’ valuations were used as training data to model deep\\nneural networks for the purpose of performing monotonic\\ntransformations on miners’ bids. Wang et al. in [144] proposed\\na video surveillance system based on the integration of edge\\ncomputing, permissioned blockchain, IPFS technology, and\\nTABLE III\\nMAIN DIFFERENCES BETWEEN WEB 3.0 AND METAVERSE.\\nAttributes\\nWeb 3.0\\nMetaverse\\nDefinition\\na new version of Web\\ndigital reality\\nFocus\\nownership\\nexperience\\nInterface\\nfront-end\\nVR/AR\\nArchitecture\\nfully decentralized\\ncentralized/decentralized\\nKey technology\\nblockchain/AI\\nextended reality\\nCNNs. The goal was to address challenges that commonly\\narise within large-scale video surveillance, such as massive\\ndevice access, high bandwidth requirements, vulnerabilities\\nto attack, and real-time monitoring. Respectively, the system\\nused edge computing to facilitate extensive wireless sensor\\ninformation gathering and data processing in a distributed\\nmanner. Permissioned blockchain underlain the framework to\\nensure reliability and robustness. IPFS technology was used\\nfor massive video data storage to reduce bandwidth usage.\\nCNN technology permitted object recognition capabilities\\nwithin video streams, achieving real-time surveillance.\\nE. Summary and insights\\nThe exponential growth of the IoT has resulted in billions\\nof devices being deployed around us. These edge devices are\\nincreasingly becoming the foundational carrier for supporting\\nWeb 3.0, generating massive amounts of heterogeneous and\\nconfidential data. In traditional centralized architectures, it is\\neasy to unify and coordinate real-time data processing, com-\\nputation, and decision-making. However, in a decentralized\\nWeb 3.0, this task becomes extremely challenging. Especially\\nas centralized solutions mature, the efficient allocation of re-\\nsources for storage and computation in the Web 3.0 ecosystem\\nneeds to be further optimized. In addition, the development of\\nlightweight multimodal learning algorithms for edge devices\\nis essential for edge resource management and optimization in\\nWeb 3.0 scenarios.\\nVI. USE CASES FOR WEB 3.0\\nAlthough Web 3.0 is still in its emerging stage, it has a solid\\ntechnological foundation. Blockchain, AI, and edge computing\\nwill enable Web 3.0 to play an important role in various fields.\\nNotably, when it comes to Web 3.0 applications, Metaverse\\nmay come up in the discussion. However, Metaverse is con-\\nsidered to be a different kind of web state than Web 3.0. The\\nmain differences between Web 3.0 and Metaverse are provided\\nin Table III.\\nMetaverse is a gigantic and shared virtual space created\\nwhen the physical world converges with the virtual world.\\nAs opposed to Web 3.0, which is primarily concerned with\\nwho will own and govern the Web, Metaverse focuses on\\nhow people will interact with it. Moreover, people may still\\nbrowse the Web using the front ends of various end devices for\\n23\\n6) showcase NFT\\n5) load NFT\\n5) load NFT\\n6) showcase NFT\\n7) offer bid (1 ETH)\\n7) offer bid (1.5 ETH)\\n9) own NFT\\nDAO\\ncoded into\\nBuyer 1\\nBuyer 2\\nDApp in DeFi marketplace\\nExchange \\nsmart contract\\nIPFS\\nIPFS\\nMint\\nsmart contract\\n1) upload data\\n1) upload data\\n2) mint NFT\\n2) mint NFT\\n4) list NFT\\n4) list NFT\\n8) accept highest bid\\nSeller\\n3) store NFT\\n3) store NFT\\nFig. 20. NFT trading process monitored by the DAO in the DeFi market.\\nWeb 3.0. However, Metaverse users will access the Web using\\nvirtual reality headsets while navigating a digital avatar across\\nthe virtual environment. If Metaverse manifests, it may do so\\nin a centralized manner (e.g., Meta) or decentralized manner\\n(e.g., Decentraland), or in any combination of the two [145]–\\n[147]. Although there is a lot of overlap in the technology\\nsupport for Web 3.0 and Metaverse, Web 3.0 relies more on\\nblockchain, AI, and some other emerging technologies while\\nMetaverse relies on extended reality technologies such as\\nvirtual reality (VR), augmented reality (AR), and mixed reality\\n(MR). Therefore, even though the two concepts of Web 3.0 and\\nMetaverse are highly related, the overlap does not necessarily\\nmean that either is an application of the other. Metaverse\\naims to correlate the digital and physical worlds so that social\\nlife, the real economy, and physical identity can all find their\\ncounterparts in the virtual world. Web 3.0 incorporates many\\nsimilar features and characteristics but is distinguished by\\nits focus on decentralization, trustless, permissionless, and\\nindividual data ownership.\\nIn this section, we will introduce three use cases in Web 3.0,\\ni.e., NFTs, DeFi, and DAO. Firstly, we will show how they\\ncan work together through a specific NFT trading process as\\nshown in Fig. 20. Next, we will discuss these three main use-\\ncases in terms of definition, relationship to blockchain and AI,\\napplications, and corresponding issues.\\nA key criterion for successful NFT trading is decentral-\\nization, which enables trustlessness and security. To achieve\\nthis, the entire trading process must be carried out by SCs\\ndeployed on the blockchain. Furthermore, exchange contracts\\nare designed to interact with all other NFT exchange contracts,\\nwhich implies a widely adopted and recognized standard\\ninterface (e.g., ERC-721) should be used. Additionally, a DAO\\nshould be coded into the exchange SC such that users can\\ncollectively manage the trading process. Notably, the exchange\\nSC does not store NFT data itself, rather it only maintains\\ninformation required to perform the transfer of ownership\\n(e.g., NFT token ID, seller address, and buyer address). The\\nactual NFT data is retrieved from a separate SC dedicated to\\nminting the NFT. Specifically, the seller first uploads data to\\na decentralized database (e.g., IPFS) in order to subsequently\\nmint the corresponding NFT. Mint SC then retrieves data and\\nuses it to mint NFT. Minted NFT will also be stored in the\\ndecentralized database and listed through the Exchange SC.\\nOn the buyer side, they send requests to Exchange SC to load\\nNFTs and provide offers. Typically, the seller will accept the\\noffer with highest bid. To accomplish this, Exchange SC will\\ntransfer the bid to the seller and NFT ownership to the buyer.\\nA. NFTs\\n1) What is an NFT? An NFT is a token that represents a\\nunique digital asset. It can be used to represent ownership and\\nauthenticity. The assets cannot be exchanged with one another\\nsince each person has a digital signature, making them distinct\\nand non-interchangeable [148].\\n2) Blockchain for NFTs: NFTs are minted through SCs de-\\nployed on the blockchain, which determines the characteristics\\nof the NFTs. The main features are listed below [149]–[152].\\n• Ownership: Ownership depends on where the private\\nkey associated with the NFT is stored. The transfer of\\nthe private key is the replacement of ownership, which\\nrealizes the trading of NFTs.\\n• Scarcity: Each NFT has a unique ID, making it a scarce\\nand non-fungible asset. Therefore, the certificate of own-\\nership can be used across the network, enabling the owner\\nto be effectively verified.\\n• Interoperability: Users are allowed to seamlessly trade or\\nshare NFTs across multiple blockchain-based ecosystems,\\nincreasing the liquidity and reach of NFTs.\\n• Immutability: The creation of an NFT means that the\\nownership and provenance of the NFT, as well as any\\nrelated data or metadata, are permanently stored on the\\nblockchain and cannot be changed.\\n• Programmability: The ownership and logic of NFTs can\\nbe programmed through SCs. This allows more complex\\nfunctionality, such as transfer rules and scarcity, to be\\nencoded directly into SCs.\\n• Transparency: Blockchain provides an immutable and\\ntransparent record of ownership, attributes, and SCs\\nassociated with NFTs. In this case, the integrity and\\nprovenance of unique digital assets can be ensured.\\nIt is worth noting that an NFT can only have one owner\\nat a time. This owner can add more attributes related to the\\nasset in the NFT. The public ledger can be viewed by anybody,\\nmaking it simple to verify and trace an NFT’s ownership. In\\n24\\nthis way, creators can monetize their work, trade it globally,\\nand have indisputable rights over their creations.\\n3) AI for NFTs: AI and NFTs have a symbiotic relationship.\\nAI greatly enhances NFTs through scarcity, personalization,\\nand market optimization. In turn, NFTs provide a way to\\nrecord, verify, and potentially monetize AI’s contributions.\\nTogether, they are transforming collecting, creativity, identity,\\nwork, and value. Specifically, there are a variety of ways that\\nAI can be used in the context of NFTs.\\n• Originality: In art, generative AI models can be used\\nto generate new ideas and designs by studying large\\ndatabases of human-created artwork. This is especially\\nuseful for creators who want to issue large numbers of\\nNFTs quickly.\\n• Verification: Blockchain is used to establish proof of\\nownership of NFTs. AI can play a complementary role\\nby using techniques, such as fingerprinting, metadata\\nanalysis, and content matching, to further verify NFT\\nownership claims on blockchains.\\n• Enhanced interactivity: AI-powered NFT can leverage\\ndeep learning methods to make the tokenized assets more\\ndynamic and interactive. The owner of NFTs can program\\nto respond to certain commands or generate new designs,\\nallowing the output of tokenized assets to evolve.\\n• Optimization: AI can provide valuable insights into pric-\\ning, improving liquidity, and maximizing the value of\\nNFT by analyzing historical sales data and attributes\\nof successful NFT, especially for items, collections, and\\nassets with limited supply.\\n• Personalization: AI provides personalized recommenda-\\ntions about purchasing or collecting new NFTs by analyz-\\ning a user’s collection, interests, and preferences, leading\\nto a more curated and valuable collection.\\n• Wider ecosystem: AI can be used to analyze the NFT\\nmarket and forecast trends and demands, helping in-\\nvestors and collectors make more informed decisions\\nwhen trading NFTs.\\n4) Applications for NFT: In this section, we will explore\\nvarious notable applications of NFTs, that showcase how\\nblockchain and AI technologies can drive the advancement\\nof NFTs.\\n• Securechain: Securechain is a hybrid verification system\\ndesigned to protect NFTs stored in hot wallets from\\nwallet-draining attacks [153]. The main idea is that with\\na hybrid system, transfer verification can be created on-\\nchain and accepted or rejected off-chain, unlike current\\nsolutions such as transferring NFTs to cold wallets.\\nIt needs to be made clear that cold wallets make it\\ninconvenient to use NFTs. In addition, since the pri-\\nvate keys of hot wallets cannot be changed, once the\\nkey is compromised, users will be responsible for all\\nresulting losses. In terms of specific implementation,\\nthere are various security measures such as authentication\\ncontroller, contract controller, authority controller, user\\ncontroller, and verification controller. Additionally, the\\nevent listening module allows the backend to monitor\\nSC for any on-chain changes. All these functionalities\\nare designed to ensure that the backend only accepts\\nverifications, but strictly prohibits any changes to the\\nverified information, as this information is permanently\\nrecorded in the blockchain ledger.\\n• NFTool: NFTool is an NFT platform powered by a suite\\nof tools including a chatbot, an NFT minting tool, SC\\nauditor, NFT search, and built-in NFT deployment [154].\\nSpecifically, a ChatGPT-style chatbot that serves as an\\nintelligent guide capable of handling related cross-chain\\nfunctions and issues. To avoid creative concepts remain-\\ning un-minted, users can follow the detailed instructions\\nof Mint NFT to launch their own NFTs on different\\nchains. However, errors in SCs can be easily exploited by\\nmalicious actors. It is crucial to utilize the SC analysis\\ntool to ensure SCs are tested thoroughly and ready for\\ndeployment. In addition, the NFT Search tool enables the\\nexploration of NFT collections across the blockchain by\\nutilizing Covalent, Zora, and Graph. Users can convert\\nfiat currencies into corresponding cryptocurrencies to\\nhelp deploy SCs.\\n• StoryChain: StoryChain is a new interpretation of story\\nediting, leveraging Artificial Intelligence Generated Con-\\ntent (AIGC) and blockchain technology to enable col-\\nlaborative story creation [155]. With StoryChain, users\\ncan collaboratively craft stories comprising distinctive\\nchapters and artistic works. Notably, each page is an\\nNFT minted for the corresponding user. During the story\\ncreation process, the contract first verifies the appropri-\\nateness of the user prompt, then ChatGPT generates the\\ntext and illustrates it with an AI image generator. The\\nentire story, along with the resulting images, will then\\nbe uploaded to IPFS. The generated hash is submitted\\nto the contract to mint the NFT for the author. This\\nway, authors will have a permanent record of ownership\\nand chapter details accessible on-chain via IPFS. Alterna-\\ntively, a voting mechanism allows the story community\\nto democratically select the direction of future entries,\\ntreating each story like a DAO. The proposed chapter is\\nsubject to consensus among NFT owners to determine the\\ndirection of the story.\\n5) Issues: Items that typically end up lost on the Web can\\nnow be monetized through NFT technology. However, both\\nthe NFT technology and the NFT market are currently in their\\ninfancy. Critical infrastructure, including technology platforms\\nand trading platforms, will continue to exist in a centralized\\nform. We list the main issues from both technical and non-\\ntechnical perspectives in Table IV [149], [150], [156]–[158].\\nB. DeFi\\n1) What is DeFi? DeFi manages financial services primarily\\nusing blockchain technology and a number of cryptocurren-\\ncies. It is an alternative to the global financial system of\\nthe Web 3.0 era and aims to democratize finance, which is\\ndifficult to achieve in the traditional financial system [159]–\\n[162]. The biggest difference between DeFi and traditional\\nfinancial institutions is that DeFi is decentralized and does\\nnot use a third party to carry out financial operations. DeFi is\\n25\\nTABLE IV\\nISSUES OF NFTS.\\nTypes\\nDescription\\nTechnical\\nComplexity\\nThe complex development of NFTs has not yet been simplified by high-quality tools.\\nStorage\\nThe URL where the artwork is stored makes the artwork itself vulnerable to link damage.\\nFees\\nArtists pay more on average in the NFT market than they earn in sales.\\nSC risks\\nSC vulnerability caused a massive attack leading to the NFT theft incident.\\nRapid innovation\\nThis creates a challenge of continuous change for those who adopt the technology.\\nUsability\\nSlow confirmation and high gas prices will limit the rapid growth of NFTs.\\nExtensibility\\nIt is difficult to interact with other ecosystems.\\nCybersecurity\\nIt is challenging to identify fake NFT stores and malicious proxies.\\nSecurity and privacy\\nNFT data is at risk of being lost or misused by malicious parties.\\nOthers\\nRegulatory\\nNew technologies bring unique regulatory and legal considerations.\\nEnvironmental concerns\\nTransactions result in high energy consumption and consequent greenhouse gas emissions.\\nAnti-money laundering\\nDecentralized transactions can lead to money laundering.\\nCopyright\\nThe public nature makes it easy for anyone to copy the referenced documents.\\nPonzi scheme\\nCritics have likened NFT to a Ponzi scheme.\\nopen and transparent and performs a range of functions based\\non the issuance code, which cannot be modified by any node\\nand can only be updated if necessary with the consent of most\\nnodes on the chain. A more detailed comparison of several key\\naspects is shown in Table V [163], [164].\\n2) Blockchain for DeFi: Blockchain is the core technology\\nthat replaces traditional centralized institutions and enables\\ndecentralized financial services as shown in Fig. 21 [165],\\nTABLE V\\nDIFFERENCES BETWEEN DEFI AND TRADITIONAL FINANCE.\\nAttributes\\nDeFi\\nTraditional finance\\nInfrastructure Decentralization\\nCentralization\\nCustody\\nUsers\\nCompanies\\nCurrency\\nDigital asset\\nFiat currency\\nSpeed\\nMinutes\\nDepends (manual processing)\\nAuditability\\nAnyone\\nAuthenticated organizations\\nCollateral\\nRequired\\nOptional\\nAnonymity\\nYes\\nNo\\nPermission\\nNo\\nYes\\nAvailability\\nYes\\nNo\\nTransparency\\nYes\\nNo\\n[166]. Cryptocurrencies, SCs, stablecoins, and dApps are the\\nfour components that comprise DeFi and are all based on\\nblockchain technology [167].\\n• Cryptocurrency: As one of the earliest and most suc-\\ncessful deployments of blockchain, cryptocurrencies are\\nubiquitous in the decentralized world. It has underpinned\\nthe rise and continued success of DeFi. DeFi’s successful\\noperation requires the support of cryptocurrencies be-\\ncause they enable many core functions. For example,\\ncryptocurrencies are used to represent and transfer value.\\nWithout cryptocurrencies, basic lending and borrowing\\nfunctions would not be possible.\\n• SCs: As a blockchain-based program, a SC can be ac-\\ntivated automatically when certain criteria are met. It\\neliminates third parties or central authorities typically\\nrequired in traditional financial transactions. It also allows\\nusers to program any transaction into code, decentralizing\\nthe financial process. When a SC goes live, no one\\ncan change it. As a result, many of the business terms\\nfound in traditional financial industry agreements can be\\ntransferred to SCs and enforced through code.\\n• Stablecoins: One of the main drawbacks of many cryp-\\ntocurrencies is their excessive volatility, which greatly\\nreduces the incentive to participate for those users who do\\nnot have sufficient risk tolerance. To solve this problem,\\nthe concept of stablecoins was created. A stablecoin is a\\ncryptocurrency with a fiat stable price. It is designed to\\nmaintain price parity with a stable asset, such as the US\\ndollar or gold, to provide the necessary stability.\\n• dApps: A dApp is essentially an application that runs\\n26\\nBorrowing\\nand lending\\nData\\ninsurance\\nDigital\\nPayment\\nPortfolio\\nmanagement\\nidentity\\nStable\\ncurrencies\\nanalytics\\nsolutions\\nDecentralized\\nDecentralized\\nexchanges\\nBuying\\nderivatives\\nDecentralized\\norganizations\\nInfrastructure\\ntooling\\nPrediction\\nmarket\\nFinancial Services\\nBlockchain platform\\nEthereum Virtual Machine (Ethereum, Solana, etc.)\\nCryptocurrency\\nSmart contract\\nStablecoin\\ndApps\\nFrontend\\nWallets\\nFig. 21. DeFi stack.\\non the blockchain. Unlike traditional applications that\\nrun on large servers, dApps are created and deployed on\\nthe blockchain through SCs. The main benefits are their\\npermissionless nature and resistance to censorship.\\n3) AI for DeFi: DeFi aims to democratize finance to bridge\\nthe limitations of traditional finance. It can provide financial\\nservices to anyone, anywhere, regardless of location, income,\\nor background [168]–[170]. With the rapid and widespread\\ndeployment of AI in multiple fields, AI is promising to provide\\nnovel solutions to enhance the DeFi ecosystem [171], [172].\\nSpecifically, it can be reflected in the following aspects.\\n• Fraud Detection: AI can analyze transaction data, user\\nbehavior, and transaction patterns to detect anomalies that\\nmay indicate fraud, scams, or money laundering in DeFi’s\\nplatform and protocols. Take money laundering as an\\nexample, various techniques have been proposed to detect\\nmoney laundering activities (see Section IV-E).\\n• Risk Analysis: AI can assess the risks of different DeFi\\nprojects based on technology, market, operations, regula-\\ntions, management team, and other factors. This can help\\nDeFi users make informed decisions about which projects\\nto invest in and which to avoid.\\n• Automated Trading: AI bots can analyze real-time market\\ndata, trends, and opportunities on the DeFi platform to\\nautomatically trade digital assets and provide liquidity to\\ngenerate maximum profits.\\n• Credit Scoring: AI can analyze DeFi users’ transaction\\nhistory, loan data, and collateral information to generate\\ncredit scores for them. These scores can then be used\\nto determine their eligibility for loans and credit limits\\nunder the DeFi loan agreement.\\n• Personalization: By understanding the user profile, in-\\nvestment goals, risk appetite, and portfolio details, AI\\ncan provide customized recommendations about interest\\nrates and lending options that are best suited for each\\nDeFi user.\\n• Product Development: Generative AI allows for rapid un-\\nderstanding of DeFi users’ needs and issues, developing\\nnew products and expanding DeFi’s ecosystem.\\n4) Applications for DeFi: In this section, we will show\\nhow blockchain and AI technologies can improve the DeFi\\necosystem by exploring several applications of DeFi.\\n• Agrosurance: Agrosurance aims to revolutionize how\\nagricultural insurance and liquidity are managed by de-\\nveloping an innovative platform that delivers transparent,\\nreliable, and decentralized solutions [173]. This plat-\\nform consists of five SCs, each with a unique purpose.\\nSpecifically, AgroCoin contract allows the transfer and\\nmanagement of AgroCoins between users. AgroSurance-\\nLand contract represents and manages land assets by\\nminting them into NFTs. StakeManager contract enables\\nusers to earn AgroCoins through staking to incentivize\\nliquidity and participation within agricultural insurance.\\nInsuranceManage uses Chainlink DONs to obtain off-\\nchain real-time data to trigger predefined rules to cal-\\nculate insurance premiums and verify claim eligibility.\\nFundManager contract acts as a repository for managed\\nfunds, storing tokens received from the InsuranceManager\\nand StakeManager contracts.\\n• Prompt DeFi: Prompt DeFi simplifies the interaction\\nprocess with DeFi into simple voice commands, thereby\\nattracting more users without relevant backgrounds to\\nenter the DeFi world [174]. This platform uses ChatGPT\\nto execute transactions based on text prompts. In addition,\\nthe use of the web3auth library greatly simplifies the\\naccount creation process, making new users interacting\\nwith Web 3.0 as easy as with Web 2.0. For example,\\nPrompt DeFi integrates prominent DeFi platforms, in-\\ncluding Uniswap, Lido, and Aave. This allows users\\nto easily send and exchange tokens through Uniswap,\\ndeposit funds into Lido, and manage loans in Aave.\\nFurthermore, the platform utilizes Chainlink Automations\\nto incorporate additional portfolio triggers, enhancing the\\noverall user experience.\\n• RoboFI: RoboFi is a robotic DeFi ecosystem that enables\\nrobotic entities to generate and trade Energy Attribute\\nCertificates (EACs) via a decentralized infrastructure\\npowered by blockchain [175]. In RoboFi, there are two\\nrobotic entities that provide commercial services for\\nhumans and other robots. One of the robots, called EAC\\nprovider, owns a solar power plant that produces green\\nelectricity. When 1 MWh of electricity is generated, 1\\nEAC NFT is created to confirm the fact and origin of\\nthis electricity. The other robot, called EAC consumer,\\nis charged from the common power grid of the RoboFi\\necosystem. To be sustainable, the EAC consumer needs\\nto confirm the origin and track of consumed electricity\\nby connecting to the RoboFi NFT EACs trading platform.\\nThe EAC consumer can showcase that it has the certifi-\\ncate to use the corresponding amount of green energy,\\nconfirming the creation of sustainable Value.\\n5) Issues: While DeFi can minimize transaction risks by\\neliminating third parties and enabling the exchange of financial\\nassets on a trustless basis, innovations always come with a new\\nset of issues. In particular, DeFi has not been stress tested for\\n27\\nTABLE VI\\nISSUES OF DEFI.\\nTypes\\nDescription\\nTechnical\\nScalability\\nThe slow-transaction nature of the consensus mechanism limits large-scale adoption.\\nOracle\\nIt is difficult for off-chain data to be reported securely on-chain.\\nOperational security\\nA malicious third party could break the SC once they get the key.\\nCustodial risk\\nThe theft of private keys can be catastrophic for users.\\nBias\\nData-driven decisions on DeFi protocols may reflect or even amplify biases.\\nLimited data\\nLimited transaction data makes it difficult to train accurate AI models.\\nIntegration\\nIntegrating centralized AI models and systems into a decentralized DeFi protocol is difficult.\\nOthers\\nRegulatory\\nFinding the right regulatory balance will be tricky.\\nCollateralization\\nOver-collateralization will limit DeFi lending business.\\nDependencies\\nThe openness and composability of DeFi introduce dependencies to the system.\\nResponsibility\\nDeFi shifts the responsibility from the third party to the user.\\nlong-term or widespread use. As shown in Table VI, a number\\nof key issues must be addressed in order to offer customers and\\ninstitutions a reliable, fault-tolerant ecosystem that can handle\\nnew financial applications at scales [167], [176]–[178].\\nC. DAOs\\n1) What is a DAO? A DAO is an organization that operates\\nfully autonomously on a blockchain, conforming to rules\\nencoded through SCs and their underlying consensus mecha-\\nnisms. It is designed to reduce or bypass the need for cascading\\nhuman intervention or centralized coordination [179]. For this\\nreason, a DAO is often referred to as a trustless system, which\\ndiffers from the traditional model of management by a small\\ngroup of people. All the rules are set up in advance in a\\nSC and executed by P2P computing nodes. A more detailed\\ncomparison between DAOs and traditional organizations is\\nshown in Table VII [180]–[182].\\n2) Blockchain for DAO: The underlying technology of\\nDAO is the blockchain. It relies heavily on SCs, which are\\ntransparent, verifiable, autonomous, and publicly auditable.\\nThe workflow of DAO is shown in Fig. 22. SCs are used\\nto establish the rules of DAO, which are set by a core team of\\ncommunity members. Due to the tamper-proof nature of the\\nblockchain, once the contract is in effect on the blockchain,\\nno one can change the code without a consensus reached\\nthrough a vote of the members. The rules and logic in the code\\nstrictly limit its functionality [183]–[185]. Financing is usually\\nachieved through a token offering, in which case the tokens are\\nsold to raise funds and replenish the coffers of DAO. Token\\nholders receive voting rights in exchange for their money. The\\nvoting rights are usually proportional to their holdings. Once\\nfundraising is complete, DAO is ready for deployment. No\\nparticular organization has the right to change the code in the\\nSC. It is entirely up to the token holders to decide. Based on\\nthese features, DAO can provide significant support for many\\napplications.\\n3) AI for DAO: The combination of DAO and AI can\\nbe complementary. AI plays a pivotal role in bringing more\\nfunctionality and greater efficiency to DAOs. AI gains the\\nresources it lacks; on the other hand, DAO gets critical\\nautonomous decision-making capabilities [186]. In the context\\nof Web 3.0, AI can enhance DAOs to fit their mission in\\nnumerous ways.\\n• Autonomous functions: AI can autonomously perform\\ncertain automated tasks, such as computation and data\\nanalysis, based on constraints, goals, and rules defined\\nby a DAO.\\nTABLE VII\\nDIFFERENCES BETWEEN DAOS AND TRADITIONAL ORGANIZATIONS.\\nAttributes\\nDAOs\\nTraditional organizations\\nTrust\\nBlockchain\\nExperience\\nGovernance\\nCommunity\\nMain stakeholders\\nStructure\\nDemocratic\\nHierarchical\\nTransparency\\nComplete\\nRestricted\\nPattern\\nCollaboration\\nCompetition\\nService\\nFully automated\\nCentralized automation\\nAccess\\nOpen\\nClosed\\nAffiliation\\nMultiple\\nOne\\nCost\\nLow\\nHigh\\n28\\nDevelopers\\nSmart\\ncontract\\nBlockchain\\nEthereum Virtual Machine\\n(Ethereum, Solana, etc.)\\nVoting\\nGovernance\\nmechanism\\ntokens\\nTest &\\nDeployment\\nCommunity\\nSmart contract\\ncreation\\nFunding for\\ngovernance\\nApplications\\nBusiness\\nservices\\nFig. 22. DAO workflow.\\n• Enhanced control: AI integrated into a DAO has no\\ncentralized control by the nature of DAOs. Its knowledge\\nand capabilities will be designed to serve the overall goals\\nand tasks of a DAO in a transparent and decentralized\\nmanner, thus enhancing decentralized control.\\n• Facilitate collaboration: AI integrated into DAOs can\\nhelp facilitate collaboration among different stakeholders\\nby providing shared information, coordination tools, and\\nalignment metrics.\\n• SCs: Generative AI can aid in the rapid development of\\nSCs by precisely coding the goals and rules of the DAO\\nso that the SC enforces these terms in a fair manner.\\n• Monitoring: AI can help continuously monitor key met-\\nrics, risks, and processes within a DAO, providing com-\\nprehensive reporting for greater transparency and ac-\\ncountability.\\n4) Applications for DAO: In this section, we will show the\\npromise of DAO powered by blockchain and AI technologies\\nin decentralized governance through specific applications.\\n• OmniGovern DAO: OmniGovern is a decentralized gov-\\nernance system deployed on a layer 2 blockchain, de-\\nsigned to simplify on-chain governance [187]. To enable\\nseamless governance across blockchains, Layerzero acts\\nas an interoperable middleware that connects multiple\\nblockchains with Omnichain Fungible Token, facilitating\\ngas-less transactions through a relay mechanism. World-\\ncoin’s authentication mechanism is used to eliminate po-\\ntential bot activity to ensure the integrity and authenticity\\nof votes and proposals. OmniGovern implements robust\\naccount abstraction on the Base Gorelli chain to simplify\\nthe complexity of user interaction with the platform by\\nmasking complex blockchain details. Additionally, Cova-\\nlent’s integration ensures transparency of voting results,\\nproposal history, and token analysis, promoting trust and\\naccountability.\\n• Rooster DAO: Rooster DAO is an investment fund man-\\naged in the form of DAO, focusing solely on investments\\nin the Dotsama ecosystem [188]. To incentivize active\\nparticipation, every member of Rooster Dao owns an\\nevolving NFT that represents their level of engagement\\nin investment proposals and voting. As members actively\\ncontribute, the rooster image gains color and levels up.\\nMoreover, when a member proposes a highly profitable\\ninvestment, all members collectively transfer a portion\\nof the profits to the proposer. Specifically, there are\\ntwo types of SCs. The NFT management contract is\\nresponsible for creating collections owned by the contract\\nitself, minting and transferring NFTs, validating owner-\\nship, and adding resources to or removing resources from\\nNFTs. The governance contract interacts with the NFT\\nmanagement contract to track proposals, authorizations,\\nand votes.\\n• DAOasis: DAOasis provides a social networking platform\\nfacilitating the creation and management of multisigniture\\nauthorities [189]. This empowers users to execute trans-\\nactions to manage their digital assets, handle customized\\ntransactions, and perform secure cross-chain interoper-\\nability. Specifically, Polybase is a decentralized database\\nthat provides a secure and decentralized method for data\\ninteraction. The Gnosis Safe wallet offers users the ability\\nto create accounts and safes. The Safe is a multi-signature\\nwallet that requires a minimum number of signatures to\\nperform a transaction, ensuring maximum security for\\nall involved parties. Connext facilitates seamless interac-\\ntions across multiple blockchains by enabling cross-chain\\ntransactions and fund transfers.\\n5) Issues: Although DAOs are still in the early stages of\\ndevelopment, it has attracted widespread attention. However,\\nimproperly building or maintaining a DAO can have serious\\nconsequences. Since a DAO directly controls assets, vulnera-\\nbilities always can cause catastrophic damage. In addition, due\\nto their infrastructure, DAOs suffer from many of the same\\nlimitations and security issues as the blockchains on which\\nthey operate. Beyond that, some of the major limitations, as\\nwell as issues, are listed in Table VIII [190]–[193].\\nVII. CHALLENGES AND FUTURE RESEARCH DIRECTIONS\\nAdvanced technologies, represented by blockchain, AI, and\\nedge computing are driving the rapid development of the Web\\n3.0 ecosystem, which is expected to revolutionize the way\\npeople interact with the Web. However, the fast iteration of\\nthese technologies also presents many challenges and limi-\\ntations to Web 3.0. The miscreants are well aware of this\\nand try to exploit this iterative gap for their own nefarious\\npurposes. As a result, some major challenges and open issues\\nneed to be addressed urgently. In the following, we will discuss\\nsome of the major issues that Web 3.0 is facing [194]–[197].\\nAdditionally, we also discuss the potential research directions\\nfor building future Web 3.0 ecosystem.\\nA. Key challenge and research direction of Web 3.0 in the\\ncontext of blockchain\\n1) Key challenge: Scalability has proven to be a major\\nobstacle to the rapid development of the Web 3.0 ecosystem.\\nScalability refers to the ability of a blockchain network to\\ndevelop and adapt to growing demands as more users are\\nadded to the network without compromising its security or\\neffectiveness. As a typical problem of the blockchain trilemma,\\nthere is no general solution as of today. As the underlying\\n29\\nTABLE VIII\\nISSUES OF DAOS.\\nTypes\\nDescription\\nTechnical\\nSecurity\\nThe code is extremely difficult to fix, thus leaving a vulnerability.\\nSpeed\\nEvery user is given an opportunity to vote, which requires a longer voting period.\\nEngagement\\nAbandoning participation in governance will lead to a re-centralization of power.\\nPseudonym\\nPseudonyms may hinder efforts to combat financial crime.\\nUnfairness\\nAutonomous attributes may be undermined by a few users who have a larger voice.\\nConsistency\\nData bias makes it challenging to fully align AI’s mission with DAO’s goals.\\nAutonomy\\nThe integration of AI into DAOs brings some centralization of control and power.\\nTransparency\\nThe lack of interpretability of AI can pose a challenge to DAO’s decision-making process.\\nOthers\\nRegulatory\\nThe legal status is typically ambiguous and may change depending on the jurisdiction.\\nInefficiency\\nIt is easy for a DAO to spend much more time discussing than implementing.\\nSocial\\nInactive or non-voting shareholders can cause disruptions in an organization’s operations.\\nEducation\\nIt is difficult for people with different backgrounds to develop strategies together.\\necology of Web 3.0, the blockchain platform often needs\\nto make a trade-off between scalability, decentralization, and\\nsecurity in different scenarios. For example, Blockchain 3.0\\nchooses to sacrifice security for high throughput and fast\\ntransactions. This results in lower fault tolerance than those in\\nblockchain 1.0 and blockchain 2.0. This could make Web 3.0\\nsolutions based on such blockchain platforms more vulnerable\\nto attacks. Meanwhile, digital wallets, existing as Web 3.0\\nportals, typically as browser extensions, pose security issues\\nsince digital wallets are connected to the blockchain through\\na centralized platform at this stage. Once the centralized plat-\\nform is compromised, users will suffer huge financial losses.\\nFor example, according to the Twitter account, Solana Status,\\nan unidentified hacker has stolen approximately $8 million\\nfrom approximately 8,000 wallets on the Solana network\\n[198]. Therefore, the resolution of the trilemma, or how to\\nmake effective trade-offs, will greatly affect the development\\nand deployment of Web 3.0.\\n2) Future direction: To effectively solve the scalability\\nchallenges faced by decentralized technologies required by\\nWeb 3.0, sharding is a promising solution. Although the\\nconcept of sharding has been proposed for years as a solu-\\ntion to scalability challenges, mainstream Web 3.0 platforms\\nhave yet to fully integrate sharding technology. The devel-\\nopment and implementation of practical sharding techniques\\nfor Web 3.0 applications remain an ongoing area of research.\\nSpecifically, cross-shard communication is an urgent problem\\nthat needs to be solved as it requires additional protocols\\nand mechanisms to ensure the consistency and validity of\\ndata and transactions across shards. Sharding security is also\\nimportant for the Web 3.0 ecosystem. It refers to the risk\\nof malicious nodes taking over a shard and manipulating its\\noperations. One attractive solution to strengthen shard security\\nis by using randomization and incentives to assign nodes to\\nshards while applying cryptographic proofs (e.g., ZK proofs)\\nto detect malicious behavior. Additionally, layer 2 scaling\\nsolutions are another important research direction that could\\ncomplement sharding. By combining sharding with layer 2\\nsolutions, blockchain networks can dramatically increase their\\nthroughput, thus realizing the Web 3.0 decentralized vision.\\nFor example, state channels allow high-frequency transactions\\nto be processed off-chain within individual shards, while only\\nsettlement states are periodically committed on-chain. Cross-\\nshard state channels are used to maintain interconnectivity. In\\nthis way, the scaling issue will be effectively mitigated by\\ncombining layer 1 sharding with a layer 2 solution, which\\nallows blockchain-powered Web 3.0 to support massive data\\nconcurrency.\\nB. Key challenge and research direction of Web 3.0 in the\\ncontext of AI\\n1) Key challenge: Unconscious bias refers to implicit at-\\ntitudes and stereotypes that influence people’s understanding,\\nactions, and decisions in an unconscious manner. Although\\nWeb 3.0 is still in its early stages, unconscious bias seems\\nto be creeping in. According to a Bloomberg report, in\\nDecember 2021, digital avatars of popular CryptoPunks NFTs\\nfluctuated in price based on race, gender, and skin color, with\\nmedium and dark-skinned avatars averaging less than light-\\nskinned NFTs [199]. The researchers at People of Crypto\\nLab, an organization aiming to promote diversity, equity, and\\ninclusion in the Web 3.0 ecosystem, examined the current\\nstate of gender diversity among Web 3.0 startup founders\\nand investors. They used Crunchbase’s extensive database of\\n30\\nnearly 2,800 participants worldwide to classify and analyze\\nparticipants based on gender. Only 13% of Web 3.0 startups\\ninclude females. Additionally, only 7% of the founders of Web\\n3.0 startups are female. Both numbers are worse than average\\nfor startups overall [200]. The lack of gender balance in the\\nWeb 3.0 ecosystem has significant implications for how people\\nself-present, conduct business, and interact with each other\\nonline. As a result, the impacts of current underrepresenta-\\ntion maybe greater than in previous generations of the Web.\\nAdditionally, AI algorithms also display unconscious bias due\\nto the unbalanced datasets they are trained with. For instance,\\nAmazon had to stop using an AI recruiting tool that was biased\\nagainst women in 2018. The tool was trained on a dataset\\ncontaining resumes of applicants dating back 10 years. This\\ndataset consisted mostly of male candidates, causing the AI\\nalgorithm to degrade resumes containing keywords such as\\n“woman” and “female” [201]. In 2019, researchers discovered\\nbias against black patients in a commercially accessible AI\\nsystem designed to predict patient outcomes. The algorithm\\nhad primarily been trained on data from white patients, re-\\nsulting in higher misdiagnosis rates for black patients [202].\\nUtilizing the biased dataset can harm the Web 3.0 ecosystem.\\nGiven the signs of these impending problems, unconscious\\nbias will be one of the major challenges for the Web 3.0\\necosystem.\\n2) Future direction: The main reason for introducing unin-\\ntentional bias is usually that the training data is unbalanced or\\nunrepresentative. However, data diversity is not always fully\\nachieved in the real world due to factors such as structural in-\\nequalities and historical patterns. When AI systems developed\\nbased on such data become widely used, unconscious bias\\ncan create a vicious cycle. This is particularly concerning as\\ngenerative AI plays an increasingly important role in creating\\nvast amounts of new digital content in the decentralized Web\\n3.0 ecosystem. It is crucial to ensure that such content is not\\nbiased. Given the prevalence of generative AI, a promising\\nresearch direction is to build an AIGC-driven bias-free Web\\n3.0 ecosystem. Specifically, unconscious bias in Web 3.0 can\\nbe effectively reduced by leveraging AIGC to generate training\\ndata that scales diversity and inclusion. Furthermore, to build\\na more inclusive and secure Web 3.0, it is necessary to rethink\\nfairness as well as privacy and security in AIGC-driven Web\\n3.0. An unfair AIGC model may further exacerbate inequalities\\nin the Web 3.0 ecosystem. It is critical to ensure that AIGC\\nalgorithms are designed to promote inclusivity and avoid\\nreinforcing bias. With the rise of AIGC, the digital economy\\ndriven by Web 3.0 has been greatly enriched. The classic\\nissues of privacy and security will also be an important area\\nof research.\\nC. Key challenge and research direction of Web 3.0 in the\\ncontext of edge computing\\n1) Key challenge: Managing a large number of intercon-\\nnected and heterogeneous devices poses significant challenges\\nto the Web 3.0 ecosystem. As devices become more connected\\nthrough edge computing architecture, threats can now spread\\nmore easily between devices. A vulnerability in one device\\nmay affect many other devices or even paralyze the entire sys-\\ntem [203]. The devices themselves also come in many different\\nforms, with different hardware, software, operating systems,\\nand use cases. For example, smartphones and IoT sensor\\nnodes will have very different technical specifications and\\ndeployment environments. This high degree of heterogeneity\\nmeans that universal security solutions must account for a large\\nnumber of potential configurations and usage patterns. As the\\nnumber of connected devices continues to grow exponentially,\\nthe ways in which these different devices interact with each\\nother also grow dramatically. It becomes incredibly difficult\\nto develop a security approach that perfectly addresses each\\nunique scenario. Solutions designed for maximum generality\\nmay lack accuracy for certain device types or environments.\\nHowever, an approach that is too specific will not be able to\\nscale and cover the entire content of the device ecosystem.\\nHow to achieve the right trade-off between generality and\\naccuracy is the key to solving the problem [204]. Furthermore,\\ncoordinating edge computing resources in a decentralized\\nmanner is a challenging task. Traditional centralized man-\\nagement approaches rely on a central authority or control\\npoint and may not scale well in a decentralized network\\nenvironment. Decentralized coordination of edge computing\\nresources involves distributing decision-making and control\\nmechanisms among multiple nodes or entities within the\\nnetwork. This approach aligns with Web 3.0 principles, which\\naim to distribute power and control among network partic-\\nipants. This requires further exploration of edge computing\\nand blockchain technologies (e.g., consensus protocols, SCs,\\netc.).\\n2) Future direction: Solving device management and re-\\nsource allocation issues in the Web 3.0 ecosystem requires\\nthe development of adaptive and scalable approaches. One\\npotential research direction is the modular architecture and\\nprotocol design of edge computing-enabled Web 3.0 to adapt\\nto different device types, configurations, and use cases. These\\nframeworks should enable seamless integration and interop-\\nerability between heterogeneous devices to facilitate commu-\\nnication and collaboration across the Web 3.0 ecosystem. In\\naddition, since edge devices may dynamically join or leave\\nthe network, the allocation of resources and tasks becomes\\nmore challenging. Therefore, developing decentralized algo-\\nrithms and mechanisms for resource allocation, load balancing,\\nand task offloading helps optimize resource utilization and\\nensure efficient coordination among edge devices. Specifically,\\nconsidering the functionality and availability of edge devices\\nis crucial for the design of intelligent resource allocation\\nalgorithms. These algorithms should efficiently distribute tasks\\namong edge devices to maximize resource utilization while\\nminimizing latency and energy consumption. Second, design-\\ning a load balancing mechanism is key to achieving even\\nworkload distribution across edge devices. Load balancing\\nalgorithms should consider factors such as device capacity,\\nnetwork congestion, and task demands to ensure optimal re-\\nsource utilization and prevent overloading of specific devices.\\nThird, effective task offloading strategies need to be developed\\nto determine when and which tasks should be offloaded\\nfrom edge devices to other edge devices or edge computing\\n31\\nclusters for acceleration, load balancing, etc. These policies\\nshould consider aspects such as task characteristics, network\\nconditions, and device capabilities to minimize latency and\\nimprove overall system performance, thereby facilitating the\\nscheduling of task processing in a system-wide view.\\nVIII. CONCLUSION\\nThis paper conducted a thorough investigation of the impact\\nof blockchain, AI, and edge computing on Web 3.0, the most\\npromising technologies driving the next generation of the\\nWeb. By exploring the development of the Web at different\\nstages, the necessity and timeliness of web evolution are\\nclarified. Technically, Web 3.0 is a back-end evolution based\\non blockchain technology that allows for the distribution of\\npower and trust, enabling users to have more control over\\ntheir personal data and digital assets. AI can empower Web\\n3.0 with key features, such as intelligent automation, enhanced\\nsecurity, and improved governance. Conversely, Web 3.0 can\\nprovide AI with the two most important elements: data and\\ncomputing power. Edge computing brings practical benefits\\nsuch as low latency and cost-effective performance to the\\nWeb 3.0 ecosystem. Then, this article conducted an extensive\\nliterature review and discussed the practical applications of\\neach technology in Web 3.0. We also proposed decentralized\\nstorage and computing solutions by exploring the integration\\nof technologies. Furthermore, we had an in-depth discussion\\non the mainstream use cases (i.e., NFTs, DeFi, and DAO)\\nfrom the aspects of definition, key attributes, related appli-\\ncations, and potential issues. Finally, the key challenges and\\npotential research directions were raised to provide guidance\\nfor research in related fields. Overall, Web 3.0 is envisioned as\\nan ecosystem, built on top of blockchain, powered by AI, and\\noptimized via edge computing, with the potential to change\\nthe way people interact with information fundamentally. We\\nexpect that this survey can facilitate a clearer understanding\\nof Web 3.0 and inspire further innovative research within this\\nemerging field.\\nREFERENCES\\n[1] Statista, “Worldwide digital population July 2022,” https://www.statis\\nta.com/statistics/617136/digital-population-worldwide/#statisticConta\\niner, Sep. 2022.\\n[2] G. Korpal and D. Scott, “Decentralization and Web3 technologies,”\\n2022, techRxiv preprint.\\n[3] Web3Foundation, “Web 3.0 technology stack,” https://web3.foundatio\\nn/about/, 2022.\\n[4] S. Voj´ıˇr and J. Kuˇcera, “Towards re-decentralized future of the web:\\nPrivacy, security and technology development,” Acta Informatica Pra-\\ngensia, vol. 2021, no. 3, pp. 349–369, 2021.\\n[5] J. Zarrin et al., “Blockchain for decentralization of Internet: prospects,\\ntrends, and challenges,” Cluster Computing, vol. 24, no. 4, pp. 2841–\\n2866, May 2021.\\n[6] Q. Wang et al., “Exploring Web3 from the view of blockchain,” 2022,\\narXiv preprint arXiv:2206.08821.\\n[7] P. Ray, “Web3: A comprehensive review on background, technologies,\\napplications, zero-trust architectures, challenges and future directions,”\\nInternet of Things and Cyber-Physical Systems, 2023.\\n[8] W. Gan et al., “Web 3.0: The future of Internet,” 2023, arXiv preprint\\narXiv:2304.06032.\\n[9] X. Ren et al., “Building resilient Web 3.0 with quantum informa-\\ntion technologies and blockchain: An ambilateral view,” 2023, arXiv\\npreprint arXiv:2303.13050.\\n[10] R. Huang et al., “An overview of Web3. 0 technology: Infrastructure,\\napplications, and popularity,” 2023, arXiv preprint arXiv:2305.00427.\\n[11] M. Shen et al., “Artificial intelligence for Web 3.0: A comprehensive\\nsurvey,” 2023, arXiv preprint arXiv:2309.09972.\\n[12] A. Beniiche et al., “Society 5.0: Internet as if people mattered,” IEEE\\nWireless Communications, vol. 29, no. 6, pp. 160–168, 2022.\\n[13] A. Park et al., “Interoperability: Our exciting and terrifying Web3\\nfuture,” Business Horizons, vol. 66, no. 4, pp. 529–541, 2023.\\n[14] T. O’Reilly, “What is Web 2.0? design patterns and business models\\nfor the next generation of software,” https://www.oreilly.com/pub/a/we\\nb2/archive/what-is-web-20.html, Sep. 2005.\\n[15] Ethereum, “Introduction to Web3,” https://ethereum.org/en/web3/,\\nMay. 2022.\\n[16] T. Berners-Lee et al., “Solid protocol,” https://solidproject.org/TR/prot\\nocol#terminology, Dec. 2020.\\n[17] World-Wide-Web-Foundation, “Three challenges for the web, accord-\\ning to its inventor,” https://webfoundation.org/2017/03/web-turns-28-l\\netter/, Mar. 2017.\\n[18] PewResearchCenter, “Americans and privacy: Concerned, confused and\\nfeeling lack of control over their personal information,” https://www.\\npewresearch.org/internet/2019/11/15/americans-and-privacy-concern\\ned-confused-and-feeling-lack-of-control-over-their-personal-informa\\ntion/pi 2019-11-14 privacy 0-01/, Nov. 2019.\\n[19] Statista, “Number of data records exposed worldwide from 1st quarter\\n2020 to 1st quarter 2023,” https://www.statista.com/statistics/1307426/\\nnumber-of-data-breaches-worldwide/, Jun. 2023.\\n[20] S. Duan, M. Reiter, and H. Zhang, “BEAT: Asynchronous BFT made\\npractical,” in Proceedings of ACM SIGSAC Conference on Computer\\nand Communications Security, Jan. 2018, pp. 2028–2041.\\n[21] M. Yin, D. Malkhi, M. Reiter, G. Gueta, and I. Abraham, “Hotstuff:\\nBFT consensus with linearity and responsiveness,” in Proceedings of\\nthe ACM Symposium on Principles of Distributed Computing (PODC),\\nJul. 2019, pp. 347–356.\\n[22] A. Miller, Y. Xia, K. Croman, E. Shi, and D. Song, “The Honey Badger\\nof BFT protocols,” in ACM SIGSAC Conference on Computer and\\nCommunications Security, Oct. 2016.\\n[23] M. Jalalzai, C. Busch, and G. Richard, “Proteus: A scalable BFT\\nconsensus protocol for blockchains,” in IEEE International Conference\\non Blockchain (Blockchain), Jul. 2019.\\n[24] G. Gueta, I. Abraham, S. Grossman, D. Malkhi, B. Pinkas, M. Reiter,\\nD. Seredinschi, O. Tamir, and A. Tomescu, “SBFT: A scalable and\\ndecentralized trust infrastructure,” in Annual IEEE/IFIP International\\nConference on Dependable Systems and Networks (DSN), Jun. 2019.\\n[25] P. Li, G. Wang, X. Chen, F. Long, and W. Xu, “Gosig: a scalable and\\nhigh-performance Byzantine consensus for consortium blockchains,” in\\nProceedings of the 11th ACM Symposium on Cloud Computing, 2020,\\npp. 223–237.\\n[26] S. Nakamoto, “Bitcoin: A peer-to-peer electronic cash system,” 2008.\\n[27] G. Wood, “Polkadot: Vision for a heterogeneous multi-chain frame-\\nwork,” White Paper, vol. 21, pp. 2327–4662, 2016.\\n[28] A. Kiayias, A. Russell, B. David, and R. Oliynykov, “Ouroboros: A\\nprovably secure Proof-of-Stake blockchain protocol,” in Advances in\\nCryptology – CRYPTO. Lecture Notes in Computer Science, vol. 10401,\\n2017.\\n[29] Y. Gilad, R. Hemo, S. Micali, G. Vlachos, and N. Zeldovich, “Algo-\\nrand: Scaling Byzantine agreements for cryptocurrencies,” in Proceed-\\nings of Symposium on Operating Systems Principles, Oct. 2017, pp.\\n51–68.\\n[30] I. Bentov, C. Lee, A. Mizrahi, and M. Rosenfeld, “Proof of Activity:\\nExtending Bitcoin’s Proof of Work via Proof of Stake,” ACM SIG-\\nMETRICS Performance Evaluation Review, vol. 42, no. 3, pp. 34–37,\\n2014.\\n[31] A. Yakovenko, “Solana: A new architecture for a high performance\\nblockchain v0. 8.13,” Whitepaper, 2018.\\n[32] K. Karantias, A. Kiayias, and D. Zindros, “Proof-of-Burn,” in In-\\nternational conference on financial cryptography and data security.\\nSpringer, 2020, pp. 523–540.\\n[33] NEM, “Nem whitepaper,” https://whitepaper.io/document/583/nem-w\\nhitepaper, 2018.\\n[34] B. Fisch, “Poreps: Proofs of Space on useful data,” Cryptology ePrint\\nArchive, 2018.\\n[35] S. Dziembowski, S. Faust, V. Kolmogorov, and K. Pietrzak, “Proofs of\\nSpace,” in Annual Cryptology Conference.\\nSpringer, Nov. 2015, pp.\\n585–605.\\n[36] E. Agbozo et al., “Applying multi-criteria decision making to priori-\\ntization of Web 3.0 development factors,” in E-business technologies\\nconference proceedings, vol. 3, no. 1, 2023, pp. 229–232.\\n32\\n[37] N. Chaudhry and M. Yousaf, “Consensus algorithms in blockchain:\\ncomparative analysis, challenges and opportunities,” in International\\nConference on Open Source Systems and Technologies (ICOSST).\\nIEEE, 2018, pp. 54–63.\\n[38] M.\\nFerdous,\\nM.\\nChowdhury,\\nM.\\nHoque,\\nand\\nA.\\nColman,\\n“Blockchain consensus algorithms: A survey,” 2020, arXiv preprint\\narXiv:2001.07091.\\n[39] S. Bamakan, A. Motavali, and A. Bondarti, “A survey of blockchain\\nconsensus algorithms performance evaluation criteria,” Expert Systems\\nwith Applications, vol. 154, p. 113385, 2020.\\n[40] I. C. Education, “Artificial intelligence (AI),” https://www.ibm.com/cl\\noud/learn/what-is-artificial-intelligence, Jun. 2020.\\n[41] H. Hua et al., “Edge computing with artificial intelligence: A machine\\nlearning perspective,” ACM Computing Surveys, vol. 55, no. 9, pp. 1–\\n35, Apr. 2023.\\n[42] J. Bambacht and J. Pouwelse, “Web3: A decentralized societal in-\\nfrastructure for identity, trust, money, and data,” 2022, arXiv preprint\\narXiv:2203.00398.\\n[43] G. Huang et al., “Efficient and low overhead website fingerprinting\\nattacks and defenses based on TCP/IP traffic,” in Proceedings of the\\nACM Web Conference 2023, Apr. 2023, pp. 1991–1999.\\n[44] W. D. la Cadena et al., “Trafficsliver: Fighting website fingerprinting\\nattacks with traffic splitting,” in Proceedings of the 2020 ACM SIGSAC\\nConference on Computer and Communications Security, Oct. 2020, pp.\\n1971–1985.\\n[45] S. Voshmgir, Token Economy: How the Web3 reinvents the Internet.\\nToken Kitchen, 2020, vol. 2.\\n[46] P. Kasireddy, “The architecture of a Web 3.0 application,” https://www.\\npreethikasireddy.com/post/the-architecture-of-a-web-3-0-application,\\nSep. 2021.\\n[47] H. Xu et al., “deController: a Web3 native cyberspace infrastructure\\nperspective,” IEEE Communications Magazine, 2023.\\n[48] C. Bassi, “Sustainable blockchain: Estimating the carbon footprint of\\nalgorand’s pure Proof-of-Stake,” https://algorand.com/resources/blog/\\nsustainable-blockchain-calculating-the-carbon-footprint, Apr. 2021.\\n[49] V. Kohli et al., “An analysis of energy consumption and carbon\\nfootprints of cryptocurrencies and possible solutions,” Digital Com-\\nmunications and Networks, vol. 9, no. 1, pp. 79–89, Jun 2022.\\n[50] Digiconomist, “Bitcoin energy consumption index,” https://digiconomi\\nst.net/bitcoin-energy-consumption, Nov. 2023.\\n[51] ——, “Ethereum energy consumption index,” https://digiconomist.net\\n/ethereum-energy-consumption, Nov. 2023.\\n[52] L. Breidenbach et al., “Chainlink 2.0: Next steps in the evolution\\nof decentralized oracle networks,” Chainlink Labs, vol. 1, pp. 1–136,\\n2021.\\n[53] V. Buterin, “Chain interoperability,” R3 Research Paper, vol. 9, 2016.\\n[54] R. Belchior, A. Vasconcelos, S. Guerreiro, and M. Correia, “A survey\\non blockchain interoperability: Past, present, and future trends,” ACM\\nComputing Surveys, vol. 54, no. 8, pp. 1–41, 2021.\\n[55] G. Wang, Q. Wang, and S. Chen, “Exploring blockchains interoper-\\nability: A systematic survey,” ACM Computing Surveys, 2023.\\n[56] M. Borkowski, D. McDonald, C. Ritzer, and S. Schulte, “Towards\\natomic cross-chain token transfers: State of the art and open questions\\nwithin tast,” Distributed Systems Group TU Wien (Technische Universit\\nat Wien), Report, vol. 8, 2018.\\n[57] Multichain, “Multichain bridge,” https://docs.multichain.org/getting-s\\ntarted/introduction.\\n[58] Threshold, “tBTC bridge,” https://threshold.network/earn/btc/.\\n[59] Parity, “Bridging the dapp-scaling now with parity bridge,” https://ww\\nw.parity.io/blog/tag/parity-bridge, Mar. 2018.\\n[60] Solana, “Wormhole,” https://solana.com/ecosystem/wormhole, Apr.\\n2020.\\n[61] C. Smith et al., “Scaling,” https://ethereum.org/en/developers/docs/sc\\naling/, Apr. 2023.\\n[62] Ethereum, “Danksharding,” https://ethereum.org/en/roadmap/dankshar\\nding/, Nov. 2023.\\n[63] P. Joseph and D. Thaddeus, “The bitcoin lightning network: Scalable\\noff-chain instant payments,” 2016.\\n[64] Raiden-Network, “What is the raiden network?” https://raiden.netwo\\nrk/101.html.\\n[65] A. Cahill and S. Deshpande, “Layer-2 scaling solutions: A framework\\nfor comparison,” https://www.tbstat.com/wp/uploads/2022/05/202205\\n05 Layer2ScalingSolutions TheBlockResearch.pdf, May 2022.\\n[66] Liquid-Network, “The liquid network,” https://liquid.net/.\\n[67] A. Tripathi, “Introduction to Polygon PoS,” https://wiki.polygon.techn\\nology/docs/pos/polygon-architecture/, Jun 2023.\\n[68] J. Benet, “IPFS - content addressed, versioned, P2P file system,” 2014,\\narXiv preprint arXiv:1407.3561.\\n[69] P. Drakatos et al., “Triastore: A Web 3.0 blockchain datastore for\\nmassive IoT workloads,” in 2021 22nd IEEE International Conference\\non Mobile Data Management (MDM), 2021, pp. 187–192.\\n[70] Z. Liu et al., “Make Web 3.0 connected,” IEEE Transactions on\\nDependable and Secure Computing, vol. 19, pp. 2965–2981, 2022.\\n[71] A. Chopra et al., “Va3: A Web 3.0 based I2I power transaction\\nplatform,” in 2022 7th IEEE Workshop on the Electronic Grid (eGRID),\\n2022, pp. 1–5.\\n[72] Y. Lin et al., “A unified blockchain-semantic framework for wireless\\nedge intelligence enabled Web 3.0,” IEEE Wireless Communications,\\n2023.\\n[73] D. Palanikkumar et al., “An enhanced decentralized social network\\nbased on Web3 and IPFS using blockchain,” in 2023 7th International\\nConference on Trends in Electronics and Informatics (ICOEI), 2023,\\npp. 616–623.\\n[74] A. Petcu et al., “A secure and decentralized authentication mechanism\\nbased on Web 3.0 and Ethereum blockchain technology,” Applied\\nSciences, vol. 13, no. 4, 2023.\\n[75] A. Razzaq et al., “IoT data sharing platform in Web 3.0 using\\nblockchain technology,” Electronics, vol. 12, no. 5, 2023.\\n[76] Y. Lin et al., “A blockchain-based semantic exchange framework\\nfor Web 3.0 toward participatory economy,” IEEE Communications\\nMagazine, Aug. 2023.\\n[77] S. Guo et al., “Blockchain-assisted privacy-preserving data computing\\narchitecture for Web3,” IEEE Communications Magazine, vol. 61,\\nno. 8, pp. 28–34, Aug. 2023.\\n[78] Y. Qiu et al., “Fog-assisted blockchain radio access network for Web3,”\\nIEEE Communications Magazine, Aug. 2023.\\n[79] G. Yu et al., “Towards Web3 applications: Easing the access and\\ntransition,” 2022, arXiv preprint arXiv:2210.05903.\\n[80] Y. Lin et al., “Blockchain-aided secure semantic communication for AI-\\ngenerated content in Metaverse,” IEEE Open Journal of the Computer\\nSociety, vol. 4, pp. 72–83, 2023.\\n[81] ——, “A unified framework for integrating semantic communica-\\ntion and AI-generated content in Metaverse,” 2023, arXiv preprint\\narXiv:2305.11911.\\n[82] G. Liu et al., “Semantic communications for artificial intelligence\\ngenerated content (AIGC) toward effective content creation,” 2023,\\narXiv preprint arXiv:2308.04942.\\n[83] L. Xia et al., “Generative AI for semantic communication: Architecture,\\nchallenges, and outlook,” 2023, arXiv preprint arXiv:2308.15483.\\n[84] R. Cheng et al., “A wireless AI-generated content (AIGC) provisioning\\nframework empowered by semantic communication,” 2023, arXiv\\npreprint arXiv:2310.17705.\\n[85] H. Du et al., “Enabling AI-generated content (AIGC) services in\\nwireless edge networks,” 2023, arXiv preprint arXiv:2301.03220.\\n[86] Y. Liu et al., “Blockchain-empowered lifecycle management for AI-\\ngenerated content (AIGC) products in edge networks,” 2023, arXiv\\npreprint arXiv:2303.02836.\\n[87] M. Xu et al., “Joint foundation model caching and inference of\\ngenerative AI services for edge intelligence,” 2023, arXiv preprint\\narXiv:2305.12130.\\n[88] H. Du et al., “Generative AI-aided optimization for AI-generated\\ncontent (AIGC) services in edge networks,” 2023, arXiv preprint\\narXiv:2303.13052.\\n[89] J. Wang et al., “A unified framework for guiding generative AI with\\nwireless perception in resource constrained mobile edge networks,”\\n2023, arXiv preprint arXiv:2309.01426.\\n[90] Y. Cao et al., “A comprehensive survey of AI-generated content\\n(AIGC): A history of generative AI from GAN to ChatGPT,” 2023,\\narXiv preprint arXiv:2303.04226.\\n[91] C. Zhang et al., “A complete survey on generative AI (AIGC): Is\\nChatGPT from GPT-4 to GPT-5 all you need?” 2023, arXiv preprint\\narXiv:2303.11717.\\n[92] I. C. Education, “Natural language processing (NLP),” https://www.ib\\nm.com/cloud/learn/natural-language-processing, Jul. 2020.\\n[93] M. Treviso et al., “Efficient methods for natural language processing: A\\nsurvey,” Transactions of the Association for Computational Linguistics,\\nvol. 11, pp. 826–860, 2023.\\n[94] C. Qin et al., “Is ChatGPT a general-purpose natural language pro-\\ncessing task solver?” 2023, arXiv preprint arXiv:2302.06476.\\n[95] D. Khurana, A. Koli, K. Khatter, and S. Singh, “Natural language\\nprocessing: State of the art, current trends and challenges,” Multimedia\\ntools and applications, vol. 82, no. 3, pp. 3713–3744, 2023.\\n33\\n[96] N. Le et al., “Deep reinforcement learning in computer vision: A\\ncomprehensive survey,” Artificial Intelligence Review, pp. 1–87, 2022.\\n[97] Y. Bi et al., “A survey on evolutionary computation for computer\\nvision and image analysis: Past, present, and future trends,” IEEE\\nTransactions on Evolutionary Computation, 2022.\\n[98] A. Vaswani et al., “Attention is all you need,” Advances in neural\\ninformation processing systems, vol. 30, 2017.\\n[99] I. Goodfellow et al., “Generative adversarial nets,” in Advances in\\nneural information processing systems, 2014, pp. 2672–2680.\\n[100] D. Kingma et al., “Auto-encoding variational bayes,” 2013, arXiv\\npreprint arXiv:1312.6114.\\n[101] K. Gregor et al., “Deep autoregressive networks,” in International\\nConference on Machine Learning, 2014, pp. 1242–1250.\\n[102] AletheaAI, “Robert Alice,” https://www.sothebys.com/en/buy/auction/\\n2021/natively-digital-a-curated-nft-sale-2/to-the-young-artists-of-cyb\\nerspace, Jun. 2021.\\n[103] J. Pregelj, “Web3 plugin for ChatGPT,” https://github.com/jernejprege\\nlj/web3-chatgpt-plugin, May 2023.\\n[104] D. Sathavara et al., “SuperCool-AI,” https://supercool.vercel.app/, Jun\\n2023.\\n[105] M. Sokoli et al., “Web3GPT,” https://w3gpt.ai/, May 2023.\\n[106] J. Savage, “ETHGPT,” https://github.com/Jsavage1325/ETHGPT, May\\n2023.\\n[107] C. Yang et al., “FlashGPT,” https://github.com/alt-research/flashGPT,\\nMar. 2023.\\n[108] TokenGPT, “Tokengpt,” https://ethglobal.com/showcase/tokengpt-ko8\\nx6, May 2023.\\n[109] M. Zhang, “CoinGPT,” https://github.com/mccowanzhang/coingpt,\\nJun. 2023.\\n[110] Memosys and Greg, “Defi-companion-covalent,” https://github.com/g\\nregfromstl/defi-companion, Aug. 2023.\\n[111] Quantstamp, “Quantstamp,” https://quantstamp.com/, 2017.\\n[112] ChainSecurity, “Chainsecurity,” https://chainsecurity.com/, 2017.\\n[113] K. Gupta et al., “Secure Semantic Snap,” https://nozk.kanavgupta.xyz/,\\nDec 2022.\\n[114] A. Alam et al., “MedDAO,” https://github.com/Arsalaan-Alam/hackfs,\\nJun. 2023.\\n[115] A. Shamir, “How to share a secret,” Communications of the ACM,\\nvol. 22, no. 11, pp. 612–613, 1979.\\n[116] S. Das et al., “Practical asynchronous high-threshold distributed key\\ngeneration and distributed polynomial sampling,” in 32nd USENIX\\nSecurity Symposium (USENIX Security 23), Aug. 2023, pp. 5359–5376.\\n[117] ——, “A new paradigm for verifiable secret sharing,” 2023, cryptology\\nePrint Archive.\\n[118] C. Ge et al., “Revocable identity-based broadcast proxy re-encryption\\nfor data sharing in clouds,” IEEE Transactions on Dependable and\\nSecure Computing, vol. 18, no. 3, pp. 1214–1226, 2019.\\n[119] W. Zhang et al., “A secure revocable fine-grained access control and\\ndata sharing scheme for SCADA in IIoT systems,” IEEE Internet of\\nThings Journal, vol. 9, no. 3, pp. 1976–1984, 2021.\\n[120] J. Zhang et al., “Revocable and privacy-preserving decentralized data\\nsharing framework for fog-assisted Internet of Things,” IEEE Internet\\nof Things Journal, vol. 9, no. 13, pp. 10 446–10 463, 2021.\\n[121] X. Yang, W. Li, and K. Fan, “A revocable attribute-based encryption\\nEHR sharing scheme with multiple authorities in blockchain,” Peer-to-\\npeer Networking and Applications, vol. 16, no. 1, pp. 107–125, 2023.\\n[122] N. Keizer et al., “The case for AI based Web3 reputation systems,” in\\n2021 IFIP Networking Conference (IFIP Networking), 2021, pp. 1–2.\\n[123] J. Lorenz et al., “Machine learning methods to detect money laun-\\ndering in the Bitcoin blockchain in the presence of label scarcity,” in\\nProceedings of the first ACM international conference on AI in finance,\\nOct. 2021, pp. 1–8.\\n[124] M. Weber et al., “Anti-money laundering in Bitcoin: Experimenting\\nwith graph convolutional networks for financial forensics,” 2019, arXiv\\npreprint arXiv:1908.02591.\\n[125] I. Alarab and S. Prakoonwit, “Graph-based LSTM for anti-money\\nlaundering: Experimenting temporal graph convolutional network with\\nbitcoin data,” Neural Processing Letters, vol. 55, no. 1, pp. 689–707,\\n2023.\\n[126] W. Lo et al., “Inspection-l: self-supervised GNN node embeddings for\\nmoney laundering detection in bitcoin,” Applied Intelligence, vol. 53,\\npp. 19 406–19 417, Aug 2023.\\n[127] M. Unzeelah and Z. Memon, “Fighting against fake news by connecting\\nmachine learning approaches with Web3,” in 2022 International Con-\\nference on Emerging Trends in Smart Technologies (ICETST), 2022,\\npp. 1–6.\\n[128] J. Kim et al., “A machine learning approach to anomaly detection\\nbased on traffic monitoring for secure blockchain networking,” IEEE\\nTransactions on Network and Service Management, vol. 19, no. 3, pp.\\n3619–3632, 2022.\\n[129] M. Xu et al., “When quantum information technologies meet\\nblockchain in Web 3.0,” IEEE Network, 2023.\\n[130] G. Yu et al., “Predicting NFT classification with GNN: A recommender\\nsystem for Web3 assets,” in 2023 IEEE International Conference on\\nBlockchain and Cryptocurrency (ICBC), 2023, pp. 1–5.\\n[131] R. Madhwal and J. Pouwelse, “Web3recommend: Decentralised\\nrecommendations with trust and relevance,” 2023, arXiv preprint\\narXiv:2307.01411.\\n[132] Z. Xiong et al., “When mobile blockchain meets edge computing,”\\nIEEE Communications Magazine, vol. 56, no. 8, pp. 33–39, 2018.\\n[133] A. Singh and K. Chatterjee, “Securing smart healthcare system with\\nedge computing,” Computers & Security, vol. 108, 2021.\\n[134] T. Qiu et al., “Edge computing in industrial Internet of Things:\\nArchitecture, advances and challenges,” IEEE Communications Surveys\\n& Tutorials, vol. 22, no. 4, pp. 2462–2488, 2020.\\n[135] L. Lin et al., “Computation offloading toward edge computing,” Pro-\\nceedings of the IEEE, vol. 107, no. 8, pp. 1584–1607, 2019.\\n[136] T. Silva, “Cloud computing or edge computing: Cost comparison,” ht\\ntps://www.azion.com/en/blog/cloud-computing-or-edge-computing-c\\nost/, Dec. 2022.\\n[137] M. Liu et al., “Computation offloading and content caching in wireless\\nblockchain networks with mobile edge computing,” IEEE Transactions\\non Vehicular Technology, vol. 67, no. 11, pp. 11 008–11 021, 2018.\\n[138] Y. Zhu et al., “Blockchain-enabled access management system for edge\\ncomputing,” Electronics, vol. 10, no. 9, 2021.\\n[139] D. Doe et al., “Promoting the sustainability of blockchain in Web 3.0\\nand the Metaverse through diversified incentive mechanism design,”\\nIEEE Open Journal of the Computer Society, 2023.\\n[140] X. Wang et al., “Convergence of edge computing and deep learning:\\nA comprehensive survey,” IEEE Communications Surveys & Tutorials,\\nvol. 22, no. 2, pp. 869–904, 2020.\\n[141] S. Deng et al., “Edge intelligence: The confluence of edge computing\\nand artificial intelligence,” IEEE Internet of Things Journal, vol. 7,\\nno. 8, pp. 7457–7469, 2020.\\n[142] L. Cao, “Decentralized AI: Edge intelligence and smart blockchain,\\nmetaverse, Web3, and desci,” IEEE Intelligent Systems, vol. 37, no. 3,\\npp. 6–19, 2022.\\n[143] N. Luong et al., “Optimal auction for edge computing resource man-\\nagement in mobile blockchain networks: A deep learning approach,” in\\n2018 IEEE international conference on communications (ICC), 2018,\\npp. 1–6.\\n[144] R. Wang et al., “A video surveillance system based on permissioned\\nblockchains and edge computing,” in 2019 IEEE international confer-\\nence on big data and smart computing (BigComp), 2019, pp. 1–6.\\n[145] N. Kuznetsov, “Facebook’s centralized metaverse a threat to the decen-\\ntralized ecosystem?” https://cointelegraph.com/news/facebook-s-centr\\nalized-metaverse-a-threat-to-the-decentralized-ecosystem, Nov. 2021.\\n[146] A. Jeffries, “Can Facebook align with the values of the metaverse?”\\nhttps://www.marketingdive.com/news/can-facebook-align-with-value\\ns-metaverse/608768/, Oct. 2021.\\n[147] M. Lodge, “What is decentraland?” https://www.investopedia.com/w\\nhat-is-decentraland-6827259, Nov. 2022.\\n[148] Ethereum, “Non-fungible tokens (NFT),” https://ethereum.org/en/nft/\\n#what-are-nfts.\\n[149] Q. Wang, R. Li, Q. Wang, and S. Chen, “Non-fungible token (NFT):\\nOverview, evaluation, opportunities and challenges,” 2021, arXiv\\npreprint arXiv:2105.07447.\\n[150] W. Rehman, H. Zainab, J. Imran, and N. Bawany, “NFTs: Applications\\nand challenges,” in International Arab Conference on Information\\nTechnology (ACIT).\\nIEEE, 2021, pp. 1–7.\\n[151] U. Chohan, “Non-fungible tokens: Blockchains, scarcity, and value,”\\nCritical Blockchain Research Initiative (CBRI) Working Papers, 2021.\\n[152] L. Yang et al., “Generic-NFT: A generic non-fungible token architec-\\nture for flexible value transfer in Web3,” 2023, techRxiv preprint.\\n[153] E. Lopez, “Securechain,” https://github.com/eduardfina/Securechain,\\nJun. 2023.\\n[154] J. Zhu et al., “NFTool,” https://github.com/Bobliuuu/NFTool, Aug.\\n2023.\\n[155] C. Adiloglu, “StoryChain,” https://storychain.ai, Mar. 2023.\\n[156] K. Busch, “Non-fungible tokens (NFTs),” https://crsreports.congress.\\ngov/product/pdf/R/R47189, Jul. 2022.\\n[157] Q. Wang et al., “Non-fungible token (NFT): Overview, evaluation,\\nopportunities and challenges,” 2021, arXiv preprint arXiv:2105.07447.\\n34\\n[158] R. Kr¨aussl and A. Tugnetti, “Non-fungible tokens (NFTs): A review\\nof pricing determinants, applications and opportunities,” Applications\\nand Opportunities, 2022.\\n[159] D. Zetzsche, D. Arner, and R. Buckley, “Decentralized finance,”\\nJournal of Financial Regulation, vol. 6, no. 2, pp. 172–203, 2020.\\n[160] S. Werner et al., “SoK: Decentralized finance (DeFi),” 2021, arXiv\\npreprint arXiv:2101.08778.\\n[161] P. Winter, A. Lorimer, P. Snyder, and B. Livshits, “What’s in your\\nwallet? privacy and security issues in Web 3.0,” 2021, arXiv preprint\\narXiv:2109.06836.\\n[162] E. Jiang et al., “Decentralized finance (DeFi): A survey,” 2023, arXiv\\npreprint arXiv:2308.05282.\\n[163] Q. Kaihua et al., “CeFi vs. DeFi–comparing centralized to decentral-\\nized finance,” 2021, arXiv preprint arXiv:2106.08157.\\n[164] Ethereum, “Decentralized finance (DeFi),” https://ethereum.org/en/de\\nfi/.\\n[165] F. Sch¨ar, “Decentralized finance: On blockchain-and smart contract-\\nbased financial markets,” FRB of St. Louis Review, 2021.\\n[166] Y. Chen and C. Bellavitis, “Blockchain disruption and decentralized\\nfinance: The rise of decentralized business models,” Journal of Business\\nVenturing Insights, vol. 13, p. e00151, 2020.\\n[167] C. Harvey, A. Ramachandran, and J. Santoro, DeFi and the Future of\\nFinance.\\nJohn Wiley & Sons, 2021.\\n[168] X. Zhao et al., “FinBrain: when finance meets AI 2.0,” Frontiers of\\nInformation Technology & Electronic Engineering, vol. 20, no. 7, pp.\\n914–924, 2019.\\n[169] L. Cao, “AI in finance: A review,” Available at SSRN 3647625, 2020.\\n[170] N. Sadman et al., “Promise of AI in DeFi, A systematic review,”\\nDigital, vol. 2, no. 1, pp. 88–103, 2022.\\n[171] EasyFi, “Artificial intelligence (AI) & decentralized finance (DeFi): A\\nmatch made in heaven,” https://medium.com/easify-network/artificia\\nl-intelligence-ai-decentralized-finance-defi-a-match-made-in-heave\\nn-483d24129481, Feb. 2023.\\n[172] Binance, “How AI will influence DeFi: Promises and delusions.”\\n[173] Y. Goyal et al., “AgroSurance,” https://github.com/agrosurance, Mar.\\n2023.\\n[174] A. Kondaurova and K. Orlov, “Prompt DeFi,” https://github.com/Dig\\nberi/promptdefi-web, Mar. 2023.\\n[175] A. Dubyk et al., “RoboFI,” https://robofi.482.solutions/, Jul. 2023.\\n[176] G. Iredale, “Pros and cons of decentralized finance (DeFi),” https:\\n//101blockchains.com/pros-and-cons-of-decentralized-finance/, Jul.\\n2021.\\n[177] C. Chen et al., “When digital economy meets Web 3.0: Applications\\nand challenges,” IEEE Open Journal of the Computer Society, 2022.\\n[178] W. Ma et al., “A comprehensive study of governance issues in decen-\\ntralized finance applications,” 2023, arXiv preprint arXiv:2311.01433.\\n[179] R. Qin et al., “Web3-based decentralized autonomous organizations\\nand operations: Architectures, models, and mechanisms,” IEEE Trans-\\nactions on Systems, Man, and Cybernetics: Systems, vol. 53, no. 4, pp.\\n2073–2082, 2022.\\n[180] S. Wang et al., “Decentralized autonomous organizations: Concept,\\nmodel, and applications,” IEEE Transactions on Computational Social\\nSystems, vol. 6, no. 5, pp. 870–878, 2019.\\n[181] R. Qin et al., “Web3-based decentralized autonomous organizations\\nand operations: Architectures, models, and mechanisms,” IEEE Trans-\\nactions on Systems, Man, and Cybernetics: Systems, 2022.\\n[182] Ethereum, “Decentralized autonomous organizations (DAOs),” https:\\n//ethereum.org/en/dao/.\\n[183] Y. E. Faqir, J. Arroyo, and S. Hassan, “An overview of decentralized\\nautonomous organizations on the blockchain,” in Proceedings of the\\n16th international symposium on open collaboration, 2020, pp. 1–8.\\n[184] X. Zhao et al., “Task management in decentralized autonomous or-\\nganization,” Journal of Operations Management, vol. 68, no. 6-7, pp.\\n649–674, 2022.\\n[185] C. Santana and L. Albareda, “Blockchain and the emergence of\\ndecentralized autonomous organizations (DAOs): An integrative model\\nand research agenda,” Technological Forecasting and Social Change,\\nvol. 182, p. 121806, 2022.\\n[186] M. Haque and M. H. S. Hossain, “A comprehensive review and\\narchitecture of a decentralized automated direct government system\\nusing artificial intelligence and blockchain,” International Journal of\\nScientific & Engineering Research, vol. 13, 2022.\\n[187] K. Nayan, “OmniGovern DAO,” https://github.com/kamalbuilds/Omn\\niGovern-DAO/, Aug. 2023.\\n[188] D. Duportail, “Rooster DAO,” https://github.com/RoosterDao, Jul.\\n2022.\\n[189] S. Kapadia, A. Aghadi, and N. Lionis, “DAOasis,” https://github.com\\n/Suhel-Kap/DAOasis, Mar. 2023.\\n[190] W. Ding et al., “Desci based on Web3 and DAO: A comprehensive\\noverview and reference model,” IEEE Transactions on Computational\\nSocial Systems, vol. 9, no. 5, pp. 1563–1573, 2022.\\n[191] G.\\nYu\\net\\nal.,\\n“Leveraging\\narchitectural\\napproaches\\nin\\nWeb3\\napplications-a DAO perspective focused,” in 2023 IEEE International\\nConference on Blockchain and Cryptocurrency (ICBC), 2023, pp. 1–6.\\n[192] D. Gogel, B. Kremer, A. Slavin, and K. Werbach, “Decentralized\\nautonomous organizations: Beyond the hype,” White Paper, Jun. 2022.\\n[193] J. Tan et al., “Open problems in DAOs,” 2023, arXiv preprint\\narXiv:2310.19201.\\n[194] R. Rudman and R. Bruwer, “Defining Web 3.0: Opportunities and\\nchallenges,” The Electronic Library, 2016.\\n[195] D. Sheridan et al., “Web3 challenges and opportunities for the market,”\\n2022, arXiv preprint arXiv:2209.02446.\\n[196] Y. Fan et al., “The current opportunities and challenges of Web 3.0,”\\n2023, arXiv preprint arXiv:2306.03351.\\n[197] C. Barabas, N. Narula, and E. Zuckerman, “Defending Internet freedom\\nthrough decentralization: Back to the future,” The Center for Civic\\nMedia & The Digital Currency Initiative MIT Media Lab, 2017.\\n[198] SolanaStatus, “An incident resulted in approximately 8,000 wallets\\nbeing drained,” https://twitter.com/SolanaStatus, Aug. 2022.\\n[199] M. Egkolfopoulou and A. Gardner, “Even in the Metaverse, not all\\nidentities are created equal,” https://www.bloomberg.com/news/feature\\ns/2021-12-06/cryptopunk-nft-prices-suggest-a-diversity-problem-in-t\\nhe-metaverse#xj4y7vzkg, Dec. 2021.\\n[200] J. Apotheker et al., “Web3 already has a gender diversity problem,”\\nhttps://www.bcg.com/publications/2023/how-to-unravel-lack-of-gende\\nr-diversity-web3, Feb. 2023.\\n[201] Reuters, “Amazon scrapped a secret AI recruitment tool that showed\\nbias against women,” https://venturebeat.com/ai/amazon-scrapped-a\\n-secret-ai-recruitment-tool-that-showed-bias-against-women/, Oct.\\n2018.\\n[202] H. Ledford, “Millions of black people affected by racial bias in health-\\ncare algorithms,” https://www.nature.com/articles/d41586-019-03228\\n-6, Oct. 2019.\\n[203] M. Antonakakis et al., “Understanding the mirai botnet,” in 26th\\nUSENIX security symposium (USENIX Security 17), 2017, pp. 1093–\\n1110.\\n[204] X. Jin et al., “Edge security: Challenges and issues,” 2022, arXiv\\npreprint arXiv:2206.07164.\\n',\n",
       " 'Prompting Frameworks for Large Language Models: A Survey\\nXIAOXIA LIU, Zhejiang University, China\\nJINGYI WANG, Zhejiang University, China\\nJUN SUN, Singapore Management University, Singapore\\nXIAOHAN YUAN, Zhejiang University, China\\nGUOLIANG DONG, Singapore Management University, Singapore\\nPENG DI, Ant Group, China\\nWENHAI WANG, Zhejiang University, China\\nDONGXIA WANG*, Zhejiang University, China\\nSince the launch of ChatGPT, a powerful AI Chatbot developed by OpenAI, large language models (LLMs) have made significant\\nadvancements in both academia and industry, bringing about a fundamental engineering paradigm shift in many areas. While\\nLLMs are powerful, it is also crucial to best use their power where “prompt” plays a core role. However, the booming LLMs\\nthemselves, including excellent APIs like ChatGPT, have several inherent limitations: 1) temporal lag of training data, and 2)\\nthe lack of physical capabilities to perform external actions. Recently, we have observed the trend of utilizing prompt-based\\ntools to better utilize the power of LLMs for downstream tasks, but a lack of systematic literature and standardized terminology,\\npartly due to the rapid evolution of this field. Therefore, in this work, we survey related prompting tools and promote the\\nconcept of the “Prompting Framework\" (PF), i.e. the framework for managing, simplifying, and facilitating interaction with\\nlarge language models. We define the lifecycle of the PF as a hierarchical structure, from bottom to top, namely: Data Level,\\nBase Level, Execute Level, and Service Level. We also systematically depict the overall landscape of the emerging PF field\\nand discuss potential future research and challenges. To continuously track the developments in this area, we maintain a\\nrepository at https://github.com/lxx0628/Prompting-Framework-Survey, which can be a useful resource sharing platform for\\nboth academic and industry in this field.\\nCCS Concepts: • Computing methodologies →Natural language processing; • Software and its engineering →\\nDevelopment frameworks and environments.\\nAdditional Key Words and Phrases: Large language models, prompting\\n1\\nINTRODUCTION\\nSince the release of ChatGPT 1, which attracted widespread social attention, research on large language models\\n(LLMs) has been in full swing in both academia and industry, resulting in a number of amazing products such as\\nPaLM [27], GPT-4 [82], and LLaMA [108, 109]. These LLMs have been shown to exhibit remarkable capabilities\\n1https://openai.com/blog/chatgpt/\\n*Corresponding author.\\nAuthors’ addresses: Xiaoxia Liu, Zhejiang University, China, liuxiaoxia@zju.edu.cn; Jingyi Wang, Zhejiang University, China, wangjyee@zju.\\nedu.cn; Jun Sun, Singapore Management University, Singapore, junsun@smu.edu.sg; Xiaohan Yuan, Zhejiang University, China, 22332075@zju.\\nedu.cn; Guoliang Dong, Singapore Management University, Singapore, gldong@smu.edu.sg; Peng Di, Ant Group, China, dipeng.dp@antgroup.\\ncom; Wenhai Wang, Zhejiang University, China, zdzzlab@zju.edu.cn; Dongxia Wang*, Zhejiang University, China, dxwang@zju.edu.cn.\\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that\\ncopies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first\\npage. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy\\notherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from\\npermissions@acm.org.\\n© 2023 ACM.\\nACM 0360-0300/2023/11-ART\\nhttps://doi.org/XXXXXXX.XXXXXXX\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\narXiv:2311.12785v1  [cs.SE]  21 Nov 2023\\n2\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\nin approaching or even exceeding human-level performance in dialogue, text translation, and sentiment analysis\\n[2, 11, 25, 54], etc, potentially bringing in fundamental changes of many fields [18, 30, 38, 61, 65, 76, 123, 137].\\nThe development of language models to the current flourishing state has undergone a series of evolutionary\\nprocesses: fully supervised learning →deep learning for NLP →“Pre-train, Fine-tune\" →“Pre-train, Prompt, Predict\"\\n[60, 135]. Initially, language models (LMs) applied a fully supervised learning paradigm, where task-specific models\\nwere trained solely on the target task dataset, heavily relying on feature engineering [53, 80, 98]. Subsequently,\\nwith the rise of deep learning, neural networks for NLP emerged, enabling the integration of feature learning and\\nmodel training, i.e., a network architecture designed to automatically learn data features [7, 8, 29, 72]. Later, as\\nthe demand for LMs increased and to accommodate the growing number of NLP tasks, the “Pre-train, Fine-tune\"\\nparadigm was introduced. In this paradigm, a model with a fixed architecture undergoes pre-training to predict\\nthe probability of observed text data. Additional parameters are then introduced, and the model is fine-tuned\\nusing task-specific objective functions to adapt the pre-trained LM to various downstream tasks [55, 100, 111, 128].\\nThen came the era of LLMs, where the trend shifted towards downstream tasks actively adapting to pre-trained\\nmodels. The paradigm of “Pre-train, Prompt, Predict\" became mainstream and prompts successfully empowering\\nthe LLMs to effortlessly tackle a wide range of complex and diverse tasks. By providing a suitable set of prompts,\\na single language model trained entirely on context-based predictions can be employed to address various tasks\\n[13, 95]. Therefore, the quality and appropriateness of prompts are increasingly playing a crucial role in task\\nresolution [51, 120, 136]. Both the academic and industrial communities have shown growing attention and\\ninterest in research related to prompts.\\nNumerous studies have demonstrated the necessity of employing appropriate methods to unleash the potential\\nof LLMs [116, 120, 129, 136]. In March 2023, OpenAI officially unveiled a significant innovation known as\\nChatGPT plugins, which enable ChatGPT to utilize external tools, reflecting a clear response to the growing\\ndemand for enhancing LLMs’ interaction capabilities with the external world. When analogized to humans, LLMs\\ncan be regarded as the intelligent system’s brain, responsible for perceiving instructions and generating and\\ncontrolling a series of actions. Therefore, by combining their inherent knowledge and capabilities with external\\ntools such as search engines, computational utilities, visual models, and more, LLMs can perform a wide array of\\nreal-world tasks, including real-time data retrieval, browser-based information retrieval, database access, precise\\nmathematical calculations, complex language generation, and image analysis, thus showcasing their potential\\nacross diverse domains like education, healthcare, social media, finance, and natural sciences [64, 68, 78, 93].\\nConsequently, the development of tools that facilitate the optimization and streamlining of the interaction process\\nbecomes crucial. In this paper, we collectively refer to these forward-looking tools as a proposed novel concept:\\n“Prompting Framework\" (PF).\\nIn general, Prompting Framework is the upper layer which enables LLMs to interact with the external world. A\\nprompting framework manages, simplifies, and facilitates such interactions, helping LLMs overcome fundamental\\nchallenges like data lag or “brain in a vet”. Moreover, prompting frameworks also serve as the basic infrastructure\\nof recently emerging autonomous agents based on LLMs, such as AutoGPT [103], HuggingGPT [122], and\\nMetaGPT [46].\\nSince the release of the open-source project LangChain [20] by Harrison Chase in October 2022, it has garnered\\nattention from over 60,000 supporters on GitHub and stands as one of the most popular prompting frameworks to\\ndate. LangChain is a framework for building applications with LLMs through composability. Besides LangChain,\\nour investigation encompasses various kinds of state-of-the-art prompting frameworks, including 1) Semantic\\nKernel [112], LlamaIndex [59], and OpenDAN [83], which can be arguably considered as the operating systems\\nfor LLMs, as well as 2) output restrictors for LLMs such as Guidance [69], TypeChat [70], NeMo-Guardrails [79],\\nand 3) language for interacting with LLMs, such as LMQL [10], gpt-jargon [14], SudoLang [40]. When referring\\nto prompting frameworks, a notable challenge arises due to the rapid pace of development in the domain, making\\nit difficult to track and stay informed about the multitude of methods dispersed across GitHub, preprint papers,\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n3\\nTwitter, and top conferences/journals. Furthermore, the abundance of prompting framework approaches with\\nvarying focuses makes it challenging to systematically categorize and compare them, hindering the selection\\nof the most suitable product for specific needs. Therefore, there is currently a lack of but an urgent need of\\nsystematic literature and standardized terminology for introducing and comparing these tools that are essential\\nfor better using LLMs’ capabilities.\\nIn this survey, we introduce the concept of ‘Prompting Framework’, and provide a comprehensive and systematic\\nsurvey of existing prompting frameworks. We present categorization, comparative analysis, and evaluation criteria\\nfor them, assess their applicability and limitations, and provide practical recommendations for their effective\\nutilization for real-world LLM-enabled tasks. Additionally, we discuss some useful toolkits related to prompts\\nthat fall beyond the scope of Prompting Frameworks. We also present recommendations for future research. In a\\nnutshell, we make the following main contributions:\\n• We introduce the concept of Prompting Frameworks that garnered attention in both academia and industry,\\nand provided systematic and standardized definitions and terminology.\\n• We categorize the existing Prompting Frameworks into 3 classes, conduct a comprehensive comparison of\\ntheir strengths and limitations across various dimensions, and provide practical recommendations. Based\\non the research findings, we present the future directions of the Prompting Framework and extensively\\nexplore its potential development and challenges in more domains.\\n• We conduct extensive research beyond the scope of prompting frameworks, including works and tools\\nrelated to LLMs’ prompts and task execution of prompting frameworks. We put them together in our\\nGitHub repository to facilitate researchers’ access and exploration for further studies.\\nThe rest of the article is structured as follows. Section 2 presents background knowledge of the Prompting\\nFramework, including the characteristics of LLMs and the necessity of the Propmpting Framework. Section 3\\ndescribes the investigation, including the methodologies and results. Section 4 provides the systematic definitions\\nand taxonomy of Prompting Frameworks. Section 6 presents the comparison and challenges across various\\ndimensions of various Prompting Frameworks. Section 5 reviews prompt-based work outside the scope of the\\nPrompting Framework but related to LLMs. Section 7 presents the future directions of the Prompting Framework\\nand the potential developments and challenges in more domains.\\n2\\nBACKGROUND\\nIn this section, we present the background of the Prompting Framework, including the reasons behind its\\nemergence and the pertinent terminologies. We aim to address the following aspects: 1) elucidating the concept\\nof LLMs by tracing their development history, and 2) explicating the current capability limitations of LLMs to\\nunderscore the necessity for the Prompting Framework.\\n2.1\\nTrends in Language Model: from LMs to 𝐿𝐿𝑀𝑠\\nEarly language models were predictive models based on Markov assumptions using statistical learning methods,\\nalso known as Statistical language models (SLM) [50, 52, 80, 106]. However, due to the limitations imposed by the\\nfully supervised learning approach, the curse of dimensionality was inevitably a challenge. With the rise of deep\\nlearning, researchers turned to neural networks to enhance LM’s capabilities, leading to the emergence of Neural\\nLanguage Models (NLMs) [71, 73]. NLMs aims to establish a universal neural network framework for various\\nnatural language processing (NLP) tasks. Subsequently, the introduction and popularity of the Transformer\\narchitecture and self-attention mechanism [111] gave rise to a series of task-agnostic pre-trained models, such\\nas BERT and GPT, called Pre-trained language models (PLM), which promoted the emergence of the “pre-train,\\nfine-tune\" paradigm [60]. PLMs have exhibited remarkable performance improvements across a wide range of\\nNLP tasks [33, 55, 63, 94].\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n4\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\nFig. 1. The timeline of representative prompting frameworks.\\nTo further explore the performance of LMs, researchers have continuously increased the scale of model\\nparameters, the trend has shifted towards downstream tasks actively adapting to pre-trained models. The paradigm\\nof “Pre-train, Prompt, Predict\" became mainstream [60]. Prompts are an important medium for interaction with\\nLanguage Models, usually in text form. In this process, the augmented models not only exhibit better performance\\non various NLP tasks but also demonstrate remarkable “emergent abilities\" [119], which were previously unseen\\nin smaller PLMs with similar architectures. For instance, ChatGPT can mimic human language style and logical\\nreasoning and also demonstrates outstanding contextual comprehension, which was absent in previous models\\nlike GPT-2. Based on this new capability distinction, researchers refer to these emerging PLMs with hundreds of\\nbillions of parameters as Large Language Models (LLMs) [47, 51, 120], such as ChatGPT, and GPT-4 [82]. With\\nthis advancement, language models have completed the leap from LMs to LLMs and inspiring new prospects for\\nartificial general intelligence (AGI).\\n2.2\\nLLMs still “Brains in a Vat\": Limitations and Mitigation\\nAnalogous to humans, LLMs can be perceived as the brains of artificial intelligence systems, responsible for\\nperceiving instructional information and generating and controlling actions. Although there has been evidence\\nof “Emergent Abilities\" [74, 117, 119, 126] in LLMs, which refers to the abilities that emerge in large-scale models\\nbut have not been observed in smaller models and can be primarily categorized into four aspects: in-context\\nlearning[36, 75, 115, 121], reasoning for complex content [56, 120, 136], instruction following [28, 85, 88, 116],\\nand creative capacity [16, 37, 133, 134].\\nHowever, the capacity limitations of LLMs cannot be ignored. Firstly, LLMs suffer from temporal lag in their\\ntraining data, such as ChatGPT’s latest training data being limited to September 2021 (at the time of paper writing).\\nLLMs are unable to access real-time information and trends, and they may struggle to accurately comprehend\\nspecific terminology or domain-specific knowledge, occasionally leading to incomplete or erroneous responses,\\neven illusions [17, 19, 25, 32, 41, 57, 113]. Additionally, LLMs are bound by strict limitations on the number of\\ntokens they can process during interactions, severely restricting the amount of contextual information they can\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n5\\ntake in and process [9, 15, 127, 131]. Secondly, LLMs are incapable of direct interaction with external expert\\nmodels, such as utilizing search engines, querying databases, and invoking external tools, or APIs, which limits\\ntheir usability [68, 93, 135]. Furthermore, the majority of LLMs are offered as paid APIs, potentially imposing\\nfinancial burdens on individuals, organizations, and projects with limited resources when dealing with large-scale\\nor frequent requests [23, 84].\\nBased on the above challenges, it is thus desirable to overcome these barriers by bridging the gap between\\nLLMs and external applications. The adoption of Prompting Frameworks, such as Langchain and semantic kernel,\\nbecomes imperative [22, 76]. These frameworks not only enable LLMs to stay constantly exposed to emerging\\ninformation but also enable the processing of long texts and documents, and facilitate seamless integration with\\nexternal applications.\\n3\\nSURVEY OVERVIEW\\nIn this section, we provide a comprehensive description of our survey process. The domains of LLMs and associated\\ntechnologies are currently undergoing an unprecedented phase of rapid development. As a consequence, the\\nlandscape of relevant research and achievements is characterized by its dispersed nature. Many contributions\\nhave yet to be formally published in traditional academic journals or conferences. Instead, they are often\\nfound on platforms like arXiv or as open-source toolkits available on GitHub. Some noteworthy developments\\nexist primarily within online communities on platforms such as Twitter, GitHub, and Discord, lacking formal\\ndocumentation. Furthermore, there is a notable absence of comprehensive review literature in the field, resulting\\nin a scarcity of established academic terminology and official definitions.\\nOur exploration of prompting frameworks begins with an in-depth examination of LangChain, recognized as one\\nof the most influential frameworks in this domain. We start by delving into LangChain’s official description, which\\nemphasizes the concept of “Building applications with Large Language Models (LLMs) through composability.\"\\nThis primary phase of our research seeks to establish a foundational understanding of the terminology and\\nconcepts central to these frameworks. We scrutinize and analyze terms such as “frameworks,\" “tools,\" “Agent,\"\\n“Large Model,\" “prompt,\" and “toolkits.\" These keywords are thoughtfully selected to ensure an encompassing\\nperspective, allowing us to include a wide range of relevant materials and resources.\\nIn our pursuit of a comprehensive examination, we conduct multiple rounds of keyword searches across diverse\\nplatforms. This includes exhaustive searches on prominent repositories like GitHub and scholarly databases\\nsuch as arXiv. Additionally, we extend our exploration to encompass reputable conferences and journals within\\nthe fields of artificial intelligence (AI) and natural language processing (NLP). These additional searches ensure\\nthat we are not only capturing the latest developments but also accessing academic and research-oriented\\nmaterials of significance. Throughout this research process, our focus is to identify, collect, and analyze relevant\\nmaterials. In total, we amass substantial works comprising 49 open-source projects available on GitHub and a\\nsignificant number of academic papers. This methodical approach and rigorous examination of resources form the\\ncornerstone of our research into prompting frameworks, facilitating a thorough and well-rounded exploration.\\nSubsequently, our investigation delves into a meticulous and systematic assessment of the 49 works under\\nscrutiny. This comprehensive evaluation begins with an exhaustive review of their technical documentation,\\nwherein we scrutinize the minutiae of each work’s conceptual underpinnings, functional implementations, and\\ncrucial code segments. We embark on an in-depth exploration, configuring and pragmatically employing these\\ntools to conduct a scientific and methodical analysis, evaluating their performance, efficiency, and applicability.\\nIn detail, we conduct extensive testing and research, which involve running all the test cases provided in the\\ntechnical documentation and manually creating numerous more detailed test cases that better reflect real-world\\nrequirements. Following the fundamental procedures of software testing, we begin with unit testing of each\\nindividual module within the framework. Subsequently, we proceed to performance testing of modules assembled\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n6\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\naccording to requirements and standards in complex applications, thus accomplishing integration testing. Finally,\\nwe conduct comprehensive system testing to validate and evaluate the capabilities claimed in these tasks, while\\nalso organizing aspects related to user experience.\\nFinally, this multi-faceted examination enables us to identify the merits and limitations of each work, providing\\nus with a nuanced understanding of their capabilities and relevance to the overarching objectives of our survey.\\nFollowing this rigorous assessment, we judiciously select approximately 30 works that not only conform to the\\nconceptual prerequisites of the prompting framework but also stand out in the field. These selected works are\\nchosen to be included in our survey to ensure a comprehensive and representative illustration of the burgeoning\\nand dynamically evolving landscape of the prompting framework, which significantly shapes interactions between\\nindividuals and LLMs.\\nImage\\nText\\nVideo\\nSpeech\\nDocument\\nAzure\\nHugging Face\\nClaude\\nPaLM\\nMeta\\nEducation\\nLegal\\nAdvertising \\nand Marketing\\nFinance\\nScientific \\nResearch\\nNews and Media\\nHealthcare\\nOpenAI\\nRaw Output\\nConversation\\nQuestion\\nTask\\nCreative\\nExpert Model\\nDatabase\\nMathematical \\nTools\\nDocument Managers\\nSearch Engines\\nSocial Media\\nMultimodal \\nProcess Tools\\nOthers\\nAgent\\nMechanical \\nEquipment\\n...\\n...\\n...\\n...\\n...\\n...\\nRetail and \\nE-commerce\\nVehicle\\nData \\nLevel\\nBase\\nLevel\\nExecute\\nLevel\\nService\\nLevel\\nPrompting \\nFramework\\nData Loading\\nData Process /\\nData to Prompt\\nAccess and Configuration\\nCoordinate Data Transfer\\nCoordinate and Respond \\nto Configuration and \\nInvocation based on \\nSpecific Real-world Tasks\\nTask Scheduling\\nExtend the Functionality \\nof Different General \\nIn More Domain-Targeted \\nManner\\nOperational Results or \\nIntermediate Data\\nControl Flow\\nData Flow\\nData Propagation Iteratively\\nInter-layer \\nCommunication\\nIntra-layer \\nScheduling\\nFig. 2. The workflow for facilitating interactions between LLMs and external entities using the Prompting Framework.\\n4\\nSTATE-OF-THE-ART PROMPTING FRAMEWORK\\nIn Sec.2, we analyze the current constraints and limitations of LLMs in practical applications. Despite these\\nlimitations, LLMs exhibit remarkable emergence abilities. By combining LLMs with the Prompting Framework,\\nthe limitations of LLMs can be mitigated to some extent, enabling the realization of more astonishing capabilities.\\nTherefore, in this section, we provide a systematic and comprehensive definition and description of the Prompting\\nFramework, which is crucial to break down the application barriers of LLMs and empowers them as critical tools\\nin real-world scenarios. We also classify the state-of-the-art Prompting Frameworks to provide a systematic\\nreview of various approaches.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n7\\n4.1\\nConceptualization\\nPrompt typically serves as a crucial medium for interacting with LLMs, taking the form of textual content. A\\nFramework is a general and extensible infrastructure that provides a structured approach and a set of guidelines.\\nConsequently, we provide the following definition of the Prompting Framework:\\nPrompting Framework (PF) is the framework for managing, simplifying, and facilitating interaction with\\nlarge language models, which adheres to four essential properties: modularity, abstraction, extensibility,\\nand standardization.\\nSpecifically, modularity refers to breaking down the structure of the prompting framework into independent\\nmodules for easy code management and reusability; abstraction refers to providing high-level, simplified interfaces\\nto hide complex implementation details in the prompting framework’s design; extensibility inclines to allow\\nusers to customize and extend framework functionalities as needed, and standardization refers to consistency in\\ndevelopment to improve code maintainability and readability.\\nWe categorize the workflow for facilitating interactions between LLMs and external entities using the Prompting\\nFramework into four hierarchical layers, arranged from bottom to top as Data Level, Base Level, Execute Level, and\\nService Level. The Prompting Framework serves as the facilitator for inter-layer communication and intra-layer\\nscheduling. It is important to note that the interactions between different levels are non-linear. In the course of a\\nsingle task execution, data may iteratively propagate between various layers to accomplish intricate operations.\\nThe following is a detailed exposition of these four levels and the role played by the prompting framework within\\nthem:\\n4.1.1\\nData Level. The Data Level is typically the foundational layer, serving as the most direct interface with the\\nexternal environment. The Data Level primarily handles tasks such as data transmission and preprocessing, while\\nbeing responsible for managing interactions with external data sources, such as databases or file systems. Within\\nthis process, the prompting framework plays a pivotal role in achieving a unified approach to dealing with various\\ntypes of data, including text, images, videos, structured data, and documents. Simultaneously, the prompting\\nframework has the capability to transform raw, unprocessed input into well-crafted prompts tailored to specific\\ntasks or requirements, including question-answering, dialogue, and reasoning, facilitating more efficient and\\neffective interactions with high-performance models at the Base Level.\\n4.1.2\\nBase Level. The Base Level operates as a computational hub situated between the data level and the execute\\nlevel, serving as the analogical equivalent of the human brain or, in a computer analogy, the CPU. The Base Level\\nprimarily takes responsibility for the management of LLMs as the computational and control center, involving\\nthe reception and comprehension of instructions, execution of commands, and conducting various computations,\\nwhich supports knowledge management and decision-making processes. Throughout this process, the prompting\\nframework plays a critical role in coordinating data transfer and task scheduling. Furthermore, the prompting\\nframework facilitates user-friendly access and flexible configuration of LLMs and can even autonomously select\\nthe most suitable LLMs for specific tasks.\\n4.1.3\\nExecute Level. The Execute Level constitutes a critical component of the business logic and is responsible for\\ninteracting with LLMs to accomplish specific real-world tasks. The Execute Level maintains communication with\\nLLMs through the prompting framework collaboratively, and based on this, constructs tasks and takes appropriate\\nactions based on the interactive information obtained from the prompting framework, and coordinates and\\nresponds to the configuration and invocation of models in alignment with LLMs to achieve the final completion\\nof tasks. The Execute Level represents the terminal stage of task execution and primarily consists of three parts.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n8\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\nTable 1. Representative Works of Prompting Frameworks.\\nCategory\\nSubcategory\\nRepresentative Works\\nThe Shell of LLMs\\n(LLM-SH)\\nUniversal LLM-SH\\nHaystack [90]\\nSemantic Kernel [112]\\nLangChain [20]\\nGriptape [44]\\nPromptFlow [48]\\nLLM-chain [105]\\nLinGoose [45]\\nLLMStack [26]\\nOpenDAN [83]\\nHyv [107]\\nDomain-Specific LLM-SH\\nLlamaIndex [59]\\nembedchain [104]\\nAgentVerse [24]\\nSuperAGI [110]\\nTxtai [67]\\nAutoChain [42]\\nTermGPT [101]\\nBotpress [12]\\nLanguage for Interaction with LLMs\\n(LLM-LNG)\\nProgramming LLM-LNG\\nLQML [10]\\nPseudocode LLM-LNG\\nPromptLang [99]\\nSudoLang [40]\\ngpt-jargon [14]\\nOutput Restrictors of LLMs\\n(LLM-RSTR)\\nContent LLM-RSTR\\nNeMo-Guardrails [79]\\nGuardrails [102]\\nStructure LLM-RSTR\\nGuidance [69]\\nPromptify [86]\\nReLLM [97]\\nTypeChat [70]\\nThe first part involves directly utilizing the Raw Output of LLMs from the Base Level to complete tasks without\\nexternal assistance, representing the simplest business workflow. The second part entails selecting and invoking\\none or several external specialized models based on the interactive information from the prompting framework\\nto handle aspects of task execution beyond the capabilities of LLMs, enabling the achievement of relatively\\ncomplex tasks. The third part involves the coordination and integration of LLMs with higher-order models, such\\nas interacting with various mechanical models (robotic arms, machines, vehicles, etc.) to realize LLM-based\\nembodied intelligence or engaging with different types of agents to create LLM-based intelligent autonomous\\nagents, further advancing the progress of Artificial General Intelligence (AGI).\\n4.1.4\\nService Level. The Service Level resides at the top tier of the entire business workflow and is responsible\\nfor facilitating the management, scheduling, and integration of advanced tasks within specific domains, in\\ncoordination with the prompting framework. Service Level extends the functionality of different general in a\\nmore targeted manner by interacting with the prompting framework, particularly in critical domains such as\\neducation, healthcare, e-commerce, law, and finance.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n9\\n4.2\\nTaxonomy of Prompting Framework\\nTaking into consideration the technical features, design objectives, and application scenarios, the current prompt-\\ning framework can be broadly covered by three types: The Shell of LLMs (LLM-SH), Language for Interaction with\\nLLMs (LLM-LNG), and Output Restrictors of LLMs (LLM-RSTR). In this section, we will elucidate the reasons for\\nthis classification and provide a detailed description of the characteristics and distinctions among these various\\ntypes of prompting frameworks. The rationale behind designing the prompting framework is to facilitate the\\ninteraction between LLMs and the external world, and different types of prompting frameworks manifest this\\nenhancement effect from different perspectives. LLM-SH functions are much like a shell or interface layer in\\ncomputer systems, emphasizing interaction with LLMs by facilitating their engagement with highly capable third\\nparties, thereby enabling stronger interaction between LLMs, users, and external models. LLM-LNG, on the other\\nhand, is designed to create a language (programming or pseudo-language) for interaction with LLMs, focusing\\non providing users with a more concise and compact interaction channel. LLM-RSTR, meanwhile, achieves\\ncontrolled generation by emphasizing interactions with LLMs that are of higher quality and better aligned with\\nrequirements. Furthermore, in the practical use of these tools, we have found that these three types of prompting\\nframeworks are often compatible with each other. In other words, depending on the requirements, multiple\\ndifferent categories of prompting framework can be used in parallel within the same task-solving process.\\n4.2.1\\nThe Shell of LLMs (LLM-SH). The shell of LLMs (LLM-SH) is a type of prompting framework aimed at\\nenhancing the capabilities of LLMs by enabling them to access various external tools and knowledge sources. In\\ntraditional terms, a shell is often associated with an operating system, where the operating system’s shell serves\\nas a command-line interpreter that receives user input commands, interprets them, and passes them on to the\\noperating system for execution, facilitating users in efficiently and comprehensively utilizing the functionality\\nof the operating system. In other words, a shell can be viewed as a layer of encapsulation over the kernel,\\nbridging the communication gap between commands and applications. Similarly, the design motivation behind\\nLLM-SH, as a prompting framework, is to expand the action potential of LLMs. Specifically, with the assistance\\nof LLM-SH, LLMs can not only accomplish conventional NLP tasks such as question answering, sentiment\\nanalysis, and information retrieval, but also higher-level functions across various domains including natural\\nsciences, healthcare, education, finance, computer science, which encompass image processing and analysis,\\nobject detection, mathematical computations, database access, utilizing search engines, code comprehension and\\ngeneration, social media posting, weather forecasting, and more. The LLM-SH simplifies complex interactions\\nbetween LLMs and the external world, with a focus on improving their usability, universality, and scalability.\\nLLM-SH also supports customization, allowing configuration and tailoring to specific needs and requirements for\\ndifferent application scenarios and specific domains.\\nIn Tab. 1, we provide classification and representative works according to categories. It is worth noting that\\nwe include many instances of “Agent\", but this paper primarily investigates the Agent framework rather than\\nindividual Agents. The distinction lies in the fact that LLMs-based Agents, exemplified by AutoGPT and BabyAGI\\n[77], emphasize the formulation of plans based on user-defined goals and the autonomous execution of these plans,\\nwhose main contributions lie in task acceptance, comprehension, automated decision-making, and execution\\nprocesses. On the other hand, Agent frameworks, exemplified by SuperAGI [110] and AgentVerse [24] in the\\ntable, focus on customizing and building, managing, and running Autonomous Agents according to user-specific\\nrequirements. In simple terms, LLMs-based Agents are products primarily geared towards usage, whereas Agent\\nframeworks serve as auxiliary tools to assist users in assembling and maintaining Agents, with an emphasis on\\nconstruction.\\nThere are two primary forms within LLM-SH. One is designed to support a wide range of applications and\\ndomains and is referred to as Universal LLM-SH. The other is more specialized and focused on a specific domain,\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n10\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\nsuch as Agent building and maintenance, data processing, or chat-bot building, and is known as Domain-Specific\\nLLM-SH.\\nUniversal LLM-SH is designed with the intention of accommodating a wide range of application scenarios\\nand domains, offering extensive functionality and flexibility to meet the diverse needs of users, which typically\\npossess higher generality and scalability. Representative works include Haystack, Semantic Kernel, LangChain,\\nGriptape [44], PromptFlow [48], LLM-chain [105], LinGoose [45], LLMStack [26], OpenDAN [83], Hyv [107].\\nDomain-Specific LLM-SH is specifically designed for particular domains or application scenarios. They are\\ntypically finely tuned and optimized for the requirements of that domain, often achieving better performance\\nand higher efficiency in completing specific tasks. Representative works include LlamaIndex [59] and Txtai [67],\\nwhich are data frameworks designed to assist in building LLM-based applications. For building and managing\\nLLM-based autonomous agents, we have AgentVerse [24] and SuperAGI [110], along with AutoChain [42]. In the\\ndomain of creating LLM-powered bots, there are embedchain [104] and botpress [12]. Additionally, for giving\\nLLMs the capability to plan and execute terminal commands, there is TermGPT [101].\\n4.2.2\\nLanguage for Interaction with LLMs (LLM-LNG). Language for Interaction with LLMs (LLM-LNG) is\\nan innovative type of prompting framework designed to facilitate more concise, direct, and compact interactions\\nwith LLMs by introducing a specialized language for programming.\\nPrompts serve as crucial intermediaries for interacting with LLMs and are typically presented in the form\\nof natural language text. However, the capabilities of pure natural language text are limited and can increase\\ncomplexity and cost when dealing with advanced tasks, sometimes even failing to yield accurate outputs. In\\ncontrast to purely natural language prompts, languages that integrate both natural language and programming\\nlogic are more structured, concise, and compact. They not only enhance reasoning performance but also provide\\nbetter support for various prompting methods, such as chain-of-thought reasoning and decision trees. Additionally,\\nthey can offer improved support for control flow.\\nLLM-LNG comes in two primary forms: Programming LLM-LNG, which involves interactions with LLMs using\\nprogramming languages, and Pseudocode LLM-LNG, which interacts with LLMs using a pseudo-code language.\\nThe main distinction between the two lies in their nature. Programming LLM-LNG belongs to the domain of\\nprogramming languages and adheres to complex syntax rules and structures, which require compliance with\\nspecific syntax specifications to ensure program correctness and often require compilation or interpretation\\nto transform it into executable code. On the other hand, Pseudocode LLM-LNG provides a simpler and more\\nintuitive way of describing algorithms, combining natural language and structured coding with fewer formal\\nconstraints. As a result, Programming LLM-LNG, due to the interpretation and compilation process, tends to be\\nmore powerful in handling tasks and control flow. However, it also entails a steeper learning curve compared to\\nPseudocode LLM-LNG. Each approach has its own advantages.\\nProgramming LLM-LNG primarily involves designing a new programmable language for interacting with\\nLLMs by simulating the syntax and architecture of existing programming languages. Given the significant overlap\\nbetween user interactions with LLMs and the functionality of query languages, combining query language\\nand language model prompts is a logical approach. This expansion transforms prompts from pure text-based\\nprompts (natural language) to a combination of text prompts and scripts (natural language combined with\\nprogramming language), enhancing the intuitiveness of interactions. In compound prompts that blend natural\\nlanguage with the programming language, constraints, and control flow are embedded into the instruction parsing\\nand output parsing processes of LLMs through structured query languages. This functionality aims to streamline\\nthe reasoning process while reducing calls to resource-intensive underlying LLMs. Notable products in this\\ncategory include LMQL [10].\\nPseudocode LLM-LNG is a more open-ended form that flexibly combines natural language with structured\\ncoding, relying on the inherent capabilities of LLMs. Pseudocode is a wonderful method for outlining programs\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n11\\ninformally in natural language, without the constraints of specific syntax, which is like sketching out your ideas\\nbefore diving into detailed coding. The design of Pseudocode LLM-LNG is driven by the need to unlock the full\\npotential of LLMs, which possess strong capabilities but are hindered by inconvenient interactions or inaccurate\\nprompts. Therefore, Pseudocode LLM-LNG offers a standardized structure and syntax that is easy to understand\\nand interpret. It provides feasibility-verified template use cases or background explanations for communication\\nwith LLMs, combining natural language with simple coding conventions. Representative works in this category\\ninclude PromptLang [99], SudoLang [40], and gpt-jargon [14].\\n4.2.3\\nOutput Restrictors of LLMs (LLM-RSTR). Output Restrictors of LLMs (LLM-RSTR) are a type of\\nprompting framework designed to enable controlled generation by LLMs. The controlled generation problem\\nwith LLMs pertains to how to ensure that the generated text meets specific requirements, constraints, or demands,\\nadapting to various application scenarios and professional domains. This involves control over multiple aspects\\nsuch as semantic content, output structure, and semantic style. Currently, due to the uncontrolled nature of\\nLLMs, the generated natural language text tends to be unstructured. Additionally, generated text may contain\\npotential risks like bias, misinformation, or inappropriate content. LLMs also struggle with off-topic responses and\\nmaintaining consistency with predefined requirements. However, the application of LLM-RSTR can effectively\\nalleviate these issues. LLM-RSTR primarily focuses on controlled generation from two perspectives: Content\\nControl, referred to as Content LLM-RSTR, and Structure Control, referred to as Structure LLM-RSTR.\\nContent LLM-RSTR focuses on achieving controlled generation by LLMs in three main aspects: privacy\\nprotection, security, and alignment with the topic and accuracy. As for privacy protection, Content LLM-RSTR\\nensures that user-provided personal or sensitive information is not leaked or misused. Security control aims\\nto filter out unsafe, or dangerous content such as societal and cultural biases about gender, race, politics, and\\ninappropriate or offensive content, and also prevents the generation of false or misleading information, thereby\\nmaintaining the accuracy and credibility of the generated content. The generated text should align with the user’s\\nor application’s topic or requirements to ensure the generated content is useful. Additionally, text generation\\nneeds to maintain high accuracy, especially in specific domain applications such as medicine, law, or science.\\nRepresentative works in this category include NeMo-Guardrails [79] and Guardrails [102].\\nStructure LLM-RSTR plays a critical role in information processing, data management, and decision support,\\nenabling both computers and humans to better understand and utilize the information, for tasks such as database\\nmanagement, search engine optimization, natural language processing (NLP), information extraction, data mining,\\nand analysis. Unstructured original output from LLMs is challenging to use in business or other applications.\\nTherefore, constraining and specifying the desired output text format is crucial. The most intuitive way to obtain\\nstructured text as output from LLMs is to write extensive and cumbersome tutorials and templates to instruct\\nLLMs on what format the output should take. However, this is a time-consuming and complex process. The\\ndesign of Structure LLM-RSTR aims to address this issue, allowing users to interact with LLMs in a simpler, more\\ndirect manner, and obtain structured outputs that are clear, easier to handle, and analyze. Representative works\\nin this category include Guidance, Promptify [86], ReLLM [97], and TypeChat [70].\\n4.3\\nCrucial Component in the Construction of Prompting Framework\\nAfter elucidating the concept of the prompting framework and conducting a comparative analysis, in this\\nsection, we introduce one of the pivotal concerns within the prompting framework—specifically, the essential\\ncomponents required when constructing a prompting framework. Given the rapid development of both LLMs\\nand the prompting framework itself, this field has not only given rise to numerous emerging technologies but\\nhas also reactivated many traditional techniques.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n12\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\n4.3.1\\nVector Database. In the midst of the ongoing AIGC revolution, a particular challenge lies in the capability\\nof large-scale storage and querying of unstructured data, such as images, videos, and text. Vector databases\\noffer developers the means to handle unstructured data in the form of vector embeddings, which becomes\\nespecially crucial for the utilization and expansion of LLMs, for example, tools like OpenAI’s Retrieval plugin\\nrely on vector databases to assist users in retrieving relevant document excerpts from the data sources. A vector\\ndatabase is a specialized database designed for storing and managing vector data. Vector data refers to data\\ncomposed of multiple numerical values, often representing specific features or attributes. Vectorization is the\\nprocess of transforming discrete variables, such as images and text, into continuous vector spaces. For example,\\ndifferent-sized or content images can be mapped into vectors within the same space, or various lengths of text can\\nbe mapped to a common vector space. In this space, adjacent vectors carry semantically similar meanings, and\\nthe vector space is commonly referred to as the embedding space, the generated vectors are known as embedding\\nvectors or vector embeddings. The primary characteristics of vector databases include efficient storage and\\nquerying of large-scale vector data. Typically, they employ queries based on vector similarity, retrieving data\\nbased on the similarity between vectors. This querying approach finds applications in various scenarios like\\nimage search, music recommendation, and text classification.\\nVector databases depend on three key elements: vectorization (encoding), data structure, and distance cal-\\nculation. The quality of vectorization determines the upper limit of vector database performance, yet current\\nvectorization processes lack universality due to their strong dependence on data types. Properly constructing\\ndata structures to manage vectors ensures computational and retrieval efficiency, which determines the lower\\nlimit of vector database performance. Reasonable distance calculation between vectors can minimize resource\\nconsumption.\\nIn recent years, there has been a proliferation of specialized database products. For instance, Milvus[114] is\\nconsidered the world’s first true vector database product, with over 1000 enterprise users worldwide, making it\\none of the most popular open-source vector databases globally. Pinecone[91], designed for machine learning\\napplications, offers speed, scalability, and support for various machine learning algorithms. Pinecone is also a\\npartner of OpenAI, and users can generate language embeddings using OpenAI’s Embedding API. Weaviate[34],\\na vector database, can store as many as billions of vectors. Additionally, Weaviate has introduced a Plug-in for\\nChatGPT, which has received recognition from OpenAI. The main distinction between Weaviate and Pinecone\\nlies in how they manage services. Pinecone handles data storage and resource management fully for users,\\noften in conjunction with AWS or GCP hosting. In contrast, Weaviate allows users to self-host their data while\\nproviding supportive operations and services. For users who value retaining control and not relinquishing their\\ndata entirely, Weaviate offers greater flexibility but may come with a relatively higher time cost.\\n4.3.2\\nCache for LLMs. Fundamentally, every form of computation necessitates storage. Computation and\\nstorage represent the two fundamental abstractions, yet they are mutually convertible: storage can be exchanged\\nfor computation, and vice versa. Achieving an optimal trade-off is crucial in enhancing the input-output ratio.\\nWhether dealing with large-scale or small-scale models, they fundamentally encode global knowledge and\\noperational rules, serving as a compression of all human data. However, embedding all data into LLMs is\\nchallenging. For instance, some assert that ChatGPT serves as a highly efficient compression encoding, albeit not\\nachieving lossless compression, in which the process inevitably introduces entropy reduction and information loss.\\nEncoding all information into neural networks results in an excessively bulky model with an enormous parameter\\nscale, leading to sluggish performance. Therefore, complete integration is unfeasible, implying the potential\\nnecessity for external storage. Similar situations exist in computer architecture, where the CPU incorporates\\non-chip SRAM, typically constrained in size due to the significantly higher cost of on-chip storage (100 times\\nmore expensive than DRAM and 10,000 times more expensive than disk storage). Neural networks function as\\non-chip storage for large models, with larger-scale models possessing more on-chip storage. However, utilizing\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n13\\nneural networks for data storage proves costly, causing a rapid escalation in network scale. Hence, large models\\nrequire a more efficient data storage method beyond neural networks, known as memory of LLMs.\\nFor instance, GPTCache[139] is a tool specifically designed to build semantic caches for storing LLMs’ responses.\\nIt employs a modular design, including six main modules: LLM adapter, embedding generator, cache storage,\\nvector store, cache manager, and similarity evaluator. The system offers multiple implementation options for each\\nmodule, allowing users to customize their semantic cache to meet specific needs. Zep is a long-term memory\\nstore designed for building conversational LLM applications, which supports storing, summarizing, embedding,\\nindexing, and enriching the history of LLM applications/chatbots. Zep[132] enables long-term memory persistence,\\nautomatic summarization based on configurable message windows, vector search, and automatic memory token\\ncounting.\\n4.4\\nTypical Applications of Prompting Framework\\nIn this section, we elucidate some typical applications of the prompting framework throughout the entire lifecycle\\nof LLMs. These applications, situated at the closest proximity to the user at the application layer, are poised to\\noffer boundless insights and inspiration for future developers and users.\\n4.4.1\\nIntegrated Application Platform. The initial goal of constructing the prompting framework was\\nto reduce the interaction barriers with LLMs and facilitate the development of LLM applications. Therefore,\\nafter addressing prototype issues, the subsequent challenge is to assist these applications in transitioning to\\npractical development while ensuring implementation in a reliable and maintainable manner. Debugging, testing,\\nevaluating, and monitoring the intricate data and control flow within LLM systems are crucial steps in this\\nprocess, which ensures the robust deployment of LLMs in real-world production scenarios is of paramount\\nimportance. Consequently, considering both immediate requirements and future strategic objectives, integrated\\napplication platforms emerge as a typical application of the prompting framework.\\nFor example, The newly developed LangSmith [20] by LangChain developers introduces innovative features\\ncentered around five core pillars: debugging, testing, evaluation, monitoring, and usage metrics. LangSmith\\nfacilitates the execution of these operations through a simple and intuitive user interface, significantly lowering the\\nbarriers for developers without a software background. From a numerical perspective, many features of LLMs lack\\nintuitiveness, making visual representation essential. We observe that a thoughtfully designed user interface can\\nexpedite user prototyping and work, as handling everything through code alone can be cumbersome. Furthermore,\\nvisualizing the processes and intricate command chains of LLM systems proves valuable in understanding the\\nreasons behind specific outputs. As users construct more complex workflows, comprehending how queries\\ntraverse different processes becomes challenging. Therefore, a user-friendly interface to visualize these processes\\nand record historical data represents a forward-looking innovative application.\\n4.4.2\\nLLM-based Agent. For a long time, autonomous agents have been a significant research topic. However,\\nbefore the advent of LLMs and related technologies, limitations in training data, training methods, and interaction\\nwith the environment severely constrained the capabilities of agents. Consequently, agents struggled to make\\ndecisions similar to humans and achieve remarkable performance. However, with the current prevalence of LLMs\\nand their outstanding capabilities, LLM-based autonomous agents have demonstrated immense potential in task\\nprocessing and autonomous decision-making.\\nIn a broad sense, an agent refers to any system capable of thinking, interacting with the environment, operating\\nindependently, and collaborating with other entities. In theory, given any objective, an agent should be able to\\nachieve it automatically. LLM-based Agents belong to AI systems that autonomously generate sub-agents, which\\ncan execute tasks independently based on user requirements without the user’s direct intervention, following\\nthe basic three sub-steps used by people to solve various problems: perception, decision-making, and action.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n14\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\nLLM-based Agents can handle tasks ranging from daily event analysis, marketing plan generation, and code\\nprogramming, to mathematical computations, among others. If ChatGPT follows user instructions, doing what\\nthe user tells it to do, then an LLM-based Agent acts on what it deems should be done. In other words, LLM-\\nbased Agents demonstrate a potential form of integration between LLMs and prompting frameworks. However,\\nit’s important to note that this is still an experimental concept and not a fully realized commercial product.\\nCurrently, LLM-based autonomous agents typically follow a unified architecture, consisting of four main modules:\\na configuration module representing agent attributes, a memory module for storing historical information, a\\nplanning module for formulating future action strategies, and an action module for executing plan decisions.\\nAutoGPT [103], released on GitHub by Significant Gravitas, is a well-known autonomous agent capable of\\nexecuting actions based on LLMs’ autonomous decision results and external resources. AutoGPT uses a cyclic\\nevaluation strategy to assess the degree of goal achievement in real-time, determining whether a task is complete.\\nAutoGPT is mainly composed of three parts: task distribution, autonomous execution, and result output. The\\nautonomous execution module is the core of AutoGPT. Currently, AutoGPT can perform basic tasks such as\\ninternet searches and information collection, long-term and short-term memory management, access to common\\nwebsites and platforms, and extension through plugins. HuggingGPT [122], developed by Zhejiang University and\\nMicrosoft Research Asia, is a collaborative system that connects LLMs with the ML community (HuggingFace). It\\ncan handle inputs from various modalities and address a wide range of complex AI tasks. In essence, HuggingGPT\\ntakes introductions to all models on the HuggingFace community as input and runs them through models. Then,\\nbased on the user’s input question, it parses matches and decides which model to use for solving the task. Similarly,\\nHuggingGPT’s workflow comprises four stages: task planning, model selection, task execution, and response\\ngeneration, which aligns closely with that of AutoGPT. In addition, AgentGPT [96] is a web-based solution\\nthat allows for the configuration and deployment of autonomous AI agents, facilitating interactive experiences\\nwith web users. CAMEL [3], short for “Communicative Agents for ’Mind’ Exploration of Large Scale Language\\nModels,\" implements a novel role-playing agent. GPTRPG [39] combines game design with large language models,\\nenabling the deployment of multiple agents to autonomously participate in online games by embedding AI agents\\ninto the roles within the game environment using the OpenAI API.\\n5\\nRELATED PROMPTING TOOLS\\nIn this section, we provide an extensive overview of prominent prompting tools that contribute to generating\\nhigher-quality prompts or achieving advanced functionality through prompts. Since these tools do note possess\\nall four fundamental characteristics of prompting frameworks, namely modularity, abstraction, scalability, and\\nstandardization, they are not classified as prompting frameworks. Nevertheless, the problems they address and\\nthe functionalities they enable are also significant for future interactions with LLMs. Additionally, we introduce\\nsome auxiliary tools that play a vital role in task completion of prompting frameworks. Links to these tools are\\nalso organized in our GitHub repository.\\nPrompt is a powerful tool that enhances the flexibility and controllability of large language models (LLMs),\\nmaking them applicable across various domains. Through clever design and utilization of prompts, users can\\nguide the model to generate desired text, resulting in improved performance and effectiveness across various\\ntasks. It can be stated that a well-crafted prompt can significantly boost the productivity of LLMs. The significance\\nof predefined prompt templates, example libraries, or prompt optimization tools that template user-inputted\\nprompts for large language models lies in their ability to not only lower technical barriers, enabling non-technical\\nindividuals to easily interact with the model, but also enhance interaction efficiency. In other words, users can\\nselect suitable prompts from existing templates without the need to write their own from scratch. Furthermore,\\nsince templates are designed and tested, they tend to be more precise and reliable, reducing errors caused by\\nunclear or vague user instructions.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n15\\nPrompt’s Template Library. Awesome ChatGPT Prompts [1] is an open-source website and application\\ncreated by JavaScript developer Fatih Kadir Akın, which contains over 160 prompt templates for ChatGPT,\\nallowing it to mimic a Linux terminal, JavaScript console, Excel page, and more. These prompts have been\\ncollected from excellent real-world use cases. LangGPT [130] is designed to write high-quality prompts in\\na structured, templated manner. It not only provides templates but also supports variable configuration and\\nreferences based on templates. PromptSource [4] is a toolkit for creating, sharing, and using natural language\\nprompts. PromptSource allows for the use of thousands of existing and newly created prompts, which are stored\\nin separate structured files and written in a simple template language called Jinja.\\nOptimizer for Prompts. OpenPrompt [35] provides a standardized, flexible, and extensible framework for\\ndeploying prompt-based learning pipelines. It supports existing prompt learning methods and allows for the\\ndesign of custom prompt learning tasks. HumanPrompt [124] is a framework that makes it easier for humans\\nto design, manage, share, and use prompts and prompting methods. InstructZero [21] aims to optimize poorly\\nphrased prompts provided by users to LLMs, transforming them into well-structured and compliant prompts. The\\noptimization process primarily aligns humans with LLMs, rather than fine-tuning LLMs to align with humans, as\\nin instruction fine-tuning.\\nEvaluation of LLMs. Evaluating LLMs has always been a crucial topic to ensure their reliability, safety,\\nusability, and compliance while helping identify potential issues and improvement areas [5, 49, 58, 92]. Evals\\n[81] is a framework for evaluating LLMs and LLM systems and serves as an open-source registry of benchmarks.\\nEvals simplifies the process of constructing evaluations with minimal code while being straightforward to\\nuse. PromptBench [138] is a framework for robustness evaluations of large language models under adversarial\\nprompts, which facilitates examining and analyzing interactions between large language models and various\\nprompts, providing a convenient infrastructure for simulating black-box adversarial prompt attacks and evaluating\\nperformance. PromptInject [89] is a framework that modularly assembles prompts to provide quantitative analysis\\nof LLMs’ robustness against adversarial prompt attacks.\\nFig. 3. The dimensions and metrics for comparative analysis.\\n6\\nCOMPARISONS AND CHALLENGES\\nIn this section, we provide a comparison of existing prompting frameworks from various dimensions and analyze\\nthe challenges that prompting frameworks encounter in terms of development, practical implementation, and\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n16\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\nfurther advancements. The dimensions and metrics for conducting the comparative analysis are shown in Fig.\\n3, and the detailed capability matrix based on the dimensions and metrics above of the mainstream prompting\\nframework is illustrated in Fig. 4.\\nHandling \\nUnconventional Input \\nContent \\nExceeding \\nLLM’s \\nToken Limit\\nNon-textual \\nContents \\nBeyond LLMs’\\nCapabilities \\nBeneficial Effects of \\nthe Reasoning\\nAcceleration \\nof Reasoning\\nRefining \\nOutputs to \\nStipulated \\nCriteria\\nControl of LLMs \\nOutputs\\nOutput’s \\nContent\\nOutput’s \\nStructure\\nCapability \\nof Utilizing \\nExternal \\nTools\\nMaintenance \\nof Historical\\nInformation\\nImpact of \\nInvocation Costs\\nDecrease LLMs \\nInvocation \\nFrequency\\nDecrease Token \\nProcessing During \\nLLMs Invocation\\nPrompting \\nFramework\\nLangChain\\n!\\n✅\\n⛔\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\nHaystack\\n✅\\n!\\n✅\\n✅\\n✅\\n✅\\n⛔\\n✅\\n✅\\nSemantic Kernel\\n✅\\n!\\n✅\\n✅\\n✅\\n✅\\n⛔\\n✅\\n✅\\nGriptape\\nPromptFlow\\nLLM-chain\\nLinGoose\\nLLMStack\\nOpenDAN\\nHyv\\nUniversal \\nLLM-SH\\n!\\n!\\n!\\n✅\\n!\\n✅\\n✅\\n✅\\n✅\\n⛔\\n✅\\n✅\\n!\\n✅\\n⛔\\n✅\\n✅\\n✅\\n✅\\n⛔\\n✅\\n✅\\n!\\n✅\\n✅\\n!\\n✅\\n✅\\n✅\\n✅\\n⛔\\n✅\\n✅\\n!\\n✅\\n⛔\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n!\\n!\\n✅\\n⛔\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n!\\n!\\n✅\\n⛔\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n!\\n⛔\\n!\\n!\\n!\\n✅\\n✅\\n✅\\n✅\\n⛔\\n⛔\\nLlamaIndex\\n!\\n✅\\n⛔\\n✅\\n✅\\n✅\\n✅\\n✅\\nembedchain\\nAgentVerse\\nSuperAGI\\nTxtai\\nAutoChain\\nTermGPT\\nBotpress\\nDomain-\\nSpecific \\nLLM-SH\\n!\\n!\\n✅\\n!\\n⛔\\n!\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n⛔\\n✅\\n!\\n⛔\\n✅\\n✅\\n!\\n⛔\\n✅\\n✅\\n!\\n✅\\n✅\\n⛔\\n✅\\n✅\\n!\\n✅\\n✅\\n⛔\\n✅\\n✅\\n!\\n⛔\\n!\\n✅\\n⛔\\n⛔\\n!\\n⛔\\n⛔\\n!\\n!\\n⛔\\n⛔\\n!\\n✅\\n!\\n✅\\n!\\n⛔\\n⛔\\n✅\\n✅\\n!\\nLLM-SH\\nHandling \\nUnconventional Input \\nContent \\nExceeding \\nLLM’s \\nToken Limit\\nNon-textual \\nContents \\nBeyond LLMs’\\nCapabilities \\nBeneficial Effects of \\nthe Reasoning\\nAcceleration \\nof Reasoning\\nRefining \\nOutputs to \\nStipulated \\nCriteria\\nControl of LLMs \\nOutputs\\nOutput’s \\nContent\\nOutput’s \\nStructure\\nCapability \\nof Utilizing \\nExternal \\nTools\\nMaintenance \\nof Historical\\nInformation\\nImpact of \\nInvocation Costs\\nDecrease LLMs \\nInvocation \\nFrequency\\nDecrease Token \\nProcessing During \\nLLMs Invocation\\nPrompting \\nFramework\\nLMQL\\nProgram-\\n-ming \\nLLM-LNG\\n✅\\n✅\\n✅\\n✅\\n!\\n⛔\\n⛔\\n✅\\n!\\n⛔\\nSudoLang\\nPromptLang\\ngpt-jargon\\nPseudocode \\nLLM-LNG\\n⛔\\n⛔\\n✅\\n✅\\n✅\\n✅\\n!\\n!\\n⛔\\n⛔\\n⛔\\n⛔\\n⛔\\n⛔\\n⛔\\n⛔\\n⛔\\n✅\\n✅\\n✅\\n⛔\\n⛔\\n⛔\\n⛔\\n⛔\\n✅\\n✅\\n✅\\n⛔\\n⛔\\nLLM-LNG\\nHandling \\nUnconventional Input \\nContent \\nExceeding \\nLLM’s \\nToken Limit\\nNon-textual \\nContents \\nBeyond LLMs’\\nCapabilities \\nBeneficial Effects of \\nthe Reasoning\\nAcceleration \\nof Reasoning\\nRefining \\nOutputs to \\nStipulated \\nCriteria\\nControl of LLMs \\nOutputs\\nOutput’s \\nContent\\nOutput’s \\nStructure\\nCapability \\nof Utilizing \\nExternal \\nTools\\nMaintenance \\nof Historical\\nInformation\\nImpact of \\nInvocation Costs\\nDecrease LLMs \\nInvocation \\nFrequency\\nDecrease Token \\nProcessing During \\nLLMs Invocation\\nPrompting \\nFramework\\nContent \\nLLM-RSTR\\nGuidance\\nPromptify\\nReLLM\\nStructure \\nLLM-RSTR\\nLLM-RSTR\\nNeMo-Guardrails\\nGuardrails\\nTypeChat\\n!\\n✅\\n!\\n!\\n⛔\\n✅\\n✅\\n✅\\n✅\\n⛔\\n⛔\\n✅\\n⛔\\n⛔\\n✅\\n✅\\n✅\\n✅\\n⛔\\n✅\\n⛔\\n✅\\n✅\\n✅\\n⛔\\n✅\\n⛔\\n!\\n!\\n!\\n⛔\\n⛔\\n⛔\\n⛔\\n⛔\\n✅\\n✅\\n✅\\n⛔\\n⛔\\n⛔\\n⛔\\n⛔\\n⛔\\n✅\\n✅\\n✅\\n✅\\n✅\\n✅\\n⛔\\n⛔\\n⛔\\n✅\\n✅\\n!\\n!\\n⛔\\n⛔\\n⛔\\n!\\n⛔\\n✅support \\npartial support\\nnot support\\nFig. 4. The capability matrix of representative prompting frameworks.\\n6.1\\nComparative Analysis of Prompting Frameworks\\nWe have examined the three macro dimensions of compatibility, capabilities and features, as well as documentation\\nand support. Within these dimensions, we have focused on more detailed key issues, providing a comprehensive\\nanalysis and comparison of existing prompting frameworks, which offer systematic experiences and guidelines\\nfor developers and users in their practical adoption of prompting frameworks and for further advancements.\\n6.1.1\\nCompatibility. Compatibility refers to the adaptability and interoperability of systems, software, hard-\\nware, or other components in various environments or conditions. We primarily investigate the compatibility of\\nthe prompting framework with programming languages and its compatibility with LLMs.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n17\\nCompatibility of Programming Languages. Due to different development team preferences and project\\nrequirements, prompting frameworks are typically designed to consider the use of multiple programming\\nlanguages by developers. As a result, various prompting frameworks often provide interfaces supporting one or\\nmultiple mainstream programming languages to allow developers to flexibly choose and interact with languages\\nin different projects and environments, thereby enhancing development efficiency and adaptability. The currently\\navailable prompting framework provides comprehensive coverage of programming languages, including Python,\\nJava, JavaScript, C#, C++, Go (Golang), Rust, and TypeScript.\\nComparative Analysis. Currently, the prompting framework is still in its early stages of rapid development.\\nLanguage support tends to begin with an implementation in a specific language and then expand to support\\na wider range of programming languages, accommodating more use cases and domains. Overall, LLM-SH is\\ndesigned to be more adaptable to a broader range of scenarios and to support a richer set of tools. Consequently,\\nLLM-SH exhibits stronger compatibility with programming languages compared to LLM-RSTR and LLM-LNG.\\nFor instance, Txtai, within LLM-SH, offers impressive support for five mainstream programming languages:\\nPython, Java, Rust, Golang, and JavaScript. Meanwhile, LangChain and Semantic Kernel can each support three\\nprogramming languages: Python, TypeScript, and JavaScript, as well as C#, Python, and Java, respectively. Most\\nprompting frameworks tend to focus on supporting one mainstream programming language, with Python and\\nTypeScript being the primary choices. For instance, in LLM-SH, tools like Haystack, Griptape, PromptFlow,\\nLLMStack, OpenDAN, AutoChain, TermGPT, and in LLM-LNG, LMQL, as well as in LLM-RSTR, NeMo-Guardrails,\\nGuardrails, Guidance, Promptify, and ReLLM primarily support Python. On the other hand, Hyv and botpress\\nbelonging to LLM-SH, and TypeChat belonging to LLM-RSTR are specifically designed for TypeScript. LlamaIndex\\nand embedchain in LLM-SH support both Python and TypeScript. Furthermore, LLM-chain is exclusively focused\\non Rust, while LinGoose is tailored for the Golang. As for Pseudocode LLM-LNG, its intent is to create a new\\nlanguage to simplify interaction with LLMs, so SudoLang, PromptLang, and gpt-jargon support only the syntax\\nof the language designed within the framework and natural language.\\nIn summary, in terms of compatibility with programming languages, LLM-SH surpasses LLM-RSTR, which in\\nturn surpasses LLM-LNG.\\nCompatibility of LLMs. The original intention of the Prompting Framework is to establish a medium for\\ninteraction between external and LLMs. Therefore, one of the key requirements for the Prompting Framework\\nis its compatibility with LLMs, which means that the Prompting Framework should seamlessly integrate with\\nvarious types of LLMs and handle their inputs and outputs correctly. In other words, Prompting Frameworks\\nwith better compatibility generally offer a unified interface, which enables users to use the different Prompting\\nFrameworks with corresponding instructions to interact with LLMs, without requiring additional handling of\\nspecific details. The current prompting framework supports various LLMs, primarily including the previously\\nmentioned OpenAI API, Azure OpenAI API, HuggingFace API, as well as other APIs such as Llama API, Anthropic,\\nERNIE-Bot, Google PaLM, and so on.\\nComparative Analysis. Currently, support for LLMs within prompting frameworks is in a phase of rapid\\nevolution due to the continuous emergence of new LLMs. Developers need to swiftly integrate these models into\\nprompting frameworks once they are familiar with their functionalities and usage. It’s worth noting that when\\nwe refer to LLMs compatibility, we mean the ability to seamlessly integrate models into prompting frameworks\\nwithout the need for complex additional operations or coding, which implies direct utilization of models in\\nprompting frameworks through modifications to certain configurations, using the LLMs in their native supported\\nform, rather than relying on additional plugins or frameworks. Models that are natively supported by prompting\\nframeworks tend to integrate better with the framework, fully leveraging the model’s capabilities and minimizing\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n18\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\nTable 2. The maximum tokens supported and pricing of mainstream LLMs.\\nModel\\nDeveloper\\nMax Token\\nCost / 1K tokens\\nInput\\nOutput\\ngpt-4\\nOpenAI\\n8,192\\n$0.03\\n$0.06\\nAzure OpenAI\\ngpt-4-32k\\nOpenAI\\n32,768\\n$0.06\\n$0.12\\nAzure OpenAI\\ngpt-3.5-turbo\\nOpenAI\\n4,097\\n$0.0015\\n$0.002\\nAzure OpenAI\\ngpt-3.5-turbo-16k\\nOpenAI\\n16,385\\n$0.003\\n$0.004\\nAzure OpenAI\\ntext-davinci-003\\nOpenAI\\n4,097\\n$0.012\\n$0.016\\nAzure OpenAI\\ntext-davinci-002\\nOpenAI\\n4,097\\n$0.012\\n$0.012\\nAzure OpenAI\\ntext-embedding-ada-002\\nOpenAI\\n8,191\\n$0.0001\\n$0.0001\\nClaude Instant\\nAnthropic\\n100,000\\n$0.00163\\n$0.00551\\nClaude 2\\nAnthropic\\n100,000\\n$0.01102\\n$0.03268\\nLlama 2\\nMetaAI\\n4,096\\nfree\\nfree\\nCohere\\nCohere\\n4,096\\n$0.015\\n$0.015\\nPaLM 2\\nGoogle\\n8,000\\n$0.0005\\n$0.0005\\nunexpected bugs during programming. At present, all prompting frameworks offer good support for prominent\\nAPIs released by OpenAI, namely text-davinci-003, gpt-3.5-turbo, chatgpt, and gpt-4. In other words, prompting\\nframeworks were originally introduced to facilitate user interactions with these mainstream APIs. Pseudocode\\nLLM-LNG is a special case where this mutation-free pseudocode language can work well with any interactive\\ninterface-based LLMs. Consequently, SudoLang, PromptLang, and gpt-jargon can be compatible with almost\\nall interactive LLMs. Only a few prompting frameworks currently offer support for Hugging Face APIs. For\\ninstance, within LLM-SH, LangChain, Semantic Kernel, Haystack, Griptape, PromptFlow, LinGoose, LlamaIndex,\\nembedchain, Txtai, AutoChain, and within LLM-RSTR, TypeChat and Promptify, provide such support. The\\nmentioned prompting frameworks can also be compatible with Google’s Azure OpenAI API. Furthermore, for\\nother popular APIs like Claude from Anthropic, Llama API, Google PaLM, etc., only LLM-SH’s LangChain,\\nSemantic Kernel, Haystack, Griptape, Txtai, LlmaIndex, and embedchain can offer good support.\\nIn summary, all prompting frameworks offer good support for OpenAI’s APIs. In general, LLM-SH exhibits the\\nstrongest compatibility with LLMs, while Pseudocode LLM-LNG demonstrates exceptional compatibility when\\ndealing with interactive interface-based LLMs without requiring compilation.\\n6.1.2\\nCapabilities and Features. Capabilities and features are a crucial dimension when comparing different\\nPrompting Frameworks, as they directly determine the framework’s ability and flexibility in addressing problems\\nand meeting user requirements. We elaborate on various crucial stages of the interaction between LLMs and\\nthe Prompting Framework, including data preprocessing, reasoning process, output control, cost considerations,\\ntool learning, and information maintenance. The comparison dimensions of capabilities and features we have\\nenumerated can be employed not only for analyzing the strengths and limitations of diverse prompting frameworks\\nbut also as evaluation metrics for forthcoming tasks in assessing the prompting frameworks.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n19\\nCapability of Handling Unconventional Contents. The ability of prompting frameworks to assist LLMs in\\nhandling unconventional content primarily manifests in two aspects. Firstly, the prompting framework helps\\nLLMs deal with content that exceeds the token limit, and secondly, the prompting framework empowers LLMs to\\nprocess non-textual content formats that go beyond their inherent capabilities. Usually, LLMs have a token limit\\ndetermined by the model’s architecture and memory constraints. For example, GPT-3.5-turbo and text-davinci-003\\nhave a maximum input length of 4,097 tokens, while gpt-3.5-turbo-16k allows for 16,385 tokens, and GPT-4-32k\\nallows for 32,768 tokens, which results in LLMs being unable to capture the global context of a text when dealing\\nwith extremely long documents without external support because only a portion of the text can be included.\\nThe maximum tokens supported and pricing of mainstream LLMs are shown in Tab. 2. Moreover, processing\\nsuch long text can lead to performance issues, especially in resource-constrained environments. LLMs need to\\nmaintain a lot of information within a single input, which may require more computational resources and time.\\nTherefore, prompting frameworks have emerged to assist LLMs in handling complex tasks involving extremely\\nlong texts, such as machine translation, legal document analysis, sentiment analysis of lengthy novels or articles,\\nlong-context dialogue systems, knowledge graph construction, etc. LLMs are primarily designed for processing\\npure textual data, making them less suitable for unconventional formats like images, audio, or videos, whose\\nmain inputs and outputs are text data. Prompting frameworks effectively mitigate this limitation, enabling LLMs\\nto handle a variety of data types, which broadens the application of LLMs to a wide range of multimedia tasks.\\nComparative Analysis. In terms of the capability to handle content exceeding token limits and non-textual\\ncontent, only LLM-SH can achieve these functionalities without the need for additional plugins or program calls.\\nLLM-LNG and LLM-RSTR achieve these capabilities by making calls to LLM-SH within their framework design.\\nHowever, it’s important to note that such compatibility can potentially lead to unexpected bugs.\\nFor handling content that exceeds token limits, LLM-SH empowers LLMs through methods like splitting,\\nfiltering, concatenation, or summarization. For instance, a classic approach is the “Retrieval\" module in LangChain,\\nwhere “Document transformers\" offer pre-packaged functional functions for document splitting, composition, and\\nfiltering. In the “Chains\" module, there is a package called “chains.summarize\" that provides various methods for\\nsummarizing documents (PDFs, Notion pages, customer questions, etc.), including Map-Reduce, Stuff, and Refine\\napproaches to organizing documents. By configuring parameters to design a \"chain\" structure differently and\\nintroducing vector databases and text embedding models, LLMs can effectively manage extremely long documents.\\nSimilarly, modules like \"Summarizer\" in Haystack and \"Summary Engines\" in GripTape can summarize long texts,\\nand components like \"PreProcessor\" in Haystack and \"Chunkers\" in GripTape can perform text splitting and\\nfiltering for long texts.\\nWhen it comes to handling non-textual content, LLM-SH can process text extracted from non-text formats\\nlike YouTube videos or HTML files or generate multi-modal content such as images, videos, and audio, based\\non pure text content. However, it doesn’t provide full-fledged processing of multimedia files throughout the\\ninput-output process. For instance, the \"Tool Memory\" module in GripTape can generate images, videos, PDFs,\\nand other non-textual content. Similarly, the \"Document loaders\" module in LangChain exposes a \"load\" method\\nfor loading data as documents from a configured source.\\nIn summary, only LLM-SH can assist LLMs in handling unconventional input contents, while LLM-LNG and\\nLLM-RSTR need to rely on LLM-SH to achieve this functionality. LLM-SH deals with content exceeding token\\nlimits by splitting, filtering, reassembling, or summarizing long documents. Regarding non-textual content,\\nLLM-SH processes the text portions extracted from multimedia files or generates multi-modal multimedia\\nfiles based on pure text content.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n20\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\nBeneficial Effects of the Reasoning Process. The benefits of prompting frameworks for LLMs in the\\nreasoning process are primarily evident in two capabilities: accelerating reasoning and ensuring that reasoning\\nresults meet preset requirements. In the current scenario with a surge in data volume and user usage, the speed\\nof LLMs’ reasoning is crucial for completing tasks efficiently. Additionally, improved reasoning results enable\\nLLMs to accomplish more work in a given unit of time, greatly facilitating the application of these powerful\\nnatural language processing models in tasks requiring rapid responses and high throughput. For example, it’s\\nuseful in online customer support (providing instant responses to customer queries for better user experiences),\\nreal-time financial analysis (for timely financial decision-making by analyzing news events and market data), and\\nreal-time sentiment analysis (for tracking product or brand feedback on social media in real-time).\\nComparative Analysis. Regarding the crucial functionality of accelerating reasoning, most prompting frame-\\nworks do not provide support. Among the prompting frameworks surveyed, only LMQL within LLM-LNG offers\\nthis relevant service. LMQL accelerates inference by providing eager validation during LLM runtime. The principle\\nbehind eager validation is that LLMs typically generate text sequentially, similar to how humans write. When\\nusers make requests to LLMs with conditions like \"the output must satisfy A and B,\" LMQL monitors the output\\nas it’s being generated. If LMQL detects that the currently outputted portion no longer satisfies condition A, it\\nforcibly stops the LLM’s execution and triggers it to re-infer, which eliminates the need to wait until the LLM\\ncompletes the entire response to determine if the output complies with the conditions. For example, if a user\\ninstructs Chatgpt with the input \"Write a poem about the sky, excluding clouds and birds,\" conditions A and B are\\n\"excluding clouds\" and \"excluding birds.\" If Chatgpt generates a description of \"clouds\" during the writing process,\\nit no longer meets the user’s request. Therefore, LMQL performs a forced termination of Chatgpt and resumes\\nfrom the error-free portion to continue the task. This \"validate-as-you-go\" approach significantly accelerates\\nLLM inference.\\nTo ensure that inference results meet preset requirements, LLM-LNG, LLM-RSTR, and LLM-SH all utilize\\nvalidate templates or allow for user-defined templates to ensure more standardized and accurate prompts (inputs).\\nFor instance, features like \"Prompts\" in LangChain’s Model I/O module and \"PromptTemplate\" in Haystack\\nenable predefined templates as well as user-defined templates within the framework. Additionally, the previously\\nmentioned eager validation not only accelerates inference but also enforces stricter compliance with output\\nrequirements, making it easier to obtain outputs consistent with expectations and standards.\\nIn summary, to enhance the inference process of LLMs, LLM-LNG, LLM-RSTR, and LLM-SH all use methods\\nsuch as predefined templates or compatibility with user-defined templates to ensure that inference results\\nbetter meet requirements. Only LMQL within LLM-LNG supports the acceleration of the reasoning process\\nduring LLM runtime.\\nControl of LLMs Outputs. Prompting framework’s role in achieving controllable generation with LLMs\\nprimarily addresses two issues: imposing fine-grained structural constraints on generated output and ensuring\\nthat LLMs do not produce sensitive, non-compliant, or unsafe content. The significance of structured output\\nfrom LLMs lies in its ability to transform natural language text into a structured format, making information\\neasier to process, analyze, and apply. The structured output aids in tasks such as extracting key information\\nfrom text, building knowledge graphs, and performing data analysis. Structured data plays a crucial role in\\ninformation management and data analysis, supporting decision-making, process optimization, insight discovery,\\nand the development of intelligent applications. Structured data is essential in various industries and domains,\\nhelping organizations better understand and leverage their data assets. The safety and relevance of LLMs’ output\\ncontent are crucial because these factors directly impact whether the text generated by the model is appropriate,\\naccurate, and useful. For example, content filtering on social media platforms ensures that content posted on\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n21\\nthese platforms does not contain inappropriate or rule-violating material, maintaining the platform’s reputation\\nand user experience. In online customer support, automated response systems generate information only related\\nto product support or common issues, ensuring that responses generated by automated systems are both on-topic\\nand free from inappropriate content. Maintaining the online platform’s brand reputation, protecting user rights,\\nproviding accurate information, and enhancing the availability of automated systems are all essential. Using\\nprompting frameworks to assist in the automated and intelligent handling of LLMs’ output content, ensuring that\\ngenerated text meets specific requirements, has practical applications in social media, news media, e-commerce,\\nonline education, and many other fields.\\nComparative Analysis. When it comes to constraining the output structure of LLMs, LLM-SH, LLM-LNG, and\\nContent LLM-RSTR typically provide interfaces or pre-packaged functions that, when given custom structured\\ntemplates provided by users, transform LLMs’ output into the corresponding structured format. For example,\\nLangChain’s Model I/O module offers \"Output parsers,\" which are classes designed to help structure language\\nmodel responses. By invoking LangChain’s built-in functions and combining them with user-configured structural\\ntemplates, LLM-SH’s LangChain directly supports various commonly used structured output forms, such as\\nlists, time formats, enumerations, JSON, and more. In Semantic Kernel within LLM-SH, LMQL within LLM-LNG,\\nand SudoLang, which are designed with frameworks and syntax that allow the mixing of natural language with\\ncode, support for structured data is achieved through user-configured custom structural templates. This means\\nthat users need to design, describe, and write their own templates in the corresponding framework’s custom\\ntemplate locations. However, in the case of Structure LLM-RSTR, a category of prompting frameworks specifically\\ndesigned for structured output, they offer built-in features for structured data generation and validation and\\nexcel at supporting formats like JSON and dialogue-based data. For instance, in Guidance, you can use the \"gen\"\\ncommand to interleave generation, prompting, and logic control in a continuous sequential flow that aligns with\\nhow the language model processes text. In TypeChat, there’s the provision of Schema, a data structure used to\\ndescribe the expected format and fields of a prompt. By defining a Schema, you can validate and correct user\\ninput to ensure it adheres to the expected format and requirements.\\nSecuring and ensuring compliance with the output content of LLMs is crucial. However, except for Content LLM-\\nRSTR within LLM-RSTR, no other prompting frameworks address this issue. In Content LLM-RSTR, Guardrails is\\na Python package that adds type and quality assurance to LLMs’ output, including semantic validation, such as\\nchecking for biases in generated text and errors in generated code and takes corrective measures when validation\\nfails. Guardrails provides a file format (.rail) for executing \"specifications\" (user-specified structural and type\\ninformation, validators, and corrective actions) on LLMs’ output and offers a lightweight API call wrapper to\\nimplement these specifications on the output. NVIDIA’s NeMo-Guardrails follows a similar design philosophy,\\nensuring control, safety, and security of large model language generation by limiting templates and themes in\\nconversations. NeMo-Guardrails employs a custom language to implement a three-layer protection mechanism,\\nincluding Topical GuardRail for topic-related questions, Safety GuardRail for ensuring controlled responses, and\\nSecurity GuardRail to protect against malicious or abusive questions. However, this approach, while practical, also\\nintroduces potential challenges such as configuration redundancy, inflexibility, operational risks, and limitations\\non the original conversational capabilities of LLMs.\\nIn summary, LLM-SH, LLM-LNG, and LLM-RSTR all offer different ways to support control over the structure\\nof LLMs’ output, but only Content LLM-RSTR within LLM-RSTR provides constraints and validation for the\\nsafety and compliance of LLMs’ output content, albeit with certain potential issues in its functionality.\\nImpact of Invocation Costs. Reducing the cost of LLMs invocation primarily involves two approaches: firstly,\\nreducing the frequency of invoking LLMs, and secondly, decreasing the number of tokens processed during LLMs\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n22\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\ninvocation. Utilizing LLMs services on cloud computing platforms such as AWS, Azure, and Google Cloud incurs\\ncharges for each model invocation. These costs escalate with the frequency of invocations and the extent of\\ncomputational resources used. One of the significant challenges in implementing LLMs for practical production\\nscenarios is the high cost associated with invoking LLMs, which can be burdensome for individuals and even\\nenterprises with limited financial resources. LLMs are typically billed based on the number of tokens generated\\nor processed, with the number of tokens subject to charges determined by the prompt and the corresponding\\nresponse length. The billing unit is the \"token,\" which can represent a word, character, or punctuation symbol. In\\nEnglish, one token typically corresponds to one word, but for other languages, token forms may vary due to\\ndifferences in language structures. Different models have varying token pricing standards; for example, GPT-3.5\\nis priced at $0.002 per 1000 tokens, while GPT-4’s token price is nearly six times higher than that of GPT-3.5. The\\nmaximum tokens supported and pricing of mainstream LLMs are shown in Tab. 2. While the cost per individual\\ntoken may appear acceptable from a computational perspective, it becomes substantial for long-term usage and\\ncomplex tasks. For instance, translating large documents, especially complex technical documents across multiple\\nlanguages, may require extended processing time and additional computational resources. Similarly, employing\\nLLMs for large-scale data analysis, text mining, or information extraction tasks, such as processing tens of\\nthousands of news articles to extract key information, might necessitate distributed computing environments\\nand substantial storage, resulting in high invocation costs.\\nComparative Analysis. In terms of reducing the frequency of LLMs invocation, LLM-SH introduces the \"Memory\"\\nmodule that stores historical query information. Leveraging vector databases, enables a form of \"learning from\\nthe past,\" so that when encountering the same or similar questions, LLMs do not need to be invoked again, thus\\nsaving unnecessary computational expenses. For instance, LLM-SH’s LangChain implements a \"Memory\" module\\nfor storing past interactions, Haystack includes a \"Module memory\" module with the InMemoryDocumentStore\\nclass for recording and retrieving interaction content, and Griptape offers a \"Conversation Memory\" module\\nwith BufferConversationMemory functionality for constructing prompts with sliding window tasks. In contrast,\\nLLM-LNG primarily reduces the frequency of invoking LLMs by embedding preprocessing programs and modules\\nwithin the framework. Simple questions are first handled by smaller or free models, and then LLMs are utilized for\\nmore detailed processing, thus reducing the number of LLMs invocations. However, this method has limitations\\nin broader tasks. Additionally, LLM-RSTR frameworks typically do not consider this functionality. Regarding\\nthe prompting framework’s role in reducing the number of tokens that LLMs need to process, LLM-SH employs\\ntechniques like splitting, filtering, concatenating, or summarizing text segments to abbreviate and simplify the\\ncontent to be processed. This aligns with the earlier-discussed approach of handling extremely long documents.\\nIn summary, the current state of prompting frameworks does not fully address the crucial challenge of reducing\\nthe cost of LLMs invocation. LLM-SH employs \"Memory\" functionality and text manipulation techniques to\\nreduce the frequency of invocations and the number of tokens to be processed. LLM-LNG relies on embedded\\npreprocessing modules, which have limited applicability, while LLM-RSTR frameworks generally do not\\nimplement this capability. Therefore, in the future, reducing the cost of LLMs invocation should be an essential\\narea of development for prompting frameworks.\\nCapability of Utilizing External Tools. The ability to use tools is one of the most significant distinctions\\nbetween humans and other species. Currently, a crucial limitation of LLMs in practical applications is their\\ninability to use external tools like humans. However, the advent of prompting frameworks effectively mitigates\\nthis deficiency. Typically, LLMs are generalized models, so the capability for LLMs to utilize external tools holds\\nsignificant importance for enhancing their functionality, adapting to specific tasks and domain requirements,\\nproviding access to more data and resource support, and meeting compliance and security demands. For example,\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n23\\nin custom text generation tasks, combining external plugins with LLMs allows the generation of industry-specific\\nnews reports, creative writing, or legal documents. In complex data query tasks, integrating LLMs with database\\nquery plugins enables them to respond to intricate business queries such as sales reports, inventory management,\\nor medical record retrieval. Furthermore, multimodal processing plugins can be integrated with LLMs to analyze\\nand generate content with text, images, and audio elements, such as social media posts or advertisements.\\nComparative Analysis. In terms of enabling LLMs to use external tools, LLM-SH outperforms LLM-RSTR and\\nLLM-LNG due to its design focus. LLM-SH can support the integration of LLMs with a wide range of tools spanning\\nvarious domains, such as web browsers, databases, email clients, image processing tools, speech recognition\\nengines, code processors, and more. For instance, LangChain’s Agents module offers a Toolkit function in which\\na collection of tools designed for specific tasks and conveniently loaded methods are available. These tools\\nencompass Gmail, GitHub, SQL Databases, Vectorstore, and various Natural Language APIs. GripTape utilizes\\nthe Tools module’s TextToolMemory to enhance the output of all tools, while also allowing users to perform\\ndifferent degrees of customization at the structural, task, or tool activity levels. TextToolMemory empowers LLMs\\nto interact with the external world, generating non-textual content such as images, videos, PDFs, and others. In\\ncontrast, LLM-LNG and LLM-RSTR provide limited support for only the most commonly used external tools. For\\ninstance, LMQL in LLM-LNG offers services restricted to calculators and Wikipedia tools, while Guidance in\\nLLM-RSTR offers integration with the Bing search engine.\\nIn summary, the current state of prompting frameworks for enabling LLMs to integrate with external tools\\nis in its initial and somewhat immature stage. LLM-SH provides LLMs with the capability to use tools in\\nrelatively diverse scenarios to some degree, while LLM-LNG and LLM-RSTR offer very limited support in this\\nregard.\\nMaintenance of Historical Information. Maintenance of historical interaction information is crucial for\\nLLMs as it provides them with the ability to store, retrieve, and reference information. This capability aids in\\nbetter understanding context, maintaining coherence in complex tasks and long texts, and benefiting from past\\ncomputations. However, apart from chat models like ChatGPT, which can record some history within the same\\nconversation interface (with no sharing of information across different interfaces), LLMs typically process only\\nthe current context information provided in the prompt during service. This limitation is inconvenient for users\\nas historical interaction information not only enhances interactions with LLMs, reducing the need for repetitive\\nwork but also stimulates non-dialogue LLMs like GPT-3.5 in chat tasks. Prompting frameworks address this need\\nby offering \"Memory\" systems, supporting two fundamental operations: reading and writing. This enables the\\nstorage of historical interaction information and its utilization through queries, searches, and retrieval. Prompting\\nframeworks empower LLMs with the ability to maintain historical interaction information, aiding in context\\nunderstanding, information retrieval, multi-turn question-answering, document reading, error detection and\\ncorrection using memory, caching intermediate computation results, and storing user preferences, historical\\nbehavior, or personalized information.\\nComparative Analysis. Regarding the maintenance of historical interaction information, LLM-SH excels due to\\nits comprehensive Memory system, which allows integration with various tools across different domains. Taking\\nLangChain as an example, the \"Memory\" can store past chat messages, queries, and results, effectively adding\\nmemory to the system. This storage function can be used independently or seamlessly integrated into various\\nchains. Moreover, LangChain supports the use of embedded models and vector databases to store, query, and\\nmaintain historical information. During a single run, the system interacts with \"Memory\" twice, once when\\nproviding a query. The prompt includes two parts, one directly from user input, and the other possibly extracted\\nfrom information stored in memory. The second interaction records the current interaction in memory for\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n24\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\nfuture queries and retrieval. LLM-SH’s Memory system usually offers multiple ways to manage short-term\\nmemory, such as ConversionMemory and VectorStore-backed Memory. ConversionMemory summarizes ongoing\\nconversations and stores the current summary in memory, passing it as short-term memory to LLMs in new\\nrounds of conversation. This compression of historical conversation information is particularly useful for lengthy\\nconversations. On the other hand, VectorStore-backed Memory stores all past conversations in vector form in\\na vector database. In each new conversation round, it matches the user’s input against the vector database to\\nfind the most similar K sets of conversations. LLM-LNG and LLM-RSTR typically achieve historical information\\nmaintenance by invoking the corresponding functional modules in LLM-SH. An interesting feature in LLM-LNG is\\nLMQL’s \"Caching Layer,\" implemented as a tree-like data structure. This layer caches all model outputs, including\\nlogs and historical information, to enable more efficient exploration of the LLM’s token space during runtime,\\neven in the presence of multiple variables, constraints, and tool enhancements. The cache can be seen as a tree\\nwith only appendices, explored during query execution and expanded based on query code, constraint conditions,\\nand inferred execution scenarios.\\nIn summary, LLM-SH provides a relatively complete and comprehensive memory system for maintaining\\nhistorical interaction information, while LLM-LNG and LLM-RSTR typically achieve this by invoking corre-\\nsponding functional modules within LLM-SH.\\n6.2\\nDocumentation and Support.\\nDocument quality and community support are crucial for a prompting framework. Document integrity refers to\\nthe accuracy, readability, and completeness of technical documentation, which assesses whether the development\\nteam provides detailed, clear, and comprehensive documentation to facilitate user learning and usage. Community\\nsupport involves the presence of an active developer community around the framework, allowing users to receive\\ntimely assistance and feedback.\\nDocument Completeness. The investigated prompting frameworks offer three primary deployment methods.\\nThe first method is command-line installation, where Python-based frameworks use commands like \"pip install\"\\nor \"conda install,\" and JavaScript-based frameworks use \"npm install\" for deployment. This method is available\\nfor almost all prompting frameworks. The second method is a custom interactive user interface, providing a\\nplayground that allows users to interact with the framework directly through a user-friendly interface without the\\nneed for installation, for example, LMQL in LLM-LNG. The third method is the \"open-and-use\" approach, where\\ndeployment and execution are done directly on the interface provided by LLMs, offering the most straightforward\\nand simple operation. SudoLang in LLM-LNG is an example. Overall, the prompting frameworks studied provide\\ncomprehensive technical documentation that covers almost all features and use cases. They also offer detailed\\nexample code, tutorials, and operation guides, making it easy for users to get started, understand, and use these\\nframeworks. These technical documents are readily accessible on GitHub. Additionally, some frameworks have\\ncreated well-designed web pages with high readability and attractiveness, such as LangChain in LLM-SH.\\nDocument Readability. At present, the technical documentation of existing prompting frameworks is\\ncomprehensive and detailed but may lack readability. The rapid proliferation of LLMs and their derivatives has led\\nto a need for frequent updates to the technical documentation. These updates may occur daily to accommodate\\nmore products and features. The introduction of new features can sometimes render old ones unusable or\\nintroduce bugs, causing significant challenges for users and developers. Furthermore, the continuous addition of\\nfeatures and product introductions can make the documentation structure complex and the content increasingly\\nlengthy. This can lead to a situation where the documentation becomes overwhelming and resembles a \"code\\nmountain\" rather than maintaining the clarity and simplicity of its initial state, which can be frustrating for users.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n25\\nIn summary, the dynamic nature of LLMs and their associated frameworks necessitates frequent documentation\\nupdates, but these updates must be managed carefully to maintain clarity and usability for users and developers.\\nCommunity Support. Regarding community support and user feedback channels, the development teams\\nbehind these prompting frameworks typically offer Discord online community services. Users can ask questions,\\nshare experiences, and engage with other users in these communities. Furthermore, they maintain official support\\nteams on Twitter and have dedicated communication topics (tags) for users to provide feedback, suggestions,\\nand opinions, thus facilitating framework improvements. Additionally, they provide communication spaces on\\nGitHub for users and developers.\\n6.3\\nChallenges Confronting the Prompting Framework\\nThe existing prompting frameworks currently alleviate many limitations of LLMs in practical applications,\\nsignificantly enhancing the capabilities of LLMs themselves and further elevating their performance. However,\\nburgeoning development still encounters numerous challenges. In this section, we will analyze the challenges\\nand opportunities that the prompting framework currently faces in terms of functionality implementation and\\nissues related to safety and ethics.\\n6.3.1\\nSecurity Mechanisms of Prompting Framework. For a developed tool, both functionality and security\\nmechanisms are equally crucial. Software that cannot guarantee the security of user information and is not\\nharmless to society, regardless of its robust functionality, is unlikely to gain user support. Existing evidence\\nsuggests that LLMs and relatively mature prompting frameworks like LangChain have certain security issues\\n[6, 62, 66, 87, 118]. However, the existing prompting frameworks have paid minimal attention to the significance\\nof security ethics and privacy protection. Due to LLMs possessing an \"Achilles’ heel\" – being uncontrollable\\ngenerative AI, we cannot predict the outputs, which can be fatal in certain scenarios. Therefore, we argue that the\\nsecurity mechanisms that prompting frameworks urgently need to enhance should consist of two parts: defense\\nagainst prompt-based attacks and safeguarding the behavior of LLMs.\\nDefense Against Prompt-based Attacks. We begin by introducing the concept of Prompt-based Attacks\\nand then provide some suggestions to mitigate this issue within future prompting frameworks. Prompt-based\\nAttacks share essential similarities with Prompt Engineering in that they both aim to obtain desired outputs\\nthrough expertly crafted, rational, and optimized instructions. However, Prompt Engineering is user-oriented,\\nwhile Prompt-based Attacks adopt a hacker-attack perspective. Malicious inputs from external sources can\\ncontaminate the model’s outputs through Prompt-based Attacks, thereby exerting influence on external systems,\\nresulting in adversarial actions. The impact of such attacks depends on the capabilities granted to the model by\\nthe system. Prompt-based Attacks refer to attempts to generate content that contradicts the developer’s intent\\nusing LLMs [31, 43, 62, 89, 125]. Typically, there are two forms of attacks: Prompt-based Deception (bypassing\\nscrutiny through linguistic techniques) and Prompt-based Injection (tampering with instructions). In scenarios\\nlimited to content generation, the harm caused by these attacks may be relatively insignificant. However, with the\\nproliferation of various prompting frameworks and projects like AutoGPT, more individuals are granted execution\\nauthority over LLMs, expanding the potential danger. These scenarios encompass not only the creation of email\\nworms utilizing automated email processing functions but also poisoning email extraction systems through\\nweb-based attacks, code poisoning through code completion mechanisms, and more ominous possibilities, such\\nas manipulating or accessing local files or diverting funds if a private prompting framework assistant were to be\\ncompromised or granted execution authority.\\nAs for defense mechanisms against Prompt-based Attacks, we offer several suggestions from the perspective\\nof instruction design. Firstly, when constructing prompts for interaction with LLMs, it is advisable to employ\\ndelimiters to rigorously differentiate instructions from content, which involves encapsulating user-generated\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n26\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\ncontent within delimiters and imposing specific authority constraints, a practice endorsed by OpenAI and machine\\nlearning expert Andrew Ng as a best practice. Secondly, place crucial instructions at the end of the prompt.\\nGiven that most malicious instructions currently tend to disregard preceding instructions, positioning developer\\ninstructions at the end of the entire prompt is indeed a straightforward and convenient method in practice.\\nLastly, consider incorporating a pre-filtering layer, such as establishing whitelists and blacklists for prompt\\ncontent. Whitelists define permissible inputs, for instance, in the case of designing a machine translation model\\nfrom Chinese to English, pre-detect and allow only Chinese characters in the prompt for synthesis with the\\nmodel. Conversely, blacklists prohibit specific inputs, for instance, detecting common jailbreak-related phrases or\\ninstructions like \"ignore\" and refrain from inputting them into the model or checking for the presence of phrases\\nprohibited by other legal regulations.\\nSafeguards of LLMs’ Behavior. As is widely acknowledged, LLMs while gaining favor from millions of users,\\noccasionally exhibit undesirable behaviors such as escaping, hallucinating, and deception. Therefore, it is crucial\\nto \"muzzle\" LLMs by adding an additional safeguard layer to their output. Starting from the design principles\\nand implementations of the prompting framework, augmenting LLMs with an additional protective mechanism\\nwithin the prompting framework is both reasonable and aligned with software development principles. This\\naugmentation allows for the early interception and modification of objectionable or non-compliant content in\\nthe output of LLMs before obtaining the final results.\\nThe Nemo Guardrails developed by Microsoft, as mentioned earlier, still has several issues when it comes\\nto protecting LLMs’ behavior. Firstly, it uses its proprietary definition language, which may appear more user-\\nfriendly but limits its extensibility. Moreover, it transforms a model’s security and control problem into a manual\\npolicy configuration problem. This approach brings various potential issues such as redundant configurations,\\nlack of flexibility, operational risks, and potential curtailment of the original capabilities of large language models.\\nIt seems to be more like a compromise solution in today’s commercial scenarios where there is a desire to\\neffectively utilize the generation capabilities of large models but no effective solution for controllability and\\nsecurity.\\nTherefore, we believe that future prompting frameworks should be designed based on mainstream programming\\nlanguages, employing advanced technologies to establish flexible and automated mechanisms for extracting and\\nconfiguring protection rules, which focus on three main aspects: topic relevance, content safety, and application\\nsecurity, ultimately standardizing the behavior of LLMs. Thematic integrity safeguards aim to prevent LLMs from\\ngoing off-topic. LLMs possess a richer imagination and are more capable of creative code and text generation\\ncompared to other AIs. However, for specific applications such as coding or customer service, users do not\\nwant them to \"stray from the intended scope\" while addressing issues, and generating irrelevant content. In\\nsuch cases, topic-constrained safeguards are required. When a large model generates text or code that goes\\nbeyond the predefined topic, these safeguards guide it back to the designated functionality and topic. Content\\nsafety safeguards are intended to prevent incoherent output from large models. Incoherent output includes two\\nscenarios: factual inaccuracies in the answers generated by LLMs, which are things that \"sound reasonable but\\nare entirely incorrect,\" and the generation of biased or malicious output, such as using offensive language when\\nprompted by users or generating unethical content. Application security refers to restricting the application’s\\nconnections to known secure third-party applications. The prompting framework should avoid exposing LLMs to\\nmalicious attacks from external sources during task execution. This includes preventing the induction of LLMs to\\ncall external virus plugins and defending against hackers who may attempt to attack LLMs through methods like\\nnetwork intrusion or malicious software.\\n6.3.2\\nCapability Limitations of Prompting Framework. In comparing and analyzing the capabilities and\\nfeatures of prompting frameworks, we delineate 6 dimensions. Prompting frameworks exhibit commendable\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n27\\nperformance across these capability dimensions, but they still exhibit shortcomings in the degree of implementa-\\ntion within each capability dimension. For instance, concerning the handling of unconventional inputs, current\\nprompting frameworks can significantly assist LLMs in text processing leaps but remain somewhat constrained\\nin multi-modal scenarios (e.g., video and images). Similarly, limitations exist in invoking external expert models.\\nFurthermore, as the landscape of large models continuously evolves with the emergence of numerous LLMs and\\nexternal plugins, many prompting frameworks adapt by continually adding encapsulated invocation functions to\\nsupport relevant services. However, this rapid evolution introduces several challenges. The updated functionalities\\nare often haphazardly aggregated and do not offer the same level of support as native capabilities provided by\\nthe framework. Additionally, more intricate functionalities may lead to contradictions or duplications when\\nnot properly planned, resulting in a steep learning curve for users. Consequently, we analyze the limitations\\nof current prompting frameworks from these perspectives: an increasingly steep learning curve, constraints in\\ninvoking external interfaces and handling multi-modal I/O.\\nIncreasingly Steep Learning Curve. With the explosive growth in the field of large models, numerous related\\ntools and plugins have emerged, which has posed significant challenges to the development and maintenance\\nof prompting frameworks, requiring software engineers to quickly familiarize themselves with these emerging\\nexternal tools and integrate their interfaces into the existing prompting framework. This has resulted in some\\nfunctionality stacking and redundancy. For example, native functionalities within the prompting framework\\ntypically allow for straightforward invocation with uniform interfaces, achieved by simply modifying parameters.\\nConversely, newly added functionalities often necessitate users to invoke other packages and employ relatively\\ncomplex and non-uniform calling procedures. Consequently, users must acquire additional knowledge before\\nusage, resulting in steeper learning curves. The relatively complex processes and methods also lead to suboptimal\\nuser experiences or program bugs. Furthermore, the introduction of new functionalities may disrupt the proper\\nfunctioning of previously implemented native features, which is a recurring issue within existing prompting\\nframeworks. As previously indicated, it has been observed that the technical documentation of the existing\\nprompting framework exhibits deficiencies in terms of readability. The emergence of this problem is logical,\\nand an effective mitigation strategy involves developers considering future developments and changes in the\\nframework’s structural design, which entails enhancing the modularity, scalability, and standardization of the\\nprompting framework.\\nConstraints in Invoking External Interfaces. Currently, prompting frameworks can support relatively basic\\nexternal tool usage, such as browsing the web or querying databases. However, we argue that the accessibility of\\nexternal expert models remains rudimentary within most prompting frameworks. For instance, current prompting\\nframeworks cannot fully assist LLMs in utilizing the widely-used \"Microsoft Suite\" in commercial and office\\nenvironments, including Microsoft Word, Microsoft Excel, and Microsoft PowerPoint. Additionally, prompting\\nframeworks lack secure protocols for accessing and handling users’ private or commercial data that meet security\\nand privacy requirements. Furthermore, because current prompting frameworks can only handle text-based\\ntasks, there are limitations in handling multi-modal inputs such as videos, Word documents, emails, etc. This\\nmakes it challenging to provide support for widely-used functional tools like YouTube (one of the world’s largest\\nvideo-sharing platforms with billions of users), arXiv (a significant open-access academic preprint platform),\\nTwitter (a prominent social media platform in the realm of social media and news dissemination), Outlook (one of\\nMicrosoft’s widely-used email and calendar management tools), and others. In the future, prompting frameworks\\nshould aim to not only assist LLMs in supporting these widely-used mainstream software but also allow for the\\nintegration of more emerging or niche tools or platforms to foster a more vibrant AI community ecosystem.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n28\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\n7\\nFUTURE DIRECTIONS AND CONCLUSION\\n7.1\\nConclusion of Existing Prompting Frameworks\\nIn this paper, we elucidate the genesis of the prompting framework and its underpinning technological foundations.\\nSubsequently, we proffer a conceptual definition of the prompting framework, along with its requisite character-\\nistics of modularity, abstraction, extensibility, and standardization. We then classify the prompting framework\\nbased on usage scenarios and technical attributes into three categories: the shell of LLMs (LLM-SH), language for\\ninteraction with LLMs (LLM-LNG), output restrictors of LLMs (LLM-RSTR). Following this categorization, we\\nconduct a comprehensive comparative analysis of the compatibility, capabilities and features, documentation,\\nand community support of these prompting frameworks across various dimensions. Finally, we delineate the\\nchallenges currently confronting the development of prompting frameworks. Additionally, we introduce several\\npractical relevant prompt-based tools that fall outside the purview of the prompting framework domain and\\ntools that play a significant role in assisting LLMs in accomplishing tasks. In this section, we summarize the\\napplicability and limitations of existing prompting frameworks.\\nDespite the various attempts made by current prompting frameworks to alleviate the limitations of LLMs in\\nreal-world applications, there are still challenges and limitations that need to be addressed. These frameworks\\nhave emerged with different focuses and features, addressing various dimensions of user concerns, including\\ndocumentation and community support, compatibility, capabilities (such as the ability to use external tools,\\ncost reduction, etc.), which have indeed made strides in solving some of the issues. However, it is important\\nto note that current prompting frameworks can be considered as compromise solutions to meet user needs in\\ntoday’s commercial scenarios, rather than fully future-proof methods. The limitations of existing prompting\\nframeworks primarily revolve around the lack of support for security mechanisms and inherent limitations in\\ntheir capabilities.\\nSecurity Mechanisms. Regarding the security mechanisms within prompting frameworks, including resis-\\ntance to prompt-related attacks and constraints on LLMs’ behavior, there are currently significant limitations.\\nFirstly, most prompting frameworks do not adequately address resistance against prompt-related attacks, such\\nas injection and deception. These vulnerabilities pose a severe threat to system security. Additionally, in terms\\nof constraining LLMs’ behavior, current prompting frameworks rely primarily on manually configured safety\\npolicies similar to Reinforcement Learning from Human Feedback (RLHF). They have not fully leveraged advanced\\ntechnologies and methods, which can result in issues like redundant configurations, inflexibility, operational\\nrisks, and even limitations on the original functionality of LLMs.\\nCapability Limitations. The limitations in the capabilities of prompting frameworks themselves are evident,\\nespecially when it comes to developing applications with large language models (LLMs). One of the primary\\nreasons for this limitation is that many of the issues in LLM applications are rooted in the deficiencies of the\\nunderlying technology of large models, emphasizing the importance of prompt engineering. For instance, when\\nmanipulating LLMs to perform highly complex tasks using prompting frameworks, developers often rely on\\nhighly customized, handcrafted prompts. However, many existing prompting frameworks are designed with\\na \"simplification to complexity\" principle in mind. They assume that more complex structures lead to more\\ncomprehensive functionality. In other words, these frameworks tend to be overly complex and do not provide\\nsufficient openness in terms of prompt design. As a result, users often find themselves needing to configure\\nmany aspects of the system themselves, but prompting frameworks do not provide appropriate support for this\\nrequirement. Therefore, simplifying and streamlining the configuration process and providing more open and\\nflexible prompt design options could enhance the usability and effectiveness of these frameworks in developing\\ncomplex LLM applications. Simultaneously, the current prompting framework still faces notable shortcomings\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n29\\nin its accessibility to the broader external world, such as the limited support for third-party tools, including\\nmultimodal tools, and mainstream platforms like arXiv and Twitter.\\n7.2\\nFuture Directions\\nWe believe that the next-generation of prompting frameworks should overcome the limitations mentioned above\\nwhile integrating the strengths of the three prompting frameworks in this paper, which can provide users with\\nmore concise and compact interaction channels, facilitate LLMs interactions with powerful third-party interfaces,\\nand enable interactions with higher-quality and more tailored. The next-generation prompting framework should\\nbe a comprehensive platform that is more streamlined, more secure, more versatile, and more standardized, which\\nseamlessly integrates development, testing, evaluation, maintenance, expansion, and communication with LLMs,\\nconstituting an organic LLM ecosystem.\\nMore streamlined. The next-generation prompting framework should embody a higher degree of streamlining,\\nprimarily manifested in the simplification of user interactions with LLMs and the interactions between LLMs and\\nenvironments. Furthermore, the technical architecture and documentation should exhibit enhanced compatibility\\nwith new products and technologies, coupled with a more user-friendly learning curve and instructional materials.\\nIn essence, it should adhere to the principle of \"simplify without oversimplifying, embracing the concept of\\nsimplicity as the ultimate sophistication.\"\\nMore secure. The next-generation prompting framework ensures the secure and compliant generation of\\ncontent by Large Language Models (LLMs) while safeguarding user privacy and security, serving as a bidirectional\\nsecurity barrier between users and LLMs and between LLMs and applications.\\nMore versatile. The next-generation prompting framework seamlessly integrates with more diverse, feature-\\nrich external applications, enabling LLMs to excel in various domains such as healthcare, research, education,\\ntransportation, and more.\\nMore standardized The next-generation prompting framework adheres to established domain standards,\\nwhich are widely accepted sets of rules, guidelines, specifications, or best practices within specific domains\\nto ensure the quality, consistency, and reliability of products, services, or processes. Examples include ISO\\n27001 for information security management systems (ISMS) in the field of information technology and GMP\\nstandards for quality management in pharmaceutical and medical device manufacturing in the healthcare domain.\\nThese standards facilitate compliance across different prompting frameworks, eliminating the need for users to\\nacquire additional knowledge and promoting mutual support and complementarity between different prompting\\nframeworks.\\nOrganic LLMs ecosystem. The next-generation prompting framework seamlessly integrates with LLMs,\\nserving as a comprehensive platform for LLM development, testing, comparison, evaluation, user interaction,\\nand developer communication. This integration fosters an ecosystem that evolves through continuous feedback,\\nultimately delivering enhanced services and enabling leaps in technology and application development.\\nREFERENCES\\n[1] Fatih Kadir Akın. 2022. Awesome ChatGPT Prompts. https://github.com/f/awesome-chatgpt-prompts\\n[2] Mostafa M Amin, Erik Cambria, and Björn W Schuller. 2023. Will Affective Computing Emerge From Foundation Models and General\\nArtificial Intelligence? A First Evaluation of ChatGPT. IEEE Intelligent Systems 38, 2 (2023), 15–23.\\n[3] apache. 2022. CAMEL. https://github.com/apache/camel\\n[4] Stephen H. Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful\\nBari, Thibault Fevry, Zaid Alyafeaiu, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-David, Canwen Xu, Gunjan Chhablani, Han\\nWang, Jason Alan Fries, Maged S. Al-shaibani, Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Mike Tian-Jian, and\\nAlexander M. Rush. 2022. PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts.\\n(2022). https://arxiv.org/abs/2202.01279\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n30\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\n[5] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung,\\net al. 2023. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint\\narXiv:2302.04023 (2023).\\n[6] Clark Barrett, Brad Boyd, Ellie Burzstein, Nicholas Carlini, Brad Chen, Jihye Choi, Amrita Roy Chowdhury, Mihai Christodorescu,\\nAnupam Datta, Soheil Feizi, et al. 2023. Identifying and Mitigating the Security Risks of Generative AI. arXiv preprint arXiv:2308.14840\\n(2023).\\n[7] Yoshua Bengio, Aaron Courville, and Pascal Vincent. 2013. Representation learning: A review and new perspectives. IEEE transactions\\non pattern analysis and machine intelligence 35, 8 (2013), 1798–1828.\\n[8] Yoshua Bengio, Réjean Ducharme, and Pascal Vincent. 2000. A neural probabilistic language model. Advances in neural information\\nprocessing systems 13 (2000).\\n[9] Amanda Bertsch, Uri Alon, Graham Neubig, and Matthew R Gormley. 2023. Unlimiformer: Long-range transformers with unlimited\\nlength input. arXiv preprint arXiv:2305.01625 (2023).\\n[10] Luca Beurer-Kellner, Marc Fischer, and Martin Vechev. 2023. Prompting is programming: A query language for large language models.\\nProceedings of the ACM on Programming Languages 7, PLDI (2023), 1946–1969.\\n[11] Rishi Bommasani, Percy Liang, and Tony Lee. 2023. Holistic Evaluation of Language Models. Annals of the New York Academy of\\nSciences (2023).\\n[12] botpress. 2023. Botpress. https://github.com/botpress/botpress\\n[13] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam,\\nGirish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33\\n(2020), 1877–1901.\\n[14] Jake Brukhman. 2023. gpt-jargon. https://github.com/jbrukh/gpt-jargon\\n[15] Aydar Bulatov, Yuri Kuratov, and Mikhail S Burtsev. 2023. Scaling Transformer to 1M tokens and beyond with RMT. arXiv preprint\\narXiv:2304.11062 (2023).\\n[16] Yihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philip S Yu, and Lichao Sun. 2023. A comprehensive survey of ai-generated\\ncontent (aigc): A history of generative ai from gan to chatgpt. arXiv preprint arXiv:2303.04226 (2023).\\n[17] Yong Cao, Li Zhou, Seolhwa Lee, Laura Cabello, Min Chen, and Daniel Hershcovich. 2023. Assessing cross-cultural alignment between\\nchatgpt and human societies: An empirical study. arXiv preprint arXiv:2303.17466 (2023).\\n[18] Marco Cascella, Jonathan Montomoli, Valentina Bellini, and Elena Bignami. 2023. Evaluating the feasibility of ChatGPT in healthcare:\\nan analysis of multiple clinical and research scenarios. Journal of Medical Systems 47, 1 (2023), 33.\\n[19] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang,\\net al. 2023. A survey on evaluation of large language models. arXiv preprint arXiv:2307.03109 (2023).\\n[20] Harrison Chase. 2022. LangChain. https://github.com/hwchase17/langchain\\n[21] Lichang Chen, Jiuhai Chen, Tom Goldstein, Heng Huang, and Tianyi Zhou. 2023. InstructZero: Efficient Instruction Optimization for\\nBlack-Box Large Language Models. arXiv preprint arXiv:2306.03082 (2023).\\n[22] Le Chen, Pei-Hung Lin, Tristan Vanderbruggen, Chunhua Liao, Murali Emani, and Bronis de Supinski. 2023. LM4HPC: Towards\\nEffective Language Model Application in High-Performance Computing. arXiv preprint arXiv:2306.14979 (2023).\\n[23] Lingjiao Chen, Matei Zaharia, and James Zou. 2023. FrugalGPT: How to Use Large Language Models While Reducing Cost and\\nImproving Performance. arXiv preprint arXiv:2305.05176 (2023).\\n[24] Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, Zhiyuan\\nLiu, Maosong Sun, and Jie Zhou. 2023. AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in\\nAgents. arXiv:2308.10848 [cs.CL]\\n[25] Xuanting Chen, Junjie Ye, Can Zu, Nuo Xu, Rui Zheng, Minlong Peng, Jie Zhou, Tao Gui, Qi Zhang, and Xuanjing Huang. 2023. How\\nRobust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks. arXiv preprint arXiv:2303.00293 (2023).\\n[26] Ajay Kumar Chintala and Vignesh Aigal. [n. d.]. LLMStack: A platform to build and deploy LLM applications. https://github.com/\\ntrypromptly/llmstack\\n[27] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won\\nChung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker\\nBarnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob\\nAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski,\\nXavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph,\\nAlexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana\\nPillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,\\nBrennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and\\nNoah Fiedel. 2022. PaLM: Scaling Language Modeling with Pathways. arXiv:2204.02311 [cs.CL]\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n31\\n[28] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha\\nBrahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416 (2022).\\n[29] Ronan Collobert, Jason Weston, Léon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing\\n(almost) from scratch. Journal of machine learning research 12, ARTICLE (2011), 2493–2537.\\n[30] Wei Dai, Jionghao Lin, Flora Jin, Tongguang Li, Yi-Shan Tsai, Dragan Gasevic, and Guanliang Chen. 2023. Can large language models\\nprovide feedback to students? A case study on ChatGPT. (2023).\\n[31] Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang, Zefeng Li, Haoyu Wang, Tianwei Zhang, and Yang Liu. 2023. Jailbreaker:\\nAutomated Jailbreak Across Multiple Large Language Model Chatbots. arXiv preprint arXiv:2307.08715 (2023).\\n[32] Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, and Karthik Narasimhan. 2023. Toxicity in chatgpt:\\nAnalyzing persona-assigned language models. arXiv preprint arXiv:2304.05335 (2023).\\n[33] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for\\nlanguage understanding. arXiv preprint arXiv:1810.04805 (2018).\\n[34] Etienne Dilocker, Bob van Luijt, Byron Voorbach, Mohd Shukri Hasan, Abdel Rodriguez, Dirk Alexander Kulawiak, Marcin Antas, and\\nParker Duckworth. [n. d.]. Weaviate. https://github.com/weaviate/weaviate\\n[35] Ning Ding, Shengding Hu, Weilin Zhao, Yulin Chen, Zhiyuan Liu, Hai-Tao Zheng, and Maosong Sun. 2021. OpenPrompt: An\\nOpen-source Framework for Prompt-learning. arXiv preprint arXiv:2111.01998 (2021).\\n[36] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. A survey for\\nin-context learning. arXiv preprint arXiv:2301.00234 (2022).\\n[37] Hongyang Du, Zonghang Li, Dusit Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim, et al. 2023. Enabling AI-generated content (AIGC)\\nservices in wireless edge networks. arXiv preprint arXiv:2301.03220 (2023).\\n[38] Yogesh K Dwivedi, Nir Kshetri, Laurie Hughes, Emma Louise Slade, Anand Jeyaraj, Arpan Kumar Kar, Abdullah M Baabdullah,\\nAlex Koohang, Vishnupriya Raghavan, Manju Ahuja, et al. 2023. “So what if ChatGPT wrote it?” Multidisciplinary perspectives on\\nopportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of\\nInformation Management 71 (2023), 102642.\\n[39] Chris Dzoba. 2023. GPTRPG. https://github.com/dzoba/gptrpg\\n[40] Eric Elliott. 2023. SudoLang. https://github.com/paralleldrive/sudolang-llm-support\\n[41] Emilio Ferrara. 2023. Should chatgpt be biased? challenges and risks of bias in large language models. arXiv preprint arXiv:2304.03738\\n(2023).\\n[42] Forethought-Technologies. [n. d.]. AutoChain. https://github.com/Forethought-Technologies/AutoChain\\n[43] Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, and Mario Fritz. 2023. More than you’ve asked\\nfor: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models. arXiv preprint\\narXiv:2302.12173 (2023).\\n[44] griptape ai. 2023. Griptape. https://github.com/griptape-ai/griptape\\n[45] henomis. 2023. LinGoose. https://github.com/henomis/lingoose\\n[46] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin,\\nLiyang Zhou, Chenyu Ran, Lingfeng Xiao, and Chenglin Wu. 2023. MetaGPT: Meta Programming for Multi-Agent Collaborative\\nFramework. arXiv:2308.00352 [cs.AI]\\n[47] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora:\\nLow-rank adaptation of large language models. arXiv preprint arXiv:2106.09685 (2021).\\n[48] InsuranceToolkits. 2023. PromptFlow. https://github.com/InsuranceToolkits/promptflow\\n[49] Neel Jain, Khalid Saifullah, Yuxin Wen, John Kirchenbauer, Manli Shu, Aniruddha Saha, Micah Goldblum, Jonas Geiping, and Tom\\nGoldstein. 2023. Bring Your Own Data! Self-Supervised Evaluation for Large Language Models. arXiv preprint arXiv:2306.13651 (2023).\\n[50] Frederick Jelinek. 1998. Statistical methods for speech recognition. MIT press.\\n[51] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot\\nreasoners. Advances in neural information processing systems 35 (2022), 22199–22213.\\n[52] Sotiris B Kotsiantis, Ioannis Zaharakis, P Pintelas, et al. 2007. Supervised machine learning: A review of classification techniques.\\nEmerging artificial intelligence applications in computer engineering 160, 1 (2007), 3–24.\\n[53] John Lafferty, Andrew McCallum, and Fernando CN Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and\\nlabeling sequence data. (2001).\\n[54] Md Tahmid Rahman Laskar, M Saiful Bari, Mizanur Rahman, Md Amran Hossen Bhuiyan, Shafiq Joty, and Jimmy Xiangji Huang. 2023.\\nA Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets. arXiv preprint arXiv:2305.18486 (2023).\\n[55] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer.\\n2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv\\npreprint arXiv:1910.13461 (2019).\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n32\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\n[56] Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil,\\nImanol Schlag, Theo Gutman-Solo, et al. 2022. Solving quantitative reasoning problems with language models. Advances in Neural\\nInformation Processing Systems 35 (2022), 3843–3857.\\n[57] Xinzhe Li, Ming Liu, Shang Gao, and Wray Buntine. 2023. A survey on out-of-distribution evaluation of neural nlp models. arXiv\\npreprint arXiv:2306.15261 (2023).\\n[58] Yen-Ting Lin and Yun-Nung Chen. 2023. LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations\\nwith Large Language Models. arXiv preprint arXiv:2305.13711 (2023).\\n[59] Jerry Liu. 2022. LlamaIndex. https://doi.org/10.5281/zenodo.1234\\n[60] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2023. Pre-train, prompt, and predict: A\\nsystematic survey of prompting methods in natural language processing. Comput. Surveys 55, 9 (2023), 1–35.\\n[61] Siru Liu, Aileen P Wright, Barron L Patterson, Jonathan P Wanderer, Robert W Turer, Scott D Nelson, Allison B McCoy, Dean F Sittig,\\nand Adam Wright. 2023. Using AI-generated suggestions from ChatGPT to optimize clinical decision support. Journal of the American\\nMedical Informatics Association 30, 7 (2023), 1237–1245.\\n[62] Yi Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng, and Yang Liu. 2023. Prompt\\nInjection attack against LLM-integrated Applications. arXiv preprint arXiv:2306.05499 (2023).\\n[63] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin\\nStoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019).\\n[64] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, and Jianfeng Gao. 2023. Chameleon:\\nPlug-and-play compositional reasoning with large language models. arXiv preprint arXiv:2304.09842 (2023).\\n[65] Brady D Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, and Ziang Wang. 2023. ChatGPT and a new academic\\nreality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing. Journal of\\nthe Association for Information Science and Technology 74, 5 (2023), 570–581.\\n[66] Kai Mei, Zheng Li, Zhenting Wang, Yang Zhang, and Shiqing Ma. 2023. NOTABLE: Transferable Backdoor Attacks Against Prompt-based\\nNLP Models. arXiv preprint arXiv:2305.17826 (2023).\\n[67] David Mezzetti. 2020. txtai: the all-in-one embeddings database. https://github.com/neuml/txtai\\n[68] Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo\\nSchick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. 2023. Augmented language models: a survey. arXiv preprint arXiv:2302.07842 (2023).\\n[69] microsoft. 2023. Guidance. https://github.com/guidance-ai/guidance\\n[70] microsoft. 2023. TypeChat. https://github.com/microsoft/TypeChat\\n[71] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv\\npreprint arXiv:1301.3781 (2013).\\n[72] Tomas Mikolov, Martin Karafiát, Lukas Burget, Jan Cernock`y, and Sanjeev Khudanpur. 2010. Recurrent neural network based language\\nmodel.. In Interspeech, Vol. 2. Makuhari, 1045–1048.\\n[73] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and\\ntheir compositionality. Advances in neural information processing systems 26 (2013).\\n[74] Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, and Dan\\nRoth. 2023. Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey. ACM Comput. Surv.\\n56, 2, Article 30 (sep 2023), 40 pages. https://doi.org/10.1145/3605943\\n[75] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Rethinking the\\nrole of demonstrations: What makes in-context learning work? arXiv preprint arXiv:2202.12837 (2022).\\n[76] Marta Montenegro-Rueda, José Fernández-Cerero, José María Fernández-Batanero, and Eloy López-Meneses. 2023. Impact of the\\nImplementation of ChatGPT in Education: A Systematic Review. Computers 12, 8 (2023), 153.\\n[77] Yohei Nakajima. 2023. BabyAGI. https://github.com/yoheinakajima/babyagi\\n[78] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju,\\nWilliam Saunders, et al. 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332\\n(2021).\\n[79] NVIDIA. 2023. NeMo-Guardrails. https://github.com/NVIDIA/NeMo-Guardrails\\n[80] Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alexander Fraser, Shankar Kumar, Libin Shen,\\nDavid A Smith, Katherine Eng, et al. 2004. A smorgasbord of features for statistical machine translation. In Proceedings of the Human\\nLanguage Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004.\\n161–168.\\n[81] OpenAI. 2023. Evals. https://github.com/openai/evals\\n[82] OpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL]\\n[83] OpenDAN.ai. 2023. OpenDAN. https://www.opendan.ai/\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\nPrompting Frameworks for Large Language Models: A Survey\\n•\\n33\\n[84] Jonas Oppenlaender and Joonas Hämäläinen. 2023. Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and\\nGPT-4 for Cost-Efficient Question Answering. arXiv preprint arXiv:2306.05036 (2023).\\n[85] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina\\nSlama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information\\nProcessing Systems 35 (2022), 27730–27744.\\n[86] Ankit Pal. 2022. Promptify: Structured Output from LLMs. https://github.com/promptslab/Promptify. Prompt-Engineering components\\nfor NLP tasks in Python.\\n[87] Rodrigo Pedro, Daniel Castro, Paulo Carreira, and Nuno Santos. 2023. From Prompt Injections to SQL Injection Attacks: How Protected\\nis Your LLM-Integrated Web Application? arXiv preprint arXiv:2308.01990 (2023).\\n[88] Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023. Instruction tuning with gpt-4. arXiv preprint\\narXiv:2304.03277 (2023).\\n[89] Fábio Perez and Ian Ribeiro. 2022. Ignore Previous Prompt: Attack Techniques For Language Models. https://doi.org/10.48550/ARXIV.\\n2211.09527\\n[90] Malte Pietsch, Timo Möller, Bogdan Kostic, Julian Risch, Massimiliano Pippi, Mayank Jobanputra, Sara Zanzottera, Silvano Cerza,\\nVladimir Blagojevic, Thomas Stadelmann, Tanay Soni, and Sebastian Lee. 2019. Haystack: the end-to-end NLP framework for pragmatic\\nbuilders. https://github.com/deepset-ai/haystack\\n[91] Pinecone. 2023. Pinecone. https://github.com/pinecone-io\\n[92] Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi Yang. 2023. Is ChatGPT a general-purpose\\nnatural language processing task solver? arXiv preprint arXiv:2302.06476 (2023).\\n[93] Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, et al.\\n2023. Tool learning with foundation models. arXiv preprint arXiv:2304.08354 (2023).\\n[94] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language Models are Unsupervised Multitask\\nLearners. (2019).\\n[95] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020.\\nExploring the limits of transfer learning with a unified text-to-text transformer. The Journal of Machine Learning Research 21, 1 (2020),\\n5485–5551.\\n[96] reworkd. 2023. AgentGPT. https://github.com/reworkd/AgentGPT\\n[97] Matt Rickard. 2023. ReLLM. https://github.com/r2d4/rellm\\n[98] Ronald Rosenfeld. 2000. Two decades of statistical language modeling: Where do we go from here? Proc. IEEE 88, 8 (2000), 1270–1278.\\n[99] ruvnet. 2023. PromptLang. https://github.com/ruvnet/promptlang\\n[100] Justyna Sarzynska-Wawer, Aleksander Wawer, Aleksandra Pawlak, Julia Szymanowska, Izabela Stefaniak, Michal Jarkiewicz, and\\nLukasz Okruszek. 2021. Detecting formal thought disorder by deep contextualized word representations. Psychiatry Research 304\\n(2021), 114135.\\n[101] Sentdex. 2023. TermGPT. https://github.com/Sentdex/TermGPT\\n[102] ShreyaR. 2023. Guardrails. https://github.com/ShreyaR/guardrails\\n[103] Significant Gravitas. [n. d.]. Auto-GPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[104] Taranjeet Singh. 2023. Embedchain. https://github.com/embedchain/embedchain\\n[105] sobelio. 2023. llm-chain. https://github.com/sobelio/llm-chain\\n[106] Scott M Thede and Mary Harper. 1999. A second-order hidden Markov model for part-of-speech tagging. In Proceedings of the 37th\\nannual meeting of the Association for Computational Linguistics. 175–182.\\n[107] TimPietrusky. [n. d.]. Hyv. https://github.com/failfa-st/hyv\\n[108] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman\\nGoyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971\\n(2023).\\n[109] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal\\nBhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023).\\n[110] TransformerOptimus. 2023. SuperAGI. https://github.com/TransformerOptimus/SuperAGI\\n[111] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.\\nAttention is all you need. Advances in neural information processing systems 30 (2017).\\n[112] Gil LaHaye Vic Perdana. 2023. Semantic-kernel. https://github.com/microsoft/semantic-kernel\\n[113] Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng, Yidong Wang, Linyi Yang, Haojun Huang, Wei Ye, Xiubo Geng, et al.\\n2023. On the robustness of chatgpt: An adversarial and out-of-distribution perspective. arXiv preprint arXiv:2302.12095 (2023).\\n[114] Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin, Peng Xu, Shengjun Li, Xiangyu Wang, Xiangzhou Guo, Chengming Li, Xiaohai\\nXu, et al. 2021. Milvus: A Purpose-Built Vector Data Management System. In Proceedings of the 2021 International Conference on\\nManagement of Data. 2614–2627.\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n34\\n•\\nXiaoxia Liu, Jingyi Wang, Jun Sun, Xiaohan Yuan, Guoliang Dong, Peng Di, Wenhai Wang, and Dongxia Wang*\\n[115] Xinlong Wang, Wen Wang, Yue Cao, Chunhua Shen, and Tiejun Huang. 2023. Images speak in images: A generalist painter for\\nin-context visual learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 6830–6839.\\n[116] Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022. Self-instruct:\\nAligning language model with self generated instructions. arXiv preprint arXiv:2212.10560 (2022).\\n[117] Taylor Webb, Keith J Holyoak, and Hongjing Lu. 2023. Emergent analogical reasoning in large language models. Nature Human\\nBehaviour (2023), 1–16.\\n[118] Alexander Wei, Nika Haghtalab, and Jacob Steinhardt. 2023. Jailbroken: How does llm safety training fail? arXiv preprint arXiv:2307.02483\\n(2023).\\n[119] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou,\\nDonald Metzler, et al. 2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682 (2022).\\n[120] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought\\nprompting elicits reasoning in large language models. Advances in Neural Information Processing Systems 35 (2022), 24824–24837.\\n[121] Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, et al. 2023.\\nLarger language models do in-context learning differently. arXiv preprint arXiv:2303.03846 (2023).\\n[122] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Perric Cistac, Clara Ma, Yacine Jernite,\\nJulien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2020. Transformers:\\nState-of-the-Art Natural Language Processing. Association for Computational Linguistics, 38–45. https://www.aclweb.org/anthology/\\n2020.emnlp-demos.6\\n[123] Changrong Xiao, Sean Xin Xu, Kunpeng Zhang, Yufang Wang, and Lei Xia. 2023. Evaluating Reading Comprehension Exercises\\nGenerated by LLMs: A Showcase of ChatGPT in Education Applications. In Proceedings of the 18th Workshop on Innovative Use of NLP\\nfor Building Educational Applications (BEA 2023). 610–625.\\n[124] Tianbao Xie, Zhoujun Cheng, Yiheng Xu, Peng Shi, and Tao Yu. 2022. A framework for human-readable prompt-based method with large\\nlanguage models.\\n[125] Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen, Zheng Tang, Hai Wang, Vijay Srinivasan, Xiang Ren, and Hongxia Jin. 2023. Virtual\\nPrompt Injection for Instruction-Tuned Large Language Models. arXiv preprint arXiv:2307.16888 (2023).\\n[126] Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu. 2023. Harnessing the\\npower of llms in practice: A survey on chatgpt and beyond. arXiv preprint arXiv:2304.13712 (2023).\\n[127] Xianjun Yang, Yan Li, Xinlu Zhang, Haifeng Chen, and Wei Cheng. 2023. Exploring the limits of chatgpt for query or aspect-based text\\nsummarization. arXiv preprint arXiv:2302.08081 (2023).\\n[128] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive\\npretraining for language understanding. Advances in neural information processing systems 32 (2019).\\n[129] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. 2023. Tree of thoughts:\\nDeliberate problem solving with large language models. arXiv preprint arXiv:2305.10601 (2023).\\n[130] yzfly. 2023. LangGPT. https://github.com/yzfly/LangGPT\\n[131] Zhanpeng Zeng, Cole Hawkins, Mingyi Hong, Aston Zhang, Nikolaos Pappas, Vikas Singh, and Shuai Zheng. 2023. Vcc: Scaling\\nTransformers to 128K Tokens or More by Prioritizing Important Tokens. arXiv preprint arXiv:2305.04241 (2023).\\n[132] Zetaphor. 2023. Zep. https://github.com/getzep/zep\\n[133] Chaoning Zhang, Chenshuang Zhang, Chenghao Li, Yu Qiao, Sheng Zheng, Sumit Kumar Dam, Mengchun Zhang, Jung Uk Kim,\\nSeong Tae Kim, Jinwoo Choi, et al. 2023. One small step for generative ai, one giant leap for agi: A complete survey on chatgpt in aigc\\nera. arXiv preprint arXiv:2304.06488 (2023).\\n[134] Chaoning Zhang, Chenshuang Zhang, Sheng Zheng, Yu Qiao, Chenghao Li, Mengchun Zhang, Sumit Kumar Dam, Chu Myaet Thwal,\\nYe Lin Tun, Le Luang Huy, et al. 2023. A complete survey on generative ai (aigc): Is chatgpt from gpt-4 to gpt-5 all you need? arXiv\\npreprint arXiv:2303.11717 (2023).\\n[135] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican\\nDong, et al. 2023. A survey of large language models. arXiv preprint arXiv:2303.18223 (2023).\\n[136] Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc\\nLe, et al. 2022. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625 (2022).\\n[137] Jiaming Zhou, Tengyue Li, Simon James Fong, Nilanjan Dey, and Rubén González Crespo. 2023. Exploring chatGPT’S potential for\\nconsultation, recommendations and report diagnosis: Gastric cancer and gastroscopy reports’ case. IJIMAI 8, 2 (2023), 7–13.\\n[138] Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang,\\net al. 2023. PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts. arXiv preprint\\narXiv:2306.04528 (2023).\\n[139] zilliztech. 2023. GPTCache. https://github.com/zilliztech/GPTCache\\nACM Comput. Surv., Vol. 1, No. 1, Article . Publication date: November 2023.\\n']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [\"2402.01383v1\",\"2409.09957\",\"2409.15180\",\"2409.15816\",\"2408.02085\",\"2311.13731\",\"2311.12785\"]\n",
    "#ids = [\"2402.01383v1\",\"2409.09957\",\"2409.15180\",\"2409.15816\",\"2408.02085\",\"2311.13731\",\"2402.06196\",\"2408.02304\"]\n",
    "name = 'rag10_large_data'\n",
    "summaries = [get_summaries([name],id)[0] for id in ids]\n",
    "originals = [get_json('dataset/'+id+'data')['fulltext'] for id in ids]\n",
    "originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_all(candidate, reference,filename):\n",
    "    scores = []\n",
    "    if len(candidate)<100:\n",
    "        num = len(candidate)\n",
    "    else:\n",
    "        num = 100\n",
    "    for i in range(num):\n",
    "        P, R, F1 = scorer_bert.score([candidate[i]], [reference[i]])\n",
    "        scores.append([round(float(P[0]),4),round(float(R[0]),4),round(float(F1[0]),4)])\n",
    "    \n",
    "    m = np.mean(scores,axis=0)\n",
    "    s = np.std(scores,axis=0)\n",
    "    scores.append(m)\n",
    "    scores.append(s) \n",
    "    np.savetxt('results/'+filename+'_bert.txt',np.matrix(scores),fmt='%.2f')\n",
    "    return np.matrix(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.6609    , 0.6197    , 0.6396    ],\n",
       "        [0.5958    , 0.5836    , 0.5896    ],\n",
       "        [0.6509    , 0.6229    , 0.6366    ],\n",
       "        [0.6348    , 0.5999    , 0.6168    ],\n",
       "        [0.6145    , 0.5857    , 0.5998    ],\n",
       "        [0.6373    , 0.607     , 0.6218    ],\n",
       "        [0.5914    , 0.5679    , 0.5794    ],\n",
       "        [0.62651429, 0.5981    , 0.61194286],\n",
       "        [0.02473502, 0.01867045, 0.02137868]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bert_all(summaries, originals,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2402.01383v1', '2409.09957', '2409.15180', '2409.15816']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate length of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06044055943230335"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text of RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset \n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FaithulnesswithHHEM\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n",
      "File \u001b[0;32m~/FS24/masterarbeit/State_of_the_art/.venv/lib/python3.12/site-packages/ragas/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madaptation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adapt\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluationDataset, MultiTurnSample, SingleTurnSample\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n",
      "File \u001b[0;32m~/FS24/masterarbeit/State_of_the_art/.venv/lib/python3.12/site-packages/ragas/adaptation.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLanguageModel\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m llm_factory\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRagasLLM, LangchainLLMWrapper\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetricWithLLM\n",
      "File \u001b[0;32m~/FS24/masterarbeit/State_of_the_art/.venv/lib/python3.12/site-packages/ragas/llms/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     BaseRagasLLM,\n\u001b[1;32m      3\u001b[0m     LangchainLLMWrapper,\n\u001b[1;32m      4\u001b[0m     LlamaIndexLLMWrapper,\n\u001b[1;32m      5\u001b[0m     llm_factory,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseRagasLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLangchainLLMWrapper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlamaIndexLLMWrapper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_factory\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n",
      "File \u001b[0;32m~/FS24/masterarbeit/State_of_the_art/.venv/lib/python3.12/site-packages/ragas/llms/base.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass, field\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvertexai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatVertexAI\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VertexAI\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLanguageModel\n",
      "File \u001b[0;32m~/FS24/masterarbeit/State_of_the_art/.venv/lib/python3.12/site-packages/langchain_community/chat_models/vertexai.py:32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGeneration, ChatGenerationChunk, ChatResult\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pre_init\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvertexai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     _VertexAICommon,\n\u001b[1;32m     34\u001b[0m     is_codey_model,\n\u001b[1;32m     35\u001b[0m     is_gemini_model,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvertexai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     load_image_from_gcs,\n\u001b[1;32m     39\u001b[0m     raise_vertex_import_error,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/FS24/masterarbeit/State_of_the_art/.venv/lib/python3.12/site-packages/langchain_community/llms/vertexai.py:209\u001b[0m\n\u001b[1;32m    200\u001b[0m             params\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_count\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m params\n\u001b[1;32m    204\u001b[0m \u001b[38;5;129;43m@deprecated\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43msince\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.12\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremoval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43malternative_import\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlangchain_google_vertexai.VertexAI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mVertexAI\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43m_VertexAICommon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBaseLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Google Vertex AI large language models.\"\"\"\u001b[39;49;00m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-bison\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset \n",
    "from ragas.metrics import FaithulnesswithHHEM\n",
    "from ragas import evaluate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithfulness_with_hhem = FaithulnesswithHHEM()\n",
    "data_samples = {\n",
    "    'question': ['When was the first super bowl?', 'Who won the most super bowls?'],\n",
    "    'answer': ['The first superbowl was held on Jan 15, 1967', 'The most super bowls have been won by The New England Patriots'],\n",
    "    'contexts' : [['The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,'], \n",
    "    ['The Green Bay Packers...Green Bay, Wisconsin.','The Packers compete...Football Conference']],\n",
    "}\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "score = evaluate(dataset,metrics=[faithfulness_with_hhem])\n",
    "score.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
