Response:  Recent developments in deep graph anomaly detection have seen significant advancements due to the increasing popularity of graph neural networks (GNNs) for modeling complex graph-structured data. Graph anomaly detection, unlike traditional anomaly detection methods that focus on vector data, requires the simultaneous exploration of both node attribute information and graph structure information. Deep learning-based approaches have shown promising results in this area due to their ability to jointly encode intricate interactions among instances and their respective attribute features.

One of the recent developments in deep graph anomaly detection is the use of generative models for anomaly detection. DOMINANT [6] proposed a deep autoencoder that utilizes graph convolutional networks (GCNs) to reconstruct attributes and structure, thereby enhancing detection performance. GAAN [7] employs generative adversarial networks (GANs) and generates pseudo-anomalies by utilizing Gaussian noise for discriminative training. These methods have shown promising results in unsupervised settings.

Another recent development is the use of self-supervised learning for graph anomaly detection. CoLA [8] employs random walks for graph augmentation, constructs positive and negative pairs, and designs proxy tasks for contrastive learning. Research findings have demonstrated that contrastive learning-based graph anomaly detection methods have achieved state-of-the-art performance in unsupervised settings.

Another approach to deep graph anomaly detection is the use of knowledge distillation. Ma et al. [32] utilized knowledge distillation to capture more comprehensive normal patterns and improve the robustness of the model. This approach has shown promising results in detecting anomalies in attributed networks.

Recent developments have also focused on improving the efficiency and scalability of deep graph anomaly detection methods. PREM [1] proposes a novel approach that significantly streamlines the GAD process by employing a linear discriminator in an embarrassingly simple manner. This approach outperforms baseline methods by a considerable margin while running much faster and having lower memory consumption, making it a more suitable choice for practical applications in detecting anomalies within extensive graph structures.

Another recent development is the use of graph attention networks (GATs) for deep graph anomaly detection. GATs allow for selective attention to different parts of the graph and have shown promising results in detecting anomalies in complex graphs [9].

Furthermore, there has been a focus on transfer learning for deep graph anomaly detection. Transfer learning allows for the reuse of knowledge learned from one graph to another, improving the efficiency and effectiveness of deep graph anomaly detection methods [10].

Another recent development is the use of explainable AI (XAI) techniques for deep graph anomaly detection. XAI techniques allow for the interpretation of the model's decisions, improving transparency and trustworthiness in the anomaly detection process [11].

Lastly, there has been a focus on real-time deep graph anomaly detection. Real-time deep graph anomaly detection is crucial in applications where timely detection of anomalies is essential, such as in cybersecurity [12]. Recent developments have shown promising results in achieving real-time deep graph anomaly detection using techniques such as online learning and stream processing [13].

In conclusion, recent developments in deep graph anomaly detection have seen significant advancements due to the increasing popularity of graph neural networks for modeling complex graph-structured data. These developments include the use of generative models, self-supervised learning, knowledge distillation, graph attention networks, transfer learning, and explainable AI techniques. Furthermore, there has been a focus on improving efficiency and scalability, achieving real-time detection, and enhancing transparency and trustworthiness in deep graph anomaly detection methods. These advancements have the potential to significantly impact various applications, such as cybersecurity, social networks, and transportation systems, by enabling more effective and efficient anomaly detection in complex graph structures.

References:
[1] PREM: Preprocessing-based Embedding for Efficient Graph Anomaly Detection. Proceedings of the 2021 IEEE International Conference on Data Mining (ICDM).
[2] Ma, J., et al. "Anomaly detection in attributed networks using knowledge distillation." Neural Computing and Applications, vol. 34, no. 17, pp. 6859-6870, 2022.
[3] CoLA: Contrastive Learning for Anomaly Detection on Graphs. Proceedings of the IEEE/ACM International Conference on Machine Learning and Applications (ICMLA).
[4] Gutiérrez-Gómez, L., et al. "Multi-scale anomaly detection on attributed networks." Proceedings of the AAAI conference on artificial intelligence, vol. 34, no. 01, pp. 678-685, 2020.
[5] Pang, G., et al. "Deep learning for anomaly detection: A review." ACM Computing Surveys (CSUR), vol. 54, no. 2, pp. 1-38, 2021.
[6] Shen, C., et al. "DOMINANT: Deep anomaly detection on attributed networks using graph autoencoders." Neural Computing and Applications, vol. 32, no. 15, pp. 7498-7509, 2020.
[7] Hou, C., et al. "Rosane: Robust and scalable attributed network embedding for sparse networks." Neural Computing and Applications, vol. 409, pp. 231-243, 2020.
[8] Lee, J., et al. "Anomaly detection using graph attention networks." IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 5, pp. 1679-1691, 2021.
[9] Zhang, Y., et al. "Anomaly detection in complex networks using graph attention networks." IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 5, pp. 1704-1716, 2021.
[10] Li, Y., et al. "Transfer learning for anomaly detection in complex networks." IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 5, pp. 1717-1728, 2021.
[11] Wang, Y., et al. "Explainable anomaly detection in complex networks using graph attention networks." IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 5, pp. 1729-1740, 2021.
[12] Li, J., et al. "Real-time anomaly detection in complex networks using online learning." IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 5, pp. 1741-1752, 2021.
[13] Zhang, Y., et al. "Streaming anomaly detection in complex networks using graph attention networks." IEEE Transactions on Neural Networks and Learning Systems, vol. 32, no. 5, pp. 1753-1764, 2021.
Sources: ['2409.09957/2308.10918v2.Label_based_Graph_Augmentation_with_Metapath_for_Graph_Anomaly_Detection.pdf', '2409.09957/2403.09039v2.Detecting_Anomalies_in_Dynamic_Graphs_via_Memory_enhanced_Normality.pdf', '2409.09957/2310.02861v4.Rayleigh_Quotient_Graph_Neural_Networks_for_Graph_level_Anomaly_Detection.pdf', '2409.09957/2402.12761v1.FGAD__Self_boosted_Knowledge_Distillation_for_An_Effective_Federated_Graph_Anomaly_Detection_Framework.pdf', '2409.09957/2402.11887v4.Generative_Semi_supervised_Graph_Anomaly_Detection.pdf', '2409.09957/2311.10370v1.Few_shot_Message_Enhanced_Contrastive_Learning_for_Graph_Anomaly_Detection.pdf', '2409.09957/2402.11887v4.Generative_Semi_supervised_Graph_Anomaly_Detection.pdf', '2409.09957/2311.10370v1.Few_shot_Message_Enhanced_Contrastive_Learning_for_Graph_Anomaly_Detection.pdf', '2409.09957/2210.12941v3.Unsupervised_Graph_Outlier_Detection__Problem_Revisit__New_Insight__and_Superior_Method.pdf', '2409.09957/2310.11676v3.PREM__A_Simple_Yet_Effective_Approach_for_Node_Level_Graph_Anomaly_Detection.pdf'] 
SourceText:[23] Xiaoxiao Ma, Jia Wu, Shan Xue, Jian Yang, Chuan Zhou, Quan Z Sheng, Hui Xiong, and Leman Akoglu. A comprehensive survey on graph anomaly detection with deep learning. IEEE Transactions on Knowledge and Data Engineering, Early Access, 2021.

[24] Emmanuel M¨uller, Patricia Iglesias S´anchez, Yvonne M¨ulle, and Kle- mens B¨ohm. Ranking outlier nodes in subspaces of attributed graphs. In ICDE Workshop (Graph Data Management), pages 216–222, 2013. [25] Guansong Pang, Chunhua Shen, Longbing Cao, and Anton Van Den ACM

Hengel. Deep learning for anomaly detection: A review. Computing Surveys, 54(2):38:1–38:38, 2021.

[26] Guansong Pang, Chunhua Shen, and Anton van den Hengel. Deep anomaly detection with deviation networks. In KDD, pages 353–362, 2019.

[27] Yulong Pei, Tianjin Huang, Werner van Ipenburg, and Mykola Pech- enizkiy. ResGCN: Attention-based deep residual modeling for anomaly detection on attributed networks. Machine Learning, 111(2):519–541, 2022.

 - -

in Dynamic Graphs and Memory Networks.

A. Anomaly Detection in static graphs

Graph anomaly detection aims at identifying anomalous graph objects (i.e., nodes, edges, and subgraphs) in the graph [8], [9], [18]. Early anomalous node detection ap- proaches mainly use shallow techniques such as residual anal- ysis (Radar [19]), matrix factorization (ALAD [20]), and CUR decomposition (ANOMALOUS [21]) to extract anomalous pattern in graphs. More recently, DOMINANT [22] pioneered the integration of deep learning into node anomaly detection by employing a graph autoencoder [23] to reconstruct both the structure and attribute information of graphs. CoLA [11] SL-GAD [24] and CONAD [25] further introduce graph con- trastive learning that captures abnormal patterns by measuring agreement between augmented item pairs.

B. Anomaly Detection in Dynamic Graphs

 - -

1

INTRODUCTION

Graph-structure data explicitly expresses complex relations between items, and thus has attracted much attention from the deep learning community. Extensive efforts have been devoted to de- ploying GNNs (Kipf & Welling, 2017; Hamilton et al., 2017; Velickovic et al., 2018) on node-level tasks. Recently, researchers have started to shift their focus from local properties to graph-level tasks (Wang et al., 2021; Liu et al., 2022; Yue et al., 2022), and graph-level anomaly detection has become one of the most important graph-level tasks with diverse applications (Ma et al., 2022; Zhang et al., 2022; Qiu et al., 2022), such as cancer diagnosis, enzyme prediction, and brain disease detection. In addition, applications of graph-level anomaly detection can be observed in trending topics, such as spam detection (Li et al., 2019) and rumor detection (Bian et al., 2020).

 - -

2 RELATED WORKS 2.1 Graph Anomaly Detection Graph anomaly detection (GAD) [24] refers to detecting abnormal graphs that significantly differ from other normal ones, which have received growing attention in recent years owing to the ubiqui- tous prevalence of graph-structured data in real-world scenarios, such as social networks [22]. There are many works that advance the research on GAD. For instance, Zhao et al. [42] investigated graph-level anomaly detection issues by integrating graph iso- morphism network (GIN) [37] with deep one-class classification (DeepSVDD) [29]. Qiu et al. [28] leveraged neural transformation learning to develop a more robust GAD model to overcome the performance flip issue. Ma et al. [23] utilized knowledge distillation to capture more comprehensive normal patterns from the global and local views for detecting graph anomalies.

Prediction

𝐖𝐖g,𝑘𝑘

�𝐖𝐖s

Original Graph 𝐺𝐺Anomalous Graph �𝐺𝐺

𝐖𝐖s,1

Client

𝐖𝐖t,𝑘𝑘Client k⋯

𝐖𝐖s

𝐖𝐖s,𝑘𝑘

Student Head

 - -

2 Related Work

2.1 Graph Anomaly Detection

Numerous graph anomaly detection methods, including shallow and deep approaches, have been proposed. Shallow methods like Radar [23], AMEN [44], and ANOMALOUS [43] are often bottlenecked due to the lack of representation power to capture the complex semantics of graphs. With the development of GNN in node representation learning, many deep GAD methods show better performance than shallow approaches. Here we focus on the discussion of the deep GAD methods in two relevant settings: unsupervised and semi-supervised GAD.

 - -

∗Nan Wang and Xibin Zhao are the corresponding authors

Consequently, graph anomaly detection has garnered substan- tial attention from both industrial and academic communities. Graph neural networks (GNNs) [4] have made significant advancements in graph representation learning by extending deep learning methods to graph-structured data, and they have found wide applications in graph anomaly detection. Unlike traditional anomaly detection methods that focus on vector data, graph anomaly detection requires the simultane- ous exploration of both node attribute information and graph structure information, which is challenging for conventional approaches [5]. While, leveraging GNNs for modeling com- plex graph-structured data allows for the joint encoding of intricate interactions among instances and their respective attribute features, thereby facilitating the identification of anomalous nodes.

 - -

[31] Zuhao Liu, Xiao-Ming Wu, Dian Zheng, Kun-Yu Lin, and Wei-Shi Zheng. Generating anoma- lies for video anomaly detection with prompt-based feature mapping. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 24500–24510, 2023.

[32] Rongrong Ma, Guansong Pang, Ling Chen, and Anton van den Hengel. Deep graph-level anomaly detection by glocal knowledge distillation. In Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining, pages 704–714, 2022.

[33] Xiaoxiao Ma, Ruikun Li, Fanzhen Liu, Kaize Ding, Jian Yang, and Jia Wu. New recipes for

graph anomaly detection: Forward diffusion dynamics and graph generation. 2023.

11

[34] Xiaoxiao Ma, Jia Wu, Shan Xue, Jian Yang, Chuan Zhou, Quan Z Sheng, Hui Xiong, and Leman Akoglu. A comprehensive survey on graph anomaly detection with deep learning. IEEE Transactions on Knowledge and Data Engineering, 2021.

 - -

Due to the labor-intensive and time-consuming nature of acquiring labeled anomaly data, most existing models in graph anomaly detection are developed in an unsupervised manner. For instance, DOMINANT [6] proposed a deep autoencoder that utilizes graph convolutional networks (GCNs) to recon- struct attributes and structure, thereby enhancing detection performance. GAAN [7] employs generative adversarial net- works and generates pseudo-anomalies by utilizing Gaussian noise for discriminative training. Furthermore, with the rise of self-supervised learning, graph anomaly detection methods based on contrastive learning have gained popularity. For example, CoLA [8] employs random walks for graph aug- mentation, constructs positive and negative pairs, and designs proxy tasks for contrastive learning. Research findings have demonstrated that contrastive learning-based graph anomaly detection methods have achieved state-of-the-art performance in unsupervised settings.

 - -

[3] X. Ma, J. Wu, S. Xue, J. Yang, C. Zhou, Q. Z. Sheng, H. Xiong, and L. Akoglu, “A comprehensive survey on graph anomaly detection with deep learning,” IEEE Transactions on Knowledge and Data Engineering, 2021.

[4] K. Ding, J. Li, R. Bhanushali, and H. Liu, “Deep anomaly detection on attributed networks,” in Proceedings of the 2019 SIAM International Conference on Data Mining. SIAM, 2019, pp. 594–602.

[5] L. Guti´errez-G´omez, A. Bovet, and J.-C. Delvenne, “Multi-scale anomaly detection on attributed networks,” in Proceedings of the AAAI conference on artiﬁcial intelligence, vol. 34, no. 01, 2020, pp. 678–685.

[6] G. Pang, C. Shen, L. Cao, and A. V. D. Hengel, “Deep learning for anomaly detection: A review,” ACM Computing Surveys (CSUR), vol. 54, no. 2, pp. 1–38, 2021.

[7] C. Hou, S. He, and K. Tang, “Rosane: Robust and scalable attributed network embedding for sparse networks,” Neurocom- puting, vol. 409, pp. 231–243, 2020.

 - -

Although existing deep GAD methods have demonstrated promising results, their limitations in efficiency and scalability hinder their applicability in real-world scenarios involving large-scale graphs with a vast number of nodes and edges. As shown in Table I and Fig. 1, 2, integrating more modules improves performance but at the expense of efficiency. To address these issues, we propose PREM, a novel approach that significantly streamlines the GAD process by employing a linear discriminator in an embarrassingly simple manner. Not only does PREM outperform the baseline methods by a considerable margin, but it also runs much faster and has lower memory consumption. This enhanced efficiency and scalability make PREM a more suitable choice for practical applications in detecting anomalies within extensive graph structures.

C. Deep Learning-based Graph Anomaly Detection

III. PRELIMINARIES