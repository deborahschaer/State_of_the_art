 In this research, three studies were presented focusing on different aspects of evaluating the quality of language models (LLMs) in various natural language processing tasks.

1. CoAScore: An NLG evaluation metric called CoAScore was proposed, which utilizes multi-aspect knowledge through a Chain-of-Aspects (CoA) prompting framework. The CoAScore first prompts the LLM to generate a chain of aspects relevant to the target aspect and then collects evaluation scores for each generated aspect. Finally, it leverages the knowledge of these aspects to improve the evaluation of the target aspect. The study demonstrated that CoAScore outperforms existing unsupervised evaluation metrics in five NLG evaluation tasks and nine aspects, with a higher correlation to human judgments.

2. RAGAs: A framework called Retrieval Augmented Generation Assessment (RAGAs) was introduced for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAG systems consist of a retrieval system and an LLM-based generation module, which can act as a natural language layer between users and textual databases. The study proposed a suite of metrics to evaluate the different dimensions of RAG architectures without relying on ground truth human annotations, contributing to faster evaluation cycles.

3. Split and Merge: To address position bias in LLM-based evaluators, PORTIA (Position Bias Rectification using Transformers for Inter-Answer Alignment) was proposed. PORTIA splits answers into multiple segments, aligns similar content across candidate answers, and merges them back into a single prompt for evaluation by LLMs. The study demonstrated that PORTIA enhances the consistency rates for all models and comparison forms tested, enabling less advanced GPT models to achieve high agreement with state-of-the-art models at lower costs. Additionally, it rectifies around 80% of position bias instances within the GPT-4 model, elevating its consistency rate up to 98%.

Overall, these studies aim to improve the evaluation of LLMs in various natural language processing tasks by addressing challenges such as position bias and the need for reference-free evaluation.