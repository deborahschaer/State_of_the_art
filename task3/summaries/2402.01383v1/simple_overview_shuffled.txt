 Title: Recent Advances in Large Language Model Evaluation: TIGERScore, EvalLM, Branch-Solve-Merge, and FLASK

In recent years, there has been a surge of interest in evaluating the performance of large language models (LLMs) in natural language generation (NLG) tasks. In this summary, we will discuss four recent studies that have made significant strides in developing new methods for evaluating LLMs: TIGERScore, EvalLM, Branch-Solve-Merge, and FLASK.

1. TIGERScore: A Universal Explainable Metric for NLG Tasks
TIGERScore is a reference-free metric that evaluates the rationality of explanations generated by LLMs. The study demonstrates that TIGERScore's correlation with human ratings is high and approaches that of GPT-4 evaluators. Human evaluation of the generated explanations showed an accuracy of 70.8%. The researchers believe that TIGERScore shows the potential for building universal explainable metrics to evaluate any NLG task.

2. EvalLM: Interactive System for Iteratively Refining Prompts by Evaluating Multiple Outputs on User-Defined Criteria
EvalLM is an interactive system designed to help developers refine prompts for LLMs by evaluating multiple outputs based on user-defined criteria. The study shows that EvalLM helps participants compose more diverse criteria, examine twice as many outputs, and reach satisfactory prompts with 59% fewer revisions compared to manual evaluation.

3. Branch-Solve-Merge: Improving Large Language Model Evaluation and Generation
Branch-Solve-Merge (BSM) is a program that uses branch, solve, and merge modules to tackle challenging NLG tasks by planning a decomposition of the task into multiple parallel sub-tasks, independently solving them, and fusing the solutions. The study shows that BSM enhances human-LLM agreement, reduces length and pairwise position biases, and allows LLMs to match or outperform GPT-4 on most domains.

4. FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets
FLASK is a fine-grained evaluation protocol for both human-based and model-based evaluation that decomposes coarse-level scoring to skill set-level scoring for each instruction. The study shows that the fine-graininess of evaluation is crucial for attaining a holistic view of model performance and increasing the reliability of the evaluation. Using FLASK, multiple open-source and proprietary LLMs were compared, resulting in high correlation between model-based and human-based evaluations.

These studies represent significant advancements in the field of LLM-based NLG evaluation and demonstrate the potential for developing more effective methods for evaluating and refining LLMs for various applications. For more information on these studies, please visit the project websites provided:

* TIGERScore: <https://tiger-ai-lab.github.io/TIGERScore/>
* EvalLM: N/A (The study was published in arXiv and does not have a dedicated website)
* Branch-Solve-Merge: <https://arxiv.org/abs/2304.13958>
* FLASK: <https://github.com/kaistAI/FLASK>